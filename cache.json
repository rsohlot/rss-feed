{
  "sources": [
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Blog",
      "feedUrl": "http://machinelearningmastery.com/blog/feed",
      "siteUrl": "https://machinelearningmastery.com",
      "articles": [
        {
          "id": "https://machinelearningmastery.com/?p=13540",
          "author": "Zhe Ming Chng",
          "description": "You’ve probably heard of Kaggle data science competitions, but did you know that Kaggle has many other features that can help you with your next machine learning project? For people looking for datasets for their next machine learning project, Kaggle allows you to access public datasets by others and share your own datasets. For those […]\nThe post Using Kaggle in Machine Learning Projects appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/using-kaggle-in-machine-learning-projects/",
          "publishedOn": "2022-05-02T14:02:04.000Z",
          "wordCount": 2074,
          "title": "Using Kaggle in Machine Learning Projects",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/stefan-widua-kOuaZs7jDZE-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13534",
          "author": "Adrian Tam",
          "description": "We write a program to solve a problem or make a tool that we can repeatedly solve a similar problem. For the latter, it is inevitable that we come back to revisit the program we wrote, or someone else is reusing the program we write. There is also a chance that we will encounter data […]\nThe post Techniques to Write Better Python Code appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/techniques-to-write-better-python-code/",
          "publishedOn": "2022-04-29T14:47:30.000Z",
          "wordCount": 4370,
          "title": "Techniques to Write Better Python Code",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/pexels-anna-shvets-5711877-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13531",
          "author": "MLM Team",
          "description": "Sponsored Post In our interconnected world, a decision made thousands of miles away can have lasting consequences for entire organizations or economies. When small changes have big effects, it is unsurprising that companies and governments are turning to machine learning and AI to accurately predict risk. ​ How the Global Community is Applying Machine Learning […]\nThe post Take Your Machine Learning Skills Global appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/take-your-machine-learning-skills-global/",
          "publishedOn": "2022-04-28T02:48:36.000Z",
          "wordCount": 722,
          "title": "Take Your Machine Learning Skills Global",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/mlm-allcampus-0428-header.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13494",
          "author": "Zhe Ming Chng",
          "description": "Have you ever wanted an easy-to-configure interactive environment to run your machine learning code that came with access to GPUs for free? Google Colab is the answer you’ve been looking for. It is a convenient and easy to use way to run Jupyter notebooks on the cloud and their free version comes with some limited […]\nThe post Google Colab for Machine Learning Projects appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/google-colab-for-machine-learning-projects/",
          "publishedOn": "2022-04-27T19:39:20.000Z",
          "wordCount": 3787,
          "title": "Google Colab for Machine Learning Projects",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/PIA25015-scaled.jpeg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13492",
          "author": "Daniel Chung",
          "description": "When you work on a computer vision project, you probably need to preprocess a lot of image data. This is time-consuming, and it would be great if you could process multiple images in parallel. Multiprocessing is the ability of a system to run multiple processors at one time. If you had a computer with a […]\nThe post Multiprocessing in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/multiprocessing-in-python/",
          "publishedOn": "2022-04-25T14:02:57.000Z",
          "wordCount": 2731,
          "title": "Multiprocessing in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/pexels-thirdman-6193847-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13523",
          "author": "MLM Team",
          "description": "Sponsored Post Search systems are in the process of being revolutionized by Deep Learning and AI applications. To successfully evaluate, build, deploy and scale information retrieval systems, engineers working with search systems must understand the frameworks and algorithms that underpin this technology. Professors Ricardo Baeza-Yates (Northeastern University) has done research on information retrieval and web […]\nThe post Interactive Course on Optimizing Search Engines With Ricardo Baeza-Yates Starting May 10 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/interactive-course-on-optimizing-search-engines-with-ricardo-baeza-yates-starting-may-10/",
          "publishedOn": "2022-04-24T22:00:19.000Z",
          "wordCount": 495,
          "title": "Interactive Course on Optimizing Search Engines With Ricardo Baeza-Yates Starting May 10",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/ricardo.png"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13483",
          "author": "Adrian Tam",
          "description": "When we finished a Python project and roll it out for other people to use it, the easiest is to present our project as a command line program. If you want to make it friendlier, you may want to develop a GUI for your program so people can interact with the program with mouse clicks […]\nThe post Web Frameworks for Your Python Projects appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/web-frameworks-for-your-python-projects/",
          "publishedOn": "2022-04-22T14:00:39.000Z",
          "wordCount": 10847,
          "title": "Web Frameworks for Your Python Projects",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/pexels-quang-nguyen-vinh-2150371-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13475",
          "author": "Adrian Tam",
          "description": "After all the hard work on developing a project in Python, we want to share our project with other people. It can be your friend or your colleagues. Maybe they do not interested in your code, but they want to run it and make some real use of it. An example is you created a […]\nThe post A First Course on Deploying Python Projects appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/a-first-course-on-deploying-python-projects/",
          "publishedOn": "2022-04-20T13:45:53.000Z",
          "wordCount": 2974,
          "title": "A First Course on Deploying Python Projects",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/pexels-kelly-l-6595774.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13479",
          "author": "MLM Team",
          "description": "Sponsored Post Unlike traditional online courses, Foster Provost’s workshops will give you the chance to engage live with a world-class […]\nThe post 10 seats remaining | A series of live ML strategy workshops appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/10-seats-remaining-a-series-of-live-ml-strategy-workshops/",
          "publishedOn": "2022-04-19T17:56:48.000Z",
          "wordCount": 493,
          "title": "10 seats remaining | A series of live ML strategy workshops",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/image1.png"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13478",
          "author": "MLM Team",
          "description": "Sponsored Post By Luis Bermudez This blog walks through a process for experimenting with hyperparameters, training algorithms and other parameters […]\nThe post Guide to Iteratively Tuning GNNs appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/guide-to-iteratively-tuning-gnns/",
          "publishedOn": "2022-04-18T17:14:51.000Z",
          "wordCount": 1907,
          "title": "Guide to Iteratively Tuning GNNs",
          "imageUrl": "https://www.kdnuggets.com/wp-content/uploads/sigopt_guide_tuning_gnn_8.png"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13410",
          "author": "Zhe Ming Chng",
          "description": "Big data, labeled data, noisy data. Machine learning projects all need to look at data. Data is a critical aspect […]\nThe post Managing Data for Machine Learning Project appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/managing-data-for-machine-learning-project/",
          "publishedOn": "2022-04-18T13:00:12.000Z",
          "wordCount": 8936,
          "title": "Managing Data for Machine Learning Project",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/25260822078_88802ea8fa_h.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13468",
          "author": "Adrian Tam",
          "description": "In the old days, it was a tedious job to collect data, and sometimes very expensive. Machine learning projects cannot […]\nThe post Web Crawling in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/web-crawling-in-python/",
          "publishedOn": "2022-04-15T18:05:18.000Z",
          "wordCount": 3625,
          "title": "Web Crawling in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/pexels-ray-bilcliff-4805619-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13457",
          "author": "Adrian Tam",
          "description": "When we talk about managing data, it is quite inevitable to see data presented in tables. With column header, and […]\nThe post Massaging Data using Pandas appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/massaging-data-using-pandas/",
          "publishedOn": "2022-04-13T14:00:08.000Z",
          "wordCount": 7442,
          "title": "Massaging Data using Pandas",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/pexels-mark-de-jong-6939449-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13454",
          "author": "MLM Team",
          "description": "By Vincent Granville, Ph.D., Author at MLtechniques.com Sponsored Post Very deep neural networks (VDNN) illustrated with data animation: a 40 second […]\nThe post Very Deep Neural Networks Explained in 40 Seconds appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/very-deep-neural-networks-explained-in-40-seconds/",
          "publishedOn": "2022-04-12T16:37:13.000Z",
          "wordCount": 1213,
          "title": "Very Deep Neural Networks Explained in 40 Seconds",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/dnn.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13442",
          "author": "Adrian Tam",
          "description": "Python is a general-purpose computation language, but it is very welcomed in scientific computing. It can replace R and Matlab […]\nThe post Scientific Functions in NumPy and SciPy appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/scientific-functions-in-numpy-and-scipy/",
          "publishedOn": "2022-04-12T02:24:11.000Z",
          "wordCount": 3561,
          "title": "Scientific Functions in NumPy and SciPy",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/pexels-nothing-ahead-4494641-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13440",
          "author": "Mitch Bartlett",
          "description": "Sponsored Post Join the UK’s most forward-thinking technologists and business professionals this June in a celebration of emerging technology. Machine […]\nThe post Win tickets to The AI Summit London 2022 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/win-tickets-to-the-ai-summit-london-2022/",
          "publishedOn": "2022-04-05T21:04:02.000Z",
          "wordCount": 489,
          "title": "Win tickets to The AI Summit London 2022",
          "imageUrl": "https://www.kdnuggets.com/wp-content/uploads/informa-ai-summit-lopndon-header-mlm-20220405.png"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13385",
          "author": "Daniel Chung",
          "description": "Logging is a way to store information about your script and track events that occur. When writing any complex script […]\nThe post Logging in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/logging-in-python/",
          "publishedOn": "2022-04-04T20:00:58.000Z",
          "wordCount": 6639,
          "title": "Logging in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/pexels-ilaria-122588-scaled.jpg"
        }
      ]
    },
    {
      "title": "Machine Learning Archives - Uber Engineering Blog",
      "feedUrl": "https://eng.uber.com/tag/machine-learning/feed",
      "siteUrl": "https://eng.uber.com",
      "articles": []
    },
    {
      "title": "AWS Machine Learning Blog",
      "feedUrl": "https://aws.amazon.com/blogs/machine-learning/feed",
      "siteUrl": "https://aws.amazon.com/blogs/machine-learning/",
      "articles": [
        {
          "id": "ca41bfb156ca03da3041d19681f4f8e3f26aefa2",
          "author": "Vikram Elango",
          "description": "Machine learning (ML) applications are complex to deploy and often require multiple ML models to serve a single inference request. A typical request may flow across multiple models with steps like preprocessing, data transformations, model selection logic, model aggregation, and postprocessing. This has led to the evolution of common design patterns such as serial inference […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/achieve-hyperscale-performance-for-model-serving-using-nvidia-triton-inference-server-on-amazon-sagemaker/",
          "publishedOn": "2022-05-02T20:30:50.000Z",
          "wordCount": 4642,
          "title": "Achieve hyperscale performance for model serving using NVIDIA Triton Inference Server on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/21/ML-7392-image003-new.png"
        },
        {
          "id": "f8814a9c31f9794fc4534fa3c01cde7f24d7586e",
          "author": "Sanjiv Das",
          "description": "Today, we’re releasing a new solution for financial graph machine learning (ML) in Amazon SageMaker JumpStart. JumpStart helps you quickly get started with ML and provides a set of solutions for the most common use cases that can be trained and deployed with just a few clicks. The new JumpStart solution (Graph-Based Credit Scoring) demonstrates […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-corporate-credit-ratings-classifier-using-graph-machine-learning-in-amazon-sagemaker-jumpstart/",
          "publishedOn": "2022-05-02T18:52:21.000Z",
          "wordCount": 2467,
          "title": "Build a corporate credit ratings classifier using graph machine learning in Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/27/Featured-images-for-ML-9318.jpg"
        },
        {
          "id": "3f85ab1c3652913c9223c17b0f6d3eec4a8a7b50",
          "author": "Harry Pan",
          "description": "Reading the printed word opens up a world of information, imagination, and creativity. However, scanned books and documents may be difficult for people with vision impairment and learning disabilities to consume. In addition, some people prefer to listen to text-based content versus reading it. A document-to-speech solution extends the reach of digital content by giving […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/increase-your-content-reach-with-automated-document-to-speech-conversion-using-amazon-ai-services/",
          "publishedOn": "2022-05-02T18:40:37.000Z",
          "wordCount": 2294,
          "title": "Increase your content reach with automated document-to-speech conversion using Amazon AI services",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/26/Featured-images-for-ML-3497.jpg"
        },
        {
          "id": "42b6c7e3dc16fa083df0423b83bac100aee86c18",
          "author": "Prathyusha Cheruku",
          "description": "Today, AWS announced the general availability of Amazon Rekognition Streaming Video Events, a fully managed service for camera manufacturers and service providers that uses machine learning (ML) to detect objects such as people, pets, and packages in live video streams from connected cameras. Amazon Rekognition Streaming Video Events sends them a notification as soon as […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/amazon-rekognition-introduces-streaming-video-events-to-provide-real-time-alerts-on-live-video-streams/",
          "publishedOn": "2022-04-28T20:41:10.000Z",
          "wordCount": 2316,
          "title": "Amazon Rekognition introduces Streaming Video Events to provide real-time alerts on live video streams",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/28/Tangelo-2x-2-tile-image-with-bounding-boxes.png"
        },
        {
          "id": "fee0af2db1c09913aaf3783a385b99a06227861e",
          "author": "Mike Ames",
          "description": "3xLOGIC is a leader in commercial electronic security systems. They provide commercial security systems and managed video monitoring for businesses, hospitals, schools, and government agencies. Managed video monitoring is a critical component of a comprehensive security strategy for 3xLOGIC’s customers. With more than 50,000 active cameras in the field, video monitoring teams face a daily […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/3xlogic-uses-amazon-rekognition-streaming-video-events-to-provide-intelligent-video-analytics-on-live-video-streams-to-monitoring-agents/",
          "publishedOn": "2022-04-28T20:40:44.000Z",
          "wordCount": 1345,
          "title": "3xLOGIC uses Amazon Rekognition Streaming Video Events to provide intelligent video analytics on live video streams to monitoring agents",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/27/Featured-images-for-3XLogic.jpg"
        },
        {
          "id": "a452e05b90e412ef2591797f9b30e1b82f8c67c5",
          "author": "Mike Ames",
          "description": "Abode Systems (Abode) offers homeowners a comprehensive suite of do-it-yourself home security solutions that can be set up in minutes and enables homeowners to keep their family and property safe. Since the company’s launch in 2015, in-camera motion detection sensors have played an essential part in Abode’s solution, enabling customers to receive notifications and monitor […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/abode-uses-amazon-rekognition-streaming-video-events-to-provide-real-time-notifications-to-their-smart-home-customers/",
          "publishedOn": "2022-04-28T20:40:37.000Z",
          "wordCount": 1781,
          "title": "Abode uses Amazon Rekognition Streaming Video Events to provide real-time notifications to their smart home customers",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/27/Featured-images-for-ML-8236.jpg"
        },
        {
          "id": "82c9bf029678969db18d7ce93d1c4f3d82831775",
          "author": "Ben Harris",
          "description": "Amazon SageMaker Data Wrangler reduces the time to aggregate and prepare data for machine learning (ML) from weeks to minutes. With Data Wrangler, you can select and query data with just a few clicks, quickly transform data with over 300 built-in data transformations, and understand your data with built-in visualizations without writing any code. Additionally, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/pandas-user-defined-functions-are-now-available-in-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2022-04-28T17:38:34.000Z",
          "wordCount": 1314,
          "title": "Pandas user-defined functions are now available in Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/28/Featured-images-for-ML-9272-new.jpg"
        },
        {
          "id": "e49c9610e2acf6b2c82fc2f56a2f6cc6f362627f",
          "author": "Daniel Burke",
          "description": "Searchmetrics is a global provider of search data, software, and consulting solutions, helping customers turn search data into unique business insights. To date, Searchmetrics has helped more than 1,000 companies such as McKinsey & Company, Lowe’s, and AXA find an advantage in the hyper-competitive search landscape. In 2021, Searchmetrics turned to AWS to help with […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-searchmetrics-uses-amazon-sagemaker-to-automatically-find-relevant-keywords-and-make-their-human-analysts-20-faster/",
          "publishedOn": "2022-04-28T17:33:57.000Z",
          "wordCount": 1427,
          "title": "How Searchmetrics uses Amazon SageMaker to automatically find relevant keywords and make their human analysts 20% faster",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/28/searchmetrics-sagemaker.jpg"
        },
        {
          "id": "69dd315e48aee73eed96e91151bb0073416a09f6",
          "author": "Bala Krishnamoorthy",
          "description": "Identifying paraphrased text has business value in many use cases. For example, by identifying sentence paraphrases, a text summarization system could remove redundant information. Another application is to identify plagiarized documents. In this post, we fine-tune a Hugging Face transformer on Amazon SageMaker to identify paraphrased sentence pairs in a few steps. A truly robust […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/identify-paraphrased-text-with-hugging-face-on-amazon-sagemaker/",
          "publishedOn": "2022-04-28T16:56:28.000Z",
          "wordCount": 3024,
          "title": "Identify paraphrased text with Hugging Face on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/12/ML-5880-image001.jpg"
        },
        {
          "id": "2b968f82c9280437990c6d71a7597ecbaac3b385",
          "author": "Sharon Dahan",
          "description": "This is a guest post by Moovit’s Software and Cloud Architect, Sharon Dahan. Moovit, an Intel company, is a leading Mobility as a Service (MaaS) solutions provider and creator of the top urban mobility app. Moovit serves over 1.3 billion riders in 3,500 cities around the world. We help people everywhere get to their destination […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-moovit-turns-data-into-insights-to-help-passengers-avoid-delays-using-apache-airflow-and-amazon-sagemaker/",
          "publishedOn": "2022-04-28T16:45:49.000Z",
          "wordCount": 2197,
          "title": "How Moovit turns data into insights to help passengers avoid delays using Apache Airflow and Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/19/ai_lake_architecture-whitebackground-696x630.png"
        },
        {
          "id": "a09e6d1ea472a4b37ad7742d1609d684a6ba654e",
          "author": "Kanwaljit Khurmi",
          "description": "In this post, we demonstrate Kubeflow on AWS (an AWS-specific distribution of Kubeflow) and the value it adds over open-source Kubeflow through the integration of highly optimized, cloud-native, enterprise-ready AWS services. Kubeflow is the open-source machine learning (ML) platform dedicated to making deployments of ML workflows on Kubernetes simple, portable and scalable. Kubeflow provides many […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-and-deploy-a-scalable-machine-learning-system-on-kubernetes-with-kubeflow-on-aws/",
          "publishedOn": "2022-04-26T21:30:15.000Z",
          "wordCount": 4398,
          "title": "Build and deploy a scalable machine learning system on Kubernetes with Kubeflow on AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/26/ML-8280-image003.jpg"
        },
        {
          "id": "9d6ad740d7777311d14dc8be3ae99a342b4768b0",
          "author": "Ben Harris",
          "description": "In this post, we walk you through two sampling techniques in Amazon SageMaker Data Wrangler so you can quickly create processing workflows for your data. We cover both random sampling and stratified sampling techniques to help you sample your data based on your specific requirements. Data Wrangler reduces the time it takes to aggregate and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/create-random-and-stratified-samples-of-data-with-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2022-04-26T16:02:16.000Z",
          "wordCount": 2093,
          "title": "Create random and stratified samples of data with Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/26/random-stratified-data-samples.jpg"
        },
        {
          "id": "1550d4343120c213c9f66037ffe762fc6aa632e8",
          "author": "Pauline Ting",
          "description": "The adoption of AWS cloud technology at NatWest Group means moving our machine learning (ML) workloads to a more robust and scalable solution, while reducing our time-to-live to deliver the best products and services for our customers. In this cloud adoption journey, we selected the Customer Lifetime Value (CLV) model to migrate to AWS. The […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/part-4-how-natwest-group-migrated-ml-models-to-amazon-sagemaker-architectures/",
          "publishedOn": "2022-04-26T15:17:56.000Z",
          "wordCount": 3580,
          "title": "Part 4: How NatWest Group migrated ML models to Amazon SageMaker architectures",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/22/Featured-images-for-ML-8402.jpg"
        },
        {
          "id": "8e4a3ac2768624f09211ab1a89596db3e1a3757b",
          "author": "Ariadna Blanca Romero",
          "description": "This is the third post of a four-part series detailing how NatWest Group, a major financial services institution, partnered with AWS Professional Services to build a new machine learning operations (MLOps) platform. This post is intended for data scientists, MLOps engineers, and data engineers who are interested in building ML pipeline templates with Amazon SageMaker. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/part-3-how-natwest-group-built-auditable-reproducible-and-explainable-ml-models-with-amazon-sagemaker/",
          "publishedOn": "2022-04-26T15:17:37.000Z",
          "wordCount": 2375,
          "title": "Part 3: How NatWest Group built auditable, reproducible, and explainable ML models with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/22/Featured-images-for-ML-8228.jpg"
        },
        {
          "id": "20ecdc2337a1340117aad64f8ae30f385b9d116f",
          "author": "Junaid Baba",
          "description": "This is the second post of a four-part series detailing how NatWest Group, a major financial services institution, partnered with AWS Professional Services to build a new machine learning operations (MLOps) platform. In this post, we share how the NatWest Group utilized AWS to enable the self-service deployment of their standardized, secure, and compliant MLOps […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/part-2-how-natwest-group-built-a-secure-compliant-self-service-mlops-platform-using-aws-service-catalog-and-amazon-sagemaker/",
          "publishedOn": "2022-04-26T15:17:16.000Z",
          "wordCount": 3698,
          "title": "Part 2: How NatWest Group built a secure, compliant, self-service MLOps platform using AWS Service Catalog and Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/22/Featured-images-for-ML-8415.jpg"
        },
        {
          "id": "8cf179a457c08a833b48256ab02c913c04a986a5",
          "author": "Maira Ladeira Tanke",
          "description": "This is the first post of a four-part series detailing how NatWest Group, a major financial services institution, partnered with AWS to build a scalable, secure, and sustainable machine learning operations (MLOps) platform. This initial post provides an overview of the AWS and NatWest Group joint team implemented Amazon SageMaker Studio as the standard for […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/part-1-how-natwest-group-built-a-scalable-secure-and-sustainable-mlops-platform/",
          "publishedOn": "2022-04-26T15:17:04.000Z",
          "wordCount": 3400,
          "title": "Part 1: How NatWest Group built a scalable, secure, and sustainable MLOps platform",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/22/Featured-images-for-ML-8208.jpg"
        },
        {
          "id": "fe09079e961020b1931806fd3509052e73288359",
          "author": "Yanyan Zhang",
          "description": "Amazon SageMaker Data Wrangler is a new capability of Amazon SageMaker that helps data scientists and data engineers quickly and easily prepare data for machine learning (ML) applications using a visual interface. It contains over 300 built-in data transformations so you can quickly normalize, transform, and combine features without having to write any code. Today, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-data-preparation-with-data-quality-and-insights-in-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2022-04-26T14:56:53.000Z",
          "wordCount": 2221,
          "title": "Accelerate data preparation with data quality and insights in Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/26/accelerate-data-prep-data-wrangler.jpg"
        },
        {
          "id": "d4066e13a5576572cc8bb0e6abc8f2812af11841",
          "author": "James Yi",
          "description": "The last few years have seen rapid growth in the field of natural language processing (NLP) using transformer deep learning architectures. With its Transformers open-source library and machine learning (ML) platform, Hugging Face makes transfer learning and the latest transformer models accessible to the global AI community. This can reduce the time needed for data […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/host-hugging-face-transformer-models-using-amazon-sagemaker-serverless-inference/",
          "publishedOn": "2022-04-25T21:12:39.000Z",
          "wordCount": 2292,
          "title": "Host Hugging Face transformer models using Amazon SageMaker Serverless Inference",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/21/ML-8598-image001-1019x630.png"
        },
        {
          "id": "40d2bdb4b99fed5c680db876cf6d1b33d2f62db5",
          "author": "Daniel Burke",
          "description": "Nordic Aviation Capital (NAC) is the industry’s leading regional aircraft lessor, serving almost 70 airlines in approximately 45 countries worldwide. In 2021, NAC turned to AWS to help it use artificial intelligence (AI) to further improve its leasing operations and reduce its reliance on manual labor. With Amazon Rekognition Custom Labels, NAC built an AI […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-nordic-aviation-capital-uses-amazon-rekognition-to-streamline-operations-and-save-up-to-eur200000-annually/",
          "publishedOn": "2022-04-25T17:47:30.000Z",
          "wordCount": 1548,
          "title": "How Nordic Aviation Capital uses Amazon Rekognition to streamline operations and save up to EUR200,000 annually",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/25/ML-8594-image003-2.jpg"
        },
        {
          "id": "c1051aee6c3bb071b4069fd2ddca91a6b4c288d9",
          "author": "Dan Ferguson",
          "description": "AWS CodeArtifact allows developers to connect internal code repositories to upstream code repositories like Pypi, Maven, or NPM. AWS CodeArtifact is a powerful addition to CI/CD workflows on AWS, but it is similarly effective for code-bases hosted on a Jupyter notebook. This is a common development paradigm for Machine Learning developers that build and train […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/secure-aws-codeartifact-access-for-isolated-amazon-sagemaker-notebook-instances/",
          "publishedOn": "2022-04-22T16:56:29.000Z",
          "wordCount": 2726,
          "title": "Secure AWS CodeArtifact access for isolated Amazon SageMaker notebook instances",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/19/ML-4423-image001-whitebackground.png"
        },
        {
          "id": "21a3046ba8f883173c962ba36d5d48c49efd00e8",
          "author": "Uday Narayanan",
          "description": "Amazon Textract is a machine learning (ML) service that automatically extracts text, handwriting, and data from any document or image. Amazon Textract now offers the flexibility to specify the data you need to extract from documents using the new Queries feature within the Analyze Document API. You don’t need to know the structure of the […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/specify-and-extract-information-from-documents-using-the-new-queries-feature-in-amazon-textract/",
          "publishedOn": "2022-04-21T17:32:12.000Z",
          "wordCount": 3204,
          "title": "Specify and extract information from documents using the new Queries feature in Amazon Textract",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/21/specify-extract-textract.jpg"
        },
        {
          "id": "4d89b7000b553a0ed3675113cd8b7856b5e91b3b",
          "author": "Ashish Lagwankar",
          "description": "Organizations use collaborative document authoring solutions like Salesforce Quip to embed real-time, collaborative documents inside Salesforce records. Quip is Salesforce’s productivity platform that transforms the way enterprises work together, delivering modern collaboration securely and simply across any device. A Quip repository captures invaluable organizational knowledge in the form of collaborative documents and workflows. However, finding […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/search-for-knowledge-in-quip-documents-with-intelligent-search-using-the-quip-connector-for-amazon-kendra/",
          "publishedOn": "2022-04-20T01:50:58.000Z",
          "wordCount": 1816,
          "title": "Search for knowledge in Quip documents with intelligent search using the Quip connector for Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/19/ML-8536-image001.jpg"
        },
        {
          "id": "c724effc75362e3687819604539d3a515b9ddb13",
          "author": "Chanki Nathani",
          "description": "Conversational interfaces (or chatbots) can provide an intuitive interface for processes such as creating and monitoring tickets. Let’s consider a situation in which a recent hire on your team is required to cut tickets for office equipment. To do so, they have to interact with a ticketing software that the organization uses. This often requires […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/integrate-servicenow-with-amazon-lex-chatbot-for-ticket-processing/",
          "publishedOn": "2022-04-19T16:55:07.000Z",
          "wordCount": 3130,
          "title": "Integrate ServiceNow with Amazon Lex chatbot for ticket processing",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/15/ML-3932-image001-new2.png"
        },
        {
          "id": "f9202ebc8ef6c1f2afaaf179eacafa3188aae5db",
          "author": "Ying Hou",
          "description": "Automatic speech recognition (ASR) is a commonly used machine learning (ML) technology in our daily lives and business scenarios. Applications such as voice-controlled assistants like Alexa and Siri, and voice-to-text applications like automatic subtitling for videos and transcribing meetings, are all powered by this technology. These applications take audio clips as input and convert speech […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/fine-tune-and-deploy-a-wav2vec2-model-for-speech-recognition-with-hugging-face-and-amazon-sagemaker/",
          "publishedOn": "2022-04-15T19:53:54.000Z",
          "wordCount": 3163,
          "title": "Fine-tune and deploy a Wav2Vec2 model for speech recognition with Hugging Face and Amazon SageMaker",
          "enclosure": {
            "length": "136188",
            "type": "audio/wav",
            "url": "https://datashare.ed.ac.uk/bitstream/handle/10283/343/MKH800_19_0001.wav"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/13/ML-7125-image003-1260x261.png"
        },
        {
          "id": "e2fb9c1df3de2070a33e6590c79d6fb66231bf6e",
          "author": "Dipkumar Mehta",
          "description": "Banking and financial institutions review thousands of credit applications per week. The credit approval process requires financial organizations to invest time and resources in reviewing documents like W2s, bank statements, and utility bills. The overall experience can be costly for the organization. At the same time, organizations have to consider borrowers, who are waiting for […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-virtual-credit-approval-agent-with-amazon-lex-amazon-textract-and-amazon-connect/",
          "publishedOn": "2022-04-15T17:48:03.000Z",
          "wordCount": 2542,
          "title": "Build a virtual credit approval agent with Amazon Lex, Amazon Textract, and Amazon Connect",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/15/ML-7548-image013.jpg"
        },
        {
          "id": "681eb7cd028c64101dbdc23c7af7af61a3cc8aa9",
          "author": "Arnaud Lauer",
          "description": "You can establish feature stores to provide a central repository for machine learning (ML) features that can be shared with data science teams across your organization for training, batch scoring, and real-time inference. Data science teams can reuse features stored in the central repository, avoiding the need to reengineer feature pipelines for different projects and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/control-access-to-amazon-sagemaker-feature-store-offline-using-aws-lake-formation/",
          "publishedOn": "2022-04-13T18:54:26.000Z",
          "wordCount": 2871,
          "title": "Control access to Amazon SageMaker Feature Store offline using AWS Lake Formation",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/12/ML-8495-image001.png"
        },
        {
          "id": "06e1c05fec26be8f89c634c5de937fdd773f426a",
          "author": "Brian Yost",
          "description": "Amazon Lex can add powerful automation to contact center solutions, so you can enable self-service via interactive voice response (IVR) interactions or route calls to the appropriate agent based on caller input. These capabilities can increase customer satisfaction by streamlining the user experience, and improve containment rates in the contact center. In both the self-service […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/manage-dialog-to-elicit-amazon-lex-slots-in-amazon-connect-contact-flows/",
          "publishedOn": "2022-04-13T15:09:58.000Z",
          "wordCount": 1918,
          "title": "Manage dialog to elicit Amazon Lex slots in Amazon Connect contact flows",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/06/ML-8879-image001-whitebackground-1139x630.png"
        },
        {
          "id": "0d01c636ffdbb651bb76c8c2f8ff1eb0118a73b1",
          "author": "Joshua Levy",
          "description": "In many industries, it’s critical to extract custom entities from documents in a timely manner. This can be challenging. Insurance claims, for example, often contain dozens of important attributes (such as dates, names, locations, and reports) sprinkled across lengthy and dense documents. Manually scanning and extracting such information can be error-prone and time-consuming. Rule-based software […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-custom-entity-recognizer-for-pdf-documents-using-amazon-comprehend/",
          "publishedOn": "2022-04-08T17:32:30.000Z",
          "wordCount": 1954,
          "title": "Build a custom entity recognizer for PDF documents using Amazon Comprehend",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/25/image-46.png"
        },
        {
          "id": "c460ad7425a2142b35a23d87bcece5f7ff3037a6",
          "author": "Bob Strahan",
          "description": "Amazon Kendra is a highly accurate and easy-to-use intelligent search service powered by machine learning (ML). Amazon Kendra offers a suite of data source connectors to simplify the process of ingesting and indexing your content, wherever it resides. For many organizations, Box Content Cloud is a core part of their content storage and lifecycle management […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/getting-started-with-the-amazon-kendra-box-connector/",
          "publishedOn": "2022-04-08T16:10:06.000Z",
          "wordCount": 1853,
          "title": "Getting started with the Amazon Kendra Box connector",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png"
        },
        {
          "id": "9770db1640db4792d317e78fe4a612d13b6f8025",
          "author": "Jay Rao",
          "description": "Amazon Rekognition Custom Labels is a fully managed computer vision service that allows developers to build custom models to classify and identify objects in images that are specific and unique to your business. Rekognition Custom Labels doesn’t require you to have any prior computer vision expertise. You can get started by simply uploading tens of […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/receive-notifications-for-image-analysis-with-amazon-rekognition-custom-labels-and-analyze-predictions/",
          "publishedOn": "2022-04-06T16:46:32.000Z",
          "wordCount": 2176,
          "title": "Receive notifications for image analysis with Amazon Rekognition Custom Labels and analyze predictions",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/01/ML-3899-image031.jpg"
        },
        {
          "id": "0e8423c3b0ca2b8aa2fd2cab118be4196def0bbd",
          "author": "Peyman Razaghi",
          "description": "The built-in Amazon SageMaker XGBoost algorithm provides a managed container to run the popular XGBoost machine learning (ML) framework, with added convenience of supporting advanced training or inference features like distributed training, dataset sharding for large-scale datasets, A/B model testing, or multi-model inference endpoints. You can also extend this powerful algorithm to accommodate different requirements. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/customize-the-amazon-sagemaker-xgboost-algorithm-container/",
          "publishedOn": "2022-04-05T17:24:58.000Z",
          "wordCount": 1535,
          "title": "Customize the Amazon SageMaker XGBoost algorithm container",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/18/ML-2441-archdiag.png"
        },
        {
          "id": "b427fe772702e9e6bb92c140946b1bcd9c5c6dc0",
          "author": "Nathalie Rauschmayr",
          "description": "Research over the past few years has shown that machine learning (ML) models are vulnerable to adversarial inputs, where an adversary can craft inputs to strategically alter the model’s output (in image classification, speech recognition, or fraud detection). For example, imagine you have deployed a model that identifies your employees based on images of their […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/detect-adversarial-inputs-using-amazon-sagemaker-model-monitor-and-amazon-sagemaker-debugger/",
          "publishedOn": "2022-04-05T17:19:32.000Z",
          "wordCount": 3547,
          "title": "Detect adversarial inputs using Amazon SageMaker Model Monitor and Amazon SageMaker Debugger",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/29/ML-7609-image005.jpg"
        },
        {
          "id": "093bc4f91e188e1a2e2f385311b63204025f2c19",
          "author": "Rumi Olsen",
          "description": "As more organizations move to machine learning (ML) to drive deeper insights, two key stumbling blocks they run into are labeling and lifecycle management. Labeling is the identification of data and adding labels to provide context so an ML model can learn from it. Labels might indicate a phrase in an audio file, a car […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-mlops-sentiment-analysis-pipeline-using-amazon-sagemaker-ground-truth-and-databricks-mlflow/",
          "publishedOn": "2022-04-04T19:43:42.000Z",
          "wordCount": 2188,
          "title": "Build an MLOps sentiment analysis pipeline using Amazon SageMaker Ground Truth and Databricks MLflow",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/17/ML-5351-image002-1-657x630.png"
        },
        {
          "id": "44ec1f237a527c498cfe53252dabc3cb1f64d1ce",
          "author": "Sanjay Tiwary",
          "description": "Amazon Kendra is an intelligent search service powered by machine learning (ML). Amazon Kendra reimagines search for your websites and applications so your employees and customers can easily find the content they’re looking for, even when it’s scattered across multiple locations and content repositories within your organization. Amazon Kendra supports a variety of document formats, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/enable-amazon-kendra-search-for-a-scanned-or-image-based-text-document/",
          "publishedOn": "2022-04-04T18:07:45.000Z",
          "wordCount": 1648,
          "title": "Enable Amazon Kendra search for a scanned or image-based text document",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/25/ML-6030-image001-feature-1065x630.png"
        },
        {
          "id": "2aeebc95eb280c09dba0b3c96cc6c229198abe7f",
          "author": "Kai Loreck",
          "description": "Customer service calls require customer agents to have the customer’s account information to process the caller’s request. For example, to provide a status on an insurance claim, the support agent needs policy holder information such as the policy ID and claim number. Such information is often collected in the interactive voice response (IVR) flow at […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/interpret-caller-input-using-grammar-slot-types-in-amazon-lex/",
          "publishedOn": "2022-04-04T16:45:41.000Z",
          "wordCount": 1869,
          "title": "Interpret caller input using grammar slot types in Amazon Lex",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2204.14118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_M/0/1/0/all/0/1\">Meng-Zhang Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ai_Z/0/1/0/all/0/1\">Zheng Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Teng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wei Gao</a>",
          "description": "Margin has played an important role on the design and analysis of learning\nalgorithms during the past years, mostly working with the maximization of the\nminimum margin. Recent years have witnessed the increasing empirical studies on\nthe optimization of margin distribution according to different statistics such\nas medium margin, average margin, margin variance, etc., whereas there is a\nrelative paucity of theoretical understanding. In this work, we take one step\non this direction by providing a new generalization error bound, which is\nheavily relevant to margin distribution by incorporating ingredients such as\naverage margin and semi-variance, a new margin statistics for the\ncharacterization of margin distribution. Inspired by the theoretical findings,\nwe propose the MSVMAv, an efficient approach to achieve better performance by\noptimizing margin distribution in terms of its empirical average margin and\nsemi-variance. We finally conduct extensive experiments to show the superiority\nof the proposed MSVMAv approach.",
          "link": "http://arxiv.org/abs/2204.14118",
          "publishedOn": "2022-05-02T00:57:34.128Z",
          "wordCount": 567,
          "title": "On the Optimization of Margin Distribution. (arXiv:2204.14118v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.12488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elsner_T/0/1/0/all/0/1\">Tim Elsner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibing_M/0/1/0/all/0/1\">Moritz Ibing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Czech_V/0/1/0/all/0/1\">Victor Czech</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nehring_Wirxel_J/0/1/0/all/0/1\">Julius Nehring-Wirxel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobbelt_L/0/1/0/all/0/1\">Leif Kobbelt</a>",
          "description": "The use of autoencoders for shape editing or generation through latent space\nmanipulation suffers from unpredictable changes in the output shape. Our\nautoencoder-based method enables intuitive shape editing in latent space by\ndisentangling latent sub-spaces into style variables and control points on the\nsurface that can be manipulated independently. The key idea is adding a\nLipschitz-type constraint to the loss function, i.e. bounding the change of the\noutput shape proportionally to the change in latent space, leading to\ninterpretable latent space representations. The control points on the surface\nthat are part of the latent code of an object can then be freely moved,\nallowing for intuitive shape editing directly in latent space. We evaluate our\nmethod by comparing to state-of-the-art data-driven shape editing methods. We\nfurther demonstrate the expressiveness of our learned latent space by\nleveraging it for unsupervised part segmentation.",
          "link": "http://arxiv.org/abs/2111.12488",
          "publishedOn": "2022-05-02T00:57:34.121Z",
          "wordCount": 611,
          "title": "Intuitive Shape Editing in Latent Space. (arXiv:2111.12488v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14133",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Ling Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Lin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhendong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Junlan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Chao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longbo Huang</a>",
          "description": "Topology impacts important network performance metrics, including link\nutilization, throughput and latency, and is of central importance to network\noperators. However, due to the combinatorial nature of network topology, it is\nextremely difficult to obtain an optimal solution, especially since topology\nplanning in networks also often comes with management-specific constraints. As\na result, local optimization with hand-tuned heuristic methods from human\nexperts are often adopted in practice. Yet, heuristic methods cannot cover the\nglobal topology design space while taking into account constraints, and cannot\nguarantee to find good solutions.\n\nIn this paper, we propose a novel deep reinforcement learning (DRL)\nalgorithm, called Advantage Actor Critic-Graph Searching (A2C-GS), for network\ntopology optimization. A2C-GS consists of three novel components, including a\nverifier to validate the correctness of a generated network topology, a graph\nneural network (GNN) to efficiently approximate topology rating, and a DRL\nactor layer to conduct a topology search. A2C-GS can efficiently search over\nlarge topology space and output topology with satisfying performance. We\nconduct a case study based on a real network scenario, and our experimental\nresults demonstrate the superior performance of A2C-GS in terms of both\nefficiency and performance.",
          "link": "http://arxiv.org/abs/2204.14133",
          "publishedOn": "2022-05-02T00:57:34.114Z",
          "wordCount": 632,
          "title": "Network Topology Optimization via Deep Reinforcement Learning. (arXiv:2204.14133v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_T/0/1/0/all/0/1\">Takahiro Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanaoka_S/0/1/0/all/0/1\">Shouhei Hanaoka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>",
          "description": "A computer-aided detection (CAD) system based on machine learning is expected\nto assist radiologists in making a diagnosis. It is desirable to build CAD\nsystems for the various types of diseases accumulating daily in a hospital. An\nobstacle in developing a CAD system for a disease is that the number of medical\nimages is typically too small to improve the performance of the machine\nlearning model. In this paper, we aim to explore ways to address this problem\nthrough a sim2real transfer approach in medical image fields. To build a\nplatform to evaluate the performance of sim2real transfer methods in the field\nof medical imaging, we construct a benchmark dataset that consists of $101$\nchest X-images with difficult-to-identify pneumonia lesions judged by an\nexperienced radiologist and a simulator based on fractal Perlin noise and the\nX-ray principle for generating pseudo pneumonia lesions. We then develop a\nnovel domain randomization method, called Goldilocks-curriculum domain\nrandomization (GDR) and evaluate our method in this platform.",
          "link": "http://arxiv.org/abs/2204.13849",
          "publishedOn": "2022-05-02T00:57:34.088Z",
          "wordCount": 604,
          "title": "Goldilocks-curriculum Domain Randomization and Fractal Perlin Noise with Application to Sim2Real Pneumonia Lesion Detection. (arXiv:2204.13849v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12443",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Belenguer_A/0/1/0/all/0/1\">Aitor Belenguer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navaridas_J/0/1/0/all/0/1\">Javier Navaridas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pascual_J/0/1/0/all/0/1\">Jose A. Pascual</a>",
          "description": "Intrusion detection systems are evolving into intelligent systems that\nperform data analysis searching for anomalies in their environment. The\ndevelopment of deep learning technologies opened the door to build more complex\nand effective threat detection models. However, training those models may be\ncomputationally infeasible in most Internet of Things devices. Current\napproaches rely on powerful centralized servers that receive data from all\ntheir parties -- violating basic privacy constraints and substantially\naffecting response times and operational costs due to the huge communication\noverheads. To mitigate these issues, Federated Learning emerged as a promising\napproach where different agents collaboratively train a shared model, neither\nexposing training data to others nor requiring a compute-intensive centralized\ninfrastructure. This paper focuses on the application of Federated Learning\napproaches in the field of Intrusion Detection. Both technologies are described\nin detail and current scientific progress is reviewed and categorized. Finally,\nthe paper highlights the limitations present in recent works and presents some\nfuture directions for this technology.",
          "link": "http://arxiv.org/abs/2204.12443",
          "publishedOn": "2022-05-02T00:57:34.080Z",
          "wordCount": null,
          "title": "A review of Federated Learning in Intrusion Detection Systems for IoT. (arXiv:2204.12443v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_A/0/1/0/all/0/1\">Andreas Holm Nielsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karstoft_H/0/1/0/all/0/1\">Henrik Karstoft</a>",
          "description": "Classifying the state of the atmosphere into a finite number of large-scale\ncirculation regimes is a popular way of investigating teleconnections, the\npredictability of severe weather events, and climate change. Here, we\ninvestigate a supervised machine learning approach based on deformable\nconvolutional neural networks (deCNNs) and transfer learning to forecast the\nNorth Atlantic-European weather regimes during extended boreal winter for 1 to\n15 days into the future. We apply state-of-the-art interpretation techniques\nfrom the machine learning literature to attribute particular regions of\ninterest or potential teleconnections relevant for any given weather cluster\nprediction or regime transition. We demonstrate superior forecasting\nperformance relative to several classical meteorological benchmarks, as well as\nlogistic regression and random forests. Due to its wider field of view, we also\nobserve deCNN achieving considerably better performance than regular\nconvolutional neural networks at lead times beyond 5-6 days. Finally, we find\ntransfer learning to be of paramount importance, similar to previous\ndata-driven atmospheric forecasting studies.",
          "link": "http://arxiv.org/abs/2202.04964",
          "publishedOn": "2022-05-02T00:57:34.079Z",
          "wordCount": null,
          "title": "Forecasting large-scale circulation regimes using deformable convolutional neural networks and global spatiotemporal climate data. (arXiv:2202.04964v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.05735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotzen_K/0/1/0/all/0/1\">Kevin Kotzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charlton_P/0/1/0/all/0/1\">Peter H. Charlton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salabi_S/0/1/0/all/0/1\">Sharon Salabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amar_L/0/1/0/all/0/1\">Lea Amar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landesberg_A/0/1/0/all/0/1\">Amir Landesberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behar_J/0/1/0/all/0/1\">Joachim A. Behar</a>",
          "description": "Introduction: Sleep staging is an essential component in the diagnosis of\nsleep disorders and management of sleep health. It is traditionally measured in\na clinical setting and requires a labor-intensive labeling process. We\nhypothesize that it is possible to perform robust 4-class sleep staging using\nthe raw photoplethysmography (PPG) time series and modern advances in deep\nlearning (DL). Methods: We used two publicly available sleep databases that\nincluded raw PPG recordings, totalling 2,374 patients and 23,055 hours. We\ndeveloped SleepPPG-Net, a DL model for 4-class sleep staging from the raw PPG\ntime series. SleepPPG-Net was trained end-to-end and consists of a residual\nconvolutional network for automatic feature extraction and a temporal\nconvolutional network to capture long-range contextual information. We\nbenchmarked the performance of SleepPPG-Net against models based on the\nbest-reported state-of-the-art (SOTA) algorithms. Results: When benchmarked on\na held-out test set, SleepPPG-Net obtained a median Cohen's Kappa ($\\kappa$)\nscore of 0.75 against 0.69 for the best SOTA approach. SleepPPG-Net showed good\ngeneralization performance to an external database, obtaining a $\\kappa$ score\nof 0.74 after transfer learning. Perspective: Overall, SleepPPG-Net provides\nnew SOTA performance. In addition, performance is high enough to open the path\nto the development of wearables that meet the requirements for usage in\nclinical applications such as the diagnosis and monitoring of obstructive sleep\napnea.",
          "link": "http://arxiv.org/abs/2202.05735",
          "publishedOn": "2022-05-02T00:57:34.079Z",
          "wordCount": null,
          "title": "SleepPPG-Net: a deep learning algorithm for robust sleep staging from continuous photoplethysmography. (arXiv:2202.05735v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tabatabai_S/0/1/0/all/0/1\">Shadha Tabatabai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammed_I/0/1/0/all/0/1\">Ihab Mohammed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qolomany_B/0/1/0/all/0/1\">Basheer Qolomany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albasser_A/0/1/0/all/0/1\">Abdullatif Albasser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_K/0/1/0/all/0/1\">Kashif Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdallah_M/0/1/0/all/0/1\">Mohamed Abdallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Fuqaha_A/0/1/0/all/0/1\">Ala Al-Fuqaha</a>",
          "description": "Federated Learning (FL) is one of the hot research topics, and it utilizes\nMachine Learning (ML) in a distributed manner without directly accessing\nprivate data on clients. However, FL faces many challenges, including the\ndifficulty to obtain high accuracy, high communication cost between clients and\nthe server, and security attacks related to adversarial ML. To tackle these\nthree challenges, we propose an FL algorithm inspired by evolutionary\ntechniques. The proposed algorithm groups clients randomly in many clusters,\neach with a model selected randomly to explore the performance of different\nmodels. The clusters are then trained in a repetitive process where the worst\nperforming cluster is removed in each iteration until one cluster remains. In\neach iteration, some clients are expelled from clusters either due to using\npoisoned data or low performance. The surviving clients are exploited in the\nnext iteration. The remaining cluster with surviving clients is then used for\ntraining the best FL model (i.e., remaining FL model). Communication cost is\nreduced since fewer clients are used in the final training of the FL model. To\nevaluate the performance of the proposed algorithm, we conduct a number of\nexperiments using FEMNIST dataset and compare the result against the random FL\nalgorithm. The experimental results show that the proposed algorithm\noutperforms the baseline algorithm in terms of accuracy, communication cost,\nand security.",
          "link": "http://arxiv.org/abs/2204.14020",
          "publishedOn": "2022-05-02T00:57:34.078Z",
          "wordCount": null,
          "title": "Exploration and Exploitation in Federated Learning to Exclude Clients with Poisoned Data. (arXiv:2204.14020v1 [cs.DC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07409",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Muller_J/0/1/0/all/0/1\">Johannes M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/math/1/au:+Montufar_G/0/1/0/all/0/1\">Guido Mont&#xfa;far</a>",
          "description": "We consider the problem of finding the best memoryless stochastic policy for\nan infinite-horizon partially observable Markov decision process (POMDP) with\nfinite state and action spaces with respect to either the discounted or mean\nreward criterion. We show that the (discounted) state-action frequencies and\nthe expected cumulative reward are rational functions of the policy, whereby\nthe degree is determined by the degree of partial observability. We then\ndescribe the optimization problem as a linear optimization problem in the space\nof feasible state-action frequencies subject to polynomial constraints that we\ncharacterize explicitly. This allows us to address the combinatorial and\ngeometric complexity of the optimization problem using recent tools from\npolynomial optimization. In particular, we estimate the number of critical\npoints and use the polynomial programming description of reward maximization to\nsolve a navigation problem in a grid world.",
          "link": "http://arxiv.org/abs/2110.07409",
          "publishedOn": "2022-05-02T00:57:34.078Z",
          "wordCount": null,
          "title": "The Geometry of Memoryless Stochastic Policy Optimization in Infinite-Horizon POMDPs. (arXiv:2110.07409v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pelosin_F/0/1/0/all/0/1\">Francesco Pelosin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Saurav Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torsello_A/0/1/0/all/0/1\">Andrea Torsello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raducanu_B/0/1/0/all/0/1\">Bogdan Raducanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weijer_J/0/1/0/all/0/1\">Joost van de Weijer</a>",
          "description": "In this paper, we investigate the continual learning of Vision Transformers\n(ViT) for the challenging exemplar-free scenario, with special focus on how to\nefficiently distill the knowledge of its crucial self-attention mechanism\n(SAM). Our work takes an initial step towards a surgical investigation of SAM\nfor designing coherent continual learning methods in ViTs. We first carry out\nan evaluation of established continual learning regularization techniques. We\nthen examine the effect of regularization when applied to two key enablers of\nSAM: (a) the contextualized embedding layers, for their ability to capture\nwell-scaled representations with respect to the values, and (b) the prescaled\nattention maps, for carrying value-independent global contextual information.\nWe depict the perks of each distilling strategy on two image recognition\nbenchmarks (CIFAR100 and ImageNet-32) -- while (a) leads to a better overall\naccuracy, (b) helps enhance the rigidity by maintaining competitive\nperformances. Furthermore, we identify the limitation imposed by the symmetric\nnature of regularization losses. To alleviate this, we propose an asymmetric\nvariant and apply it to the pooled output distillation (POD) loss adapted for\nViTs. Our experiments confirm that introducing asymmetry to POD boosts its\nplasticity while retaining stability across (a) and (b). Moreover, we\nacknowledge low forgetting measures for all the compared methods, indicating\nthat ViTs might be naturally inclined continual learner",
          "link": "http://arxiv.org/abs/2203.13167",
          "publishedOn": "2022-05-02T00:57:34.078Z",
          "wordCount": null,
          "title": "Towards Exemplar-Free Continual Learning in Vision Transformers: an Account of Attention, Functional and Weight Regularization. (arXiv:2203.13167v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Coda_E/0/1/0/all/0/1\">Elizabeth Coda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courts_N/0/1/0/all/0/1\">Nico Courts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wight_C/0/1/0/all/0/1\">Colby Wight</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_L/0/1/0/all/0/1\">Loc Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_W/0/1/0/all/0/1\">WoongJo Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godfrey_C/0/1/0/all/0/1\">Charles Godfrey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emerson_T/0/1/0/all/0/1\">Tegan Emerson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kappagantula_K/0/1/0/all/0/1\">Keerti Kappagantula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1\">Henry Kvinge</a>",
          "description": "While it is not generally reflected in the `nice' datasets used for\nbenchmarking machine learning algorithms, the real-world is full of processes\nthat would be best described as many-to-many. That is, a single input can\npotentially yield many different outputs (whether due to noise, imperfect\nmeasurement, or intrinsic stochasticity in the process) and many different\ninputs can yield the same output (that is, the map is not injective). For\nexample, imagine a sentiment analysis task where, due to linguistic ambiguity,\na single statement can have a range of different sentiment interpretations\nwhile at the same time many distinct statements can represent the same\nsentiment. When modeling such a multivalued function $f: X \\rightarrow Y$, it\nis frequently useful to be able to model the distribution on $f(x)$ for\nspecific input $x$ as well as the distribution on fiber $f^{-1}(y)$ for\nspecific output $y$. Such an analysis helps the user (i) better understand the\nvariance intrinsic to the process they are studying and (ii) understand the\nrange of specific input $x$ that can be used to achieve output $y$. Following\nexisting work which used a fiber bundle framework to better model many-to-one\nprocesses, we describe how morphisms of fiber bundles provide a template for\nbuilding models which naturally capture the structure of many-to-many\nprocesses.",
          "link": "http://arxiv.org/abs/2203.08189",
          "publishedOn": "2022-05-02T00:57:34.077Z",
          "wordCount": 676,
          "title": "Fiber Bundle Morphisms as a Framework for Modeling Many-to-Many Maps. (arXiv:2203.08189v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14103",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ingolfsson_T/0/1/0/all/0/1\">Thorir Mar Ingolfsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vero_M/0/1/0/all/0/1\">Mark Vero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaying Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamberti_L/0/1/0/all/0/1\">Lorenzo Lamberti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spallanzani_M/0/1/0/all/0/1\">Matteo Spallanzani</a>",
          "description": "The computational demands of neural architecture search (NAS) algorithms are\nusually directly proportional to the size of their target search spaces. Thus,\nlimiting the search to high-quality subsets can greatly reduce the\ncomputational load of NAS algorithms. In this paper, we present\nClustering-Based REDuction (C-BRED), a new technique to reduce the size of NAS\nsearch spaces. C-BRED reduces a NAS space by clustering the computational\ngraphs associated with its architectures and selecting the most promising\ncluster using proxy statistics correlated with network accuracy. When\nconsidering the NAS-Bench-201 (NB201) data set and the CIFAR-100 task, C-BRED\nselects a subset with 70% average accuracy instead of the whole space's 64%\naverage accuracy.",
          "link": "http://arxiv.org/abs/2204.14103",
          "publishedOn": "2022-05-02T00:57:34.069Z",
          "wordCount": 561,
          "title": "Reducing Neural Architecture Search Spaces with Training-Free Statistics and Computational Graph Clustering. (arXiv:2204.14103v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.05839",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1\">Murray Shanahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1\">Melanie Mitchell</a>",
          "description": "We characterise the problem of abstraction in the context of deep\nreinforcement learning. Various well established approaches to analogical\nreasoning and associative memory might be brought to bear on this issue, but\nthey present difficulties because of the need for end-to-end differentiability.\nWe review developments in AI and machine learning that could facilitate their\nadoption.",
          "link": "http://arxiv.org/abs/2202.05839",
          "publishedOn": "2022-05-02T00:57:34.062Z",
          "wordCount": null,
          "title": "Abstraction for Deep Reinforcement Learning. (arXiv:2202.05839v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.13916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1\">Dan Hendrycks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulman_J/0/1/0/all/0/1\">John Schulman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>",
          "description": "Machine learning (ML) systems are rapidly increasing in size, are acquiring\nnew capabilities, and are increasingly deployed in high-stakes settings. As\nwith other powerful technologies, safety for ML should be a leading research\npriority. In response to emerging safety challenges in ML, such as those\nintroduced by recent large-scale models, we provide a new roadmap for ML Safety\nand refine the technical problems that the field needs to address. We present\nfour problems ready for research, namely withstanding hazards (\"Robustness\"),\nidentifying hazards (\"Monitoring\"), reducing inherent model hazards\n(\"Alignment\"), and reducing systemic hazards (\"Systemic Safety\"). Throughout,\nwe clarify each problem's motivation and provide concrete research directions.",
          "link": "http://arxiv.org/abs/2109.13916",
          "publishedOn": "2022-05-02T00:57:34.061Z",
          "wordCount": null,
          "title": "Unsolved Problems in ML Safety. (arXiv:2109.13916v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.11736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+An_Y/0/1/0/all/0/1\">Yang An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1\">Bo Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiaopeng Wei</a>",
          "description": "Predicting medications is a crucial task in many intelligent healthcare\nsystems. It can assist doctors in making informed medication decisions for\npatients according to electronic medical records (EMRs). However, medication\nprediction is a challenging data mining task due to the complex relations\nbetween medical codes. Most existing studies focus on utilizing inherent\nrelations between homogeneous codes of medical ontology graph to enhance their\nrepresentations using supervised methods, and few studies pay attention to the\nvaluable relations between heterogeneous or homogeneous medical codes from\nhistory EMRs, which further limits the prediction performance and application\nscenarios. Therefore, to address these limitations, this paper proposes\nKnowAugNet, a multi-sourced medical knowledge augmented medication prediction\nnetwork which can fully capture the diverse relations between medical codes via\nmulti-level graph contrastive learning framework. Specifically, KnowAugNet\nfirst leverages the graph contrastive learning using graph attention network as\nthe encoder to capture the implicit relations between homogeneous medical codes\nfrom the medical ontology graph and obtains the knowledge augmented medical\ncodes embedding vectors. Then, it utilizes the graph contrastive learning using\na weighted graph convolutional network as the encoder to capture the\ncorrelative relations between homogeneous or heterogeneous medical codes from\nthe constructed medical prior relation graph and obtains the relation augmented\nmedical codes embedding vectors. Finally, the augmented medical codes embedding\nvectors and the supervised medical codes embedding vectors are retrieved and\ninput to the sequential learning network to capture the temporal relations of\nmedical codes and predict medications for patients.",
          "link": "http://arxiv.org/abs/2204.11736",
          "publishedOn": "2022-05-02T00:57:34.060Z",
          "wordCount": 704,
          "title": "KnowAugNet: Multi-Source Medical Knowledge Augmented Medication Prediction Network with Multi-Level Graph Contrastive Learning. (arXiv:2204.11736v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04762",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_L/0/1/0/all/0/1\">Louis L. Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Royset_J/0/1/0/all/0/1\">Johannes O. Royset</a>",
          "description": "In practice, optimization models are often prone to unavoidable inaccuracies\ndue to lack of data and dubious assumptions. Traditionally, this placed special\nemphasis on risk-based and robust formulations, and their focus on\n\"conservative\" decisions. We develop, in contrast, an \"optimistic\" framework\nbased on Rockafellian relaxations in which optimization is conducted not only\nover the original decision space but also jointly with a choice of model\nperturbation. The framework enables us to address challenging problems with\nambiguous probability distributions from the areas of two-stage stochastic\noptimization without relatively complete recourse, probability functions\nlacking continuity properties, expectation constraints, and outlier analysis.\nWe are also able to circumvent the fundamental difficulty in stochastic\noptimization that convergence of distributions fails to guarantee convergence\nof expectations. The framework centers on the novel concepts of exact and\nasymptotically exact Rockafellians, with interpretations of \"negative\"\nregularization emerging in certain settings. We illustrate the role of\nPhi-divergence, examine rates of convergence under changing distributions, and\nexplore extensions to first-order optimality conditions. The main development\nis free of assumptions about convexity, smoothness, and even continuity of\nobjective functions.",
          "link": "http://arxiv.org/abs/2204.04762",
          "publishedOn": "2022-05-02T00:57:34.040Z",
          "wordCount": null,
          "title": "Rockafellian Relaxation in Optimization under Uncertainty: Asymptotically Exact Formulations. (arXiv:2204.04762v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.08981",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gao_X/0/1/0/all/0/1\">Xiangyu Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xing_G/0/1/0/all/0/1\">Guanbin Xing</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Roy_S/0/1/0/all/0/1\">Sumit Roy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>",
          "description": "Millimeter-wave radars are being increasingly integrated into commercial\nvehicles to support new advanced driver-assistance systems by enabling robust\nand high-performance object detection, localization, as well as recognition - a\nkey component of new environmental perception. In this paper, we propose a\nnovel radar multiple-perspectives convolutional neural network (RAMP-CNN) that\nextracts the location and class of objects based on further processing of the\nrange-velocity-angle (RVA) heatmap sequences. To bypass the complexity of 4D\nconvolutional neural networks (NN), we propose to combine several\nlower-dimension NN models within our RAMP-CNN model that nonetheless approaches\nthe performance upper-bound with lower complexity. The extensive experiments\nshow that the proposed RAMP-CNN model achieves better average recall and\naverage precision than prior works in all testing scenarios. Besides, the\nRAMP-CNN model is validated to work robustly under nighttime, which enables\nlow-cost radars as a potential substitute for pure optical sensing under severe\nconditions.",
          "link": "http://arxiv.org/abs/2011.08981",
          "publishedOn": "2022-05-02T00:57:34.037Z",
          "wordCount": 643,
          "title": "RAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object Recognition. (arXiv:2011.08981v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Halah_Z/0/1/0/all/0/1\">Ziad Al-Halah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_S/0/1/0/all/0/1\">Santhosh K. Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1\">Kristen Grauman</a>",
          "description": "In reinforcement learning for visual navigation, it is common to develop a\nmodel for each new task, and train that model from scratch with task-specific\ninteractions in 3D environments. However, this process is expensive; massive\namounts of interactions are needed for the model to generalize well. Moreover,\nthis process is repeated whenever there is a change in the task type or the\ngoal modality. We present a unified approach to visual navigation using a novel\nmodular transfer learning model. Our model can effectively leverage its\nexperience from one source task and apply it to multiple target tasks (e.g.,\nObjectNav, RoomNav, ViewNav) with various goal modalities (e.g., image, sketch,\naudio, label). Furthermore, our model enables zero-shot experience learning,\nwhereby it can solve the target tasks without receiving any task-specific\ninteractive training. Our experiments on multiple photorealistic datasets and\nchallenging tasks show that our approach learns faster, generalizes better, and\noutperforms SoTA models by a significant margin.",
          "link": "http://arxiv.org/abs/2202.02440",
          "publishedOn": "2022-05-02T00:57:34.037Z",
          "wordCount": null,
          "title": "Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation. (arXiv:2202.02440v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gal_A/0/1/0/all/0/1\">Avigdor Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shraga_R/0/1/0/all/0/1\">Roee Shraga</a>",
          "description": "Data integration has been recently challenged by the need to handle large\nvolumes of data, arriving at high velocity from a variety of sources, which\ndemonstrate varying levels of veracity. This challenging setting, often\nreferred to as big data, renders many of the existing techniques, especially\nthose that are human-intensive, obsolete. Big data also produces technological\nadvancements such as Internet of things, cloud computing, and deep learning,\nand accordingly, provides a new, exciting, and challenging research agenda.\nGiven the availability of data and the improvement of machine learning\ntechniques, this blog discusses the respective roles of humans and machines in\nachieving cognitive tasks in matching, aiming to determine whether traditional\nroles of humans and machines are subject to change. Such investigation, we\nbelieve, will pave a way to better utilize both human and machine resources in\nnew and innovative manners. We shall discuss two possible modes of change,\nnamely humans out and humans in. Humans out aim at exploring out-of-the-box\nlatent matching reasoning using machine learning algorithms when attempting to\noverpower human matcher performance. Pursuing out-of-the-box thinking, machine\nand deep learning can be involved in matching. Humans in explores how to better\ninvolve humans in the matching loop by assigning human matchers with a\nsymmetric role to algorithmic matcher in the matching process.",
          "link": "http://arxiv.org/abs/2204.14192",
          "publishedOn": "2022-05-02T00:57:34.029Z",
          "wordCount": 640,
          "title": "Human's Role in-the-Loop. (arXiv:2204.14192v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14141",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Messenger_D/0/1/0/all/0/1\">Daniel A. Messenger</a> (1), <a href=\"http://arxiv.org/find/q-bio/1/au:+Wheeler_G/0/1/0/all/0/1\">Graycen E. Wheeler</a> (2), <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_X/0/1/0/all/0/1\">Xuedong Liu</a> (2), <a href=\"http://arxiv.org/find/q-bio/1/au:+Bortz_D/0/1/0/all/0/1\">David M. Bortz</a> (1) ((1) Department of Applied Mathematics, University of Colorado, Boulder, CO 80309-0526, (2) Department of Biochemistry, University of Colorado, Boulder, CO 80309-0596)",
          "description": "Interacting particle system (IPS) models have proven to be highly successful\nfor describing the spatial movement of organisms. However, it has proven\nchallenging to infer the interaction rules directly from data. In the field of\nequation discovery, the Weak form Sparse Identification of Nonlinear Dynamics\n(WSINDy) methodology has been shown to be very computationally efficient for\nidentifying the governing equations of complex systems, even in the presence of\nsubstantial noise. Motivated by the success of IPS models to describe the\nspatial movement of organisms, we develop WSINDy for second order IPSs to model\nthe movement of communities of cells. Specifically, our approach learns the\ndirectional interaction rules that govern the dynamics of a heterogeneous\npopulation of migrating cells. Rather than aggregating cellular trajectory data\ninto a single best-fit model, we learn the models for each individual cell.\nThese models can then be efficiently classified according to the active classes\nof interactions present in the model. From these classifications, aggregated\nmodels are constructed hierarchically to simultaneously identify different\nspecies of cells present in the population and determine best-fit models for\neach species. We demonstrate the efficiency and proficiency of the method on\nseveral test scenarios, motivated by common cell migration experiments.",
          "link": "http://arxiv.org/abs/2204.14141",
          "publishedOn": "2022-05-02T00:57:34.020Z",
          "wordCount": null,
          "title": "Learning Anisotropic Interaction Rules from Individual Trajectories in a Heterogeneous Cellular Population. (arXiv:2204.14141v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13808",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dahlgaard_M/0/1/0/all/0/1\">Mads Emil Dahlgaard</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jorgensen_M/0/1/0/all/0/1\">Morten Wehlast J&#xf8;rgensen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fuglsang_N/0/1/0/all/0/1\">Niels Asp Fuglsang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nassar_H/0/1/0/all/0/1\">Hiba Nassar</a>",
          "description": "The idea of federated learning is to train deep neural network models\ncollaboratively and share them with multiple participants without exposing\ntheir private training data to each other. This is highly attractive in the\nmedical domain due to patients' privacy records. However, a recently proposed\nmethod called Deep Leakage from Gradients enables attackers to reconstruct data\nfrom shared gradients. This study shows how easy it is to reconstruct images\nfor different data initialization schemes and distance measures. We show how\ndata and model architecture influence the optimal choice of initialization\nscheme and distance measure configurations when working with single images. We\ndemonstrate that the choice of initialization scheme and distance measure can\nsignificantly increase convergence speed and quality. Furthermore, we find that\nthe optimal attack configuration depends largely on the nature of the target\nimage distribution and the complexity of the model architecture.",
          "link": "http://arxiv.org/abs/2204.13808",
          "publishedOn": "2022-05-02T00:57:34.019Z",
          "wordCount": null,
          "title": "Analysing the Influence of Attack Configurations on the Reconstruction of Medical Images in Federated Learning. (arXiv:2204.13808v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.08215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahl_G/0/1/0/all/0/1\">George E. Dahl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1\">Kevin Swersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chansoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mariet_Z/0/1/0/all/0/1\">Zelda Mariet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nado_Z/0/1/0/all/0/1\">Zachary Nado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilmer_J/0/1/0/all/0/1\">Justin Gilmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snoek_J/0/1/0/all/0/1\">Jasper Snoek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghahramani_Z/0/1/0/all/0/1\">Zoubin Ghahramani</a>",
          "description": "Bayesian optimization (BO) has become a popular strategy for global\noptimization of many expensive real-world functions. Contrary to a common\nbelief that BO is suited to optimizing black-box functions, it actually\nrequires domain knowledge on characteristics of those functions to deploy BO\nsuccessfully. Such domain knowledge often manifests in Gaussian process priors\nthat specify initial beliefs on functions. However, even with expert knowledge,\nit is not an easy task to select a prior. This is especially true for\nhyperparameter tuning problems on complex machine learning models, where\nlandscapes of tuning objectives are often difficult to comprehend. We seek an\nalternative practice for setting these functional priors. In particular, we\nconsider the scenario where we have data from similar functions that allow us\nto pre-train a tighter distribution a priori. Theoretically, we show a bounded\nregret of BO with pre-trained priors. To verify our approach in realistic model\ntraining setups, we collected a large multi-task hyperparameter tuning dataset\nby training tens of thousands of configurations of near-state-of-the-art models\non popular image and text datasets, as well as a protein sequence dataset. Our\nresults show that on average, our method is able to locate good hyperparameters\nat least 3 times more efficiently than the best competing methods.",
          "link": "http://arxiv.org/abs/2109.08215",
          "publishedOn": "2022-05-02T00:57:34.018Z",
          "wordCount": null,
          "title": "Pre-training helps Bayesian optimization too. (arXiv:2109.08215v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14025",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Palmeiro_J/0/1/0/all/0/1\">Jo&#xe3;o Palmeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malveiro_B/0/1/0/all/0/1\">Beatriz Malveiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_R/0/1/0/all/0/1\">Rita Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polido_D/0/1/0/all/0/1\">David Polido</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreira_R/0/1/0/all/0/1\">Ricardo Moreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bizarro_P/0/1/0/all/0/1\">Pedro Bizarro</a>",
          "description": "Machine learning on data streams is increasingly more present in multiple\ndomains. However, there is often data distribution shift that can lead machine\nlearning models to make incorrect decisions. While there are automatic methods\nto detect when drift is happening, human analysis, often by data scientists, is\nessential to diagnose the causes of the problem and adjust the system. We\npropose Data+Shift, a visual analytics tool to support data scientists in the\ntask of investigating the underlying factors of shift in data features in the\ncontext of fraud detection. Design requirements were derived from interviews\nwith data scientists. Data+Shift is integrated with JupyterLab and can be used\nalongside other data science tools. We validated our approach with a\nthink-aloud experiment where a data scientist used the tool for a fraud\ndetection use case.",
          "link": "http://arxiv.org/abs/2204.14025",
          "publishedOn": "2022-05-02T00:57:34.015Z",
          "wordCount": null,
          "title": "Data+Shift: Supporting visual investigation of data distribution shifts by data scientists. (arXiv:2204.14025v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_C/0/1/0/all/0/1\">Cong Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Peipei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_A/0/1/0/all/0/1\">Alex Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jingtong Hu</a>",
          "description": "The complex nature of real-world problems calls for heterogeneity in both\nmachine learning (ML) models and hardware systems. The heterogeneity in ML\nmodels comes from multi-sensor perceiving and multi-task learning, i.e.,\nmulti-modality multi-task (MMMT), resulting in diverse deep neural network\n(DNN) layers and computation patterns. The heterogeneity in systems comes from\ndiverse processing components, as it becomes the prevailing method to integrate\nmultiple dedicated accelerators into one system. Therefore, a new problem\nemerges: heterogeneous model to heterogeneous system mapping (H2H). While\nprevious mapping algorithms mostly focus on efficient computations, in this\nwork, we argue that it is indispensable to consider computation and\ncommunication simultaneously for better system efficiency. We propose a novel\nH2H mapping algorithm with both computation and communication awareness; by\nslightly trading computation for communication, the system overall latency and\nenergy consumption can be largely reduced. The superior performance of our work\nis evaluated based on MAESTRO modeling, demonstrating 15%-74% latency reduction\nand 23%-64% energy reduction compared with existing computation-prioritized\nmapping algorithms.",
          "link": "http://arxiv.org/abs/2204.13852",
          "publishedOn": "2022-05-02T00:57:34.014Z",
          "wordCount": 611,
          "title": "H2H: Heterogeneous Model to Heterogeneous System Mapping with Computation and Communication Awareness. (arXiv:2204.13852v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rombach_K/0/1/0/all/0/1\">Katharina Rombach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michau_D/0/1/0/all/0/1\">Dr. Gabriel Michau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fink_P/0/1/0/all/0/1\">Prof. Dr. Olga Fink</a>",
          "description": "New operating conditions can result in a performance drop of fault\ndiagnostics models due to the domain gap between the training and the testing\ndata distributions. While several domain adaptation approaches have been\nproposed to overcome such domain shifts, their application is limited if the\nlabel spaces of the two domains are not congruent. To improve the\ntransferability of the trained models, particularly in setups where only the\nhealthy data class is shared between the two domains, we propose a new\nframework based on a Wasserstein GAN for Partial and OpenSet&Partial domain\nadaptation. The main contribution is the controlled fault data generation that\nenables to generate unobserved fault types and severity levels in the target\ndomain by having only access to the healthy samples in the target domain and\nfaulty samples in the source domain. To evaluate the ability of the proposed\nmethod to bridge domain gaps in different domain adaption settings, we conduct\nPartial as well as OpenSet&Partial domain adaptation experiments on two bearing\nfault diagnostics case studies. The results show the versatility of the\nframework and that the synthetically generated fault data helps bridging the\ndomain gaps, especially in instances where the domain gap is large.",
          "link": "http://arxiv.org/abs/2204.14068",
          "publishedOn": "2022-05-02T00:57:34.014Z",
          "wordCount": null,
          "title": "Controlled Generation of Unseen Faults for Partial and OpenSet&Partial Domain Adaptation. (arXiv:2204.14068v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05231",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weiyi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1\">Tianchuan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schroeder_B/0/1/0/all/0/1\">Benjamin Schroeder</a>",
          "description": "Recently, semantic search has been successfully applied to e-commerce product\nsearch and the learned semantic space(s) for query and product encoding are\nexpected to generalize to unseen queries or products. Yet, whether\ngeneralization can conveniently emerge has not been thoroughly studied in the\ndomain thus far. In this paper, we examine several general-domain and\ndomain-specific pre-trained Roberta variants and discover that general-domain\nfine-tuning does not help generalization, which aligns with the discovery of\nprior art. Proper domain-specific fine-tuning with clickstream data can lead to\nbetter model generalization, based on a bucketed analysis of a publicly\navailable manual annotated query-product pair da",
          "link": "http://arxiv.org/abs/2204.05231",
          "publishedOn": "2022-05-02T00:57:33.991Z",
          "wordCount": 591,
          "title": "Towards Generalizable Semantic Product Search by Text Similarity Pre-training on Search Click Logs. (arXiv:2204.05231v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14226",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Homeyer_A/0/1/0/all/0/1\">Andr&#xe9; Homeyer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Geissler_C/0/1/0/all/0/1\">Christian Gei&#xdf;ler</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schwen_L/0/1/0/all/0/1\">Lars Ole Schwen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zakrzewski_F/0/1/0/all/0/1\">Falk Zakrzewski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Evans_T/0/1/0/all/0/1\">Theodore Evans</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Strohmenger_K/0/1/0/all/0/1\">Klaus Strohmenger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Westphal_M/0/1/0/all/0/1\">Max Westphal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bulow_R/0/1/0/all/0/1\">Roman David B&#xfc;low</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kargl_M/0/1/0/all/0/1\">Michaela Kargl</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karjauv_A/0/1/0/all/0/1\">Aray Karjauv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Munne_Bertran_I/0/1/0/all/0/1\">Isidre Munn&#xe9;-Bertran</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Retzlaff_C/0/1/0/all/0/1\">Carl Orge Retzlaff</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Romero_Lopez_A/0/1/0/all/0/1\">Adri&#xe0; Romero-L&#xf3;pez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Soltysinski_T/0/1/0/all/0/1\">Tomasz So&#x142;tysi&#x144;ski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Plass_M/0/1/0/all/0/1\">Markus Plass</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Carvalho_R/0/1/0/all/0/1\">Rita Carvalho</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Steinbach_P/0/1/0/all/0/1\">Peter Steinbach</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lan_Y/0/1/0/all/0/1\">Yu-Chia Lan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bouteldja_N/0/1/0/all/0/1\">Nassim Bouteldja</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Haber_D/0/1/0/all/0/1\">David Haber</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rojas_Carulla_M/0/1/0/all/0/1\">Mateo Rojas-Carulla</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sadr_A/0/1/0/all/0/1\">Alireza Vafaei Sadr</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kraft_M/0/1/0/all/0/1\">Matthias Kraft</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kruger_D/0/1/0/all/0/1\">Daniel Kr&#xfc;ger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fick_R/0/1/0/all/0/1\">Rutger Fick</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lang_T/0/1/0/all/0/1\">Tobias Lang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boor_P/0/1/0/all/0/1\">Peter Boor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Muller_H/0/1/0/all/0/1\">Heimo M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hufnagl_P/0/1/0/all/0/1\">Peter Hufnagl</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zerbe_N/0/1/0/all/0/1\">Norman Zerbe</a>",
          "description": "Artificial intelligence (AI) solutions that automatically extract information\nfrom digital histology images have shown great promise for improving\npathological diagnosis. Prior to routine use, it is important to evaluate their\npredictive performance and obtain regulatory approval. This assessment requires\nappropriate test datasets. However, compiling such datasets is challenging and\nspecific recommendations are missing.\n\nA committee of various stakeholders, including commercial AI developers,\npathologists, and researchers, discussed key aspects and conducted extensive\nliterature reviews on test datasets in pathology. Here, we summarize the\nresults and derive general recommendations for the collection of test datasets.\n\nWe address several questions: Which and how many images are needed? How to\ndeal with low-prevalence subsets? How can potential bias be detected? How\nshould datasets be reported? What are the regulatory requirements in different\ncountries?\n\nThe recommendations are intended to help AI developers demonstrate the\nutility of their products and to help regulatory agencies and end users verify\nreported performance measures. Further research is needed to formulate criteria\nfor sufficiently representative test datasets so that AI solutions can operate\nwith less user intervention and better support diagnostic workflows in the\nfuture.",
          "link": "http://arxiv.org/abs/2204.14226",
          "publishedOn": "2022-05-02T00:57:33.979Z",
          "wordCount": 695,
          "title": "Recommendations on test datasets for evaluating AI solutions in pathology. (arXiv:2204.14226v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.06263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Taskesen_B/0/1/0/all/0/1\">Bahar Taskesen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafieezadeh_Abadeh_S/0/1/0/all/0/1\">Soroosh Shafieezadeh-Abadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhn_D/0/1/0/all/0/1\">Daniel Kuhn</a>",
          "description": "Semi-discrete optimal transport problems, which evaluate the Wasserstein\ndistance between a discrete and a generic (possibly non-discrete) probability\nmeasure, are believed to be computationally hard. Even though such problems are\nubiquitous in statistics, machine learning and computer vision, however, this\nperception has not yet received a theoretical justification. To fill this gap,\nwe prove that computing the Wasserstein distance between a discrete probability\nmeasure supported on two points and the Lebesgue measure on the standard\nhypercube is already #P-hard. This insight prompts us to seek approximate\nsolutions for semi-discrete optimal transport problems. We thus perturb the\nunderlying transportation cost with an additive disturbance governed by an\nambiguous probability distribution, and we introduce a distributionally robust\ndual optimal transport problem whose objective function is smoothed with the\nmost adverse disturbance distributions from within a given ambiguity set. We\nfurther show that smoothing the dual objective function is equivalent to\nregularizing the primal objective function, and we identify several ambiguity\nsets that give rise to several known and new regularization schemes. As a\nbyproduct, we discover an intimate relation between semi-discrete optimal\ntransport problems and discrete choice models traditionally studied in\npsychology and economics. To solve the regularized optimal transport problems\nefficiently, we use a stochastic gradient descent algorithm with imprecise\nstochastic gradient oracles. A new convergence analysis reveals that this\nalgorithm improves the best known convergence guarantee for semi-discrete\noptimal transport problems with entropic regularizers.",
          "link": "http://arxiv.org/abs/2103.06263",
          "publishedOn": "2022-05-02T00:57:33.957Z",
          "wordCount": null,
          "title": "Semi-Discrete Optimal Transport: Hardness, Regularization and Numerical Solution. (arXiv:2103.06263v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.07819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wahle_J/0/1/0/all/0/1\">Jan Philip Wahle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashok_N/0/1/0/all/0/1\">Nischal Ashok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruas_T/0/1/0/all/0/1\">Terry Ruas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meuschke_N/0/1/0/all/0/1\">Norman Meuschke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosal_T/0/1/0/all/0/1\">Tirthankar Ghosal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1\">Bela Gipp</a>",
          "description": "A drastic rise in potentially life-threatening misinformation has been a\nby-product of the COVID-19 pandemic. Computational support to identify false\ninformation within the massive body of data on the topic is crucial to prevent\nharm. Researchers proposed many methods for flagging online misinformation\nrelated to COVID-19. However, these methods predominantly target specific\ncontent types (e.g., news) or platforms (e.g., Twitter). The methods'\ncapabilities to generalize were largely unclear so far. We evaluate fifteen\nTransformer-based models on five COVID-19 misinformation datasets that include\nsocial media posts, news articles, and scientific papers to fill this gap. We\nshow tokenizers and models tailored to COVID-19 data do not provide a\nsignificant advantage over general-purpose ones. Our study provides a realistic\nassessment of models for detecting COVID-19 misinformation. We expect that\nevaluating a broad spectrum of datasets and models will benefit future research\nin developing misinformation detection systems.",
          "link": "http://arxiv.org/abs/2111.07819",
          "publishedOn": "2022-05-02T00:57:33.957Z",
          "wordCount": null,
          "title": "Testing the Generalization of Neural Language Models for COVID-19 Misinformation Detection. (arXiv:2111.07819v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09076",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hintersdorf_D/0/1/0/all/0/1\">Dominik Hintersdorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Struppek_L/0/1/0/all/0/1\">Lukas Struppek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>",
          "description": "Membership inference attacks (MIAs) aim to determine whether a specific\nsample was used to train a predictive model. Knowing this may indeed lead to a\nprivacy breach. Most MIAs, however, make use of the model's prediction scores -\nthe probability of each output given some input - following the intuition that\nthe trained model tends to behave differently on its training data. We argue\nthat this is a fallacy for many modern deep network architectures.\nConsequently, MIAs will miserably fail since overconfidence leads to high\nfalse-positive rates not only on known domains but also on out-of-distribution\ndata and implicitly acts as a defense against MIAs. Specifically, using\ngenerative adversarial networks, we are able to produce a potentially infinite\nnumber of samples falsely classified as part of the training data. In other\nwords, the threat of MIAs is overestimated, and less information is leaked than\npreviously assumed. Moreover, there is actually a trade-off between the\noverconfidence of models and their susceptibility to MIAs: the more classifiers\nknow when they do not know, making low confidence predictions, the more they\nreveal the training data.",
          "link": "http://arxiv.org/abs/2111.09076",
          "publishedOn": "2022-05-02T00:57:33.957Z",
          "wordCount": null,
          "title": "To Trust or Not To Trust Prediction Scores for Membership Inference Attacks. (arXiv:2111.09076v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13883",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Watcharasupat_K/0/1/0/all/0/1\">Karn N. Watcharasupat</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ooi_K/0/1/0/all/0/1\">Kenneth Ooi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lam_B/0/1/0/all/0/1\">Bhan Lam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wong_T/0/1/0/all/0/1\">Trevor Wong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ong_Z/0/1/0/all/0/1\">Zhen-Ting Ong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gan_W/0/1/0/all/0/1\">Woon-Seng Gan</a>",
          "description": "The selection of maskers and playback gain levels in a soundscape\naugmentation system is crucial to its effectiveness in improving the overall\nacoustic comfort of a given environment. Traditionally, the selection of\nappropriate maskers and gain levels has been informed by expert opinion, which\nmay not representative of the target population, or by listening tests, which\ncan be time-consuming and labour-intensive. Furthermore, the resulting static\nchoices of masker and gain are often inflexible to the dynamic nature of\nreal-world soundscapes. In this work, we utilized a deep learning model to\nperform joint selection of the optimal masker and its gain level for a given\nsoundscape. The proposed model was designed with highly modular building\nblocks, allowing for an optimized inference process that can quickly search\nthrough a large number of masker and gain combinations. In addition, we\nintroduced the use of feature-domain soundscape augmentation conditioned on the\ndigital gain level, eliminating the computationally expensive waveform-domain\nmixing process during inference time, as well as the tedious pre-calibration\nprocess required for new maskers. The proposed system was validated on a\nlarge-scale dataset of subjective responses to augmented soundscapes with more\nthan 440 participants, ensuring the ability of the model to predict combined\neffect of the masker and its gain level on the perceptual pleasantness level.",
          "link": "http://arxiv.org/abs/2204.13883",
          "publishedOn": "2022-05-02T00:57:33.956Z",
          "wordCount": 695,
          "title": "Autonomous In-Situ Soundscape Augmentation via Joint Selection of Masker and Gain. (arXiv:2204.13883v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1\">Adityanarayanan Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belkin_M/0/1/0/all/0/1\">Mikhail Belkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uhler_C/0/1/0/all/0/1\">Caroline Uhler</a>",
          "description": "While neural networks are used for classification tasks across domains, a\nlong-standing open problem in machine learning is determining whether neural\nnetworks trained using standard procedures are optimal for classification,\ni.e., whether such models minimize the probability of misclassification for\narbitrary data distributions. In this work, we identify and construct an\nexplicit set of neural network classifiers that achieve optimality. Since\neffective neural networks in practice are typically both wide and deep, we\nanalyze infinitely wide networks that are also infinitely deep. In particular,\nusing the recent connection between infinitely wide neural networks and Neural\nTangent Kernels, we provide explicit activation functions that can be used to\nconstruct networks that achieve optimality. Interestingly, these activation\nfunctions are simple and easy to implement, yet differ from commonly used\nactivations such as ReLU or sigmoid. More generally, we create a taxonomy of\ninfinitely wide and deep networks and show that these models implement one of\nthree well-known classifiers depending on the activation function used: (1)\n1-nearest neighbor (model predictions are given by the label of the nearest\ntraining example); (2) majority vote (model predictions are given by the label\nof the class with greatest representation in the training set); or (3) singular\nkernel classifiers (a set of classifiers containing those that achieve\noptimality). Our results highlight the benefit of using deep networks for\nclassification tasks, in contrast to regression tasks, where excessive depth is\nharmful.",
          "link": "http://arxiv.org/abs/2204.14126",
          "publishedOn": "2022-05-02T00:57:33.956Z",
          "wordCount": null,
          "title": "Wide and Deep Neural Networks Achieve Optimality for Classification. (arXiv:2204.14126v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stapleton_A/0/1/0/all/0/1\">Adam Stapleton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eichelmann_E/0/1/0/all/0/1\">Elke Eichelmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roantree_M/0/1/0/all/0/1\">Mark Roantree</a>",
          "description": "A deeper understanding of the drivers of evapotranspiration and the modelling\nof its constituent parts (evaporation and transpiration) could be of\nsignificant importance to the monitoring and management of water resources\nglobally over the coming decades. In this work, we developed a framework to\nidentify the best performing machine learning algorithm from a candidate set,\nselect optimal predictive features as well as ranking features in terms of\ntheir im- portance to predictive accuracy. Our experiments used 3 separate\nfeature sets across 4 wetland sites as input into 8 candidate machine learning\nalgorithms, providing 96 sets of experimental configurations. Given this high\nnumber of parameters, our results show strong evidence that there is no\nsingularly optimal machine learning algorithm or feature set across all of the\nwetland sites studied despite their similarities. A key finding discovered when\nexamining feature importance is that methane flux, a feature whose relationship\nwith evapotranspiration is not generally examined, may contribute to further\nbiophysical process understanding.",
          "link": "http://arxiv.org/abs/2204.14142",
          "publishedOn": "2022-05-02T00:57:33.947Z",
          "wordCount": null,
          "title": "A Framework for Constructing Machine Learning Models with Feature Set Optimisation for Evapotranspiration Partitioning. (arXiv:2204.14142v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.11783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kevin P. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montillo_A/0/1/0/all/0/1\">Albert Montillo</a> (for the Alzheimer&#x27;s Disease Neuroimaging Initiative)",
          "description": "Natural science datasets frequently violate assumptions of independence.\nSamples may be clustered (e.g. by study site, subject, or experimental batch),\nleading to spurious associations, poor model fitting, and confounded analyses.\nWhile largely unaddressed in deep learning, this problem has been handled in\nthe statistics community through mixed effects models, which separate\ncluster-invariant fixed effects from cluster-specific random effects. We\npropose a general-purpose framework for Adversarially-Regularized Mixed Effects\nDeep learning (ARMED) models through non-intrusive additions to existing neural\nnetworks: 1) an adversarial classifier constraining the original model to learn\nonly cluster-invariant features, 2) a random effects subnetwork capturing\ncluster-specific features, and 3) an approach to apply random effects to\nclusters unseen during training. We apply ARMED to dense, convolutional, and\nautoencoder neural networks on 4 applications including simulated nonlinear\ndata, dementia prognosis and diagnosis, and live-cell image analysis. Compared\nto prior techniques, ARMED models better distinguish confounded from true\nassociations in simulations and learn more biologically plausible features in\nclinical applications. They can also quantify inter-cluster variance and\nvisualize cluster effects in data. Finally, ARMED improves accuracy on data\nfrom clusters seen during training (up to 28% vs. conventional models) and\ngeneralization to unseen clusters (up to 9% vs. conventional models).",
          "link": "http://arxiv.org/abs/2202.11783",
          "publishedOn": "2022-05-02T00:57:33.939Z",
          "wordCount": null,
          "title": "Adversarially-regularized mixed effects deep learning (ARMED) models for improved interpretability, performance, and generalization on clustered data. (arXiv:2202.11783v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13851",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zeng_E/0/1/0/all/0/1\">E. Zhixuan Zeng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Florea_A/0/1/0/all/0/1\">Adrian Florea</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wong_A/0/1/0/all/0/1\">Alexander Wong</a>",
          "description": "As the global population continues to face significant negative impact by the\non-going COVID-19 pandemic, there has been an increasing usage of point-of-care\nultrasound (POCUS) imaging as a low-cost and effective imaging modality of\nchoice in the COVID-19 clinical workflow. A major barrier with widespread\nadoption of POCUS in the COVID-19 clinical workflow is the scarcity of expert\nclinicians that can interpret POCUS examinations, leading to considerable\ninterest in deep learning-driven clinical decision support systems to tackle\nthis challenge. A major challenge to building deep neural networks for COVID-19\nscreening using POCUS is the heterogeneity in the types of probes used to\ncapture ultrasound images (e.g., convex vs. linear probes), which can lead to\nvery different visual appearances. In this study, we explore the impact of\nleveraging extended linear-convex ultrasound augmentation learning on producing\nenhanced deep neural networks for COVID-19 assessment, where we conduct data\naugmentation on convex probe data alongside linear probe data that have been\ntransformed to better resemble convex probe data. Experimental results using an\nefficient deep columnar anti-aliased convolutional neural network designed via\na machined-driven design exploration strategy (which we name COVID-Net US-X)\nshow that the proposed extended linear-convex ultrasound augmentation learning\nsignificantly increases performance, with a gain of 5.1% in test accuracy and\n13.6% in AUC.",
          "link": "http://arxiv.org/abs/2204.13851",
          "publishedOn": "2022-05-02T00:57:33.936Z",
          "wordCount": null,
          "title": "COVID-Net US-X: Enhanced Deep Neural Network for Detection of COVID-19 Patient Cases from Convex Ultrasound Imaging Through Extended Linear-Convex Ultrasound Augmentation Learning. (arXiv:2204.13851v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.00133",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lew_L/0/1/0/all/0/1\">Lukasz Lew</a>",
          "description": "Optimization of Top-1 ImageNet promotes enormous networks that may be\nimpractical in inference settings. Binary neural networks (BNNs) have the\npotential to significantly lower the compute intensity but existing models\nsuffer from low quality. To overcome this deficiency, we propose PokeConv, a\nbinary convolution block which improves quality of BNNs by techniques such as\nadding multiple residual paths, and tuning the activation function. We apply it\nto ResNet-50 and optimize ResNet's initial convolutional layer which is hard to\nbinarize. We name the resulting network family PokeBNN. These techniques are\nchosen to yield favorable improvements in both top-1 accuracy and the network's\ncost. In order to enable joint optimization of the cost together with accuracy,\nwe define arithmetic computation effort (ACE), a hardware- and energy-inspired\ncost metric for quantized and binarized networks. We also identify a need to\noptimize an under-explored hyper-parameter controlling the binarization\ngradient approximation.\n\nWe establish a new, strong state-of-the-art (SOTA) on top-1 accuracy together\nwith commonly-used CPU64 cost, ACE cost and network size metrics.\nReActNet-Adam, the previous SOTA in BNNs, achieved a 70.5% top-1 accuracy with\n7.9 ACE. A small variant of PokeBNN achieves 70.5% top-1 with 2.6 ACE, more\nthan 3x reduction in cost; a larger PokeBNN achieves 75.6% top-1 with 7.8 ACE,\nmore than 5% improvement in accuracy without increasing the cost. PokeBNN\nimplementation in JAX/Flax and reproduction instructions are available in AQT\nrepository: https://github.com/google/aqt",
          "link": "http://arxiv.org/abs/2112.00133",
          "publishedOn": "2022-05-02T00:57:33.936Z",
          "wordCount": null,
          "title": "PokeBNN: A Binary Pursuit of Lightweight Accuracy. (arXiv:2112.00133v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.07650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mollas_I/0/1/0/all/0/1\">Ioannis Mollas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bassiliades_N/0/1/0/all/0/1\">Nick Bassiliades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1\">Grigorios Tsoumakas</a>",
          "description": "Explainable AI is an emerging field providing solutions for acquiring\ninsights into automated systems' rationale. It has been put on the AI map by\nsuggesting ways to tackle key ethical and societal issues. Existing explanation\ntechniques are often not comprehensible to the end user. Lack of evaluation and\nselection criteria also makes it difficult for the end user to choose the most\nsuitable technique. In this study, we combine logic-based argumentation with\nInterpretable Machine Learning, introducing a preliminary meta-explanation\nmethodology that identifies the truthful parts of feature importance oriented\ninterpretations. This approach, in addition to being used as a meta-explanation\ntechnique, can be used as an evaluation or selection tool for multiple feature\nimportance techniques. Experimentation strongly indicates that an ensemble of\nmultiple interpretation techniques yields considerably more truthful\nexplanations.",
          "link": "http://arxiv.org/abs/2010.07650",
          "publishedOn": "2022-05-02T00:57:33.934Z",
          "wordCount": null,
          "title": "Altruist: Argumentative Explanations through Local Interpretations of Predictive Models. (arXiv:2010.07650v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Ying Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunay_C/0/1/0/all/0/1\">Cengiz Gunay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tangirala_S/0/1/0/all/0/1\">Sairam Tangirala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerven_D/0/1/0/all/0/1\">David Kerven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Wei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savage_J/0/1/0/all/0/1\">Jamye Curry Savage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seungjin Lee</a>",
          "description": "Learning management systems (LMSs) have become essential in higher education\nand play an important role in helping educational institutions to promote\nstudent success. Traditionally, LMSs have been used by postsecondary\ninstitutions in administration, reporting, and delivery of educational content.\nIn this paper, we present an additional use of LMS by using its data logs to\nperform data-analytics and identify academically at-risk students. The\ndata-driven insights would allow educational institutions and educators to\ndevelop and implement pedagogical interventions targeting academically at-risk\nstudents. We used anonymized data logs created by Brightspace LMS during fall\n2019, spring 2020, and fall 2020 semesters at our college. Supervised machine\nlearning algorithms were used to predict the final course performance of\nstudents, and several algorithms were found to perform well with accuracy above\n90%. SHAP value method was used to assess the relative importance of features\nused in the predictive models. Unsupervised learning was also used to group\nstudents into different clusters based on the similarities in their\ninteraction/involvement with LMS. In both of supervised and unsupervised\nlearning, we identified two most-important features\n(Number_Of_Assignment_Submissions and Content_Completed). More importantly, our\nstudy lays a foundation and provides a framework for developing a real-time\ndata analytics metric that may be incorporated into a LMS.",
          "link": "http://arxiv.org/abs/2204.13700",
          "publishedOn": "2022-05-02T00:57:33.926Z",
          "wordCount": 642,
          "title": "Identifying Critical LMS Features for Predicting At-risk Students. (arXiv:2204.13700v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baraka_S/0/1/0/all/0/1\">Shimaa Baraka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerdawy_A/0/1/0/all/0/1\">Ahmed M. El Kerdawy</a>",
          "description": "Predicting the yield percentage of a chemical reaction is useful in many\naspects such as reducing wet-lab experimentation by giving the priority to the\nreactions with a high predicted yield. In this work we investigated the use of\nmultiple type inputs to predict chemical reaction yield. We used simplified\nmolecular-input line-entry system (SMILES) as well as calculated chemical\ndescriptors as model inputs. The model consists of a pre-trained bidirectional\ntransformer-based encoder (BERT) and a multi-layer perceptron (MLP) with a\nregression head to predict the yield. We experimented on two high throughput\nexperimentation (HTE) datasets for Buchwald-Hartwig and Suzuki-Miyaura\nreactions. The experiments show improvements in the prediction on both datasets\ncompared to systems using only SMILES or chemical descriptors as input. We also\ntested the model's performance on out-of-sample dataset splits of\nBuchwald-Hartwig and achieved comparable results with the state-of-the-art. In\naddition to predicting the yield, we demonstrated the model's ability to\nsuggest the optimum (highest yield) reaction conditions. The model was able to\nsuggest conditions that achieves 94% of the optimum reported yields. This\nproves the model to be useful in achieving the best results in the wet lab\nwithout expensive experimentation.",
          "link": "http://arxiv.org/abs/2204.14062",
          "publishedOn": "2022-05-02T00:57:33.916Z",
          "wordCount": null,
          "title": "Multimodal Transformer-based Model for Buchwald-Hartwig and Suzuki-Miyaura Reaction Yield Prediction. (arXiv:2204.14062v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuting Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuan-Chi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Garadi_M/0/1/0/all/0/1\">Mohammed Ali Al-Garadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarker_A/0/1/0/all/0/1\">Abeed Sarker</a>",
          "description": "Objective: Few-shot learning (FSL) methods require small numbers of labeled\ninstances for training. As many medical topics have limited annotated textual\ndata in practical settings, FSL-based natural language processing (NLP) methods\nhold substantial promise. We aimed to conduct a systematic review to explore\nthe state of FSL methods for medical NLP. Materials and Methods: We searched\nfor articles published between January 2016 and August 2021 using\nPubMed/Medline, Embase, ACL Anthology, and IEEE Xplore Digital Library. To\nidentify the latest relevant methods, we also searched other sources such as\npreprint servers (eg., medRxiv) via Google Scholar. We included all articles\nthat involved FSL and any type of medical text. We abstracted articles based on\ndata source(s), aim(s), training set size(s), primary method(s)/approach(es),\nand evaluation method(s). Results: 31 studies met our inclusion criteria-all\npublished after 2018; 22 (71%) since 2020. Concept extraction/named entity\nrecognition was the most frequently addressed task (13/31; 42%), followed by\ntext classification (10/31; 32%). Twenty-one (68%) studies reconstructed\nexisting datasets to create few-shot scenarios synthetically, and MIMIC-III was\nthe most frequently used dataset (7/31; 23%). Common methods included FSL with\nattention mechanisms (12/31; 39%), prototypical networks (8/31; 26%), and\nmeta-learning (6/31; 19%). Discussion: Despite the potential for FSL in\nbiomedical NLP, progress has been limited compared to domain-independent FSL.\nThis may be due to the paucity of standardized, public datasets, and the\nrelative underperformance of FSL methods on biomedical topics. Creation and\nrelease of specialized datasets for biomedical FSL may aid method development\nby enabling comparative analyses.",
          "link": "http://arxiv.org/abs/2204.14081",
          "publishedOn": "2022-05-02T00:57:33.904Z",
          "wordCount": null,
          "title": "Few-shot learning for medical text: A systematic review. (arXiv:2204.14081v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02470",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Md. Khaledur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1\">Abhigya Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azad_A/0/1/0/all/0/1\">Ariful Azad</a>",
          "description": "Most real-world networks contain well-defined community structures where\nnodes are densely connected internally within communities. To learn from these\nnetworks, we develop MarkovGNN that captures the formation and evolution of\ncommunities directly in different convolutional layers. Unlike most Graph\nNeural Networks (GNNs) that consider a static graph at every layer, MarkovGNN\ngenerates different stochastic matrices using a Markov process and then uses\nthese community-capturing matrices in different layers. MarkovGNN is a general\napproach that could be used with most existing GNNs. We experimentally show\nthat MarkovGNN outperforms other GNNs for clustering, node classification, and\nvisualization tasks. The source code of MarkovGNN is publicly available at\n\\url{https://github.com/HipGraph/MarkovGNN}.",
          "link": "http://arxiv.org/abs/2202.02470",
          "publishedOn": "2022-05-02T00:57:33.893Z",
          "wordCount": null,
          "title": "MarkovGNN: Graph Neural Networks on Markov Diffusion. (arXiv:2202.02470v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13744",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bilgin_O/0/1/0/all/0/1\">Onur Bilgin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vergutz_T/0/1/0/all/0/1\">Thomas Vergutz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehrkanoon_S/0/1/0/all/0/1\">Siamak Mehrkanoon</a>",
          "description": "This paper introduces a novel two-stream deep model based on graph\nconvolutional network (GCN) architecture and feed-forward neural networks\n(FFNN) for learning the solution of nonlinear partial differential equations\n(PDEs). The model aims at incorporating both graph and grid input\nrepresentations using two streams corresponding to GCN and FFNN models,\nrespectively. Each stream layer receives and processes its own input\nrepresentation. As opposed to FFNN which receives a grid-like structure, the\nGCN stream layer operates on graph input data where the neighborhood\ninformation is incorporated through the adjacency matrix of the graph. In this\nway, the proposed GCN-FFNN model learns from two types of input\nrepresentations, i.e. grid and graph data, obtained via the discretization of\nthe PDE domain. The GCN-FFNN model is trained in two phases. In the first\nphase, the model parameters of each stream are trained separately. Both streams\nemploy the same error function to adjust their parameters by enforcing the\nmodels to satisfy the given PDE as well as its initial and boundary conditions\non grid or graph collocation (training) data. In the second phase, the learned\nparameters of two-stream layers are frozen and their learned representation\nsolutions are fed to fully connected layers whose parameters are learned using\nthe previously used error function. The learned GCN-FFNN model is tested on\ntest data located both inside and outside the PDE domain. The obtained\nnumerical results demonstrate the applicability and efficiency of the proposed\nGCN-FFNN model over individual GCN and FFNN models on 1D-Burgers,\n1D-Schr\\\"odinger, 2D-Burgers and 2D-Schr\\\"odinger equations.",
          "link": "http://arxiv.org/abs/2204.13744",
          "publishedOn": "2022-05-02T00:57:33.892Z",
          "wordCount": null,
          "title": "GCN-FFNN: A Two-Stream Deep Model for Learning Solution to Partial Differential Equations. (arXiv:2204.13744v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.07703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guanxiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haoyu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_I/0/1/0/all/0/1\">Ian M. Mitchell</a>",
          "description": "We introduce ROS-X-Habitat, a software interface that bridges the AI Habitat\nplatform for embodied learning-based agents with other robotics resources via\nROS. This interface not only offers standardized communication protocols\nbetween embodied agents and simulators, but also enables physically and\nphotorealistic simulation that benefits the training and/or testing of\nvision-based embodied agents. With this interface, roboticists can evaluate\ntheir own Habitat RL agents in another ROS-based simulator or use Habitat Sim\nv2 as the test bed for their own robotic algorithms. Through in silico\nexperiments, we demonstrate that ROS-X-Habitat has minimal impact on the\nnavigation performance and simulation speed of a Habitat RGBD agent; that a\nstandard set of ROS mapping, planning and navigation tools can run in Habitat\nSim v2; and that a Habitat agent can run in the standard ROS simulator Gazebo.",
          "link": "http://arxiv.org/abs/2109.07703",
          "publishedOn": "2022-05-02T00:57:33.891Z",
          "wordCount": null,
          "title": "ROS-X-Habitat: Bridging the ROS Ecosystem with Embodied AI. (arXiv:2109.07703v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13916",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zeng_Y/0/1/0/all/0/1\">Yinuo Zeng</a>",
          "description": "Tree-based methods are popular machine learning techniques used in various\nfields. In this work, we review their foundations and a general framework the\nimportance sampled learning ensemble (ISLE) that accelerates their fitting\nprocess. Furthermore, we describe a model combination strategy called the\nadaptive regression by mixing (ARM), which is feasible for tree- based methods\nvia ISLE. Moreover, three modified ISLEs are proposed, and their performance\nare evaluated on the real data sets.",
          "link": "http://arxiv.org/abs/2204.13916",
          "publishedOn": "2022-05-02T00:57:33.890Z",
          "wordCount": null,
          "title": "A study of tree-based methods and their combination. (arXiv:2204.13916v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maho_T/0/1/0/all/0/1\">Thibault Maho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furon_T/0/1/0/all/0/1\">Teddy Furon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merrer_E/0/1/0/all/0/1\">Erwan Le Merrer</a>",
          "description": "Randomized smoothing is a recent and celebrated solution to certify the\nrobustness of any classifier. While it indeed provides a theoretical robustness\nagainst adversarial attacks, the dimensionality of current classifiers\nnecessarily imposes Monte Carlo approaches for its application in practice.\nThis paper questions the effectiveness of randomized smoothing as a defense,\nagainst state of the art black-box attacks. This is a novel perspective, as\nprevious research works considered the certification as an unquestionable\nguarantee. We first formally highlight the mismatch between a theoretical\ncertification and the practice of attacks on classifiers. We then perform\nattacks on randomized smoothing as a defense. Our main observation is that\nthere is a major mismatch in the settings of the RS for obtaining high\ncertified robustness or when defeating black box attacks while preserving the\nclassifier accuracy.",
          "link": "http://arxiv.org/abs/2204.14187",
          "publishedOn": "2022-05-02T00:57:33.890Z",
          "wordCount": null,
          "title": "Randomized Smoothing under Attack: How Good is it in Pratice?. (arXiv:2204.14187v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shuzhao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yuan Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yifei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>",
          "description": "With the advancement of deep learning techniques, major cloud providers and\nniche machine learning service providers start to offer their cloud-based\nmachine learning tools, also known as machine learning as a service (MLaaS), to\nthe public. According to our measurement, for the same task, these MLaaSes from\ndifferent providers have varying performance due to the proprietary datasets,\nmodels, etc. Federating different MLaaSes together allows us to improve the\nanalytic performance further. However, naively aggregating results from\ndifferent MLaaSes not only incurs significant momentary cost but also may lead\nto sub-optimal performance gain due to the introduction of possible\nfalse-positive results. In this paper, we propose Armol, a framework to\nfederate the right selection of MLaaS providers to achieve the best possible\nanalytic performance. We first design a word grouping algorithm to unify the\noutput labels across different providers. We then present a deep combinatorial\nreinforcement learning based-approach to maximize the accuracy while minimizing\nthe cost. The predictions from the selected providers are then aggregated\ntogether using carefully chosen ensemble strategies. The real-world\ntrace-driven evaluation further demonstrates that Armol is able to achieve the\nsame accuracy results with $67\\%$ less inference cost.",
          "link": "http://arxiv.org/abs/2204.13971",
          "publishedOn": "2022-05-02T00:57:33.885Z",
          "wordCount": null,
          "title": "Cost Effective MLaaS Federation: A Combinatorial Reinforcement Learning Approach. (arXiv:2204.13971v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Baihan Lin</a>",
          "description": "The absence of a conventional association between the cell-cell cohabitation\nand its emergent dynamics into cliques during development has hindered our\nunderstanding of how cell populations proliferate, differentiate, and compete,\ni.e. the cell ecology. With the recent advancement of the single-cell\nRNA-sequencing (RNA-seq), we can potentially describe such a link by\nconstructing network graphs that characterize the similarity of the gene\nexpression profiles of the cell-specific transcriptional programs, and\nanalyzing these graphs systematically using the summary statistics informed by\nthe algebraic topology. We propose the single-cell topological simplicial\nanalysis (scTSA). Applying this approach to the single-cell gene expression\nprofiles from local networks of cells in different developmental stages with\ndifferent outcomes reveals a previously unseen topology of cellular ecology.\nThese networks contain an abundance of cliques of single-cell profiles bound\ninto cavities that guide the emergence of more complicated habitation forms. We\nvisualize these ecological patterns with topological simplicial architectures\nof these networks, compared with the null models. Benchmarked on the\nsingle-cell RNA-seq data of zebrafish embryogenesis spanning 38,731 cells, 25\ncell types and 12 time steps, our approach highlights the gastrulation as the\nmost critical stage, consistent with consensus in developmental biology. As a\nnonlinear, model-independent, and unsupervised framework, our approach can also\nbe applied to tracing multi-scale cell lineage, identifying critical stages, or\ncreating pseudo-time series.",
          "link": "http://arxiv.org/abs/2204.14048",
          "publishedOn": "2022-05-02T00:57:33.885Z",
          "wordCount": null,
          "title": "Topological Data Analysis in Time Series: Temporal Filtration and Application to Single-Cell Genomics. (arXiv:2204.14048v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+An_S/0/1/0/all/0/1\">Suyeong An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junghoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minsam Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Juneyoung Park</a>",
          "description": "Student assessment is one of the most fundamental tasks in the field of AI\nEducation (AIEd). One of the most common approach to student assessment is\nKnowledge Tracing (KT), which evaluates a student's knowledge state by\npredicting whether the student will answer a given question correctly or not.\nHowever, in the context of multiple choice (polytomous) questions, conventional\nKT approaches are limited in that they only consider the binary (dichotomous)\ncorrectness label (i.e., correct or incorrect), and disregard the specific\noption chosen by the student. Meanwhile, Option Tracing (OT) attempts to model\na student by predicting which option they will choose for a given question, but\noverlooks the correctness information. In this paper, we propose\nDichotomous-Polytomous Multi-Task Learning (DP-MTL), a multi-task learning\nframework that combines KT and OT for more precise student assessment. In\nparticular, we show that the KT objective acts as a regularization term for OT\nin the DP-MTL framework, and propose an appropriate architecture for applying\nour method on top of existing deep learning-based KT models. We experimentally\nconfirm that DP-MTL significantly improves both KT and OT performances, and\nalso benefits downstream tasks such as Score Prediction (SP).",
          "link": "http://arxiv.org/abs/2204.14006",
          "publishedOn": "2022-05-02T00:57:33.883Z",
          "wordCount": null,
          "title": "No Task Left Behind: Multi-Task Learning of Knowledge Tracing and Option Tracing for Better Student Assessment. (arXiv:2204.14006v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13846",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jianhao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siliang Tang</a>",
          "description": "Graph contrastive learning has gained significant progress recently. However,\nexisting works have rarely explored non-aligned node-node contrasting. In this\npaper, we propose a novel graph contrastive learning method named RoSA that\nfocuses on utilizing non-aligned augmented views for node-level representation\nlearning. First, we leverage the earth mover's distance to model the minimum\neffort to transform the distribution of one view to the other as our\ncontrastive objective, which does not require alignment between views. Then we\nintroduce adversarial training as an auxiliary method to increase sampling\ndiversity and enhance the robustness of our model. Experimental results show\nthat RoSA outperforms a series of graph contrastive learning frameworks on\nhomophilous, non-homophilous and dynamic graphs, which validates the\neffectiveness of our work. To the best of our awareness, RoSA is the first work\nfocuses on the non-aligned node-node graph contrastive learning problem. Our\ncodes are available at:\n\\href{https://github.com/ZhuYun97/RoSA}{\\texttt{https://github.com/ZhuYun97/RoSA}}",
          "link": "http://arxiv.org/abs/2204.13846",
          "publishedOn": "2022-05-02T00:57:33.873Z",
          "wordCount": null,
          "title": "RoSA: A Robust Self-Aligned Framework for Node-Node Graph Contrastive Learning. (arXiv:2204.13846v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1\">Sihui Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahloujifar_S/0/1/0/all/0/1\">Saeed Mahloujifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>",
          "description": "Existing defenses against adversarial examples such as adversarial training\ntypically assume that the adversary will conform to a specific or known threat\nmodel, such as $\\ell_p$ perturbations within a fixed budget. In this paper, we\nfocus on the scenario where there is a mismatch in the threat model assumed by\nthe defense during training, and the actual capabilities of the adversary at\ntest time. We ask the question: if the learner trains against a specific\n\"source\" threat model, when can we expect robustness to generalize to a\nstronger unknown \"target\" threat model during test-time? Our key contribution\nis to formally define the problem of learning and generalization with an\nunforeseen adversary, which helps us reason about the increase in adversarial\nrisk from the conventional perspective of a known adversary. Applying our\nframework, we derive a generalization bound which relates the generalization\ngap between source and target threat models to variation of the feature\nextractor, which measures the expected maximum difference between extracted\nfeatures across a given threat model. Based on our generalization bound, we\npropose adversarial training with variation regularization (AT-VR) which\nreduces variation of the feature extractor across the source threat model\nduring training. We empirically demonstrate that AT-VR can lead to improved\ngeneralization to unforeseen attacks during test-time compared to standard\nadversarial training on Gaussian and image datasets.",
          "link": "http://arxiv.org/abs/2204.13779",
          "publishedOn": "2022-05-02T00:57:33.872Z",
          "wordCount": null,
          "title": "Formulating Robustness Against Unforeseen Attacks. (arXiv:2204.13779v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mosteiro_P/0/1/0/all/0/1\">Pablo Mosteiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijcken_E/0/1/0/all/0/1\">Emil Rijcken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zervanou_K/0/1/0/all/0/1\">Kalliopi Zervanou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaymak_U/0/1/0/all/0/1\">Uzay Kaymak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheepers_F/0/1/0/all/0/1\">Floortje Scheepers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spruit_M/0/1/0/all/0/1\">Marco Spruit</a>",
          "description": "Violence risk assessment in psychiatric institutions enables interventions to\navoid violence incidents. Clinical notes written by practitioners and available\nin electronic health records (EHR) are valuable resources that are seldom used\nto their full potential. Previous studies have attempted to assess violence\nrisk in psychiatric patients using such notes, with acceptable performance.\nHowever, they do not explain why classification works and how it can be\nimproved. We explore two methods to better understand the quality of a\nclassifier in the context of clinical note analysis: random forests using topic\nmodels, and choice of evaluation metric. These methods allow us to understand\nboth our data and our methodology more profoundly, setting up the groundwork to\nwork on improved models that build upon this understanding. This is\nparticularly important when it comes to the generalizability of evaluated\nclassifiers to new data, a trustworthiness problem that is of great interest\ndue to the increased availability of new data in electronic format.",
          "link": "http://arxiv.org/abs/2204.13976",
          "publishedOn": "2022-05-02T00:57:33.872Z",
          "wordCount": null,
          "title": "Making sense of violence risk predictions using clinical notes. (arXiv:2204.13976v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_K/0/1/0/all/0/1\">KiYoon Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwak_N/0/1/0/all/0/1\">Nojun Kwak</a>",
          "description": "Recent advances in federated learning have demonstrated its promising\ncapability to learn on decentralized datasets. However, a considerable amount\nof work has raised concerns due to the potential risks of adversaries\nparticipating in the framework to poison the global model for an adversarial\npurpose. This paper investigates the feasibility of model poisoning for\nbackdoor attacks through \\textit{rare word embeddings of NLP models} in text\nclassification and sequence-to-sequence tasks. In text classification, less\nthan 1\\% of adversary clients suffices to manipulate the model output without\nany drop in the performance of clean sentences. For a less complex dataset, a\nmere 0.1\\% of adversary clients is enough to poison the global model\neffectively. We also propose a technique specialized in the federated learning\nscheme called gradient ensemble, which enhances the backdoor performance in all\nexperimental settings.",
          "link": "http://arxiv.org/abs/2204.14017",
          "publishedOn": "2022-05-02T00:57:33.871Z",
          "wordCount": null,
          "title": "Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling. (arXiv:2204.14017v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14174",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Heaton_H/0/1/0/all/0/1\">Howard Heaton</a>, <a href=\"http://arxiv.org/find/math/1/au:+Fung_S/0/1/0/all/0/1\">Samy Wu Fung</a>",
          "description": "Indecipherable black boxes are common in machine learning (ML), but\napplications increasingly require explainable artificial intelligence (XAI).\nThe core of XAI is to establish transparent and interpretable data-driven\nalgorithms. This work provides concrete tools for XAI in situations where prior\nknowledge must be encoded and untrustworthy inferences flagged. We use the\n\"learn to optimize\" (L2O) methodology wherein each inference solves a\ndata-driven optimization problem. Our L2O models are straightforward to\nimplement, directly encode prior knowledge, and yield theoretical guarantees\n(e.g. satisfaction of constraints). We also propose use of interpretable\ncertificates to verify whether model inferences are trustworthy. Numerical\nexamples are provided in the applications of dictionary-based signal recovery,\nCT imaging, and arbitrage trading of cryptoassets.",
          "link": "http://arxiv.org/abs/2204.14174",
          "publishedOn": "2022-05-02T00:57:33.871Z",
          "wordCount": null,
          "title": "Explainable AI via Learning to Optimize. (arXiv:2204.14174v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14079",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongyeun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae Young Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Doyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaehyun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junmo Kim</a>",
          "description": "Transfer learning of StyleGAN has recently shown great potential to solve\ndiverse tasks, especially in domain translation. Previous methods utilized a\nsource model by swapping or freezing weights during transfer learning, however,\nthey have limitations on visual quality and controlling source features. In\nother words, they require additional models that are computationally demanding\nand have restricted control steps that prevent a smooth transition. In this\npaper, we propose a new approach to overcome these limitations. Instead of\nswapping or freezing, we introduce a simple feature matching loss to improve\ngeneration quality. In addition, to control the degree of source features, we\ntrain a target model with the proposed strategy, FixNoise, to preserve the\nsource features only in a disentangled subspace of a target feature space.\nOwing to the disentangled feature space, our method can smoothly control the\ndegree of the source features in a single model. Extensive experiments\ndemonstrate that the proposed method can generate more consistent and realistic\nimages than previous works.",
          "link": "http://arxiv.org/abs/2204.14079",
          "publishedOn": "2022-05-02T00:57:33.870Z",
          "wordCount": null,
          "title": "Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN. (arXiv:2204.14079v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathews_S/0/1/0/all/0/1\">Sherin Mary Mathews</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assefa_S/0/1/0/all/0/1\">Samuel A. Assefa</a>",
          "description": "Federated learning holds great promise in learning from fragmented sensitive\ndata and has revolutionized how machine learning models are trained. This\narticle provides a systematic overview and detailed taxonomy of federated\nlearning. We investigate the existing security challenges in federated learning\nand provide a comprehensive overview of established defense techniques for data\npoisoning, inference attacks, and model poisoning attacks. The work also\npresents an overview of current training challenges for federated learning,\nfocusing on handling non-i.i.d. data, high dimensionality issues, and\nheterogeneous architecture, and discusses several solutions for the associated\nchallenges. Finally, we discuss the remaining challenges in managing federated\nlearning training and suggest focused research directions to address the open\nquestions. Potential candidate areas for federated learning, including IoT\necosystem, healthcare applications, are discussed with a particular focus on\nbanking and financial domains.",
          "link": "http://arxiv.org/abs/2204.13697",
          "publishedOn": "2022-05-02T00:57:33.867Z",
          "wordCount": null,
          "title": "Federated Learning: Balancing the Thin Line Between Data Intelligence and Privacy. (arXiv:2204.13697v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sicen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yang Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Buzhou Tang</a>",
          "description": "Medical event prediction (MEP) is a fundamental task in the medical domain,\nwhich needs to predict medical events, including medications, diagnosis codes,\nlaboratory tests, procedures, outcomes, and so on, according to historical\nmedical records. The task is challenging as medical data is a type of complex\ntime series data with heterogeneous and temporal irregular characteristics.\nMany machine learning methods that consider the two characteristics have been\nproposed for medical event prediction. However, most of them consider the two\ncharacteristics separately and ignore the correlations among different types of\nmedical events, especially relations between historical medical events and\ntarget medical events. In this paper, we propose a novel neural network based\non attention mechanism, called cross-event attention-based time-aware network\n(CATNet), for medical event prediction. It is a time-aware, event-aware and\ntask-adaptive method with the following advantages: 1) modeling heterogeneous\ninformation and temporal information in a unified way and considering temporal\nirregular characteristics locally and globally respectively, 2) taking full\nadvantage of correlations among different types of events via cross-event\nattention. Experiments on two public datasets (MIMIC-III and eICU) show CATNet\ncan be adaptive with different MEP tasks and outperforms other state-of-the-art\nmethods on various MEP tasks. The source code of CATNet will be released after\nthis manuscript is accepted.",
          "link": "http://arxiv.org/abs/2204.13847",
          "publishedOn": "2022-05-02T00:57:33.864Z",
          "wordCount": null,
          "title": "CATNet: Cross-event Attention-based Time-aware Network for Medical Event Prediction. (arXiv:2204.13847v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_A/0/1/0/all/0/1\">Aiqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Beibei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiawei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yifa Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jian Liu</a>",
          "description": "We propose volume-preserving networks (VPNets) for learning unknown\nsource-free dynamical systems using trajectory data. We propose three modules\nand combine them to obtain two network architectures, coined R-VPNet and\nLA-VPNet. The distinct feature of the proposed models is that they are\nintrinsic volume-preserving. In addition, the corresponding approximation\ntheorems are proved, which theoretically guarantee the expressivity of the\nproposed VPNets to learn source-free dynamics. The effectiveness,\ngeneralization ability and structure-preserving property of the VP-Nets are\ndemonstrated by numerical experiments.",
          "link": "http://arxiv.org/abs/2204.13843",
          "publishedOn": "2022-05-02T00:57:33.863Z",
          "wordCount": null,
          "title": "VPNets: Volume-preserving neural networks for learning source-free dynamics. (arXiv:2204.13843v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arpogaus_M/0/1/0/all/0/1\">Marcel Arpogaus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voss_M/0/1/0/all/0/1\">Marcus Voss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1\">Beate Sick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nigge_Uricher_M/0/1/0/all/0/1\">Mark Nigge-Uricher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durr_O/0/1/0/all/0/1\">Oliver D&#xfc;rr</a>",
          "description": "The transition to a fully renewable energy grid requires better forecasting\nof demand at the low-voltage level to increase efficiency and ensure reliable\ncontrol. However, high fluctuations and increasing electrification cause huge\nforecast variability, not reflected in traditional point estimates.\nProbabilistic load forecasts take future uncertainties into account and thus\nallow more informed decision-making for the planning and operation of\nlow-carbon energy systems. We propose an approach for flexible conditional\ndensity forecasting of short-term load based on Bernstein polynomial\nnormalizing flows, where a neural network controls the parameters of the flow.\nIn an empirical study with 363 smart meter customers, our density predictions\ncompare favorably against Gaussian and Gaussian mixture densities. Also, they\noutperform a non-parametric approach based on the pinball loss for 24h-ahead\nload forecasting for two different neural network architectures.",
          "link": "http://arxiv.org/abs/2204.13939",
          "publishedOn": "2022-05-02T00:57:33.863Z",
          "wordCount": null,
          "title": "Short-Term Density Forecasting of Low-Voltage Load using Bernstein-Polynomial Normalizing Flows. (arXiv:2204.13939v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scheurer_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;my Scheurer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campos_J/0/1/0/all/0/1\">Jon Ander Campos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_J/0/1/0/all/0/1\">Jun Shern Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Angelica Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1\">Ethan Perez</a>",
          "description": "Pretrained language models often do not perform tasks in ways that are in\nline with our preferences, e.g., generating offensive text or factually\nincorrect summaries. Recent work approaches the above issue by learning from a\nsimple form of human evaluation: comparisons between pairs of model-generated\ntask outputs. Comparison feedback conveys limited information about human\npreferences per human evaluation. Here, we propose to learn from natural\nlanguage feedback, which conveys more information per human evaluation. We\nlearn from language feedback on model outputs using a three-step learning\nalgorithm. First, we condition the language model on the initial output and\nfeedback to generate many refinements. Second, we choose the refinement with\nthe highest similarity to the feedback. Third, we finetune a language model to\nmaximize the likelihood of the chosen refinement given the input. In synthetic\nexperiments, we first evaluate whether language models accurately incorporate\nfeedback to produce refinements, finding that only large language models (175B\nparameters) do so. Using only 100 samples of human-written feedback, our\nlearning algorithm finetunes a GPT-3 model to roughly human-level\nsummarization.",
          "link": "http://arxiv.org/abs/2204.14146",
          "publishedOn": "2022-05-02T00:57:33.856Z",
          "wordCount": null,
          "title": "Learning from Natural Language Feedback. (arXiv:2204.14146v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonov_K/0/1/0/all/0/1\">Kirill Antonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raponi_E/0/1/0/all/0/1\">Elena Raponi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doerr_C/0/1/0/all/0/1\">Carola Doerr</a>",
          "description": "Bayesian Optimization (BO) is a surrogate-based global optimization strategy\nthat relies on a Gaussian Process regression (GPR) model to approximate the\nobjective function and an acquisition function to suggest candidate points. It\nis well-known that BO does not scale well for high-dimensional problems because\nthe GPR model requires substantially more data points to achieve sufficient\naccuracy and acquisition optimization becomes computationally expensive in high\ndimensions. Several recent works aim at addressing these issues, e.g., methods\nthat implement online variable selection or conduct the search on a\nlower-dimensional sub-manifold of the original search space. Advancing our\nprevious work of PCA-BO that learns a linear sub-manifold, this paper proposes\na novel kernel PCA-assisted BO (KPCA-BO) algorithm, which embeds a non-linear\nsub-manifold in the search space and performs BO on this sub-manifold.\nIntuitively, constructing the GPR model on a lower-dimensional sub-manifold\nhelps improve the modeling accuracy without requiring much more data from the\nobjective function. Also, our approach defines the acquisition function on the\nlower-dimensional sub-manifold, making the acquisition optimization more\nmanageable.\n\nWe compare the performance of KPCA-BO to the vanilla BO and PCA-BO on the\nmulti-modal problems of the COCO/BBOB benchmark suite. Empirical results show\nthat KPCA-BO outperforms BO in terms of convergence speed on most test\nproblems, and this benefit becomes more significant when the dimensionality\nincreases. For the 60D functions, KPCA-BO surpasses PCA-BO in many test cases.\nMoreover, it efficiently reduces the CPU time required to train the GPR model\nand optimize the acquisition function compared to the vanilla BO.",
          "link": "http://arxiv.org/abs/2204.13753",
          "publishedOn": "2022-05-02T00:57:33.855Z",
          "wordCount": null,
          "title": "High Dimensional Bayesian Optimization with Kernel Principal Component Analysis. (arXiv:2204.13753v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.14299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciprijanovic_A/0/1/0/all/0/1\">Aleksandra &#x106;iprijanovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kafkes_D/0/1/0/all/0/1\">Diana Kafkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snyder_G/0/1/0/all/0/1\">Gregory Snyder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_F/0/1/0/all/0/1\">F. Javier S&#xe1;nchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perdue_G/0/1/0/all/0/1\">Gabriel Nathan Perdue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedro_K/0/1/0/all/0/1\">Kevin Pedro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nord_B/0/1/0/all/0/1\">Brian Nord</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madireddy_S/0/1/0/all/0/1\">Sandeep Madireddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wild_S/0/1/0/all/0/1\">Stefan M. Wild</a>",
          "description": "Data processing and analysis pipelines in cosmological survey experiments\nintroduce data perturbations that can significantly degrade the performance of\ndeep learning-based models. Given the increased adoption of supervised deep\nlearning methods for processing and analysis of cosmological survey data, the\nassessment of data perturbation effects and the development of methods that\nincrease model robustness are increasingly important. In the context of\nmorphological classification of galaxies, we study the effects of perturbations\nin imaging data. In particular, we examine the consequences of using neural\nnetworks when training on baseline data and testing on perturbed data. We\nconsider perturbations associated with two primary sources: 1) increased\nobservational noise as represented by higher levels of Poisson noise and 2)\ndata processing noise incurred by steps such as image compression or telescope\nerrors as represented by one-pixel adversarial attacks. We also test the\nefficacy of domain adaptation techniques in mitigating the perturbation-driven\nerrors. We use classification accuracy, latent space visualizations, and latent\nspace distance to assess model robustness. Without domain adaptation, we find\nthat processing pixel-level errors easily flip the classification into an\nincorrect class and that higher observational noise makes the model trained on\nlow-noise data unable to classify galaxy morphologies. On the other hand, we\nshow that training with domain adaptation improves model robustness and\nmitigates the effects of these perturbations, improving the classification\naccuracy by 23% on data with higher observational noise. Domain adaptation also\nincreases by a factor of ~2.3 the latent space distance between the baseline\nand the incorrectly classified one-pixel perturbed image, making the model more\nrobust to inadvertent perturbations.",
          "link": "http://arxiv.org/abs/2112.14299",
          "publishedOn": "2022-05-02T00:57:33.854Z",
          "wordCount": null,
          "title": "DeepAdversaries: Examining the Robustness of Deep Learning Models for Galaxy Morphology Classification. (arXiv:2112.14299v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13841",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Mehak Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallamoza_B/0/1/0/all/0/1\">Brennan Gallamoza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutrona_N/0/1/0/all/0/1\">Nicolas Cutrona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhakal_P/0/1/0/all/0/1\">Pranjal Dhakal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poulain_R/0/1/0/all/0/1\">Raphael Poulain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beheshti_R/0/1/0/all/0/1\">Rahmatollah Beheshti</a>",
          "description": "An increasing amount of research is being devoted to applying machine\nlearning methods to electronic health record (EHR) data for various clinical\ntasks. This growing area of research has exposed the limitation of\naccessibility of EHR datasets for all, as well as the reproducibility of\ndifferent modeling frameworks. One reason for these limitations is the lack of\nstandardized pre-processing pipelines. MIMIC is a freely available EHR dataset\nin a raw format that has been used in numerous studies. The absence of\nstandardized pre-processing steps serves as a major barrier to the wider\nadoption of the dataset. It also leads to different cohorts being used in\ndownstream tasks, limiting the ability to compare the results among similar\nstudies. Contrasting studies also use various distinct performance metrics,\nwhich can greatly reduce the ability to compare model results. In this work, we\nprovide an end-to-end fully customizable pipeline to extract, clean, and\npre-process data; and to predict and evaluate the fourth version of the MIMIC\ndataset (MIMIC-IV) for ICU and non-ICU-related clinical time-series prediction\ntasks.",
          "link": "http://arxiv.org/abs/2204.13841",
          "publishedOn": "2022-05-02T00:57:33.847Z",
          "wordCount": null,
          "title": "An Extensive Data Processing Pipeline for MIMIC-IV. (arXiv:2204.13841v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bayat_N/0/1/0/all/0/1\">Nasrin Bayat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Setayeshnazar_M/0/1/0/all/0/1\">Mehrdad Setayeshnazar</a>",
          "description": "In the present study, a Particle Swarm Optimization (PSO) based Demand\nResponse (DR) model, using Artificial Neural Network (ANN) to predict load is\nproposed. The electrical load and climatological data of a residential area in\nAustin city in Texas are used as the inputs of the ANN. Then, the outcomes with\nthe day-ahead prices data are used to solve the load shifting and cost\nreduction problem. According to the results, the proposed model has the ability\nto decrease payment costs and peak load.",
          "link": "http://arxiv.org/abs/2204.13990",
          "publishedOn": "2022-05-02T00:57:33.845Z",
          "wordCount": null,
          "title": "Particle Swarm Optimization Based Demand Response Using Artificial Neural Network Based Load Prediction. (arXiv:2204.13990v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.04495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pol_E/0/1/0/all/0/1\">Elise van der Pol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoof_H/0/1/0/all/0/1\">Herke van Hoof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliehoek_F/0/1/0/all/0/1\">Frans A. Oliehoek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "This paper introduces Multi-Agent MDP Homomorphic Networks, a class of\nnetworks that allows distributed execution using only local information, yet is\nable to share experience between global symmetries in the joint state-action\nspace of cooperative multi-agent systems. In cooperative multi-agent systems,\ncomplex symmetries arise between different configurations of the agents and\ntheir local observations. For example, consider a group of agents navigating:\nrotating the state globally results in a permutation of the optimal joint\npolicy. Existing work on symmetries in single agent reinforcement learning can\nonly be generalized to the fully centralized setting, because such approaches\nrely on the global symmetry in the full state-action spaces, and these can\nresult in correspondences across agents. To encode such symmetries while still\nallowing distributed execution we propose a factorization that decomposes\nglobal symmetries into local transformations. Our proposed factorization allows\nfor distributing the computation that enforces global symmetries over local\nagents and local interactions. We introduce a multi-agent equivariant policy\nnetwork based on this factorization. We show empirically on symmetric\nmulti-agent problems that globally symmetric distributable policies improve\ndata efficiency compared to non-equivariant baselines.",
          "link": "http://arxiv.org/abs/2110.04495",
          "publishedOn": "2022-05-02T00:57:33.775Z",
          "wordCount": null,
          "title": "Multi-Agent MDP Homomorphic Networks. (arXiv:2110.04495v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sicking_J/0/1/0/all/0/1\">Joachim Sicking</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akila_M/0/1/0/all/0/1\">Maram Akila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jan David Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huger_F/0/1/0/all/0/1\">Fabian H&#xfc;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlicht_P/0/1/0/all/0/1\">Peter Schlicht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirtz_T/0/1/0/all/0/1\">Tim Wirtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wrobel_S/0/1/0/all/0/1\">Stefan Wrobel</a>",
          "description": "Uncertainty estimation bears the potential to make deep learning (DL) systems\nmore reliable. Standard techniques for uncertainty estimation, however, come\nalong with specific combinations of strengths and weaknesses, e.g., with\nrespect to estimation quality, generalization abilities and computational\ncomplexity. To actually harness the potential of uncertainty quantification,\nestimators are required whose properties closely match the requirements of a\ngiven use case. In this work, we propose a framework that, firstly, structures\nand shapes these requirements, secondly, guides the selection of a suitable\nuncertainty estimation method and, thirdly, provides strategies to validate\nthis choice and to uncover structural weaknesses. By contributing tailored\nuncertainty estimation in this sense, our framework helps to foster trustworthy\nDL systems. Moreover, it anticipates prospective machine learning regulations\nthat require, e.g., in the EU, evidences for the technical appropriateness of\nmachine learning systems. Our framework provides such evidences for system\ncomponents modeling uncertainty.",
          "link": "http://arxiv.org/abs/2204.13963",
          "publishedOn": "2022-05-02T00:57:33.769Z",
          "wordCount": null,
          "title": "Tailored Uncertainty Estimation for Deep Learning Systems. (arXiv:2204.13963v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13704",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wenjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenxue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_F/0/1/0/all/0/1\">Fulan Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanping Zhang</a>",
          "description": "Knowledge graph embeddings (KGE) have been validated as powerful methods for\ninferring missing links in knowledge graphs (KGs) since they map entities into\nEuclidean space and treat relations as transformations of entities. Currently,\nsome Euclidean KGE methods model semantic hierarchies prevalent in KGs and\npromote the performance of link prediction. For hierarchical data, instead of\ntraditional Euclidean space, hyperbolic space as an embedding space has shown\nthe promise of high fidelity and low memory consumption; however, existing\nhyperbolic KGE methods neglect to model them. To address this issue, we propose\na novel KGE model -- hyperbolic hierarchical KGE (HypHKGE). To be specific, we\nfirst design the attention-based learnable curvatures for hyperbolic space to\npreserve rich semantic hierarchies. Moreover, we define the hyperbolic\nhierarchical transformations based on the theory of hyperbolic geometry, which\nutilize hierarchies that we preserved to infer the links. Experiments show that\nHypHKGE can effectively model semantic hierarchies in hyperbolic space and\noutperforms the state-of-the-art hyperbolic methods, especially in low\ndimensions.",
          "link": "http://arxiv.org/abs/2204.13704",
          "publishedOn": "2022-05-02T00:57:33.757Z",
          "wordCount": null,
          "title": "Hyperbolic Hierarchical Knowledge Graph Embeddings for Link Prediction in Low Dimensions. (arXiv:2204.13704v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tabbaa_H/0/1/0/all/0/1\">Hiba Tabbaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ifzarne_S/0/1/0/all/0/1\">Samir Ifzarne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hafidi_I/0/1/0/all/0/1\">Imad Hafidi</a>",
          "description": "In today's modern world, the usage of technology is unavoidable and the rapid\nadvances in the Internet and communication fields have resulted to expand the\nWireless Sensor Network (WSN) technology. A huge number of sensing devices\ncollect and/or generate numerous sensory data throughout time for a wide range\nof fields and applications. However, WSN has been proven to be vulnerable to\nsecurity breaches, the harsh and unattended deployment of these networks,\ncombined with their constrained resources and the volume of data generated\nintroduce a major security concern. WSN applications are extremely critical, it\nis essential to build reliable solutions that involve fast and continuous\nmechanisms for online data stream analysis enabling the detection of attacks\nand intrusions. In this context, our aim is to develop an intelligent,\nefficient, and updatable intrusion detection system by applying an important\nmachine learning concept known as ensemble learning in order to improve\ndetection performance. Although ensemble models have been proven to be useful\nin offline learning, they have received less attention in streaming\napplications. In this paper, we examine the application of different\nhomogeneous and heterogeneous online ensembles in sensory data analysis, on a\nspecialized wireless sensor network-detection system (WSN-DS) dataset in order\nto classify four types of attacks: Blackhole attack, Grayhole, Flooding, and\nScheduling among normal network traffic. Among the proposed novel online\nensembles, both the heterogeneous ensemble consisting of an Adaptive Random\nForest (ARF) combined with the Hoeffding Adaptive Tree (HAT) algorithm and the\nhomogeneous ensemble HAT made up of 10 models achieved higher detection rates\nof 96.84% and 97.2%, respectively. The above models are efficient and effective\nin dealing with concept drift, while taking into account the resource\nconstraints of WSNs.",
          "link": "http://arxiv.org/abs/2204.13814",
          "publishedOn": "2022-05-02T00:57:33.756Z",
          "wordCount": null,
          "title": "An Online Ensemble Learning Model for Detecting Attacks in Wireless Sensor Networks. (arXiv:2204.13814v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14096",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Shao_K/0/1/0/all/0/1\">Kaidi Shao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Logothetis_N/0/1/0/all/0/1\">Nikos K. Logothetis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1\">Michel Besserve</a>",
          "description": "Transient recurring phenomena are ubiquitous in many scientific fields like\nneuroscience and meteorology. Time inhomogenous Vector Autoregressive Models\n(VAR) may be used to characterize peri-event system dynamics associated with\nsuch phenomena, and can be learned by exploiting multi-dimensional data\ngathering samples of the evolution of the system in multiple time windows\ncomprising, each associated with one occurrence of the transient phenomenon,\nthat we will call \"trial\". However, optimal VAR model order selection methods,\ncommonly relying on the Akaike or Bayesian Information Criteria (AIC/BIC), are\ntypically not designed for multi-trial data. Here we derive the BIC methods for\nmulti-trial ensemble data which are gathered after the detection of the events.\nWe show using simulated bivariate AR models that the multi-trial BIC is able to\nrecover the real model order. We also demonstrate with simulated transient\nevents and real data that the multi-trial BIC is able to estimate a\nsufficiently small model order for dynamic system modeling.",
          "link": "http://arxiv.org/abs/2204.14096",
          "publishedOn": "2022-05-02T00:57:33.756Z",
          "wordCount": null,
          "title": "Bayesian Information Criterion for Event-based Multi-trial Ensemble data. (arXiv:2204.14096v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bardos_A/0/1/0/all/0/1\">Avraam Bardos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mollas_I/0/1/0/all/0/1\">Ioannis Mollas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bassiliades_N/0/1/0/all/0/1\">Nick Bassiliades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1\">Grigorios Tsoumakas</a>",
          "description": "Dimensionality reduction (DR) is a popular method for preparing and analyzing\nhigh-dimensional data. Reduced data representations are less computationally\nintensive and easier to manage and visualize, while retaining a significant\npercentage of their original information. Aside from these advantages, these\nreduced representations can be difficult or impossible to interpret in most\ncircumstances, especially when the DR approach does not provide further\ninformation about which features of the original space led to their\nconstruction. This problem is addressed by Interpretable Machine Learning, a\nsubfield of Explainable Artificial Intelligence that addresses the opacity of\nmachine learning models. However, current research on Interpretable Machine\nLearning has been focused on supervised tasks, leaving unsupervised tasks like\nDimensionality Reduction unexplored. In this paper, we introduce LXDR, a\ntechnique capable of providing local interpretations of the output of DR\ntechniques. Experiment results and two LXDR use case examples are presented to\nevaluate its usefulness.",
          "link": "http://arxiv.org/abs/2204.14012",
          "publishedOn": "2022-05-02T00:57:33.685Z",
          "wordCount": null,
          "title": "Local Explanation of Dimensionality Reduction. (arXiv:2204.14012v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jahani_Nezhad_T/0/1/0/all/0/1\">Tayyebeh Jahani-Nezhad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddah_Ali_M/0/1/0/all/0/1\">Mohammad Ali Maddah-Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Songze Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caire_G/0/1/0/all/0/1\">Giuseppe Caire</a>",
          "description": "We propose SwiftAgg, a novel secure aggregation protocol for federated\nlearning systems, where a central server aggregates local models of $N$\ndistributed users, each of size $L$, trained on their local data, in a\nprivacy-preserving manner. Compared with state-of-the-art secure aggregation\nprotocols, SwiftAgg significantly reduces the communication overheads without\nany compromise on security. Specifically, in presence of at most $D$ dropout\nusers, SwiftAgg achieves a users-to-server communication load of $(T+1)L$ and a\nusers-to-users communication load of up to $(N-1)(T+D+1)L$, with a worst-case\ninformation-theoretic security guarantee, against any subset of up to $T$\nsemi-honest users who may also collude with the curious server. The key idea of\nSwiftAgg is to partition the users into groups of size $D+T+1$, then in the\nfirst phase, secret sharing and aggregation of the individual models are\nperformed within each group, and then in the second phase, model aggregation is\nperformed on $D+T+1$ sequences of users across the groups. If a user in a\nsequence drops out in the second phase, the rest of the sequence remain silent.\nThis design allows only a subset of users to communicate with each other, and\nonly the users in a single group to directly communicate with the server,\neliminating the requirements of 1) all-to-all communication network across\nusers; and 2) all users communicating with the server, for other secure\naggregation protocols. This helps to substantially slash the communication\ncosts of the system.",
          "link": "http://arxiv.org/abs/2202.04169",
          "publishedOn": "2022-05-02T00:57:33.685Z",
          "wordCount": null,
          "title": "SwiftAgg: Communication-Efficient and Dropout-Resistant Secure Aggregation for Federated Learning with Worst-Case Security Guarantees. (arXiv:2202.04169v2 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Niger_T/0/1/0/all/0/1\">Tasnim Niger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rayhan_H/0/1/0/all/0/1\">Hasanur Rayhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_R/0/1/0/all/0/1\">Rashidul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noor_K/0/1/0/all/0/1\">Kazi Asif Abdullah Noor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_K/0/1/0/all/0/1\">Kamrul Hasan</a>",
          "description": "In this modern world, people are becoming more self-centered and unsocial. On\nthe other hand, people are stressed, becoming more anxious during COVID-19\npandemic situation and exhibits symptoms of behavioral disorder. To measure the\nsymptoms of behavioral disorder, usually psychiatrist use long hour sessions\nand inputs from specific questionnaire. This process is time consuming and\nsometime is ineffective to detect the right behavioral disorder. Also, reserved\npeople sometime hesitate to follow this process. We have created a digital\nframework which can detect behavioral disorder and prescribe virtual Cognitive\nBehavioral Therapy (vCBT) for recovery. By using this framework people can\ninput required data that are highly responsible for the three behavioral\ndisorders namely depression, anxiety and internet addiction. We have applied\nmachine learning technique to detect specific behavioral disorder from samples.\nThis system guides the user with basic understanding and treatment through vCBT\nfrom anywhere any time which would potentially be the steppingstone for the\nuser to be conscious and pursue right treatment.",
          "link": "http://arxiv.org/abs/2204.13900",
          "publishedOn": "2022-05-02T00:57:33.608Z",
          "wordCount": null,
          "title": "Framework for Behavioral Disorder Detection Using Machine Learning and Application of Virtual Cognitive Behavioral Therapy in COVID-19 Pandemic. (arXiv:2204.13900v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cirstea_R/0/1/0/all/0/1\">Razvan-Gabriel Cirstea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chenjuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kieu_T/0/1/0/all/0/1\">Tung Kieu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xuanyi Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shirui Pan</a>",
          "description": "A variety of real-world applications rely on far future information to make\ndecisions, thus calling for efficient and accurate long sequence multivariate\ntime series forecasting. While recent attention-based forecasting models show\nstrong abilities in capturing long-term dependencies, they still suffer from\ntwo key limitations. First, canonical self attention has a quadratic complexity\nw.r.t. the input time series length, thus falling short in efficiency. Second,\ndifferent variables' time series often have distinct temporal dynamics, which\nexisting studies fail to capture, as they use the same model parameter space,\ne.g., projection matrices, for all variables' time series, thus falling short\nin accuracy. To ensure high efficiency and accuracy, we propose Triformer, a\ntriangular, variable-specific attention. (i) Linear complexity: we introduce a\nnovel patch attention with linear complexity. When stacking multiple layers of\nthe patch attentions, a triangular structure is proposed such that the layer\nsizes shrink exponentially, thus maintaining linear complexity. (ii)\nVariable-specific parameters: we propose a light-weight method to enable\ndistinct sets of model parameters for different variables' time series to\nenhance accuracy without compromising efficiency and memory usage. Strong\nempirical evidence on four datasets from multiple domains justifies our design\nchoices, and it demonstrates that Triformer outperforms state-of-the-art\nmethods w.r.t. both accuracy and efficiency. This is an extended version of\n\"Triformer: Triangular, Variable-Specific Attentions for Long Sequence\nMultivariate Time Series Forecasting\", to appear in IJCAI 2022 [Cirstea et al.,\n2022a], including additional experimental results.",
          "link": "http://arxiv.org/abs/2204.13767",
          "publishedOn": "2022-05-02T00:57:33.605Z",
          "wordCount": null,
          "title": "Triformer: Triangular, Variable-Specific Attentions for Long Sequence Multivariate Time Series Forecasting--Full Version. (arXiv:2204.13767v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.14621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guanting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaocheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yinyu Ye</a>",
          "description": "In this paper, we consider an online resource allocation problem where a\ndecision maker accepts or rejects incoming customer requests irrevocably in\norder to maximize expected reward given limited resources. At each time, a new\norder/customer/bid is revealed with a request of some resource(s) and a reward.\nWe consider a stochastic setting where all the orders are i.i.d. sampled from\nan unknown distribution. Such formulation arises from many classic applications\nsuch as the canonical (quantity-based) network revenue management problem and\nthe Adwords problem. While the literature on the topic mainly focuses on regret\nminimization, our paper considers the \\textit{fairness} aspect of the problem.\nOn a high level, we define the fairness in a way that a fair online algorithm\nshould treat similar agents/customers similarly, and the decision made for\nsimilar agents/customers should be consistent over time. To achieve this goal,\nwe define the fair offline solution as the analytic center of the offline\noptimal solution set, and introduce \\textit{cumulative unfairness} as the\ncumulative deviation from the online solutions to the fair offline solution\nover time. We propose a fair algorithm based on an interior-point LP solver and\na mechanism that dynamically detects unfair resource spending. Our algorithm\nachieves cumulative unfairness on the scale of order $O(\\log(T))$, while\nmaintains the regret to be bounded without dependency on $T$. In addition,\ncompared to the literature, our result is produced under less restrictive\nassumptions on the degeneracy of the underlying linear program.",
          "link": "http://arxiv.org/abs/2110.14621",
          "publishedOn": "2022-05-02T00:57:33.604Z",
          "wordCount": null,
          "title": "Fairer LP-based Online Allocation via Analytic Center. (arXiv:2110.14621v3 [cs.DS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1\">Sourav Chatterjee</a>",
          "description": "Optimization by gradient descent has been one of main drivers of the \"deep\nlearning revolution\". Yet, despite some recent progress for extremely wide\nnetworks, it remains an open problem to understand why gradient descent often\nconverges to global minima when training deep neural networks. This article\npresents a new criterion for convergence of gradient descent to a global\nminimum, which is provably more powerful than the best available criteria from\nthe literature, namely, the Lojasiewicz inequality and its generalizations.\nThis criterion is used to show that gradient descent with proper initialization\nconverges to a global minimum when training any feedforward neural network with\nsmooth and strictly increasing activation functions, provided that the input\ndimension is greater than or equal to the number of data points.",
          "link": "http://arxiv.org/abs/2203.16462",
          "publishedOn": "2022-05-02T00:57:33.597Z",
          "wordCount": null,
          "title": "Convergence of gradient descent for deep neural networks. (arXiv:2203.16462v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sanghyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byun_J/0/1/0/all/0/1\">Jungyun Byun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Kwansik Park</a>",
          "description": "In urban areas, global navigation satellite system (GNSS) signals are often\nreflected or blocked by buildings, thus resulting in large positioning errors.\nIn this study, we proposed a machine learning approach for global positioning\nsystem (GPS) multipath detection that uses dual antennas. A machine learning\nmodel that could classify GPS signal reception conditions was trained with\nseveral GPS measurements selected as suggested features. We applied five\nfeatures for machine learning, including a feature obtained from the dual\nantennas, and evaluated the classification performance of the model, after\napplying four machine learning algorithms: gradient boosting decision tree\n(GBDT), random forest, decision tree, and K-nearest neighbor (KNN). It was\nfound that a classification accuracy of 82%-96% was achieved when the test data\nset was collected at the same locations as those of the training data set.\nHowever, when the test data set was collected at locations different from those\nof the training data, a classification accuracy of 44%-77% was obtained.",
          "link": "http://arxiv.org/abs/2204.14001",
          "publishedOn": "2022-05-02T00:57:33.551Z",
          "wordCount": null,
          "title": "Machine Learning-Based GPS Multipath Detection Method Using Dual Antennas. (arXiv:2204.14001v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">John Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_L/0/1/0/all/0/1\">Le An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixit_A/0/1/0/all/0/1\">Anurag Dixit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koo_J/0/1/0/all/0/1\">Jinkyu Koo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Su Inn Park</a>",
          "description": "Transformer and its variants have shown state-of-the-art results in many\nvision tasks recently, ranging from image classification to dense prediction.\nDespite of their success, limited work has been reported on improving the model\nefficiency for deployment in latency-critical applications, such as autonomous\ndriving and robotic navigation. In this paper, we aim at improving upon the\nexisting transformers in vision, and propose a method for self-supervised\nmonocular Depth Estimation with Simplified Transformer (DEST), which is\nefficient and particularly suitable for deployment on GPU-based platforms.\nThrough strategic design choices, our model leads to significant reduction in\nmodel size, complexity, as well as inference latency, while achieving superior\naccuracy as compared to state-of-the-art. We also show that our design\ngeneralize well to other dense prediction task without bells and whistles.",
          "link": "http://arxiv.org/abs/2204.13791",
          "publishedOn": "2022-05-02T00:57:33.548Z",
          "wordCount": null,
          "title": "Depth Estimation with Simplified Transformer. (arXiv:2204.13791v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.02278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shevchenko_A/0/1/0/all/0/1\">Alexander Shevchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kungurtsev_V/0/1/0/all/0/1\">Vyacheslav Kungurtsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mondelli_M/0/1/0/all/0/1\">Marco Mondelli</a>",
          "description": "Understanding the properties of neural networks trained via stochastic\ngradient descent (SGD) is at the heart of the theory of deep learning. In this\nwork, we take a mean-field view, and consider a two-layer ReLU network trained\nvia SGD for a univariate regularized regression problem. Our main result is\nthat SGD is biased towards a simple solution: at convergence, the ReLU network\nimplements a piecewise linear map of the inputs, and the number of \"knot\"\npoints - i.e., points where the tangent of the ReLU network estimator changes -\nbetween two consecutive training inputs is at most three. In particular, as the\nnumber of neurons of the network grows, the SGD dynamics is captured by the\nsolution of a gradient flow and, at convergence, the distribution of the\nweights approaches the unique minimizer of a related free energy, which has a\nGibbs form. Our key technical contribution consists in the analysis of the\nestimator resulting from this minimizer: we show that its second derivative\nvanishes everywhere, except at some specific locations which represent the\n\"knot\" points. We also provide empirical evidence that knots at locations\ndistinct from the data points might occur, as predicted by our theory.",
          "link": "http://arxiv.org/abs/2111.02278",
          "publishedOn": "2022-05-02T00:57:33.536Z",
          "wordCount": null,
          "title": "Mean-field Analysis of Piecewise Linear Solutions for Wide ReLU Networks. (arXiv:2111.02278v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.10528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akan_A/0/1/0/all/0/1\">Adil Kaan Akan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safadoust_S/0/1/0/all/0/1\">Sadra Safadoust</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guney_F/0/1/0/all/0/1\">Fatma G&#xfc;ney</a>",
          "description": "While stochastic video prediction models enable future prediction under\nuncertainty, they mostly fail to model the complex dynamics of real-world\nscenes. For example, they cannot provide reliable predictions for scenes with a\nmoving camera and independently moving foreground objects in driving scenarios.\nThe existing methods fail to fully capture the dynamics of the structured world\nby only focusing on changes in pixels. In this paper, we assume that there is\nan underlying process creating observations in a video and propose to factorize\nit into static and dynamic components. We model the static part based on the\nscene structure and the ego-motion of the vehicle, and the dynamic part based\non the remaining motion of the dynamic objects. By learning separate\ndistributions of changes in foreground and background, we can decompose the\nscene into static and dynamic parts and separately model the change in each.\nOur experiments demonstrate that disentangling structure and motion helps\nstochastic video prediction, leading to better future predictions in complex\ndriving scenarios on two real-world driving datasets, KITTI and Cityscapes.",
          "link": "http://arxiv.org/abs/2203.10528",
          "publishedOn": "2022-05-02T00:57:33.518Z",
          "wordCount": null,
          "title": "Stochastic Video Prediction with Structure and Motion. (arXiv:2203.10528v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13551",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Romero_M/0/1/0/all/0/1\">Miguel Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramirez_O/0/1/0/all/0/1\">Oscar Ram&#xed;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finke_J/0/1/0/all/0/1\">Jorge Finke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocha_C/0/1/0/all/0/1\">Camilo Rocha</a>",
          "description": "Gene annotation addresses the problem of predicting unknown associations\nbetween gene and functions (e.g., biological processes) of a specific organism.\nDespite recent advances, the cost and time demanded by annotation procedures\nthat rely largely on in vivo biological experiments remain prohibitively high.\nThis paper presents a novel in silico approach for to the annotation problem\nthat combines cluster analysis and hierarchical multi-label classification\n(HMC). The approach uses spectral clustering to extract new features from the\ngene co-expression network (GCN) and enrich the prediction task. HMC is used to\nbuild multiple estimators that consider the hierarchical structure of gene\nfunctions. The proposed approach is applied to a case study on Zea mays, one of\nthe most dominant and productive crops in the world. The results illustrate how\nin silico approaches are key to reduce the time and costs of gene annotation.\nMore specifically, they highlight the importance of: (i) building new features\nthat represent the structure of gene relationships in GCNs to annotate genes;\nand (ii) taking into account the structure of biological processes to obtain\nconsistent predictions.",
          "link": "http://arxiv.org/abs/2203.13551",
          "publishedOn": "2022-05-02T00:57:33.506Z",
          "wordCount": null,
          "title": "Feature extraction using Spectral Clustering for Gene Function Prediction using Hierarchical Multi-label Classification. (arXiv:2203.13551v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gutmann_M/0/1/0/all/0/1\">Michael U. Gutmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinegesse_S/0/1/0/all/0/1\">Steven Kleinegesse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhodes_B/0/1/0/all/0/1\">Benjamin Rhodes</a>",
          "description": "The likelihood function plays a crucial role in statistical inference and\nexperimental design. However, it is computationally intractable for several\nimportant classes of statistical models, including energy-based models and\nsimulator-based models. Contrastive learning is an intuitive and\ncomputationally feasible alternative to likelihood-based learning. We here\nfirst provide an introduction to contrastive learning and then show how we can\nuse it to derive methods for diverse statistical problems, namely parameter\nestimation for energy-based models, Bayesian inference for simulator-based\nmodels, as well as experimental design.",
          "link": "http://arxiv.org/abs/2204.13999",
          "publishedOn": "2022-05-02T00:57:33.442Z",
          "wordCount": null,
          "title": "Statistical applications of contrastive learning. (arXiv:2204.13999v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Doboli_A/0/1/0/all/0/1\">Alex Doboli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doboli_S/0/1/0/all/0/1\">Simona Doboli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duke_R/0/1/0/all/0/1\">Ryan Duke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Sangjin Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1\">Wendy Tang</a>",
          "description": "Student diversity, like academic background, learning styles, career and life\ngoals, ethnicity, age, social and emotional characteristics, course load and\nwork schedule, offers unique opportunities in education, like learning new\nskills, peer mentoring and example setting. But student diversity can be\nchallenging too as it adds variability in the way in which students learn and\nprogress over time. A single teaching approach is likely to be ineffective and\nresult in students not meeting their potential. Automated support could address\nlimitations of traditional teaching by continuously assessing student learning\nand implementing needed interventions. This paper discusses a novel methodology\nbased on data analytics and Machine Learning to measure and causally diagnose\nthe progress and shortcomings of student learning, and then utilizes the\ninsight gained on individuals to optimize learning. Diagnosis pertains to\ndynamic diagnostic formative assessment, which aims to uncover the causes of\nlearning shortcomings. The methodology groups learning difficulties into four\ncategories: recall from memory, concept adjustment, concept modification, and\nproblem decomposition into sub-goals (sub-problems) and concept combination.\nData models are predicting the occurrence of each of the four challenge types,\nas well as a student's learning trajectory. The models can be used to\nautomatically create real-time, student-specific interventions (e.g., learning\ncues) to address less understood concepts. We envision that the system will\nenable new adaptive pedagogical approaches to unleash student learning\npotential through customization of the course material to the background,\nabilities, situation, and progress of each student; and leveraging\ndiversity-related learning experiences.",
          "link": "http://arxiv.org/abs/2204.13989",
          "publishedOn": "2022-05-02T00:57:33.441Z",
          "wordCount": null,
          "title": "Dynamic Diagnosis of the Progress and Shortcomings of Student Learning using Machine Learning based on Cognitive, Social, and Emotional Features. (arXiv:2204.13989v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rakotoson_L/0/1/0/all/0/1\">Lo&#xef;c Rakotoson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Letaillieur_C/0/1/0/all/0/1\">Charles Letaillieur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massip_S/0/1/0/all/0/1\">Sylvain Massip</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laleye_F/0/1/0/all/0/1\">Fr&#xe9;jus Laleye</a>",
          "description": "With the explosive growth of scientific publications, making the synthesis of\nscientific knowledge and fact checking becomes an increasingly complex task. In\nthis paper, we propose a multi-task approach for verifying the scientific\nquestions based on a joint reasoning from facts and evidence in research\narticles. We propose an intelligent combination of (1) an automatic information\nsummarization and (2) a Boolean Question Answering which allows to generate an\nanswer to a scientific question from only extracts obtained after\nsummarization. Thus on a given topic, our proposed approach conducts structured\ncontent modeling based on paper abstracts to answer a scientific question while\nhighlighting texts from paper that discuss the topic. We based our final system\non an end-to-end Extractive Question Answering (EQA) combined with a three\noutputs classification model to perform in-depth semantic understanding of a\nquestion to illustrate the aggregation of multiple responses. With our light\nand fast proposed architecture, we achieved an average error rate of 4% and a\nF1-score of 95.6%. Our results are supported via experiments with two QA models\n(BERT, RoBERTa) over 3 Million Open Access (OA) articles in the medical and\nhealth domains on Europe PMC.",
          "link": "http://arxiv.org/abs/2204.12263",
          "publishedOn": "2022-05-02T00:57:33.434Z",
          "wordCount": null,
          "title": "Science Checker: Extractive-Boolean Question Answering For Scientific Fact Checking. (arXiv:2204.12263v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07537",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_C/0/1/0/all/0/1\">Chien-yu Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Any-to-any voice conversion technologies convert the vocal timbre of an\nutterance to any speaker even unseen during training. Although there have been\nseveral state-of-the-art any-to-any voice conversion models, they were all\nbased on clean utterances to convert successfully. However, in real-world\nscenarios, it is difficult to collect clean utterances of a speaker, and they\nare usually degraded by noises or reverberations. It thus becomes highly\ndesired to understand how these degradations affect voice conversion and build\na degradation-robust model. We report in this paper the first comprehensive\nstudy on the degradation robustness of any-to-any voice conversion. We show\nthat the performance of state-of-the-art models nowadays was severely hampered\ngiven degraded utterances. To this end, we then propose speech enhancement\nconcatenation and denoising training to improve the robustness. In addition to\ncommon degradations, we also consider adversarial noises, which alter the model\noutput significantly yet are human-imperceptible. It was shown that both\nconcatenations with off-the-shelf speech enhancement models and denoising\ntraining on voice conversion models could improve the robustness, while each of\nthem had pros and cons.",
          "link": "http://arxiv.org/abs/2110.07537",
          "publishedOn": "2022-05-02T00:57:33.362Z",
          "wordCount": 655,
          "title": "Toward Degradation-Robust Voice Conversion. (arXiv:2110.07537v3 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13858",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_S/0/1/0/all/0/1\">Shuxiao Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jiang_S/0/1/0/all/0/1\">Sizun Jiang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ma_Z/0/1/0/all/0/1\">Zongming Ma</a>, <a href=\"http://arxiv.org/find/math/1/au:+Nolan_G/0/1/0/all/0/1\">Garry P. Nolan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_B/0/1/0/all/0/1\">Bokai Zhu</a>",
          "description": "We study one-way matching of a pair of datasets with low rank signals. Under\na stylized model, we first derive information-theoretic limits of matching. We\nthen show that linear assignment with projected data achieves fast rates of\nconvergence and sometimes even minimax rate optimality for this task. The\ntheoretical error bounds are corroborated by simulated examples. Furthermore,\nwe illustrate practical use of the matching procedure on two single-cell data\nexamples.",
          "link": "http://arxiv.org/abs/2204.13858",
          "publishedOn": "2022-05-02T00:57:33.349Z",
          "wordCount": null,
          "title": "One-Way Matching of Datasets with Low Rank Signals. (arXiv:2204.13858v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.04840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madsen_A/0/1/0/all/0/1\">Andreas Madsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>",
          "description": "Neural networks for NLP are becoming increasingly complex and widespread, and\nthere is a growing concern if these models are responsible to use. Explaining\nmodels helps to address the safety and ethical concerns and is essential for\naccountability. Interpretability serves to provide these explanations in terms\nthat are understandable to humans. Additionally, post-hoc methods provide\nexplanations after a model is learned and are generally model-agnostic. This\nsurvey provides a categorization of how recent post-hoc interpretability\nmethods communicate explanations to humans, it discusses each method in-depth,\nand how they are validated, as the latter is often a common concern.",
          "link": "http://arxiv.org/abs/2108.04840",
          "publishedOn": "2022-05-02T00:57:33.348Z",
          "wordCount": null,
          "title": "Post-hoc Interpretability for Neural NLP: A Survey. (arXiv:2108.04840v4 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1\">Chi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiyue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lydia Y. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Decouchant_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;mie Decouchant</a>",
          "description": "Federated learning is a private-by-design distributed learning paradigm where\nclients train local models on their own data before a central server aggregates\ntheir local updates to compute a global model. Depending on the aggregation\nmethod used, the local updates are either the gradients or the weights of local\nlearning models. Recent reconstruction attacks apply a gradient inversion\noptimization on the gradient update of a single minibatch to reconstruct the\nprivate data used by clients during training. As the state-of-the-art\nreconstruction attacks solely focus on single update, realistic adversarial\nscenarios are overlooked, such as observation across multiple updates and\nupdates trained from multiple mini-batches. A few studies consider a more\nchallenging adversarial scenario where only model updates based on multiple\nmini-batches are observable, and resort to computationally expensive simulation\nto untangle the underlying samples for each local step. In this paper, we\npropose AGIC, a novel Approximate Gradient Inversion Attack that efficiently\nand effectively reconstructs images from both model or gradient updates, and\nacross multiple epochs. In a nutshell, AGIC (i) approximates gradient updates\nof used training samples from model updates to avoid costly simulation\nprocedures, (ii) leverages gradient/model updates collected from multiple\nepochs, and (iii) assigns increasing weights to layers with respect to the\nneural network structure for reconstruction quality. We extensively evaluate\nAGIC on three datasets, CIFAR-10, CIFAR-100 and ImageNet. Our results show that\nAGIC increases the peak signal-to-noise ratio (PSNR) by up to 50% compared to\ntwo representative state-of-the-art gradient inversion attacks. Furthermore,\nAGIC is faster than the state-of-the-art simulation based attack, e.g., it is\n5x faster when attacking FedAvg with 8 local steps in between model updates.",
          "link": "http://arxiv.org/abs/2204.13784",
          "publishedOn": "2022-05-02T00:57:33.344Z",
          "wordCount": null,
          "title": "AGIC: Approximate Gradient Inversion Attack on Federated Learning. (arXiv:2204.13784v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junshen K. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Card_D/0/1/0/all/0/1\">Dallas Card</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>",
          "description": "Off-the-shelf models are widely used by computational social science\nresearchers to measure properties of text, such as sentiment. However, without\naccess to source data it is difficult to account for domain shift, which\nrepresents a threat to validity. Here, we treat domain adaptation as a modular\nprocess that involves separate model producers and model consumers, and show\nhow they can independently cooperate to facilitate more accurate measurements\nof text. We introduce two lightweight techniques for this scenario, and\ndemonstrate that they reliably increase out-of-domain accuracy on four\nmulti-domain text classification datasets when used with linear and contextual\nembedding models. We conclude with recommendations for model producers and\nconsumers, and release models and replication code to accompany this paper.",
          "link": "http://arxiv.org/abs/2204.14213",
          "publishedOn": "2022-05-02T00:57:33.342Z",
          "wordCount": 540,
          "title": "Modular Domain Adaptation. (arXiv:2204.14213v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nakajima_M/0/1/0/all/0/1\">Mitsumasa Nakajima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1\">Katsuma Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_K/0/1/0/all/0/1\">Kenji Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1\">Yasuo Kuniyoshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1\">Toshikazu Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakajima_K/0/1/0/all/0/1\">Kohei Nakajima</a>",
          "description": "The ever-growing demand for further advances in artificial intelligence\nmotivated research on unconventional computation based on analog physical\ndevices. While such computation devices mimic brain-inspired analog information\nprocessing, learning procedures still relies on methods optimized for digital\nprocessing such as backpropagation. Here, we present physical deep learning by\nextending a biologically plausible training algorithm called direct feedback\nalignment. As the proposed method is based on random projection with arbitrary\nnonlinear activation, we can train a physical neural network without knowledge\nabout the physical system. In addition, we can emulate and accelerate the\ncomputation for this training on a simple and scalable physical system. We\ndemonstrate the proof-of-concept using a hierarchically connected\noptoelectronic recurrent neural network called deep reservoir computer. By\nconstructing an FPGA-assisted optoelectronic benchtop, we confirmed the\npotential for accelerated computation with competitive performance on\nbenchmarks. Our results provide practical solutions for the training and\nacceleration of neuromorphic computation.",
          "link": "http://arxiv.org/abs/2204.13991",
          "publishedOn": "2022-05-02T00:57:33.328Z",
          "wordCount": 594,
          "title": "Physical Deep Learning with Biologically Plausible Training Method. (arXiv:2204.13991v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shaw_S/0/1/0/all/0/1\">Sayan Shaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chia_K/0/1/0/all/0/1\">Keaton Chia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleissl_J/0/1/0/all/0/1\">Jan Kleissl</a>",
          "description": "This paper presents an optimized logistic regression machine learning model\nthat predicts the occupancy of an Electric Vehicle (EV) charging station given\nthe occupancy of neighboring stations. The model was optimized for the time of\nday. Trained on data from 57 EV charging stations around the University of\nCalifornia San Diego campus, the model achieved an 88.43% average accuracy and\n92.23% maximum accuracy in predicting occupancy, outperforming a persistence\nmodel benchmark.",
          "link": "http://arxiv.org/abs/2204.13702",
          "publishedOn": "2022-05-02T00:57:33.321Z",
          "wordCount": 518,
          "title": "Neighbor-Based Optimized Logistic Regression Machine Learning Model For Electric Vehicle Occupancy Detection. (arXiv:2204.13702v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.02479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mendes_P/0/1/0/all/0/1\">Pedro Mendes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casimiro_M/0/1/0/all/0/1\">Maria Casimiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romano_P/0/1/0/all/0/1\">Paolo Romano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garlan_D/0/1/0/all/0/1\">David Garlan</a>",
          "description": "In the literature on hyper-parameter tuning, a number of recent solutions\nrely on low-fidelity observations (e.g., training with sub-sampled datasets or\nfor short periods of time) to extrapolate good configurations to use when\nperforming full training. Among these, HyperBand is arguably one of the most\npopular solutions, due to its efficiency and theoretically provable robustness.\nIn this work, we introduce HyperJump, a new approach that builds on HyperBand's\nrobust search strategy and complements it with novel model-based risk analysis\ntechniques that accelerate the search by \\textit{jumping} the evaluation of low\nrisk configurations, i.e., configurations that are likely to be discarded by\nHyperBand. We evaluate HyperJump on a suite of hyper-parameter optimization\nproblems and show that it provides over one-order of magnitude speed-ups, both\nin sequential and parallel deployments, on a variety of deep learning,\nkernel-based learning, and neural architectural search problems when compared\nto HyperBand and to several state-of-the-art optimizers.",
          "link": "http://arxiv.org/abs/2108.02479",
          "publishedOn": "2022-05-02T00:57:33.295Z",
          "wordCount": 614,
          "title": "HyperJump: Accelerating HyperBand via Risk Modelling. (arXiv:2108.02479v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_L/0/1/0/all/0/1\">Lennart Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfisterer_F/0/1/0/all/0/1\">Florian Pfisterer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_J/0/1/0/all/0/1\">Janek Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>",
          "description": "The goal of Quality Diversity Optimization is to generate a collection of\ndiverse yet high-performing solutions to a given problem at hand. Typical\nbenchmark problems are, for example, finding a repertoire of robot arm\nconfigurations or a collection of game playing strategies. In this paper, we\npropose a set of Quality Diversity Optimization problems that tackle\nhyperparameter optimization of machine learning models - a so far underexplored\napplication of Quality Diversity Optimization. Our benchmark problems involve\nnovel feature functions, such as interpretability or resource usage of models.\nTo allow for fast and efficient benchmarking, we build upon YAHPO Gym, a\nrecently proposed open source benchmarking suite for hyperparameter\noptimization that makes use of high performing surrogate models and returns\nthese surrogate model predictions instead of evaluating the true expensive\nblack box function. We present results of an initial experimental study\ncomparing different Quality Diversity optimizers on our benchmark problems.\nFurthermore, we discuss future directions and challenges of Quality Diversity\nOptimization in the context of hyperparameter optimization.",
          "link": "http://arxiv.org/abs/2204.14061",
          "publishedOn": "2022-05-02T00:57:33.282Z",
          "wordCount": 609,
          "title": "A Collection of Quality Diversity Optimization Problems Derived from Hyperparameter Optimization of Machine Learning Models. (arXiv:2204.14061v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akin_B/0/1/0/all/0/1\">Berkin Akin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Suyog Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1\">Yun Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spiridonov_A/0/1/0/all/0/1\">Anton Spiridonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_M/0/1/0/all/0/1\">Marie White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Ping Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yanqi Zhou</a>",
          "description": "On-device ML accelerators are becoming a standard in modern mobile\nsystem-on-chips (SoC). Neural architecture search (NAS) comes to the rescue for\nefficiently utilizing the high compute throughput offered by these\naccelerators. However, existing NAS frameworks have several practical\nlimitations in scaling to multiple tasks and different target platforms. In\nthis work, we provide a two-pronged approach to this challenge: (i) a\nNAS-enabling infrastructure that decouples model cost evaluation, search space\ndesign, and the NAS algorithm to rapidly target various on-device ML tasks, and\n(ii) search spaces crafted from group convolution based inverted bottleneck\n(IBN) variants that provide flexible quality/performance trade-offs on ML\naccelerators, complementing the existing full and depthwise convolution based\nIBNs. Using this approach we target a state-of-the-art mobile platform, Google\nTensor SoC, and demonstrate neural architectures that improve the\nquality-performance pareto frontier for various computer vision\n(classification, detection, segmentation) as well as natural language\nprocessing tasks.",
          "link": "http://arxiv.org/abs/2204.14007",
          "publishedOn": "2022-05-02T00:57:33.267Z",
          "wordCount": 603,
          "title": "Searching for Efficient Neural Architectures for On-Device ML on Edge TPUs. (arXiv:2204.14007v1 [cs.DC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.00425",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Xu_Y/0/1/0/all/0/1\">Yangyang Xu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xu_Y/0/1/0/all/0/1\">Yibo Xu</a>",
          "description": "Stochastic gradient methods (SGMs) have been extensively used for solving\nstochastic problems or large-scale machine learning problems. Recent works\nemploy various techniques to improve the convergence rate of SGMs for both\nconvex and nonconvex cases. Most of them require a large number of samples in\nsome or all iterations of the improved SGMs. In this paper, we propose a new\nSGM, named PStorm, for solving nonconvex nonsmooth stochastic problems. With a\nmomentum-based variance reduction technique, PStorm can achieve the optimal\ncomplexity result $O(\\varepsilon^{-3})$ to produce a stochastic\n$\\varepsilon$-stationary solution, if a mean-squared smoothness condition\nholds. Different from existing optimal methods, PStorm can achieve the\n${O}(\\varepsilon^{-3})$ result by using only one or $O(1)$ samples in every\nupdate. With this property, PStorm can be applied to online learning problems\nthat favor real-time decisions based on one or $O(1)$ new observations. In\naddition, for large-scale machine learning problems, PStorm can generalize\nbetter by small-batch training than other optimal methods that require\nlarge-batch training and the vanilla SGM, as we demonstrate on training a\nsparse fully-connected neural network and a sparse convolutional neural\nnetwork.",
          "link": "http://arxiv.org/abs/2006.00425",
          "publishedOn": "2022-05-02T00:57:33.259Z",
          "wordCount": 682,
          "title": "Momentum-based variance-reduced proximal stochastic gradient method for composite nonconvex stochastic optimization. (arXiv:2006.00425v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alayrac_J/0/1/0/all/0/1\">Jean-Baptiste Alayrac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donahue_J/0/1/0/all/0/1\">Jeff Donahue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luc_P/0/1/0/all/0/1\">Pauline Luc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miech_A/0/1/0/all/0/1\">Antoine Miech</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barr_I/0/1/0/all/0/1\">Iain Barr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasson_Y/0/1/0/all/0/1\">Yana Hasson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenc_K/0/1/0/all/0/1\">Karel Lenc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mensch_A/0/1/0/all/0/1\">Arthur Mensch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Millican_K/0/1/0/all/0/1\">Katie Millican</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reynolds_M/0/1/0/all/0/1\">Malcolm Reynolds</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ring_R/0/1/0/all/0/1\">Roman Ring</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rutherford_E/0/1/0/all/0/1\">Eliza Rutherford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cabi_S/0/1/0/all/0/1\">Serkan Cabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Tengda Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1\">Zhitao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samangooei_S/0/1/0/all/0/1\">Sina Samangooei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monteiro_M/0/1/0/all/0/1\">Marianne Monteiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menick_J/0/1/0/all/0/1\">Jacob Menick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgeaud_S/0/1/0/all/0/1\">Sebastian Borgeaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brock_A/0/1/0/all/0/1\">Andrew Brock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nematzadeh_A/0/1/0/all/0/1\">Aida Nematzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharifzadeh_S/0/1/0/all/0/1\">Sahand Sharifzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Binkowski_M/0/1/0/all/0/1\">Mikolaj Binkowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barreira_R/0/1/0/all/0/1\">Ricardo Barreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1\">Oriol Vinyals</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1\">Andrew Zisserman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simonyan_K/0/1/0/all/0/1\">Karen Simonyan</a>",
          "description": "Building models that can be rapidly adapted to numerous tasks using only a\nhandful of annotated examples is an open challenge for multimodal machine\nlearning research. We introduce Flamingo, a family of Visual Language Models\n(VLM) with this ability. Flamingo models include key architectural innovations\nto: (i) bridge powerful pretrained vision-only and language-only models, (ii)\nhandle sequences of arbitrarily interleaved visual and textual data, and (iii)\nseamlessly ingest images or videos as inputs. Thanks to their flexibility,\nFlamingo models can be trained on large-scale multimodal web corpora containing\narbitrarily interleaved text and images, which is key to endow them with\nin-context few-shot learning capabilities. We perform a thorough evaluation of\nthe proposed Flamingo models, exploring and measuring their ability to rapidly\nadapt to a variety of image and video understanding benchmarks. These include\nopen-ended tasks such as visual question-answering, where the model is prompted\nwith a question which it has to answer, captioning tasks, which evaluate the\nability to describe a scene or an event, and close-ended tasks such as multiple\nchoice visual question-answering. For tasks lying anywhere on this spectrum, we\ndemonstrate that a single Flamingo model can achieve a new state of the art for\nfew-shot learning, simply by prompting the model with task-specific examples.\nOn many of these benchmarks, Flamingo actually surpasses the performance of\nmodels that are fine-tuned on thousands of times more task-specific data.",
          "link": "http://arxiv.org/abs/2204.14198",
          "publishedOn": "2022-05-02T00:57:33.250Z",
          "wordCount": 712,
          "title": "Flamingo: a Visual Language Model for Few-Shot Learning. (arXiv:2204.14198v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.12707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pichao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Estimating 3D human poses from monocular videos is a challenging task due to\ndepth ambiguity and self-occlusion. Most existing works attempt to solve both\nissues by exploiting spatial and temporal relationships. However, those works\nignore the fact that it is an inverse problem where multiple feasible solutions\n(i.e., hypotheses) exist. To relieve this limitation, we propose a\nMulti-Hypothesis Transformer (MHFormer) that learns spatio-temporal\nrepresentations of multiple plausible pose hypotheses. In order to effectively\nmodel multi-hypothesis dependencies and build strong relationships across\nhypothesis features, the task is decomposed into three stages: (i) Generate\nmultiple initial hypothesis representations; (ii) Model self-hypothesis\ncommunication, merge multiple hypotheses into a single converged representation\nand then partition it into several diverged hypotheses; (iii) Learn\ncross-hypothesis communication and aggregate the multi-hypothesis features to\nsynthesize the final 3D pose. Through the above processes, the final\nrepresentation is enhanced and the synthesized pose is much more accurate.\nExtensive experiments show that MHFormer achieves state-of-the-art results on\ntwo challenging datasets: Human3.6M and MPI-INF-3DHP. Without bells and\nwhistles, its performance surpasses the previous best result by a large margin\nof 3% on Human3.6M. Code and models are available at\n\\url{https://github.com/Vegetebird/MHFormer}.",
          "link": "http://arxiv.org/abs/2111.12707",
          "publishedOn": "2022-05-02T00:57:33.224Z",
          "wordCount": 687,
          "title": "MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation. (arXiv:2111.12707v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14199",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bouget_D/0/1/0/all/0/1\">D. Bouget</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pedersen_A/0/1/0/all/0/1\">A. Pedersen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jakola_A/0/1/0/all/0/1\">A. S. Jakola</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kavouridis_V/0/1/0/all/0/1\">V. Kavouridis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Emblem_K/0/1/0/all/0/1\">K. E. Emblem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Eijgelaar_R/0/1/0/all/0/1\">R. S. Eijgelaar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kommers_I/0/1/0/all/0/1\">I. Kommers</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ardon_H/0/1/0/all/0/1\">H. Ardon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barkhof_F/0/1/0/all/0/1\">F. Barkhof</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bello_L/0/1/0/all/0/1\">L. Bello</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Berger_M/0/1/0/all/0/1\">M. S. Berger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nibali_M/0/1/0/all/0/1\">M. C. Nibali</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Furtner_J/0/1/0/all/0/1\">J. Furtner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hervey_Jumper_S/0/1/0/all/0/1\">S. Hervey-Jumper</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Idema_A/0/1/0/all/0/1\">A. J. S. Idema</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiesel_B/0/1/0/all/0/1\">B. Kiesel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kloet_A/0/1/0/all/0/1\">A. Kloet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mandonnet_E/0/1/0/all/0/1\">E. Mandonnet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Muller_D/0/1/0/all/0/1\">D. M. J. M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Robe_P/0/1/0/all/0/1\">P. A. Robe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rossi_M/0/1/0/all/0/1\">M. Rossi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sciortino_T/0/1/0/all/0/1\">T. Sciortino</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brink_W/0/1/0/all/0/1\">W. Van den Brink</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wagemakers_M/0/1/0/all/0/1\">M. Wagemakers</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Widhalm_G/0/1/0/all/0/1\">G. Widhalm</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Witte_M/0/1/0/all/0/1\">M. G. Witte</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zwinderman_A/0/1/0/all/0/1\">A. H. Zwinderman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hamer_P/0/1/0/all/0/1\">P. C. De Witt Hamer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Solheim_O/0/1/0/all/0/1\">O. Solheim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Reinertsen_I/0/1/0/all/0/1\">I. Reinertsen</a>",
          "description": "For patients suffering from brain tumor, prognosis estimation and treatment\ndecisions are made by a multidisciplinary team based on a set of preoperative\nMR scans. Currently, the lack of standardized and automatic methods for tumor\ndetection and generation of clinical reports represents a major hurdle. In this\nstudy, we investigate glioblastomas, lower grade gliomas, meningiomas, and\nmetastases, through four cohorts of up to 4000 patients. Tumor segmentation\nmodels were trained using the AGU-Net architecture with different preprocessing\nsteps and protocols. Segmentation performances were assessed in-depth using a\nwide-range of voxel and patient-wise metrics covering volume, distance, and\nprobabilistic aspects. Finally, two software solutions have been developed,\nenabling an easy use of the trained models and standardized generation of\nclinical reports: Raidionics and Raidionics-Slicer. Segmentation performances\nwere quite homogeneous across the four different brain tumor types, with an\naverage true positive Dice ranging between 80% and 90%, patient-wise recall\nbetween 88% and 98%, and patient-wise precision around 95%. With our Raidionics\nsoftware, running on a desktop computer with CPU support, tumor segmentation\ncan be performed in 16 to 54 seconds depending on the dimensions of the MRI\nvolume. For the generation of a standardized clinical report, including the\ntumor segmentation and features computation, 5 to 15 minutes are necessary. All\ntrained models have been made open-access together with the source code for\nboth software solutions and validation metrics computation. In the future, an\nautomatic classification of the brain tumor type would be necessary to replace\nmanual user input. Finally, the inclusion of post-operative segmentation in\nboth software solutions will be key for generating complete post-operative\nstandardized clinical reports.",
          "link": "http://arxiv.org/abs/2204.14199",
          "publishedOn": "2022-05-02T00:57:33.216Z",
          "wordCount": 796,
          "title": "Preoperative brain tumor imaging: models and software for segmentation and standardized reporting. (arXiv:2204.14199v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yazdani_Abyaneh_A/0/1/0/all/0/1\">Amir-Hossein Yazdani-Abyaneh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krunz_M/0/1/0/all/0/1\">Marwan Krunz</a>",
          "description": "Convolutional Neural Networks (CNNs) are one of the most studied family of\ndeep learning models for signal classification, including modulation,\ntechnology, detection, and identification. In this work, we focus on technology\nclassification based on raw I/Q samples collected from multiple synchronized\nreceivers. As an example use case, we study protocol identification of Wi-Fi,\nLTE-LAA, and 5G NR-U technologies that coexist over the 5 GHz Unlicensed\nNational Information Infrastructure (U-NII) bands. Designing and training\naccurate CNN classifiers involve significant time and effort that goes into\nfine-tuning a model's architectural settings and determining the appropriate\nhyperparameter configurations, such as learning rate and batch size. We tackle\nthe former by defining architectural settings themselves as hyperparameters. We\nattempt to automatically optimize these architectural parameters, along with\nother preprocessing (e.g., number of I/Q samples within each classifier input)\nand learning hyperparameters, by forming a Hyperparameter Optimization\n(HyperOpt) problem, which we solve in a near-optimal fashion using the\nHyperband algorithm. The resulting near-optimal CNN (OCNN) classifier is then\nused to study classification accuracy for OTA as well as simulations datasets,\nconsidering various SNR values. We show that the number of receivers to\nconstruct multi-channel inputs for CNNs should be defined as a preprocessing\nhyperparameter to be optimized via Hyperband. OTA results reveal that our OCNN\nclassifiers improve classification accuracy by 24.58% compared to manually\ntuned CNNs. We also study the effect of min-max normalization of I/Q samples\nwithin each classifier's input on generalization accuracy over simulated\ndatasets with SNRs other than training set's SNR and show an average of 108.05%\nimprovement when I/Q samples are normalized.",
          "link": "http://arxiv.org/abs/2204.13819",
          "publishedOn": "2022-05-02T00:57:33.208Z",
          "wordCount": 729,
          "title": "Automatic Machine Learning for Multi-Receiver CNN Technology Classifiers. (arXiv:2204.13819v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jonghyuk Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiun-Shyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susuki_K/0/1/0/all/0/1\">Kristen Susuki</a>",
          "description": "Modeling the localized intensive deformation in a damaged solid requires\nhighly refined discretization for accurate prediction, which significantly\nincreases the computational cost. Although adaptive model refinement can be\nemployed for enhanced effectiveness, it is cumbersome for the traditional\nmesh-based methods to perform while modeling the evolving localizations. In\nthis work, neural network-enhanced reproducing kernel particle method (NN-RKPM)\nis proposed, where the location, orientation, and shape of the solution\ntransition near a localization is automatically captured by the NN\napproximation via a block-level neural network optimization. The weights and\nbiases in the blocked parametrization network control the location and\norientation of the localization. The designed basic four-kernel NN block is\ncapable of capturing a triple junction or a quadruple junction topological\npattern, while more complicated localization topological patters are captured\nby the superposition of multiple four-kernel NN blocks. The standard RK\napproximation is then utilized to approximate the smooth part of the solution,\nwhich permits a much coarser discretization than the high-resolution\ndiscretization needed to capture sharp solution transitions with the\nconventional methods. A regularization of the neural network approximation is\nadditionally introduced for discretization-independent material responses. The\neffectiveness of the proposed NN-RKPM is verified by a series of numerical\nverifications.",
          "link": "http://arxiv.org/abs/2204.13821",
          "publishedOn": "2022-05-02T00:57:33.200Z",
          "wordCount": 656,
          "title": "A Neural Network-enhanced Reproducing Kernel Particle Method for Modeling Strain Localization. (arXiv:2204.13821v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14180",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marijan_D/0/1/0/all/0/1\">Dusica Marijan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1\">Sagar Sen</a>",
          "description": "Increasing the impact of software engineering research in the software\nindustry and the society at large has long been a concern of high priority for\nthe software engineering community. The problem of two cultures, research\nconducted in a vacuum (disconnected from the real world), or misaligned time\nhorizons are just some of the many complex challenges standing in the way of\nsuccessful industry-academia collaborations. This paper reports on the\nexperience of research collaboration and knowledge co-creation between industry\nand academia in software engineering as a way to bridge the research-practice\ncollaboration gap. Our experience spans 14 years of collaboration between\nresearchers in software engineering and the European and Norwegian software and\nIT industry. Using the participant observation and interview methods we have\ncollected and afterwards analyzed an extensive record of qualitative data.\nDrawing upon the findings made and the experience gained, we provide a set of\n14 patterns and 14 anti-patterns for industry-academia collaborations, aimed to\nsupport other researchers and practitioners in establishing and running\nresearch collaboration projects in software engineering.",
          "link": "http://arxiv.org/abs/2204.14180",
          "publishedOn": "2022-05-02T00:57:33.181Z",
          "wordCount": 639,
          "title": "Industry-academia research collaboration and knowledge co-creation: Patterns and anti-patterns. (arXiv:2204.14180v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14224",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nurseitov_D/0/1/0/all/0/1\">Daniyar Nurseitov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bostanbekov_K/0/1/0/all/0/1\">Kairat Bostanbekov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdimanap_G/0/1/0/all/0/1\">Galymzhan Abdimanap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdallah_A/0/1/0/all/0/1\">Abdelrahman Abdallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alimova_A/0/1/0/all/0/1\">Anel Alimova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurmangaliyev_D/0/1/0/all/0/1\">Darkhan Kurmangaliyev</a>",
          "description": "During exploration campaigns, oil companies rely heavily on drill core\nsamples as they provide valuable geological information that helps them find\nimportant oil deposits. Traditional core logging techniques are laborious and\nsubjective. Core imaging, a new technique in the oil industry, is used to\nsupplement analysis by rapidly characterising large quantities of drill cores\nin a nondestructive and noninvasive manner. In this paper, we will present the\nproblem of core detection and classification. The first problem is detecting\nthe cores and segmenting the holes in images by using Faster RCNN and Mask RCNN\nmodels respectively. The second problem is filling the hole in the core image\nby applying the Generative adversarial network(GAN) technique and using\nContextual Residual Aggregation(CRA) which creates high frequency residual for\nmissing contents in images. And finally applying Texture recognition models for\nthe classification of core images.",
          "link": "http://arxiv.org/abs/2204.14224",
          "publishedOn": "2022-05-02T00:57:33.171Z",
          "wordCount": 599,
          "title": "Application of machine learning methods to detect and classify Core images using GAN and texture recognition. (arXiv:2204.14224v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schreiber_J/0/1/0/all/0/1\">Jens Schreiber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_S/0/1/0/all/0/1\">Stephan Vogt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1\">Bernhard Sick</a>",
          "description": "Task embeddings in multi-layer perceptrons for multi-task learning and\ninductive transfer learning in renewable power forecasts have recently been\nintroduced. In many cases, this approach improves the forecast error and\nreduces the required training data. However, it does not take the seasonal\ninfluences in power forecasts within a day into account, i.e., the diurnal\ncycle. Therefore, we extended this idea to temporal convolutional networks to\nconsider those seasonalities. We propose transforming the embedding space,\nwhich contains the latent similarities between tasks, through convolution and\nproviding these results to the network's residual block. The proposed\narchitecture significantly improves up to 25 percent for multi-task learning\nfor power forecasts on the EuropeWindFarm and GermanSolarFarm dataset compared\nto the multi-layer perceptron approach. Based on the same data, we achieve a\nten percent improvement for the wind datasets and more than 20 percent in most\ncases for the solar dataset for inductive transfer learning without\ncatastrophic forgetting. Finally, we are the first proposing zero-shot learning\nfor renewable power forecasts to provide predictions even if no training data\nis available.",
          "link": "http://arxiv.org/abs/2204.13908",
          "publishedOn": "2022-05-02T00:57:33.161Z",
          "wordCount": 627,
          "title": "Task Embedding Temporal Convolution Networks for Transfer Learning Problems in Renewable Power Time-Series Forecast. (arXiv:2204.13908v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wendi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_W/0/1/0/all/0/1\">Wenyi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "The development of the transformer-based text-to-image models are impeded by\nits slow generation and complexity for high-resolution images. In this work, we\nput forward a solution based on hierarchical transformers and local parallel\nauto-regressive generation. We pretrain a 6B-parameter transformer with a\nsimple and flexible self-supervised task, Cross-modal general language model\n(CogLM), and finetune it for fast super-resolution. The new text-to-image\nsystem, CogView2, shows very competitive generation compared to concurrent\nstate-of-the-art DALL-E-2, and naturally supports interactive text-guided\nediting on images.",
          "link": "http://arxiv.org/abs/2204.14217",
          "publishedOn": "2022-05-02T00:57:33.154Z",
          "wordCount": 515,
          "title": "CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers. (arXiv:2204.14217v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Ching-pei Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1\">Ling Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tianyun Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toh_K/0/1/0/all/0/1\">Kim-Chuan Toh</a>",
          "description": "This work proposes a rapid global solver for nonconvex low-rank matrix\nfactorization (MF) problems that we name MF-Global. Through convex lifting\nsteps, our method efficiently escapes saddle points and spurious local minima\nubiquitous in noisy real-world data, and is guaranteed to always converge to\nthe global optima. Moreover, the proposed approach adaptively adjusts the rank\nfor the factorization and provably identifies the optimal rank for MF\nautomatically in the course of optimization through tools of manifold\nidentification, and thus it also spends significantly less time on parameter\ntuning than existing MF methods, which require an exhaustive search for this\noptimal rank. On the other hand, when compared to methods for solving the\nlifted convex form only, MF-Global leads to significantly faster convergence\nand much shorter running time. Experiments on real-world large-scale\nrecommendation system problems confirm that MF-Global can indeed effectively\nescapes spurious local solutions at which existing MF approaches stuck, and is\nmagnitudes faster than state-of-the-art algorithms for the lifted convex form.",
          "link": "http://arxiv.org/abs/2204.14067",
          "publishedOn": "2022-05-02T00:57:33.146Z",
          "wordCount": 596,
          "title": "Escaping Spurious Local Minima of Low-Rank Matrix Factorization Through Convex Lifting. (arXiv:2204.14067v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13940",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fermanian_R/0/1/0/all/0/1\">Rita Fermanian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pendu_M/0/1/0/all/0/1\">Mikael Le Pendu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guillemot_C/0/1/0/all/0/1\">Christine Guillemot</a>",
          "description": "The Plug-and-Play (PnP) framework allows integrating advanced image denoising\npriors into optimization algorithms, to efficiently solve a variety of image\nrestoration tasks. The Plug-and-Play alternating direction method of\nmultipliers (ADMM) and the Regularization by Denoising (RED) algorithms are two\nexamples of such methods that made a breakthrough in image restoration.\nHowever, while the former method only applies to proximal algorithms, it has\nrecently been shown that there exists no regularization that explains the RED\nalgorithm when the denoisers lack Jacobian symmetry, which happen to be the\ncase of most practical denoisers. To the best of our knowledge, there exists no\nmethod for training a network that directly represents the gradient of a\nregularizer, which can be directly used in Plug-and-Play gradient-based\nalgorithms. We show that it is possible to train a denoiser along with a\nnetwork that corresponds to the gradient of its regularizer. We use this\ngradient of the regularizer in gradient-based optimization methods and obtain\nbetter results comparing to other generic Plug-and-Play approaches. We also\nshow that the regularizer can be used as a pre-trained network for unrolled\ngradient descent. Lastly, we show that the resulting denoiser allows for a\nquick convergence of the Plug-and-Play ADMM.",
          "link": "http://arxiv.org/abs/2204.13940",
          "publishedOn": "2022-05-02T00:57:33.126Z",
          "wordCount": 640,
          "title": "Learned Gradient of a Regularizer for Plug-and-Play Gradient Descent. (arXiv:2204.13940v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_D/0/1/0/all/0/1\">Daesol Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jigang Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">H. Jin Kim</a>",
          "description": "Current reinforcement learning (RL) in robotics often experiences difficulty\nin generalizing to new downstream tasks due to the innate task-specific\ntraining paradigm. To alleviate it, unsupervised RL, a framework that\npre-trains the agent in a task-agnostic manner without access to the\ntask-specific reward, leverages active exploration for distilling diverse\nexperience into essential skills or reusable knowledge. For exploiting such\nbenefits also in robotic manipulation, we propose an unsupervised method for\ntransferable manipulation skill discovery that ties structured exploration\ntoward interacting behavior and transferable skill learning. It not only\nenables the agent to learn interaction behavior, the key aspect of the robotic\nmanipulation learning, without access to the environment reward, but also to\ngeneralize to arbitrary downstream manipulation tasks with the learned\ntask-agnostic skills. Through comparative experiments, we show that our\napproach achieves the most diverse interacting behavior and significantly\nimproves sample efficiency in downstream tasks including the extension to\nmulti-object, multitask problems.",
          "link": "http://arxiv.org/abs/2204.13906",
          "publishedOn": "2022-05-02T00:57:33.100Z",
          "wordCount": 598,
          "title": "Unsupervised Reinforcement Learning for Transferable Manipulation Skill Discovery. (arXiv:2204.13906v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.01441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kar_O/0/1/0/all/0/1\">O&#x11f;uzhan Fatih Kar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeo_T/0/1/0/all/0/1\">Teresa Yeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atanov_A/0/1/0/all/0/1\">Andrei Atanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamir_A/0/1/0/all/0/1\">Amir Zamir</a>",
          "description": "We introduce a set of image transformations that can be used as corruptions\nto evaluate the robustness of models as well as data augmentation mechanisms\nfor training neural networks. The primary distinction of the proposed\ntransformations is that, unlike existing approaches such as Common Corruptions,\nthe geometry of the scene is incorporated in the transformations -- thus\nleading to corruptions that are more likely to occur in the real world. We also\nintroduce a set of semantic corruptions (e.g. natural object occlusions). We\nshow these transformations are `efficient' (can be computed on-the-fly),\n`extendable' (can be applied on most image datasets), expose vulnerability of\nexisting models, and can effectively make models more robust when employed as\n`3D data augmentation' mechanisms. The evaluations on several tasks and\ndatasets suggest incorporating 3D information into benchmarking and training\nopens up a promising direction for robustness research.",
          "link": "http://arxiv.org/abs/2203.01441",
          "publishedOn": "2022-05-02T00:57:32.823Z",
          "wordCount": null,
          "title": "3D Common Corruptions and Data Augmentation. (arXiv:2203.01441v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiandian Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiantao Zhou</a>",
          "description": "Multimodal sentiment analysis has been studied under the assumption that all\nmodalities are available. However, such a strong assumption does not always\nhold in practice, and most of multimodal fusion models may fail when partial\nmodalities are missing. Several works have addressed the missing modality\nproblem; but most of them only considered the single modality missing case, and\nignored the practically more general cases of multiple modalities missing. To\nthis end, in this paper, we propose a Tag-Assisted Transformer Encoder (TATE)\nnetwork to handle the problem of missing uncertain modalities. Specifically, we\ndesign a tag encoding module to cover both the single modality and multiple\nmodalities missing cases, so as to guide the network's attention to those\nmissing modalities. Besides, we adopt a new space projection pattern to align\ncommon vectors. Then, a Transformer encoder-decoder network is utilized to\nlearn the missing modality features. At last, the outputs of the Transformer\nencoder are used for the final sentiment classification. Extensive experiments\nare conducted on CMU-MOSI and IEMOCAP datasets, showing that our method can\nachieve significant improvements compared with several baselines.",
          "link": "http://arxiv.org/abs/2204.13707",
          "publishedOn": "2022-05-02T00:57:32.629Z",
          "wordCount": 617,
          "title": "Tag-assisted Multimodal Sentiment Analysis under Uncertain Missing Modalities. (arXiv:2204.13707v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13713",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Villanueva_Domingo_P/0/1/0/all/0/1\">Pablo Villanueva-Domingo</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Villaescusa_Navarro_F/0/1/0/all/0/1\">Francisco Villaescusa-Navarro</a>",
          "description": "We train deep learning models on thousands of galaxy catalogues from the\nstate-of-the-art hydrodynamic simulations of the CAMELS project to perform\nregression and inference. We employ Graph Neural Networks (GNNs), architectures\ndesigned to work with irregular and sparse data, like the distribution of\ngalaxies in the Universe. We first show that GNNs can learn to compute the\npower spectrum of galaxy catalogues with a few percent accuracy. We then train\nGNNs to perform likelihood-free inference at the galaxy-field level. Our models\nare able to infer the value of $\\Omega_{\\rm m}$ with a $\\sim12\\%-13\\%$ accuracy\njust from the positions of $\\sim1000$ galaxies in a volume of $(25~h^{-1}{\\rm\nMpc})^3$ at $z=0$ while accounting for astrophysical uncertainties as modelled\nin CAMELS. Incorporating information from galaxy properties, such as stellar\nmass, stellar metallicity, and stellar radius, increases the accuracy to\n$4\\%-8\\%$. Our models are built to be translational and rotational invariant,\nand they can extract information from any scale larger than the minimum\ndistance between two galaxies. However, our models are not completely robust:\ntesting on simulations run with a different subgrid physics than the ones used\nfor training does not yield as accurate results.",
          "link": "http://arxiv.org/abs/2204.13713",
          "publishedOn": "2022-05-02T00:57:32.604Z",
          "wordCount": 657,
          "title": "Learning cosmology and clustering with cosmic graphs. (arXiv:2204.13713v1 [astro-ph.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vardasbi_A/0/1/0/all/0/1\">Ali Vardasbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarvi_F/0/1/0/all/0/1\">Fatemeh Sarvi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1\">Maarten de Rijke</a>",
          "description": "There are several measures for fairness in ranking, based on different\nunderlying assumptions and perspectives. PL optimization with the REINFORCE\nalgorithm can be used for optimizing black-box objective functions over\npermutations. In particular, it can be used for optimizing fairness measures.\nHowever, though effective for queries with a moderate number of repeating\nsessions, PL optimization has room for improvement for queries with a small\nnumber of repeating sessions.\n\nIn this paper, we present a novel way of representing permutation\ndistributions, based on the notion of permutation graphs. Similar to PL, our\ndistribution representation, called PPG, can be used for black-box optimization\nof fairness. Different from PL, where pointwise logits are used as the\ndistribution parameters, in PPG pairwise inversion probabilities together with\na reference permutation construct the distribution. As such, the reference\npermutation can be set to the best sampled permutation regarding the objective\nfunction, making PPG suitable for both deterministic and stochastic rankings.\nOur experiments show that PPG, while comparable to PL for larger session\nrepetitions (i.e., stochastic ranking), improves over PL for optimizing\nfairness metrics for queries with one session (i.e., deterministic ranking).\nAdditionally, when accurate utility estimations are available, e.g., in tabular\nmodels, the performance of PPG in fairness optimization is significantly\nboosted compared to lower quality utility estimations from a learning to rank\nmodel, leading to a large performance gap with PL. Finally, the pairwise\nprobabilities make it possible to impose pairwise constraints such as \"item\n$d_1$ should always be ranked higher than item $d_2$.\" Such constraints can be\nused to simultaneously optimize the fairness metric and control another\nobjective such as ranking performance.",
          "link": "http://arxiv.org/abs/2204.13765",
          "publishedOn": "2022-05-02T00:57:32.597Z",
          "wordCount": 722,
          "title": "Probabilistic Permutation Graph Search: Black-Box Optimization for Fairness in Ranking. (arXiv:2204.13765v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinsheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yongxin Chen</a>",
          "description": "The past few years have witnessed the great success of Diffusion models~(DMs)\nin generating high-fidelity samples in generative modeling tasks. A major\nlimitation of the DM is its notoriously slow sampling procedure which normally\nrequires hundreds to thousands of time discretization steps of the learned\ndiffusion process to reach the desired accuracy. Our goal is to develop a fast\nsampling method for DMs with much less number of steps while retaining high\nsample quality. To this end, we systematically analyze the sampling procedure\nin DMs and identify key factors that affect the sample quality, among which the\nmethod of discretization is most crucial. By carefully examining the learned\ndiffusion process, we propose Diffusion Exponential Integrator Sampler~(DEIS).\nIt is based on the Exponential Integrator designed for discretizing ordinary\ndifferential equations (ODEs) and leverages a semilinear structure of the\nlearned diffusion process to reduce the discretization error. The proposed\nmethod can be applied to any DMs and can generate high-fidelity samples in as\nfew as 10 steps. In our experiments, it takes about 3 minutes on one A6000 GPU\nto generate $50k$ images from CIFAR10.\n\nMoreover, by directly using pre-trained DMs, we achieve the state-of-art\nsampling performance when the number of score function evaluation~(NFE) is\nlimited, e.g., 3.37 FID and 9.74 Inception score with only 15 NFEs on CIFAR10.",
          "link": "http://arxiv.org/abs/2204.13902",
          "publishedOn": "2022-05-02T00:57:32.589Z",
          "wordCount": 639,
          "title": "Fast Sampling of Diffusion Models with Exponential Integrator. (arXiv:2204.13902v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Semenov_A/0/1/0/all/0/1\">Alexander Semenov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_M/0/1/0/all/0/1\">Marisa Ponti</a>",
          "description": "Citizen science and machine learning should be considered for monitoring the\ncoastal and ocean environment due to the scale of threats posed by climate\nchange and the limited resources to fill knowledge gaps. Using data from the\nannotation activity of citizen scientists in a Swedish marine project, we\nconstructed Deep Neural Network models to predict forthcoming engagement. We\ntested the models to identify patterns in annotation engagement. Based on the\nresults, it is possible to predict whether an annotator will remain active in\nfuture sessions. Depending on the goals of individual citizen science projects,\nit may also be necessary to identify either those volunteers who will leave or\nthose who will continue annotating. This can be predicted by varying the\nthreshold for the prediction. The engagement metrics used to construct the\nmodels are based on time and activity and can be used to infer latent\ncharacteristics of volunteers and predict their task interest based on their\nactivity patterns. They can estimate if volunteers can accomplish a given\nnumber of tasks in a certain amount of time, identify early on who is likely to\nbecome a top contributor or identify who is likely to quit and provide them\nwith targeted interventions. The novelty of our predictive models lies in the\nuse of Deep Neural Networks and the sequence of volunteer annotations. A\nlimitation of our models is that they do not use embeddings constructed from\nuser profiles as input data, as many recommender systems do. We expect that\nincluding user profiles would improve prediction performance.",
          "link": "http://arxiv.org/abs/2204.14046",
          "publishedOn": "2022-05-02T00:57:32.549Z",
          "wordCount": 687,
          "title": "Who will stay? Using Deep Learning to predict engagement of citizen scientists. (arXiv:2204.14046v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_A/0/1/0/all/0/1\">Anjul Tyagi</a>",
          "description": "High dimensional parameter space optimization is crucial in many\napplications. The parameters affecting this performance can be both numerical\nand categorical in their type. The existing techniques of black-box\noptimization and visual analytics are good in dealing with numerical parameters\nbut analyzing categorical variables in context of the numerical variables are\nnot well studied. Hence, we propose a novel approach, to create an auto-tuning\nframework for storage systems optimization combining both direct optimization\ntechniques and visual analytics research. While the optimization algorithm will\nbe the core of the system, visual analytics will provide a guideline with the\nhelp of an external agent (expert) to provide crucial hints to narrow down the\nlarge search space for the optimization engine. As part of the initial step\ntowards creating an auto-tuning engine for storage systems optimization, we\ncreated an Interactive Configuration Explorer \\textit{ICE}, which directly\naddresses the need of analysts to learn how the dependent numerical variable is\naffected by the parameter settings given multiple optimization objectives. No\ninformation is lost as ICE shows the complete distribution and statistics of\nthe dependent variable in context with each categorical variable. Analysts can\ninteractively filter the variables to optimize for certain goals such as\nachieving a system with maximum performance, low variance, etc. Our system was\ndeveloped in tight collaboration with a group of systems performance\nresearchers and its final effectiveness was evaluated with expert interviews, a\ncomparative user study, and two case studies. We also discuss our research plan\nfor creating an efficient auto-tuning framework combining black-box\noptimization and visual analytics for storage systems performance optimization.",
          "link": "http://arxiv.org/abs/2204.13812",
          "publishedOn": "2022-05-02T00:57:32.542Z",
          "wordCount": 710,
          "title": "Visualization and Optimization Techniques for High Dimensional Parameter Spaces. (arXiv:2204.13812v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13705",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Peacock_S/0/1/0/all/0/1\">Sophie Peacock</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jacob_E/0/1/0/all/0/1\">Etai Jacob</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Burlutskiy_N/0/1/0/all/0/1\">Nikolay Burlutskiy</a>",
          "description": "Genomics data such as RNA gene expression, methylation and micro RNA\nexpression are valuable sources of information for various clinical predictive\ntasks. For example, predicting survival outcomes, cancer histology type and\nother patients' related information is possible using not only clinical data\nbut molecular data as well. Moreover, using these data sources together, for\nexample in multitask learning, can boost the performance. However, in practice,\nthere are many missing data points which leads to significantly lower patient\nnumbers when analysing full cases, which in our setting refers to all\nmodalities being present.\n\nIn this paper we investigate how imputing data with missing values using deep\nlearning coupled with multitask learning can help to reach state-of-the-art\nperformance results using combined genomics modalities, RNA, micro RNA and\nmethylation. We propose a generalised deep imputation method to impute values\nwhere a patient has all modalities present except one. Interestingly enough,\ndeep imputation alone outperforms multitask learning alone for the\nclassification and regression tasks across most combinations of modalities. In\ncontrast, when using all modalities for survival prediction we observe that\nmultitask learning alone outperforms deep imputation alone with statistical\nsignificance (adjusted p-value 0.03). Thus, both approaches are complementary\nwhen optimising performance for downstream predictive tasks.",
          "link": "http://arxiv.org/abs/2204.13705",
          "publishedOn": "2022-05-02T00:57:32.531Z",
          "wordCount": 664,
          "title": "Coupling Deep Imputation with Multitask Learning for Downstream Tasks on Genomics Data. (arXiv:2204.13705v1 [q-bio.GN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Benjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wicker_M/0/1/0/all/0/1\">Matthew Wicker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwiatkowska_M/0/1/0/all/0/1\">Marta Kwiatkowska</a>",
          "description": "Bayesian structure learning allows one to capture uncertainty over the causal\ndirected acyclic graph (DAG) responsible for generating given data. In this\nwork, we present Tractable Uncertainty for STructure learning (TRUST), a\nframework for approximate posterior inference that relies on probabilistic\ncircuits as the representation of our posterior belief. In contrast to\nsample-based posterior approximations, our representation can capture a much\nricher space of DAGs, while being able to tractably answer a range of useful\ninference queries. We empirically show how probabilistic circuits can be used\nas an augmented representation for structure learning methods, leading to\nimprovement in both the quality of inferred structures and posterior\nuncertainty. Experimental results also demonstrate the improved\nrepresentational capacity of TRUST, outperforming competing methods on\nconditional query answering.",
          "link": "http://arxiv.org/abs/2204.14170",
          "publishedOn": "2022-05-02T00:57:32.519Z",
          "wordCount": 548,
          "title": "Tractable Uncertainty for Structure Learning. (arXiv:2204.14170v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petersen_F/0/1/0/all/0/1\">Felix Petersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldluecke_B/0/1/0/all/0/1\">Bastian Goldluecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgelt_C/0/1/0/all/0/1\">Christian Borgelt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deussen_O/0/1/0/all/0/1\">Oliver Deussen</a>",
          "description": "In this work, we present and study a generalized family of differentiable\nrenderers. We discuss from scratch which components are necessary for\ndifferentiable rendering and formalize the requirements for each component. We\ninstantiate our general differentiable renderer, which generalizes existing\ndifferentiable renderers like SoftRas and DIB-R, with an array of different\nsmoothing distributions to cover a large spectrum of reasonable settings. We\nevaluate an array of differentiable renderer instantiations on the popular\nShapeNet 3D reconstruction benchmark and analyze the implications of our\nresults. Surprisingly, the simple uniform distribution yields the best overall\nresults when averaged over 13 classes; in general, however, the optimal choice\nof distribution heavily depends on the task.",
          "link": "http://arxiv.org/abs/2204.13845",
          "publishedOn": "2022-05-02T00:57:32.510Z",
          "wordCount": 557,
          "title": "GenDR: A Generalized Differentiable Renderer. (arXiv:2204.13845v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13878",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Bin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hongyi Wu</a>",
          "description": "Energy is an essential, but often forgotten aspect in large-scale federated\nsystems. As most of the research focuses on tackling computational and\nstatistical heterogeneity from the machine learning algorithms, the impact on\nthe mobile system still remains unclear. In this paper, we design and implement\nan online optimization framework by connecting asynchronous execution of\nfederated training with application co-running to minimize energy consumption\non battery-powered mobile devices. From a series of experiments, we find that\nco-running the training process in the background with foreground applications\ngives the system a deep energy discount with negligible performance slowdown.\nBased on these results, we first study an offline problem assuming all the\nfuture occurrences of applications are available, and propose a dynamic\nprogramming-based algorithm. Then we propose an online algorithm using the\nLyapunov framework to explore the solution space via the energy-staleness\ntrade-off. The extensive experiments demonstrate that the online optimization\nframework can save over 60% energy with 3 times faster convergence speed\ncompared to the previous schemes.",
          "link": "http://arxiv.org/abs/2204.13878",
          "publishedOn": "2022-05-02T00:57:32.487Z",
          "wordCount": 612,
          "title": "Energy Minimization for Federated Asynchronous Learning on Battery-Powered Mobile Devices via Application Co-running. (arXiv:2204.13878v1 [cs.DC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13838",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pan_L/0/1/0/all/0/1\">Liangrui Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hetian Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_L/0/1/0/all/0/1\">Lian Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ji_B/0/1/0/all/0/1\">Boya Ji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_M/0/1/0/all/0/1\">Mingting Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chongcheawchamnan_M/0/1/0/all/0/1\">Mitchai Chongcheawchamnan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yuan_J/0/1/0/all/0/1\">Jin Yuan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_S/0/1/0/all/0/1\">Shaoliang Peng</a>",
          "description": "The degree of malignancy of osteosarcoma and its tendency to\nmetastasize/spread mainly depend on the pathological grade (determined by\nobserving the morphology of the tumor under a microscope). The purpose of this\nstudy is to use artificial intelligence to classify osteosarcoma histological\nimages and to assess tumor survival and necrosis, which will help doctors\nreduce their workload, improve the accuracy of osteosarcoma cancer detection,\nand make a better prognosis for patients. The study proposes a typical\ntransformer image classification framework by integrating noise reduction\nconvolutional autoencoder and feature cross fusion learning (NRCA-FCFL) to\nclassify osteosarcoma histological images. Noise reduction convolutional\nautoencoder could well denoise histological images of osteosarcoma, resulting\nin more pure images for osteosarcoma classification. Moreover, we introduce\nfeature cross fusion learning, which integrates two scale image patches, to\nsufficiently explore their interactions by using additional classification\ntokens. As a result, a refined fusion feature is generated, which is fed to the\nresidual neural network for label predictions. We conduct extensive experiments\nto evaluate the performance of the proposed approach. The experimental results\ndemonstrate that our method outperforms the traditional and deep learning\napproaches on various evaluation metrics, with an accuracy of 99.17% to support\nosteosarcoma diagnosis.",
          "link": "http://arxiv.org/abs/2204.13838",
          "publishedOn": "2022-05-02T00:57:32.478Z",
          "wordCount": 663,
          "title": "Noise-reducing attention cross fusion learning transformer for histological image classification of osteosarcoma. (arXiv:2204.13838v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Poddar_S/0/1/0/all/0/1\">Soham Poddar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samad_A/0/1/0/all/0/1\">Azlaan Mustafa Samad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_R/0/1/0/all/0/1\">Rajdeep Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1\">Niloy Ganguly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Saptarshi Ghosh</a>",
          "description": "Convincing people to get vaccinated against COVID-19 is a key societal\nchallenge in the present times. As a first step towards this goal, many prior\nworks have relied on social media analysis to understand the specific concerns\nthat people have towards these vaccines, such as potential side-effects,\nineffectiveness, political factors, and so on. Though there are datasets that\nbroadly classify social media posts into Anti-vax and Pro-Vax labels, there is\nno dataset (to our knowledge) that labels social media posts according to the\nspecific anti-vaccine concerns mentioned in the posts. In this paper, we have\ncurated CAVES, the first large-scale dataset containing about 10k COVID-19\nanti-vaccine tweets labelled into various specific anti-vaccine concerns in a\nmulti-label setting. This is also the first multi-label classification dataset\nthat provides explanations for each of the labels. Additionally, the dataset\nalso provides class-wise summaries of all the tweets. We also perform\npreliminary experiments on the dataset and show that this is a very challenging\ndataset for multi-label explainable classification and tweet summarization, as\nis evident by the moderate scores achieved by some state-of-the-art models. Our\ndataset and codes are available at: https://github.com/sohampoddar26/caves-data",
          "link": "http://arxiv.org/abs/2204.13746",
          "publishedOn": "2022-05-02T00:57:32.468Z",
          "wordCount": 704,
          "title": "CAVES: A Dataset to facilitate Explainable Classification and Summarization of Concerns towards COVID Vaccines. (arXiv:2204.13746v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yinan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yinpeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shihang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_P/0/1/0/all/0/1\">Peng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Youzuo Lin</a>",
          "description": "Inversion techniques are widely used to reconstruct subsurface physical\nproperties (e.g., velocity, conductivity, and others) from surface-based\ngeophysical measurements (e.g., seismic, electric/magnetic (EM) data). The\nproblems are governed by partial differential equations~(PDEs) like the wave or\nMaxwell's equations. Solving geophysical inversion problems is challenging due\nto the ill-posedness and high computational cost. To alleviate those issues,\nrecent studies leverage deep neural networks to learn the inversion mappings\nfrom geophysical measurements to the geophysical property directly.\n\nIn this paper, we show that such a mapping can be well modeled by a\n\\textit{very shallow}~(but not wide) network with only five layers. This is\nachieved based on our new finding of an intriguing property: \\textit{a\nnear-linear relationship between the input and output, after applying integral\ntransform in high dimensional space.} In particular, when dealing with the\ninversion from seismic data to subsurface velocity governed by a wave equation,\nthe integral results of velocity with Gaussian kernels are linearly correlated\nto the integral of seismic data with sine kernels. Furthermore, this property\ncan be easily turned into a light-weight encoder-decoder network for inversion.\nThe encoder contains the integration of seismic data and the linear\ntransformation without need for fine-tuning. The decoder only consists of a\nsingle transformer block to reverse the integral of velocity.\n\nExperiments show that this interesting property holds for two geophysics\ninversion problems over four different datasets. Compared to much deeper\nInversionNet~\\cite{wu2019inversionnet}, our method achieves comparable\naccuracy, but consumes significantly fewer parameters.",
          "link": "http://arxiv.org/abs/2204.13731",
          "publishedOn": "2022-05-02T00:57:32.458Z",
          "wordCount": 681,
          "title": "An Intriguing Property of Geophysics Inversion. (arXiv:2204.13731v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yujia Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1\">Regina Barzilay</a>",
          "description": "Classifiers are biased when trained on biased datasets. As a remedy, we\npropose Learning to Split (ls), an algorithm for automatic bias detection.\nGiven a dataset with input-label pairs, ls learns to split this dataset so that\npredictors trained on the training split generalize poorly to the testing\nsplit. This performance gap provides a proxy for measuring the degree of bias\nin the learned features and can therefore be used to reduce biases. Identifying\nnon-generalizable splits is challenging as we don't have any explicit\nannotations about how to split. In this work, we show that the prediction\ncorrectness of the testing example can be used as a source of weak supervision:\ngeneralization performance will drop if we move examples that are predicted\ncorrectly away from the testing split, leaving only those that are\nmispredicted. We evaluate our approach on Beer Review, Waterbirds, CelebA and\nMNLI. Empirical results show that ls is able to generate astonishingly\nchallenging splits that correlate with human-identified biases. Moreover, we\ndemonstrate that combining robust learning algorithms (such as group DRO) with\nsplits identified by ls enables automatic de-biasing. Compared with previous\nstate-of-the-arts, we substantially improves the worst-group performance (23.4%\non average) when the source of biases is unknown during training and\nvalidation.",
          "link": "http://arxiv.org/abs/2204.13749",
          "publishedOn": "2022-05-02T00:57:32.433Z",
          "wordCount": 648,
          "title": "Learning to Split for Automatic Bias Detection. (arXiv:2204.13749v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Na Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dras_M/0/1/0/all/0/1\">Mark Dras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Emma Zhang</a>",
          "description": "Although deep neural networks have achieved state-of-the-art performance in\nvarious machine learning tasks, adversarial examples, constructed by adding\nsmall non-random perturbations to correctly classified inputs, successfully\nfool highly expressive deep classifiers into incorrect predictions. Approaches\nto adversarial attacks in natural language tasks have boomed in the last five\nyears using character-level, word-level, phrase-level, or sentence-level\ntextual perturbations. While there is some work in NLP on defending against\nsuch attacks through proactive methods, like adversarial training, there is to\nour knowledge no effective general reactive approaches to defence via detection\nof textual adversarial examples such as is found in the image processing\nliterature. In this paper, we propose two new reactive methods for NLP to fill\nthis gap, which unlike the few limited application baselines from NLP are based\nentirely on distribution characteristics of learned representations: we adapt\none from the image processing literature (Local Intrinsic Dimensionality\n(LID)), and propose a novel one (MultiDistance Representation Ensemble Method\n(MDRE)). Adapted LID and MDRE obtain state-of-the-art results on\ncharacter-level, word-level, and phrase-level attacks on the IMDB dataset as\nwell as on the later two with respect to the MultiNLI dataset. For future\nresearch, we publish our code.",
          "link": "http://arxiv.org/abs/2204.13853",
          "publishedOn": "2022-05-02T00:57:32.424Z",
          "wordCount": 632,
          "title": "Detecting Textual Adversarial Examples Based on Distributional Characteristics of Data Representations. (arXiv:2204.13853v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yassine_T/0/1/0/all/0/1\">Taha Yassine</a> (IRT b-com, INSA Rennes), <a href=\"http://arxiv.org/find/cs/1/au:+Magoarou_L/0/1/0/all/0/1\">Luc Le Magoarou</a> (IRT b-com), <a href=\"http://arxiv.org/find/cs/1/au:+Paquelet_S/0/1/0/all/0/1\">St&#xe9;phane Paquelet</a> (IRT b-com), <a href=\"http://arxiv.org/find/cs/1/au:+Crussiere_M/0/1/0/all/0/1\">Matthieu Crussi&#xe8;re</a> (IRT b-com, IETR, INSA Rennes)",
          "description": "Channel charting is an unsupervised learning method that aims at mapping\nwireless channels to a so-called chart, preserving as much as possible spatial\nneighborhoods. In this paper, a model-based deep learning approach to this\nproblem is proposed. It builds on a physically motivated distance measure to\nstructure and initialize a neural network that is subsequently trained using a\ntriplet loss function. The proposed structure exhibits a low number of\nparameters and clever initialization leads to fast training. These two features\nmake the proposed approach amenable to on-the-fly channel charting. The method\nis empirically assessed on realistic synthetic channels, yielding encouraging\nresults.",
          "link": "http://arxiv.org/abs/2204.13996",
          "publishedOn": "2022-05-02T00:57:32.416Z",
          "wordCount": 561,
          "title": "Leveraging triplet loss and nonlinear dimensionality reduction for on-the-fly channel charting. (arXiv:2204.13996v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao-Chun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_W/0/1/0/all/0/1\">Wan-Ting Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Trista Pei-Chun Chen</a>",
          "description": "Electrocardiogram(ECG) is commonly used to detect cardiac irregularities such\nas atrial fibrillation, bradycardia, and other irregular complexes. While\nprevious studies have achieved great accomplishment classifying these\nirregularities with standard 12-lead ECGs, there existed limited evidence\ndemonstrating the utility of reduced-lead ECGs in capturing a wide-range of\ndiagnostic information. In addition, classification model's generalizability\nacross multiple recording sources also remained uncovered. As part of the\nPhysioNet Computing in Cardiology Challenge 2021, our team HaoWan AIeC,\nproposed Mixed-Domain Self-Attention Resnet (MDARsn) to identify cardiac\nabnormalities from reduced-lead ECG. Our classifiers received scores of 0.602,\n0.593, 0.597, 0.591, and 0.589 (ranked 54th, 37th, 38th, 38th, and 39th) for\nthe 12-lead, 6-lead, 4-lead, 3-lead, and 2-lead versions of the hidden\nvalidation set with the evaluation metric defined by the challenge.",
          "link": "http://arxiv.org/abs/2204.13917",
          "publishedOn": "2022-05-02T00:57:32.405Z",
          "wordCount": 555,
          "title": "A Mixed-Domain Self-Attention Network for Multilabel Cardiac Irregularity Classification Using Reduced-Lead Electrocardiogram. (arXiv:2204.13917v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.14008",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kubo_Y/0/1/0/all/0/1\">Yoshimasa Kubo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalmers_E/0/1/0/all/0/1\">Eric Chalmers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luczak_A/0/1/0/all/0/1\">Artur Luczak</a>",
          "description": "Since humans still outperform artificial neural networks on many tasks,\ndrawing inspiration from the brain may help to improve current machine learning\nalgorithms. Contrastive Hebbian Learning (CHL) and Equilibrium Propagation (EP)\nare biologically plausible algorithms that update weights using only local\ninformation (without explicitly calculating gradients) and still achieve\nperformance comparable to conventional backpropagation. In this study, we\naugmented CHL and EP with Adjusted Adaptation, inspired by the adaptation\neffect observed in neurons, in which a neuron's response to a given stimulus is\nadjusted after a short time. We add this adaptation feature to multilayer\nperceptrons and convolutional neural networks trained on MNIST and CIFAR-10.\nSurprisingly, adaptation improved the performance of these networks. We discuss\nthe biological inspiration for this idea and investigate why Neuronal\nAdaptation could be an important brain mechanism to improve the stability and\naccuracy of learning.",
          "link": "http://arxiv.org/abs/2204.14008",
          "publishedOn": "2022-05-02T00:57:32.392Z",
          "wordCount": 575,
          "title": "Biologically-inspired neuronal adaptation improves learning in neural networks. (arXiv:2204.14008v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bekci_R/0/1/0/all/0/1\">Recep Yusuf Bekci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahdid_Y/0/1/0/all/0/1\">Yacine Mahdid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1\">Jinling Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Letov_N/0/1/0/all/0/1\">Nikita Letov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasha_Z/0/1/0/all/0/1\">Zahid Pasha</a>",
          "description": "In this study, we utilize Gaussian processes, probabilistic neural network,\nnatural gradient boosting, and quantile regression augmented gradient boosting\nto model lead times of laser manufacturing processes. We introduce\nprobabilistic modelling in the domain and compare the models in terms of\ndifferent abilities. While providing a comparison between the models in\nreal-life data, our work has many use cases and substantial business value. Our\nresults indicate that all of the models beat the company estimation benchmark\nthat uses domain experience and have good calibration with the empirical\nfrequencies.",
          "link": "http://arxiv.org/abs/2204.13792",
          "publishedOn": "2022-05-02T00:57:32.371Z",
          "wordCount": 521,
          "title": "Probabilistic Models for Manufacturing Lead Times. (arXiv:2204.13792v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13751",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Kulshrestha_A/0/1/0/all/0/1\">Ankit Kulshrestha</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Safro_I/0/1/0/all/0/1\">Ilya Safro</a>",
          "description": "Barren plateaus are a notorious problem in the optimization of variational\nquantum algorithms and pose a critical obstacle in the quest for more efficient\nquantum machine learning algorithms. Many potential reasons for barren plateaus\nhave been identified but few solutions have been proposed to avoid them in\npractice. Existing solutions are mainly focused on the initialization of\nunitary gate parameters without taking into account the changes induced by\ninput data. In this paper, we propose an alternative strategy which initializes\nthe parameters of a unitary gate by drawing from a beta distribution. The\nhyperparameters of the beta distribution are estimated from the data. To\nfurther prevent barren plateau during training we add a novel perturbation at\nevery gradient descent step. Taking these ideas together, we empirically show\nthat our proposed framework significantly reduces the possibility of a complex\nquantum neural network getting stuck in a barren plateau.",
          "link": "http://arxiv.org/abs/2204.13751",
          "publishedOn": "2022-05-02T00:57:32.357Z",
          "wordCount": 577,
          "title": "BEINIT: Avoiding Barren Plateaus in Variational Quantum Algorithms. (arXiv:2204.13751v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.04615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1\">Mohit Kumar</a>",
          "description": "This paper considers the problem of differentially private semi-supervised\ntransfer and multi-task learning. The notion of \\emph{membership-mapping} has\nbeen developed using measure theory basis to learn data representation via a\nfuzzy membership function. An alternative conception of deep autoencoder,\nreferred to as \\emph{Conditionally Deep Membership-Mapping Autoencoder\n(CDMMA)}, is considered for transferrable deep learning. Under\npractice-oriented settings, an analytical solution for the learning of CDMMA\ncan be derived by means of variational optimization. The paper proposes a\ntransfer and multi-task learning approach that combines CDMMA with a tailored\nnoise adding mechanism to achieve a given level of privacy-loss bound with the\nminimum perturbation of the data. Numerous experiments were carried out using\nMNIST, USPS, Office, and Caltech256 datasets to verify the competitive robust\nperformance of the proposed methodology.",
          "link": "http://arxiv.org/abs/2105.04615",
          "publishedOn": "2022-04-30T01:01:35.530Z",
          "wordCount": 631,
          "title": "Differentially Private Transferrable Deep Learning with Membership-Mappings. (arXiv:2105.04615v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.13441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mengjia Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Apoorva Vikram Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Dynamic graph embedding has gained great attention recently due to its\ncapability of learning low dimensional graph representations for complex\ntemporal graphs with high accuracy. However, recent advances mostly focus on\nlearning node embeddings as deterministic \"vectors\" for static graphs yet\ndisregarding the key graph temporal dynamics and the evolving uncertainties\nassociated with node embedding in the latent space. In this work, we propose an\nefficient stochastic dynamic graph embedding method (DynG2G) that applies an\ninductive feed-forward encoder trained with node triplet-based contrastive\nloss. Every node per timestamp is encoded as a time-dependent probabilistic\nmultivariate Gaussian distribution in the latent space, hence we can quantify\nthe node embedding uncertainty on-the-fly. We adopted eight different\nbenchmarks that represent diversity in size (from 96 nodes to 87,626 and from\n13,398 edges to 4,870,863) and diversity in dynamics. We demonstrate via\nextensive experiments on these eight dynamic graph benchmarks that DynG2G\nachieves new state-of-the-art performance in capturing the underlying temporal\nnode embeddings. We also demonstrate that DynG2G can predict the evolving node\nembedding uncertainty, which plays a crucial role in quantifying the intrinsic\ndimensionality of the dynamical system over time. We obtain a universal\nrelation of the optimal embedding dimension, $L_o$, versus the effective\ndimensionality of uncertainty, $D_u$, and we infer that $L_o=D_u$ for all\ncases. This implies that the uncertainty quantification approach we employ in\nthe DynG2G correctly captures the intrinsic dimensionality of the dynamics of\nsuch evolving graphs despite the diverse nature and composition of the graphs\nat each timestamp. Moreover, this $L_0 - D_u$ correlation provides a clear path\nto select adaptively the optimum embedding size at each timestamp by setting $L\n\\ge D_u$.",
          "link": "http://arxiv.org/abs/2109.13441",
          "publishedOn": "2022-04-30T01:01:35.511Z",
          "wordCount": 744,
          "title": "DynG2G: An Efficient Stochastic Graph Embedding Method for Temporal Graphs. (arXiv:2109.13441v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suk_J/0/1/0/all/0/1\">Joe Suk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>",
          "description": "In bandit with distribution shifts, one aims to automatically adapt to\nunknown changes in reward distribution, and restart exploration when necessary.\nWhile this problem has been studied for many years, a recent breakthrough of\nAuer et al. (2018, 2019) provides the first adaptive procedure to guarantee an\noptimal (dynamic) regret $\\sqrt{LT}$, for $T$ rounds, and an unknown number $L$\nof changes. However, while this rate is tight in the worst case, it remained\nopen whether faster rates are possible, without prior knowledge, if few changes\nin distribution are actually severe.\n\nTo resolve this question, we propose a new notion of significant shift, which\nonly counts very severe changes that clearly necessitate a restart: roughly,\nthese are changes involving not only best arm switches, but also involving\nlarge aggregate differences in reward overtime. Thus, our resulting procedure\nadaptively achieves rates always faster (sometimes significantly) than\n$O(\\sqrt{ST})$, where $S\\ll L$ only counts best arm switches, while at the same\ntime, always faster than the optimal $O(V^{\\frac{1}{3}}T^{\\frac{2}{3}})$ when\nexpressed in terms of total variation $V$ (which aggregates differences\novertime). Our results are expressed in enough generality to also capture\nnon-stochastic adversarial settings.",
          "link": "http://arxiv.org/abs/2112.13838",
          "publishedOn": "2022-04-30T01:01:35.496Z",
          "wordCount": 672,
          "title": "Tracking Most Significant Arm Switches in Bandits. (arXiv:2112.13838v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.04931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Swiechowski_M/0/1/0/all/0/1\">Maciej &#x15a;wiechowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godlewski_K/0/1/0/all/0/1\">Konrad Godlewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawicki_B/0/1/0/all/0/1\">Bartosz Sawicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandziuk_J/0/1/0/all/0/1\">Jacek Ma&#x144;dziuk</a>",
          "description": "Monte Carlo Tree Search (MCTS) is a powerful approach to designing\ngame-playing bots or solving sequential decision problems. The method relies on\nintelligent tree search that balances exploration and exploitation. MCTS\nperforms random sampling in the form of simulations and stores statistics of\nactions to make more educated choices in each subsequent iteration. The method\nhas become a state-of-the-art technique for combinatorial games, however, in\nmore complex games (e.g. those with high branching factor or real-time ones),\nas well as in various practical domains (e.g. transportation, scheduling or\nsecurity) an efficient MCTS application often requires its problem-dependent\nmodification or integration with other techniques. Such domain-specific\nmodifications and hybrid approaches are the main focus of this survey. The last\nmajor MCTS survey has been published in 2012. Contributions that appeared since\nits release are of particular interest for this review.",
          "link": "http://arxiv.org/abs/2103.04931",
          "publishedOn": "2022-04-30T01:01:35.489Z",
          "wordCount": 630,
          "title": "Monte Carlo Tree Search: A Review of Recent Modifications and Applications. (arXiv:2103.04931v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bilski_J/0/1/0/all/0/1\">Jakub Micha&#x142; Bilski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jastrzebska_A/0/1/0/all/0/1\">Agnieszka Jastrz&#x119;bska</a>",
          "description": "Classification of sequences of temporal intervals is a part of time series\nanalysis which concerns series of events. We propose a new method of\ntransforming the problem to a task of multivariate series classification. We\nuse one of the state-of-the-art algorithms from the latter domain on the new\nrepresentation to obtain significantly better accuracy than the\nstate-of-the-art methods from the former field. We discuss limitations of this\nworkflow and address them by developing a novel method for classification\ntermed COSTI (short for Classification of Sequences of Temporal Intervals)\noperating directly on sequences of temporal intervals. The proposed method\nremains at a high level of accuracy and obtains better performance while\navoiding shortcomings connected to operating on transformed data. We propose a\ngeneralized version of the problem of classification of temporal intervals,\nwhere each event is supplemented with information about its intensity. We also\nprovide two new data sets where this information is of substantial value.",
          "link": "http://arxiv.org/abs/2204.13467",
          "publishedOn": "2022-04-30T01:01:35.482Z",
          "wordCount": 586,
          "title": "COSTI: a New Classifier for Sequences of Temporal Intervals. (arXiv:2204.13467v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.12556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yapar_C/0/1/0/all/0/1\">&#xc7;a&#x11f;kan Yapar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levie_R/0/1/0/all/0/1\">Ron Levie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1\">Gitta Kutyniok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caire_G/0/1/0/all/0/1\">Giuseppe Caire</a>",
          "description": "This paper deals with the problem of localization in a cellular network in a\ndense urban scenario. Global Navigation Satellite Systems typically perform\npoorly in urban environments, where the likelihood of line-of-sight conditions\nbetween the devices and the satellites is low, and thus alternative\nlocalization methods are required for good accuracy. We present LocUNet: A\nfully convolutional, end-to-end trained neural network for the localization\ntask, which merely depends on the received signal strengths (RSS) from Base\nStations (BSs).In a wireless network, user devices scan the base station beacon\nslots and identify the few strongest base station signals for handover and\nuser-base station association purposes. In the proposed method, the user to be\nlocalized simply reports such received signal strengths to a central processing\nunit, which may be located in the cloud. Alternatively, the localization can be\nperformed locally at the user. Using the pathloss radio map estimations and the\nRSS measurements, LocUNet can localize users with state-of-the-art accuracy and\nenjoys high robustness to inaccuracies in the estimations of the radio maps.\nThe proposed method does not require pre-sampling of the environment; and is\nsuitable for real-time applications, thanks to the RadioUNet, a neural\nnetwork-based radio map estimator. Moreover, two novel datasets that allow for\nnumerical evaluations of RSS and ToA methods in realistic urban environments\nare presented and set publicly available for the use of research community. By\nusing these datasets, we also provided a fair comparison of state-of-the-art\nRSS and ToA-based methods in the dense urban scenario, LocUNet outperforming\nall the compared methods.",
          "link": "http://arxiv.org/abs/2106.12556",
          "publishedOn": "2022-04-30T01:01:35.465Z",
          "wordCount": 744,
          "title": "Real-time Outdoor Localization Using Radio Maps: A Deep Learning Approach. (arXiv:2106.12556v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.07564",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pronzato_L/0/1/0/all/0/1\">Luc Pronzato</a>",
          "description": "We analyse the performance of several iterative algorithms for the\nquantisation of a probability measure $\\mu$, based on the minimisation of a\nMaximum Mean Discrepancy (MMD). Our analysis includes kernel herding, greedy\nMMD minimisation and Sequential Bayesian Quadrature (SBQ). We show that the\nfinite-sample-size approximation error, measured by the MMD, decreases as $1/n$\nfor SBQ and also for kernel herding and greedy MMD minimisation when using a\nsuitable step-size sequence. The upper bound on the approximation error is\nslightly better for SBQ, but the other methods are significantly faster, with a\ncomputational cost that increases only linearly with the number of points\nselected. This is illustrated by two numerical examples, with the target\nmeasure $\\mu$ being uniform (a space-filling design application) and with $\\mu$\na Gaussian mixture. They suggest that the bounds derived in the paper are\noverly pessimistic, in particular for SBQ. The sources of this pessimism are\nidentified but seem difficult to counter.",
          "link": "http://arxiv.org/abs/2101.07564",
          "publishedOn": "2022-04-30T01:01:35.444Z",
          "wordCount": 625,
          "title": "Performance analysis of greedy algorithms for minimising a Maximum Mean Discrepancy. (arXiv:2101.07564v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.03350",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Munkhdalai_L/0/1/0/all/0/1\">Lkhagvadorj Munkhdalai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Munkhdalai_T/0/1/0/all/0/1\">Tsendsuren Munkhdalai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ryu_K/0/1/0/all/0/1\">Keun Ho Ryu</a>",
          "description": "Machine learning models with both good predictability and high\ninterpretability are crucial for decision support systems. Linear regression is\none of the most interpretable prediction models. However, the linearity in a\nsimple linear regression worsens its predictability. In this work, we introduce\na locally adaptive interpretable regression (LoAIR). In LoAIR, a metamodel\nparameterized by neural networks predicts percentile of a Gaussian distribution\nfor the regression coefficients for a rapid adaptation. Our experimental\nresults on public benchmark datasets show that our model not only achieves\ncomparable or better predictive performance than the other state-of-the-art\nbaselines but also discovers some interesting relationships between input and\ntarget variables such as a parabolic relationship between CO2 emissions and\nGross National Product (GNP). Therefore, LoAIR is a step towards bridging the\ngap between econometrics, statistics, and machine learning by improving the\npredictive ability of linear regression without depreciating its\ninterpretability.",
          "link": "http://arxiv.org/abs/2005.03350",
          "publishedOn": "2022-04-30T01:01:35.438Z",
          "wordCount": 611,
          "title": "A Locally Adaptive Interpretable Regression. (arXiv:2005.03350v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sivaprasad_S/0/1/0/all/0/1\">Sarath Sivaprasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goindani_A/0/1/0/all/0/1\">Akshay Goindani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_V/0/1/0/all/0/1\">Vaibhav Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_R/0/1/0/all/0/1\">Ritam Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosgi_S/0/1/0/all/0/1\">Saiteja Kosgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gandhi_V/0/1/0/all/0/1\">Vineet Gandhi</a>",
          "description": "Given that Neural Networks generalize unreasonably well in the IID setting\n(with benign overfitting and betterment in performance with more parameters),\nOOD presents a consistent failure case to better the understanding of how they\nlearn. This paper focuses on Domain Generalization (DG), which is perceived as\nthe front face of OOD generalization. We find that the presence of multiple\ndomains incentivizes domain agnostic learning and is the primary reason for\ngeneralization in Tradition DG. We show that the state-of-the-art results can\nbe obtained by borrowing ideas from IID generalization and the DG tailored\nmethods fail to add any performance gains. Furthermore, we perform explorations\nbeyond the Traditional DG (TDG) formulation and propose a novel ClassWise DG\n(CWDG) benchmark, where for each class, we randomly select one of the domains\nand keep it aside for testing. Despite being exposed to all domains during\ntraining, CWDG is more challenging than TDG evaluation. We propose a novel\niterative domain feature masking approach, achieving state-of-the-art results\non the CWDG benchmark. Overall, while explaining these observations, our work\nfurthers insights into the learning mechanisms of neural networks.",
          "link": "http://arxiv.org/abs/2110.07981",
          "publishedOn": "2022-04-30T01:01:35.418Z",
          "wordCount": 652,
          "title": "Reappraising Domain Generalization in Neural Networks. (arXiv:2110.07981v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13739",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Marshall_S/0/1/0/all/0/1\">Simon C. Marshall</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gyurik_C/0/1/0/all/0/1\">Casper Gyurik</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Dunjko_V/0/1/0/all/0/1\">Vedran Dunjko</a>",
          "description": "Quantum computers hold great promise to enhance machine learning, but their\ncurrent qubit counts restrict the realisation of this promise. In an attempt to\nplacate this limitation techniques can be applied for evaluating a quantum\ncircuit using a machine with fewer qubits than the circuit naively requires.\nThese techniques work by evaluating many smaller circuits on the smaller\nmachine, that are then combined in a polynomial to replicate the output of the\nlarger machine. This scheme requires more circuit evaluations than are\npractical for general circuits. However, we investigate the possibility that\nfor certain applications many of these subcircuits are superfluous, and that a\nmuch smaller sum is sufficient to estimate the full circuit. We construct a\nmachine learning model that may be capable of approximating the outputs of the\nlarger circuit with much fewer circuit evaluations. We successfully apply our\nmodel to the task of digit recognition, using simulated quantum computers much\nsmaller than the data dimension. The model is also applied to the task of\napproximating a random 10 qubit PQC with simulated access to a 5 qubit\ncomputer, even with only relatively modest number of circuits our model\nprovides an accurate approximation of the 10 qubit PQCs output, superior to a\nneural network attempt. The developed method might be useful for implementing\nquantum models on larger data throughout the NISQ era.",
          "link": "http://arxiv.org/abs/2203.13739",
          "publishedOn": "2022-04-30T01:01:35.411Z",
          "wordCount": 682,
          "title": "High Dimensional Quantum Machine Learning With Small Quantum Computers. (arXiv:2203.13739v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Hansi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1\">Hamed Zamani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinay_V/0/1/0/all/0/1\">Vishwa Vinay</a>",
          "description": "Recent work has shown that more effective dense retrieval models can be\nobtained by distilling ranking knowledge from an existing base re-ranking\nmodel. In this paper, we propose a generic curriculum learning based\noptimization framework called CL-DRD that controls the difficulty level of\ntraining data produced by the re-ranking (teacher) model. CL-DRD iteratively\noptimizes the dense retrieval (student) model by increasing the difficulty of\nthe knowledge distillation data made available to it. In more detail, we\ninitially provide the student model coarse-grained preference pairs between\ndocuments in the teacher's ranking and progressively move towards finer-grained\npairwise document ordering requirements. In our experiments, we apply a simple\nimplementation of the CL-DRD framework to enhance two state-of-the-art dense\nretrieval models. Experiments on three public passage retrieval datasets\ndemonstrate the effectiveness of our proposed framework.",
          "link": "http://arxiv.org/abs/2204.13679",
          "publishedOn": "2022-04-30T01:01:35.377Z",
          "wordCount": 566,
          "title": "Curriculum Learning for Dense Retrieval Distillation. (arXiv:2204.13679v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13678",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Ye Yuan</a>",
          "description": "Understanding and modeling human behavior is fundamental to almost any\ncomputer vision and robotics applications that involve humans. In this thesis,\nwe take a holistic approach to human behavior modeling and tackle its three\nessential aspects -- simulation, perception, and generation. Throughout the\nthesis, we show how the three aspects are deeply connected and how utilizing\nand improving one aspect can greatly benefit the other aspects. We also discuss\nthe lessons learned and our vision for what is next for human behavior\nmodeling.",
          "link": "http://arxiv.org/abs/2204.13678",
          "publishedOn": "2022-04-30T01:01:35.068Z",
          "wordCount": null,
          "title": "Unified Simulation, Perception, and Generation of Human Behavior. (arXiv:2204.13678v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13599",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cocola_J/0/1/0/all/0/1\">Jorio Cocola</a>",
          "description": "We study compressive sensing with a deep generative network prior. Initial\ntheoretical guarantees for efficient recovery from compressed linear\nmeasurements have been developed for signals in the range of a ReLU network\nwith Gaussian weights and logarithmic expansivity: that is when each layer is\nlarger than the previous one by a logarithmic factor. It was later shown that\nconstant expansivity is sufficient for recovery. It has remained open whether\nthe expansivity can be relaxed allowing for networks with contractive layers,\nas often the case of real generators. In this work we answer this question,\nproving that a signal in the range of a Gaussian generative network can be\nrecovered from a few linear measurements provided that the width of the layers\nis proportional to the input layer size (up to log factors). This condition\nallows the generative network to have contractive layers. Our result is based\non showing that Gaussian matrices satisfy a matrix concentration inequality,\nwhich we term Range Restricted Weight Distribution Condition (R2WDC), and\nweakens the Weight Distribution Condition (WDC) upon which previous theoretical\nguarantees were based on. The WDC has also been used to analyze other signal\nrecovery problems with generative network priors. By replacing the WDC with the\nR2WDC, we are able to extend previous results for signal recovery with\nexpansive generative network priors to non-expansive ones. We discuss these\nextensions for phase retrieval, denoising, and spiked matrix recovery.",
          "link": "http://arxiv.org/abs/2204.13599",
          "publishedOn": "2022-04-30T01:01:35.064Z",
          "wordCount": null,
          "title": "Signal Recovery with Non-Expansive Generative Network Priors. (arXiv:2204.13599v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12131",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yousefzadeh_R/0/1/0/all/0/1\">Roozbeh Yousefzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xuenan Cao</a>",
          "description": "The right to AI explainability has consolidated as a consensus in the\nresearch community and policy-making. However, a key component of\nexplainability has been missing: extrapolation, which describes the extent to\nwhich AI models can be clueless when they encounter unfamiliar samples (i.e.,\nsamples outside the convex hull of their training sets, as we will explain). We\nreport that AI models extrapolate outside their range of familiar data,\nfrequently and without notifying the users and stakeholders. Knowing whether a\nmodel has extrapolated or not is a fundamental insight that should be included\nin explaining AI models in favor of transparency and accountability. Instead of\ndwelling on the negatives, we offer ways to clear the roadblocks in promoting\nAI transparency. Our analysis commentary accompanying practical clauses useful\nto include in AI regulations such as the National AI Initiative Act in the US\nand the AI Act by the European Commission.",
          "link": "http://arxiv.org/abs/2203.12131",
          "publishedOn": "2022-04-30T01:01:35.063Z",
          "wordCount": null,
          "title": "Should Machine Learning Models Report to Us When They Are Clueless?. (arXiv:2203.12131v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.05915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1\">Rohitash Chandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Mahir Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maharana_M/0/1/0/all/0/1\">Manavendra Maharana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krivitsky_P/0/1/0/all/0/1\">Pavel N. Krivitsky</a>",
          "description": "Autoencoders gained popularity in the deep learning revolution given their\nability to compress data and provide dimensionality reduction. Although\nprominent deep learning methods have been used to enhance autoencoders, the\nneed to provide robust uncertainty quantification remains a challenge. This has\nbeen addressed with variational autoencoders so far. Bayesian inference via\nMarkov Chain Monte Carlo (MCMC) sampling has faced several limitations for\nlarge models; however, recent advances in parallel computing and advanced\nproposal schemes have opened routes less traveled. This paper presents Bayesian\nautoencoders powered by MCMC sampling implemented using parallel computing and\nLangevin-gradient proposal distribution. The results indicate that the proposed\nBayesian autoencoder provides similar performance accuracy when compared to\nrelated methods in the literature. Furthermore, it provides uncertainty\nquantification in the reduced data representation. This motivates further\napplications of the Bayesian autoencoder framework for other deep learning\nmodels.",
          "link": "http://arxiv.org/abs/2104.05915",
          "publishedOn": "2022-04-30T01:01:35.058Z",
          "wordCount": null,
          "title": "Revisiting Bayesian Autoencoders with MCMC. (arXiv:2104.05915v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.03940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_Garcia_M/0/1/0/all/0/1\">Miguel Ruiz-Garcia</a>",
          "description": "The work of McCloskey and Cohen popularized the concept of catastrophic\ninterference. They used a neural network that tried to learn addition using two\ngroups of examples as two different tasks. In their case, learning the second\ntask rapidly deteriorated the acquired knowledge about the previous one. We\nhypothesize that this could be a symptom of a fundamental problem: addition is\nan algorithmic task that should not be learned through pattern recognition.\nTherefore, other model architectures better suited for this task would avoid\ncatastrophic forgetting. We use a neural network with a different architecture\nthat can be trained to recover the correct algorithm for the addition of binary\nnumbers. This neural network includes conditional clauses that are naturally\ntreated within the back-propagation algorithm. We test it in the setting\nproposed by McCloskey and Cohen and training on random additions one by one.\nThe neural network not only does not suffer from catastrophic forgetting but it\nimproves its predictive power on unseen pairs of numbers as training\nprogresses. We also show that this is a robust effect, also present when\naveraging many simulations. This work emphasizes the importance that neural\nnetwork architecture has for the emergence of catastrophic forgetting and\nintroduces a neural network that is able to learn an algorithm.",
          "link": "http://arxiv.org/abs/2108.03940",
          "publishedOn": "2022-04-30T01:01:35.056Z",
          "wordCount": null,
          "title": "Model architecture can transform catastrophic forgetting into positive transfer. (arXiv:2108.03940v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05745",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Neidhardt_M/0/1/0/all/0/1\">Maximilian Neidhardt</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bengs_M/0/1/0/all/0/1\">Marcel Bengs</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Latus_S/0/1/0/all/0/1\">Sarah Latus</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gerlach_S/0/1/0/all/0/1\">Stefan Gerlach</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cyron_C/0/1/0/all/0/1\">Christian J. Cyron</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sprenger_J/0/1/0/all/0/1\">Johanna Sprenger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schlaefer_A/0/1/0/all/0/1\">Alexander Schlaefer</a>",
          "description": "Ultrasound shear wave elasticity imaging is a valuable tool for quantifying\nthe elastic properties of tissue. Typically, the shear wave velocity is derived\nand mapped to an elasticity value, which neglects information such as the shape\nof the propagating shear wave or push sequence characteristics. We present 3D\nspatio-temporal CNNs for fast local elasticity estimation from ultrasound data.\nThis approach is based on retrieving elastic properties from shear wave\npropagation within small local regions. A large training data set is acquired\nwith a robot from homogeneous gelatin phantoms ranging from 17.42 kPa to 126.05\nkPa with various push locations. The results show that our approach can\nestimate elastic properties on a pixelwise basis with a mean absolute error of\n5.01+-4.37 kPa. Furthermore, we estimate local elasticity independent of the\npush location and can even perform accurate estimates inside the push region.\nFor phantoms with embedded inclusions, we report a 53.93% lower MAE (7.50 kPa)\nand on the background of 85.24% (1.64 kPa) compared to a conventional shear\nwave method. Overall, our method offers fast local estimations of elastic\nproperties with small spatio-temporal window sizes.",
          "link": "http://arxiv.org/abs/2204.05745",
          "publishedOn": "2022-04-30T01:01:35.056Z",
          "wordCount": null,
          "title": "Ultrasound Shear Wave Elasticity Imaging with Spatio-Temporal Deep Learning. (arXiv:2204.05745v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhecan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Codella_N/0/1/0/all/0/1\">Noel Codella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Luowei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xiyang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Bin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1\">Haoxuan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shih-fu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lu Yuan</a>",
          "description": "Cross-modal encoders for vision-language (VL) tasks are often pretrained with\ncarefully curated vision-language datasets. While these datasets reach an order\nof 10 million samples, the labor cost is prohibitive to scale further.\nConversely, unimodal encoders are pretrained with simpler annotations that are\nless cost-prohibitive, achieving scales of hundreds of millions to billions. As\na result, unimodal encoders have achieved state-of-art (SOTA) on many\ndownstream tasks. However, challenges remain when applying to VL tasks. The\npretraining data is not optimal for cross-modal architectures and requires\nheavy computational resources. In addition, unimodal architectures lack\ncross-modal interactions that have demonstrated significant benefits for VL\ntasks. Therefore, how to best leverage pretrained unimodal encoders for VL\ntasks is still an area of active research. In this work, we propose a method to\nleverage unimodal vision and text encoders for VL tasks that augment existing\nVL approaches while conserving computational complexity. Specifically, we\npropose Multimodal Adaptive Distillation (MAD), which adaptively distills\nuseful knowledge from pretrained encoders to cross-modal VL encoders. Second,\nto better capture nuanced impacts on VL task performance, we introduce an\nevaluation protocol that includes Visual Commonsense Reasoning (VCR), Visual\nEntailment (SNLI-VE), and Visual Question Answering (VQA), across a variety of\ndata constraints and conditions of domain shift. Experiments demonstrate that\nMAD leads to consistent gains in the low-shot, domain-shifted, and\nfully-supervised conditions on VCR, SNLI-VE, and VQA, achieving SOTA\nperformance on VCR compared to other single models pretrained with image-text\ndata. Finally, MAD outperforms concurrent works utilizing pretrained vision\nencoder from CLIP. Code will be made available.",
          "link": "http://arxiv.org/abs/2204.10496",
          "publishedOn": "2022-04-30T01:01:35.055Z",
          "wordCount": null,
          "title": "Multimodal Adaptive Distillation for Leveraging Unimodal Encoders for Vision-Language Tasks. (arXiv:2204.10496v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.06771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yunpeng Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_G/0/1/0/all/0/1\">Guoliang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_X/0/1/0/all/0/1\">Xinwen Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu Liu</a>",
          "description": "Recent years have witnessed the great success of multi-agent systems (MAS).\nValue decomposition, which decomposes joint action values into individual\naction values, has been an important work in MAS. However, many value\ndecomposition methods ignore the coordination among different agents, leading\nto the notorious \"lazy agents\" problem. To enhance the coordination in MAS,\nthis paper proposes HyperGraph CoNvolution MIX (HGCN-MIX), a method that\nincorporates hypergraph convolution with value decomposition. HGCN-MIX models\nagents as well as their relationships as a hypergraph, where agents are nodes\nand hyperedges among nodes indicate that the corresponding agents can\ncoordinate to achieve larger rewards. Then, it trains a hypergraph that can\ncapture the collaborative relationships among agents. Leveraging the learned\nhypergraph to consider how other agents' observations and actions affect their\ndecisions, the agents in a MAS can better coordinate. We evaluate HGCN-MIX in\nthe StarCraft II multi-agent challenge benchmark. The experimental results\ndemonstrate that HGCN-MIX can train joint policies that outperform or achieve a\nsimilar level of performance as the current state-of-the-art techniques. We\nalso observe that HGCN-MIX has an even more significant improvement of\nperformance in the scenarios with a large amount of agents. Besides, we conduct\nadditional analysis to emphasize that when the hypergraph learns more\nrelationships, HGCN-MIX can train stronger joint policies.",
          "link": "http://arxiv.org/abs/2112.06771",
          "publishedOn": "2022-04-30T01:01:35.052Z",
          "wordCount": null,
          "title": "Cooperative Multi-Agent Reinforcement Learning with Hypergraph Convolution. (arXiv:2112.06771v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13574",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1\">Talhat Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_K/0/1/0/all/0/1\">Kashif Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_J/0/1/0/all/0/1\">Jebran Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_I/0/1/0/all/0/1\">Imran Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_N/0/1/0/all/0/1\">Nasir Ahmad</a>",
          "description": "Prediction of a machine's Remaining Useful Life (RUL) is one of the key tasks\nin predictive maintenance. The task is treated as a regression problem where\nMachine Learning (ML) algorithms are used to predict the RUL of machine\ncomponents. These ML algorithms are generally used as a black box with a total\nfocus on the performance without identifying the potential causes behind the\nalgorithms' decisions and their working mechanism. We believe, the performance\n(in terms of Mean Squared Error (MSE), etc.,) alone is not enough to build the\ntrust of the stakeholders in ML prediction rather more insights on the causes\nbehind the predictions are needed. To this aim, in this paper, we explore the\npotential of Explainable AI (XAI) techniques by proposing an explainable\nregression framework for the prediction of machines' RUL. We also evaluate\nseveral ML algorithms including classical and Neural Networks (NNs) based\nsolutions for the task. For the explanations, we rely on two model agnostic XAI\nmethods namely Local Interpretable Model-Agnostic Explanations (LIME) and\nShapley Additive Explanations (SHAP). We believe, this work will provide a\nbaseline for future research in the domain.",
          "link": "http://arxiv.org/abs/2204.13574",
          "publishedOn": "2022-04-30T01:01:35.046Z",
          "wordCount": null,
          "title": "An Explainable Regression Framework for Predicting Remaining Useful Life of Machines. (arXiv:2204.13574v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.00408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Mengzhou Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1\">Zexuan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>",
          "description": "The growing size of neural language models has led to increased attention in\nmodel compression. The two predominant approaches are pruning, which gradually\nremoves weights from a pre-trained model, and distillation, which trains a\nsmaller compact model to match a larger one. Pruning methods can significantly\nreduce the model size but hardly achieve large speedups as distillation.\nHowever, distillation methods require large amounts of unlabeled data and are\nexpensive to train. In this work, we propose a task-specific structured pruning\nmethod CoFi (Coarse- and Fine-grained Pruning), which delivers highly\nparallelizable subnetworks and matches the distillation methods in both\naccuracy and latency, without resorting to any unlabeled data. Our key insight\nis to jointly prune coarse-grained (e.g., layers) and fine-grained (e.g., heads\nand hidden units) modules, which controls the pruning decision of each\nparameter with masks of different granularity. We also devise a layerwise\ndistillation strategy to transfer knowledge from unpruned to pruned models\nduring optimization. Our experiments on GLUE and SQuAD datasets show that CoFi\nyields models with over 10x speedups with a small accuracy drop, showing its\neffectiveness and efficiency compared to previous pruning and distillation\napproaches.",
          "link": "http://arxiv.org/abs/2204.00408",
          "publishedOn": "2022-04-30T01:01:34.994Z",
          "wordCount": null,
          "title": "Structured Pruning Learns Compact and Accurate Models. (arXiv:2204.00408v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.01188",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Arefeen_Y/0/1/0/all/0/1\">Yamin Arefeen</a> (1), <a href=\"http://arxiv.org/find/eess/1/au:+Beker_O/0/1/0/all/0/1\">Onur Beker</a> (2), <a href=\"http://arxiv.org/find/eess/1/au:+Cho_J/0/1/0/all/0/1\">Jaejin Cho</a> (3), <a href=\"http://arxiv.org/find/eess/1/au:+Yu_H/0/1/0/all/0/1\">Heng Yu</a> (4), <a href=\"http://arxiv.org/find/eess/1/au:+Adalsteinsson_E/0/1/0/all/0/1\">Elfar Adalsteinsson</a> (1 and 5 and 6), <a href=\"http://arxiv.org/find/eess/1/au:+Bilgic_B/0/1/0/all/0/1\">Berkin Bilgic</a> (3 and 5 and 7) ((1) Massachusetts Institute of Technology, (2) &#xc9;cole Polytechnique F&#xe9;d&#xe9;rale de Lausanne, (3) Athinoula A. Martinos Center for Biomedical Imaging (4) Tsinghua University, (5) Harvard-MIT Health Sciences and Technology, (6) Institute for Medical Engineering and Science, (7) Harvard Medical School)",
          "description": "Purpose: To develop a scan-specific model that estimates and corrects k-space\nerrors made when reconstructing accelerated Magnetic Resonance Imaging (MRI)\ndata.\n\nMethods: Scan-Specific Artifact Reduction in k-space (SPARK) trains a\nconvolutional-neural-network to estimate and correct k-space errors made by an\ninput reconstruction technique by back-propagating from the mean-squared-error\nloss between an auto-calibration signal (ACS) and the input technique's\nreconstructed ACS. First, SPARK is applied to GRAPPA and demonstrates improved\nrobustness over other scan-specific models, such as RAKI and residual-RAKI.\nSubsequent experiments demonstrate that SPARK synergizes with residual-RAKI to\nimprove reconstruction performance. SPARK also improves reconstruction quality\nwhen applied to advanced acquisition and reconstruction techniques like 2D\nvirtual coil (VC-) GRAPPA, 2D LORAKS, 3D GRAPPA without an integrated ACS\nregion, and 2D/3D wave-encoded images.\n\nResults: SPARK yields 1.5x - 2x RMSE reduction when applied to GRAPPA and\nimproves robustness to ACS size for various acceleration rates in comparison to\nother scan-specific techniques. When applied to advanced reconstruction\ntechniques such as residual-RAKI, 2D VC-GRAPPA and LORAKS, SPARK achieves up to\n20% RMSE improvement. SPARK with 3D GRAPPA also improves performance by ~2x and\nperceived image quality without a fully sampled ACS region. Finally, SPARK\nsynergizes with non-cartesian 2D and 3D wave-encoding imaging by reducing RMSE\nbetween 20-25% and providing qualitative improvements.\n\nConclusion: SPARK synergizes with physics-based acquisition and\nreconstruction techniques to improve accelerated MRI by training scan-specific\nmodels to estimate and correct reconstruction errors in k-space.",
          "link": "http://arxiv.org/abs/2104.01188",
          "publishedOn": "2022-04-30T01:01:34.993Z",
          "wordCount": null,
          "title": "Scan Specific Artifact Reduction in K-space (SPARK) Neural Networks Synergize with Physics-based Reconstruction to Accelerate MRI. (arXiv:2104.01188v3 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haug_J/0/1/0/all/0/1\">Johannes Haug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tramountani_E/0/1/0/all/0/1\">Effi Tramountani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1\">Gjergji Kasneci</a>",
          "description": "Due to the unspecified and dynamic nature of data streams, online machine\nlearning requires powerful and flexible solutions. However, evaluating online\nmachine learning methods under realistic conditions is difficult. Existing work\ntherefore often draws on different heuristics and simulations that do not\nnecessarily produce meaningful and reliable results. Indeed, in the absence of\ncommon evaluation standards, it often remains unclear how online learning\nmethods will perform in practice or in comparison to similar work. In this\npaper, we propose a comprehensive set of properties for high-quality machine\nlearning in evolving data streams. In particular, we discuss sensible\nperformance measures and evaluation strategies for online predictive modelling,\nonline feature selection and concept drift detection. As one of the first\nworks, we also look at the interpretability of online learning methods. The\nproposed evaluation standards are provided in a new Python framework called\nfloat. Float is completely modular and allows the simultaneous integration of\ncommon libraries, such as scikit-multiflow or river, with custom code. Float is\nopen-sourced and can be accessed at https://github.com/haugjo/float. In this\nsense, we hope that our work will contribute to more standardized, reliable and\nrealistic testing and comparison of online machine learning methods.",
          "link": "http://arxiv.org/abs/2204.13625",
          "publishedOn": "2022-04-30T01:01:34.969Z",
          "wordCount": null,
          "title": "Standardized Evaluation of Machine Learning Methods for Evolving Data Streams. (arXiv:2204.13625v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barbar_M/0/1/0/all/0/1\">Marc Barbar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallapragada_D/0/1/0/all/0/1\">Dharik S. Mallapragada</a>",
          "description": "Power sector capacity expansion models (CEMs) that are used for studying\nfuture low-carbon grid scenarios must incorporate detailed representation of\ngrid operations. Often CEMs are formulated to model grid operations over\nrepresentative periods that are sampled from the original input data using\nclustering algorithms. However, such representative period selection (RPS)\nmethods are limited by the declining efficacy of the clustering algorithm with\nincreasing dimensionality of the input data and do not consider the relative\nimportance of input data variations on CEM outcomes. Here, we propose a RPS\nmethod that addresses these limitations by incorporating dimensionality\nreduction, accomplished via neural network based autoencoders, prior to\nclustering. Such dimensionality reduction not only improves the performance of\nthe clustering algorithm, but also facilitates using additional features, such\nas estimated outputs produced from parallel solutions of simplified versions of\nthe CEM for each disjoint period in the input data (e.g. 1 week). The impact of\nincorporating dimensionality reduction as part of RPS methods is quantified\nthrough the error in outcomes of the corresponding reduced-space CEM vs. the\nfull space CEM. Extensive numerical experimentation across various networks and\nrange of technology and policy scenarios establish the superiority of the\ndimensionality-reduction based RPS methods.",
          "link": "http://arxiv.org/abs/2204.13608",
          "publishedOn": "2022-04-30T01:01:34.965Z",
          "wordCount": null,
          "title": "Representative period selection for power system planning using autoencoder-based dimensionality reduction. (arXiv:2204.13608v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Linfeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingzhi Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1\">Robin Walters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1\">Lawson L.S. Wong</a>",
          "description": "Compositional generalization is a critical ability in learning and\ndecision-making. We focus on the setting of reinforcement learning in\nobject-oriented environments to study compositional generalization in world\nmodeling. We (1) formalize the compositional generalization problem with an\nalgebraic approach and (2) study how a world model can achieve that. We\nintroduce a conceptual environment, Object Library, and two instances, and\ndeploy a principled pipeline to measure the generalization ability. Motivated\nby the formulation, we analyze several methods with exact} or no compositional\ngeneralization ability using our framework, and design a differentiable\napproach, Homomorphic Object-oriented World Model (HOWM), that achieves\napproximate but more efficient compositional generalization.",
          "link": "http://arxiv.org/abs/2204.13661",
          "publishedOn": "2022-04-30T01:01:34.958Z",
          "wordCount": null,
          "title": "Toward Compositional Generalization in Object-Oriented World Modeling. (arXiv:2204.13661v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaofeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Feng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Rui Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaokang Yang</a>",
          "description": "Scalability is an important consideration for deep graph neural networks.\nInspired by the conventional pooling layers in CNNs, many recent graph learning\napproaches have introduced the pooling strategy to reduce the size of graphs\nfor learning, such that the scalability and efficiency can be improved.\nHowever, these pooling-based methods are mainly tailored to a single\ngraph-level task and pay more attention to local information, limiting their\nperformance in multi-task settings which often require task-specific global\ninformation. In this paper, departure from these pooling-based efforts, we\ndesign a new approach called DOTIN (\\underline{D}r\\underline{o}pping\n\\underline{T}ask-\\underline{I}rrelevant \\underline{N}odes) to reduce the size\nof graphs. Specifically, by introducing $K$ learnable virtual nodes to\nrepresent the graph embeddings targeted to $K$ different graph-level tasks,\nrespectively, up to 90\\% raw nodes with low attentiveness with an attention\nmodel -- a transformer in this paper, can be adaptively dropped without notable\nperformance decreasing. Achieving almost the same accuracy, our method speeds\nup GAT by about 50\\% on graph-level tasks including graph classification and\ngraph edit distance (GED) with about 60\\% less memory, on D\\&D dataset. Code\nwill be made publicly available in https://github.com/Sherrylone/DOTIN.",
          "link": "http://arxiv.org/abs/2204.13429",
          "publishedOn": "2022-04-30T01:01:34.949Z",
          "wordCount": null,
          "title": "DOTIN: Dropping Task-Irrelevant Nodes for GNNs. (arXiv:2204.13429v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13582",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adkins_D/0/1/0/all/0/1\">David Adkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alsallakh_B/0/1/0/all/0/1\">Bilal Alsallakh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheema_A/0/1/0/all/0/1\">Adeel Cheema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokhlikyan_N/0/1/0/all/0/1\">Narine Kokhlikyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McReynolds_E/0/1/0/all/0/1\">Emily McReynolds</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1\">Pushkar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Procope_C/0/1/0/all/0/1\">Chavez Procope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawruk_J/0/1/0/all/0/1\">Jeremy Sawruk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1\">Erin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zvyagina_P/0/1/0/all/0/1\">Polina Zvyagina</a>",
          "description": "Specialized documentation techniques have been developed to communicate key\nfacts about machine-learning (ML) systems and the datasets and models they rely\non. Techniques such as Datasheets, FactSheets, and Model Cards have taken a\nmainly descriptive approach, providing various details about the system\ncomponents. While the above information is essential for product developers and\nexternal experts to assess whether the ML system meets their requirements,\nother stakeholders might find it less actionable. In particular, ML engineers\nneed guidance on how to mitigate potential shortcomings in order to fix bugs or\nimprove the system's performance. We survey approaches that aim to provide such\nguidance in a prescriptive way. We further propose a preliminary approach,\ncalled Method Cards, which aims to increase the transparency and\nreproducibility of ML systems by providing prescriptive documentation of\ncommonly-used ML methods and techniques. We showcase our proposal with an\nexample in small object detection, and demonstrate how Method Cards can\ncommunicate key considerations for model developers. We further highlight\navenues for improving the user experience of ML engineers based on Method\nCards.",
          "link": "http://arxiv.org/abs/2204.13582",
          "publishedOn": "2022-04-30T01:01:34.940Z",
          "wordCount": null,
          "title": "Prescriptive and Descriptive Approaches to Machine-Learning Transparency. (arXiv:2204.13582v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shang_X/0/1/0/all/0/1\">Xinyi Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hanzi Wang</a>",
          "description": "Federated learning (FL) provides a privacy-preserving solution for\ndistributed machine learning tasks. One challenging problem that severely\ndamages the performance of FL models is the co-occurrence of data heterogeneity\nand long-tail distribution, which frequently appears in real FL applications.\nIn this paper, we reveal an intriguing fact that the biased classifier is the\nprimary factor leading to the poor performance of the global model. Motivated\nby the above finding, we propose a novel and privacy-preserving FL method for\nheterogeneous and long-tailed data via Classifier Re-training with Federated\nFeatures (CReFF). The classifier re-trained on federated features can produce\ncomparable performance as the one re-trained on real data in a\nprivacy-preserving manner without information leakage of local data or class\ndistribution. Experiments on several benchmark datasets show that the proposed\nCReFF is an effective solution to obtain a promising FL model under\nheterogeneous and long-tailed data. Comparative results with the\nstate-of-the-art FL methods also validate the superiority of CReFF. Our code is\navailable at https://github.com/shangxinyi/CReFF-FL.",
          "link": "http://arxiv.org/abs/2204.13399",
          "publishedOn": "2022-04-30T01:01:34.939Z",
          "wordCount": null,
          "title": "Federated Learning on Heterogeneous and Long-Tailed Data via Classifier Re-Training with Federated Features. (arXiv:2204.13399v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yufei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xunzhao Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_C/0/1/0/all/0/1\">Cheng Zhuo</a>",
          "description": "Worst-case dynamic PDN noise analysis is an essential step in PDN sign-off to\nensure the performance and reliability of chips. However, with the growing PDN\nsize and increasing scenarios to be validated, it becomes very time- and\nresource-consuming to conduct full-stack PDN simulation to check the worst-case\nnoise for different test vectors. Recently, various works have proposed machine\nlearning based methods for supply noise prediction, many of which still suffer\nfrom large training overhead, inefficiency, or non-scalability. Thus, this\npaper proposed an efficient and scalable framework for the worst-case dynamic\nPDN noise prediction. The framework first reduces the spatial and temporal\nredundancy in the PDN and input current vector, and then employs efficient\nfeature extraction as well as a novel convolutional neural network architecture\nto predict the worst-case dynamic PDN noise. Experimental results show that the\nproposed framework consistently outperforms the commercial tool and the\nstate-of-the-art machine learning method with only 0.63-1.02% mean relative\nerror and 25-69$\\times$ speedup.",
          "link": "http://arxiv.org/abs/2204.13109",
          "publishedOn": "2022-04-30T01:01:34.938Z",
          "wordCount": null,
          "title": "Worst-Case Dynamic Power Distribution Network Noise Prediction Using Convolutional Neural Network. (arXiv:2204.13109v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramaiah_C/0/1/0/all/0/1\">Chetan Ramaiah</a>",
          "description": "Current contrastive learning frameworks focus on leveraging a single\nsupervisory signal to learn representations, which limits the efficacy on\nunseen data and downstream tasks. In this paper, we present a hierarchical\nmulti-label representation learning framework that can leverage all available\nlabels and preserve the hierarchical relationship between classes. We introduce\nnovel hierarchy preserving losses, which jointly apply a hierarchical penalty\nto the contrastive loss, and enforce the hierarchy constraint. The loss\nfunction is data driven and automatically adapts to arbitrary multi-label\nstructures. Experiments on several datasets show that our\nrelationship-preserving embedding performs well on a variety of tasks and\noutperform the baseline supervised and self-supervised approaches. Code is\navailable at https://github.com/salesforce/hierarchicalContrastiveLearning.",
          "link": "http://arxiv.org/abs/2204.13207",
          "publishedOn": "2022-04-30T01:01:34.935Z",
          "wordCount": null,
          "title": "Use All The Labels: A Hierarchical Multi-Label Contrastive Learning Framework. (arXiv:2204.13207v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13209",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fabiani_F/0/1/0/all/0/1\">Filippo Fabiani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goulart_P/0/1/0/all/0/1\">Paul J. Goulart</a>",
          "description": "We consider the design of reliable neural network (NN)-based approximations\nof traditional stabilizing controllers for linear systems affected by polytopic\nuncertainty, including controllers with variable structure and those based on a\nminimal selection policy. We develop a systematic procedure to certify the\nclosed-loop stability and performance of a polytopic system when a rectified\nlinear unit (ReLU)-based approximation replaces such traditional controllers.\nWe provide sufficient conditions to ensure stability involving the worst-case\napproximation error and the Lipschitz constant characterizing the error\nfunction between ReLU-based and traditional controller-based state-to-input\nmappings, and further provide offline, mixed-integer optimization-based methods\nthat allow us to compute those quantities exactly.",
          "link": "http://arxiv.org/abs/2204.13209",
          "publishedOn": "2022-04-30T01:01:34.935Z",
          "wordCount": null,
          "title": "Neural network controllers for uncertain linear systems. (arXiv:2204.13209v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.01742",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Davidson_S/0/1/0/all/0/1\">Scot Davidson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McCallan_N/0/1/0/all/0/1\">Niamh McCallan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ng_K/0/1/0/all/0/1\">Kok Yew Ng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Biglarbeigi_P/0/1/0/all/0/1\">Pardis Biglarbeigi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Finlay_D/0/1/0/all/0/1\">Dewar Finlay</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lan_B/0/1/0/all/0/1\">Boon Leong Lan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McLaughlin_J/0/1/0/all/0/1\">James McLaughlin</a>",
          "description": "Epilepsy affects 50 million people worldwide and is one of the most common\nserious neurological disorders. Seizure detection and classification is a\nvaluable tool for diagnosing and maintaining the condition. An automated\nclassification algorithm will allow for accurate diagnosis. Utilising the\nTemple University Hospital (TUH) Seizure Corpus, six seizure types are\ncompared; absence, complex partial, myoclonic, simple partial, tonic and tonic-\nclonic models. This study proposes a method that utilises unique features with\na novel parallel classifier - Parallel Genetic Naive Bayes (NB) Seizure\nClassifier (PGNBSC). The PGNBSC algorithm searches through the features and by\nreclassifying the data each time, the algorithm will create a matrix for\noptimum search criteria. Ictal states from the EEGs are segmented into 1.8 s\nwindows, where the epochs are then further decomposed into 13 different\nfeatures from the first intrinsic mode function (IMF). The features are\ncompared using an original NB classifier in the first model. This is improved\nupon in a second model by using a genetic algorithm (Binary Grey Wolf\nOptimisation, Option 1) with a NB classifier. The third model uses a\ncombination of the simple partial and complex partial seizures to provide the\nhighest classification accuracy for each of the six seizures amongst the three\nmodels (20%, 53%, and 85% for first, second, and third model, respectively).",
          "link": "http://arxiv.org/abs/2110.01742",
          "publishedOn": "2022-04-30T01:01:34.930Z",
          "wordCount": null,
          "title": "Epileptic Seizure Classification Using Combined Labels and a Genetic Algorithm. (arXiv:2110.01742v4 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Sin Kit Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1\">Qinghua Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paik_H/0/1/0/all/0/1\">Hye-Young Paik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Liming Zhu</a>",
          "description": "Federated learning is growing fast in both academia and industry to resolve\ndata hungriness and privacy issues in machine learning. A federated learning\nsystem being widely distributed with different components and stakeholders\nrequires software system design thinking. For instance, multiple patterns and\ntactics have been summarised by researchers that cover various aspects, from\nclient management, training configuration, model deployment, etc. However, the\nmultitude of patterns leaves the designers confused about when and which\npattern to adopt or adapt. Therefore, in this paper, we present a set of\ndecision models to assist designers and architects who have limited knowledge\nin federated learning, in selecting architectural patterns for federated\nlearning architecture design. Each decision model maps functional and\nnon-functional requirements of federated learning systems to a set of patterns.\nwe also clarify the trade-offs that may be implicit in the patterns. We\nevaluated the decision model through a set of interviews with practitioners to\nassess the correctness and usefulness in guiding the architecture design\nprocess through various design decision options.",
          "link": "http://arxiv.org/abs/2204.13291",
          "publishedOn": "2022-04-30T01:01:34.929Z",
          "wordCount": null,
          "title": "A Decision Model for Federated Learning Architecture Pattern Selection. (arXiv:2204.13291v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hazami_L/0/1/0/all/0/1\">Louay Hazami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mama_R/0/1/0/all/0/1\">Rayhane Mama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thurairatnam_R/0/1/0/all/0/1\">Ragavan Thurairatnam</a>",
          "description": "Hierarchical VAEs have emerged in recent years as a reliable option for\nmaximum likelihood estimation. However, instability issues and demanding\ncomputational requirements have hindered research progress in the area. We\npresent simple modifications to the Very Deep VAE to make it converge up to\n$2.6\\times$ faster, save up to $20\\times$ in memory load and improve stability\nduring training. Despite these changes, our models achieve comparable or better\nnegative log-likelihood performance than current state-of-the-art models on all\n$7$ commonly used image datasets we evaluated on. We also make an argument\nagainst using 5-bit benchmarks as a way to measure hierarchical VAE's\nperformance due to undesirable biases caused by the 5-bit quantization.\nAdditionally, we empirically demonstrate that roughly $3\\%$ of the hierarchical\nVAE's latent space dimensions is sufficient to encode most of the image\ninformation, without loss of performance, opening up the doors to efficiently\nleverage the hierarchical VAEs' latent space in downstream tasks. We release\nour source code and models at https://github.com/Rayhane-mamah/Efficient-VDVAE .",
          "link": "http://arxiv.org/abs/2203.13751",
          "publishedOn": "2022-04-30T01:01:34.926Z",
          "wordCount": null,
          "title": "Efficient-VDVAE: Less is more. (arXiv:2203.13751v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Soydaner_D/0/1/0/all/0/1\">Derya Soydaner</a>",
          "description": "A long time ago in the machine learning literature, the idea of incorporating\na mechanism inspired by the human visual system into neural networks was\nintroduced. This idea is named the attention mechanism, and it has gone through\na long development period. Today, many works have been devoted to this idea in\na variety of tasks. Remarkable performance has recently been demonstrated. The\ngoal of this paper is to provide an overview from the early work on searching\nfor ways to implement attention idea with neural networks until the recent\ntrends. This review emphasizes the important milestones during this progress\nregarding different tasks. By this way, this study aims to provide a road map\nfor researchers to explore the current development and get inspired for novel\napproaches beyond the attention.",
          "link": "http://arxiv.org/abs/2204.13154",
          "publishedOn": "2022-04-30T01:01:34.925Z",
          "wordCount": null,
          "title": "Attention Mechanism in Neural Networks: Where it Comes and Where it Goes. (arXiv:2204.13154v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.11727",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zhiyuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zihan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clausen_T/0/1/0/all/0/1\">Thomas Clausen</a>",
          "description": "This paper presents the network load balancing problem, a challenging\nreal-world task for multi-agent reinforcement learning (MARL) methods.\nTraditional heuristic solutions like Weighted-Cost Multi-Path (WCMP) and Local\nShortest Queue (LSQ) are less flexible to the changing workload distributions\nand arrival rates, with a poor balance among multiple load balancers. The\ncooperative network load balancing task is formulated as a Dec-POMDP problem,\nwhich naturally induces the MARL methods. To bridge the reality gap for\napplying learning-based methods, all methods are directly trained and evaluated\non an emulation system from moderate-to large-scale. Experiments on realistic\ntestbeds show that the independent and \"selfish\" load balancing strategies are\nnot necessarily the globally optimal ones, while the proposed MARL solution has\na superior performance over different realistic settings. Additionally, the\npotential difficulties of MARL methods for network load balancing are analysed,\nwhich helps to draw the attention of the learning and network communities to\nsuch challenges.",
          "link": "http://arxiv.org/abs/2201.11727",
          "publishedOn": "2022-04-30T01:01:34.921Z",
          "wordCount": null,
          "title": "Multi-Agent Reinforcement Learning for Network Load Balancing in Data Center. (arXiv:2201.11727v3 [cs.DC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11383",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shang_X/0/1/0/all/0/1\">Xiaoxiao Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhiyuan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1\">Qiming Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Sabiq Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lauren Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yi Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_S/0/1/0/all/0/1\">Subramaniam Vincent</a>",
          "description": "Professional news media organizations have always touted the importance that\nthey give to multiple perspectives. However, in practice the traditional\napproach to all-sides has favored people in the dominant culture. Hence it has\ncome under ethical critique under the new norms of diversity, equity, and\ninclusion (DEI). When DEI is applied to journalism, it goes beyond conventional\nnotions of impartiality and bias and instead democratizes the journalistic\npractice of sourcing -- who is quoted or interviewed, who is not, how often,\nfrom which demographic group, gender, and so forth. There is currently no\nreal-time or on-demand tool in the hands of reporters to analyze the persons\nthey quote. In this paper, we present DIANES, a DEI Audit Toolkit for News\nSources. It consists of a natural language processing pipeline on the backend\nto extract quotes, speakers, titles, and organizations from news articles in\nreal time. On the frontend, DIANES offers the WordPress plugins, a Web monitor,\nand a DEI annotation API service, to help news media monitor their own quoting\npatterns and push themselves towards DEI norms.",
          "link": "http://arxiv.org/abs/2203.11383",
          "publishedOn": "2022-04-30T01:01:34.921Z",
          "wordCount": null,
          "title": "DIANES: A DEI Audit Toolkit for News Sources. (arXiv:2203.11383v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arzamasov_V/0/1/0/all/0/1\">Vadim Arzamasov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jochum_B/0/1/0/all/0/1\">Benjamin Jochum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohm_K/0/1/0/all/0/1\">Klemens B&#xf6;hm</a>",
          "description": "Machine-learning models are ubiquitous. In some domains, for instance, in\nmedicine, the models' predictions must be interpretable. Decision trees,\nclassification rules, and subgroup discovery are three broad categories of\nsupervised machine-learning models presenting knowledge in the form of\ninterpretable rules. The accuracy of these models learned from small datasets\nis usually low. Obtaining larger datasets is often hard to impossible.\nPedagogical rule extraction methods could help to learn better rules from small\ndata by augmenting a dataset employing statistical models and using it to learn\na rule-based model. However, existing evaluation of these methods is often\ninconclusive, and they were not compared so far. Our framework PRELIM unifies\nexisting pedagogical rule extraction techniques. In the extensive experiments,\nwe identified promising PRELIM configurations not studied before.",
          "link": "http://arxiv.org/abs/2112.13285",
          "publishedOn": "2022-04-30T01:01:34.919Z",
          "wordCount": null,
          "title": "Pedagogical Rule Extraction to Learn Interpretable Models - an Empirical Study. (arXiv:2112.13285v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.11295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Donghua Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Maoyin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_X/0/1/0/all/0/1\">Xia Hong</a>",
          "description": "In this paper, a novel multimode dynamic process monitoring approach is\nproposed by extending elastic weight consolidation (EWC) to probabilistic slow\nfeature analysis (PSFA) in order to extract multimode slow features for online\nmonitoring. EWC was originally introduced in the setting of machine learning of\nsequential multi-tasks with the aim of avoiding catastrophic forgetting issue,\nwhich equally poses as a major challenge in multimode dynamic process\nmonitoring. When a new mode arrives, a set of data should be collected so that\nthis mode can be identified by PSFA and prior knowledge. Then, a regularization\nterm is introduced to prevent new data from significantly interfering with the\nlearned knowledge, where the parameter importance measures are estimated. The\nproposed method is denoted as PSFA-EWC, which is updated continually and\ncapable of achieving excellent performance for successive modes. Different from\ntraditional multimode monitoring algorithms, PSFA-EWC furnishes backward and\nforward transfer ability. The significant features of previous modes are\nretained while consolidating new information, which may contribute to learning\nnew relevant modes. Compared with several known methods, the effectiveness of\nthe proposed method is demonstrated via a continuous stirred tank heater and a\npractical coal pulverizing system.",
          "link": "http://arxiv.org/abs/2202.11295",
          "publishedOn": "2022-04-30T01:01:34.919Z",
          "wordCount": null,
          "title": "Continual learning-based probabilistic slow feature analysis for multimode dynamic process monitoring. (arXiv:2202.11295v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.05120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1\">Ainesh Bakshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clarkson_K/0/1/0/all/0/1\">Kenneth L. Clarkson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "We study iterative methods based on Krylov subspaces for low-rank\napproximation under any Schatten-$p$ norm. Here, given access to a matrix $A$\nthrough matrix-vector products, an accuracy parameter $\\epsilon$, and a target\nrank $k$, the goal is to find a rank-$k$ matrix $Z$ with orthonormal columns\nsuch that $\\| A(I -ZZ^\\top)\\|_{S_p} \\leq (1+\\epsilon)\\min_{U^\\top U = I_k}\n\\|A(I - U U^\\top)\\|_{S_p}$, where $\\|M\\|_{S_p}$ denotes the $\\ell_p$ norm of\nthe the singular values of $M$. For the special cases of $p=2$ (Frobenius norm)\nand $p = \\infty$ (Spectral norm), Musco and Musco (NeurIPS 2015) obtained an\nalgorithm based on Krylov methods that uses $\\tilde{O}(k/\\sqrt{\\epsilon})$\nmatrix-vector products, improving on the na\\\"ive $\\tilde{O}(k/\\epsilon)$\ndependence obtainable by the power method, where $\\tilde{O}$ suppresses\npoly$(\\log(dk/\\epsilon))$ factors.\n\nOur main result is an algorithm that uses only\n$\\tilde{O}(kp^{1/6}/\\epsilon^{1/3})$ matrix-vector products, and works for all\n$p \\geq 1$. For $p = 2$ our bound improves the previous\n$\\tilde{O}(k/\\epsilon^{1/2})$ bound to $\\tilde{O}(k/\\epsilon^{1/3})$. Since the\nSchatten-$p$ and Schatten-$\\infty$ norms are the same up to a $1+ \\epsilon$\nfactor when $p \\geq (\\log d)/\\epsilon$, our bound recovers the result of Musco\nand Musco for $p = \\infty$. Further, we prove a matrix-vector query lower bound\nof $\\Omega(1/\\epsilon^{1/3})$ for any fixed constant $p \\geq 1$, showing that\nsurprisingly $\\tilde{\\Theta}(1/\\epsilon^{1/3})$ is the optimal complexity for\nconstant~$k$.\n\nTo obtain our results, we introduce several new techniques, including\noptimizing over multiple Krylov subspaces simultaneously, and pinching\ninequalities for partitioned operators. Our lower bound for $p \\in [1,2]$ uses\nthe Araki-Lieb-Thirring trace inequality, whereas for $p>2$, we appeal to a\nnorm-compression inequality for aligned partitioned operators.",
          "link": "http://arxiv.org/abs/2202.05120",
          "publishedOn": "2022-04-30T01:01:34.909Z",
          "wordCount": null,
          "title": "Low-Rank Approximation with $1/\\epsilon^{1/3}$ Matrix-Vector Products. (arXiv:2202.05120v2 [cs.DS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07884",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhou_M/0/1/0/all/0/1\">Min-Gang Zhou</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cao_X/0/1/0/all/0/1\">Xiao-Yu Cao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lu_Y/0/1/0/all/0/1\">Yu-Shuo Lu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Bao_Y/0/1/0/all/0/1\">Yu Bao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jia_Z/0/1/0/all/0/1\">Zhao-Ying Jia</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Fu_Y/0/1/0/all/0/1\">Yao Fu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Yin_H/0/1/0/all/0/1\">Hua-Lei Yin</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Chen_Z/0/1/0/all/0/1\">Zeng-Bing Chen</a>",
          "description": "An increasing number of communication and computational schemes with quantum\nadvantages have recently been proposed, which implies that quantum technology\nhas fertile application prospects. However, demonstrating these schemes\nexperimentally continues to be a central challenge because of the difficulty in\npreparing high-dimensional states or highly entangled states. In this study, we\nintroduce and analyse a quantum coupon collector protocol by employing coherent\nstates and simple linear optical elements, which was successfully demonstrated\nusing realistic experimental equipment. We showed that our protocol can\nsignificantly reduce the number of samples needed to learn a specific set\ncompared with the classical limit of the coupon collector problem. We also\ndiscuss the potential values and expansions of the quantum coupon collector by\nconstructing a quantum blind box game. The information transmitted by the\nproposed game also broke the classical limit. These results strongly prove the\nadvantages of quantum mechanics in machine learning and communication\ncomplexity.",
          "link": "http://arxiv.org/abs/2112.07884",
          "publishedOn": "2022-04-30T01:01:34.904Z",
          "wordCount": null,
          "title": "Experimental quantum advantage with quantum coupon collector. (arXiv:2112.07884v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guoqiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niwa_K/0/1/0/all/0/1\">Kenta Niwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleijn_W/0/1/0/all/0/1\">W. Bastiaan Kleijn</a>",
          "description": "Adam and AdaBelief compute and make use of elementwise adaptive stepsizes in\ntraining deep neural networks (DNNs) by tracking the exponential moving average\n(EMA) of the squared-gradient g_t^2 and the squared prediction error\n(m_t-g_t)^2, respectively, where m_t is the first momentum at iteration t and\ncan be viewed as a prediction of g_t. In this work, we investigate if layerwise\ngradient statistics can be expoited in Adam and AdaBelief to allow for more\neffective training of DNNs. We address the above research question in two\nsteps. Firstly, we slightly modify Adam and AdaBelief by introducing layerwise\nadaptive stepsizes in their update procedures via either pre- or\npost-processing. Our empirical results indicate that the slight modification\nproduces comparable performance for training VGG and ResNet models over CIFAR10\nand CIFAR100, suggesting that layer-wise gradient statistics play an important\nrole towards the success of Adam and AdaBelief for at least certian DNN tasks.\nIn the second step, we propose Aida, a new optimisation method, with the\nobjective that the elementwise stepsizes within each layer have significantly\nsmaller statistical variances, and the layerwise average stepsizes are much\nmore compact across all the layers. Motivated by the fact that (m_t-g_t)^2 in\nAdaBelief is conservative in comparison to g_t^2 in Adam in terms of layerwise\nstatistical averages and variances, Aida is designed by tracking a more\nconservative function of m_t and g_t than (m_t-g_t)^2 via layerwise vector\nprojections. Experimental results show that Aida produces either competitive or\nbetter performance with respect to a number of existing methods including Adam\nand AdaBelief for a set of challenging DNN tasks.",
          "link": "http://arxiv.org/abs/2203.13273",
          "publishedOn": "2022-04-30T01:01:34.904Z",
          "wordCount": null,
          "title": "On Exploiting Layerwise Gradient Statistics for Effective Training of Deep Neural Networks. (arXiv:2203.13273v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.15380",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Infante_G/0/1/0/all/0/1\">Guillermo Infante</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonsson_A/0/1/0/all/0/1\">Anders Jonsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_V/0/1/0/all/0/1\">Vicen&#xe7; G&#xf3;mez</a>",
          "description": "In this work we present a novel approach to hierarchical reinforcement\nlearning for linearly-solvable Markov decision processes. Our approach assumes\nthat the state space is partitioned, and the subtasks consist in moving between\nthe partitions. We represent value functions on several levels of abstraction,\nand use the compositionality of subtasks to estimate the optimal values of the\nstates in each partition. The policy is implicitly defined on these optimal\nvalue estimates, rather than being decomposed among the subtasks. As a\nconsequence, our approach can learn the globally optimal policy, and does not\nsuffer from the non-stationarity of high-level decisions. If several partitions\nhave equivalent dynamics, the subtasks of those partitions can be shared. If\nthe set of boundary states is smaller than the entire state space, our approach\ncan have significantly smaller sample complexity than that of a flat learner,\nand we validate this empirically in several experiments.",
          "link": "http://arxiv.org/abs/2106.15380",
          "publishedOn": "2022-04-30T01:01:34.901Z",
          "wordCount": null,
          "title": "Globally Optimal Hierarchical Reinforcement Learning for Linearly-Solvable Markov Decision Processes. (arXiv:2106.15380v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.16223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leplat_V/0/1/0/all/0/1\">Valentin Leplat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gillis_N/0/1/0/all/0/1\">Nicolas Gillis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Idier_J/0/1/0/all/0/1\">J&#xe9;r&#xf4;me Idier</a>",
          "description": "Nonnegative matrix factorization (NMF) is the problem of approximating an\ninput nonnegative matrix, $V$, as the product of two smaller nonnegative\nmatrices, $W$ and $H$. In this paper, we introduce a general framework to\ndesign multiplicative updates (MU) for NMF based on $\\beta$-divergences\n($\\beta$-NMF) with disjoint equality constraints, and with penalty terms in the\nobjective function. By disjoint, we mean that each variable appears in at most\none equality constraint. Our MU satisfy the set of constraints after each\nupdate of the variables during the optimization process, while guaranteeing\nthat the objective function decreases monotonically. We showcase this framework\non three NMF models, and show that it competes favorably the state of the art:\n(1)~$\\beta$-NMF with sum-to-one constraints on the columns of $H$, (2)\nminimum-volume $\\beta$-NMF with sum-to-one constraints on the columns of $W$,\nand (3) sparse $\\beta$-NMF with $\\ell_2$-norm constraints on the columns of\n$W$.",
          "link": "http://arxiv.org/abs/2010.16223",
          "publishedOn": "2022-04-30T01:01:34.895Z",
          "wordCount": null,
          "title": "Multiplicative Updates for NMF with $\\beta$-Divergences under Disjoint Equality Constraints. (arXiv:2010.16223v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_E/0/1/0/all/0/1\">Eric R. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Connor Z. Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_M/0/1/0/all/0/1\">Matthew A. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagano_K/0/1/0/all/0/1\">Koki Nagano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_B/0/1/0/all/0/1\">Boxiao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mello_S/0/1/0/all/0/1\">Shalini De Mello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallo_O/0/1/0/all/0/1\">Orazio Gallo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas Guibas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tremblay_J/0/1/0/all/0/1\">Jonathan Tremblay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khamis_S/0/1/0/all/0/1\">Sameh Khamis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karras_T/0/1/0/all/0/1\">Tero Karras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wetzstein_G/0/1/0/all/0/1\">Gordon Wetzstein</a>",
          "description": "Unsupervised generation of high-quality multi-view-consistent images and 3D\nshapes using only collections of single-view 2D photographs has been a\nlong-standing challenge. Existing 3D GANs are either compute-intensive or make\napproximations that are not 3D-consistent; the former limits quality and\nresolution of the generated images and the latter adversely affects multi-view\nconsistency and shape quality. In this work, we improve the computational\nefficiency and image quality of 3D GANs without overly relying on these\napproximations. We introduce an expressive hybrid explicit-implicit network\narchitecture that, together with other design choices, synthesizes not only\nhigh-resolution multi-view-consistent images in real time but also produces\nhigh-quality 3D geometry. By decoupling feature generation and neural\nrendering, our framework is able to leverage state-of-the-art 2D CNN\ngenerators, such as StyleGAN2, and inherit their efficiency and expressiveness.\nWe demonstrate state-of-the-art 3D-aware synthesis with FFHQ and AFHQ Cats,\namong other experiments.",
          "link": "http://arxiv.org/abs/2112.07945",
          "publishedOn": "2022-04-30T01:01:34.892Z",
          "wordCount": null,
          "title": "Efficient Geometry-aware 3D Generative Adversarial Networks. (arXiv:2112.07945v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.09871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thompson_R/0/1/0/all/0/1\">Rylee Thompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knyazev_B/0/1/0/all/0/1\">Boris Knyazev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghalebi_E/0/1/0/all/0/1\">Elahe Ghalebi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jungtaek Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1\">Graham W. Taylor</a>",
          "description": "In image generation, generative models can be evaluated naturally by visually\ninspecting model outputs. However, this is not always the case for graph\ngenerative models (GGMs), making their evaluation challenging. Currently, the\nstandard process for evaluating GGMs suffers from three critical limitations:\ni) it does not produce a single score which makes model selection challenging,\nii) in many cases it fails to consider underlying edge and node features, and\niii) it is prohibitively slow to perform. In this work, we mitigate these\nissues by searching for scalar, domain-agnostic, and scalable metrics for\nevaluating and ranking GGMs. To this end, we study existing GGM metrics and\nneural-network-based metrics emerging from generative models of images that use\nembeddings extracted from a task-specific network. Motivated by the power of\ncertain Graph Neural Networks (GNNs) to extract meaningful graph\nrepresentations without any training, we introduce several metrics based on the\nfeatures extracted by an untrained random GNN. We design experiments to\nthoroughly test metrics on their ability to measure the diversity and fidelity\nof generated graphs, as well as their sample and computational efficiency.\nDepending on the quantity of samples, we recommend one of two random-GNN-based\nmetrics that we show to be more expressive than pre-existing metrics. While we\nfocus on applying these metrics to GGM evaluation, in practice this enables the\nability to easily compute the dissimilarity between any two sets of graphs\nregardless of domain. Our code is released at:\nhttps://github.com/uoguelph-mlrg/GGM-metrics.",
          "link": "http://arxiv.org/abs/2201.09871",
          "publishedOn": "2022-04-30T01:01:34.890Z",
          "wordCount": null,
          "title": "On Evaluation Metrics for Graph Generative Models. (arXiv:2201.09871v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.05922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meding_K/0/1/0/all/0/1\">Kristof Meding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buschoff_L/0/1/0/all/0/1\">Luca M. Schulze Buschoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geirhos_R/0/1/0/all/0/1\">Robert Geirhos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wichmann_F/0/1/0/all/0/1\">Felix A. Wichmann</a>",
          "description": "\"The power of a generalization system follows directly from its biases\"\n(Mitchell 1980). Today, CNNs are incredibly powerful generalisation systems --\nbut to what degree have we understood how their inductive bias influences model\ndecisions? We here attempt to disentangle the various aspects that determine\nhow a model decides. In particular, we ask: what makes one model decide\ndifferently from another? In a meticulously controlled setting, we find that\n(1.) irrespective of the network architecture or objective (e.g.\nself-supervised, semi-supervised, vision transformers, recurrent models) all\nmodels end up with a similar decision boundary. (2.) To understand these\nfindings, we analysed model decisions on the ImageNet validation set from epoch\nto epoch and image by image. We find that the ImageNet validation set, among\nothers, suffers from dichotomous data difficulty (DDD): For the range of\ninvestigated models and their accuracies, it is dominated by 46.0% \"trivial\"\nand 11.5% \"impossible\" images (beyond label errors). Only 42.5% of the images\ncould possibly be responsible for the differences between two models' decision\nboundaries. (3.) Only removing the \"impossible\" and \"trivial\" images allows us\nto see pronounced differences between models. (4.) Humans are highly accurate\nat predicting which images are \"trivial\" and \"impossible\" for CNNs (81.4%).\nThis implies that in future comparisons of brains, machines and behaviour, much\nmay be gained from investigating the decisive role of images and the\ndistribution of their difficulties.",
          "link": "http://arxiv.org/abs/2110.05922",
          "publishedOn": "2022-04-30T01:01:34.889Z",
          "wordCount": null,
          "title": "Trivial or impossible -- dichotomous data difficulty masks model differences (on ImageNet and beyond). (arXiv:2110.05922v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.12657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiavazzi_D/0/1/0/all/0/1\">Daniele E. Schiavazzi</a>",
          "description": "Fast inference of numerical model parameters from data is an important\nprerequisite to generate predictive models for a wide range of applications.\nUse of sampling-based approaches such as Markov chain Monte Carlo may become\nintractable when each likelihood evaluation is computationally expensive. New\napproaches combining variational inference with normalizing flow are\ncharacterized by a computational cost that grows only linearly with the\ndimensionality of the latent variable space, and rely on gradient-based\noptimization instead of sampling, providing a more efficient approach for\nBayesian inference about the model parameters. Moreover, the cost of frequently\nevaluating an expensive likelihood can be mitigated by replacing the true model\nwith an offline trained surrogate model, such as neural networks. However, this\napproach might generate significant bias when the surrogate is insufficiently\naccurate around the posterior modes. To reduce the computational cost without\nsacrificing inferential accuracy, we propose Normalizing Flow with Adaptive\nSurrogate (NoFAS), an optimization strategy that alternatively updates the\nnormalizing flow parameters and surrogate model parameters. We also propose an\nefficient sample weighting scheme for surrogate model training that preserves\nglobal accuracy while effectively capturing high posterior density regions. We\ndemonstrate the inferential and computational superiority of NoFAS against\nvarious benchmarks, including cases where the underlying model lacks\nidentifiability. The source code and numerical experiments used for this study\nare available at https://github.com/cedricwangyu/NoFAS.",
          "link": "http://arxiv.org/abs/2108.12657",
          "publishedOn": "2022-04-30T01:01:34.885Z",
          "wordCount": null,
          "title": "Variational Inference with NoFAS: Normalizing Flow with Adaptive Surrogate for Computationally Expensive Models. (arXiv:2108.12657v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.01052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Angelopoulos_A/0/1/0/all/0/1\">Anastasios N. Angelopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bates_S/0/1/0/all/0/1\">Stephen Bates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candes_E/0/1/0/all/0/1\">Emmanuel J. Cand&#xe8;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_L/0/1/0/all/0/1\">Lihua Lei</a>",
          "description": "We introduce a framework for calibrating machine learning models so that\ntheir predictions satisfy explicit, finite-sample statistical guarantees. Our\ncalibration algorithm works with any underlying model and (unknown)\ndata-generating distribution and does not require model refitting. The\nframework addresses, among other examples, false discovery rate control in\nmulti-label classification, intersection-over-union control in instance\nsegmentation, and the simultaneous control of the type-1 error of outlier\ndetection and confidence set coverage in classification or regression. Our main\ninsight is to reframe the risk-control problem as multiple hypothesis testing,\nenabling techniques and mathematical arguments different from those in the\nprevious literature. We use our framework to provide new calibration methods\nfor several core machine learning tasks with detailed worked examples in\ncomputer vision and tabular medical data.",
          "link": "http://arxiv.org/abs/2110.01052",
          "publishedOn": "2022-04-30T01:01:34.884Z",
          "wordCount": null,
          "title": "Learn then Test: Calibrating Predictive Algorithms to Achieve Risk Control. (arXiv:2110.01052v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.06081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_F/0/1/0/all/0/1\">Feng-Lei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mengzhou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_R/0/1/0/all/0/1\">Rongjie Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Ge Wang</a>",
          "description": "Inspired by the diversity of biological neurons, quadratic artificial neurons\ncan play an important role in deep learning models. The type of quadratic\nneurons of our interest replaces the inner-product operation in the\nconventional neuron with a quadratic function. Despite promising results so far\nachieved by networks of quadratic neurons, there are important issues not well\naddressed. Theoretically, the superior expressivity of a quadratic network over\neither a conventional network or a conventional network via quadratic\nactivation is not fully elucidated, which makes the use of quadratic networks\nnot well grounded. Practically, although a quadratic network can be trained via\ngeneric backpropagation, it can be subject to a higher risk of collapse than\nthe conventional counterpart. To address these issues, we first apply the\nspline theory and a measure from algebraic geometry to give two theorems that\ndemonstrate better model expressivity of a quadratic network than the\nconventional counterpart with or without quadratic activation. Then, we propose\nan effective and efficient training strategy referred to as ReLinear to\nstabilize the training process of a quadratic network, thereby unleashing the\nfull potential in its associated machine learning tasks. Comprehensive\nexperiments on popular datasets are performed to support our findings and\nevaluate the performance of quadratic deep learning.",
          "link": "http://arxiv.org/abs/2110.06081",
          "publishedOn": "2022-04-30T01:01:34.882Z",
          "wordCount": null,
          "title": "On Expressivity and Trainability of Quadratic Networks. (arXiv:2110.06081v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.04825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kushnareva_L/0/1/0/all/0/1\">Laida Kushnareva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cherniavskii_D/0/1/0/all/0/1\">Daniil Cherniavskii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikhailov_V/0/1/0/all/0/1\">Vladislav Mikhailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artemova_E/0/1/0/all/0/1\">Ekaterina Artemova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barannikov_S/0/1/0/all/0/1\">Serguei Barannikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernstein_A/0/1/0/all/0/1\">Alexander Bernstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piontkovskaya_I/0/1/0/all/0/1\">Irina Piontkovskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piontkovski_D/0/1/0/all/0/1\">Dmitri Piontkovski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>",
          "description": "The impressive capabilities of recent generative models to create texts that\nare challenging to distinguish from the human-written ones can be misused for\ngenerating fake news, product reviews, and even abusive content. Despite the\nprominent performance of existing methods for artificial text detection, they\nstill lack interpretability and robustness towards unseen models. To this end,\nwe propose three novel types of interpretable topological features for this\ntask based on Topological Data Analysis (TDA) which is currently understudied\nin the field of NLP. We empirically show that the features derived from the\nBERT model outperform count- and neural-based baselines up to 10\\% on three\ncommon datasets, and tend to be the most robust towards unseen GPT-style\ngeneration models as opposed to existing methods. The probing analysis of the\nfeatures reveals their sensitivity to the surface and syntactic properties. The\nresults demonstrate that TDA is a promising line with respect to NLP tasks,\nspecifically the ones that incorporate surface and structural information.",
          "link": "http://arxiv.org/abs/2109.04825",
          "publishedOn": "2022-04-30T01:01:34.844Z",
          "wordCount": null,
          "title": "Artificial Text Detection via Examining the Topology of Attention Maps. (arXiv:2109.04825v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2004.13316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1\">Wenlong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaokang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tao He</a>",
          "description": "Small and cluttered objects are common in real-world which are challenging\nfor detection. The difficulty is further pronounced when the objects are\nrotated, as traditional detectors often routinely locate the objects in\nhorizontal bounding box such that the region of interest is contaminated with\nbackground or nearby interleaved objects. In this paper, we first innovatively\nintroduce the idea of denoising to object detection. Instance-level denoising\non the feature map is performed to enhance the detection to small and cluttered\nobjects. To handle the rotation variation, we also add a novel IoU constant\nfactor to the smooth L1 loss to address the long standing boundary problem,\nwhich to our analysis, is mainly caused by the periodicity of angular (PoA) and\nexchangeability of edges (EoE). By combing these two features, our proposed\ndetector is termed as SCRDet++. Extensive experiments are performed on large\naerial images public datasets DOTA, DIOR, UCAS-AOD as well as natural image\ndataset COCO, scene text dataset ICDAR2015, small traffic light dataset BSTLD\nand our released S$^2$TLD by this paper. The results show the effectiveness of\nour approach. The released dataset S2TLD is made public available, which\ncontains 5,786 images with 14,130 traffic light instances across five\ncategories.",
          "link": "http://arxiv.org/abs/2004.13316",
          "publishedOn": "2022-04-30T01:01:34.825Z",
          "wordCount": null,
          "title": "SCRDet++: Detecting Small, Cluttered and Rotated Objects via Instance-Level Feature Denoising and Rotation Loss Smoothing. (arXiv:2004.13316v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13338",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hirano_M/0/1/0/all/0/1\">Masanori Hirano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakaji_H/0/1/0/all/0/1\">Hiroki Sakaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izumi_K/0/1/0/all/0/1\">Kiyoshi Izumi</a>",
          "description": "This study proposes a new generative adversarial network (GAN) for generating\nrealistic orders in financial markets. In some previous works, GANs for\nfinancial markets generated fake orders in continuous spaces because of GAN\narchitectures' learning limitations. However, in reality, the orders are\ndiscrete, such as order prices, which has minimum order price unit, or order\ntypes. Thus, we change the generation method to place the generated fake orders\ninto discrete spaces in this study. Because this change disabled the ordinary\nGAN learning algorithm, this study employed a policy gradient, frequently used\nin reinforcement learning, for the learning algorithm. Through our experiments,\nwe show that our proposed model outperforms previous models in generated order\ndistribution. As an additional benefit of introducing the policy gradient, the\nentropy of the generated policy can be used to check GAN's learning status. In\nthe future, higher performance GANs, better evaluation methods, or the\napplications of our GANs can be addressed.",
          "link": "http://arxiv.org/abs/2204.13338",
          "publishedOn": "2022-04-30T01:01:34.815Z",
          "wordCount": null,
          "title": "Policy Gradient Stock GAN for Realistic Discrete Order Data Generation in Financial Markets. (arXiv:2204.13338v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.12471",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lim_K/0/1/0/all/0/1\">Katherine S. Lim</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Reidenbach_A/0/1/0/all/0/1\">Andrew G. Reidenbach</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hua_B/0/1/0/all/0/1\">Bruce K. Hua</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mason_J/0/1/0/all/0/1\">Jeremy W. Mason</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gerry_C/0/1/0/all/0/1\">Christopher J. Gerry</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Clemons_P/0/1/0/all/0/1\">Paul A. Clemons</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Coley_C/0/1/0/all/0/1\">Connor W. Coley</a>",
          "description": "DNA-encoded library (DEL) screening and quantitative structure-activity\nrelationship (QSAR) modeling are two techniques used in drug discovery to find\nsmall molecules that bind a protein target. Applying QSAR modeling to DEL data\ncan facilitate the selection of compounds for off-DNA synthesis and evaluation.\nSuch a combined approach has been shown recently by training binary classifiers\nto learn DEL enrichments of aggregated \"disynthons\" to accommodate the sparse\nand noisy nature of DEL data. However, a binary classifier cannot distinguish\nbetween different levels of enrichment, and information is potentially lost\nduring disynthon aggregation. Here, we demonstrate a regression approach to\nlearning DEL enrichments of individual molecules using a custom negative\nlog-likelihood loss function that effectively denoises DEL data and introduces\nopportunities for visualization of learned structure-activity relationships\n(SAR). Our approach explicitly models the Poisson statistics of the sequencing\nprocess used in the DEL experimental workflow under a frequentist view. We\nillustrate this approach on a dataset of 108k compounds screened against CAIX,\nand a dataset of 5.7M compounds screened against sEH and SIRT2. Due to the\ntreatment of uncertainty in the data through the negative log-likelihood loss\nfunction, the models can ignore low-confidence outliers. While our approach\ndoes not demonstrate a benefit for extrapolation to novel structures, we expect\nour denoising and visualization pipeline to be useful in identifying SAR trends\nand enriched pharmacophores in DEL data. Further, this approach to\nuncertainty-aware regression is applicable to other sparse or noisy datasets\nwhere the nature of stochasticity is known or can be modeled; in particular,\nthe Poisson enrichment ratio metric we use can apply to other settings that\ncompare sequencing count data between two experimental conditions.",
          "link": "http://arxiv.org/abs/2108.12471",
          "publishedOn": "2022-04-30T01:01:34.813Z",
          "wordCount": null,
          "title": "Machine learning on DNA-encoded library count data using an uncertainty-aware probabilistic loss function. (arXiv:2108.12471v2 [q-bio.QM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.13113",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Romain_D/0/1/0/all/0/1\">Djoumbissie David Romain</a>",
          "description": "We propose a unified multi-tasking framework to represent the complex and\nuncertain causal process of financial market dynamics, and then to predict the\nmovement of any type of index with an application on the monthly direction of\nthe S&P500 index. our solution is based on three main pillars: (i) the use of\ntransfer learning to share knowledge and feature (representation, learning)\nbetween all financial markets, increase the size of the training sample and\npreserve the stability between training, validation and test sample. (ii) The\ncombination of multidisciplinary knowledge (Financial economics, behavioral\nfinance, market microstructure and portfolio construction theories) to\nrepresent a global top-down dynamics of any financial market, through a graph.\n(iii) The integration of forward looking unstructured data, different types of\ncontexts (long, medium and short term) through latent variables/nodes and then,\nuse a unique VAE network (parameter sharing) to learn simultaneously their\ndistributional representation. We obtain Accuracy, F1-score, and Matthew\nCorrelation of 74.3 %, 67 % and 0.42 above the industry and other benchmark on\n12 years test period which include three unstable and difficult sub-period to\npredict.",
          "link": "http://arxiv.org/abs/2011.13113",
          "publishedOn": "2022-04-30T01:01:34.802Z",
          "wordCount": null,
          "title": "Predicting S&P500 Index direction with Transfer Learning and a Causal Graph as main Input. (arXiv:2011.13113v3 [q-fin.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_Z/0/1/0/all/0/1\">Zhang-Wei Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Ge Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Pulkit Agrawal</a>",
          "description": "The dominant framework for off-policy multi-goal reinforcement learning\ninvolves estimating goal conditioned Q-value function. When learning to achieve\nmultiple goals, data efficiency is intimately connected with the generalization\nof the Q-function to new goals. The de-facto paradigm is to approximate Q(s, a,\ng) using monolithic neural networks. To improve the generalization of the\nQ-function, we propose a bilinear decomposition that represents the Q-value via\na low-rank approximation in the form of a dot product between two vector\nfields. The first vector field, f(s, a), captures the environment's local\ndynamics at the state s; whereas the second component, {\\phi}(s, g), captures\nthe global relationship between the current state and the goal. We show that\nour bilinear decomposition scheme substantially improves data efficiency, and\nhas superior transfer to out-of-distribution goals compared to prior methods.\nEmpirical evidence is provided on the simulated Fetch robot task-suite and\ndexterous manipulation with a Shadow hand.",
          "link": "http://arxiv.org/abs/2204.13695",
          "publishedOn": "2022-04-30T01:01:34.801Z",
          "wordCount": null,
          "title": "Bilinear value networks. (arXiv:2204.13695v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scheiermann_J/0/1/0/all/0/1\">Johannes Scheiermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konen_W/0/1/0/all/0/1\">Wolfgang Konen</a>",
          "description": "Recently, the seminal algorithms AlphaGo and AlphaZero have started a new era\nin game learning and deep reinforcement learning. While the achievements of\nAlphaGo and AlphaZero - playing Go and other complex games at super human level\n- are truly impressive, these architectures have the drawback that they are\nvery complex and require high computational resources. Many researchers are\nlooking for methods that are similar to AlphaZero, but have lower computational\ndemands and are thus more easily reproducible. In this paper, we pick an\nimportant element of AlphaZero - the Monte Carlo Tree Search (MCTS) planning\nstage - and combine it with reinforcement learning (RL) agents. We wrap MCTS\nfor the first time around RL n-tuple networks to create versatile agents that\nkeep at the same time the computational demands low. We apply this new\narchitecture to several complex games (Othello, ConnectFour, Rubik's Cube) and\nshow the advantages achieved with this AlphaZero-inspired MCTS wrapper. In\nparticular, we present results that this AlphaZero-inspired agent is the first\none trained on standard hardware (no GPU or TPU) to beat the very strong\nOthello program Edax up to and including level 7 (where most other algorithms\ncould only defeat Edax up to level 2).",
          "link": "http://arxiv.org/abs/2204.13307",
          "publishedOn": "2022-04-30T01:01:34.784Z",
          "wordCount": null,
          "title": "AlphaZero-Inspired General Board Game Learning and Playing. (arXiv:2204.13307v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.05165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ludtke_S/0/1/0/all/0/1\">Stefan L&#xfc;dtke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartelt_C/0/1/0/all/0/1\">Christian Bartelt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stuckenschmidt_H/0/1/0/all/0/1\">Heiner Stuckenschmidt</a>",
          "description": "Sum-Product Networks (SPNs) are expressive probabilistic models that provide\nexact, tractable inference. They achieve this efficiency by making use of local\nindependence. On the other hand, mixtures of exchangeable variable models\n(MEVMs) are a class of tractable probabilistic models that make use of\nexchangeability of discrete random variables to render inference tractable.\nExchangeability, which arises naturally in relational domains, has not been\nconsidered for efficient representation and inference in SPNs yet. The\ncontribution of this paper is a novel probabilistic model which we call\nExchangeability-Aware Sum-Product Networks (XSPNs). It contains both SPNs and\nMEVMs as special cases, and combines the ability of SPNs to efficiently learn\ndeep probabilistic models with the ability of MEVMs to efficiently handle\nexchangeable random variables. We introduce a structure learning algorithm for\nXSPNs and empirically show that they can be more accurate than conventional\nSPNs when the data contains repeated, interchangeable parts.",
          "link": "http://arxiv.org/abs/2110.05165",
          "publishedOn": "2022-04-30T01:01:34.780Z",
          "wordCount": null,
          "title": "Exchangeability-Aware Sum-Product Networks. (arXiv:2110.05165v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13587",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Brunhuemer_A/0/1/0/all/0/1\">Alexander Brunhuemer</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Larcher_L/0/1/0/all/0/1\">Lukas Larcher</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Seidl_P/0/1/0/all/0/1\">Philipp Seidl</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Desmettre_S/0/1/0/all/0/1\">Sascha Desmettre</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Kofler_J/0/1/0/all/0/1\">Johannes Kofler</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Larcher_G/0/1/0/all/0/1\">Gerhard Larcher</a>",
          "description": "In this working paper we present our current progress in the training of\nmachine learning models to execute short option strategies on the S&P500. As a\nfirst step, this paper is breaking this problem down to a supervised\nclassification task to decide if a short straddle on the S&P500 should be\nexecuted or not on a daily basis. We describe our used framework and present an\noverview over our evaluation metrics on different classification models. In\nthis preliminary work, using standard machine learning techniques and without\nhyperparameter search, we find no statistically significant outperformance to a\nsimple \"trade always\" strategy, but gain additional insights on how we could\nproceed in further experiments.",
          "link": "http://arxiv.org/abs/2204.13587",
          "publishedOn": "2022-04-30T01:01:34.773Z",
          "wordCount": null,
          "title": "Supervised machine learning classification for short straddles on the S&P500. (arXiv:2204.13587v1 [q-fin.CP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1905.10395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1\">Yunfei Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wenbo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalus_F/0/1/0/all/0/1\">Francois Chalus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanska_A/0/1/0/all/0/1\">Anna Choromanska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldfarb_D/0/1/0/all/0/1\">Donald Goldfarb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "We consider distributed optimization under communication constraints for\ntraining deep learning models. We propose a new algorithm, whose parameter\nupdates rely on two forces: a regular gradient step, and a corrective direction\ndictated by the currently best-performing worker (leader). Our method differs\nfrom the parameter-averaging scheme EASGD in a number of ways: (i) our\nobjective formulation does not change the location of stationary points\ncompared to the original optimization problem; (ii) we avoid convergence\ndecelerations caused by pulling local workers descending to different local\nminima to each other (i.e. to the average of their parameters); (iii) our\nupdate by design breaks the curse of symmetry (the phenomenon of being trapped\nin poorly generalizing sub-optimal solutions in symmetric non-convex\nlandscapes); and (iv) our approach is more communication efficient since it\nbroadcasts only parameters of the leader rather than all workers. We provide\ntheoretical analysis of the batch version of the proposed algorithm, which we\ncall Leader Gradient Descent (LGD), and its stochastic variant (LSGD). Finally,\nwe implement an asynchronous version of our algorithm and extend it to the\nmulti-leader setting, where we form groups of workers, each represented by its\nown local leader (the best performer in a group), and update each worker with a\ncorrective direction comprised of two attractive forces: one to the local, and\none to the global leader (the best performer among all workers). The\nmulti-leader setting is well-aligned with current hardware architecture, where\nlocal workers forming a group lie within a single computational node and\ndifferent groups correspond to different nodes. For training convolutional\nneural networks, we empirically demonstrate that our approach compares\nfavorably to state-of-the-art baselines. This work is a gentle extension of\n[2].",
          "link": "http://arxiv.org/abs/1905.10395",
          "publishedOn": "2022-04-30T01:01:34.772Z",
          "wordCount": null,
          "title": "Leader Stochastic Gradient Descent for Distributed Training of Deep Learning Models: Extension. (arXiv:1905.10395v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.12581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1\">Yunfei Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanska_A/0/1/0/all/0/1\">Anna Choromanska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1\">Murray Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Songtao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1\">Parikshit Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horesh_L/0/1/0/all/0/1\">Lior Horesh</a>",
          "description": "This paper studies a new design of the optimization algorithm for training\ndeep learning models with a fixed architecture of the classification network in\na continual learning framework. The training data is non-stationary and the\nnon-stationarity is imposed by a sequence of distinct tasks. We first analyze a\ndeep model trained on only one learning task in isolation and identify a region\nin network parameter space, where the model performance is close to the\nrecovered optimum. We provide empirical evidence that this region resembles a\ncone that expands along the convergence direction. We study the principal\ndirections of the trajectory of the optimizer after convergence and show that\ntraveling along a few top principal directions can quickly bring the parameters\noutside the cone but this is not the case for the remaining directions. We\nargue that catastrophic forgetting in a continual learning setting can be\nalleviated when the parameters are constrained to stay within the intersection\nof the plausible cones of individual tasks that were so far encountered during\ntraining. Based on this observation we present our direction-constrained\noptimization (DCO) method, where for each task we introduce a linear\nautoencoder to approximate its corresponding top forbidden principal\ndirections. They are then incorporated into the loss function in the form of a\nregularization term for the purpose of learning the coming tasks without\nforgetting. Furthermore, in order to control the memory growth as the number of\ntasks increases, we propose a memory-efficient version of our algorithm called\ncompressed DCO (DCO-COMP) that allocates a memory of fixed size for storing all\nautoencoders. We empirically demonstrate that our algorithm performs favorably\ncompared to other state-of-art regularization-based continual learning methods.",
          "link": "http://arxiv.org/abs/2011.12581",
          "publishedOn": "2022-04-30T01:01:34.770Z",
          "wordCount": null,
          "title": "Overcoming Catastrophic Forgetting via Direction-Constrained Optimization. (arXiv:2011.12581v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matero_M/0/1/0/all/0/1\">Matthew Matero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hung_A/0/1/0/all/0/1\">Albert Hung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1\">H. Andrew Schwartz</a>",
          "description": "Recent works have demonstrated ability to assess aspects of mental health\nfrom personal discourse. At the same time, pre-trained contextual word\nembedding models have grown to dominate much of NLP but little is known\nempirically on how to best apply them for mental health assessment. Using\ndegree of depression as a case study, we do an empirical analysis on which\noff-the-shelf language model, individual layers, and combinations of layers\nseem most promising when applied to human-level NLP tasks. Notably, we find\nRoBERTa most effective and, despite the standard in past work suggesting the\nsecond-to-last or concatenation of the last 4 layers, we find layer 19\n(sixth-to last) is at least as good as layer 23 when using 1 layer. Further,\nwhen using multiple layers, distributing them across the second half (i.e.\nLayers 12+), rather than last 4, of the 24 layers yielded the most accurate\nresults.",
          "link": "http://arxiv.org/abs/2112.13795",
          "publishedOn": "2022-04-30T01:01:34.765Z",
          "wordCount": null,
          "title": "Evaluating Contextual Embeddings and their Extraction Layers for Depression Assessment. (arXiv:2112.13795v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nowroozi_E/0/1/0/all/0/1\">Ehsan Nowroozi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abhishek/0/1/0/all/0/1\">Abhishek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_M/0/1/0/all/0/1\">Mohammadreza Mohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1\">Mauro Conti</a>",
          "description": "Malicious advertisement URLs pose a security risk since they are the source\nof cyber-attacks, and the need to address this issue is growing in both\nindustry and academia. Generally, the attacker delivers an attack vector to the\nuser by means of an email, an advertisement link or any other means of\ncommunication and directs them to a malicious website to steal sensitive\ninformation and to defraud them. Existing malicious URL detection techniques\nare limited and to handle unseen features as well as generalize to test data.\nIn this study, we extract a novel set of lexical and web-scrapped features and\nemploy machine learning technique to set up system for fraudulent advertisement\nURLs detection. The combination set of six different kinds of features\nprecisely overcome the obfuscation in fraudulent URL classification. Based on\ndifferent statistical properties, we use twelve different formatted datasets\nfor detection, prediction and classification task. We extend our prediction\nanalysis for mismatched and unlabelled datasets. For this framework, we analyze\nthe performance of four machine learning techniques: Random Forest, Gradient\nBoost, XGBoost and AdaBoost in the detection part. With our proposed method, we\ncan achieve a false negative rate as low as 0.0037 while maintaining high\naccuracy of 99.63%. Moreover, we devise a novel unsupervised technique for data\nclustering using K- Means algorithm for the visual analysis. This paper\nanalyses the vulnerability of decision tree-based models using the limited\nknowledge attack scenario. We considered the exploratory attack and implemented\nZeroth Order Optimization adversarial attack on the detection models.",
          "link": "http://arxiv.org/abs/2204.13172",
          "publishedOn": "2022-04-30T01:01:34.761Z",
          "wordCount": null,
          "title": "An Adversarial Attack Analysis on Malicious Advertisement URL Detection Framework. (arXiv:2204.13172v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.08467",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Niyas_S/0/1/0/all/0/1\">S Niyas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pawan_S/0/1/0/all/0/1\">S J Pawan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_M/0/1/0/all/0/1\">M Anand Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rajan_J/0/1/0/all/0/1\">Jeny Rajan</a>",
          "description": "Computer-aided medical image analysis plays a significant role in assisting\nmedical practitioners for expert clinical diagnosis and deciding the optimal\ntreatment plan. At present, convolutional neural networks (CNN) are the\npreferred choice for medical image analysis. In addition, with the rapid\nadvancements in three-dimensional (3D) imaging systems and the availability of\nexcellent hardware and software support to process large volumes of data, 3D\ndeep learning methods are gaining popularity in medical image analysis. Here,\nwe present an extensive review of the recently evolved 3D deep learning methods\nin medical image segmentation. Furthermore, the research gaps and future\ndirections in 3D medical image segmentation are discussed.",
          "link": "http://arxiv.org/abs/2108.08467",
          "publishedOn": "2022-04-30T01:01:34.761Z",
          "wordCount": null,
          "title": "Medical Image Segmentation with 3D Convolutional Neural Networks: A Survey. (arXiv:2108.08467v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1\">Debasrita Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Ashish Ghosh</a>",
          "description": "With the ever increasing data deluge and the success of deep neural networks,\nthe research of distributed deep learning has become pronounced. Two common\napproaches to achieve this distributed learning is synchronous and asynchronous\nweight update. In this manuscript, we have explored very simplistic synchronous\nweight update mechanisms. It has been seen that with an increasing number of\nworker nodes, the performance degrades drastically. This effect has been\nstudied in the context of extreme imbalanced classification (e.g. outlier\ndetection). In practical cases, the assumed conditions of i.i.d. may not be\nfulfilled. There may also arise global class imbalance situations like that of\noutlier detection where the local servers receive severely imbalanced data and\nmay not get any samples from the minority class. In that case, the DNNs in the\nlocal servers will get completely biased towards the majority class that they\nreceive. This would highly impact the learning at the parameter server (which\npractically does not see any data). It has been observed that in a parallel\nsetting if one uses the existing federated weight update mechanisms at the\nparameter server, the performance degrades drastically with the increasing\nnumber of worker nodes. This is mainly because, with the increasing number of\nnodes, there is a high chance that one worker node gets a very small portion of\nthe data, either not enough to train the model without overfitting or having a\nhighly imbalanced class distribution. The chapter, hence, proposes a workaround\nto this problem by introducing the concept of adaptive cost-sensitive momentum\naveraging. It is seen that for the proposed system, there was no to minimal\ndegradation in performance while most of the other methods hit their bottom\nperformance before that.",
          "link": "http://arxiv.org/abs/2204.13414",
          "publishedOn": "2022-04-30T01:01:34.727Z",
          "wordCount": null,
          "title": "Improving the Robustness of Federated Learning for Severely Imbalanced Datasets. (arXiv:2204.13414v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.10227",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Herrera_Marti_D/0/1/0/all/0/1\">David A. Herrera-Mart&#xed;</a>",
          "description": "We propose a method for finding approximate compilations of quantum unitary\ntransformations, based on techniques from policy gradient reinforcement\nlearning. The choice of a stochastic policy allows us to rephrase the\noptimization problem in terms of probability distributions, rather than\nvariational gates. In this framework, finding the optimal configuration is done\nby optimizing over distribution parameters, rather than over free angles. We\nshow numerically that this approach can be more competitive than gradient-free\nmethods, for comparable amounts of resources (i.e. quantum circuit runs).\nAnother interesting feature of this approach to variational compilation is that\nit does not need a separate register and long-range interactions to estimate\nthe end-point fidelity, which is an improvement over methods which rely on the\nHilbert-Schmidt test. We expect these techniques to be relevant for training\nvariational circuits in other contexts.",
          "link": "http://arxiv.org/abs/2111.10227",
          "publishedOn": "2022-04-30T01:01:34.715Z",
          "wordCount": null,
          "title": "Policy Gradient Approach to Compilation of Variational Quantum Circuits. (arXiv:2111.10227v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.14124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seff_A/0/1/0/all/0/1\">Ari Seff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenda Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richardson_N/0/1/0/all/0/1\">Nick Richardson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adams_R/0/1/0/all/0/1\">Ryan P. Adams</a>",
          "description": "Parametric computer-aided design (CAD) tools are the predominant way that\nengineers specify physical structures, from bicycle pedals to airplanes to\nprinted circuit boards. The key characteristic of parametric CAD is that design\nintent is encoded not only via geometric primitives, but also by parameterized\nconstraints between the elements. This relational specification can be viewed\nas the construction of a constraint program, allowing edits to coherently\npropagate to other parts of the design. Machine learning offers the intriguing\npossibility of accelerating the design process via generative modeling of these\nstructures, enabling new tools such as autocompletion, constraint inference,\nand conditional synthesis. In this work, we present such an approach to\ngenerative modeling of parametric CAD sketches, which constitute the basic\ncomputational building blocks of modern mechanical design. Our model, trained\non real-world designs from the SketchGraphs dataset, autoregressively\nsynthesizes sketches as sequences of primitives, with initial coordinates, and\nconstraints that reference back to the sampled primitives. As samples from the\nmodel match the constraint graph representation used in standard CAD software,\nthey may be directly imported, solved, and edited according to downstream\ndesign tasks. In addition, we condition the model on various contexts,\nincluding partial sketches (primers) and images of hand-drawn sketches.\nEvaluation of the proposed approach demonstrates its ability to synthesize\nrealistic CAD sketches and its potential to aid the mechanical design workflow.",
          "link": "http://arxiv.org/abs/2109.14124",
          "publishedOn": "2022-04-30T01:01:34.675Z",
          "wordCount": null,
          "title": "Vitruvion: A Generative Model of Parametric CAD Sketches. (arXiv:2109.14124v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.02574",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wen_F/0/1/0/all/0/1\">Fei Wen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yan_Z/0/1/0/all/0/1\">Zeyu Yan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_P/0/1/0/all/0/1\">Peilin Liu</a>",
          "description": "Recently, much progress has been made in unsupervised denoising learning.\nHowever, existing methods more or less rely on some assumptions on the signal\nand/or degradation model, which limits their practical performance. How to\nconstruct an optimal criterion for unsupervised denoising learning without any\nprior knowledge on the degradation model is still an open question. Toward\nanswering this question, this work proposes a criterion for unsupervised\ndenoising learning based on the optimal transport theory. This criterion has\nfavorable properties, e.g., approximately maximal preservation of the\ninformation of the signal, whilst achieving perceptual reconstruction.\nFurthermore, though a relaxed unconstrained formulation is used in practical\nimplementation, we prove that the relaxed formulation in theory has the same\nsolution as the original constrained formulation. Experiments on synthetic and\nreal-world data, including realistic photographic, microscopy, depth, and raw\ndepth images, demonstrate that the proposed method even compares favorably with\nsupervised methods, e.g., approaching the PSNR of supervised methods while\nhaving better perceptual quality. Particularly, for spatially correlated noise\nand realistic microscopy images, the proposed method not only achieves better\nperceptual quality but also has higher PSNR than supervised methods. Besides,\nit shows remarkable superiority in harsh practical conditions with complex\nnoise, e.g., raw depth images. Code is available at\nhttps://github.com/wangweiSJTU/OTUR.",
          "link": "http://arxiv.org/abs/2108.02574",
          "publishedOn": "2022-04-30T01:01:34.657Z",
          "wordCount": null,
          "title": "Optimal Transport for Unsupervised Denoising Learning. (arXiv:2108.02574v4 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.13567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yiwen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1\">Wangmeng Zuo</a>",
          "description": "With the progress in AI-based facial forgery (i.e., deepfake), people are\nincreasingly concerned about its abuse. Albeit effort has been made for\ntraining classification (also known as deepfake detection) models to recognize\nsuch forgeries, existing models suffer from poor generalization to unseen\nforgery technologies and high sensitivity to changes in image/video quality. In\nthis paper, we advocate adversarial training for improving the generalization\nability to both unseen facial forgeries and unseen image/video qualities. We\nbelieve training with samples that are adversarially crafted to attack the\nclassification models improves the generalization ability considerably.\nConsidering that AI-based face manipulation often leads to high-frequency\nartifacts that can be easily spotted by models yet difficult to generalize, we\nfurther propose a new adversarial training method that attempts to blur out\nthese specific artifacts, by introducing pixel-wise Gaussian blurring models.\nWith adversarial training, the classification models are forced to learn more\ndiscriminative and generalizable features, and the effectiveness of our method\ncan be verified by plenty of empirical evidence. Our code will be made publicly\navailable.",
          "link": "http://arxiv.org/abs/2103.13567",
          "publishedOn": "2022-04-30T01:01:34.649Z",
          "wordCount": null,
          "title": "Deepfake Forensics via An Adversarial Game. (arXiv:2103.13567v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.02513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Subramanian_S/0/1/0/all/0/1\">Sriram Ganapathi Subramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1\">Pascal Poupart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1\">Matthew E. Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hegde_N/0/1/0/all/0/1\">Nidhi Hegde</a>",
          "description": "Mean field theory provides an effective way of scaling multiagent\nreinforcement learning algorithms to environments with many agents that can be\nabstracted by a virtual mean agent. In this paper, we extend mean field\nmultiagent algorithms to multiple types. The types enable the relaxation of a\ncore assumption in mean field reinforcement learning, which is that all agents\nin the environment are playing almost similar strategies and have the same\ngoal. We conduct experiments on three different testbeds for the field of many\nagent reinforcement learning, based on the standard MAgents framework. We\nconsider two different kinds of mean field environments: a) Games where agents\nbelong to predefined types that are known a priori and b) Games where the type\nof each agent is unknown and therefore must be learned based on observations.\nWe introduce new algorithms for each type of game and demonstrate their\nsuperior performance over state of the art algorithms that assume that all\nagents belong to the same type and other baseline algorithms in the MAgent\nframework.",
          "link": "http://arxiv.org/abs/2002.02513",
          "publishedOn": "2022-04-30T01:01:34.645Z",
          "wordCount": null,
          "title": "Multi Type Mean Field Reinforcement Learning. (arXiv:2002.02513v6 [cs.MA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hanselmann_N/0/1/0/all/0/1\">Niklas Hanselmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Renz_K/0/1/0/all/0/1\">Katrin Renz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chitta_K/0/1/0/all/0/1\">Kashyap Chitta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_A/0/1/0/all/0/1\">Apratim Bhattacharyya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1\">Andreas Geiger</a>",
          "description": "Simulators offer the possibility of safe, low-cost development of\nself-driving systems. However, current driving simulators exhibit na\\\"ive\nbehavior models for background traffic. Hand-tuned scenarios are typically\nadded during simulation to induce safety-critical situations. An alternative\napproach is to adversarially perturb the background traffic trajectories. In\nthis paper, we study this approach to safety-critical driving scenario\ngeneration using the CARLA simulator. We use a kinematic bicycle model as a\nproxy to the simulator's true dynamics and observe that gradients through this\nproxy model are sufficient for optimizing the background traffic trajectories.\nBased on this finding, we propose KING, which generates safety-critical driving\nscenarios with a 20% higher success rate than black-box optimization. By\nsolving the scenarios generated by KING using a privileged rule-based expert\nalgorithm, we obtain training data for an imitation learning policy. After\nfine-tuning on this new data, we show that the policy becomes better at\navoiding collisions. Importantly, our generated data leads to reduced\ncollisions on both held-out scenarios generated via KING as well as traditional\nhand-crafted scenarios, demonstrating improved robustness.",
          "link": "http://arxiv.org/abs/2204.13683",
          "publishedOn": "2022-04-30T01:01:34.638Z",
          "wordCount": null,
          "title": "KING: Generating Safety-Critical Driving Scenarios for Robust Imitation via Kinematics Gradients. (arXiv:2204.13683v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13455",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bilski_J/0/1/0/all/0/1\">Jakub Micha&#x142; Bilski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jastrzebska_A/0/1/0/all/0/1\">Agnieszka Jastrz&#x119;bska</a>",
          "description": "Time series classification is one of the very popular machine learning tasks.\nIn this paper, we explore the application of Hidden Markov Model (HMM) for time\nseries classification. We distinguish between two modes of HMM application. The\nfirst, in which a single model is built for each class. The second, in which\none HMM is built for each time series. We then transfer both approaches for\nclassifier construction to the domain of Fuzzy Cognitive Maps. The identified\nfour models, HMM NN (HMM, one per series), HMM 1C (HMM, one per class), FCM NN,\nand FCM 1C are then studied in a series of experiments. We compare the\nperformance of different models and investigate the impact of their\nhyperparameters on the time series classification accuracy. The empirical\nevaluation shows a clear advantage of the one-model-per-series approach. The\nresults show that the choice between HMM and FCM should be dataset-dependent.",
          "link": "http://arxiv.org/abs/2204.13455",
          "publishedOn": "2022-04-30T01:01:34.635Z",
          "wordCount": null,
          "title": "Fuzzy Cognitive Maps and Hidden Markov Models: Comparative Analysis of Efficiency within the Confines of the Time Series Classification Task. (arXiv:2204.13455v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1\">Debasrita Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Susmita Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Ashish Ghosh</a>",
          "description": "Stock prices are highly volatile and sudden changes in trends are often very\nproblematic for traditional forecasting models to handle. The standard Long\nShort Term Memory (LSTM) networks are regarded as the state-of-the-art models\nfor such predictions. But, these models fail to handle sudden and drastic\nchanges in the price trend. Moreover, there are some inherent constraints with\nthe open, high, low and close (OHLC) prices of the stocks. Literature lacks the\nstudy on the inherent property of OHLC prices. We argue that predicting the\nOHLC prices for the next day is much more informative than predicting the\ntrends of the stocks as the trend is mostly calculated using these OHLC prices\nonly. The problem mainly is focused on Buy-Today Sell-Tomorrow (BTST) trading.\nIn this regard, AEs when pre-trained with the stock prices, may be beneficial.\nA novel framework is proposed where a pre-trained encoder is cascaded in front\nof the multi-task predictor network. This hybrid network can leverage the power\nof a combination of networks and can both handle the OHLC constraints as well\nas capture any sudden drastic changes in the prices. It is seen that such a\nnetwork is much more efficient at predicting stock prices. The experiments have\nbeen extended to recommend the most profitable and most overbought stocks on\nthe next day. The model has been tested for multiple Indian companies and it is\nfound that the recommendations from the proposed model have not resulted in a\nsingle loss for a test period of 300 days.",
          "link": "http://arxiv.org/abs/2204.13422",
          "publishedOn": "2022-04-30T01:01:34.611Z",
          "wordCount": null,
          "title": "Autoencoder based Hybrid Multi-Task Predictor Network for Daily Open-High-Low-Close Prices Prediction of Indian Stocks. (arXiv:2204.13422v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Katsuki_T/0/1/0/all/0/1\">Takayuki Katsuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miyaguchi_K/0/1/0/all/0/1\">Kohei Miyaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koseki_A/0/1/0/all/0/1\">Akira Koseki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwamori_T/0/1/0/all/0/1\">Toshiya Iwamori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yanagiya_R/0/1/0/all/0/1\">Ryosuke Yanagiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_A/0/1/0/all/0/1\">Atsushi Suzuki</a>",
          "description": "We address the problem of predicting when a disease will develop, i.e.,\nmedical event time (MET), from a patient's electronic health record (EHR). The\nMET of non-communicable diseases like diabetes is highly correlated to\ncumulative health conditions, more specifically, how much time the patient\nspent with specific health conditions in the past. The common time-series\nrepresentation is indirect in extracting such information from EHR because it\nfocuses on detailed dependencies between values in successive observations, not\ncumulative information. We propose a novel data representation for EHR called\ncumulative stay-time representation (CTR), which directly models such\ncumulative health conditions. We derive a trainable construction of CTR based\non neural networks that has the flexibility to fit the target data and\nscalability to handle high-dimensional EHR. Numerical experiments using\nsynthetic and real-world datasets demonstrate that CTR alone achieves a high\nprediction performance, and it enhances the performance of existing models when\ncombined with them.",
          "link": "http://arxiv.org/abs/2204.13451",
          "publishedOn": "2022-04-30T01:01:34.611Z",
          "wordCount": null,
          "title": "Cumulative Stay-time Representation for Electronic Health Records in Medical Event Time Prediction. (arXiv:2204.13451v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1908.01478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yi-Hsiang Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kuan-Yu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Henry Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chun-Yi Lee</a>",
          "description": "Conventional reinforcement learning (RL) typically determines an appropriate\nprimitive action at each timestep. However, by using a proper macro action,\ndefined as a sequence of primitive actions, an agent is able to bypass\nintermediate states to a farther state and facilitate its learning procedure.\nThe problem we would like to investigate is what associated beneficial\nproperties that macro actions may possess. In this paper, we unveil the\nproperties of reusability and transferability of macro actions. The first\nproperty, reusability, means that a macro action generated along with one RL\nmethod can be reused by another RL method for training, while the second one,\ntransferability, means that a macro action can be utilized for training agents\nin similar environments with different reward settings. In our experiments, we\nfirst generate macro actions along with RL methods. We then provide a set of\nanalyses to reveal the properties of reusability and transferability of the\ngenerated macro actions.",
          "link": "http://arxiv.org/abs/1908.01478",
          "publishedOn": "2022-04-30T01:01:34.608Z",
          "wordCount": null,
          "title": "Reusability and Transferability of Macro Actions for Reinforcement Learning. (arXiv:1908.01478v3 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13598",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Tian_Y/0/1/0/all/0/1\">Yang Tian</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Hou_H/0/1/0/all/0/1\">Hedong Hou</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Wang_Y/0/1/0/all/0/1\">Yaoyuan Wang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyang Zhang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sun_P/0/1/0/all/0/1\">Pei Sun</a>",
          "description": "Information transfer between coupled stochastic dynamics, measured by\ntransfer entropy and information flow, is suggested as a physical process\nunderlying the causal relation of systems. While information transfer analysis\nhas booming applications in both science and engineering fields, critical\nmysteries about its foundations remain unsolved. Fundamental yet difficult\nquestions concern how information transfer and causal relation originate, what\nthey depend on, how they differ from each other, and if they are created by a\nunified and general quantity. These questions essentially determine the\nvalidity of causal relation measurement via information transfer. Here we\npursue to lay a complete theoretical basis of information transfer and causal\nrelation. Beyond the well-known relations between these concepts that\nconditionally hold, we demonstrate that information transfer and causal\nrelation universally originate from specific information synergy and redundancy\nphenomena characterized by high-order mutual information. More importantly, our\ntheory analytically explains the mechanisms for information transfer and causal\nrelation to originate, vanish, and differ from each other. Moreover, our theory\nnaturally defines the effect sizes of information transfer and causal relation\nbased on high-dimensional coupling events. These results may provide a unified\nview of information, synergy, and causal relation to bridge Pearl's causal\ninference theory in computer science and information transfer analysis in\nphysics.",
          "link": "http://arxiv.org/abs/2204.13598",
          "publishedOn": "2022-04-30T01:01:34.605Z",
          "wordCount": null,
          "title": "A unified theory of information transfer and causal relation. (arXiv:2204.13598v1 [cond-mat.stat-mech])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maman_B/0/1/0/all/0/1\">Ben Maman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1\">Amit H. Bermano</a>",
          "description": "Multi-instrument Automatic Music Transcription (AMT), or the decoding of a\nmusical recording into semantic musical content, is one of the holy grails of\nMusic Information Retrieval. Current AMT approaches are restricted to piano and\n(some) guitar recordings, due to difficult data collection. In order to\novercome data collection barriers, previous AMT approaches attempt to employ\nmusical scores in the form of a digitized version of the same song or piece.\nThe scores are typically aligned using audio features and strenuous human\nintervention to generate training labels. We introduce NoteEM, a method for\nsimultaneously training a transcriber and aligning the scores to their\ncorresponding performances, in a fully-automated process. Using this unaligned\nsupervision scheme, complemented by pseudo-labels and pitch-shift augmentation,\nour method enables training on in-the-wild recordings with unprecedented\naccuracy and instrumental variety. Using only synthetic data and unaligned\nsupervision, we report SOTA note-level accuracy of the MAPS dataset, and large\nfavorable margins on cross-dataset evaluations. We also demonstrate robustness\nand ease of use; we report comparable results when training on a small, easily\nobtainable, self-collected dataset, and we propose alternative labeling to the\nMusicNet dataset, which we show to be more accurate. Our project page is\navailable at https://benadar293.github.io",
          "link": "http://arxiv.org/abs/2204.13668",
          "publishedOn": "2022-04-30T01:01:34.605Z",
          "wordCount": null,
          "title": "Unaligned Supervision For Automatic Music Transcription in The Wild. (arXiv:2204.13668v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scarlatos_A/0/1/0/all/0/1\">Alexander Scarlatos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1\">Christopher Brinton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_A/0/1/0/all/0/1\">Andrew Lan</a>",
          "description": "Educational process data, i.e., logs of detailed student activities in\ncomputerized or online learning platforms, has the potential to offer deep\ninsights into how students learn. One can use process data for many downstream\ntasks such as learning outcome prediction and automatically delivering\npersonalized intervention. However, analyzing process data is challenging since\nthe specific format of process data varies a lot depending on different\nlearning/testing scenarios. In this paper, we propose a framework for learning\nrepresentations of educational process data that is applicable across many\ndifferent learning scenarios. Our framework consists of a pre-training step\nthat uses BERT-type objectives to learn representations from sequential process\ndata and a fine-tuning step that further adjusts these representations on\ndownstream prediction tasks. We apply our framework to the 2019 nation's report\ncard data mining competition dataset that consists of student problem-solving\nprocess data and detail the specific models we use in this scenario. We conduct\nboth quantitative and qualitative experiments to show that our framework\nresults in process data representations that are both predictive and\ninformative.",
          "link": "http://arxiv.org/abs/2204.13607",
          "publishedOn": "2022-04-30T01:01:34.603Z",
          "wordCount": null,
          "title": "Process-BERT: A Framework for Representation Learning on Educational Process Data. (arXiv:2204.13607v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+De_S/0/1/0/all/0/1\">Soham De</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berrada_L/0/1/0/all/0/1\">Leonard Berrada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayes_J/0/1/0/all/0/1\">Jamie Hayes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1\">Samuel L. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balle_B/0/1/0/all/0/1\">Borja Balle</a>",
          "description": "Differential Privacy (DP) provides a formal privacy guarantee preventing\nadversaries with access to a machine learning model from extracting information\nabout individual training points. Differentially Private Stochastic Gradient\nDescent (DP-SGD), the most popular DP training method, realizes this protection\nby injecting noise during training. However previous works have found that\nDP-SGD often leads to a significant degradation in performance on standard\nimage classification benchmarks. Furthermore, some authors have postulated that\nDP-SGD inherently performs poorly on large models, since the norm of the noise\nrequired to preserve privacy is proportional to the model dimension. In\ncontrast, we demonstrate that DP-SGD on over-parameterized models can perform\nsignificantly better than previously thought. Combining careful hyper-parameter\ntuning with simple techniques to ensure signal propagation and improve the\nconvergence rate, we obtain a new SOTA on CIFAR-10 of 81.4% under (8,\n10^{-5})-DP using a 40-layer Wide-ResNet, improving over the previous SOTA of\n71.7%. When fine-tuning a pre-trained 200-layer Normalizer-Free ResNet, we\nachieve a remarkable 77.1% top-1 accuracy on ImageNet under (1, 8*10^{-7})-DP,\nand achieve 81.1% under (8, 8*10^{-7})-DP. This markedly exceeds the previous\nSOTA of 47.9% under a larger privacy budget of (10, 10^{-6})-DP. We believe our\nresults are a significant step towards closing the accuracy gap between private\nand non-private image classification.",
          "link": "http://arxiv.org/abs/2204.13650",
          "publishedOn": "2022-04-30T01:01:34.600Z",
          "wordCount": null,
          "title": "Unlocking High-Accuracy Differentially Private Image Classification through Scale. (arXiv:2204.13650v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13606",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pla_P/0/1/0/all/0/1\">P. del Aguila Pla</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Unser_M/0/1/0/all/0/1\">Michael Unser</a>",
          "description": "The projection of sample measurements onto a reconstruction space represented\nby a basis on a regular grid is a powerful and simple approach to estimate a\nprobability density function. In this paper, we focus on Riesz bases and\npropose a projection operator that, in contrast to previous works, guarantees\nthe bona fide properties for the estimate, namely, non-negativity and total\nprobability mass $1$. Our bona fide projection is defined as a convex problem.\nWe propose solution techniques and evaluate them. Results suggest an improved\nperformance, specifically in circumstances prone to rippling effects.",
          "link": "http://arxiv.org/abs/2204.13606",
          "publishedOn": "2022-04-30T01:01:34.596Z",
          "wordCount": null,
          "title": "Bona fide Riesz projections for density estimation. (arXiv:2204.13606v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13691",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1\">Hsin-Yuan Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Flammia_S/0/1/0/all/0/1\">Steven T. Flammia</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Preskill_J/0/1/0/all/0/1\">John Preskill</a>",
          "description": "Understanding what can be learned from experiments is central to scientific\nprogress. In this work, we use a learning-theoretic perspective to study the\ntask of learning physical operations in a quantum machine when all operations\n(state preparation, dynamics, and measurement) are a priori unknown. We prove\nthat, without any prior knowledge, if one can explore the full quantum state\nspace by composing the operations, then every operation can be learned. When\none cannot explore the full state space but all operations are approximately\nknown and noise in Clifford gates is gate-independent, we find an efficient\nalgorithm for learning all operations up to a single unlearnable parameter\ncharacterizing the fidelity of the initial state. For learning a noise channel\non Clifford gates to a fixed accuracy, our algorithm uses quadratically fewer\nexperiments than previously known protocols. Under more general conditions, the\ntrue description of the noise can be unlearnable; for example, we prove that no\nbenchmarking protocol can learn gate-dependent Pauli noise on Clifford+T gates\neven under perfect state preparation and measurement. Despite not being able to\nlearn the noise, we show that a noisy quantum computer that performs entangled\nmeasurements on multiple copies of an unknown state can yield a large advantage\nin learning properties of the state compared to a noiseless device that\nmeasures individual copies and then processes the measurement data using a\nclassical computer. Concretely, we prove that noisy quantum computers with\ntwo-qubit gate error rate $\\epsilon$ can achieve a learning task using $N$\ncopies of the state, while $N^{\\Omega(1/\\epsilon)}$ copies are required\nclassically.",
          "link": "http://arxiv.org/abs/2204.13691",
          "publishedOn": "2022-04-30T01:01:34.596Z",
          "wordCount": null,
          "title": "Foundations for learning from noisy quantum experiments. (arXiv:2204.13691v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongze Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1\">Qingfeng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_M/0/1/0/all/0/1\">Miaowen Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yik-Chung Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1\">H. Vincent Poor</a>",
          "description": "Reconfigurable intelligent surfaces (RISs) have a revolutionary capability to\ncustomize the radio propagation environment for wireless networks. To fully\nexploit the advantages of RISs in wireless systems, the phases of the\nreflecting elements must be jointly designed with conventional communication\nresources, such as beamformers, transmit power, and computation time. However,\ndue to the unique constraints on the phase shift, and massive numbers of\nreflecting units and users in large-scale networks, the resulting optimization\nproblems are challenging to solve. This paper provides a review of current\noptimization methods and artificial intelligence-based methods for handling the\nconstraints imposed by RIS and compares them in terms of solution quality and\ncomputational complexity. Future challenges in phase shift optimization\ninvolving RISs are also described and potential solutions are discussed.",
          "link": "http://arxiv.org/abs/2204.13372",
          "publishedOn": "2022-04-30T01:01:34.595Z",
          "wordCount": null,
          "title": "Phase Shift Design in RIS Empowered Wireless Networks: From Optimization to AI-Based Methods. (arXiv:2204.13372v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13361",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hosoda_K/0/1/0/all/0/1\">Kazufumi Hosoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishida_K/0/1/0/all/0/1\">Keigo Nishida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seno_S/0/1/0/all/0/1\">Shigeto Seno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mashita_T/0/1/0/all/0/1\">Tomohiro Mashita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashioka_H/0/1/0/all/0/1\">Hideki Kashioka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohzawa_I/0/1/0/all/0/1\">Izumi Ohzawa</a>",
          "description": "Learning a new concept from one example is a superior function of human brain\nand it is drawing attention in the field of machine learning as one-shot\nlearning task. In this paper, we propose the simplest method for this task,\nnamed Direct ONE-shot learning (DONE). DONE adds a new class to a pretrained\ndeep neural network (DNN) classifier with neither training optimization nor\nother-classes modification. DONE is inspired by Hebbian theory and directly\nuses the neural activity input of the final dense layer obtained from a data\nthat belongs to the new additional class as the connectivity weight (synaptic\nstrength) with a newly-provided-output neuron for the new class. DONE requires\njust one inference for obtaining the output of the final dense layer and its\nprocedure is simple, deterministic, not requiring parameter tuning and\nhyperparameters. The performance of DONE depends entirely on the pretrained DNN\nmodel used as a backbone model, and we confirmed that DONE with a well-trained\nbackbone model performs a practical-level accuracy. DONE has some advantages\nincluding a DNN's practical use that is difficult to spend high cost for a\ntraining, an evaluation of existing DNN models, and the understanding of the\nbrain. DONE might be telling us one-shot learning is an easy task that can be\nachieved by a simple principle not only for humans but also for current\nwell-trained DNN models.",
          "link": "http://arxiv.org/abs/2204.13361",
          "publishedOn": "2022-04-30T01:01:34.592Z",
          "wordCount": null,
          "title": "It's DONE: Direct ONE-shot learning without training optimization. (arXiv:2204.13361v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13404",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Ote_K/0/1/0/all/0/1\">Kibo Ote</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hashimoto_F/0/1/0/all/0/1\">Fumio Hashimoto</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Onishi_Y/0/1/0/all/0/1\">Yuya Onishi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Isobe_T/0/1/0/all/0/1\">Takashi Isobe</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ouchi_Y/0/1/0/all/0/1\">Yasuomi Ouchi</a>",
          "description": "List-mode positron emission tomography (PET) image reconstruction is an\nimportant tool for PET scanners with many lines-of-response (LORs) and\nadditional information such as time-of-flight and depth-of-interaction. Deep\nlearning is one possible solution to enhance the quality of PET image\nreconstruction. However, the application of deep learning techniques to\nlist-mode PET image reconstruction have not been progressed because list data\nis a sequence of bit codes and unsuitable for processing by convolutional\nneural networks (CNN). In this study, we propose a novel list-mode PET image\nreconstruction method using an unsupervised CNN called deep image prior (DIP)\nand a framework of alternating direction method of multipliers. The proposed\nlist-mode DIP reconstruction (LM-DIPRecon) method alternatively iterates\nregularized list-mode dynamic row action maximum likelihood algorithm\n(LM-DRAMA) and magnetic resonance imaging conditioned DIP (MR-DIP). We\nevaluated LM-DIPRecon using both simulation and clinical data, and it achieved\nsharper images and better tradeoff curves between contrast and noise than the\nLM-DRAMA and MR-DIP. These results indicated that the LM-DIPRecon is useful for\nquantitative PET imaging with limited events. In addition, as list data has\nfiner temporal information than dynamic sinograms, list-mode deep image prior\nreconstruction is expected to be useful for 4D PET imaging and motion\ncorrection.",
          "link": "http://arxiv.org/abs/2204.13404",
          "publishedOn": "2022-04-30T01:01:34.591Z",
          "wordCount": null,
          "title": "List-Mode PET Image Reconstruction Using Deep Image Prior. (arXiv:2204.13404v1 [physics.med-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rong_D/0/1/0/all/0/1\">Dazhong Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qinming He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianhai Chen</a>",
          "description": "Various attack methods against recommender systems have been proposed in the\npast years, and the security issues of recommender systems have drawn\nconsiderable attention. Traditional attacks attempt to make target items\nrecommended to as many users as possible by poisoning the training data.\nBenifiting from the feature of protecting users' private data, federated\nrecommendation can effectively defend such attacks. Therefore, quite a few\nworks have devoted themselves to developing federated recommender systems. For\nproving current federated recommendation is still vulnerable, in this work we\nprobe to design attack approaches targeting deep learning based recommender\nmodels in federated learning scenarios. Specifically, our attacks generate\npoisoned gradients for manipulated malicious users to upload based on two\nstrategies (i.e., random approximation and hard user mining). Extensive\nexperiments show that our well-designed attacks can effectively poison the\ntarget models, and the attack effectiveness sets the state-of-the-art.",
          "link": "http://arxiv.org/abs/2204.13594",
          "publishedOn": "2022-04-30T01:01:34.588Z",
          "wordCount": null,
          "title": "Poisoning Deep Learning based Recommender Model in Federated Learning Scenarios. (arXiv:2204.13594v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schreiber_J/0/1/0/all/0/1\">Jens Schreiber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1\">Bernhard Sick</a>",
          "description": "There is recent interest in using model hubs, a collection of pre-trained\nmodels, in computer vision tasks. To utilize the model hub, we first select a\nsource model and then adapt the model for the target to compensate for\ndifferences. While there is yet limited research on a model selection and\nadaption for computer vision tasks, this holds even more for the field of\nrenewable power. At the same time, it is a crucial challenge to provide\nforecasts for the increasing demand for power forecasts based on weather\nfeatures from a numerical weather prediction. We close these gaps by conducting\nthe first thorough experiment for model selection and adaptation for transfer\nlearning in renewable power forecast, adopting recent results from the field of\ncomputer vision on six datasets. We adopt models based on data from different\nseasons and limit the amount of training data. As an extension of the current\nstate of the art, we utilize a Bayesian linear regression for forecasting the\nresponse based on features extracted from a neural network. This approach\noutperforms the baseline with only seven days of training data. We further show\nhow combining multiple models through ensembles can significantly improve the\nmodel selection and adaptation approach. In fact, with more than 30 days of\ntraining data, both proposed model combination techniques achieve similar\nresults to those models trained with a full year of training data.",
          "link": "http://arxiv.org/abs/2204.13293",
          "publishedOn": "2022-04-30T01:01:34.575Z",
          "wordCount": null,
          "title": "Model Selection, Adaptation, and Combination for Deep Transfer Learning through Neural Networks in Renewable Energies. (arXiv:2204.13293v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08581",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Chen_T/0/1/0/all/0/1\">Tao Chen</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Ludkovski_M/0/1/0/all/0/1\">Mike Ludkovski</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Voss_M/0/1/0/all/0/1\">Moritz Vo&#xdf;</a>",
          "description": "We investigate optimal order execution problems in discrete time with\ninstantaneous price impact and stochastic resilience. First, in the setting of\nlinear transient price impact we derive a closed-form recursion for the optimal\nstrategy, extending the deterministic results from Obizhaeva and Wang (J\nFinancial Markets, 2013). Second, we develop a numerical algorithm based on\ndynamic programming and deep learning for the case of nonlinear transient price\nimpact as proposed by Bouchaud et al. (Quant. Finance, 2004). Specifically, we\nutilize an actor-critic framework that constructs two neural-network (NN)\nsurrogates for the value function and the feedback control. The flexible\nscalability of NN functional approximators enables parametric learning, i.e.,\nincorporating several model or market parameters as part of the input space.\nPrecise calibration of price impact, resilience, etc., is known to be extremely\nchallenging and hence it is critical to understand sensitivity of the execution\npolicy to these parameters. Our NN learner organically scales across multiple\ninput dimensions and is shown to accurately approximate optimal strategies\nacross a wide range of parameter configurations. We provide a fully\nreproducible Jupyter Notebook with our NN implementation, which is of\nindependent pedagogical interest, demonstrating the ease of use of NN\nsurrogates in (parametric) stochastic control problems.",
          "link": "http://arxiv.org/abs/2204.08581",
          "publishedOn": "2022-04-30T01:01:34.574Z",
          "wordCount": null,
          "title": "On Parametric Optimal Execution and Machine Learning Surrogates. (arXiv:2204.08581v2 [q-fin.TR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13584",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sathish_V/0/1/0/all/0/1\">Vidya Rohini Konanur Sathish</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Woo_W/0/1/0/all/0/1\">Wai Lok Woo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ho_E/0/1/0/all/0/1\">Edmond S. L. Ho</a>",
          "description": "Identifying sleep stages and patterns is an essential part of diagnosing and\ntreating sleep disorders. With the advancement of smart technologies, sensor\ndata related to sleeping patterns can be captured easily. In this paper, we\npropose a Convolution Neural Network (CNN) architecture that improves the\nclassification performance. In particular, we benchmark the classification\nperformance from different methods, including traditional machine learning\nmethods such as Logistic Regression (LR), Decision Trees (DT), k-Nearest\nNeighbour (k-NN), Naive Bayes (NB) and Support Vector Machine (SVM), on 3\npublicly available sleep datasets. The accuracy, sensitivity, specificity,\nprecision, recall, and F-score are reported and will serve as a baseline to\nsimulate the research in this direction in the future.",
          "link": "http://arxiv.org/abs/2204.13584",
          "publishedOn": "2022-04-30T01:01:34.571Z",
          "wordCount": null,
          "title": "Predicting Sleeping Quality using Convolutional Neural Networks. (arXiv:2204.13584v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Georgiou_E/0/1/0/all/0/1\">Efthymios Georgiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kritsis_K/0/1/0/all/0/1\">Kosmas Kritsis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paraskevopoulos_G/0/1/0/all/0/1\">Georgios Paraskevopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katsamanis_A/0/1/0/all/0/1\">Athanasios Katsamanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katsouros_V/0/1/0/all/0/1\">Vassilis Katsouros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potamianos_A/0/1/0/all/0/1\">Alexandros Potamianos</a>",
          "description": "Recent deep learning Text-to-Speech (TTS) systems have achieved impressive\nperformance by generating speech close to human parity. However, they suffer\nfrom training stability issues as well as incorrect alignment of the\nintermediate acoustic representation with the input text sequence. In this\nwork, we introduce Regotron, a regularized version of Tacotron2 which aims to\nalleviate the training issues and at the same time produce monotonic\nalignments. Our method augments the vanilla Tacotron2 objective function with\nan additional term, which penalizes non-monotonic alignments in the\nlocation-sensitive attention mechanism. By properly adjusting this\nregularization term we show that the loss curves become smoother, and at the\nsame time Regotron consistently produces monotonic alignments in unseen\nexamples even at an early stage (13\\% of the total number of epochs) of its\ntraining process, whereas the fully converged Tacotron2 fails to do so.\nMoreover, our proposed regularization method has no additional computational\noverhead, while reducing common TTS mistakes and achieving slighlty improved\nspeech naturalness according to subjective mean opinion scores (MOS) collected\nfrom 50 evaluators.",
          "link": "http://arxiv.org/abs/2204.13437",
          "publishedOn": "2022-04-30T01:01:34.562Z",
          "wordCount": null,
          "title": "Regotron: Regularizing the Tacotron2 architecture via monotonic alignment loss. (arXiv:2204.13437v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13502",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuchuang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Hong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1\">John C.S. Lui</a>",
          "description": "Multi-player multi-armed bandits (MMAB) study how decentralized players\ncooperatively play the same multi-armed bandit so as to maximize their total\ncumulative rewards. Existing MMAB models mostly assume when more than one\nplayer pulls the same arm, they either have a collision and obtain zero\nrewards, or have no collision and gain independent rewards, both of which are\nusually too restrictive in practical scenarios. In this paper, we propose an\nMMAB with shareable resources as an extension to the collision and\nnon-collision settings. Each shareable arm has finite shareable resources and a\n\"per-load\" reward random variable, both of which are unknown to players. The\nreward from a shareable arm is equal to the \"per-load\" reward multiplied by the\nminimum between the number of players pulling the arm and the arm's maximal\nshareable resources. We consider two types of feedback: sharing demand\ninformation (SDI) and sharing demand awareness (SDA), each of which provides\ndifferent signals of resource sharing. We design the DPE-SDI and SIC-SDA\nalgorithms to address the shareable arm problem under these two cases of\nfeedback respectively and prove that both algorithms have logarithmic regrets\nthat are tight in the number of rounds. We conduct simulations to validate both\nalgorithms' performance and show their utilities in wireless networking and\nedge computing.",
          "link": "http://arxiv.org/abs/2204.13502",
          "publishedOn": "2022-04-30T01:01:34.559Z",
          "wordCount": null,
          "title": "Multi-Player Multi-Armed Bandits with Finite Shareable Resources Arms: Learning Algorithms & Applications. (arXiv:2204.13502v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brown_N/0/1/0/all/0/1\">Nick Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gibb_G/0/1/0/all/0/1\">Gordon Gibb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belikov_E/0/1/0/all/0/1\">Evgenij Belikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nash_R/0/1/0/all/0/1\">Rupert Nash</a>",
          "description": "There is increasing interest in the use of HPC machines for urgent workloads\nto help tackle disasters as they unfold. Whilst batch queue systems are not\nideal in supporting such workloads, many disadvantages can be worked around by\naccurately predicting when a waiting job will start to run. However there are\nnumerous challenges in achieving such a prediction with high accuracy, not\nleast because the queue's state can change rapidly and depend upon many\nfactors. In this work we explore a novel machine learning approach for\npredicting queue wait times, hypothesising that such a model can capture the\ncomplex behaviour resulting from the queue policy and other interactions to\ngenerate accurate job start times.\n\nFor ARCHER2 (HPE Cray EX), Cirrus (HPE 8600) and 4-cabinet (HPE Cray EX) we\nexplore how different machine learning approaches and techniques improve the\naccuracy of our predictions, comparing against the estimation generated by\nSlurm. We demonstrate that our techniques deliver the most accurate predictions\nacross our machines of interest, with the result of this work being the ability\nto predict job start times within one minute of the actual start time for\naround 65\\% of jobs on ARCHER2 and 4-cabinet, and 76\\% of jobs on Cirrus. When\ncompared against what Slurm can deliver, this represents around 3.8 times\nbetter accuracy on ARCHER2 and 18 times better for Cirrus. Furthermore our\napproach can accurately predicting the start time for three quarters of all job\nwithin ten minutes of the actual start time on ARCHER2 and 4-cabinet, and for\n90\\% of jobs on Cirrus. Whilst the driver of this work has been to better\nfacilitate placement of urgent workloads across HPC machines, the insights\ngained can be used to provide wider benefits to users and also enrich existing\nbatch queue systems and inform policy too.",
          "link": "http://arxiv.org/abs/2204.13543",
          "publishedOn": "2022-04-30T01:01:34.556Z",
          "wordCount": null,
          "title": "Predicting batch queue job wait times for informed scheduling of urgent HPC workloads. (arXiv:2204.13543v1 [cs.DC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1\">Guochang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Fukai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Pipi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junqing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zuoqiang Shi</a>",
          "description": "Green's function plays a significant role in both theoretical analysis and\nnumerical computing of partial differential equations (PDEs). However, in most\ncases, Green's function is difficult to compute. The troubles arise in the\nfollowing three folds. Firstly, compared with the original PDE, the dimension\nof Green's function is doubled, making it impossible to be handled by\ntraditional mesh-based methods. Secondly, Green's function usually contains\nsingularities which increase the difficulty to get a good approximation.\nLastly, the computational domain may be very complex or even unbounded. To\noverride these problems, we leverage the fundamental solution, boundary\nintegral method and neural networks to develop a new method for computing\nGreen's function with high accuracy in this paper. We focus on Green's function\nof Poisson and Helmholtz equations in bounded domains, unbounded domains. We\nalso consider Poisson equation and Helmholtz domains with interfaces. Extensive\nnumerical experiments illustrate the efficiency and the accuracy of our method\nfor solving Green's function. In addition, we also use the Green's function\ncalculated by our method to solve a class of PDE, and also obtain\nhigh-precision solutions, which shows the good generalization ability of our\nmethod on solving PDEs.",
          "link": "http://arxiv.org/abs/2204.13247",
          "publishedOn": "2022-04-30T01:01:34.552Z",
          "wordCount": null,
          "title": "BI-GreenNet: Learning Green's functions by boundary integral network. (arXiv:2204.13247v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.00394",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhoubo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Puqing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raveaux_R/0/1/0/all/0/1\">Romain Raveaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huadong Liu</a>",
          "description": "Graph matching is an important problem that has received widespread\nattention, especially in the field of computer vision. Recently,\nstate-of-the-art methods seek to incorporate graph matching with deep learning.\nHowever, there is no research to explain what role the graph matching algorithm\nplays in the model. Therefore, we propose an approach integrating a MILP\nformulation of the graph matching problem. This formulation is solved to\noptimal and it provides inherent baseline. Meanwhile, similar approaches are\nderived by releasing the optimal guarantee of the graph matching solver and by\nintroducing a quality level. This quality level controls the quality of the\nsolutions provided by the graph matching solver. In addition, several\nrelaxations of the graph matching problem are put to the test. Our experimental\nevaluation gives several theoretical insights and guides the direction of deep\ngraph matching methods.",
          "link": "http://arxiv.org/abs/2108.00394",
          "publishedOn": "2022-04-30T01:01:34.552Z",
          "wordCount": null,
          "title": "Deep graph matching meets mixed-integer linear programming: Relax at your own risk ?. (arXiv:2108.00394v5 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hetzel_L/0/1/0/all/0/1\">Leon Hetzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohm_S/0/1/0/all/0/1\">Simon B&#xf6;hm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kilbertus_N/0/1/0/all/0/1\">Niki Kilbertus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lotfollahi_M/0/1/0/all/0/1\">Mohammad Lotfollahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theis_F/0/1/0/all/0/1\">Fabian Theis</a>",
          "description": "Single-cell transcriptomics enabled the study of cellular heterogeneity in\nresponse to perturbations at the resolution of individual cells. However,\nscaling high-throughput screens (HTSs) to measure cellular responses for many\ndrugs remains a challenge due to technical limitations and, more importantly,\nthe cost of such multiplexed experiments. Thus, transferring information from\nroutinely performed bulk RNA-seq HTS is required to enrich single-cell data\nmeaningfully. We introduce a new encoder-decoder architecture to study the\nperturbational effects of unseen drugs. We combine the model with a transfer\nlearning scheme and demonstrate how training on existing bulk RNA-seq HTS\ndatasets can improve generalisation performance. Better generalisation reduces\nthe need for extensive and costly screens at single-cell resolution. We\nenvision that our proposed method will facilitate more efficient experiment\ndesigns through its ability to generate in-silico hypotheses, ultimately\naccelerating targeted drug discovery.",
          "link": "http://arxiv.org/abs/2204.13545",
          "publishedOn": "2022-04-30T01:01:34.547Z",
          "wordCount": null,
          "title": "Predicting single-cell perturbation responses for unseen drugs. (arXiv:2204.13545v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Radensky_M/0/1/0/all/0/1\">Marissa Radensky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burson_D/0/1/0/all/0/1\">Dustin Burson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhaiya_R/0/1/0/all/0/1\">Rajya Bhaiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1\">Daniel S. Weld</a>",
          "description": "An important goal in the field of human-AI interaction is to help users more\nappropriately trust AI systems' decisions. A situation in which the user may\nparticularly benefit from more appropriate trust is when the AI receives\nanomalous input or provides anomalous output. To the best of our knowledge,\nthis is the first work towards understanding how anomaly alerts may contribute\nto appropriate trust of AI. In a formative mixed-methods study with 4\nradiologists and 4 other physicians, we explore how AI alerts for anomalous\ninput, very high and low confidence, and anomalous saliency-map explanations\naffect users' experience with mockups of an AI clinical decision support system\n(CDSS) for evaluating chest x-rays for pneumonia. We find evidence suggesting\nthat the four anomaly alerts are desired by non-radiologists, and the\nhigh-confidence alerts are desired by both radiologists and non-radiologists.\nIn a follow-up user study, we investigate how high- and low-confidence alerts\naffect the accuracy and thus appropriate trust of 33 radiologists working with\nAI CDSS mockups. We observe that these alerts do not improve users' accuracy or\nexperience and discuss potential reasons why.",
          "link": "http://arxiv.org/abs/2204.13194",
          "publishedOn": "2022-04-30T01:01:34.492Z",
          "wordCount": null,
          "title": "Exploring How Anomalous Model Input and Output Alerts Affect Decision-Making in Healthcare. (arXiv:2204.13194v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mosteiro_P/0/1/0/all/0/1\">Pablo Mosteiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijcken_E/0/1/0/all/0/1\">Emil Rijcken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zervanou_K/0/1/0/all/0/1\">Kalliopi Zervanou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaymak_U/0/1/0/all/0/1\">Uzay Kaymak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheepers_F/0/1/0/all/0/1\">Floortje Scheepers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spruit_M/0/1/0/all/0/1\">Marco Spruit</a>",
          "description": "Violence risk assessment in psychiatric institutions enables interventions to\navoid violence incidents. Clinical notes written by practitioners and available\nin electronic health records are valuable resources capturing unique\ninformation, but are seldom used to their full potential. We explore\nconventional and deep machine learning methods to assess violence risk in\npsychiatric patients using practitioner notes. The performance of our best\nmodels is comparable to the currently used questionnaire-based method, with an\narea under the Receiver Operating Characteristic curve of approximately 0.8. We\nfind that the deep-learning model BERTje performs worse than conventional\nmachine learning methods. We also evaluate our data and our classifiers to\nunderstand the performance of our models better. This is particularly important\nfor the applicability of evaluated classifiers to new data, and is also of\ngreat interest to practitioners, due to the increased availability of new data\nin electronic format.",
          "link": "http://arxiv.org/abs/2204.13535",
          "publishedOn": "2022-04-30T01:01:34.488Z",
          "wordCount": null,
          "title": "Machine Learning for Violence Risk Assessment Using Dutch Clinical Notes. (arXiv:2204.13535v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pachev_B/0/1/0/all/0/1\">Benjamin Pachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valseth_E/0/1/0/all/0/1\">Eirik Valseth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dawson_C/0/1/0/all/0/1\">Clint Dawson</a>",
          "description": "Storm surge is a major natural hazard for coastal regions, responsible both\nfor significant property damage and loss of life. Accurate, efficient models of\nstorm surge are needed both to assess long-term risk and to guide emergency\nmanagement decisions. While high-fidelity ocean circulation models such as the\nADvanced CIRCulation (ADCIRC) model can accurately predict storm surge, they\nare very computationally expensive. Consequently, there have been a number of\nefforts in recent years to develop data-driven surrogate models for storm\nsurge. While these models can attain good accuracy and are highly efficient,\nthey are often limited to a small geographical region and a fixed set of output\nlocations.\n\nWe develop a novel surrogate model for peak storm surge prediction based on\ngradient boosting. Unlike most surrogate approaches, our model is not\nexplicitly constrained to a fixed set of output locations or specific\ngeographical region. The model is trained with a database of 446 synthetic\nstorms that make landfall on the Texas coast and obtains a mean absolute error\nof 0.25 meters. We additionally present a test of the model on Hurricanes Ike\n(2008) and Harvey (2017).",
          "link": "http://arxiv.org/abs/2204.13168",
          "publishedOn": "2022-04-30T01:01:34.480Z",
          "wordCount": null,
          "title": "Learning Storm Surge with Gradient Boosting. (arXiv:2204.13168v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horvath_S/0/1/0/all/0/1\">Samuel Horv&#xe1;th</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1\">Maziar Sanjabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Lin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1\">Michael Rabbat</a>",
          "description": "The practice of applying several local updates before aggregation across\nclients has been empirically shown to be a successful approach to overcoming\nthe communication bottleneck in Federated Learning (FL). In this work, we\npropose a general recipe, FedShuffle, that better utilizes the local updates in\nFL, especially in the heterogeneous regime. Unlike many prior works, FedShuffle\ndoes not assume any uniformity in the number of updates per device. Our\nFedShuffle recipe comprises four simple-yet-powerful ingredients: 1) local\nshuffling of the data, 2) adjustment of the local learning rates, 3) update\nweighting, and 4) momentum variance reduction (Cutkosky and Orabona, 2019). We\npresent a comprehensive theoretical analysis of FedShuffle and show that both\ntheoretically and empirically, our approach does not suffer from the objective\nfunction mismatch that is present in FL methods which assume homogeneous\nupdates in heterogeneous FL setups, e.g., FedAvg (McMahan et al., 2017). In\naddition, by combining the ingredients above, FedShuffle improves upon FedNova\n(Wang et al., 2020), which was previously proposed to solve this mismatch. We\nalso show that FedShuffle with momentum variance reduction can improve upon\nnon-local methods under a Hessian similarity assumption. Finally, through\nexperiments on synthetic and real-world datasets, we illustrate how each of the\nfour ingredients used in FedShuffle helps improve the use of local updates in\nFL.",
          "link": "http://arxiv.org/abs/2204.13169",
          "publishedOn": "2022-04-30T01:01:34.480Z",
          "wordCount": null,
          "title": "FedShuffle: Recipes for Better Use of Local Work in Federated Learning. (arXiv:2204.13169v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10872",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oosterhuis_H/0/1/0/all/0/1\">Harrie Oosterhuis</a>",
          "description": "Plackett-Luce gradient estimation enables the optimization of stochastic\nranking models within feasible time constraints through sampling techniques.\nUnfortunately, the computational complexity of existing methods does not scale\nwell with the length of the rankings, i.e. the ranking cutoff, nor with the\nitem collection size. In this paper, we introduce the novel PL-Rank-3 algorithm\nthat performs unbiased gradient estimation with a computational complexity\ncomparable to the best sorting algorithms. As a result, our novel\nlearning-to-rank method is applicable in any scenario where standard sorting is\nfeasible in reasonable time. Our experimental results indicate large gains in\nthe time required for optimization, without any loss in performance. For the\nfield, our contribution could potentially allow state-of-the-art\nlearning-to-rank methods to be applied to much larger scales than previously\nfeasible.",
          "link": "http://arxiv.org/abs/2204.10872",
          "publishedOn": "2022-04-30T01:01:34.475Z",
          "wordCount": null,
          "title": "Learning-to-Rank at the Speed of Sampling: Plackett-Luce Gradient Estimation With Minimal Computational Complexity. (arXiv:2204.10872v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1\">Kangning Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruoning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polk_S/0/1/0/all/0/1\">Sam L. Polk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_J/0/1/0/all/0/1\">James M. Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plemmons_R/0/1/0/all/0/1\">Robert J. Plemmons</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_R/0/1/0/all/0/1\">Raymond H. Chan</a>",
          "description": "Hyperspectral images, which store a hundred or more spectral bands of\nreflectance, have become an important data source in natural and social\nsciences. Hyperspectral images are often generated in large quantities at a\nrelatively coarse spatial resolution. As such, unsupervised machine learning\nalgorithms incorporating known structure in hyperspectral imagery are needed to\nanalyze these images automatically. This work introduces the Spatial-Spectral\nImage Reconstruction and Clustering with Diffusion Geometry (DSIRC) algorithm\nfor partitioning highly mixed hyperspectral images. DSIRC reduces measurement\nnoise through a shape-adaptive reconstruction procedure. In particular, for\neach pixel, DSIRC locates spectrally correlated pixels within a data-adaptive\nspatial neighborhood and reconstructs that pixel's spectral signature using\nthose of its neighbors. DSIRC then locates high-density, high-purity pixels far\nin diffusion distance (a data-dependent distance metric) from other\nhigh-density, high-purity pixels and treats these as cluster exemplars, giving\neach a unique label. Non-modal pixels are assigned the label of their diffusion\ndistance-nearest neighbor of higher density and purity that is already labeled.\nStrong numerical results indicate that incorporating spatial information\nthrough image reconstruction substantially improves the performance of\npixel-wise clustering.",
          "link": "http://arxiv.org/abs/2204.13497",
          "publishedOn": "2022-04-30T01:01:34.472Z",
          "wordCount": null,
          "title": "Unsupervised Spatial-spectral Hyperspectral Image Reconstruction and Clustering with Diffusion Geometry. (arXiv:2204.13497v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13290",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gordon_Rodriguez_E/0/1/0/all/0/1\">Elliott Gordon-Rodriguez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Loaiza_Ganem_G/0/1/0/all/0/1\">Gabriel Loaiza-Ganem</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Potapczynski_A/0/1/0/all/0/1\">Andres Potapczynski</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cunningham_J/0/1/0/all/0/1\">John P. Cunningham</a>",
          "description": "Probability distributions supported on the simplex enjoy a wide range of\napplications across statistics and machine learning. Recently, a novel family\nof such distributions has been discovered: the continuous categorical. This\nfamily enjoys remarkable mathematical simplicity; its density function\nresembles that of the Dirichlet distribution, but with a normalizing constant\nthat can be written in closed form using elementary functions only. In spite of\nthis mathematical simplicity, our understanding of the normalizing constant\nremains far from complete. In this work, we characterize the numerical behavior\nof the normalizing constant and we present theoretical and methodological\nadvances that can, in turn, help to enable broader applications of the\ncontinuous categorical distribution. Our code is available at\nhttps://github.com/cunningham-lab/cb_and_cc/.",
          "link": "http://arxiv.org/abs/2204.13290",
          "publishedOn": "2022-04-30T01:01:34.471Z",
          "wordCount": null,
          "title": "On the Normalizing Constant of the Continuous Categorical Distribution. (arXiv:2204.13290v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13376",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Ahmed_W/0/1/0/all/0/1\">W. W. Ahmed</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Farhat_M/0/1/0/all/0/1\">M. Farhat</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Staliunas_K/0/1/0/all/0/1\">K. Staliunas</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_X/0/1/0/all/0/1\">X. Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wu_Y/0/1/0/all/0/1\">Y. Wu</a>",
          "description": "Non-Hermitian systems offer new platforms for unusual physical properties\nthat can be flexibly manipulated by redistribution of the real and imaginary\nparts of refractive indices, whose presence breaks conventional wave\npropagation symmetries, leading to asymmetric reflection and symmetric\ntransmission with respect to the wave propagation direction. Here, we use\nsupervised and unsupervised learning techniques for knowledge acquisition in\nnon-Hermitian systems which accelerate the inverse design process. In\nparticular, we construct a deep learning model that relates the transmission\nand asymmetric reflection in non-conservative settings and proposes\nsub-manifold learning to recognize non-Hermitian features from transmission\nspectra. The developed deep learning framework determines the feasibility of a\ndesired spectral response for a given structure and uncovers the role of\neffective gain-loss parameters to tailor the spectral response. These findings\npave the way for intelligent inverse design and shape our understanding of the\nphysical mechanism in general non-Hermitian systems.",
          "link": "http://arxiv.org/abs/2204.13376",
          "publishedOn": "2022-04-30T01:01:34.471Z",
          "wordCount": null,
          "title": "Machine learning for knowledge acquisition and accelerated inverse-design for non-Hermitian systems. (arXiv:2204.13376v1 [physics.optics])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiaofeng Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Keren Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Luping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1\">Hong Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1\">Chengjun Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_B/0/1/0/all/0/1\">Bo Cao</a>",
          "description": "Different from large-scale platforms such as Taobao and Amazon, CVR modeling\nin small-scale recommendation scenarios is more challenging due to the severe\nData Distribution Fluctuation (DDF) issue. DDF prevents existing CVR models\nfrom being effective since 1) several months of data are needed to train CVR\nmodels sufficiently in small scenarios, leading to considerable distribution\ndiscrepancy between training and online serving; and 2) e-commerce promotions\nhave significant impacts on small scenarios, leading to distribution\nuncertainty of the upcoming time period. In this work, we propose a novel CVR\nmethod named MetaCVR from a perspective of meta learning to address the DDF\nissue. Firstly, a base CVR model which consists of a Feature Representation\nNetwork (FRN) and output layers is designed and trained sufficiently with\nsamples across months. Then we treat time periods with different data\ndistributions as different occasions and obtain positive and negative\nprototypes for each occasion using the corresponding samples and the\npre-trained FRN. Subsequently, a Distance Metric Network (DMN) is devised to\ncalculate the distance metrics between each sample and all prototypes to\nfacilitate mitigating the distribution uncertainty. At last, we develop an\nEnsemble Prediction Network (EPN) which incorporates the output of FRN and DMN\nto make the final CVR prediction. In this stage, we freeze the FRN and train\nthe DMN and EPN with samples from recent time period, therefore effectively\neasing the distribution discrepancy. To the best of our knowledge, this is the\nfirst study of CVR prediction targeting the DDF issue in small-scale\nrecommendation scenarios. Experimental results on real-world datasets validate\nthe superiority of our MetaCVR and online A/B test also shows our model\nachieves impressive gains of 11.92% on PCVR and 8.64% on GMV.",
          "link": "http://arxiv.org/abs/2112.13753",
          "publishedOn": "2022-04-30T01:01:34.447Z",
          "wordCount": null,
          "title": "MetaCVR: Conversion Rate Prediction via Meta Learning in Small-Scale Recommendation Scenarios. (arXiv:2112.13753v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kandpal_N/0/1/0/all/0/1\">Nikhil Kandpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nieto_O/0/1/0/all/0/1\">Oriol Nieto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zeyu Jin</a>",
          "description": "Consumer-grade music recordings such as those captured by mobile devices\ntypically contain distortions in the form of background noise, reverb, and\nmicrophone-induced EQ. This paper presents a deep learning approach to enhance\nlow-quality music recordings by combining (i) an image-to-image translation\nmodel for manipulating audio in its mel-spectrogram representation and (ii) a\nmusic vocoding model for mapping synthetically generated mel-spectrograms to\nperceptually realistic waveforms. We find that this approach to music\nenhancement outperforms baselines which use classical methods for\nmel-spectrogram inversion and an end-to-end approach directly mapping noisy\nwaveforms to clean waveforms. Additionally, in evaluating the proposed method\nwith a listening test, we analyze the reliability of common audio enhancement\nevaluation metrics when used in the music domain.",
          "link": "http://arxiv.org/abs/2204.13289",
          "publishedOn": "2022-04-30T01:01:34.446Z",
          "wordCount": null,
          "title": "Music Enhancement via Image Translation and Vocoding. (arXiv:2204.13289v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McAllister_R/0/1/0/all/0/1\">Rowan McAllister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulfe_B/0/1/0/all/0/1\">Blake Wulfe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mercat_J/0/1/0/all/0/1\">Jean Mercat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellis_L/0/1/0/all/0/1\">Logan Ellis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1\">Adrien Gaidon</a>",
          "description": "Autonomous vehicle software is typically structured as a modular pipeline of\nindividual components (e.g., perception, prediction, and planning) to help\nseparate concerns into interpretable sub-tasks. Even when end-to-end training\nis possible, each module has its own set of objectives used for safety\nassurance, sample efficiency, regularization, or interpretability. However,\nintermediate objectives do not always align with overall system performance.\nFor example, optimizing the likelihood of a trajectory prediction module might\nfocus more on easy-to-predict agents than safety-critical or rare behaviors\n(e.g., jaywalking). In this paper, we present control-aware prediction\nobjectives (CAPOs), to evaluate the downstream effect of predictions on control\nwithout requiring the planner be differentiable. We propose two types of\nimportance weights that weight the predictive likelihood: one using an\nattention model between agents, and another based on control variation when\nexchanging predicted trajectories for ground truth trajectories.\nExperimentally, we show our objectives improve overall system performance in\nsuburban driving scenarios using the CARLA simulator.",
          "link": "http://arxiv.org/abs/2204.13319",
          "publishedOn": "2022-04-30T01:01:34.445Z",
          "wordCount": null,
          "title": "Control-Aware Prediction Objectives for Autonomous Driving. (arXiv:2204.13319v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12275",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ashman_M/0/1/0/all/0/1\">Matthew Ashman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bui_T/0/1/0/all/0/1\">Thang D. Bui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_C/0/1/0/all/0/1\">Cuong V. Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Markou_S/0/1/0/all/0/1\">Stratis Markou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Swaroop_S/0/1/0/all/0/1\">Siddharth Swaroop</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>",
          "description": "The proliferation of computing devices has brought about an opportunity to\ndeploy machine learning models on new problem domains using previously\ninaccessible data. Traditional algorithms for training such models often\nrequire data to be stored on a single machine with compute performed by a\nsingle node, making them unsuitable for decentralised training on multiple\ndevices. This deficiency has motivated the development of federated learning\nalgorithms, which allow multiple data owners to train collaboratively and use a\nshared model whilst keeping local data private. However, many of these\nalgorithms focus on obtaining point estimates of model parameters, rather than\nprobabilistic estimates capable of capturing model uncertainty, which is\nessential in many applications. Variational inference (VI) has become the\nmethod of choice for fitting many modern probabilistic models. In this paper we\nintroduce partitioned variational inference (PVI), a general framework for\nperforming VI in the federated setting. We develop new supporting theory for\nPVI, demonstrating a number of properties that make it an attractive choice for\npractitioners; use PVI to unify a wealth of fragmented, yet related literature;\nand provide empirical results that showcase the effectiveness of PVI in a\nvariety of federated settings.",
          "link": "http://arxiv.org/abs/2202.12275",
          "publishedOn": "2022-04-30T01:01:34.439Z",
          "wordCount": null,
          "title": "Partitioned Variational Inference: A Framework for Probabilistic Federated Learning. (arXiv:2202.12275v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09502",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Taheri_R/0/1/0/all/0/1\">Rahim Taheri</a>",
          "description": "A rising number of botnet families have been successfully detected using deep\nlearning architectures. While the variety of attacks increases, these\narchitectures should become more robust against attacks. They have been proven\nto be very sensitive to small but well constructed perturbations in the input.\nBotnet detection requires extremely low false-positive rates (FPR), which are\nnot commonly attainable in contemporary deep learning. Attackers try to\nincrease the FPRs by making poisoned samples. The majority of recent research\nhas focused on the use of model loss functions to build adversarial examples\nand robust models. In this paper, two LSTM-based classification algorithms for\nbotnet classification with an accuracy higher than 98% are presented. Then, the\nadversarial attack is proposed, which reduces the accuracy to about 30%. Then,\nby examining the methods for computing the uncertainty, the defense method is\nproposed to increase the accuracy to about 70%. By using the deep ensemble and\nstochastic weight averaging quantification methods it has been investigated the\nuncertainty of the accuracy in the proposed methods.",
          "link": "http://arxiv.org/abs/2204.09502",
          "publishedOn": "2022-04-30T01:01:34.437Z",
          "wordCount": null,
          "title": "UNBUS: Uncertainty-aware Deep Botnet Detection System in Presence of Perturbed Samples. (arXiv:2204.09502v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Machumilane_A/0/1/0/all/0/1\">Achilles Machumilane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotta_A/0/1/0/all/0/1\">Alberto Gotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cassara_P/0/1/0/all/0/1\">Pietro Cassar&#xe0;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gennaro_C/0/1/0/all/0/1\">Claudio Gennaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amato_G/0/1/0/all/0/1\">Giuseppe Amato</a>",
          "description": "Reinforcement Learning (RL) has recently found wide applications in network\ntraffic management and control because some of its variants do not require\nprior knowledge of network models. In this paper, we present a novel scheduler\nfor real-time multimedia delivery in multipath systems based on an Actor-Critic\n(AC) RL algorithm. We focus on a challenging scenario of real-time video\nstreaming from an Unmanned Aerial Vehicle (UAV) using multiple wireless paths.\nThe scheduler acting as an RL agent learns in real-time the optimal policy for\npath selection, path rate allocation and redundancy estimation for flow\nprotection. The scheduler, implemented as a module of the GStreamer framework,\ncan be used in real or simulated settings. The simulation results show that our\nscheduler can target a very low loss rate at the receiver by dynamically\nadapting in real-time the scheduling policy to the path conditions without\nperforming training or relying on prior knowledge of network channel models.",
          "link": "http://arxiv.org/abs/2204.13343",
          "publishedOn": "2022-04-30T01:01:34.436Z",
          "wordCount": null,
          "title": "Actor-Critic Scheduling for Path-Aware Air-to-Ground Multipath Multimedia Delivery. (arXiv:2204.13343v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jitkrittum_W/0/1/0/all/0/1\">Wittawat Jitkrittum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1\">Aditya Krishna Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawat_A/0/1/0/all/0/1\">Ankit Singh Rawat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>",
          "description": "Long-tail learning is the problem of learning under skewed label\ndistributions, which pose a challenge for standard learners. Several recent\napproaches for the problem have proposed enforcing a suitable margin in logit\nspace. Such techniques are intuitive analogues of the guiding principle behind\nSVMs, and are equally applicable to linear models and neural models. However,\nwhen applied to neural models, such techniques do not explicitly control the\ngeometry of the learned embeddings. This can be potentially sub-optimal, since\nembeddings for tail classes may be diffuse, resulting in poor generalization\nfor these classes. We present Embedding and Logit Margins (ELM), a unified\napproach to enforce margins in logit space, and regularize the distribution of\nembeddings. This connects losses for long-tail learning to proposals in the\nliterature on metric embedding, and contrastive learning. We theoretically show\nthat minimising the proposed ELM objective helps reduce the generalisation gap.\nThe ELM method is shown to perform well empirically, and results in tighter\ntail class embeddings.",
          "link": "http://arxiv.org/abs/2204.13208",
          "publishedOn": "2022-04-30T01:01:34.434Z",
          "wordCount": null,
          "title": "ELM: Embedding and Logit Margins for Long-Tail Learning. (arXiv:2204.13208v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Varno_F/0/1/0/all/0/1\">Farshid Varno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saghayi_M/0/1/0/all/0/1\">Marzie Saghayi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rafiee_L/0/1/0/all/0/1\">Laya Rafiee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Sharut Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matwin_S/0/1/0/all/0/1\">Stan Matwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Havaei_M/0/1/0/all/0/1\">Mohammad Havaei</a>",
          "description": "In Federated Learning a number of clients collaborate to train a model\nwithout sharing their data. Client models are optimized locally and are\ncommunicated through a central hub called server. A major challenge is to deal\nwith heterogeneity among clients' data which causes the local optimization to\ndrift away with respect to the global objective. In order to estimate and\ntherefore remove this drift, variance reduction techniques have been\nincorporated into Federated Learning optimization recently. However, the\nexisting solutions propagate the error of their estimations, throughout the\noptimization trajectory which leads to inaccurate approximations of the\nclients' drift and ultimately failure to remove them properly. In this paper,\nwe address this issue by introducing an adaptive algorithm that efficiently\nreduces clients' drift. Compared to the previous works on adapting variance\nreduction to Federated Learning, our approach uses less or the same level of\ncommunication bandwidth, computation or memory. Additionally, it addresses the\ninstability problem--prevalent in prior work, caused by increasing norm of the\nestimates which makes our approach a much more practical solution for large\nscale Federated Learning settings. Our experimental results demonstrate that\nthe proposed algorithm converges significantly faster and achieves higher\naccuracy compared to the baselines in an extensive set of Federated Learning\nbenchmarks.",
          "link": "http://arxiv.org/abs/2204.13170",
          "publishedOn": "2022-04-30T01:01:34.432Z",
          "wordCount": null,
          "title": "Minimizing Client Drift in Federated Learning via Adaptive Bias Estimation. (arXiv:2204.13170v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1\">Zhiying Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Junjie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_C/0/1/0/all/0/1\">Changhong Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wei-Shi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruixuan Wang</a>",
          "description": "Deep learning has shown its human-level performance in various applications.\nHowever, current deep learning models are characterised by catastrophic\nforgetting of old knowledge when learning new classes. This poses a challenge\nparticularly in intelligent diagnosis systems where initially only training\ndata of a limited number of diseases are available. In this case, updating the\nintelligent system with data of new diseases would inevitably downgrade its\nperformance on previously learned diseases. Inspired by the process of learning\nnew knowledge in human brains, we propose a Bayesian generative model for\ncontinual learning built on a fixed pre-trained feature extractor. In this\nmodel, knowledge of each old class can be compactly represented by a collection\nof statistical distributions, e.g. with Gaussian mixture models, and naturally\nkept from forgetting in continual learning over time. Unlike existing\nclass-incremental learning methods, the proposed approach is not sensitive to\nthe continual learning process and can be additionally well applied to the\ndata-incremental learning scenario. Experiments on multiple medical and natural\nimage classification tasks showed that the proposed approach outperforms\nstate-of-the-art approaches which even keep some images of old classes during\ncontinual learning of new classes.",
          "link": "http://arxiv.org/abs/2204.13349",
          "publishedOn": "2022-04-30T01:01:34.430Z",
          "wordCount": null,
          "title": "Continual Learning with Bayesian Model based on a Fixed Pre-trained Feature Extractor. (arXiv:2204.13349v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13160",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zelong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jianchao Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "In recommendation systems, the choice of loss function is critical since a\ngood loss may significantly improve the model performance. However, manually\ndesigning a good loss is a big challenge due to the complexity of the problem.\nA large fraction of previous work focuses on handcrafted loss functions, which\nneeds significant expertise and human effort. In this paper, inspired by the\nrecent development of automated machine learning, we propose an automatic loss\nfunction generation framework, AutoLossGen, which is able to generate loss\nfunctions directly constructed from basic mathematical operators without prior\nknowledge on loss structure. More specifically, we develop a controller model\ndriven by reinforcement learning to generate loss functions, and develop\niterative and alternating optimization schedule to update the parameters of\nboth the controller model and the recommender model. One challenge for\nautomatic loss generation in recommender systems is the extreme sparsity of\nrecommendation datasets, which leads to the sparse reward problem for loss\ngeneration and search. To solve the problem, we further develop a reward\nfiltering mechanism for efficient and effective loss generation. Experimental\nresults show that our framework manages to create tailored loss functions for\ndifferent recommendation models and datasets, and the generated loss gives\nbetter recommendation performance than commonly used baseline losses. Besides,\nmost of the generated losses are transferable, i.e., the loss generated based\non one model and dataset also works well for another model or dataset. Source\ncode of the work is available at https://github.com/rutgerswiselab/AutoLossGen.",
          "link": "http://arxiv.org/abs/2204.13160",
          "publishedOn": "2022-04-30T01:01:34.427Z",
          "wordCount": null,
          "title": "AutoLossGen: Automatic Loss Function Generation for Recommender Systems. (arXiv:2204.13160v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jahani_Nezhad_T/0/1/0/all/0/1\">Tayyebeh Jahani-Nezhad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddah_Ali_M/0/1/0/all/0/1\">Mohammad Ali Maddah-Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Songze Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caire_G/0/1/0/all/0/1\">Giuseppe Caire</a>",
          "description": "We propose SwiftAgg+, a novel secure aggregation protocol for federated\nlearning systems, where a central server aggregates local models of $N \\in\n\\mathbb{N}$ distributed users, each of size $L \\in \\mathbb{N}$, trained on\ntheir local data, in a privacy-preserving manner. SwiftAgg+ can significantly\nreduce the communication overheads without any compromise on security, and\nachieve optimal communication loads within diminishing gaps. Specifically, in\npresence of at most $D$ dropout users, SwiftAgg+ achieves a per-user\ncommunication load of $(1+\\mathcal{O}(\\frac{1}{N}))L$ and a server\ncommunication load of $(1+\\mathcal{O}(\\frac{1}{N}))L$, with a worst-case\ninformation-theoretic security guarantee, against any subset of up to $T$\nsemi-honest users who may also collude with the curious server. Moreover, the\nproposed SwiftAgg+ allows for a flexible trade-off between communication loads\nand the number of active communication links. In particular, for any\n$K\\in\\mathbb{N}$, SwiftAgg+ can achieve the server communication load of\n$(1+\\frac{T}{K})L$, and per-user communication load of up to\n$(1+\\frac{T+D}{K})L$, where the number of pair-wise active connections in the\nnetwork is $\\frac{N}{2}(K+T+D+1)$.",
          "link": "http://arxiv.org/abs/2203.13060",
          "publishedOn": "2022-04-30T01:01:34.424Z",
          "wordCount": null,
          "title": "SwiftAgg+: Achieving Asymptotically Optimal Communication Loads in Secure Aggregation for Federated Learning. (arXiv:2203.13060v2 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.10613",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Terenin_A/0/1/0/all/0/1\">Alexander Terenin</a>",
          "description": "Bayesian learning using Gaussian processes provides a foundational framework\nfor making decisions in a manner that balances what is known with what could be\nlearned by gathering data. In this dissertation, we develop techniques for\nbroadening the applicability of Gaussian processes. This is done in two ways.\nFirstly, we develop pathwise conditioning techniques for Gaussian processes,\nwhich allow one to express posterior random functions as prior random functions\nplus a dependent update term. We introduce a wide class of efficient\napproximations built from this viewpoint, which can be randomly sampled once in\nadvance, and evaluated at arbitrary locations without any subsequent\nstochasticity. This key property improves efficiency and makes it simpler to\ndeploy Gaussian process models in decision-making settings. Secondly, we\ndevelop a collection of Gaussian process models over non-Euclidean spaces,\nincluding Riemannian manifolds and graphs. We derive fully constructive\nexpressions for the covariance kernels of scalar-valued Gaussian processes on\nRiemannian manifolds and graphs. Building on these ideas, we describe a\nformalism for defining vector-valued Gaussian processes on Riemannian\nmanifolds. The introduced techniques allow all of these models to be trained\nusing standard computational methods. In total, these contributions make\nGaussian processes easier to work with and allow them to be used within a wider\nclass of domains in an effective and principled manner. This, in turn, makes it\npossible to potentially apply Gaussian processes to novel decision-making\nsettings.",
          "link": "http://arxiv.org/abs/2202.10613",
          "publishedOn": "2022-04-30T01:01:34.388Z",
          "wordCount": null,
          "title": "Gaussian Processes and Statistical Decision-making in Non-Euclidean Spaces. (arXiv:2202.10613v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.15938",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_W/0/1/0/all/0/1\">Wenliang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nishioka_M/0/1/0/all/0/1\">Mirai Nishioka</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Belta_C/0/1/0/all/0/1\">Calin Belta</a>",
          "description": "We propose a policy search approach to learn controllers from specifications\ngiven as Signal Temporal Logic (STL) formulae. The system model, which is\nunknown but assumed to be an affine control system, is learned together with\nthe control policy. The model is implemented as two feedforward neural networks\n(FNNs) - one for the drift, and one for the control directions. To capture the\nhistory dependency of STL specifications, we use a recurrent neural network\n(RNN) to implement the control policy. In contrast to prevalent model-free\nmethods, the learning approach proposed here takes advantage of the learned\nmodel and is more efficient. We use control barrier functions (CBFs) with the\nlearned model to improve the safety of the system. We validate our algorithm\nvia simulations and experiments. The results show that our approach can satisfy\nthe given specification within very few system runs, and can be used for\non-line control.",
          "link": "http://arxiv.org/abs/2103.15938",
          "publishedOn": "2022-04-30T01:01:34.306Z",
          "wordCount": null,
          "title": "Model-Based Safe Policy Search from Signal Temporal Logic Specifications Using Recurrent Neural Networks. (arXiv:2103.15938v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.11264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feihu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>",
          "description": "In the paper, we propose an effective and efficient Compositional Federated\nLearning (ComFedL) algorithm for solving a new compositional Federated Learning\n(FL) framework, which frequently appears in many data mining and machine\nlearning problems with a hierarchical structure such as distributionally robust\nFL and model-agnostic meta learning (MAML). Moreover, we study the convergence\nanalysis of our ComFedL algorithm under some mild conditions, and prove that it\nachieves a convergence rate of $O(\\frac{1}{\\sqrt{T}})$, where $T$ denotes the\nnumber of iteration. To the best of our knowledge, our new Compositional FL\nframework is the first work to bridge federated learning with composition\nstochastic optimization. In particular, we first transform the distributionally\nrobust FL (i.e., a minimax optimization problem) into a simple composition\noptimization problem by using KL divergence regularization. At the same time,\nwe also first transform the distribution-agnostic MAML problem (i.e., a minimax\noptimization problem) into a simple yet effective composition optimization\nproblem. Finally, we apply two popular machine learning tasks, i.e.,\ndistributionally robust FL and MAML to demonstrate the effectiveness of our\nalgorithm.",
          "link": "http://arxiv.org/abs/2106.11264",
          "publishedOn": "2022-04-30T01:01:34.305Z",
          "wordCount": null,
          "title": "Compositional Federated Learning for Distributionally Robust and Meta Learning. (arXiv:2106.11264v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.07415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yunhao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiuyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1\">Daiyi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1\">Deepali Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wenbo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1\">Aldo Pacchiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarlos_T/0/1/0/all/0/1\">Tamas Sarlos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuxiang Yang</a>",
          "description": "In this paper, we approach the problem of optimizing blackbox functions over\nlarge hybrid search spaces consisting of both combinatorial and continuous\nparameters. We demonstrate that previous evolutionary algorithms which rely on\nmutation-based approaches, while flexible over combinatorial spaces, suffer\nfrom a curse of dimensionality in high dimensional continuous spaces both\ntheoretically and empirically, which thus limits their scope over hybrid search\nspaces as well. In order to combat this curse, we propose ES-ENAS, a simple and\nmodular joint optimization procedure combining the class of sample-efficient\nsmoothed gradient gradient techniques, commonly known as Evolutionary\nStrategies (ES), with combinatorial optimizers in a highly scalable and\nintuitive way, inspired by the one-shot or supernet paradigm introduced in\nEfficient Neural Architecture Search (ENAS). By doing so, we achieve\nsignificantly more sample efficiency, which we empirically demonstrate over\nsynthetic benchmarks, and are further able to apply ES-ENAS for architecture\nsearch over popular RL benchmarks.",
          "link": "http://arxiv.org/abs/2101.07415",
          "publishedOn": "2022-04-30T01:01:34.265Z",
          "wordCount": null,
          "title": "ES-ENAS: Blackbox Optimization over Hybrid Spaces via Combinatorial and Continuous Evolution. (arXiv:2101.07415v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.05143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yousef_W/0/1/0/all/0/1\">Waleed A. Yousef</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Traore_I/0/1/0/all/0/1\">Issa Traore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briguglio_W/0/1/0/all/0/1\">William Briguglio</a>",
          "description": "This paper explores the calibration of a classifier output score in binary\nclassification problems. A calibrator is a function that maps the arbitrary\nclassifier score, of a testing observation, onto $[0,1]$ to provide an estimate\nfor the posterior probability of belonging to one of the two classes.\nCalibration is important for two reasons; first, it provides a meaningful\nscore, that is the posterior probability; second, it puts the scores of\ndifferent classifiers on the same scale for comparable interpretation. The\npaper presents three main contributions: (1) Introducing multi-score\ncalibration, when more than one classifier provides a score for a single\nobservation. (2) Introducing the idea that the classifier scores to a\ncalibration process are nothing but features to a classifier, hence proposing\nexpanding the classifier scores to higher dimensions to boost the calibrator's\nperformance. (3) Conducting a massive simulation study, in the order of 24,000\nexperiments, that incorporates different configurations, in addition to\nexperimenting on two real datasets from the cybersecurity domain. The results\nshow that there is no overall winner among the different calibrators and\ndifferent configurations. However, general advices for practitioners include\nthe following: the Platt's\ncalibrator~\\citep{Platt1999ProbabilisticOutputsForSupport}, a version of the\nlogistic regression that decreases bias for a small sample size, has a very\nstable and acceptable performance among all experiments; our suggested\nmulti-score calibration provides better performance than single score\ncalibration in the majority of experiments, including the two real datasets. In\naddition, expanding the scores can help in some experiments.",
          "link": "http://arxiv.org/abs/2102.05143",
          "publishedOn": "2022-04-30T01:01:34.259Z",
          "wordCount": null,
          "title": "Classifier Calibration: with application to threat scores in cybersecurity. (arXiv:2102.05143v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.11845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bin Liu</a>",
          "description": "This letter is concerned with image classification with deep convolutional\nneural networks (CNNs). The focus is on the following question: given a set of\ncandidate CNN models, how to select the right one with the best generalization\nproperty for the current task? Present model selection methods require access\nto a batch of labeled data for computing a pre-specified performance metric,\nsuch as the cross-entropy loss, the classification error rate, the negative\nlog-likelihood. In many practical cases, labels are not available in time as\nlabeling itself is a time-consuming and expensive task. To this end, this\nletter presents an approach to CNN model selection using only unlabeled data.\nThis method is developed based on a principle termed consistent relative\nconfidence. The effectiveness and efficiency of the proposed method are\ndemonstrated by experiments using benchmark datasets.",
          "link": "http://arxiv.org/abs/2108.11845",
          "publishedOn": "2022-04-30T01:01:34.246Z",
          "wordCount": null,
          "title": "Consistent Relative Confidence and Label-Free Model Selection for Convolutional Neural Networks. (arXiv:2108.11845v7 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.03278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Minh N. H. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1\">Shashi Raj Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1\">Tri Nguyen Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huh_E/0/1/0/all/0/1\">Eui-Nam Huh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_N/0/1/0/all/0/1\">Nguyen H. Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1\">Walid Saad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1\">Choong Seon Hong</a>",
          "description": "Emerging cross-device artificial intelligence (AI) applications require a\ntransition from conventional centralized learning systems towards large-scale\ndistributed AI systems that can collaboratively perform complex learning tasks.\nIn this regard, democratized learning (Dem-AI) lays out a holistic philosophy\nwith underlying principles for building large-scale distributed and\ndemocratized machine learning systems. The outlined principles are meant to\nstudy a generalization in distributed learning systems that goes beyond\nexisting mechanisms such as federated learning. Moreover, such learning systems\nrely on hierarchical self-organization of well-connected distributed learning\nagents who have limited and highly personalized data and can evolve and\nregulate themselves based on the underlying duality of specialized and\ngeneralized processes. Inspired by Dem-AI philosophy, a novel distributed\nlearning approach is proposed in this paper. The approach consists of a\nself-organizing hierarchical structuring mechanism based on agglomerative\nclustering, hierarchical generalization, and corresponding learning mechanism.\nSubsequently, hierarchical generalized learning problems in recursive forms are\nformulated and shown to be approximately solved using the solutions of\ndistributed personalized learning problems and hierarchical update mechanisms.\nTo that end, a distributed learning algorithm, namely DemLearn is proposed.\nExtensive experiments on benchmark MNIST, Fashion-MNIST, FE-MNIST, and CIFAR-10\ndatasets show that the proposed algorithms demonstrate better results in the\ngeneralization performance of learning models in agents compared to the\nconventional FL algorithms. The detailed analysis provides useful observations\nto further handle both the generalization and specialization performance of the\nlearning models in Dem-AI systems.",
          "link": "http://arxiv.org/abs/2007.03278",
          "publishedOn": "2022-04-30T01:01:34.232Z",
          "wordCount": null,
          "title": "Self-organizing Democratized Learning: Towards Large-scale Distributed Learning Systems. (arXiv:2007.03278v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.06236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pejo_B/0/1/0/all/0/1\">Bal&#xe1;zs Pej&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Totth_A/0/1/0/all/0/1\">Andr&#xe1;s T&#xf3;tth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biczok_G/0/1/0/all/0/1\">Gergely Bicz&#xf3;k</a>",
          "description": "Federated learning algorithms are developed both for efficiency reasons and\nto ensure the privacy and confidentiality of personal and business data,\nrespectively. Despite no data being shared explicitly, recent studies showed\nthat the mechanism could still leak sensitive information. Hence, secure\naggregation is utilized in many real-world scenarios to prevent attribution to\nspecific participants. In this paper, we focus on the quality of individual\ntraining datasets and show that such quality information could be inferred and\nattributed to specific participants even when secure aggregation is applied.\nSpecifically, through a series of image recognition experiments, we infer the\nrelative quality ordering of participants. Moreover, we apply the inferred\nquality information to detect misbehaviours, to stabilize training performance,\nand to measure the individual contributions of participants.",
          "link": "http://arxiv.org/abs/2007.06236",
          "publishedOn": "2022-04-30T01:01:34.230Z",
          "wordCount": null,
          "title": "Quality Inference in Federated Learning with Secure Aggregation. (arXiv:2007.06236v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13590",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_N/0/1/0/all/0/1\">Nachuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Jiahe Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenshuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lihua Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1\">Rui Fan</a>",
          "description": "Computer vision algorithms have been prevalently utilized for 3-D road\nimaging and pothole detection for over two decades. Nonetheless, there is a\nlack of systematic survey articles on state-of-the-art (SoTA) computer vision\ntechniques, especially deep learning models, developed to tackle these\nproblems. This article first introduces the sensing systems employed for 2-D\nand 3-D road data acquisition, including camera(s), laser scanners, and\nMicrosoft Kinect. Afterward, it thoroughly and comprehensively reviews the SoTA\ncomputer vision algorithms, including (1) classical 2-D image processing, (2)\n3-D point cloud modeling and segmentation, and (3) machine/deep learning,\ndeveloped for road pothole detection. This article also discusses the existing\nchallenges and future development trends of computer vision-based road pothole\ndetection approaches: classical 2-D image processing-based and 3-D point cloud\nmodeling and segmentation-based approaches have already become history; and\nConvolutional neural networks (CNNs) have demonstrated compelling road pothole\ndetection results and are promising to break the bottleneck with the future\nadvances in self/un-supervised learning for multi-modal semantic segmentation.\nWe believe that this survey can serve as practical guidance for developing the\nnext-generation road condition assessment systems.",
          "link": "http://arxiv.org/abs/2204.13590",
          "publishedOn": "2022-04-30T01:01:34.147Z",
          "wordCount": null,
          "title": "Computer Vision for Road Imaging and Pothole Detection: A State-of-the-Art Review of Systems and Algorithms. (arXiv:2204.13590v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gusev_I/0/1/0/all/0/1\">Ilya Gusev</a>",
          "description": "Text detoxification is a style transfer task of creating neutral versions of\ntoxic texts. In this paper, we use the concept of text editing to build a\ntwo-step tagging-based detoxification model using a parallel corpus of Russian\ntexts. With this model, we achieved the best style transfer accuracy among all\nmodels in the RUSSE Detox shared task, surpassing larger sequence-to-sequence\nmodels.",
          "link": "http://arxiv.org/abs/2204.13638",
          "publishedOn": "2022-04-30T01:01:34.146Z",
          "wordCount": null,
          "title": "Russian Texts Detoxification with Levenshtein Editing. (arXiv:2204.13638v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chodrow_P/0/1/0/all/0/1\">Philip Chodrow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eikmeier_N/0/1/0/all/0/1\">Nicole Eikmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haddock_J/0/1/0/all/0/1\">Jamie Haddock</a>",
          "description": "Spectral methods offer a tractable, global framework for clustering in graphs\nvia eigenvector computations on graph matrices. Hypergraph data, in which\nentities interact on edges of arbitrary size, poses challenges for matrix\nrepresentations and therefore for spectral clustering. We study spectral\nclustering for nonuniform hypergraphs based on the hypergraph nonbacktracking\noperator. After reviewing the definition of this operator and its basic\nproperties, we prove a theorem of Ihara-Bass type to enable faster computation\nof eigenpairs. We then propose an alternating algorithm for inference in a\nhypergraph stochastic blockmodel via linearized belief-propagation, offering\nproofs that both formalize and extend several previous results. We perform\nexperiments in real and synthetic data that underscore the benefits of\nhypergraph methods over graph-based ones when interactions of different sizes\ncarry different information about cluster structure. Through an analysis of our\nalgorithm, we pose several conjectures about the limits of spectral methods and\ndetectability in hypergraph stochastic blockmodels writ large.",
          "link": "http://arxiv.org/abs/2204.13586",
          "publishedOn": "2022-04-30T01:01:34.135Z",
          "wordCount": null,
          "title": "Nonbacktracking spectral clustering of nonuniform hypergraphs. (arXiv:2204.13586v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13597",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Alzantot_M/0/1/0/all/0/1\">Moustafa Alzantot</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garcia_L/0/1/0/all/0/1\">Luis Garcia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Srivastava_M/0/1/0/all/0/1\">Mani Srivastava</a>",
          "description": "Generative models such as the variational autoencoder (VAE) and the\ngenerative adversarial networks (GAN) have proven to be incredibly powerful for\nthe generation of synthetic data that preserves statistical properties and\nutility of real-world datasets, especially in the context of image and natural\nlanguage text. Nevertheless, until now, there has no successful demonstration\nof how to apply either method for generating useful physiological sensory data.\nThe state-of-the-art techniques in this context have achieved only limited\nsuccess. We present PHYSIOGAN, a generative model to produce high fidelity\nsynthetic physiological sensor data readings. PHYSIOGAN consists of an encoder,\ndecoder, and a discriminator. We evaluate PHYSIOGAN against the\nstate-of-the-art techniques using two different real-world datasets: ECG\nclassification and activity recognition from motion sensors datasets. We\ncompare PHYSIOGAN to the baseline models not only the accuracy of class\nconditional generation but also the sample diversity and sample novelty of the\nsynthetic datasets. We prove that PHYSIOGAN generates samples with higher\nutility than other generative models by showing that classification models\ntrained on only synthetic data generated by PHYSIOGAN have only 10% and 20%\ndecrease in their classification accuracy relative to classification models\ntrained on the real data. Furthermore, we demonstrate the use of PHYSIOGAN for\nsensor data imputation in creating plausible results.",
          "link": "http://arxiv.org/abs/2204.13597",
          "publishedOn": "2022-04-30T01:01:34.110Z",
          "wordCount": null,
          "title": "PhysioGAN: Training High Fidelity Generative Model for Physiological Sensor Readings. (arXiv:2204.13597v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_B/0/1/0/all/0/1\">Boxiang Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanzely_F/0/1/0/all/0/1\">Filip Hanzely</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolar_M/0/1/0/all/0/1\">Mladen Kolar</a>",
          "description": "We consider the problem of personalized federated learning when there are\nknown cluster structures within users. An intuitive approach would be to\nregularize the parameters so that users in the same cluster share similar model\nweights. The distances between the clusters can then be regularized to reflect\nthe similarity between different clusters of users. We develop an algorithm\nthat allows each cluster to communicate independently and derive the\nconvergence results. We study a hierarchical linear model to theoretically\ndemonstrate that our approach outperforms agents learning independently and\nagents learning a single shared weight. Finally, we demonstrate the advantages\nof our approach using both simulated and real-world data.",
          "link": "http://arxiv.org/abs/2204.13619",
          "publishedOn": "2022-04-30T01:01:34.102Z",
          "wordCount": null,
          "title": "Personalized Federated Learning with Multiple Known Clusters. (arXiv:2204.13619v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.11822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dubing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yuming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haofeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H.S. Torr</a>",
          "description": "Semantic-descriptor-based Generalized Zero-Shot Learning (GZSL) poses\nchallenges in recognizing novel classes in the test phase. The development of\ngenerative models enables current GZSL techniques to probe further into the\nsemantic-visual link, culminating in a two-stage form that includes a generator\nand a classifier. However, existing generation-based methods focus on enhancing\nthe generator's effect while neglecting the improvement of the classifier. In\nthis paper, we first analyze of two properties of the generated pseudo unseen\nsamples: bias and homogeneity. Then, we perform variational Bayesian inference\nto back-derive the evaluation metrics, which reflects the balance of the seen\nand unseen classes. As a consequence of our derivation, the aforementioned two\nproperties are incorporated into the classifier training as seen-unseen priors\nvia logit adjustment. The Zero-Shot Logit Adjustment further puts\nsemantic-based classifiers into effect in generation-based GZSL. Our\nexperiments demonstrate that the proposed technique achieves state-of-the-art\nwhen combined with the basic generator, and it can improve various generative\nzero-shot learning frameworks. Our codes are available on\nhttps://github.com/cdb342/IJCAI-2022-ZLA.",
          "link": "http://arxiv.org/abs/2204.11822",
          "publishedOn": "2022-04-30T01:01:34.092Z",
          "wordCount": null,
          "title": "Zero-Shot Logit Adjustment. (arXiv:2204.11822v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13591",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yixing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bert_C/0/1/0/all/0/1\">Christoph Bert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_S/0/1/0/all/0/1\">Stefan Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1\">Manuel Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dorfler_A/0/1/0/all/0/1\">Arnd D&#xf6;rfler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fietkau_R/0/1/0/all/0/1\">Rainer Fietkau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Putz_F/0/1/0/all/0/1\">Florian Putz</a>",
          "description": "Due to data privacy constraints, data sharing among multiple centers is\nrestricted. Continual learning, as one approach to peer-to-peer federated\nlearning, can promote multicenter collaboration on deep learning algorithm\ndevelopment by sharing intermediate models instead of training data. This work\naims to investigate the feasibility of continual learning for multicenter\ncollaboration on an exemplary application of brain metastasis identification\nusing DeepMedic. 920 T1 MRI contrast enhanced volumes are split to simulate\nmulticenter collaboration scenarios. A continual learning algorithm, synaptic\nintelligence (SI), is applied to preserve important model weights for training\none center after another. In a bilateral collaboration scenario, continual\nlearning with SI achieves a sensitivity of 0.917, and naive continual learning\nwithout SI achieves a sensitivity of 0.906, while two models trained on\ninternal data solely without continual learning achieve sensitivity of 0.853\nand 0.831 only. In a seven-center multilateral collaboration scenario, the\nmodels trained on internal datasets (100 volumes each center) without continual\nlearning obtain a mean sensitivity value of 0.725. With single-visit continual\nlearning (i.e., the shared model visits each center only once during training),\nthe sensitivity is improved to 0.788 and 0.849 without SI and with SI,\nrespectively. With iterative continual learning (i.e., the shared model\nrevisits each center multiple times during training), the sensitivity is\nfurther improved to 0.914, which is identical to the sensitivity using mixed\ndata for training. Our experiments demonstrate that continual learning can\nimprove brain metastasis identification performance for centers with limited\ndata. This study demonstrates the feasibility of applying continual learning\nfor peer-to-peer federated learning in multicenter collaboration.",
          "link": "http://arxiv.org/abs/2204.13591",
          "publishedOn": "2022-04-30T01:01:34.077Z",
          "wordCount": null,
          "title": "Continual Learning for Peer-to-Peer Federated Learning: A Study on Automated Brain Metastasis Identification. (arXiv:2204.13591v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bergamim_E/0/1/0/all/0/1\">Em&#xed;lio Bergamim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breve_F/0/1/0/all/0/1\">Fabricio Breve</a>",
          "description": "Semi-supervised learning (SSL) has become an interesting research area due to\nits capacity for learning in scenarios where both labeled and unlabeled data\nare available. In this work, we focus on the task of transduction - when the\nobjective is to label all data presented to the learner - with a mean-field\napproximation to the Potts model. Aiming at this particular task we study how\nclassification results depend on $\\beta$ and find that the optimal phase\ndepends highly on the amount of labeled data available. In the same study, we\nalso observe that more stable classifications regarding small fluctuations in\n$\\beta$ are related to configurations of high probability and propose a tuning\napproach based on such observation. This method relies on a novel parameter\n$\\gamma$ and we then evaluate two different values of the said quantity in\ncomparison with classical methods in the field. This evaluation is conducted by\nchanging the amount of labeled data available and the number of nearest\nneighbors in the similarity graph. Empirical results show that the tuning\nmethod is effective and allows NMF to outperform other approaches in datasets\nwith fewer classes. In addition, one of the chosen values for $\\gamma$ also\nleads to results that are more resilient to changes in the number of neighbors,\nwhich might be of interest to practitioners in the field of SSL.",
          "link": "http://arxiv.org/abs/2204.13519",
          "publishedOn": "2022-04-30T01:01:34.069Z",
          "wordCount": null,
          "title": "On tuning a mean-field model for semi-supervised classification. (arXiv:2204.13519v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Spithourakis_G/0/1/0/all/0/1\">Georgios P. Spithourakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lis_M/0/1/0/all/0/1\">Micha&#x142; Lis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casanueva_I/0/1/0/all/0/1\">I&#xf1;igo Casanueva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budzianowski_P/0/1/0/all/0/1\">Pawe&#x142; Budzianowski</a>",
          "description": "Knowledge-based authentication is crucial for task-oriented spoken dialogue\nsystems that offer personalised and privacy-focused services. Such systems\nshould be able to enrol (E), verify (V), and identify (I) new and recurring\nusers based on their personal information, e.g. postcode, name, and date of\nbirth. In this work, we formalise the three authentication tasks and their\nevaluation protocols, and we present EVI, a challenging spoken multilingual\ndataset with 5,506 dialogues in English, Polish, and French. Our proposed\nmodels set the first competitive benchmarks, explore the challenges of\nmultilingual natural language processing of spoken dialogue, and set directions\nfor future research.",
          "link": "http://arxiv.org/abs/2204.13496",
          "publishedOn": "2022-04-30T01:01:34.065Z",
          "wordCount": null,
          "title": "EVI: Multilingual Spoken Dialogue Tasks and Dataset for Knowledge-Based Enrolment, Verification, and Identification. (arXiv:2204.13496v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumabe_S/0/1/0/all/0/1\">Soh Kumabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiroshita_S/0/1/0/all/0/1\">Shinya Shiroshita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayashi_T/0/1/0/all/0/1\">Takanori Hayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maruyama_S/0/1/0/all/0/1\">Shirou Maruyama</a>",
          "description": "Inventory management in warehouses directly affects profits made by\nmanufacturers. Particularly, large manufacturers produce a very large variety\nof products that are handled by a significantly large number of retailers. In\nsuch a case, the computational complexity of classical inventory management\nalgorithms is inordinately large. In recent years, learning-based approaches\nhave become popular for addressing such problems. However, previous studies\nhave not been managed systems where both the number of products and retailers\nare large. This study proposes a reinforcement learning-based warehouse\ninventory management algorithm that can be used for supply chain systems where\nboth the number of products and retailers are large. To solve the computational\nproblem of handling large systems, we provide a means of approximate simulation\nof the system in the training phase. Our experiments on both real and\nartificial data demonstrate that our algorithm with approximated simulation can\nsuccessfully handle large supply chain networks.",
          "link": "http://arxiv.org/abs/2204.13378",
          "publishedOn": "2022-04-30T01:01:34.061Z",
          "wordCount": null,
          "title": "Learning General Inventory Management Policy for Large Supply Chain Network. (arXiv:2204.13378v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13572",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Buris_L/0/1/0/all/0/1\">Luiz H. Buris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedronette_D/0/1/0/all/0/1\">Daniel C. G. Pedronette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papa_J/0/1/0/all/0/1\">Joao P. Papa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almeida_J/0/1/0/all/0/1\">Jurandy Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1\">Gustavo Carneiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faria_F/0/1/0/all/0/1\">Fabio A. Faria</a>",
          "description": "Deep learning architectures have achieved promising results in different\nareas (e.g., medicine, agriculture, and security). However, using those\npowerful techniques in many real applications becomes challenging due to the\nlarge labeled collections required during training. Several works have pursued\nsolutions to overcome it by proposing strategies that can learn more for less,\ne.g., weakly and semi-supervised learning approaches. As these approaches do\nnot usually address memorization and sensitivity to adversarial examples, this\npaper presents three deep metric learning approaches combined with Mixup for\nincomplete-supervision scenarios. We show that some state-of-the-art approaches\nin metric learning might not work well in such scenarios. Moreover, the\nproposed approaches outperform most of them in different datasets.",
          "link": "http://arxiv.org/abs/2204.13572",
          "publishedOn": "2022-04-30T01:01:34.014Z",
          "wordCount": null,
          "title": "Mixup-based Deep Metric Learning Approaches for Incomplete Supervision. (arXiv:2204.13572v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_P/0/1/0/all/0/1\">Pengyue Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Ming Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jie Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musilek_P/0/1/0/all/0/1\">Petr Musilek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingyu Li</a>",
          "description": "Adversarial training is an effective method to boost model robustness to\nmalicious, adversarial attacks. However, such improvement in model robustness\noften leads to a significant sacrifice of standard performance on clean images.\nIn many real-world applications such as health diagnosis and autonomous\nsurgical robotics, the standard performance is more valued over model\nrobustness against such extremely malicious attacks. This leads to the\nquestion: To what extent we can boost model robustness without sacrificing\nstandard performance? This work tackles this problem and proposes a simple yet\neffective transfer learning-based adversarial training strategy that\ndisentangles the negative effects of adversarial samples on model's standard\nperformance. In addition, we introduce a training-friendly adversarial attack\nalgorithm, which facilitates the boost of adversarial robustness without\nintroducing significant training complexity. Extensive experimentation\nindicates that the proposed method outperforms previous adversarial training\nalgorithms towards the target: to improve model robustness while preserving\nmodel's standard performance on clean data.",
          "link": "http://arxiv.org/abs/2204.13232",
          "publishedOn": "2022-04-30T01:01:34.009Z",
          "wordCount": null,
          "title": "Adversarial Fine-tune with Dynamically Regulated Adversary. (arXiv:2204.13232v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beck_E/0/1/0/all/0/1\">Edgar Beck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bockelmann_C/0/1/0/all/0/1\">Carsten Bockelmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dekorsy_A/0/1/0/all/0/1\">Armin Dekorsy</a>",
          "description": "Motivated by recent success of machine learning tools at the PHY layer and\ndriven by high bandwidth demands of the next wireless communication standard\n6G, the old idea of semantic communication by Weaver from 1949 has received\nconsiderable attention. It breaks with the classic design paradigm according to\nShannon by aiming to transmit the meaning of a message rather than its exact\ncopy and thus potentially allows for savings in bandwidth.\n\nIn this work, inspired by Weaver, we propose an information-theoretic\nframework where the semantic context is explicitly introduced into\nprobabilistic models. In particular, for bandwidth efficient transmission, we\ndefine semantic communication system design as an Information Bottleneck\noptimization problem and consider important implementation aspects. Further, we\nuncover the restrictions of the classic 5G communication system design w.r.t.\nsemantic context. Notably, based on the example of distributed image\nclassification, we reveal the huge potential of a semantic communication system\ndesign. Numerical results show a tremendous saving in bandwidth of 20 dB with\nour proposed approach ISCNet compared to a classic PHY layer design.",
          "link": "http://arxiv.org/abs/2204.13366",
          "publishedOn": "2022-04-30T01:01:33.977Z",
          "wordCount": null,
          "title": "Semantic Communication: An Information Bottleneck View. (arXiv:2204.13366v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13409",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stephan_A/0/1/0/all/0/1\">Andreas Stephan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1\">Benjamin Roth</a>",
          "description": "A popular approach to decrease the need for costly manual annotation of large\ndata sets is weak supervision, which introduces problems of noisy labels,\ncoverage and bias. Methods for overcoming these problems have either relied on\ndiscriminative models, trained with cost functions specific to weak\nsupervision, and more recently, generative models, trying to model the output\nof the automatic annotation process. In this work, we explore a novel direction\nof generative modeling for weak supervision: Instead of modeling the output of\nthe annotation process (the labeling function matches), we generatively model\nthe input-side data distributions (the feature space) covered by labeling\nfunctions. Specifically, we estimate a density for each weak labeling source,\nor labeling function, by using normalizing flows. An integral part of our\nmethod is the flow-based modeling of multiple simultaneously matching labeling\nfunctions, and therefore phenomena such as labeling function overlap and\ncorrelations are captured. We analyze the effectiveness and modeling\ncapabilities on various commonly used weak supervision data sets, and show that\nweakly supervised normalizing flows compare favorably to standard weak\nsupervision baselines.",
          "link": "http://arxiv.org/abs/2204.13409",
          "publishedOn": "2022-04-30T01:01:33.911Z",
          "wordCount": null,
          "title": "WeaNF: Weak Supervision with Normalizing Flows. (arXiv:2204.13409v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.06325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dohare_S/0/1/0/all/0/1\">Shibhansh Dohare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1\">A. Rupam Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1\">Richard S. Sutton</a>",
          "description": "The Backprop algorithm for learning in neural networks utilizes two\nmechanisms: first, stochastic gradient descent and second, initialization with\nsmall random weights, where the latter is essential to the effectiveness of the\nformer. We show that in continual learning setups, Backprop performs well\ninitially, but over time its performance degrades. Stochastic gradient descent\nalone is insufficient to learn continually; the initial randomness enables only\ninitial learning but not continual learning. To the best of our knowledge, ours\nis the first result showing this degradation in Backprop's ability to learn. To\naddress this degradation in Backprop's plasticity, we propose an algorithm that\ncontinually injects random features alongside gradient descent using a new\ngenerate-and-test process. We call this the \\textit{Continual Backprop}\nalgorithm. We show that, unlike Backprop, Continual Backprop is able to\ncontinually adapt in both supervised and reinforcement learning (RL) problems.\nContinual Backprop has the same computational complexity as Backprop and can be\nseen as a natural extension of Backprop for continual learning.",
          "link": "http://arxiv.org/abs/2108.06325",
          "publishedOn": "2022-04-30T01:01:33.868Z",
          "wordCount": null,
          "title": "Continual Backprop: Stochastic Gradient Descent with Persistent Randomness. (arXiv:2108.06325v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nikolic_M/0/1/0/all/0/1\">Milo&#x161; Nikoli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_E/0/1/0/all/0/1\">Enrique Torres Sanchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiahui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zadeh_A/0/1/0/all/0/1\">Ali Hadi Zadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmoud_M/0/1/0/all/0/1\">Mostafa Mahmoud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelhadi_A/0/1/0/all/0/1\">Ameer Abdelhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moshovos_A/0/1/0/all/0/1\">Andreas Moshovos</a>",
          "description": "We introduce a software-hardware co-design approach to reduce memory traffic\nand footprint during training with BFloat16 or FP32 boosting energy efficiency\nand execution time performance. We introduce methods to dynamically adjust the\nsize and format of the floating-point containers used to store activations and\nweights during training. The different value distributions lead us to different\napproaches for exponents and mantissas. Gecko exploits the favourable exponent\ndistribution with a loss-less delta encoding approach to reduce the total\nexponent footprint by up to $58\\%$ in comparison to a 32 bit floating point\nbaseline. To content with the noisy mantissa distributions, we present two\nlossy methods to eliminate as many as possible least significant bits while not\naffecting accuracy. Quantum Mantissa, is a machine learning-first mantissa\ncompression method that taps on training's gradient descent algorithm to also\nlearn minimal mantissa bitlengths on a per-layer granularity, and obtain up to\n$92\\%$ reduction in total mantissa footprint. Alternatively, BitChop observes\nchanges in the loss function during training to adjust mantissa bit-length\nnetwork-wide yielding a reduction of $81\\%$ in footprint. Schr\\\"{o}dinger's FP\nimplements hardware encoders/decoders that guided by Gecko/Quantum Mantissa or\nGecko/BitChop transparently encode/decode values when transferring to/from\noff-chip memory boosting energy efficiency and reducing execution time.",
          "link": "http://arxiv.org/abs/2204.13666",
          "publishedOn": "2022-04-30T01:01:33.515Z",
          "wordCount": null,
          "title": "Schr\\\"odinger's FP: Dynamic Adaptation of Floating-Point Containers for Deep Learning Training. (arXiv:2204.13666v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Houliang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lifang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Brian Chen</a>",
          "description": "Identification of brain regions related to the specific neurological\ndisorders are of great importance for biomarker and diagnostic studies. In this\npaper, we propose an interpretable Graph Convolutional Network (GCN) framework\nfor the identification and classification of Alzheimer's disease (AD) using\nmulti-modality brain imaging data. Specifically, we extended the Gradient Class\nActivation Mapping (Grad-CAM) technique to quantify the most discriminative\nfeatures identified by GCN from brain connectivity patterns. We then utilized\nthem to find signature regions of interest (ROIs) by detecting the difference\nof features between regions in healthy control (HC), mild cognitive impairment\n(MCI), and AD groups. We conducted the experiments on the ADNI database with\nimaging data from three modalities, including VBM-MRI, FDG-PET, and AV45-PET,\nand showed that the ROI features learned by our method were effective for\nenhancing the performances of both clinical score prediction and disease status\nidentification. It also successfully identified biomarkers associated with AD\nand MCI.",
          "link": "http://arxiv.org/abs/2204.13188",
          "publishedOn": "2022-04-30T01:01:33.032Z",
          "wordCount": 645,
          "title": "Interpretable Graph Convolutional Network of Multi-Modality Brain Imaging for Alzheimer's Disease Diagnosis. (arXiv:2204.13188v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13342",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_G/0/1/0/all/0/1\">Gongping Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yuming Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dai_Y/0/1/0/all/0/1\">Yu Dai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1\">Jianxun Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cui_L/0/1/0/all/0/1\">Liang Cui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yin_X/0/1/0/all/0/1\">Xiaotao Yin</a>",
          "description": "Breast lesions segmentation is an important step of computer-aided diagnosis\nsystem, and it has attracted much attention. However, accurate segmentation of\nmalignant breast lesions is a challenging task due to the effects of\nheterogeneous structure and similar intensity distributions. In this paper, a\nnovel bidirectional aware guidance network (BAGNet) is proposed to segment the\nmalignant lesion from breast ultrasound images. Specifically, the bidirectional\naware guidance network is used to capture the context between global\n(low-level) and local (high-level) features from the input coarse saliency map.\nThe introduction of the global feature map can reduce the interference of\nsurrounding tissue (background) on the lesion regions. To evaluate the\nsegmentation performance of the network, we compared with several\nstate-of-the-art medical image segmentation methods on the public breast\nultrasound dataset using six commonly used evaluation metrics. Extensive\nexperimental results indicate that our method achieves the most competitive\nsegmentation results on malignant breast ultrasound images.",
          "link": "http://arxiv.org/abs/2204.13342",
          "publishedOn": "2022-04-30T01:01:33.024Z",
          "wordCount": 625,
          "title": "BAGNet: Bidirectional Aware Guidance Network for Malignant Breast lesions Segmentation. (arXiv:2204.13342v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13326",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carroll_M/0/1/0/all/0/1\">Micah Carroll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jessy Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paradise_O/0/1/0/all/0/1\">Orr Paradise</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgescu_R/0/1/0/all/0/1\">Raluca Georgescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Mingfei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bignell_D/0/1/0/all/0/1\">David Bignell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milani_S/0/1/0/all/0/1\">Stephanie Milani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hausknecht_M/0/1/0/all/0/1\">Matthew Hausknecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca Dragan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devlin_S/0/1/0/all/0/1\">Sam Devlin</a>",
          "description": "Randomly masking and predicting word tokens has been a successful approach in\npre-training language models for a variety of downstream tasks. In this work,\nwe observe that the same idea also applies naturally to sequential decision\nmaking, where many well-studied tasks like behavior cloning, offline RL,\ninverse dynamics, and waypoint conditioning correspond to different sequence\nmaskings over a sequence of states, actions, and returns. We introduce the\nFlexiBiT framework, which provides a unified way to specify models which can be\ntrained on many different sequential decision making tasks. We show that a\nsingle FlexiBiT model is simultaneously capable of carrying out many tasks with\nperformance similar to or better than specialized models. Additionally, we show\nthat performance can be further improved by fine-tuning our general model on\nspecific tasks of interest.",
          "link": "http://arxiv.org/abs/2204.13326",
          "publishedOn": "2022-04-30T01:01:33.017Z",
          "wordCount": 580,
          "title": "Towards Flexible Inference in Sequential Decision Problems via Bidirectional Transformers. (arXiv:2204.13326v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yadav_K/0/1/0/all/0/1\">Karmesh Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramrakhya_R/0/1/0/all/0/1\">Ram Ramrakhya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumdar_A/0/1/0/all/0/1\">Arjun Majumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berges_V/0/1/0/all/0/1\">Vincent-Pierre Berges</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhar_S/0/1/0/all/0/1\">Sachit Kuhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1\">Dhruv Batra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1\">Alexei Baevski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maksymets_O/0/1/0/all/0/1\">Oleksandr Maksymets</a>",
          "description": "How should we learn visual representations for embodied agents that must see\nand move? The status quo is tabula rasa in vivo, i.e. learning visual\nrepresentations from scratch while also learning to move, potentially augmented\nwith auxiliary tasks (e.g. predicting the action taken between two successive\nobservations). In this paper, we show that an alternative 2-stage strategy is\nfar more effective: (1) offline pretraining of visual representations with\nself-supervised learning (SSL) using large-scale pre-rendered images of indoor\nenvironments (Omnidata), and (2) online finetuning of visuomotor\nrepresentations on specific tasks with image augmentations under long learning\nschedules. We call this method Offline Visual Representation Learning (OVRL).\nWe conduct large-scale experiments - on 3 different 3D datasets (Gibson, HM3D,\nMP3D), 2 tasks (ImageNav, ObjectNav), and 2 policy learning algorithms (RL, IL)\n- and find that the OVRL representations lead to significant across-the-board\nimprovements in state of art, on ImageNav from 29.2% to 54.2% (+25% absolute,\n86% relative) and on ObjectNav from 18.1% to 23.2% (+5.1% absolute, 28%\nrelative). Importantly, both results were achieved by the same visual encoder\ngeneralizing to datasets that were not seen during pretraining. While the\nbenefits of pretraining sometimes diminish (or entirely disappear) with long\nfinetuning schedules, we find that OVRL's performance gains continue to\nincrease (not decrease) as the agent is trained for 2 billion frames of\nexperience.",
          "link": "http://arxiv.org/abs/2204.13226",
          "publishedOn": "2022-04-30T01:01:32.998Z",
          "wordCount": 677,
          "title": "Offline Visual Representation Learning for Embodied Navigation. (arXiv:2204.13226v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_B/0/1/0/all/0/1\">Bowen Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1\">Qinliang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jian Yin</a>",
          "description": "The goal of anomaly detection is to identify anomalous samples from normal\nones. In this paper, a small number of anomalies are assumed to be available at\nthe training stage, but they are assumed to be collected only from several\nanomaly types, leaving the majority of anomaly types not represented in the\ncollected anomaly dataset at all. To effectively leverage this kind of\nincomplete anomalous knowledge represented by the collected anomalies, we\npropose to learn a probability distribution that can not only model the normal\nsamples, but also guarantee to assign low density values for the collected\nanomalies. To this end, an anomaly-aware generative adversarial network (GAN)\nis developed, which, in addition to modeling the normal samples as most GANs\ndo, is able to explicitly avoid assigning probabilities for collected anomalous\nsamples. Moreover, to facilitate the computation of anomaly detection criteria\nlike reconstruction error, the proposed anomaly-aware GAN is designed to be\nbidirectional, attaching an encoder for the generator. Extensive experimental\nresults demonstrate that our proposed method is able to effectively make use of\nthe incomplete anomalous information, leading to significant performance gains\ncompared to existing methods.",
          "link": "http://arxiv.org/abs/2204.13335",
          "publishedOn": "2022-04-30T01:01:32.973Z",
          "wordCount": 622,
          "title": "Anomaly Detection by Leveraging Incomplete Anomalous Knowledge with Anomaly-Aware Bidirectional GANs. (arXiv:2204.13335v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yizhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jiang Qian</a>",
          "description": "Knowledge graph embedding methods are important for knowledge graph\ncompletion (link prediction) due to their robust performance and efficiency on\nlarge-magnitude datasets. One state-of-the-art method, PairRE, leverages two\nseparate vectors for relations to model complex relations (i.e., 1-to-N,\nN-to-1, and N-to-N) in knowledge graphs. However, such a method strictly\nrestricts entities on the hyper-ellipsoid surface and thus limits the\noptimization of entity distribution, which largely hinders the performance of\nknowledge graph completion. To address this problem, we propose a novel score\nfunction TransHER, which leverages relation-specific translations between head\nand tail entities restricted on separate hyper-ellipsoids. Specifically, given\na triplet, our model first maps entities onto two separate hyper-ellipsoids and\nthen conducts a relation-specific translation on one of them. The\nrelation-specific translation provides TransHER with more direct guidance in\noptimization and the ability to learn semantic characteristics of entities with\ncomplex relations. Experimental results show that TransHER can achieve\nstate-of-the-art performance and generalize to datasets in different domains\nand scales. All our code will be publicly available.",
          "link": "http://arxiv.org/abs/2204.13221",
          "publishedOn": "2022-04-30T01:01:32.966Z",
          "wordCount": 605,
          "title": "TransHER: Translating Knowledge Graph Embedding with Hyper-Ellipsoidal Restriction. (arXiv:2204.13221v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bondu_A/0/1/0/all/0/1\">Alexis Bondu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achenchabe_Y/0/1/0/all/0/1\">Youssef Achenchabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bifet_A/0/1/0/all/0/1\">Albert Bifet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clerot_F/0/1/0/all/0/1\">Fabrice Cl&#xe9;rot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornuejols_A/0/1/0/all/0/1\">Antoine Cornu&#xe9;jols</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gama_J/0/1/0/all/0/1\">Joao Gama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hebrail_G/0/1/0/all/0/1\">Georges H&#xe9;brail</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemaire_V/0/1/0/all/0/1\">Vincent Lemaire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marteau_P/0/1/0/all/0/1\">Pierre-Fran&#xe7;ois Marteau</a>",
          "description": "More and more applications require early decisions, i.e. taken as soon as\npossible from partially observed data. However, the later a decision is made,\nthe more its accuracy tends to improve, since the description of the problem to\nhand is enriched over time. Such a compromise between the earliness and the\naccuracy of decisions has been particularly studied in the field of Early Time\nSeries Classification. This paper introduces a more general problem, called\nMachine Learning based Early Decision Making (ML-EDM), which consists in\noptimizing the decision times of models in a wide range of settings where data\nis collected over time. After defining the ML-EDM problem, ten challenges are\nidentified and proposed to the scientific community to further research in this\narea. These challenges open important application perspectives, discussed in\nthis paper.",
          "link": "http://arxiv.org/abs/2204.13111",
          "publishedOn": "2022-04-30T01:01:32.958Z",
          "wordCount": 576,
          "title": "Open challenges for Machine Learning based Early Decision-Making research. (arXiv:2204.13111v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adachi_K/0/1/0/all/0/1\">Kazuki Adachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumagai_A/0/1/0/all/0/1\">Atsutoshi Kumagai</a>",
          "description": "The accuracy of deep neural networks is degraded when the distribution of\nfeatures in the test environment (target domain) differs from that of the\ntraining (source) environment. To mitigate the degradation, test-time\nadaptation (TTA), where a model adapts to the target domain without access to\nthe source dataset, can be used in the test environment. However, the existing\nTTA methods lack feature distribution alignment between the source and target\ndomains, which unsupervised domain adaptation mainly addresses, because\naccessing the source dataset is prohibited in the TTA setting. In this paper,\nwe propose a novel TTA method, named Covariance-Aware Feature alignment (CAFe),\nwhich explicitly aligns the source and target feature distributions at test\ntime. To perform alignment without accessing the source data, CAFe uses\nauxiliary feature statistics (mean and covariance) pre-computed on the source\ndomain, which are lightweight and easily prepared. Further, to improve\nefficiency and stability, we propose feature grouping, which splits the feature\ndimensions into groups according to their correlations by using spectral\nclustering to avoid degeneration of the covariance matrix. We empirically show\nthat CAFe outperforms prior TTA methods on a variety of distribution shifts.",
          "link": "http://arxiv.org/abs/2204.13263",
          "publishedOn": "2022-04-30T01:01:32.951Z",
          "wordCount": 621,
          "title": "Covariance-aware Feature Alignment with Pre-computed Source Statistics for Test-time Adaptation. (arXiv:2204.13263v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tolkachev_G/0/1/0/all/0/1\">George Tolkachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mell_S/0/1/0/all/0/1\">Stephen Mell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zdancewic_S/0/1/0/all/0/1\">Steve Zdancewic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "A key challenge facing natural language interfaces is enabling users to\nunderstand the capabilities of the underlying system. We propose a novel\napproach for generating explanations of a natural language interface based on\nsemantic parsing. We focus on counterfactual explanations, which are post-hoc\nexplanations that describe to the user how they could have minimally modified\ntheir utterance to achieve their desired goal. In particular, the user provides\nan utterance along with a demonstration of their desired goal; then, our\nalgorithm synthesizes a paraphrase of their utterance that is guaranteed to\nachieve their goal. In two user studies, we demonstrate that our approach\nsubstantially improves user performance, and that it generates explanations\nthat more closely match the user's intent compared to two ablations.",
          "link": "http://arxiv.org/abs/2204.13192",
          "publishedOn": "2022-04-30T01:01:32.944Z",
          "wordCount": 574,
          "title": "Counterfactual Explanations for Natural Language Interfaces. (arXiv:2204.13192v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Hongchang Gao</a>",
          "description": "In this paper, we studied the federated stochastic bilevel optimization\nproblem. In particular, we developed two momentum-based algorithms for\noptimizing this kind of problem. In addition, we established the convergence\nrate of these two algorithms, providing their sample and communication\ncomplexities. To the best of our knowledge, this is the first work achieving\nsuch favorable theoretical results.",
          "link": "http://arxiv.org/abs/2204.13299",
          "publishedOn": "2022-04-30T01:01:32.923Z",
          "wordCount": 492,
          "title": "On the Convergence of Momentum-Based Algorithms for Federated Stochastic Bilevel Optimization Problems. (arXiv:2204.13299v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dharna_A/0/1/0/all/0/1\">Aaron Dharna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Summers_C/0/1/0/all/0/1\">Charlie Summers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasari_R/0/1/0/all/0/1\">Rohin Dasari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1\">Julian Togelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoover_A/0/1/0/all/0/1\">Amy K. Hoover</a>",
          "description": "This paper proposes a framework called Watts for implementing, comparing, and\nrecombining open-ended learning (OEL) algorithms. Motivated by modularity and\nalgorithmic flexibility, Watts atomizes the components of OEL systems to\npromote the study of and direct comparisons between approaches. Examining\nimplementations of three OEL algorithms, the paper introduces the modules of\nthe framework. The hope is for Watts to enable benchmarking and to explore new\ntypes of OEL algorithms. The repo is available at\n\\url{https://github.com/aadharna/watts}",
          "link": "http://arxiv.org/abs/2204.13250",
          "publishedOn": "2022-04-30T01:01:32.912Z",
          "wordCount": 525,
          "title": "Watts: Infrastructure for Open-Ended Learning. (arXiv:2204.13250v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13166",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chugh_T/0/1/0/all/0/1\">Tinkle Chugh</a>",
          "description": "Many real-world multi-objective optimisation problems rely on computationally\nexpensive function evaluations. Multi-objective Bayesian optimisation (BO) can\nbe used to alleviate the computation time to find an approximated set of Pareto\noptimal solutions. In many real-world problems, a decision-maker has some\npreferences on the objective functions. One approach to incorporate the\npreferences in multi-objective BO is to use a scalarising function and build a\nsingle surrogate model (mono-surrogate approach) on it. This approach has two\nmajor limitations. Firstly, the fitness landscape of the scalarising function\nand the objective functions may not be similar. Secondly, the approach assumes\nthat the scalarising function distribution is Gaussian, and thus a closed-form\nexpression of an acquisition function e.g., expected improvement can be used.\nWe overcome these limitations by building independent surrogate models\n(multi-surrogate approach) on each objective function and show that the\ndistribution of the scalarising function is not Gaussian. We approximate the\ndistribution using Generalised value distribution. We present an a-priori\nmulti-surrogate approach to incorporate the desirable objective function values\n(or reference point) as the preferences of a decision-maker in multi-objective\nBO. The results and comparison with the existing mono-surrogate approach on\nbenchmark and real-world optimisation problems show the potential of the\nproposed approach.",
          "link": "http://arxiv.org/abs/2204.13166",
          "publishedOn": "2022-04-30T01:01:32.905Z",
          "wordCount": 655,
          "title": "R-MBO: A Multi-surrogate Approach for Preference Incorporation in Multi-objective Bayesian Optimisation. (arXiv:2204.13166v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nava_E/0/1/0/all/0/1\">Elvis Nava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">John Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michelis_M/0/1/0/all/0/1\">Mike Yan Michelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1\">Tao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1\">Pingchuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grewe_B/0/1/0/all/0/1\">Benjamin Grewe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matusik_W/0/1/0/all/0/1\">Wojciech Matusik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katzschmann_R/0/1/0/all/0/1\">Robert Katzschmann</a>",
          "description": "Aquatic locomotion is a classic fluid-structure interaction (FSI) problem of\ninterest to biologists and engineers. Solving the fully coupled FSI equations\nfor incompressible Navier-Stokes and finite elasticity is computationally\nexpensive. Optimizing robotic swimmer design within such a system generally\ninvolves cumbersome, gradient-free procedures on top of the already costly\nsimulation. To address this challenge we present a novel, fully differentiable\nhybrid approach to FSI that combines a 2D direct numerical simulation for the\ndeformable solid structure of the swimmer and a physics-constrained neural\nnetwork surrogate to capture hydrodynamic effects of the fluid. For the\ndeformable simulation of the swimmer's body, we use state-of-the-art techniques\nfrom the field of computer graphics to speed up the finite-element method\n(FEM). For the fluid simulation, we use a U-Net architecture trained with a\nphysics-based loss function to predict the flow field at each time step. The\npressure and velocity field outputs from the neural network are sampled around\nthe boundary of our swimmer using an immersed boundary method (IBM) to compute\nits swimming motion accurately and efficiently. We demonstrate the\ncomputational efficiency and differentiability of our hybrid simulator on a 2D\ncarangiform swimmer. Since both the solid simulator and the hydrodynamics model\nare automatically differentiable, we obtain a fully differentiable FSI\nsimulator that can be used for computational co-design of geometry and controls\nfor rigid and soft bodies immersed in fluids, such as minimizing drag,\nmaximizing speed, or maximizing efficiency via direct gradient-based\noptimization.",
          "link": "http://arxiv.org/abs/2204.12584",
          "publishedOn": "2022-04-28T01:16:10.201Z",
          "wordCount": 698,
          "title": "Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrodynamic Models. (arXiv:2204.12584v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Shih-Chun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chia-Hung Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei-Chi Chen</a>",
          "description": "Industry 4.0-enabled smart factory is expected to realize the next revolution\nfor manufacturers. Although artificial intelligence (AI) technologies have\nimproved productivity, current use cases belong to small-scale and single-task\noperations. To unbound the potential of smart factory, this paper develops\nzero-touch network systems for intelligent manufacturing and facilitates\ndistributed AI applications in both training and inferring stages in a\nlarge-scale manner. The open radio access network (O-RAN) architecture is first\nintroduced for the zero-touch platform to enable globally controlling\ncommunications and computation infrastructure capability in the field. The\ndesigned serverless framework allows intelligent and efficient learning\nassignments and resource allocations. Hence, requested learning tasks can be\nassigned to appropriate robots, and the underlying infrastructure can be used\nto support the learning tasks without expert knowledge. Moreover, due to the\nproposed network system's flexibility, powerful AI-enabled networking\nalgorithms can be utilized to ensure service-level agreements and superior\nperformances for factory workloads. Finally, three open research directions of\nbackward compatibility, end-to-end enhancements, and cybersecurity are\ndiscussed for zero-touch smart factory.",
          "link": "http://arxiv.org/abs/2204.12605",
          "publishedOn": "2022-04-28T01:16:10.195Z",
          "wordCount": 617,
          "title": "Zero-Touch Network on Industrial IoT: An End-to-End Machine Learning Approach. (arXiv:2204.12605v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.04604",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Jesus_Valls_C/0/1/0/all/0/1\">C&#xe9;sar Jes&#xfa;s-Valls</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lux_T/0/1/0/all/0/1\">Thorsten Lux</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sanchez_F/0/1/0/all/0/1\">Federico S&#xe1;nchez</a>",
          "description": "A common technique in high energy physics is to characterize the response of\na detector by means of models tunned to data which build parametric maps from\nthe physical parameters of the system to the expected signal of the detector.\nWhen the underlying model is unknown it is difficult to apply this method, and\noften, simplifying assumptions are made introducing modeling errors. In this\narticle, using a waveform toy model we present how deep learning in the form of\nconstrained bottleneck autoencoders can be used to learn the underlying unknown\ndetector response model directly from data. The results show that excellent\nperformance results can be achieved even when the signals are significantly\naffected by random noise. The trained algorithm can be used simultaneously to\nperform estimations on the physical parameters of the model, simulate the\ndetector response with high fidelity and to denoise detector signals.",
          "link": "http://arxiv.org/abs/2203.04604",
          "publishedOn": "2022-04-28T01:16:10.189Z",
          "wordCount": 624,
          "title": "Data-driven detector signal characterization with constrained bottleneck autoencoders. (arXiv:2203.04604v4 [physics.ins-det] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.06481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1\">Jiafei Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasgupta_A/0/1/0/all/0/1\">Arijit Dasgupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_J/0/1/0/all/0/1\">Jason Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Cheston Tan</a>",
          "description": "Research in cognitive science has provided extensive evidence of human\ncognitive ability in performing physical reasoning of objects from noisy\nperceptual inputs. Such a cognitive ability is commonly known as intuitive\nphysics. With advancements in deep learning, there is an increasing interest in\nbuilding intelligent systems that are capable of performing physical reasoning\nfrom a given scene for the purpose of building better AI systems. As a result,\nmany contemporary approaches in modelling intuitive physics for machine\ncognition have been inspired by literature from cognitive science. Despite the\nwide range of work in physical reasoning for machine cognition, there is a\nscarcity of reviews that organize and group these deep learning approaches.\nEspecially at the intersection of intuitive physics and artificial\nintelligence, there is a need to make sense of the diverse range of ideas and\napproaches. Therefore, this paper presents a comprehensive survey of recent\nadvances and techniques in intuitive physics-inspired deep learning approaches\nfor physical reasoning. The survey will first categorize existing deep learning\napproaches into three facets of physical reasoning before organizing them into\nthree general technical approaches and propose six categorical tasks of the\nfield. Finally, we highlight the challenges of the current field and present\nsome future research directions.",
          "link": "http://arxiv.org/abs/2202.06481",
          "publishedOn": "2022-04-28T01:16:10.095Z",
          "wordCount": 669,
          "title": "A Survey on Machine Learning Approaches for Modelling Intuitive Physics. (arXiv:2202.06481v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moghaddam_R/0/1/0/all/0/1\">Roshanak Zilouchian Moghaddam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Spandan Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clement_C/0/1/0/all/0/1\">Colin B. Clement</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohylevskyy_Y/0/1/0/all/0/1\">Yevhen Mohylevskyy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1\">Neel Sundaresan</a>",
          "description": "Continuous evolution in modern software often causes documentation,\ntutorials, and examples to be out of sync with changing interfaces and\nframeworks. Relying on outdated documentation and examples can lead programs to\nfail or be less efficient or even less secure. In response, programmers need to\nregularly turn to other resources on the web such as StackOverflow for examples\nto guide them in writing software. We recognize that this inconvenient,\nerror-prone, and expensive process can be improved by using machine learning\napplied to software usage data. In this paper, we present our practical system\nwhich uses machine learning on large-scale telemetry data and documentation\ncorpora, generating appropriate and complex examples that can be used to\nimprove documentation. We discuss both feature-based and transformer-based\nmachine learning approaches and demonstrate that our system achieves 100%\ncoverage for the used functionalities in the product, providing up-to-date\nexamples upon every release and reduces the numbers of PRs submitted by\nsoftware owners writing and editing documentation by >68%. We also share\nvaluable lessons learnt during the 3 years that our production quality system\nhas been deployed for Azure Cloud Command Line Interface (Azure CLI).",
          "link": "http://arxiv.org/abs/2204.12648",
          "publishedOn": "2022-04-28T01:16:10.023Z",
          "wordCount": 631,
          "title": "Generating Examples From CLI Usage: Can Transformers Help?. (arXiv:2204.12648v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12651",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yuanbo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yongjian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1\">En Wang</a>",
          "description": "Classical accuracy-oriented Recommender Systems (RSs) typically face the\ncold-start problem and the filter-bubble problem when users suffer the\nfamiliar, repeated, and even predictable recommendations, making them boring\nand unsatisfied. To address the above issues, serendipity-oriented RSs are\nproposed to recommend appealing and valuable items significantly deviating from\nusers' historical interactions and thus satisfying them by introducing\nunexplored but relevant candidate items to them. In this paper, we devise a\nnovel serendipity-oriented recommender system (\\textbf{G}enerative\n\\textbf{S}elf-\\textbf{S}erendipity \\textbf{R}ecommender \\textbf{S}ystem,\n\\textbf{GS$^2$-RS}) that generates users' self-serendipity preferences to\nenhance the recommendation performance. Specifically, this model extracts\nusers' interest and satisfaction preferences, generates virtual but convincible\nneighbors' preferences from themselves, and achieves their self-serendipity\npreference. Then these preferences are injected into the rating matrix as\nadditional information for RS models. Note that GS$^2$-RS can not only tackle\nthe cold-start problem but also provides diverse but relevant recommendations\nto relieve the filter-bubble problem. Extensive experiments on benchmark\ndatasets illustrate that the proposed GS$^2$-RS model can significantly\noutperform the state-of-the-art baseline approaches in serendipity measures\nwith a stable accuracy performance.",
          "link": "http://arxiv.org/abs/2204.12651",
          "publishedOn": "2022-04-28T01:16:09.999Z",
          "wordCount": 631,
          "title": "Generating Self-Serendipity Preference in Recommender Systems for Addressing Cold Start Problems. (arXiv:2204.12651v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13168",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Chatterjee_A/0/1/0/all/0/1\">Ayan Chatterjee</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Walters_R/0/1/0/all/0/1\">Robin Walters</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Shafi_Z/0/1/0/all/0/1\">Zohair Shafi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ahmed_O/0/1/0/all/0/1\">Omair Shafi Ahmed</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sebek_M/0/1/0/all/0/1\">Michael Sebek</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gysi_D/0/1/0/all/0/1\">Deisy Gysi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yu_R/0/1/0/all/0/1\">Rose Yu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Eliassi_Rad_T/0/1/0/all/0/1\">Tina Eliassi-Rad</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Barabasi_A/0/1/0/all/0/1\">Albert-L&#xe1;szl&#xf3; Barab&#xe1;si</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Menichetti_G/0/1/0/all/0/1\">Giulia Menichetti</a>",
          "description": "Identifying novel drug-target interactions (DTI) is a critical and rate\nlimiting step in drug discovery. While deep learning models have been proposed\nto accelerate the identification process, we show that state-of-the-art models\nfail to generalize to novel (i.e., never-before-seen) structures. We first\nunveil the mechanisms responsible for this shortcoming, demonstrating how\nmodels rely on shortcuts that leverage the topology of the protein-ligand\nbipartite network, rather than learning the node features. Then, we introduce\nAI-Bind, a pipeline that combines network-based sampling strategies with\nunsupervised pre-training, allowing us to limit the annotation imbalance and\nimprove binding predictions for novel proteins and ligands. We illustrate the\nvalue of AI-Bind by predicting drugs and natural compounds with binding\naffinity to SARS-CoV-2 viral proteins and the associated human proteins. We\nalso validate these predictions via auto-docking simulations and comparison\nwith recent experimental evidence, and step up the process of interpreting\nmachine learning prediction of protein-ligand binding by identifying potential\nactive binding sites on the amino acid sequence. Overall, AI-Bind offers a\npowerful high-throughput approach to identify drug-target combinations, with\nthe potential of becoming a powerful tool in drug discovery.",
          "link": "http://arxiv.org/abs/2112.13168",
          "publishedOn": "2022-04-28T01:16:09.859Z",
          "wordCount": 736,
          "title": "AI-Bind: Improving Binding Predictions for Novel Protein Targets and Ligands. (arXiv:2112.13168v4 [q-bio.QM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.11423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zongbo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Joey Tianyi Zhou</a>",
          "description": "Existing multi-view classification algorithms focus on promoting accuracy by\nexploiting different views, typically integrating them into common\nrepresentations for follow-up tasks. Although effective, it is also crucial to\nensure the reliability of both the multi-view integration and the final\ndecision, especially for noisy, corrupted and out-of-distribution data.\nDynamically assessing the trustworthiness of each view for different samples\ncould provide reliable integration. This can be achieved through uncertainty\nestimation. With this in mind, we propose a novel multi-view classification\nalgorithm, termed trusted multi-view classification (TMC), providing a new\nparadigm for multi-view learning by dynamically integrating different views at\nan evidence level. The proposed TMC can promote classification reliability by\nconsidering evidence from each view. Specifically, we introduce the variational\nDirichlet to characterize the distribution of the class probabilities,\nparameterized with evidence from different views and integrated with the\nDempster-Shafer theory. The unified learning framework induces accurate\nuncertainty and accordingly endows the model with both reliability and\nrobustness against possible noise or corruption. Both theoretical and\nexperimental results validate the effectiveness of the proposed model in\naccuracy, robustness and trustworthiness.",
          "link": "http://arxiv.org/abs/2204.11423",
          "publishedOn": "2022-04-28T01:16:09.842Z",
          "wordCount": 634,
          "title": "Trusted Multi-View Classification with Dynamic Evidential Fusion. (arXiv:2204.11423v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karmakar_S/0/1/0/all/0/1\">Sayar Karmakar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Anirbit Mukherjee</a>",
          "description": "A particular direction of recent advance about stochastic deep-learning\nalgorithms has been about uncovering a rather mysterious heavy-tailed nature of\nthe stationary distribution of these algorithms, even when the data\ndistribution is not so. Moreover, the heavy-tail index is known to show\ninteresting dependence on the input dimension of the net, the mini-batch size\nand the step size of the algorithm. In this short note, we undertake an\nexperimental study of this index for S.G.D. while training a $\\relu$ gate (in\nthe realizable and in the binary classification setup) and for a variant of\nS.G.D. that was proven in Karmakar and Mukherjee (2022) for ReLU realizable\ndata. From our experiments we conjecture that these two algorithms have similar\nheavy-tail behaviour on any data where the latter can be proven to converge.\nSecondly, we demonstrate that the heavy-tail index of the late time iterates in\nthis model scenario has strikingly different properties than either what has\nbeen proven for linear hypothesis classes or what has been previously\ndemonstrated for large nets.",
          "link": "http://arxiv.org/abs/2204.12554",
          "publishedOn": "2022-04-28T01:16:09.836Z",
          "wordCount": 631,
          "title": "An Empirical Study of the Occurrence of Heavy-Tails in Training a ReLU Gate. (arXiv:2204.12554v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.05158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mudigere_D/0/1/0/all/0/1\">Dheevatsa Mudigere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yuchen Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jianyu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1\">Zhihao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tulloch_A/0/1/0/all/0/1\">Andrew Tulloch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1\">Srinivas Sridharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozdal_M/0/1/0/all/0/1\">Mustafa Ozdal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jade Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jongsoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Liang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jie Amy Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Leon Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivchenko_D/0/1/0/all/0/1\">Dmytro Ivchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basant_A/0/1/0/all/0/1\">Aarti Basant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yuxi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jiyan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ardestani_E/0/1/0/all/0/1\">Ehsan K. Ardestani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaodong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komuravelli_R/0/1/0/all/0/1\">Rakesh Komuravelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1\">Ching-Hsiang Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yilmaz_S/0/1/0/all/0/1\">Serhat Yilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huayu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jiyuan Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhuobo Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yinbin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_E/0/1/0/all/0/1\">Ellie Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chonglin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Whitney Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melts_D/0/1/0/all/0/1\">Dimitry Melts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhulipala_K/0/1/0/all/0/1\">Krishna Dhulipala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kishore_K/0/1/0/all/0/1\">KR Kishore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graf_T/0/1/0/all/0/1\">Tyler Graf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenman_A/0/1/0/all/0/1\">Assaf Eisenman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matam_K/0/1/0/all/0/1\">Kiran Kumar Matam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangidi_A/0/1/0/all/0/1\">Adi Gangidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guoqiang Jerry Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_M/0/1/0/all/0/1\">Manoj Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayak_A/0/1/0/all/0/1\">Avinash Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_K/0/1/0/all/0/1\">Krishnakumar Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muthiah_B/0/1/0/all/0/1\">Bharath Muthiah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+khorashadi_M/0/1/0/all/0/1\">Mahmoud khorashadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_P/0/1/0/all/0/1\">Pallab Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapukhov_P/0/1/0/all/0/1\">Petr Lapukhov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumov_M/0/1/0/all/0/1\">Maxim Naumov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathews_A/0/1/0/all/0/1\">Ajit Mathews</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_L/0/1/0/all/0/1\">Lin Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smelyanskiy_M/0/1/0/all/0/1\">Mikhail Smelyanskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_B/0/1/0/all/0/1\">Bill Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_V/0/1/0/all/0/1\">Vijay Rao</a>",
          "description": "Deep learning recommendation models (DLRMs) are used across many\nbusiness-critical services at Facebook and are the single largest AI\napplication in terms of infrastructure demand in its data-centers. In this\npaper we discuss the SW/HW co-designed solution for high-performance\ndistributed training of large-scale DLRMs. We introduce a high-performance\nscalable software stack based on PyTorch and pair it with the new evolution of\nZion platform, namely ZionEX. We demonstrate the capability to train very large\nDLRMs with up to 12 Trillion parameters and show that we can attain 40X speedup\nin terms of time to solution over previous systems. We achieve this by (i)\ndesigning the ZionEX platform with dedicated scale-out network, provisioned\nwith high bandwidth, optimal topology and efficient transport (ii) implementing\nan optimized PyTorch-based training stack supporting both model and data\nparallelism (iii) developing sharding algorithms capable of hierarchical\npartitioning of the embedding tables along row, column dimensions and load\nbalancing them across multiple workers; (iv) adding high-performance core\noperators while retaining flexibility to support optimizers with fully\ndeterministic updates (v) leveraging reduced precision communications,\nmulti-level memory hierarchy (HBM+DDR+SSD) and pipelining. Furthermore, we\ndevelop and briefly comment on distributed data ingestion and other supporting\nservices that are required for the robust and efficient end-to-end training in\nproduction environments.",
          "link": "http://arxiv.org/abs/2104.05158",
          "publishedOn": "2022-04-28T01:16:09.830Z",
          "wordCount": 835,
          "title": "Software-Hardware Co-design for Fast and Scalable Training of Deep Learning Recommendation Models. (arXiv:2104.05158v6 [cs.DC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Liang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yibo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofei He</a>",
          "description": "Class imbalance distribution widely exists in real-world engineering.\nHowever, the mainstream optimization algorithms that seek to minimize error\nwill trap the deep learning model in sub-optimums when facing extreme class\nimbalance. It seriously harms the classification precision, especially on the\nminor classes. The essential reason is that the gradients of the classifier\nweights are imbalanced among the components from different classes. In this\npaper, we propose Attraction-Repulsion-Balanced Loss (ARB-Loss) to balance the\ndifferent components of the gradients. We perform experiments on the\nlarge-scale classification and segmentation datasets and our ARB-Loss can\nachieve state-of-the-art performance via only one-stage training instead of\n2-stage learning like nowadays SOTA works.",
          "link": "http://arxiv.org/abs/2204.08735",
          "publishedOn": "2022-04-28T01:16:09.824Z",
          "wordCount": 565,
          "title": "Neural Collapse Inspired Attraction-Repulsion-Balanced Loss for Imbalanced Learning. (arXiv:2204.08735v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.11795",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lan_E/0/1/0/all/0/1\">Ella Lan</a>",
          "description": "Cardiovascular diseases (CVDs) have become the top one cause of death;\nthree-quarters of these deaths occur in lower-income communities.\nElectrocardiography (ECG), an electrical measurement capturing the cardiac\nactivities, is a gold-standard to diagnose CVDs. However, ECG is infeasible for\ncontinuous cardiac monitoring due to its requirement for user participation.\nMeanwhile, photoplethysmography (PPG) is easy to collect, but the limited\naccuracy constrains its clinical usage. In this research, a novel\nTransformer-based architecture, Performer, is invented to reconstruct ECG from\nPPG and to create a novel digital biomarker, PPG along with its reconstructed\nECG, as multiple modalities for CVD detection. This architecture, for the first\ntime, performs Transformer sequence to sequence translation on biomedical\nwaveforms, while also utilizing the advantages of the easily accessible PPG and\nthe well-studied base of ECG. Shifted Patch-based Attention (SPA) is created to\nmaximize the signal features by fetching the various sequence lengths as\nhierarchical stages into the training while also capturing cross-patch\nconnections through the shifted patch mechanism. This architecture generates a\nstate-of-the-art performance of 0.29 RMSE for reconstructing ECG from PPG,\nachieving an average of 95.9% diagnosis for CVDs on the MIMIC III dataset and\n75.9% for diabetes on the PPG-BP dataset. Performer, along with its novel\ndigital biomarker, offers a low-cost and non-invasive solution for continuous\ncardiac monitoring, only requiring the easily extractable PPG data to\nreconstruct the not-as-accessible ECG data. As a prove of concept, an earring\nwearable, named PEARL (prototype), is designed to scale up the point-of-care\n(POC) healthcare system.",
          "link": "http://arxiv.org/abs/2204.11795",
          "publishedOn": "2022-04-28T01:16:09.818Z",
          "wordCount": 733,
          "title": "Performer: A Novel PPG to ECG Reconstruction Transformer For a Digital Biomarker of Cardiovascular Disease Detection. (arXiv:2204.11795v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.11351",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Han Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mingxuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_L/0/1/0/all/0/1\">Lican Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chenkui Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Wu</a>",
          "description": "Nowadays, the interpretation of why a machine learning (ML) model makes\ncertain inferences is as crucial as the accuracy of such inferences. Some ML\nmodels like the decision tree possess inherent interpretability that can be\ndirectly comprehended by humans. Others like artificial neural networks (ANN),\nhowever, rely on external methods to uncover the deduction mechanism. SHapley\nAdditive exPlanations (SHAP) is one of such external methods, which requires a\nbackground dataset when interpreting ANNs. Generally, a background dataset\nconsists of instances randomly sampled from the training dataset. However, the\nsampling size and its effect on SHAP remain to be unexplored. In our empirical\nstudy on the MIMIC-III dataset, we show that the two core explanations - SHAP\nvalues and variable rankings fluctuate when using different background datasets\nacquired from random sampling, indicating that users cannot unquestioningly\ntrust the one-shot interpretation from SHAP. Luckily, such fluctuation\ndecreases with the increase of the background dataset size. Also, we notice an\nU-shape in the stability assessment of SHAP variable rankings, demonstrating\nthat SHAP is more reliable in ranking the most and least important variables\ncompared to moderately important ones. Overall, our results suggest that users\nshould take into account how background data affects SHAP results, with\nimproved SHAP stability as the background sample size increases.",
          "link": "http://arxiv.org/abs/2204.11351",
          "publishedOn": "2022-04-28T01:16:09.803Z",
          "wordCount": 693,
          "title": "An empirical study of the effect of background data size on the stability of SHapley Additive exPlanations (SHAP) for deep learning models. (arXiv:2204.11351v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.11131",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karlas_B/0/1/0/all/0/1\">Bojan Karla&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dao_D/0/1/0/all/0/1\">David Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Interlandi_M/0/1/0/all/0/1\">Matteo Interlandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schelter_S/0/1/0/all/0/1\">Sebastian Schelter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wentao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>",
          "description": "Developing modern machine learning (ML) applications is data-centric, of\nwhich one fundamental challenge is to understand the influence of data quality\nto ML training -- \"Which training examples are 'guilty' in making the trained\nML model predictions inaccurate or unfair?\" Modeling data influence for ML\ntraining has attracted intensive interest over the last decade, and one popular\nframework is to compute the Shapley value of each training example with respect\nto utilities such as validation accuracy and fairness of the trained ML model.\nUnfortunately, despite recent intensive interest and research, existing methods\nonly consider a single ML model \"in isolation\" and do not consider an\nend-to-end ML pipeline that consists of data transformations, feature\nextractors, and ML training.\n\nWe present DataScope (ease.ml/datascope), the first system that efficiently\ncomputes Shapley values of training examples over an end-to-end ML pipeline,\nand illustrate its applications in data debugging for ML training. To this end,\nwe first develop a novel algorithmic framework that computes Shapley value over\na specific family of ML pipelines that we call canonical pipelines: a positive\nrelational algebra query followed by a K-nearest-neighbor (KNN) classifier. We\nshow that, for many subfamilies of canonical pipelines, computing Shapley value\nis in PTIME, contrasting the exponential complexity of computing Shapley value\nin general. We then put this to practice -- given an sklearn pipeline, we\napproximate it with a canonical pipeline to use as a proxy. We conduct\nextensive experiments illustrating different use cases and utilities. Our\nresults show that DataScope is up to four orders of magnitude faster over\nstate-of-the-art Monte Carlo-based methods, while being comparably, and often\neven more, effective in data debugging.",
          "link": "http://arxiv.org/abs/2204.11131",
          "publishedOn": "2022-04-28T01:16:09.795Z",
          "wordCount": 739,
          "title": "Data Debugging with Shapley Importance over End-to-End Machine Learning Pipelines. (arXiv:2204.11131v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.11028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yingxin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">An Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>",
          "description": "Explainability is crucial for probing graph neural networks (GNNs), answering\nquestions like \"Why the GNN model makes a certain prediction?\". Feature\nattribution is a prevalent technique of highlighting the explanatory subgraph\nin the input graph, which plausibly leads the GNN model to make its prediction.\nVarious attribution methods exploit gradient-like or attention scores as the\nattributions of edges, then select the salient edges with top attribution\nscores as the explanation. However, most of these works make an untenable\nassumption - the selected edges are linearly independent - thus leaving the\ndependencies among edges largely unexplored, especially their coalition effect.\nWe demonstrate unambiguous drawbacks of this assumption - making the\nexplanatory subgraph unfaithful and verbose. To address this challenge, we\npropose a reinforcement learning agent, Reinforced Causal Explainer\n(RC-Explainer). It frames the explanation task as a sequential decision process\n- an explanatory subgraph is successively constructed by adding a salient edge\nto connect the previously selected subgraph. Technically, its policy network\npredicts the action of edge addition, and gets a reward that quantifies the\naction's causal effect on the prediction. Such reward accounts for the\ndependency of the newly-added edge and the previously-added edges, thus\nreflecting whether they collaborate together and form a coalition to pursue\nbetter explanations. As such, RC-Explainer is able to generate faithful and\nconcise explanations, and has a better generalization power to unseen graphs.\nWhen explaining different GNNs on three graph classification datasets,\nRC-Explainer achieves better or comparable performance to SOTA approaches\nw.r.t. predictive accuracy and contrastivity, and safely passes sanity checks\nand visual inspections. Codes are available at\nhttps://github.com/xiangwang1223/reinforced_causal_explainer.",
          "link": "http://arxiv.org/abs/2204.11028",
          "publishedOn": "2022-04-28T01:16:09.789Z",
          "wordCount": 742,
          "title": "Reinforced Causal Explainer for Graph Neural Networks. (arXiv:2204.11028v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.11008",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhiling Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yufan Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xiao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menouar_H/0/1/0/all/0/1\">Hamid Menouar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaofeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junshan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1\">Flora Salim</a>",
          "description": "Many real-world ubiquitous applications, such as parking recommendations and\nair pollution monitoring, benefit significantly from accurate long-term\nspatio-temporal forecasting (LSTF). LSTF makes use of long-term dependency\nbetween spatial and temporal domains, contextual information, and inherent\npattern in the data. Recent studies have revealed the potential of multi-graph\nneural networks (MGNNs) to improve prediction performance. However, existing\nMGNN methods cannot be directly applied to LSTF due to several issues: the low\nlevel of generality, insufficient use of contextual information, and the\nimbalanced graph fusion approach. To address these issues, we construct new\ngraph models to represent the contextual information of each node and the\nlong-term spatio-temporal data dependency structure. To fuse the information\nacross multiple graphs, we propose a new dynamic multi-graph fusion module to\ncharacterize the correlations of nodes within a graph and the nodes across\ngraphs via the spatial attention and graph attention mechanisms. Furthermore,\nwe introduce a trainable weight tensor to indicate the importance of each node\nin different graphs. Extensive experiments on two large-scale datasets\ndemonstrate that our proposed approaches significantly improve the performance\nof existing graph neural network models in LSTF prediction tasks.",
          "link": "http://arxiv.org/abs/2204.11008",
          "publishedOn": "2022-04-28T01:16:09.783Z",
          "wordCount": 647,
          "title": "Long-term Spatio-temporal Forecasting via Dynamic Multiple-Graph Attention. (arXiv:2204.11008v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.09631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1\">Archan Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monath_N/0/1/0/all/0/1\">Nicholas Monath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Cameron Musco</a>",
          "description": "We study algorithms for approximating pairwise similarity matrices that arise\nin natural language processing. Generally, computing a similarity matrix for\n$n$ data points requires $\\Omega(n^2)$ similarity computations. This quadratic\nscaling is a significant bottleneck, especially when similarities are computed\nvia expensive functions, e.g., via transformer models. Approximation methods\nreduce this quadratic complexity, often by using a small subset of exactly\ncomputed similarities to approximate the remainder of the complete pairwise\nsimilarity matrix.\n\nSignificant work focuses on the efficient approximation of positive\nsemidefinite (PSD) similarity matrices, which arise e.g., in kernel methods.\nHowever, much less is understood about indefinite (non-PSD) similarity\nmatrices, which often arise in NLP. Motivated by the observation that many of\nthese matrices are still somewhat close to PSD, we introduce a generalization\nof the popular Nystr\\\"{o}m method to the indefinite setting. Our algorithm can\nbe applied to any similarity matrix and runs in sublinear time in the size of\nthe matrix, producing a rank-$s$ approximation with just $O(ns)$ similarity\ncomputations.\n\nWe show that our method, along with a simple variant of CUR decomposition,\nperforms very well in approximating a variety of similarity matrices arising in\nNLP tasks. We demonstrate high accuracy of the approximated similarity matrices\nin the downstream tasks of document classification, sentence similarity, and\ncross-document coreference.",
          "link": "http://arxiv.org/abs/2112.09631",
          "publishedOn": "2022-04-28T01:16:09.765Z",
          "wordCount": 691,
          "title": "Sublinear Time Approximation of Text Similarity Matrices. (arXiv:2112.09631v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_R/0/1/0/all/0/1\">Rong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yujie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tiehua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuze Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xin Chen</a>",
          "description": "Using the pre-trained language model (i.e. BERT) to apprehend source codes\nhas attracted increasing attention from financial institutions owing to the\ngreat potential to uncover financial risks. However, there are several\nchallenges in applying these language models to directly solve programming\nlanguage (PL) related problems. To this end, we propose the AstBERT model, a\npre-trained language model aiming to better understand the financial PL using\nthe abstract syntax tree (AST). Specifically, we collect a colossal amount of\nsource codes (both Java and Python) from the Alipay code repository and\nincorporate both syntactic and semantic code knowledge into our model through\nthe help of code parsers, in which AST information of the source codes can be\ninterpreted and integrated. We evaluate the performance of the proposed model\non three tasks, including code question answering, code clone detection and\ncode refinement. Experiment results show that our AstBERT achieves promising\nperformance on three downstream tasks.",
          "link": "http://arxiv.org/abs/2201.07984",
          "publishedOn": "2022-04-28T01:16:09.755Z",
          "wordCount": 626,
          "title": "AstBERT: Enabling Language Model for Financial Code Understanding with Abstract Syntax Trees. (arXiv:2201.07984v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02606",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xu_R/0/1/0/all/0/1\">Runsheng Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tu_Z/0/1/0/all/0/1\">Zhengzhong Tu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Du_Y/0/1/0/all/0/1\">Yuanqi Du</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dong_X/0/1/0/all/0/1\">Xiaoyu Dong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jinlong Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Meng_Z/0/1/0/all/0/1\">Zibo Meng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_J/0/1/0/all/0/1\">Jiaqi Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+YU_H/0/1/0/all/0/1\">Hongkai YU</a>",
          "description": "Renovating the memories in old photos is an intriguing research topic in\ncomputer vision fields. These legacy images often suffer from severe and\ncommingled degradations such as cracks, noise, and color-fading, while lack of\nlarge-scale paired old photo datasets makes this restoration task very\nchallenging. In this work, we present a novel reference-based end-to-end\nlearning framework that can jointly repair and colorize the degraded legacy\npictures. Specifically, the proposed framework consists of three modules: a\nrestoration sub-network for degradation restoration, a similarity sub-network\nfor color histogram matching and transfer, and a colorization subnet that\nlearns to predict the chroma elements of the images conditioned on chromatic\nreference signals. The whole system takes advantage of the color histogram\npriors in a given reference image, which vastly reduces the dependency on\nlarge-scale training data. Apart from the proposed method, we also create, to\nour knowledge, the first public and real-world old photo dataset with paired\nground truth for evaluating old photo restoration models, wherein each old\nphoto is paired with a manually restored pristine image by PhotoShop experts.\nOur extensive experiments conducted on both synthetic and real-world datasets\ndemonstrate that our method significantly outperforms state-of-the-arts both\nquantitatively and qualitatively.",
          "link": "http://arxiv.org/abs/2202.02606",
          "publishedOn": "2022-04-28T01:16:09.750Z",
          "wordCount": 674,
          "title": "ROMNet: Renovate the Old Memories. (arXiv:2202.02606v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Daya Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>",
          "description": "In this paper, we propose LaPraDoR, a pretrained dual-tower dense retriever\nthat does not require any supervised data for training. Specifically, we first\npresent Iterative Contrastive Learning (ICoL) that iteratively trains the query\nand document encoders with a cache mechanism. ICoL not only enlarges the number\nof negative instances but also keeps representations of cached examples in the\nsame hidden space. We then propose Lexicon-Enhanced Dense Retrieval (LEDR) as a\nsimple yet effective way to enhance dense retrieval with lexical matching. We\nevaluate LaPraDoR on the recently proposed BEIR benchmark, including 18\ndatasets of 9 zero-shot text retrieval tasks. Experimental results show that\nLaPraDoR achieves state-of-the-art performance compared with supervised dense\nretrieval models, and further analysis reveals the effectiveness of our\ntraining strategy and objectives. Compared to re-ranking, our lexicon-enhanced\napproach can be run in milliseconds (22.5x faster) while achieving superior\nperformance.",
          "link": "http://arxiv.org/abs/2203.06169",
          "publishedOn": "2022-04-28T01:16:09.744Z",
          "wordCount": 611,
          "title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval. (arXiv:2203.06169v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.11663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ziyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shaocong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>",
          "description": "Alternating gradient-descent-ascent (AltGDA) is an optimization algorithm\nthat has been widely used for model training in various machine learning\napplications, which aims to solve a nonconvex minimax optimization problem.\nHowever, the existing studies show that it suffers from a high computation\ncomplexity in nonconvex minimax optimization. In this paper, we develop a\nsingle-loop and fast AltGDA-type algorithm that leverages proximal gradient\nupdates and momentum acceleration to solve regularized nonconvex minimax\noptimization problems. By leveraging the momentum acceleration technique, we\nprove that the algorithm converges to a critical point in nonconvex minimax\noptimization and achieves a computation complexity in the order of\n$\\mathcal{O}(\\kappa^{\\frac{11}{6}}\\epsilon^{-2})$, where $\\epsilon$ is the\ndesired level of accuracy and $\\kappa$ is the problem's condition number. {Such\na computation complexity improves the state-of-the-art complexities of\nsingle-loop GDA and AltGDA algorithms (see the summary of comparison in\n\\Cref{table1})}. We demonstrate the effectiveness of our algorithm via an\nexperiment on adversarial deep learning.",
          "link": "http://arxiv.org/abs/2112.11663",
          "publishedOn": "2022-04-28T01:16:09.728Z",
          "wordCount": 674,
          "title": "Accelerated Proximal Alternating Gradient-Descent-Ascent for Nonconvex Minimax Machine Learning. (arXiv:2112.11663v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12169",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rikhye_R/0/1/0/all/0/1\">Rajeev Rikhye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1\">Quan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_Q/0/1/0/all/0/1\">Qiao Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yanzhang He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McGraw_I/0/1/0/all/0/1\">Ian McGraw</a>",
          "description": "VoiceFilter-Lite is a speaker-conditioned voice separation model that plays a\ncrucial role in improving speech recognition and speaker verification by\nsuppressing overlapping speech from non-target speakers. However, one\nlimitation of VoiceFilter-Lite, and other speaker-conditioned speech models in\ngeneral, is that these models are usually limited to a single target speaker.\nThis is undesirable as most smart home devices now support multiple enrolled\nusers. In order to extend the benefits of personalization to multiple users, we\npreviously developed an attention-based speaker selection mechanism and applied\nit to VoiceFilter-Lite. However, the original multi-user VoiceFilter-Lite model\nsuffers from significant performance degradation compared with single-user\nmodels. In this paper, we devised a series of experiments to improve the\nmulti-user VoiceFilter-Lite model. By incorporating a dual learning rate\nschedule and by using feature-wise linear modulation (FiLM) to condition the\nmodel with the attended speaker embedding, we successfully closed the\nperformance gap between multi-user and single-user VoiceFilter-Lite models on\nsingle-speaker evaluations. At the same time, the new model can also be easily\nextended to support any number of users, and significantly outperforms our\npreviously published model on multi-speaker evaluations.",
          "link": "http://arxiv.org/abs/2202.12169",
          "publishedOn": "2022-04-28T01:16:09.721Z",
          "wordCount": 651,
          "title": "Closing the Gap between Single-User and Multi-User VoiceFilter-Lite. (arXiv:2202.12169v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.12933",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Zilber_P/0/1/0/all/0/1\">Pini Zilber</a>, <a href=\"http://arxiv.org/find/math/1/au:+Nadler_B/0/1/0/all/0/1\">Boaz Nadler</a>",
          "description": "Low rank matrix recovery problems, including matrix completion and matrix\nsensing, appear in a broad range of applications. In this work we present GNMR\n-- an extremely simple iterative algorithm for low rank matrix recovery, based\non a Gauss-Newton linearization. On the theoretical front, we derive recovery\nguarantees for GNMR in both the matrix sensing and matrix completion settings.\nSome of these results improve upon the best currently known for other methods.\nA key property of GNMR is that it implicitly keeps the factor matrices\napproximately balanced throughout its iterations. On the empirical front, we\nshow that for matrix completion with uniform sampling, GNMR performs better\nthan several popular methods, especially when given very few observations close\nto the information limit.",
          "link": "http://arxiv.org/abs/2106.12933",
          "publishedOn": "2022-04-28T01:16:09.715Z",
          "wordCount": 597,
          "title": "GNMR: A provable one-line algorithm for low rank matrix recovery. (arXiv:2106.12933v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.09046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhenhuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1\">Yunwen Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1\">Kush R. Varshney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Siwei Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_Y/0/1/0/all/0/1\">Yiming Ying</a>",
          "description": "Stochastic gradient descent ascent (SGDA) and its variants have been the\nworkhorse for solving minimax problems. However, in contrast to the\nwell-studied stochastic gradient descent (SGD) with differential privacy (DP)\nconstraints, there is little work on understanding the generalization (utility)\nof SGDA with DP constraints. In this paper, we use the algorithmic stability\napproach to establish the generalization (utility) of DP-SGDA in different\nsettings. In particular, for the convex-concave setting, we prove that the\nDP-SGDA can achieve an optimal utility rate in terms of the weak primal-dual\npopulation risk in both smooth and non-smooth cases. To our best knowledge,\nthis is the first-ever-known result for DP-SGDA in the non-smooth case. We\nfurther provide its utility analysis in the nonconvex-strongly-concave setting\nwhich is the first-ever-known result in terms of the primal population risk.\nThe convergence and generalization results for this nonconvex setting are new\neven in the non-private setting. Finally, numerical experiments are conducted\nto demonstrate the effectiveness of DP-SGDA for both convex and nonconvex\ncases.",
          "link": "http://arxiv.org/abs/2201.09046",
          "publishedOn": "2022-04-28T01:16:09.709Z",
          "wordCount": 643,
          "title": "Differentially Private SGDA for Minimax Problems. (arXiv:2201.09046v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.00232",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bassi_P/0/1/0/all/0/1\">Pedro R.A.S. Bassi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cavalli_A/0/1/0/all/0/1\">Andrea Cavalli</a>",
          "description": "This work proposes a novel deep neural network (DNN) architecture, Implicit\nSegmentation Neural Network (ISNet), to solve the task of image segmentation\nfollowed by classification. It substitutes the common pipeline of two DNNs with\na single model. We designed the ISNet for high flexibility and performance: it\nallows virtually any classification neural network architecture to analyze a\ncommon image as if it had been previously segmented. Furthermore, in relation\nto the unmodified classifier, the ISNet does not cause any increment in\ncomputational cost at run-time. We test the architecture with two applications:\nCOVID-19 detection in chest X-rays, and facial attribute estimation. We\nimplement an ISNet based on a DenseNet121 classifier, and compare the model to\na U-net (performing lung/face segmentation) followed by a DenseNet121, and to a\nstandalone DenseNet121. The new architecture matched the other DNNs in facial\nattribute estimation. Moreover, it strongly surpassed them in COVID-19\ndetection, according to an external test dataset. The ISNet precisely ignored\nthe image regions outside of the lungs or faces. Therefore, in COVID-19\ndetection it reduced the effects of background bias and shortcut learning, and\nit improved security in facial attribute estimation. ISNet presents an\naccurate, fast, and light methodology. The successful implicit segmentation,\nconsidering two largely diverse fields, highlights the architecture's general\napplicability.",
          "link": "http://arxiv.org/abs/2202.00232",
          "publishedOn": "2022-04-28T01:16:09.703Z",
          "wordCount": 768,
          "title": "ISNet: Costless and Implicit Image Segmentation for Deep Classifiers, with Application in COVID-19 Detection. (arXiv:2202.00232v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.00653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_M/0/1/0/all/0/1\">Mayank Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madan_D/0/1/0/all/0/1\">Dhiraj Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_G/0/1/0/all/0/1\">Gaurav Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Contractor_D/0/1/0/all/0/1\">Danish Contractor</a>",
          "description": "Recent methods for knowledge grounded dialogs generate responses by\nincorporating information from an external textual document. These methods do\nnot require the exact document to be known during training and rely on the use\nof a retrieval system to fetch relevant documents from a large index. The\ndocuments used to generate the responses are modeled as latent variables whose\nprior probabilities need to be estimated. Models such as RAG and REALM,\nmarginalize the document probabilities over the documents retrieved from the\nindex to define the log likelihood loss function which is optimized end-to-end.\n\nIn this paper, we develop a variational approach to the above technique\nwherein, we instead maximize the Evidence Lower bound (ELBO). Using a\ncollection of three publicly available open-conversation datasets, we\ndemonstrate how the posterior distribution, that has information from the\nground-truth response, allows for a better approximation of the objective\nfunction during training. To overcome the challenges associated with sampling\nover a large knowledge collection, we develop an efficient approach to\napproximate the ELBO. To the best of our knowledge we are the first to apply\nvariational training for open-scale unsupervised knowledge grounded dialog\nsystems.",
          "link": "http://arxiv.org/abs/2112.00653",
          "publishedOn": "2022-04-28T01:16:09.685Z",
          "wordCount": 662,
          "title": "Variational Learning for Unsupervised Knowledge Grounded Dialogs. (arXiv:2112.00653v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09212",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_Z/0/1/0/all/0/1\">Zhishen Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ravishankar_S/0/1/0/all/0/1\">Saiprasad Ravishankar</a>",
          "description": "There is much recent interest in techniques to accelerate the data\nacquisition process in MRI by acquiring limited measurements. Often\nsophisticated reconstruction algorithms are deployed to maintain high image\nquality in such settings. In this work, we propose a data-driven sampler using\na convolutional neural network, MNet, to provide object-specific sampling\npatterns adaptive to each scanned object. The network observes very limited\nlow-frequency k-space data for each object and rapidly predicts the desired\nundersampling pattern in one go that achieves high image reconstruction\nquality.\n\nWe propose an accompanying alternating-type training framework with a\nmask-backward procedure that efficiently generates training labels for the\nsampler network and jointly trains an image reconstruction network.\nExperimental results on the fastMRI knee dataset demonstrate the ability of the\nproposed learned undersampling network to generate object-specific masks at\nfourfold and eightfold acceleration that achieve superior image reconstruction\nperformance than several existing schemes. The source code for the proposed\njoint sampling and reconstruction learning framework is available at\nhttps://github.com/zhishenhuang/mri.",
          "link": "http://arxiv.org/abs/2111.09212",
          "publishedOn": "2022-04-28T01:16:09.590Z",
          "wordCount": 632,
          "title": "Single-pass Object-adaptive Data Undersampling and Reconstruction for MRI. (arXiv:2111.09212v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01409",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rosato_C/0/1/0/all/0/1\">Conor Rosato</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beraud_V/0/1/0/all/0/1\">Vincent Beraud</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Horridge_P/0/1/0/all/0/1\">Paul Horridge</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1\">Thomas B. Sch&#xf6;n</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maskell_S/0/1/0/all/0/1\">Simon Maskell</a>",
          "description": "It has been widely documented that the sampling and resampling steps in\nparticle filters cannot be differentiated. The {\\itshape reparameterisation\ntrick} was introduced to allow the sampling step to be reformulated into a\ndifferentiable function. We extend the {\\itshape reparameterisation trick} to\ninclude the stochastic input to resampling therefore limiting the\ndiscontinuities in the gradient calculation after this step. Knowing the\ngradients of the prior and likelihood allows us to run particle Markov Chain\nMonte Carlo (p-MCMC) and use the No-U-Turn Sampler (NUTS) as the proposal when\nestimating parameters.\n\nWe compare the Metropolis-adjusted Langevin algorithm (MALA), Hamiltonian\nMonte Carlo with different number of steps and NUTS. We consider two\nstate-space models and show that NUTS improves the mixing of the Markov chain\nand can produce more accurate results in less computational time.",
          "link": "http://arxiv.org/abs/2111.01409",
          "publishedOn": "2022-04-28T01:16:09.584Z",
          "wordCount": 605,
          "title": "Efficient Learning of the Parameters of Non-Linear Models using Differentiable Resampling in Particle Filters. (arXiv:2111.01409v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08055",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Girardin_A/0/1/0/all/0/1\">Antoine Girardin</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Brunner_N/0/1/0/all/0/1\">Nicolas Brunner</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Krivachy_T/0/1/0/all/0/1\">Tam&#xe1;s Kriv&#xe1;chy</a>",
          "description": "Finding the closest separable state to a given target state is a notoriously\ndifficult task, even more difficult than deciding whether a state is entangled\nor separable. To tackle this task, we parametrize separable states with a\nneural network and train it to minimize the distance to a given target state,\nwith respect to a differentiable distance, such as the trace distance or\nHilbert--Schmidt distance. By examining the output of the algorithm, we obtain\nan upper bound on the entanglement of the target state, and construct an\napproximation for its closest separable state. We benchmark the method on a\nvariety of well-known classes of bipartite states and find excellent agreement,\neven up to local dimension of $d=10$, while providing conjectures and analytic\ninsight for isotropic and Werner states. Moreover, we show our method to be\nefficient in the multipartite case, considering different notions of\nseparability. Examining three and four-party GHZ and W states we recover known\nbounds and obtain novel ones, for instance for triseparability.",
          "link": "http://arxiv.org/abs/2112.08055",
          "publishedOn": "2022-04-28T01:16:09.578Z",
          "wordCount": 697,
          "title": "Building separable approximations for quantum states via neural networks. (arXiv:2112.08055v4 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.15186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tseng_A/0/1/0/all/0/1\">Albert Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>",
          "description": "Obtaining annotations for large training sets is expensive, especially in\nsettings where domain knowledge is required, such as behavior analysis. Weak\nsupervision has been studied to reduce annotation costs by using weak labels\nfrom task-specific labeling functions (LFs) to augment ground truth labels.\nHowever, domain experts still need to hand-craft different LFs for different\ntasks, limiting scalability. To reduce expert effort, we present AutoSWAP: a\nframework for automatically synthesizing data-efficient task-level LFs. The key\nto our approach is to efficiently represent expert knowledge in a reusable\ndomain-specific language and more general domain-level LFs, with which we use\nstate-of-the-art program synthesis techniques and a small labeled dataset to\ngenerate task-level LFs. Additionally, we propose a novel structural diversity\ncost that allows for efficient synthesis of diverse sets of LFs, further\nimproving AutoSWAP's performance. We evaluate AutoSWAP in three behavior\nanalysis domains and demonstrate that AutoSWAP outperforms existing approaches\nusing only a fraction of the data. Our results suggest that AutoSWAP is an\neffective way to automatically generate LFs that can significantly reduce\nexpert effort for behavior analysis.",
          "link": "http://arxiv.org/abs/2111.15186",
          "publishedOn": "2022-04-28T01:16:09.532Z",
          "wordCount": 652,
          "title": "Automatic Synthesis of Diverse Weak Supervision Sources for Behavior Analysis. (arXiv:2111.15186v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.02089",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>",
          "description": "We present a Newton-type method that converges fast from any initialization\nand for arbitrary convex objectives with Lipschitz Hessians. We achieve this by\nmerging the ideas of cubic regularization with a certain adaptive\nLevenberg--Marquardt penalty. In particular, we show that the iterates given by\n$x^{k+1}=x^k - \\bigl(\\nabla^2 f(x^k) + \\sqrt{H\\|\\nabla f(x^k)\\|}\n\\mathbf{I}\\bigr)^{-1}\\nabla f(x^k)$, where $H>0$ is a constant, converge\nglobally with a $\\mathcal{O}(\\frac{1}{k^2})$ rate. Our method is the first\nvariant of Newton's method that has both cheap iterations and provably fast\nglobal convergence. Moreover, we prove that locally our method converges\nsuperlinearly when the objective is strongly convex. To boost the method's\nperformance, we present a line search procedure that does not need\nhyperparameters and is provably efficient.",
          "link": "http://arxiv.org/abs/2112.02089",
          "publishedOn": "2022-04-28T01:16:09.515Z",
          "wordCount": 570,
          "title": "Regularized Newton Method with Global $O(1/k^2)$ Convergence. (arXiv:2112.02089v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.15424",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_Z/0/1/0/all/0/1\">Zhishen Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klasky_M/0/1/0/all/0/1\">Marc Klasky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wilcox_T/0/1/0/all/0/1\">Trevor Wilcox</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ravishankar_S/0/1/0/all/0/1\">Saiprasad Ravishankar</a>",
          "description": "Object density reconstruction from projections containing scattered radiation\nand noise is of critical importance in many applications. Existing scatter\ncorrection and density reconstruction methods may not provide the high accuracy\nneeded in many applications and can break down in the presence of unmodeled or\nanomalous scatter and other experimental artifacts. Incorporating\nmachine-learned models could prove beneficial for accurate density\nreconstruction particularly in dynamic imaging, where the time-evolution of the\ndensity fields could be captured by partial differential equations or by\nlearning from hydrodynamics simulations. In this work, we demonstrate the\nability of learned deep neural networks to perform artifact removal in noisy\ndensity reconstructions, where the noise is imperfectly characterized. We use a\nWasserstein generative adversarial network (WGAN), where the generator serves\nas a denoiser that removes artifacts in densities obtained from traditional\nreconstruction algorithms. We train the networks from large density time-series\ndatasets, with noise simulated according to parametric random distributions\nthat may mimic noise in experiments. The WGAN is trained with noisy density\nframes as generator inputs, to match the generator outputs to the distribution\nof clean densities (time-series) from simulations. A supervised loss is also\nincluded in the training, which leads to improved density restoration\nperformance. In addition, we employ physics-based constraints such as mass\nconservation during network training and application to further enable highly\naccurate density reconstructions. Our preliminary numerical results show that\nthe models trained in our frameworks can remove significant portions of unknown\nnoise in density time-series data.",
          "link": "http://arxiv.org/abs/2110.15424",
          "publishedOn": "2022-04-28T01:16:09.510Z",
          "wordCount": 722,
          "title": "Physics-Driven Learning of Wasserstein GAN for Density Reconstruction in Dynamic Tomography. (arXiv:2110.15424v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.12523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simko_J/0/1/0/all/0/1\">Jakub Simko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Racsko_P/0/1/0/all/0/1\">Patrik Racsko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomlein_M/0/1/0/all/0/1\">Matus Tomlein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanakova_M/0/1/0/all/0/1\">Martin Hanakova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moro_R/0/1/0/all/0/1\">Robert Moro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bielikova_M/0/1/0/all/0/1\">Maria Bielikova</a>",
          "description": "The online spreading of fake news is a major issue threatening entire\nsocieties. Much of this spreading is enabled by new media formats, namely\nsocial networks and online media sites. Researchers and practitioners have been\ntrying to answer this by characterizing the fake news and devising automated\nmethods for detecting them. The detection methods had so far only limited\nsuccess, mostly due to the complexity of the news content and context and lack\nof properly annotated datasets. One possible way to boost the efficiency of\nautomated misinformation detection methods, is to imitate the detection work of\nhumans. It is also important to understand the news consumption behavior of\nonline users. In this paper, we present an eye-tracking study, in which we let\n44 lay participants to casually read through a social media feed containing\nposts with news articles, some of which were fake. In a second run, we asked\nthe participants to decide on the truthfulness of these articles. We also\ndescribe a follow-up qualitative study with a similar scenario but this time\nwith 7 expert fake news annotators. We present the description of both studies,\ncharacteristics of the resulting dataset (which we hereby publish) and several\nfindings.",
          "link": "http://arxiv.org/abs/2109.12523",
          "publishedOn": "2022-04-28T01:16:09.503Z",
          "wordCount": 711,
          "title": "A Study of Fake News Reading and Annotating in Social Media Context. (arXiv:2109.12523v2 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.12891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Anwesh Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattheakis_M/0/1/0/all/0/1\">Marios Mattheakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Protopapas_P/0/1/0/all/0/1\">Pavlos Protopapas</a>",
          "description": "In certain situations, neural networks are trained upon data that obey\nunderlying symmetries. However, the predictions do not respect the symmetries\nexactly unless embedded in the network structure. In this work, we introduce\narchitectures that embed a special kind of symmetry namely, invariance with\nrespect to involutory linear/affine transformations up to parity $p=\\pm 1$. We\nprovide rigorous theorems to show that the proposed network ensures such an\ninvariance and present qualitative arguments for a special universal\napproximation theorem. An adaption of our techniques to CNN tasks for datasets\nwith inherent horizontal/vertical reflection symmetry is demonstrated.\nExtensive experiments indicate that the proposed model outperforms baseline\nfeed-forward and physics-informed neural networks while identically respecting\nthe underlying symmetry.",
          "link": "http://arxiv.org/abs/2106.12891",
          "publishedOn": "2022-04-28T01:16:09.496Z",
          "wordCount": 582,
          "title": "Encoding Involutory Invariances in Neural Networks. (arXiv:2106.12891v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.15808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Baihan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouneffouf_D/0/1/0/all/0/1\">Djallel Bouneffouf</a>",
          "description": "In light of the COVID-19 pandemic, it is an open challenge and critical\npractical problem to find a optimal way to dynamically prescribe the best\npolicies that balance both the governmental resources and epidemic control in\ndifferent countries and regions. To solve this multi-dimensional tradeoff of\nexploitation and exploration, we formulate this technical challenge as a\ncontextual combinatorial bandit problem that jointly optimizes a multi-criteria\nreward function. Given the historical daily cases in a region and the past\nintervention plans in place, the agent should generate useful intervention\nplans that policy makers can implement in real time to minimizing both the\nnumber of daily COVID-19 cases and the stringency of the recommended\ninterventions. We prove this concept with simulations of multiple realistic\npolicy making scenarios and demonstrate a clear advantage in providing a pareto\noptimal solution in the epidemic intervention problem.",
          "link": "http://arxiv.org/abs/2106.15808",
          "publishedOn": "2022-04-28T01:16:09.480Z",
          "wordCount": 688,
          "title": "Optimal Epidemic Control as a Contextual Combinatorial Bandit with Budget. (arXiv:2106.15808v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.00306",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Falconer_T/0/1/0/all/0/1\">Thomas Falconer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mones_L/0/1/0/all/0/1\">Letif Mones</a>",
          "description": "Machine learning assisted optimal power flow (OPF) aims to reduce the\ncomputational complexity of these non-linear and non-convex constrained\noptimization problems by consigning expensive (online) optimization to offline\ntraining. The majority of work in this area typically employs fully connected\nneural networks (FCNN). However, recently convolutional (CNN) and graph (GNN)\nneural networks have also been investigated, in effort to exploit topological\ninformation within the power grid. Although promising results have been\nobtained, there lacks a systematic comparison between these architectures\nthroughout literature. Accordingly, we introduce a concise framework for\ngeneralizing methods for machine learning assisted OPF and assess the\nperformance of a variety of FCNN, CNN and GNN models for two fundamental\napproaches in this domain: regression (predicting optimal generator set-points)\nand classification (predicting the active set of constraints). For several\nsynthetic power grids with interconnected utilities, we show that locality\nproperties between feature and target variables are scarce and subsequently\ndemonstrate marginal utility of applying CNN and GNN architectures compared to\nFCNN for a fixed grid topology. However, with variable topology (for instance,\nmodeling transmission line contingency), GNN models are able to\nstraightforwardly take the change of topological information into account and\noutperform both FCNN and CNN models.",
          "link": "http://arxiv.org/abs/2110.00306",
          "publishedOn": "2022-04-28T01:16:09.474Z",
          "wordCount": 693,
          "title": "Leveraging power grid topology in machine learning assisted optimal power flow. (arXiv:2110.00306v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.14457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nadali_A/0/1/0/all/0/1\">Alireza Nadali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ebadzadeh_M/0/1/0/all/0/1\">Mohammad Mehdi Ebadzadeh</a>",
          "description": "In recent years, there have been many deep structures for Reinforcement\nLearning, mainly for value function estimation and representations. These\nmethods achieved great success in Atari 2600 domain. In this paper, we propose\nan improved architecture based upon Dueling Networks, in this architecture,\nthere are two separate estimators, one approximate the state value function and\nthe other, state advantage function. This improvement based on Maximum Entropy,\nshows better policy evaluation compared to the original network and other\nvalue-based architectures in Atari domain.",
          "link": "http://arxiv.org/abs/2107.14457",
          "publishedOn": "2022-04-28T01:16:09.468Z",
          "wordCount": 541,
          "title": "Maximum Entropy Dueling Network Architecture in Atari Domain. (arXiv:2107.14457v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.04420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1\">Harshavardhan Kamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Alexander Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1\">B. Aditya Prakash</a>",
          "description": "In real-time forecasting in public health, data collection is a non-trivial\nand demanding task. Often after initially released, it undergoes several\nrevisions later (maybe due to human or technical constraints) - as a result, it\nmay take weeks until the data reaches to a stable value. This so-called\n'backfill' phenomenon and its effect on model performance has been barely\nstudied in the prior literature. In this paper, we introduce the multi-variate\nbackfill problem using COVID-19 as the motivating example. We construct a\ndetailed dataset composed of relevant signals over the past year of the\npandemic. We then systematically characterize several patterns in backfill\ndynamics and leverage our observations for formulating a novel problem and\nneural framework Back2Future that aims to refines a given model's predictions\nin real-time. Our extensive experiments demonstrate that our method refines the\nperformance of top models for COVID-19 forecasting, in contrast to non-trivial\nbaselines, yielding 18% improvement over baselines, enabling us obtain a new\nSOTA performance. In addition, we show that our model improves model evaluation\ntoo; hence policy-makers can better understand the true accuracy of forecasting\nmodels in real-time.",
          "link": "http://arxiv.org/abs/2106.04420",
          "publishedOn": "2022-04-28T01:16:09.462Z",
          "wordCount": 764,
          "title": "Back2Future: Leveraging Backfill Dynamics for Improving Real-time Predictions in Future. (arXiv:2106.04420v8 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.10213",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_L/0/1/0/all/0/1\">Ling Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Miao_S/0/1/0/all/0/1\">Shenghuan Miao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_S/0/1/0/all/0/1\">Sirou Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_R/0/1/0/all/0/1\">Rong Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1\">Liangying Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_M/0/1/0/all/0/1\">Mingqi Lv</a>",
          "description": "Unsupervised user adaptation aligns the feature distributions of the data\nfrom training users and the new user, so a well-trained wearable human activity\nrecognition (WHAR) model can be well adapted to the new user. With the\ndevelopment of wearable sensors, multiple wearable sensors based WHAR is\ngaining more and more attention. In order to address the challenge that the\ntransferabilities of different sensors are different, we propose SALIENCE\n(unsupervised user adaptation model for multiple wearable sensors based human\nactivity recognition) model. It aligns the data of each sensor separately to\nachieve local alignment, while uniformly aligning the data of all sensors to\nensure global alignment. In addition, an attention mechanism is proposed to\nfocus the activity classifier of SALIENCE on the sensors with strong feature\ndiscrimination and well distribution alignment. Experiments are conducted on\ntwo public WHAR datasets, and the experimental results show that our model can\nyield a competitive performance.",
          "link": "http://arxiv.org/abs/2108.10213",
          "publishedOn": "2022-04-28T01:16:09.455Z",
          "wordCount": 645,
          "title": "SALIENCE: An Unsupervised User Adaptation Model for Multiple Wearable Sensors Based Human Activity Recognition. (arXiv:2108.10213v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.00397",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Liu Yang</a>",
          "description": "In this work, we formulate a visual dialog as an information flow in which\neach piece of information is encoded with the joint visual-linguistic\nrepresentation of a single dialog round. Based on this formulation, we consider\nthe visual dialog task as a sequence problem consisting of ordered\nvisual-linguistic vectors. For featurization, we use a Dense Symmetric\nCo-Attention network as a lightweight vison-language joint representation\ngenerator to fuse multimodal features (i.e., image and text), yielding better\ncomputation and data efficiencies. For inference, we propose two Sequential\nDialog Networks (SeqDialN): the first uses LSTM for information propagation\n(IP) and the second uses a modified Transformer for multi-step reasoning (MR).\nOur architecture separates the complexity of multimodal feature fusion from\nthat of inference, which allows simpler design of the inference engine. IP\nbased SeqDialN is our baseline with a simple 2-layer LSTM design that achieves\ndecent performance. MR based SeqDialN, on the other hand, recurrently refines\nthe semantic question/history representations through the self-attention stack\nof Transformer and produces promising results on the visual dialog task. On\nVisDial v1.0 test-std dataset, our best single generative SeqDialN achieves\n62.54% NDCG and 48.63% MRR; our ensemble generative SeqDialN achieves 63.78%\nNDCG and 49.98% MRR, which set a new state-of-the-art generative visual dialog\nmodel. We fine-tune discriminative SeqDialN with dense annotations and boost\nthe performance up to 72.41% NDCG and 55.11% MRR. In this work, we discuss the\nextensive experiments we have conducted to demonstrate the effectiveness of our\nmodel components. We also provide visualization for the reasoning process from\nthe relevant conversation rounds and discuss our fine-tuning methods. Our code\nis available at https://github.com/xiaoxiaoheimei/SeqDialN",
          "link": "http://arxiv.org/abs/2008.00397",
          "publishedOn": "2022-04-28T01:16:09.436Z",
          "wordCount": 759,
          "title": "SeqDialN: Sequential Visual Dialog Networks in Joint Visual-Linguistic Representation Space. (arXiv:2008.00397v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.02588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Wayne Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Da_D/0/1/0/all/0/1\">Daicong Da</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuge_M/0/1/0/all/0/1\">Mark Fuge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rai_R/0/1/0/all/0/1\">Rahul Rai</a>",
          "description": "Variable-density cellular structures can overcome connectivity and\nmanufacturability issues of topologically optimized structures, particularly\nthose represented as discrete density maps. However, the optimization of such\ncellular structures is challenging due to the multiscale design problem. Past\nwork addressing this problem generally either only optimizes the volume\nfraction of single-type unit cells but ignores the effects of unit cell\ngeometry on properties, or considers the geometry-property relation but builds\nthis relation via heuristics. In contrast, we propose a simple yet more\nprincipled way to accurately model the property to geometry mapping using a\nconditional deep generative model, named Inverse Homogenization Generative\nAdversarial Network (IH-GAN). It learns the conditional distribution of unit\ncell geometries given properties and can realize the one-to-many mapping from\nproperties to geometries. We further reduce the complexity of IH-GAN by using\nthe implicit function parameterization to represent unit cell geometries.\nResults show that our method can 1) generate various unit cells that satisfy\ngiven material properties with high accuracy ($R^2$-scores between target\nproperties and properties of generated unit cells $>98\\%$) and 2) improve the\noptimized structural performance over the conventional variable-density\nsingle-type structure. In the minimum compliance example, our IH-GAN generated\nstructure achieves a $79.7\\%$ reduction in concentrated stress and an extra\n$3.03\\%$ reduction in displacement. In the target deformation examples, our\nIH-GAN generated structure reduces the target matching error by $86.4\\%$ and\n$79.6\\%$ for two test cases, respectively. We also demonstrated that the\nconnectivity issue for multi-type unit cells can be solved by transition layer\nblending.",
          "link": "http://arxiv.org/abs/2103.02588",
          "publishedOn": "2022-04-28T01:16:09.429Z",
          "wordCount": 756,
          "title": "IH-GAN: A Conditional Generative Model for Implicit Surface-Based Inverse Design of Cellular Structures. (arXiv:2103.02588v4 [cs.CE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.01635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shaocong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaohan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chao Shen</a>",
          "description": "Knowledge graph (KG), integrating complex information and containing rich\nsemantics, is widely considered as side information to enhance the\nrecommendation systems. However, most of the existing KG-based methods\nconcentrate on encoding the structural information in the graph, without\nutilizing the collaborative signals in user-item interaction data, which are\nimportant for understanding user preferences. Therefore, the representations\nlearned by these models are insufficient for representing semantic information\nof users and items in the recommendation environment. The combination of both\nkinds of data provides a good chance to solve this problem. To tackle this\nresearch gap, we propose a novel duet representation learning framework named\n\\sysname to fuse local information (user-item interaction data) and global\ninformation (external knowledge graph) for the top-$N$ recommendation, which is\ncomposed of two separate sub-models. One learns the local representations by\ndiscovering the inner correlations in local information with a knowledge-aware\nco-attention mechanism, and another learns the global representations by\nencoding the knowledge associations in global information with a relation-aware\nattention network. The two sub-models are jointly trained as part of the\nsemantic fusion network to compute the user preferences, which discriminates\nthe contribution of the two sub-models under the special context. We conduct\nexperiments on two real-world datasets, and the evaluations show that KADM\nsignificantly outperforms state-of-art methods. Further ablation studies\nconfirm that the duet architecture performs significantly better than either\nsub-model on the recommendation tasks.",
          "link": "http://arxiv.org/abs/2012.01635",
          "publishedOn": "2022-04-28T01:16:09.423Z",
          "wordCount": 730,
          "title": "Unify Local and Global Information for Top-$N$ Recommendation. (arXiv:2012.01635v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13089",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Das_N/0/1/0/all/0/1\">Niladri Das</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duersch_J/0/1/0/all/0/1\">Jed A. Duersch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Catanach_T/0/1/0/all/0/1\">Thomas A. Catanach</a>",
          "description": "In this paper, we address the problem of convergence of sequential\nvariational inference filter (VIF) through the application of a robust\nvariational objective and Hinf-norm based correction for a linear Gaussian\nsystem. As the dimension of state or parameter space grows, performing the full\nKalman update with the dense covariance matrix for a large scale system\nrequires increased storage and computational complexity, making it impractical.\nThe VIF approach, based on mean-field Gaussian variational inference, reduces\nthis burden through the variational approximation to the covariance usually in\nthe form of a diagonal covariance approximation. The challenge is to retain\nconvergence and correct for biases introduced by the sequential VIF steps. We\ndesire a framework that improves feasibility while still maintaining reasonable\nproximity to the optimal Kalman filter as data is assimilated. To accomplish\nthis goal, a Hinf-norm based optimization perturbs the VIF covariance matrix to\nimprove robustness. This yields a novel VIF- Hinf recursion that employs\nconsecutive variational inference and Hinf based optimization steps. We explore\nthe development of this method and investigate a numerical example to\nillustrate the effectiveness of the proposed filter.",
          "link": "http://arxiv.org/abs/2204.13089",
          "publishedOn": "2022-04-28T01:16:09.417Z",
          "wordCount": 627,
          "title": "Variational Kalman Filtering with Hinf-Based Correction for Robust Bayesian Learning in High Dimensions. (arXiv:2204.13089v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.10331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1\">Nirmalya Thakur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chia Y. Han</a>",
          "description": "This paper makes two scientific contributions to the field of\nexoskeleton-based action and movement recognition. First, it presents a novel\nmachine learning and pattern recognition-based framework that can detect a wide\nrange of actions and movements - walking, walking upstairs, walking downstairs,\nsitting, standing, lying, stand to sit, sit to stand, sit to lie, lie to sit,\nstand to lie, and lie to stand, with an overall accuracy of 82.63%. Second, it\npresents a comprehensive comparative study of different learning approaches -\nRandom Forest, Artificial Neural Network, Decision Tree, Multiway Decision\nTree, Support Vector Machine, k-NN, Gradient Boosted Trees, Decision Stump,\nAutoMLP, Linear Regression, Vector Linear Regression, Random Tree, Na\\\"ive\nBayes, Na\\\"ive Bayes (Kernel), Linear Discriminant Analysis, Quadratic\nDiscriminant Analysis, and Deep Learning applied to this framework. The\nperformance of each of these learning approaches was boosted by using the\nAdaBoost algorithm, and the Cross Validation approach was used for training and\ntesting. The results show that in boosted form, the k-NN classifier outperforms\nall the other boosted learning approaches and is, therefore, the optimal\nlearning method for this purpose. The results presented and discussed uphold\nthe importance of this work to contribute towards augmenting the abilities of\nexoskeleton-based assisted and independent living of the elderly in the future\nof Internet of Things-based living environments, such as Smart Homes. As a\nspecific use case, we also discuss how the findings of our work are relevant\nfor augmenting the capabilities of the Hybrid Assistive Limb exoskeleton, a\nhighly functional lower limb exoskeleton.",
          "link": "http://arxiv.org/abs/2106.10331",
          "publishedOn": "2022-04-28T01:16:09.402Z",
          "wordCount": 743,
          "title": "Exoskeleton-Based Multimodal Action and Movement Recognition: Identifying and Developing the Optimal Boosted Learning Approach. (arXiv:2106.10331v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.10070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1\">Nanqing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maggioni_M/0/1/0/all/0/1\">Matteo Maggioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yongxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Pellitero_E/0/1/0/all/0/1\">Eduardo P&#xe9;rez-Pellitero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leonardis_A/0/1/0/all/0/1\">Ales Leonardis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonagh_S/0/1/0/all/0/1\">Steven McDonagh</a>",
          "description": "This paper is concerned with contrastive learning (CL) for low-level image\nrestoration and enhancement tasks. We propose a new label-efficient learning\nparadigm based on residuals, residual contrastive learning (RCL), and derive an\nunsupervised visual representation learning framework, suitable for low-level\nvision tasks with noisy inputs. While supervised image reconstruction aims to\nminimize residual terms directly, RCL alternatively builds a connection between\nresiduals and CL by defining a novel instance discrimination pretext task,\nusing residuals as the discriminative feature. Our formulation mitigates the\nsevere task misalignment between instance discrimination pretext tasks and\ndownstream image reconstruction tasks, present in existing CL frameworks.\nExperimentally, we find that RCL can learn robust and transferable\nrepresentations that improve the performance of various downstream tasks, such\nas denoising and super resolution, in comparison with recent self-supervised\nmethods designed specifically for noisy inputs. Additionally, our unsupervised\npre-training can significantly reduce annotation costs whilst maintaining\nperformance competitive with fully-supervised image reconstruction.",
          "link": "http://arxiv.org/abs/2106.10070",
          "publishedOn": "2022-04-28T01:16:09.396Z",
          "wordCount": 642,
          "title": "Residual Contrastive Learning for Image Reconstruction: Learning Transferable Representations from Noisy Images. (arXiv:2106.10070v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.08388",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Libovicky_J/0/1/0/all/0/1\">Jind&#x159;ich Libovick&#xfd;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fraser_A/0/1/0/all/0/1\">Alexander Fraser</a>",
          "description": "We propose the neural string edit distance model for string-pair matching and\nstring transduction based on learnable string edit distance. We modify the\noriginal expectation-maximization learned edit distance algorithm into a\ndifferentiable loss function, allowing us to integrate it into a neural network\nproviding a contextual representation of the input. We evaluate on cognate\ndetection, transliteration, and grapheme-to-phoneme conversion, and show that\nwe can trade off between performance and interpretability in a single\nframework. Using contextual representations, which are difficult to interpret,\nwe match the performance of state-of-the-art string-pair matching models. Using\nstatic embeddings and a slightly different loss function, we force\ninterpretability, at the expense of an accuracy drop.",
          "link": "http://arxiv.org/abs/2104.08388",
          "publishedOn": "2022-04-28T01:16:09.389Z",
          "wordCount": 576,
          "title": "Neural String Edit Distance. (arXiv:2104.08388v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.03448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singhal_K/0/1/0/all/0/1\">Karan Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sidahmed_H/0/1/0/all/0/1\">Hakim Sidahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrett_Z/0/1/0/all/0/1\">Zachary Garrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shanshan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_K/0/1/0/all/0/1\">Keith Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_S/0/1/0/all/0/1\">Sushant Prakash</a>",
          "description": "Personalization methods in federated learning aim to balance the benefits of\nfederated and local training for data availability, communication cost, and\nrobustness to client heterogeneity. Approaches that require clients to\ncommunicate all model parameters can be undesirable due to privacy and\ncommunication constraints. Other approaches require always-available or\nstateful clients, impractical in large-scale cross-device settings. We\nintroduce Federated Reconstruction, the first model-agnostic framework for\npartially local federated learning suitable for training and inference at\nscale. We motivate the framework via a connection to model-agnostic meta\nlearning, empirically demonstrate its performance over existing approaches for\ncollaborative filtering and next word prediction, and release an open-source\nlibrary for evaluating approaches in this setting. We also describe the\nsuccessful deployment of this approach at scale for federated collaborative\nfiltering in a mobile keyboard application.",
          "link": "http://arxiv.org/abs/2102.03448",
          "publishedOn": "2022-04-28T01:16:09.383Z",
          "wordCount": 647,
          "title": "Federated Reconstruction: Partially Local Federated Learning. (arXiv:2102.03448v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.07437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Deli Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xuancheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>",
          "description": "Graph Contrastive Learning (GCL) has proven highly effective in promoting the\nperformance of Semi-Supervised Node Classification (SSNC). However, existing\nGCL methods are generally transferred from other fields like CV or NLP, whose\nunderlying working mechanism remains under-explored. In this work, we first\ndeeply probe the working mechanism of GCL in SSNC, and find that the promotion\nbrought by GCL is severely unevenly distributed: the improvement mainly comes\nfrom subgraphs with less annotated information, which is fundamentally\ndifferent from contrastive learning in other fields. However, existing GCL\nmethods generally ignore this uneven distribution of annotated information and\napply GCL evenly to the whole graph. To remedy this issue and further improve\nGCL in SSNC, we propose the Topology InFormation gain-Aware Graph Contrastive\nLearning (TIFA-GCL) framework that considers the annotated information\ndistribution across graph in GCL. Extensive experiments on six benchmark graph\ndatasets, including the enormous OGB-Products graph, show that TIFA-GCL can\nbring a larger improvement than existing GCL methods in both transductive and\ninductive settings. Further experiments demonstrate the generalizability and\ninterpretability of TIFA-GCL.",
          "link": "http://arxiv.org/abs/2012.07437",
          "publishedOn": "2022-04-28T01:16:09.365Z",
          "wordCount": 651,
          "title": "Rethinking the Promotion Brought by Contrastive Learning to Semi-Supervised Node Classification. (arXiv:2012.07437v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giannarakis_G/0/1/0/all/0/1\">Georgios Giannarakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitokonstantinou_V/0/1/0/all/0/1\">Vasileios Sitokonstantinou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorilla_R/0/1/0/all/0/1\">Roxanne Suzette Lorilla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kontoes_C/0/1/0/all/0/1\">Charalampos Kontoes</a>",
          "description": "Understanding the suitability of agricultural land for applying specific\nmanagement practices is of great importance for sustainable and resilient\nagriculture against climate change. Recent developments in the field of causal\nmachine learning enable the estimation of intervention impacts on an outcome of\ninterest, for samples described by a set of observed characteristics. We\nintroduce an extensible data-driven framework that leverages earth observations\nand frames agricultural land suitability as a geospatial impact assessment\nproblem, where the estimated effects of agricultural practices on\nagroecosystems serve as a land suitability score and guide decision making. We\nformulate this as a causal machine learning task and discuss how this approach\ncan be used for agricultural planning in a changing climate. Specifically, we\nextract the agricultural management practices of \"crop rotation\" and \"landscape\ncrop diversity\" from crop type maps, account for climate and land use data, and\nuse double machine learning to estimate their heterogeneous effect on Net\nPrimary Productivity (NPP), within the Flanders region of Belgium from 2010 to\n2020. We find that the effect of crop rotation was insignificant, while\nlandscape crop diversity had a small negative effect on NPP. Finally, we\nobserve considerable effect heterogeneity in space for both practices and\nanalyze it.",
          "link": "http://arxiv.org/abs/2204.12956",
          "publishedOn": "2022-04-28T01:16:09.329Z",
          "wordCount": 661,
          "title": "Towards assessing agricultural land suitability with causal machine learning. (arXiv:2204.12956v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.02508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chung-Yi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kostina_V/0/1/0/all/0/1\">Victoria Kostina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassibi_B/0/1/0/all/0/1\">Babak Hassibi</a>",
          "description": "Consider the following distributed optimization scenario. A worker has access\nto training data that it uses to compute the gradients while a server decides\nwhen to stop iterative computation based on its target accuracy or delay\nconstraints. The server receives all its information about the problem instance\nfrom the worker via a rate-limited noiseless communication channel. We\nintroduce the principle we call Differential Quantization (DQ) that prescribes\ncompensating the past quantization errors to direct the descent trajectory of a\nquantized algorithm towards that of its unquantized counterpart. Assuming that\nthe objective function is smooth and strongly convex, we prove that\nDifferentially Quantized Gradient Descent (DQ-GD) attains a linear contraction\nfactor of $\\max\\{\\sigma_{\\mathrm{GD}}, \\rho_n 2^{-R}\\}$, where\n$\\sigma_{\\mathrm{GD}}$ is the contraction factor of unquantized gradient\ndescent (GD), $\\rho_n \\geq 1$ is the covering efficiency of the quantizer, and\n$R$ is the bitrate per problem dimension $n$. Thus at any $R\\geq\\log_2 \\rho_n\n/\\sigma_{\\mathrm{GD}}$ bits, the contraction factor of DQ-GD is the same as\nthat of unquantized GD, i.e., there is no loss due to quantization. We show\nthat no algorithm within a certain class can converge faster than\n$\\max\\{\\sigma_{\\mathrm{GD}}, 2^{-R}\\}$. Since quantizers exist with $\\rho_n \\to\n1$ as $n \\to \\infty$ (Rogers, 1963), this means that DQ-GD is asymptotically\noptimal. The principle of differential quantization continues to apply to\ngradient methods with momentum such as Nesterov's accelerated gradient descent,\nand Polyak's heavy ball method. For these algorithms as well, if the rate is\nabove a certain threshold, there is no loss in contraction factor obtained by\nthe differentially quantized algorithm compared to its unquantized counterpart.\nExperimental results on least-squares problems validate our theoretical\nanalysis.",
          "link": "http://arxiv.org/abs/2002.02508",
          "publishedOn": "2022-04-28T01:16:09.287Z",
          "wordCount": 759,
          "title": "Differentially Quantized Gradient Methods. (arXiv:2002.02508v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1810.08498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagy_M/0/1/0/all/0/1\">Marcell Nagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molontay_R/0/1/0/all/0/1\">Roland Molontay</a>",
          "description": "Data-driven analysis of complex networks has been in the focus of research\nfor decades. An important area of research is to study how well real networks\ncan be described with a small selection of metrics, furthermore how well\nnetwork models can capture the relations between graph metrics observed in real\nnetworks. In this paper, we apply machine learning techniques to investigate\nthe aforementioned problems. We study 500 real-world networks along with 2,000\nsynthetic networks generated by four frequently used network models with\npreviously calibrated parameters to make the generated graphs as similar to the\nreal networks as possible. This paper unifies several branches of data-driven\ncomplex network analysis, such as the study of graph metrics and their\npair-wise relationships, network similarity estimation, model calibration, and\ngraph classification. We find that the correlation profiles of the structural\nmeasures significantly differ across network domains and the domain can be\nefficiently determined using a small selection of graph metrics. The structural\nproperties of the network models with fixed parameters are robust enough to\nperform parameter calibration. The goodness-of-fit of the network models highly\ndepends on the network domain. By solving classification problems, we find that\nthe models lack the capability of generating a graph with a high clustering\ncoefficient and relatively large diameter simultaneously. On the other hand,\nmodels are able to capture exactly the degree-distribution-related metrics.",
          "link": "http://arxiv.org/abs/1810.08498",
          "publishedOn": "2022-04-28T01:16:09.254Z",
          "wordCount": 735,
          "title": "Network Classification Based Structural Analysis of Real Networks and their Model-Generated Counterparts. (arXiv:1810.08498v4 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12929",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Hu_S/0/1/0/all/0/1\">Sihao Hu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhen Zhang</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Lu_S/0/1/0/all/0/1\">Shengliang Lu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+He_B/0/1/0/all/0/1\">Bingsheng He</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Li_Z/0/1/0/all/0/1\">Zhao Li</a>",
          "description": "As the pump-and-dump schemes (P&Ds) proliferate in the cryptocurrency market,\nit becomes imperative to detect such fraudulent activities in advance, to\ninform potentially susceptible investors before they become victims. In this\npaper, we focus on the target coin prediction task, i.e., to predict the pump\nprobability of all coins listed in the target exchange before a pump. We\nconduct a comprehensive study of the latest P&Ds, investigate 709 events\norganized in Telegram channels from Jan. 2019 to Jan. 2022, and unearth some\nabnormal yet interesting patterns of P&Ds. Empirical analysis demonstrates that\npumped coins exhibit intra-channel homogeneity and inter-channel heterogeneity,\nwhich inspires us to develop a novel sequence-based neural network named SNN.\nSpecifically, SNN encodes each channel's pump history as a sequence\nrepresentation via a positional attention mechanism, which filters useful\ninformation and alleviates the noise introduced when the sequence length is\nlong. We also identify and address the coin-side cold-start problem in a\npractical setting. Extensive experiments show a lift of 1.6% AUC and 41.0% Hit\nRatio@3 brought by our method, making it well-suited for real-world\napplication. As a side contribution, we release the source code of our entire\ndata science pipeline on GitHub, along with the dataset tailored for studying\nthe latest P&Ds.",
          "link": "http://arxiv.org/abs/2204.12929",
          "publishedOn": "2022-04-28T01:16:09.247Z",
          "wordCount": 641,
          "title": "Sequence-Based Target Coin Prediction for Cryptocurrency Pump-and-Dump. (arXiv:2204.12929v1 [q-fin.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1903.03104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hotaling_A/0/1/0/all/0/1\">Abigail Hotaling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagrow_J/0/1/0/all/0/1\">James Bagrow</a>",
          "description": "Allocation strategies improve the efficiency of crowdsourcing by decreasing\nthe work needed to complete individual tasks accurately. However, these\nalgorithms introduce bias by preferentially allocating workers onto easy tasks,\nleading to sets of completed tasks that are no longer representative of all\ntasks. This bias challenges inference of problem-wide properties such as\ntypical task difficulty or crowd properties such as worker completion times,\nimportant information that goes beyond the crowd responses themselves. Here we\nstudy inference about problem properties when using an allocation algorithm to\nimprove crowd efficiency. We introduce Decision-Explicit Probability Sampling\n(DEPS), a novel method to perform inference of problem properties while\naccounting for the potential bias introduced by an allocation strategy.\nExperiments on real and synthetic crowdsourcing data show that DEPS outperforms\nbaseline inference methods while still leveraging the efficiency gains of the\nallocation method. The ability to perform accurate inference of general\nproperties when using non-representative data allows crowdsourcers to extract\nmore knowledge out of a given crowdsourced dataset.",
          "link": "http://arxiv.org/abs/1903.03104",
          "publishedOn": "2022-04-28T01:16:09.231Z",
          "wordCount": 661,
          "title": "Accurate inference of crowdsourcing properties when using efficient allocation strategies. (arXiv:1903.03104v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaveti_P/0/1/0/all/0/1\">Pushyami Kaveti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_H/0/1/0/all/0/1\">Hanumant Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Powell_A/0/1/0/all/0/1\">Abigail Powell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fruh_E/0/1/0/all/0/1\">Erica Fruh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clarke_M/0/1/0/all/0/1\">M. Elizabeth Clarke</a>",
          "description": "In this paper, we present a methodology for fisheries-related data that\nallows us to converge on a labeled image dataset by iterating over the dataset\nwith multiple training and production loops that can exploit crowdsourcing\ninterfaces. We present our algorithm and its results on two separate sets of\nimage data collected using the Seabed autonomous underwater vehicle. The first\ndataset comprises of 2,026 completely unlabeled images, while the second\nconsists of 21,968 images that were point annotated by experts. Our results\nindicate that training with a small subset and iterating on that to build a\nlarger set of labeled data allows us to converge to a fully annotated dataset\nwith a small number of iterations. Even in the case of a dataset labeled by\nexperts, a single iteration of the methodology improves the labels by\ndiscovering additional complicated examples of labels associated with fish that\noverlap, are very small, or obscured by the contrast limitations associated\nwith underwater imagery.",
          "link": "http://arxiv.org/abs/2204.12934",
          "publishedOn": "2022-04-28T01:16:09.225Z",
          "wordCount": 598,
          "title": "An Iterative Labeling Method for Annotating Fisheries Imagery. (arXiv:2204.12934v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13065",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_G/0/1/0/all/0/1\">Guangyang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sufang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Runmin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chunming Wu</a>",
          "description": "Crowdsourcing is an online outsourcing mode which can solve the current\nmachine learning algorithm's urge need for massive labeled data. Requester\nposts tasks on crowdsourcing platforms, which employ online workers over the\nInternet to complete tasks, then aggregate and return results to requester. How\nto model the interaction between different types of workers and tasks is a hot\nspot. In this paper, we try to model workers as four types based on their\nability: expert, normal worker, sloppy worker and spammer, and divide tasks\ninto hard, medium and easy task according to their difficulty. We believe that\neven experts struggle with difficult tasks while sloppy workers can get easy\ntasks right, and spammers always give out wrong answers deliberately. So, good\nexamination tasks should have moderate degree of difficulty and\ndiscriminability to score workers more objectively. Thus, we first score\nworkers' ability mainly on the medium difficult tasks, then reducing the weight\nof answers from sloppy workers and modifying the answers from spammers when\ninferring the tasks' ground truth. A probability graph model is adopted to\nsimulate the task execution process, and an iterative method is adopted to\ncalculate and update the ground truth, the ability of workers and the\ndifficulty of the task successively. We verify the rightness and effectiveness\nof our algorithm both in simulated and real crowdsourcing scenes.",
          "link": "http://arxiv.org/abs/2204.13065",
          "publishedOn": "2022-04-28T01:16:09.219Z",
          "wordCount": 655,
          "title": "Treating Crowdsourcing as Examination: How to Score Tasks and Online Workers?. (arXiv:2204.13065v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12932",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Jain_S/0/1/0/all/0/1\">Shrey Jain</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Bruckmann_C/0/1/0/all/0/1\">Camille Bruckmann</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+McDougall_C/0/1/0/all/0/1\">Chase McDougall</a>",
          "description": "In this paper we investigate the correlation between NFT valuations and\nvarious features from three primary categories: public market data, NFT\nmetadata, and social trends data.",
          "link": "http://arxiv.org/abs/2204.12932",
          "publishedOn": "2022-04-28T01:16:09.214Z",
          "wordCount": 465,
          "title": "NFT Appraisal Prediction: Utilizing Search Trends, Public Market Data, Linear Regression and Recurrent Neural Networks. (arXiv:2204.12932v1 [q-fin.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hansen_Estruch_P/0/1/0/all/0/1\">Philippe Hansen-Estruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Ashvin Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1\">Patrick Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Building generalizable goal-conditioned agents from rich observations is a\nkey to reinforcement learning (RL) solving real world problems. Traditionally\nin goal-conditioned RL, an agent is provided with the exact goal they intend to\nreach. However, it is often not realistic to know the configuration of the goal\nbefore performing a task. A more scalable framework would allow us to provide\nthe agent with an example of an analogous task, and have the agent then infer\nwhat the goal should be for its current state. We propose a new form of state\nabstraction called goal-conditioned bisimulation that captures functional\nequivariance, allowing for the reuse of skills to achieve new goals. We learn\nthis representation using a metric form of this abstraction, and show its\nability to generalize to new goals in simulation manipulation tasks. Further,\nwe prove that this learned representation is sufficient not only for goal\nconditioned tasks, but is amenable to any downstream task described by a\nstate-only reward function. Videos can be found at\nhttps://sites.google.com/view/gc-bisimulation.",
          "link": "http://arxiv.org/abs/2204.13060",
          "publishedOn": "2022-04-28T01:16:09.208Z",
          "wordCount": 608,
          "title": "Bisimulation Makes Analogies in Goal-Conditioned Reinforcement Learning. (arXiv:2204.13060v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_C/0/1/0/all/0/1\">Chirag Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "We study the problem of making calibrated probabilistic forecasts for a\nbinary sequence generated by an adversarial nature. Following the seminal paper\nof Foster and Vohra (1998), nature is often modeled as an adaptive adversary\nwho sees all activity of the forecaster except the randomization that the\nforecaster may deploy. A number of papers have proposed randomized forecasting\nstrategies that achieve an $\\epsilon$-calibration error rate of\n$O(1/\\sqrt{T})$, which we prove is tight in general. On the other hand, it is\nwell known that it is not possible to be calibrated without randomization, or\nif nature also sees the forecaster's randomization; in both cases the\ncalibration error could be $\\Omega(1)$. Inspired by the equally seminal works\non the \"power of two choices\" and imprecise probability theory, we study a\nsmall variant of the standard online calibration problem. The adversary gives\nthe forecaster the option of making two nearby probabilistic forecasts, or\nequivalently an interval forecast of small width, and the endpoint closest to\nthe revealed outcome is used to judge calibration. This power of two choices,\nor imprecise forecast, accords the forecaster with significant power -- we show\nthat a faster $\\epsilon$-calibration rate of $O(1/T)$ can be achieved even\nwithout deploying any randomization.",
          "link": "http://arxiv.org/abs/2204.13087",
          "publishedOn": "2022-04-28T01:16:09.190Z",
          "wordCount": 656,
          "title": "Faster online calibration without randomization: interval forecasts and the power of two choices. (arXiv:2204.13087v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Orhan_A/0/1/0/all/0/1\">A. Emin Orhan</a>",
          "description": "Humans have a remarkably large capacity to store detailed visual information\nin long-term memory even after a single exposure, as demonstrated by classic\nexperiments in psychology. For example, Standing (1973) showed that humans\ncould recognize with high accuracy thousands of pictures that they had seen\nonly once a few days prior to a recognition test. In deep learning, the primary\nmode of incorporating new information into a model is through gradient descent\nin the model's parameter space. This paper asks whether deep learning via\ngradient descent can match the efficiency of human visual long-term memory to\nincorporate new information in a rigorous, head-to-head, quantitative\ncomparison. We answer this in the negative: even in the best case, models\nlearning via gradient descent appear to require approximately 10 exposures to\nthe same visual materials in order to reach a recognition memory performance\nhumans achieve after only a single exposure. Prior knowledge induced via\npretraining and bigger model sizes improve performance, but these improvements\nare not very visible after a single exposure (it takes a few exposures for the\nimprovements to become apparent), suggesting that simply scaling up the\npretraining data size or model size might not be enough for the model to reach\nhuman-level memory efficiency.",
          "link": "http://arxiv.org/abs/2204.13061",
          "publishedOn": "2022-04-28T01:16:09.183Z",
          "wordCount": 653,
          "title": "Can deep learning match the efficiency of human visual long-term memory to store object details?. (arXiv:2204.13061v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Casanueva_I/0/1/0/all/0/1\">I&#xf1;igo Casanueva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spithourakis_G/0/1/0/all/0/1\">Georgios Spithourakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budzianowski_P/0/1/0/all/0/1\">Pawe&#x142; Budzianowski</a>",
          "description": "We present NLU++, a novel dataset for natural language understanding (NLU) in\ntask-oriented dialogue (ToD) systems, with the aim to provide a much more\nchallenging evaluation environment for dialogue NLU models, up to date with the\ncurrent application and industry requirements. NLU++ is divided into two\ndomains (BANKING and HOTELS) and brings several crucial improvements over\ncurrent commonly used NLU datasets. \\textbf{1)} NLU++ provides fine-grained\ndomain ontologies with a large set of challenging \\textit{multi-intent}\nsentences, introducing and validating the idea of \\textit{intent modules} that\ncan be combined into complex intents that convey complex user goals, combined\nwith finer-grained and thus more challenging slot sets. \\textbf{2)} The\nontology is divided into \\textit{domain-specific} and \\textit{generic} (i.e.,\ndomain-universal) intent modules that overlap across domains, promoting\ncross-domain reusability of annotated examples. \\textbf{3)} The dataset design\nhas been inspired by the problems observed in industrial ToD systems, and\n\\textbf{4)} it has been collected, filtered and carefully annotated by dialogue\nNLU experts, yielding high-quality annotated data. Finally, we benchmark a\nseries of current state-of-the-art NLU models on NLU++; the results demonstrate\nthe challenging nature of the dataset, especially in low-data regimes, the\nvalidity of `intent modularisation', and call for further research on ToD NLU.",
          "link": "http://arxiv.org/abs/2204.13021",
          "publishedOn": "2022-04-28T01:16:09.176Z",
          "wordCount": 648,
          "title": "NLU++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue. (arXiv:2204.13021v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhaoyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Arpit Jain</a>",
          "description": "Dropout as regularization has been used extensively to prevent overfitting\nfor training neural networks. During training, units and their connections are\nrandomly dropped, which could be considered as sampling many different\nsubmodels from the original model. At test time, weight scaling and Monte Carlo\napproximation are two widely applied approaches to approximate the outputs.\nBoth approaches work well practically when all submodels are low-bias complex\nlearners. However, in this work, we demonstrate scenarios where some submodels\nbehave closer to high-bias models and a non-uniform weight scaling is a better\napproximation for inference.",
          "link": "http://arxiv.org/abs/2204.13047",
          "publishedOn": "2022-04-28T01:16:09.171Z",
          "wordCount": 513,
          "title": "Dropout Inference with Non-Uniform Weight Scaling. (arXiv:2204.13047v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biza_O/0/1/0/all/0/1\">Ondrej Biza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Platt_R/0/1/0/all/0/1\">Robert Platt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meent_J/0/1/0/all/0/1\">Jan-Willem van de Meent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1\">Lawson L. S. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kipf_T/0/1/0/all/0/1\">Thomas Kipf</a>",
          "description": "We study the problem of binding actions to objects in object-factored world\nmodels using action-attention mechanisms. We propose two attention mechanisms\nfor binding actions to objects, soft attention and hard attention, which we\nevaluate in the context of structured world models for five environments. Our\nexperiments show that hard attention helps contrastively-trained structured\nworld models to learn to separate individual objects in an object-based\ngrid-world environment. Further, we show that soft attention increases\nperformance of factored world models trained on a robotic manipulation task.\nThe learned action attention weights can be used to interpret the factored\nworld model as the attention focuses on the manipulated object in the\nenvironment.",
          "link": "http://arxiv.org/abs/2204.13022",
          "publishedOn": "2022-04-28T01:16:09.155Z",
          "wordCount": 547,
          "title": "Binding Actions to Objects in World Models. (arXiv:2204.13022v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barbano_C/0/1/0/all/0/1\">Carlo Alberto Barbano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tartaglione_E/0/1/0/all/0/1\">Enzo Tartaglione</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grangetto_M/0/1/0/all/0/1\">Marco Grangetto</a>",
          "description": "Deep neural networks are known for their inability to learn robust\nrepresentations when biases exist in the dataset. This results in a poor\ngeneralization to unbiased datasets, as the predictions strongly rely on\nperipheral and confounding factors, which are erroneously learned by the\nnetwork. Many existing works deal with this issue by either employing an\nexplicit supervision on the bias attributes, or assuming prior knowledge about\nthe bias. In this work we study this problem in a more difficult scenario, in\nwhich no explicit annotation about the bias is available, and without any prior\nknowledge about its nature. We propose a fully unsupervised debiasing\nframework, consisting of three steps: first, we exploit the natural preference\nfor learning malignant biases, obtaining a bias-capturing model; then, we\nperform a pseudo-labelling step to obtain bias labels; finally we employ\nstate-of-the-art supervised debiasing techniques to obtain an unbiased model.\nWe also propose a theoretical framework to assess the biasness of a model, and\nprovide a detailed analysis on how biases affect the training of neural\nnetworks. We perform experiments on synthetic and real-world datasets, showing\nthat our method achieves state-of-the-art performance in a variety of settings,\nsometimes even higher than fully supervised debiasing approaches.",
          "link": "http://arxiv.org/abs/2204.12941",
          "publishedOn": "2022-04-28T01:16:09.148Z",
          "wordCount": 633,
          "title": "Unsupervised Learning of Unbiased Visual Representations. (arXiv:2204.12941v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dung Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuoc Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1\">Svetha Venkatesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Truyen Tran</a>",
          "description": "Multi-agent reinforcement learning holds the key for solving complex tasks\nthat demand the coordination of learning agents. However, strong coordination\noften leads to expensive exploration over the exponentially large state-action\nspace. A powerful approach is to decompose team works into roles, which are\nideally assigned to agents with the relevant skills. Training agents to\nadaptively choose and play emerging roles in a team thus allows the team to\nscale to complex tasks and quickly adapt to changing environments. These\npromises, however, have not been fully realised by current role-based\nmulti-agent reinforcement learning methods as they assume either a pre-defined\nrole structure or a fixed team size. We propose a framework to learn role\nassignment and transfer across team sizes. In particular, we train a role\nassignment network for small teams by demonstration and transfer the network to\nlarger teams, which continue to learn through interaction with the environment.\nWe demonstrate that re-using the role-based credit assignment structure can\nfoster the learning process of larger reinforcement learning teams to achieve\ntasks requiring different roles. Our proposal outperforms competing techniques\nin enriched role-enforcing Prey-Predator games and in new scenarios in the\nStarCraft II Micro-Management benchmark.",
          "link": "http://arxiv.org/abs/2204.12937",
          "publishedOn": "2022-04-28T01:16:09.142Z",
          "wordCount": 628,
          "title": "Learning to Transfer Role Assignment Across Team Sizes. (arXiv:2204.12937v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12972",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Schon_O/0/1/0/all/0/1\">Oliver Sch&#xf6;n</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gotte_R/0/1/0/all/0/1\">Ricarda-Samantha G&#xf6;tte</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Timmermann_J/0/1/0/all/0/1\">Julia Timmermann</a>",
          "description": "While trade-offs between modeling effort and model accuracy remain a major\nconcern with system identification, resorting to data-driven methods often\nleads to a complete disregard for physical plausibility. To address this issue,\nwe propose a physics-guided hybrid approach for modeling non-autonomous systems\nunder control. Starting from a traditional physics-based model, this is\nextended by a recurrent neural network and trained using a sophisticated\nmulti-objective strategy yielding physically plausible models. While purely\ndata-driven methods fail to produce satisfying results, experiments conducted\non real data reveal substantial accuracy improvements by our approach compared\nto a physics-based model.",
          "link": "http://arxiv.org/abs/2204.12972",
          "publishedOn": "2022-04-28T01:16:09.137Z",
          "wordCount": 546,
          "title": "Multi-Objective Physics-Guided Recurrent Neural Networks for Identifying Non-Autonomous Dynamical Systems. (arXiv:2204.12972v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12948",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_W/0/1/0/all/0/1\">Weidong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benosman_M/0/1/0/all/0/1\">Mouhacine Benosman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1\">Rui Ma</a>",
          "description": "The design automation of analog circuits is a longstanding challenge. This\npaper presents a reinforcement learning method enhanced by graph learning to\nautomate the analog circuit parameter optimization at the pre-layout stage,\ni.e., finding device parameters to fulfill desired circuit specifications.\nUnlike all prior methods, our approach is inspired by human experts who rely on\ndomain knowledge of analog circuit design (e.g., circuit topology and couplings\nbetween circuit specifications) to tackle the problem. By originally\nincorporating such key domain knowledge into policy training with a multimodal\nnetwork, the method best learns the complex relations between circuit\nparameters and design targets, enabling optimal decisions in the optimization\nprocess. Experimental results on exemplary circuits show it achieves\nhuman-level design accuracy (99%) 1.5X efficiency of existing best-performing\nmethods. Our method also shows better generalization ability to unseen\nspecifications and optimality in circuit performance optimization. Moreover, it\napplies to design radio-frequency circuits on emerging semiconductor\ntechnologies, breaking the limitations of prior learning methods in designing\nconventional analog circuits.",
          "link": "http://arxiv.org/abs/2204.12948",
          "publishedOn": "2022-04-28T01:16:09.100Z",
          "wordCount": 619,
          "title": "Domain Knowledge-Infused Deep Learning for Automated Analog/Radio-Frequency Circuit Parameter Optimization. (arXiv:2204.12948v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rot_M/0/1/0/all/0/1\">Miha Rot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashkovska_A/0/1/0/all/0/1\">Aleksandra Rashkovska</a>",
          "description": "Meshless methods are an active and modern branch of numerical analysis with\nmany intriguing benefits. One of the main open research questions related to\nlocal meshless methods is how to select the best possible stencil - a\ncollection of neighbouring nodes - to base the calculation on. In this paper,\nwe describe the procedure for generating a labelled stencil dataset and use a\nvariation of pointNet - a deep learning network based on point clouds - to\ncreate a classifier for the quality of the stencil. We exploit features of\npointNet to implement a model that can be used to classify differently sized\nstencils and compare it against models dedicated to a single stencil size. The\nmodel is particularly good at detecting the best and the worst stencils with a\nrespectable area under the curve (AUC) metric of around 0.90. There is much\npotential for further improvement and direct application in the meshless\ndomain.",
          "link": "http://arxiv.org/abs/2204.12940",
          "publishedOn": "2022-04-28T01:16:09.092Z",
          "wordCount": 581,
          "title": "Meshless method stencil evaluation with machine learning. (arXiv:2204.12940v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xuesong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Aoying Zhou</a>",
          "description": "Code summarization with deep learning has been widely studied in recent\nyears. Current deep learning models for code summarization generally follow the\nprinciple in neural machine translation and adopt the encoder-decoder\nframework, where the encoder learns the semantic representations from source\ncode and the decoder transforms the learnt representations into human-readable\ntext that describes the functionality of code snippets. Despite they achieve\nthe new state-of-the-art performance, we notice that current models often\neither generate less fluent summaries, or fail to capture the core\nfunctionality, since they usually focus on a single type of code\nrepresentations. As such we propose GypSum, a new deep learning model that\nlearns hybrid representations using graph attention neural networks and a\npre-trained programming and natural language model. We introduce particular\nedges related to the control flow of a code snippet into the abstract syntax\ntree for graph construction, and design two encoders to learn from the graph\nand the token sequence of source code, respectively. We modify the\nencoder-decoder sublayer in the Transformer's decoder to fuse the\nrepresentations and propose a dual-copy mechanism to facilitate summary\ngeneration. Experimental results demonstrate the superior performance of GypSum\nover existing code summarization models.",
          "link": "http://arxiv.org/abs/2204.12916",
          "publishedOn": "2022-04-28T01:16:08.974Z",
          "wordCount": 648,
          "title": "GypSum: Learning Hybrid Representations for Code Summarization. (arXiv:2204.12916v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Noravesh_F/0/1/0/all/0/1\">Farshad Noravesh</a>",
          "description": "A new algorithm based on bayesian inference for learning local graph\nconductance based on Gaussian Process(GP) is given that uses advanced MCMC\nconvergence ideas to create a scalable and fast algorithm for convergence to\nstationary distribution which is provided to learn the bahavior of conductance\nwhen traversing the indirected weighted graph. First metric embedding is used\nto represent the vertices of the graph. Then, uniform induced conductance is\ncalculated for training points. Finally, in the learning step, a gaussian\nprocess is used to approximate the uniform induced conductance. MCMC is used to\nmeasure uncertainty of estimated hyper-parameters.",
          "link": "http://arxiv.org/abs/2204.12927",
          "publishedOn": "2022-04-28T01:16:08.945Z",
          "wordCount": 514,
          "title": "A Bayesian Approach To Graph Partitioning. (arXiv:2204.12927v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baggenstoss_P/0/1/0/all/0/1\">Paul M Baggenstoss</a>",
          "description": "The projected belief network (PBN) is a layered generative network (LGN) with\ntractable likelihood function, and is based on a feed-forward neural network\n(FFNN). There are two versions of the PBN: stochastic and deterministic\n(D-PBN), and each has theoretical advantages over other LGNs. However,\nimplementation of the PBN requires an iterative algorithm that includes the\ninversion of a symmetric matrix of size M X M in each layer, where M is the\nlayer output dimension. This, and the fact that the network must be always\ndimension-reducing in each layer, can limit the types of problems where the PBN\ncan be applied. In this paper, we describe techniques to avoid or mitigate\nthese restrictions and use the PBN effectively at high dimension. We apply the\ndiscriminatively aligned PBN (PBN-DA) to classifying and auto-encoding\nhigh-dimensional spectrograms of acoustic events. We also present the\ndiscriminatively aligned D-PBN for the first time.",
          "link": "http://arxiv.org/abs/2204.12922",
          "publishedOn": "2022-04-28T01:16:08.934Z",
          "wordCount": 574,
          "title": "Using the Projected Belief Network at High Dimensions. (arXiv:2204.12922v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.05183",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Cassella_G/0/1/0/all/0/1\">G. Cassella</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sutterud_H/0/1/0/all/0/1\">H. Sutterud</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Azadi_S/0/1/0/all/0/1\">S. Azadi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Drummond_N/0/1/0/all/0/1\">N. D. Drummond</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pfau_D/0/1/0/all/0/1\">D. Pfau</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Spencer_J/0/1/0/all/0/1\">J. S. Spencer</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Foulkes_W/0/1/0/all/0/1\">W. M. C. Foulkes</a>",
          "description": "Deep neural networks have been extremely successful as highly accurate wave\nfunction ans\\\"atze for variational Monte Carlo calculations of molecular ground\nstates. We present an extension of one such ansatz, FermiNet, to calculations\nof the ground states of periodic Hamiltonians, and study the homogeneous\nelectron gas. FermiNet calculations of the ground-state energies of small\nelectron gas systems are in excellent agreement with previous initiator full\nconfiguration interaction quantum Monte Carlo and diffusion Monte Carlo\ncalculations. We investigate the spin-polarized homogeneous electron gas and\ndemonstrate that the same neural network architecture is capable of accurately\nrepresenting both the delocalized Fermi liquid state and the localized Wigner\ncrystal state. The network is given no \\emph{a priori} knowledge that a phase\ntransition exists, but converges on the translationally invariant ground state\nat high density and spontaneously breaks the symmetry to produce the\ncrystalline ground state at low density.",
          "link": "http://arxiv.org/abs/2202.05183",
          "publishedOn": "2022-04-28T01:16:08.757Z",
          "wordCount": 624,
          "title": "Discovering Quantum Phase Transitions with Fermionic Neural Networks. (arXiv:2202.05183v2 [physics.comp-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.05762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_G/0/1/0/all/0/1\">Guangyuan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1\">Dehong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Libin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Fang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Duanxiao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_W/0/1/0/all/0/1\">Wei Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shirui Pan</a>",
          "description": "Client selection strategies are widely adopted to handle the\ncommunication-efficient problem in recent studies of Federated Learning (FL).\nHowever, due to the large variance of the selected subset's update, prior\nselection approaches with a limited sampling ratio cannot perform well on\nconvergence and accuracy in heterogeneous FL. To address this problem, in this\npaper, we propose a novel stratified client selection scheme to reduce the\nvariance for the pursuit of better convergence and higher accuracy.\nSpecifically, to mitigate the impact of heterogeneity, we develop\nstratification based on clients' local data distribution to derive approximate\nhomogeneous strata for better selection in each stratum. Concentrating on a\nlimited sampling ratio scenario, we next present an optimized sample size\nallocation scheme by considering the diversity of stratum's variability, with\nthe promise of further variance reduction. Theoretically, we elaborate the\nexplicit relation among different selection schemes with regard to variance,\nunder heterogeneous settings, we demonstrate the effectiveness of our selection\nscheme. Experimental results confirm that our approach not only allows for\nbetter performance relative to state-of-the-art methods but also is compatible\nwith prevalent FL algorithms.",
          "link": "http://arxiv.org/abs/2201.05762",
          "publishedOn": "2022-04-28T01:16:08.742Z",
          "wordCount": 664,
          "title": "Variance-Reduced Heterogeneous Federated Learning via Stratified Client Selection. (arXiv:2201.05762v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.03193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Makarychev_K/0/1/0/all/0/1\">Konstantin Makarychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_L/0/1/0/all/0/1\">Liren Shan</a>",
          "description": "We provide a new bi-criteria $\\tilde{O}(\\log^2 k)$ competitive algorithm for\nexplainable $k$-means clustering. Explainable $k$-means was recently introduced\nby Dasgupta, Frost, Moshkovitz, and Rashtchian (ICML 2020). It is described by\nan easy to interpret and understand (threshold) decision tree or diagram. The\ncost of the explainable $k$-means clustering equals to the sum of costs of its\nclusters; and the cost of each cluster equals the sum of squared distances from\nthe points in the cluster to the center of that cluster. The best non\nbi-criteria algorithm for explainable clustering $\\tilde{O}(k)$ competitive,\nand this bound is tight.\n\nOur randomized bi-criteria algorithm constructs a threshold decision tree\nthat partitions the data set into $(1+\\delta)k$ clusters (where $\\delta\\in\n(0,1)$ is a parameter of the algorithm). The cost of this clustering is at most\n$\\tilde{O}(1/ \\delta \\cdot \\log^2 k)$ times the cost of the optimal\nunconstrained $k$-means clustering. We show that this bound is almost optimal.",
          "link": "http://arxiv.org/abs/2111.03193",
          "publishedOn": "2022-04-28T01:16:08.737Z",
          "wordCount": 618,
          "title": "Explainable k-means. Don't be greedy, plant bigger trees!. (arXiv:2111.03193v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.14432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muravev_N/0/1/0/all/0/1\">Nikita Muravev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petiushko_A/0/1/0/all/0/1\">Aleksandr Petiushko</a>",
          "description": "Currently the most popular method of providing robustness certificates is\nrandomized smoothing where an input is smoothed via some probability\ndistribution. We propose a novel approach to randomized smoothing over\nmultiplicative parameters. Using this method we construct certifiably robust\nclassifiers with respect to a gamma correction perturbation and compare the\nresult with classifiers obtained via other smoothing distributions (Gaussian,\nLaplace, uniform). The experiments show that asymmetrical Rayleigh distribution\nallows to obtain better certificates for some values of perturbation\nparameters. To the best of our knowledge it is the first work concerning\ncertified robustness against the multiplicative gamma correction transformation\nand the first to study effects of asymmetrical distributions in randomized\nsmoothing.",
          "link": "http://arxiv.org/abs/2106.14432",
          "publishedOn": "2022-04-28T01:16:08.726Z",
          "wordCount": 563,
          "title": "Certified Robustness via Randomized Smoothing over Multiplicative Parameters. (arXiv:2106.14432v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.11180",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Zeng_Y/0/1/0/all/0/1\">Yibo Zeng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lam_H/0/1/0/all/0/1\">Henry Lam</a>",
          "description": "Established approaches to obtain generalization bounds in data-driven\noptimization and machine learning mostly build on solutions from empirical risk\nminimization (ERM), which depend crucially on the functional complexity of the\nhypothesis class. In this paper, we present an alternate route to obtain these\nbounds on the solution from distributionally robust optimization (DRO), a\nrecent data-driven optimization framework based on worst-case analysis and the\nnotion of ambiguity set to capture statistical uncertainty. In contrast to the\nhypothesis class complexity in ERM, our DRO bounds depend on the ambiguity set\ngeometry and its compatibility with the true loss function. Notably, when using\nmaximum mean discrepancy as a DRO distance metric, our analysis implies\ngeneralization bounds that depend solely on the true loss function. To the best\nof our knowledge, it is the first generalization bound in the literature that\nis entirely independent of any other candidates in the hypothesis class. We\nhope our findings can open the door for a better understanding of DRO,\nespecially its benefits on loss minimization and other machine learning\napplications.",
          "link": "http://arxiv.org/abs/2106.11180",
          "publishedOn": "2022-04-28T01:16:08.720Z",
          "wordCount": 636,
          "title": "Generalization Bounds with Minimal Dependency on Hypothesis Class via Distributionally Robust Optimization. (arXiv:2106.11180v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.12399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nayman_N/0/1/0/all/0/1\">Niv Nayman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aflalo_Y/0/1/0/all/0/1\">Yonathan Aflalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1\">Asaf Noy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1\">Rong Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zelnik_Manor_L/0/1/0/all/0/1\">Lihi Zelnik-Manor</a>",
          "description": "Practical use of neural networks often involves requirements on latency,\nenergy and memory among others. A popular approach to find networks under such\nrequirements is through constrained Neural Architecture Search (NAS). However,\nprevious methods use complicated predictors for the accuracy of the network.\nThose predictors are hard to interpret and sensitive to many hyperparameters to\nbe tuned, hence, the resulting accuracy of the generated models is often\nharmed. In this work we resolve this by introducing Bilinear Interpretable\nNeural Architecture Search (BINAS), that is based on an accurate and simple\nbilinear formulation of both an accuracy estimator and the expected resource\nrequirement, together with a scalable search method with theoretical\nguarantees. The simplicity of our proposed estimator together with the\nintuitive way it is constructed bring interpretability through many insights\nabout the contribution of different design choices. For example, we find that\nin the examined search space, adding depth and width is more effective at\ndeeper stages of the network and at the beginning of each resolution stage. Our\nexperiments show that BINAS generates comparable to or better architectures\nthan other state-of-the-art NAS methods within a reduced marginal search cost,\nwhile strictly satisfying the resource constraints.",
          "link": "http://arxiv.org/abs/2110.12399",
          "publishedOn": "2022-04-28T01:16:08.702Z",
          "wordCount": 708,
          "title": "BINAS: Bilinear Interpretable Neural Architecture Search. (arXiv:2110.12399v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.11793",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lian_H/0/1/0/all/0/1\">Heng Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atwood_J/0/1/0/all/0/1\">John Scovil Atwood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1\">Bojian Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yi He</a>",
          "description": "This paper investigates a new online learning problem with doubly-streaming\ndata, where the data streams are described by feature spaces that constantly\nevolve, with new features emerging and old features fading away. The challenges\nof this problem are two folds: 1) Data samples ceaselessly flowing in may carry\nshifted patterns over time, requiring learners to update hence adapt\non-the-fly. 2) Newly emerging features are described by very few samples,\nresulting in weak learners that tend to make error predictions. A plausible\nidea to overcome the challenges is to establish relationship between the\npre-and-post evolving feature spaces, so that an online learner can leverage\nthe knowledge learned from the old features to better the learning performance\non the new features. Unfortunately, this idea does not scale up to\nhigh-dimensional media streams with complex feature interplay, which suffers an\ntradeoff between onlineness (biasing shallow learners) and\nexpressiveness(requiring deep learners). Motivated by this, we propose a novel\nOLD^3S paradigm, where a shared latent subspace is discovered to summarize\ninformation from the old and new feature spaces, building intermediate feature\nmapping relationship. A key trait of OLD^3S is to treat the model capacity as a\nlearnable semantics, yields optimal model depth and parameters jointly, in\naccordance with the complexity and non-linearity of the input data streams in\nan online fashion. Both theoretical analyses and empirical studies substantiate\nthe viability and effectiveness of our proposal.",
          "link": "http://arxiv.org/abs/2204.11793",
          "publishedOn": "2022-04-28T01:16:08.689Z",
          "wordCount": 679,
          "title": "Online Deep Learning from Doubly-Streaming Data. (arXiv:2204.11793v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13048",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Li_A/0/1/0/all/0/1\">Alex J. Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sundar_V/0/1/0/all/0/1\">Vikram Sundar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Grigoryan_G/0/1/0/all/0/1\">Gevorg Grigoryan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Keating_A/0/1/0/all/0/1\">Amy E. Keating</a>",
          "description": "Computational protein design has the potential to deliver novel molecular\nstructures, binders, and catalysts for myriad applications. Recent neural\ngraph-based models that use backbone coordinate-derived features show\nexceptional performance on native sequence recovery tasks and are promising\nframeworks for design. A statistical framework for modeling protein sequence\nlandscapes using Tertiary Motifs (TERMs), compact units of recurring structure\nin proteins, has also demonstrated good performance on protein design tasks. In\nthis work, we investigate the use of TERM-derived data as features in neural\nprotein design frameworks. Our graph-based architecture, TERMinator,\nincorporates TERM-based and coordinate-based information and outputs a Potts\nmodel over sequence space. TERMinator outperforms state-of-the-art models on\nnative sequence recovery tasks, suggesting that utilizing TERM-based and\ncoordinate-based features together is beneficial for protein design.",
          "link": "http://arxiv.org/abs/2204.13048",
          "publishedOn": "2022-04-28T01:16:08.575Z",
          "wordCount": 567,
          "title": "TERMinator: A Neural Framework for Structure-Based Protein Design using Tertiary Repeating Motifs. (arXiv:2204.13048v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paleyes_A/0/1/0/all/0/1\">Andrei Paleyes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cabrera_C/0/1/0/all/0/1\">Christian Cabrera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrence_N/0/1/0/all/0/1\">Neil D. Lawrence</a>",
          "description": "As use of data driven technologies spreads, software engineers are more often\nfaced with the task of solving a business problem using data-driven methods\nsuch as machine learning (ML) algorithms. Deployment of ML within large\nsoftware systems brings new challenges that are not addressed by standard\nengineering practices and as a result businesses observe high rate of ML\ndeployment project failures. Data Oriented Architecture (DOA) is an emerging\napproach that can support data scientists and software developers when\naddressing such challenges. However, there is a lack of clarity about how DOA\nsystems should be implemented in practice. This paper proposes to consider\nFlow-Based Programming (FBP) as a paradigm for creating DOA applications. We\nempirically evaluate FBP in the context of ML deployment on four applications\nthat represent typical data science projects. We use Service Oriented\nArchitecture (SOA) as a baseline for comparison. Evaluation is done with\nrespect to different application domains, ML deployment stages, and code\nquality metrics. Results reveal that FBP is a suitable paradigm for data\ncollection and data science tasks, and is able to simplify data collection and\ndiscovery when compared with SOA. We discuss the advantages of FBP as well as\nthe gaps that need to be addressed to increase FBP adoption as a standard\ndesign paradigm for DOA.",
          "link": "http://arxiv.org/abs/2204.12781",
          "publishedOn": "2022-04-28T01:16:08.548Z",
          "wordCount": 681,
          "title": "An Empirical Evaluation of Flow Based Programming in the Machine Learning Deployment Context. (arXiv:2204.12781v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12950",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1\">Saeejith Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbasi_S/0/1/0/all/0/1\">Saad Abbasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alexander Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafiee_M/0/1/0/all/0/1\">Mohammad Javad Shafiee</a>",
          "description": "Neural Architecture Search (NAS) has enabled automatic discovery of more\nefficient neural network architectures, especially for mobile and embedded\nvision applications. Although recent research has proposed ways of quickly\nestimating latency on unseen hardware devices with just a few samples, little\nfocus has been given to the challenges of estimating latency on runtimes using\noptimized graphs, such as TensorRT and specifically for edge devices. In this\nwork, we propose MAPLE-Edge, an edge device-oriented extension of MAPLE, the\nstate-of-the-art latency predictor for general purpose hardware, where we train\na regression network on architecture-latency pairs in conjunction with a\nhardware-runtime descriptor to effectively estimate latency on a diverse pool\nof edge devices. Compared to MAPLE, MAPLE-Edge can describe the runtime and\ntarget device platform using a much smaller set of CPU performance counters\nthat are widely available on all Linux kernels, while still achieving up to\n+49.6% accuracy gains against previous state-of-the-art baseline methods on\noptimized edge device runtimes, using just 10 measurements from an unseen\ntarget device. We also demonstrate that unlike MAPLE which performs best when\ntrained on a pool of devices sharing a common runtime, MAPLE-Edge can\neffectively generalize across runtimes by applying a trick of normalizing\nperformance counters by the operator latency, in the measured hardware-runtime\ndescriptor. Lastly, we show that for runtimes exhibiting lower than desired\naccuracy, performance can be boosted by collecting additional samples from the\ntarget device, with an extra 90 samples translating to gains of nearly +40%.",
          "link": "http://arxiv.org/abs/2204.12950",
          "publishedOn": "2022-04-28T01:16:08.542Z",
          "wordCount": 681,
          "title": "MAPLE-Edge: A Runtime Latency Predictor for Edge Devices. (arXiv:2204.12950v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khiari_J/0/1/0/all/0/1\">Jihed Khiari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olaverri_Monreal_C/0/1/0/all/0/1\">Cristina Olaverri-Monreal</a>",
          "description": "The usability of vehicles is highly dependent on their energy consumption. In\nparticular, one of the main factors hindering the mass adoption of electric\n(EV), hybrid (HEV), and plug-in hybrid (PHEV) vehicles is range anxiety, which\noccurs when a driver is uncertain about the availability of energy for a given\ntrip. To tackle this problem, we propose a machine learning approach for\nmodeling the battery energy consumption. By reducing predictive uncertainty,\nthis method can help increase trust in the vehicle's performance and thus boost\nits usability. Most related work focuses on physical and/or chemical models of\nthe battery that affect the energy consumption. We propose a data-driven\napproach which relies on real-world datasets including battery related\nattributes. Our approach showed an improvement in terms of predictive\nuncertainty as well as in accuracy compared to traditional methods.",
          "link": "http://arxiv.org/abs/2204.12825",
          "publishedOn": "2022-04-28T01:16:08.517Z",
          "wordCount": 575,
          "title": "Uncertainty-Aware Prediction of Battery Energy Consumption for Hybrid Electric Vehicles. (arXiv:2204.12825v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1\">Fang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawei Song</a>",
          "description": "Neural text matching models have been used in a range of applications such as\nquestion answering and natural language inference, and have yielded a good\nperformance. However, these neural models are of a limited adaptability,\nresulting in a decline in performance when encountering test examples from a\ndifferent dataset or even a different task. The adaptability is particularly\nimportant in the few-shot setting: in many cases, there is only a limited\namount of labeled data available for a target dataset or task, while we may\nhave access to a richly labeled source dataset or task. However, adapting a\nmodel trained on the abundant source data to a few-shot target dataset or task\nis challenging. To tackle this challenge, we propose a Meta-Weight Regulator\n(MWR), which is a meta-learning approach that learns to assign weights to the\nsource examples based on their relevance to the target loss. Specifically, MWR\nfirst trains the model on the uniformly weighted source examples, and measures\nthe efficacy of the model on the target examples via a loss function. By\niteratively performing a (meta) gradient descent, high-order gradients are\npropagated to the source examples. These gradients are then used to update the\nweights of source examples, in a way that is relevant to the target\nperformance. As MWR is model-agnostic, it can be applied to any backbone neural\nmodel. Extensive experiments are conducted with various backbone text matching\nmodels, on four widely used datasets and two tasks. The results demonstrate\nthat our proposed approach significantly outperforms a number of existing\nadaptation methods and effectively improves the cross-dataset and cross-task\nadaptability of the neural text matching models in the few-shot setting.",
          "link": "http://arxiv.org/abs/2204.12668",
          "publishedOn": "2022-04-28T01:16:08.511Z",
          "wordCount": 729,
          "title": "Adaptable Text Matching via Meta-Weight Regulator. (arXiv:2204.12668v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Davies_T/0/1/0/all/0/1\">Thomas Davies</a>",
          "description": "Topological Data Analysis (TDA) gives practioners the ability to analyse the\nglobal structure of cybersecurity data. We use TDA for anomaly detection in\nhost-based logs collected with the open-source Logging Made Easy (LME) project.\nWe present an approach that builds a filtration of simplicial complexes\ndirectly from Windows logs, enabling analysis of their intrinsic structure\nusing topological tools. We compare the efficacy of persistent homology and the\nspectrum of graph and hypergraph Laplacians as feature vectors against a\nstandard log embedding that counts events, and find that topological and\nspectral embeddings of computer logs contain discriminative information for\nclassifying anomalous logs that is complementary to standard embeddings. We end\nby discussing the potential for our methods to be used as part of an\nexplainable framework for anomaly detection.",
          "link": "http://arxiv.org/abs/2204.12919",
          "publishedOn": "2022-04-28T01:16:08.505Z",
          "wordCount": 560,
          "title": "Topological Data Analysis for Anomaly Detection in Host-Based Logs. (arXiv:2204.12919v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13103",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_R/0/1/0/all/0/1\">Rishov Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abi_Karam_S/0/1/0/all/0/1\">Stefan Abi-Karam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuqi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sathidevi_L/0/1/0/all/0/1\">Lakshmi Sathidevi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_C/0/1/0/all/0/1\">Cong Hao</a>",
          "description": "Graph neural networks (GNNs) have recently exploded in popularity thanks to\ntheir broad applicability to graph-related problems such as quantum chemistry,\ndrug discovery, and high energy physics. However, meeting demand for novel GNN\nmodels and fast inference simultaneously is challenging because of the gap\nbetween developing efficient accelerators and the rapid creation of new GNN\nmodels. Prior art focuses on the acceleration of specific classes of GNNs, such\nas Graph Convolutional Network (GCN), but lacks the generality to support a\nwide range of existing or new GNN models. Meanwhile, most work rely on graph\npre-processing to exploit data locality, making them unsuitable for real-time\napplications. To address these limitations, in this work, we propose a generic\ndataflow architecture for GNN acceleration, named FlowGNN, which can flexibly\nsupport the majority of message-passing GNNs. The contributions are three-fold.\nFirst, we propose a novel and scalable dataflow architecture, which flexibly\nsupports a wide range of GNN models with message-passing mechanism. The\narchitecture features a configurable dataflow optimized for simultaneous\ncomputation of node embedding, edge embedding, and message passing, which is\ngenerally applicable to all models. We also propose a rich library of\nmodel-specific components. Second, we deliver ultra-fast real-time GNN\ninference without any graph pre-processing, making it agnostic to dynamically\nchanging graph structures. Third, we verify our architecture on the Xilinx\nAlveo U50 FPGA board and measure the on-board end-to-end performance. We\nachieve a speed-up of up to 51-254x against CPU (6226R) and 1.3-477x against\nGPU (A6000) (with batch sizes 1 through 1024); we also outperform the SOTA GNN\naccelerator I-GCN by 1.03x and 1.25x across two datasets. Our implementation\ncode and on-board measurement are publicly available on GitHub.",
          "link": "http://arxiv.org/abs/2204.13103",
          "publishedOn": "2022-04-28T01:16:08.500Z",
          "wordCount": 747,
          "title": "FlowGNN: A Dataflow Architecture for Universal Graph Neural Network Inference via Multi-Queue Streaming. (arXiv:2204.13103v1 [cs.DC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baggenstoss_P/0/1/0/all/0/1\">Paul M. Baggenstoss</a>",
          "description": "Activation functions (AF) are necessary components of neural networks that\nallow approximation of functions, but AFs in current use are usually simple\nmonotonically increasing functions. In this paper, we propose trainable\ncompound AF (TCA) composed of a sum of shifted and scaled simple AFs. TCAs\nincrease the effectiveness of networks with fewer parameters compared to added\nlayers. TCAs have a special interpretation in generative networks because they\neffectively estimate the marginal distributions of each dimension of the data\nusing a mixture distribution, reducing modality and making linear dimension\nreduction more effective. When used in restricted Boltzmann machines (RBMs),\nthey result in a novel type of RBM with mixture-based stochastic units.\nImproved performance is demonstrated in experiments using RBMs, deep belief\nnetworks (DBN), projected belief networks (PBN), and variational auto-encoders\n(VAE).",
          "link": "http://arxiv.org/abs/2204.12920",
          "publishedOn": "2022-04-28T01:16:08.494Z",
          "wordCount": 547,
          "title": "Trainable Compound Activation Functions for Machine Learning. (arXiv:2204.12920v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosenblatt_L/0/1/0/all/0/1\">Lucas Rosenblatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allen_J/0/1/0/all/0/1\">Joshua Allen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanovich_J/0/1/0/all/0/1\">Julia Stoyanovich</a>",
          "description": "Differentially private (DP) synthetic data generation is a practical method\nfor improving access to data as a means to encourage productive partnerships.\nOne issue inherent to DP is that the \"privacy budget\" is generally \"spent\"\nevenly across features in the data set. This leads to good statistical parity\nwith the real data, but can undervalue the conditional probabilities and\nmarginals that are critical for predictive quality of synthetic data. Further,\nloss of predictive quality may be non-uniform across the data set, with subsets\nthat correspond to minority groups potentially suffering a higher loss.\n\nIn this paper, we develop ensemble methods that distribute the privacy budget\n\"wisely\" to maximize predictive accuracy of models trained on DP data, and\n\"fairly\" to bound potential disparities in accuracy across groups and reduce\ninequality. Our methods are based on the insights that feature importance can\ninform how privacy budget is allocated, and, further, that per-group feature\nimportance and fairness-related performance objectives can be incorporated in\nthe allocation. These insights make our methods tunable to social contexts,\nallowing data owners to produce balanced synthetic data for predictive\nanalysis.",
          "link": "http://arxiv.org/abs/2204.12903",
          "publishedOn": "2022-04-28T01:16:08.479Z",
          "wordCount": 612,
          "title": "Spending Privacy Budget Fairly and Wisely. (arXiv:2204.12903v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Richens_J/0/1/0/all/0/1\">Jonathan G. Richens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beard_R/0/1/0/all/0/1\">Rory Beard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thompson_D/0/1/0/all/0/1\">Daniel H. Thompson</a>",
          "description": "To act safely and ethically in the real world, agents must be able to reason\nabout harm and avoid harmful actions. In this paper we develop the first\nstatistical definition of harm and a framework for factoring harm into\nalgorithmic decisions. We argue that harm is fundamentally a counterfactual\nquantity, and show that standard machine learning algorithms are guaranteed to\npursue harmful policies in certain environments. To resolve this, we derive a\nfamily of counterfactual objective functions that robustly mitigate for harm.\nWe demonstrate our approach with a statistical model for identifying optimal\ndrug doses. While identifying optimal doses using the causal treatment effect\nresults in harmful treatment decisions, our counterfactual algorithm identifies\ndoses that are far less harmful without sacrificing efficacy. Our results show\nthat counterfactual reasoning is a key ingredient for safe and ethical AI.",
          "link": "http://arxiv.org/abs/2204.12993",
          "publishedOn": "2022-04-28T01:16:08.473Z",
          "wordCount": 576,
          "title": "First do no harm: counterfactual objective functions for safe & ethical AI. (arXiv:2204.12993v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cascone_L/0/1/0/all/0/1\">Lucia Cascone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Distasi_R/0/1/0/all/0/1\">Riccardo Distasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nappi_M/0/1/0/all/0/1\">Michele Nappi</a>",
          "description": "Head pose estimation is a crucial challenge for many real-world applications,\nsuch as attention and human behavior analysis. This paper aims to estimate head\npose from a single image by applying notions of network curvature. In the real\nworld, many complex networks have groups of nodes that are well connected to\neach other with significant functional roles. Similarly, the interactions of\nfacial landmarks can be represented as complex dynamic systems modeled by\nweighted graphs. The functionalities of such systems are therefore\nintrinsically linked to the topology and geometry of the underlying graph. In\nthis work, using the geometric notion of Ollivier-Ricci curvature (ORC) on\nweighted graphs as input to the XGBoost regression model, we show that the\nintrinsic geometric basis of ORC offers a natural approach to discovering\nunderlying common structure within a pool of poses. Experiments on the BIWI,\nAFLW2000 and Pointing'04 datasets show that the ORC_XGB method performs well\ncompared to state-of-the-art methods, both landmark-based and image-only.",
          "link": "http://arxiv.org/abs/2204.13006",
          "publishedOn": "2022-04-28T01:16:08.303Z",
          "wordCount": null,
          "title": "Ollivier-Ricci Curvature For Head Pose Estimation From a Single Image. (arXiv:2204.13006v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12965",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kuntz_J/0/1/0/all/0/1\">Juan Kuntz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Johansen_A/0/1/0/all/0/1\">Adam M. Johansen</a>",
          "description": "Building on (Neal and Hinton, 1998), where the problem tackled by EM is\nrecast as the optimization of a free energy functional on an\ninfinite-dimensional space, we obtain three practical particle-based\nalternatives to EM applicable to broad classes of models. All three are derived\nthrough straightforward discretizations of gradient flows associated with the\nfunctional. The novel algorithms scale well to high-dimensional settings and\noutperform existing state-of-the-art methods in numerical experiments.",
          "link": "http://arxiv.org/abs/2204.12965",
          "publishedOn": "2022-04-28T01:16:08.291Z",
          "wordCount": null,
          "title": "Scalable particle-based alternatives to EM. (arXiv:2204.12965v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12904",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bencevic_M/0/1/0/all/0/1\">Marin Ben&#x10d;evi&#x107;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Habijan_M/0/1/0/all/0/1\">Marija Habijan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Galic_I/0/1/0/all/0/1\">Irena Gali&#x107;</a>",
          "description": "Epicardial adipose tissue is a type of adipose tissue located between the\nheart wall and a protective layer around the heart called the pericardium. The\nvolume and thickness of epicardial adipose tissue are linked to various\ncardiovascular diseases. It is shown to be an independent cardiovascular\ndisease risk factor. Fully automatic and reliable measurements of epicardial\nadipose tissue from CT scans could provide better disease risk assessment and\nenable the processing of large CT image data sets for a systemic epicardial\nadipose tissue study. This paper proposes a method for fully automatic semantic\nsegmentation of epicardial adipose tissue from CT images using a deep neural\nnetwork. The proposed network uses a U-Net-based architecture with slice depth\ninformation embedded in the input image to segment a pericardium region of\ninterest, which is used to obtain an epicardial adipose tissue segmentation.\nImage augmentation is used to increase model robustness. Cross-validation of\nthe proposed method yields a Dice score of 0.86 on the CT scans of 20 patients.",
          "link": "http://arxiv.org/abs/2204.12904",
          "publishedOn": "2022-04-28T01:16:08.286Z",
          "wordCount": 642,
          "title": "Epicardial Adipose Tissue Segmentation from CT Images with A Semi-3D Neural Network. (arXiv:2204.12904v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12939",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Berman_D/0/1/0/all/0/1\">David S. Berman</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Heckman_J/0/1/0/all/0/1\">Jonathan J. Heckman</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Klinger_M/0/1/0/all/0/1\">Marc Klinger</a>",
          "description": "Statistical Inference is the process of determining a probability\ndistribution over the space of parameters of a model given a data set. As more\ndata becomes available this probability distribution becomes updated via the\napplication of Bayes' theorem. We present a treatment of this Bayesian updating\nprocess as a continuous dynamical system. Statistical inference is then\ngoverned by a first order differential equation describing a trajectory or flow\nin the information geometry determined by a parametric family of models. We\nsolve this equation for some simple models and show that when the\nCram\\'{e}r-Rao bound is saturated the learning rate is governed by a simple\n$1/T$ power-law, with $T$ a time-like variable denoting the quantity of data.\nThe presence of hidden variables can be incorporated in this setting, leading\nto an additional driving term in the resulting flow equation. We illustrate\nthis with both analytic and numerical examples based on Gaussians and Gaussian\nRandom Processes and inference of the coupling constant in the 1D Ising model.\nFinally we compare the qualitative behaviour exhibited by Bayesian flows to the\ntraining of various neural networks on benchmarked data sets such as MNIST and\nCIFAR10 and show how that for networks exhibiting small final losses the simple\npower-law is also satisfied.",
          "link": "http://arxiv.org/abs/2204.12939",
          "publishedOn": "2022-04-28T01:16:08.269Z",
          "wordCount": 658,
          "title": "On the Dynamics of Inference and Learning. (arXiv:2204.12939v1 [cond-mat.dis-nn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_D/0/1/0/all/0/1\">Dong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chi Ian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mascolo_C/0/1/0/all/0/1\">Cecilia Mascolo</a>",
          "description": "Many deep learning applications, like keyword spotting, require the\nincorporation of new concepts (classes) over time, referred to as Class\nIncremental Learning (CIL). The major challenge in CIL is catastrophic\nforgetting, i.e., preserving as much of the old knowledge as possible while\nlearning new tasks. Various techniques, such as regularization, knowledge\ndistillation, and the use of exemplars, have been proposed to resolve this\nissue. However, prior works primarily focus on the incremental learning step,\nwhile ignoring the optimization during the base model training. We hypothesize\nthat a more transferable and generalizable feature representation from the base\nmodel would be beneficial to incremental learning.\n\nIn this work, we adopt multitask learning during base model training to\nimprove the feature generalizability. Specifically, instead of training a\nsingle model with all the base classes, we decompose the base classes into\nmultiple subsets and regard each of them as a task. These tasks are trained\nconcurrently and a shared feature extractor is obtained for incremental\nlearning. We evaluate our approach on two datasets under various\nconfigurations. The results show that our approach enhances the average\nincremental learning accuracy by up to 5.5%, which enables more reliable and\naccurate keyword spotting over time. Moreover, the proposed approach can be\ncombined with many existing techniques and provides additional performance\ngain.",
          "link": "http://arxiv.org/abs/2204.12915",
          "publishedOn": "2022-04-28T01:16:08.248Z",
          "wordCount": 639,
          "title": "Improving Feature Generalizability with Multitask Learning in Class Incremental Learning. (arXiv:2204.12915v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12914",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Li_L/0/1/0/all/0/1\">Linwei Li</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Matt_P/0/1/0/all/0/1\">Paul-Amaury Matt</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Heumann_C/0/1/0/all/0/1\">Christian Heumann</a>",
          "description": "The article is concerned with the problem of multi-step financial time series\nforecasting of Foreign Exchange (FX) rates. To address this problem, we\nintroduce a parameter-free regression network termed RegPred Net. The exchange\nrate to forecast is treated as a stochastic process. It is assumed to follow a\ngeneralization of Brownian motion and the mean-reverting process referred to as\nthe generalized Ornstein-Uhlenbeck (OU) process, with time-dependent\ncoefficients. Using past observed values of the input time series, these\ncoefficients can be regressed online by the cells of the first half of the\nnetwork (Reg). The regressed coefficients depend only on - but are very\nsensitive to - a small number of hyperparameters required to be set by a global\noptimization procedure for which, Bayesian optimization is an adequate\nheuristic. Thanks to its multi-layered architecture, the second half of the\nregression network (Pred) can project time-dependent values for the OU process\ncoefficients and generate realistic trajectories of the time series.\nPredictions can be easily derived in the form of expected values estimated by\naveraging values obtained by Monte Carlo simulation. The forecasting accuracy\non a 100 days horizon is evaluated for several of the most important FX rates\nsuch as EUR/USD, EUR/CNY, and EUR/GBP. Our experimental results show that the\nRegPred Net significantly outperforms ARMA, ARIMA, LSTMs, and Autoencoder-LSTM\nmodels in this task.",
          "link": "http://arxiv.org/abs/2204.12914",
          "publishedOn": "2022-04-28T01:16:08.234Z",
          "wordCount": 660,
          "title": "Forecasting Foreign Exchange Rates With Parameter-Free Regression Networks Tuned By Bayesian Optimization. (arXiv:2204.12914v1 [q-fin.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingxing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wenrui Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenglin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">Junni Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hongkai Xiong</a>",
          "description": "Graph pooling has been increasingly considered for graph neural networks\n(GNNs) to facilitate hierarchical graph representation learning. Existing graph\npooling methods commonly consist of two stages, i.e., selecting the top-ranked\nnodes and removing the rest nodes to construct a coarsened graph\nrepresentation. However, local structural information of the removed nodes\nwould be inevitably dropped in these methods, due to the inherent coupling of\nnodes (location) and their features (signals). In this paper, we propose an\nenhanced three-stage method via lifting, named LiftPool, to improve\nhierarchical graph representation by maximally preserving the local structural\ninformation in graph pooling. LiftPool introduces an additional stage of graph\nlifting before graph coarsening to preserve the local information of the\nremoved nodes and decouple the processes of node removing and feature\nreduction. Specifically, for each node to be removed, its local information is\nobtained by subtracting the global information aggregated from its neighboring\npreserved nodes. Subsequently, this local information is aligned and propagated\nto the preserved nodes to alleviate information loss in graph coarsening.\nFurthermore, we demonstrate that the proposed LiftPool is localized and\npermutation-invariant. The proposed graph lifting structure is general to be\nintegrated with existing downsampling-based graph pooling methods. Evaluations\non benchmark graph datasets show that LiftPool substantially outperforms the\nstate-of-the-art graph pooling methods in the task of graph classification.",
          "link": "http://arxiv.org/abs/2204.12881",
          "publishedOn": "2022-04-28T01:16:08.228Z",
          "wordCount": 653,
          "title": "LiftPool: Lifting-based Graph Pooling for Hierarchical Graph Representation Learning. (arXiv:2204.12881v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12868",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_A/0/1/0/all/0/1\">Alice J. Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hu_L/0/1/0/all/0/1\">Linwei Hu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1\">Jie Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nair_V/0/1/0/all/0/1\">Vijayan Nair</a>",
          "description": "This paper compares the performances of three supervised machine learning\nalgorithms in terms of predictive ability and model interpretation on\nstructured or tabular data. The algorithms considered were scikit-learn\nimplementations of extreme gradient boosting machines (XGB) and random forests\n(RFs), and feedforward neural networks (FFNNs) from TensorFlow. The paper is\norganized in a findings-based manner, with each section providing general\nconclusions supported by empirical results from simulation studies that cover a\nwide range of model complexity and correlation structures among predictors. We\nconsidered both continuous and binary responses of different sample sizes.\n\nOverall, XGB and FFNNs were competitive, with FFNNs showing better\nperformance in smooth models and tree-based boosting algorithms performing\nbetter in non-smooth models. This conclusion held generally for predictive\nperformance, identification of important variables, and determining correct\ninput-output relationships as measured by partial dependence plots (PDPs).\nFFNNs generally had less over-fitting, as measured by the difference in\nperformance between training and testing datasets. However, the difference with\nXGB was often small. RFs did not perform well in general, confirming the\nfindings in the literature. All models exhibited different degrees of bias seen\nin PDPs, but the bias was especially problematic for RFs. The extent of the\nbiases varied with correlation among predictors, response type, and data set\nsample size. In general, tree-based models tended to over-regularize the fitted\nmodel in the tails of predictor distributions. Finally, as to be expected,\nperformances were better for continuous responses compared to binary data and\nwith larger samples.",
          "link": "http://arxiv.org/abs/2204.12868",
          "publishedOn": "2022-04-28T01:16:08.206Z",
          "wordCount": 690,
          "title": "Performance and Interpretability Comparisons of Supervised Machine Learning Algorithms: An Empirical Study. (arXiv:2204.12868v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schulth_L/0/1/0/all/0/1\">Lukas Schulth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berghoff_C/0/1/0/all/0/1\">Christian Berghoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neu_M/0/1/0/all/0/1\">Matthias Neu</a>",
          "description": "Predicitions made by neural networks can be fraudulently altered by so-called\npoisoning attacks. A special case are backdoor poisoning attacks. We study\nsuitable detection methods and introduce a new method called Heatmap\nClustering. There, we apply a $k$-means clustering algorithm on heatmaps\nproduced by the state-of-the-art explainable AI method Layer-wise relevance\npropagation. The goal is to separate poisoned from un-poisoned data in the\ndataset. We compare this method with a similar method, called Activation\nClustering, which also uses $k$-means clustering but applies it on the\nactivation of certain hidden layers of the neural network as input. We test the\nperformance of both approaches for standard backdoor poisoning attacks,\nlabel-consistent poisoning attacks and label-consistent poisoning attacks with\nreduced amplitude stickers. We show that Heatmap Clustering consistently\nperforms better than Activation Clustering. However, when considering\nlabel-consistent poisoning attacks, the latter method also yields good\ndetection performance.",
          "link": "http://arxiv.org/abs/2204.12848",
          "publishedOn": "2022-04-28T01:16:08.191Z",
          "wordCount": 584,
          "title": "Detecting Backdoor Poisoning Attacks on Deep Neural Networks by Heatmap Clustering. (arXiv:2204.12848v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beltran_Hernandez_C/0/1/0/all/0/1\">Cristian C. Beltran-Hernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petit_D/0/1/0/all/0/1\">Damien Petit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramirez_Alpizar_I/0/1/0/all/0/1\">Ixchel G. Ramirez-Alpizar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harada_K/0/1/0/all/0/1\">Kensuke Harada</a>",
          "description": "The Reinforcement Learning (RL) paradigm has been an essential tool for\nautomating robotic tasks. Despite the advances in RL, it is still not widely\nadopted in the industry due to the need for an expensive large amount of robot\ninteraction with its environment. Curriculum Learning (CL) has been proposed to\nexpedite learning. However, most research works have been only evaluated in\nsimulated environments, from video games to robotic toy tasks. This paper\npresents a study for accelerating robot learning of contact-rich manipulation\ntasks based on Curriculum Learning combined with Domain Randomization (DR). We\ntackle complex industrial assembly tasks with position-controlled robots, such\nas insertion tasks. We compare different curricula designs and sampling\napproaches for DR. Based on this study, we propose a method that significantly\noutperforms previous work, which uses DR only (No CL is used), with less than a\nfifth of the training time (samples). Results also show that even when training\nonly in simulation with toy tasks, our method can learn policies that can be\ntransferred to the real-world robot. The learned policies achieved success\nrates of up to 86\\% on real-world complex industrial insertion tasks (with\ntolerances of $\\pm 0.01~mm$) not seen during the training.",
          "link": "http://arxiv.org/abs/2204.12844",
          "publishedOn": "2022-04-28T01:16:08.174Z",
          "wordCount": 658,
          "title": "Accelerating Robot Learning of Contact-Rich Manipulations: A Curriculum Learning Study. (arXiv:2204.12844v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumagai_A/0/1/0/all/0/1\">Atsutoshi Kumagai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chijiwa_D/0/1/0/all/0/1\">Daiki Chijiwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>",
          "description": "Transfer learning is crucial in training deep neural networks on new target\ntasks. Current transfer learning methods generally assume at least one of (i)\nsource and target task label spaces must overlap, (ii) source datasets are\navailable, and (iii) target network architectures are consistent with source\nones. However, these all assumptions are difficult to hold in practical\nsettings because the target task rarely has the same labels as the source task,\nthe source dataset access is restricted due to licensing and storage costs, and\nthe target architecture is often specialized to each task. To transfer source\nknowledge without these assumptions, we propose a transfer learning method that\nuses deep generative models and is composed of the following two stages: pseudo\npre-training (PP) and pseudo semi-supervised learning (P-SSL). PP trains a\ntarget architecture with a synthesized dataset by using conditional source\ngenerative models. P-SSL applies SSL algorithms to labeled target data and\nunlabeled pseudo samples, which are generated by cascading the source\nclassifier and generative models to condition them with target samples. Our\nexperimental results indicate that our method can outperform baselines of\nscratch training and knowledge distillation.",
          "link": "http://arxiv.org/abs/2204.12833",
          "publishedOn": "2022-04-28T01:16:08.153Z",
          "wordCount": 633,
          "title": "Transfer Learning with Pre-trained Conditional Generative Models. (arXiv:2204.12833v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Harel_R/0/1/0/all/0/1\">Re&#x27;em Harel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinter_Y/0/1/0/all/0/1\">Yuval Pinter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oren_G/0/1/0/all/0/1\">Gal Oren</a>",
          "description": "In past years, the world has switched to many-core and multi-core shared\nmemory architectures.\n\nAs a result, there is a growing need to utilize these architectures by\nintroducing shared memory parallelization schemes to software applications.\nOpenMP is the most comprehensive API that implements such schemes,\ncharacterized by a readable interface. Nevertheless, introducing OpenMP into\ncode is challenging due to pervasive pitfalls in management of parallel shared\nmemory. To facilitate the performance of this task, many source-to-source (S2S)\ncompilers have been created over the years, tasked with inserting OpenMP\ndirectives into code automatically.\n\nIn addition to having limited robustness to their input format, these\ncompilers still do not achieve satisfactory coverage and precision in locating\nparallelizable code and generating appropriate directives.\n\nIn this work, we propose leveraging recent advances in ML techniques,\nspecifically in natural language processing (NLP), to replace S2S compilers\naltogether.\n\nWe create a database (corpus), Open-OMP, specifically for this goal. Open-OMP\ncontains over 28,000 code snippets, half of which contain OpenMP directives\nwhile the other half do not need parallelization at all with high probability.\n\nWe use the corpus to train systems to automatically classify code segments in\nneed of parallelization, as well as suggest individual OpenMP clauses.\n\nWe train several transformer models, named PragFormer, for these tasks, and\nshow that they outperform statistically-trained baselines and automatic S2S\nparallelization compilers in both classifying the overall need for an OpenMP\ndirective and the introduction of private and reduction clauses.\n\nOur source code and database are available at:\nhttps://github.com/Scientific-Computing-Lab-NRCN/PragFormer.",
          "link": "http://arxiv.org/abs/2204.12835",
          "publishedOn": "2022-04-28T01:16:08.135Z",
          "wordCount": 697,
          "title": "Learning to Parallelize in a Shared-Memory Environment with Transformers. (arXiv:2204.12835v1 [cs.DC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12796",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Junquan Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Wei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianzhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xianyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chuan Zhang</a>",
          "description": "Similarity metric is crucial for massive MIMO positioning utilizing channel\nstate information~(CSI). In this letter, we propose a novel massive MIMO CSI\nsimilarity learning method via deep convolutional neural network~(DCNN) and\ncontrastive learning. A contrastive loss function is designed considering\nmultiple positive and negative CSI samples drawn from a training dataset. The\nDCNN encoder is trained using the loss so that positive samples are mapped to\npoints close to the anchor's encoding, while encodings of negative samples are\nkept away from the anchor's in the representation space. Evaluation results of\nfingerprint-based positioning on a real-world CSI dataset show that the learned\nsimilarity metric improves positioning accuracy significantly compared with\nother known state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2204.12796",
          "publishedOn": "2022-04-28T01:16:08.088Z",
          "wordCount": 562,
          "title": "Supervised Contrastive CSI Representation Learning for Massive MIMO Positioning. (arXiv:2204.12796v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12802",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1\">Nan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaofan Wang</a>",
          "description": "We propose Graph Tree Networks (GTNets), a deep graph learning architecture\nwith a new general message passing scheme that originates from the tree\nrepresentation of graphs. In the tree representation, messages propagate upward\nfrom the leaf nodes to the root node, and each node preserves its initial\ninformation prior to receiving information from its child nodes (neighbors). We\nformulate a general propagation rule following the nature of message passing in\nthe tree to update a node's feature by aggregating its initial feature and its\nneighbor nodes' updated features. Two graph representation learning models are\nproposed within this GTNet architecture - Graph Tree Attention Network (GTAN)\nand Graph Tree Convolution Network (GTCN), with experimentally demonstrated\nstate-of-the-art performance on several popular benchmark datasets. Unlike the\nvanilla Graph Attention Network (GAT) and Graph Convolution Network (GCN) which\nhave the \"over-smoothing\" issue, the proposed GTAN and GTCN models can go deep\nas demonstrated by comprehensive experiments and rigorous theoretical analysis.",
          "link": "http://arxiv.org/abs/2204.12802",
          "publishedOn": "2022-04-28T01:16:08.083Z",
          "wordCount": 597,
          "title": "GTNet: A Tree-Based Deep Graph Learning Architecture. (arXiv:2204.12802v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roller_R/0/1/0/all/0/1\">Roland Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budde_K/0/1/0/all/0/1\">Klemens Budde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burchardt_A/0/1/0/all/0/1\">Aljoscha Burchardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dabrock_P/0/1/0/all/0/1\">Peter Dabrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moller_S/0/1/0/all/0/1\">Sebastian M&#xf6;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osmanodja_B/0/1/0/all/0/1\">Bilgin Osmanodja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronicke_S/0/1/0/all/0/1\">Simon Ronicke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samhammer_D/0/1/0/all/0/1\">David Samhammer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmeier_S/0/1/0/all/0/1\">Sven Schmeier</a>",
          "description": "Scientific publications about machine learning in healthcare are often about\nimplementing novel methods and boosting the performance - at least from a\ncomputer science perspective. However, beyond such often short-lived\nimprovements, much more needs to be taken into consideration if we want to\narrive at a sustainable progress in healthcare. What does it take to actually\nimplement such a system, make it usable for the domain expert, and possibly\nbring it into practical usage? Targeted at Computer Scientists, this work\npresents a multidisciplinary view on machine learning in medical decision\nsupport systems and covers information technology, medical, as well as ethical\naspects. Along with an implemented risk prediction system in nephrology,\nchallenges and lessons learned in a pilot project are presented.",
          "link": "http://arxiv.org/abs/2204.12810",
          "publishedOn": "2022-04-28T01:16:08.077Z",
          "wordCount": 582,
          "title": "When Performance is not Enough -- A Multidisciplinary View on Clinical Decision Support. (arXiv:2204.12810v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12789",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Boulle_N/0/1/0/all/0/1\">Nicolas Boull&#xe9;</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kim_S/0/1/0/all/0/1\">Seick Kim</a>, <a href=\"http://arxiv.org/find/math/1/au:+Shi_T/0/1/0/all/0/1\">Tianyi Shi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Townsend_A/0/1/0/all/0/1\">Alex Townsend</a>",
          "description": "Given input-output pairs from a parabolic partial differential equation (PDE)\nin any spatial dimension $n\\geq 1$, we derive the first theoretically rigorous\nscheme for learning the associated Green's function $G$. Until now, rigorously\nlearning Green's functions associated with parabolic operators has been a major\nchallenge in the field of scientific machine learning because $G$ may not be\nsquare-integrable when $n>1$, and time-dependent PDEs have transient dynamics.\nBy combining the hierarchical low-rank structure of $G$ together with the\nrandomized singular value decomposition, we construct an approximant to $G$\nthat achieves a relative error of\n$\\smash{\\mathcal{O}(\\Gamma_\\epsilon^{-1/2}\\epsilon)}$ in the $L^1$-norm with\nhigh probability by using at most\n$\\smash{\\mathcal{O}(\\epsilon^{-\\frac{n+2}{2}}\\log(1/\\epsilon))}$ input-output\ntraining pairs, where $\\Gamma_\\epsilon$ is a measure of the quality of the\ntraining dataset for learning $G$, and $\\epsilon>0$ is sufficiently small.\nAlong the way, we extend the low-rank theory of Bebendorf and Hackbusch from\nelliptic PDEs in dimension $1\\leq n\\leq 3$ to parabolic PDEs in any dimensions,\nwhich shows that Green's functions associated with parabolic PDEs admit a\nlow-rank structure on well-separated domains.",
          "link": "http://arxiv.org/abs/2204.12789",
          "publishedOn": "2022-04-28T01:16:08.061Z",
          "wordCount": 619,
          "title": "Learning Green's functions associated with parabolic partial differential equations. (arXiv:2204.12789v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venturi_S/0/1/0/all/0/1\">Simone Venturi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casey_T/0/1/0/all/0/1\">Tiernan Casey</a>",
          "description": "Deep operator networks (DeepONets) are powerful architectures for fast and\naccurate emulation of complex dynamics. As their remarkable generalization\ncapabilities are primarily enabled by their projection-based attribute, we\ninvestigate connections with low-rank techniques derived from the singular\nvalue decomposition (SVD). We demonstrate that some of the concepts behind\nproper orthogonal decomposition (POD)-neural networks can improve DeepONet's\ndesign and training phases. These ideas lead us to a methodology extension that\nwe name SVD-DeepONet. Moreover, through multiple SVD analyses, we find that\nDeepONet inherits from its projection-based attribute strong inefficiencies in\nrepresenting dynamics characterized by symmetries. Inspired by the work on\nshifted-POD, we develop flexDeepONet, an architecture enhancement that relies\non a pre-transformation network for generating a moving reference frame and\nisolating the rigid components of the dynamics. In this way, the physics can be\nrepresented on a latent space free from rotations, translations, and stretches,\nand an accurate projection can be performed to a low-dimensional basis. In\naddition to flexibility and interpretability, the proposed perspectives\nincrease DeepONet's generalization capabilities and computational efficiencies.\nFor instance, we show flexDeepONet can accurately surrogate the dynamics of 19\nvariables in a combustion chemistry application by relying on 95% less\ntrainable parameters than the ones of the vanilla architecture. We argue that\nDeepONet and SVD-based methods can reciprocally benefit from each other. In\nparticular, the flexibility of the former in leveraging multiple data sources\nand multifidelity knowledge in the form of both unstructured data and\nphysics-informed constraints has the potential to greatly extend the\napplicability of methodologies such as POD and PCA.",
          "link": "http://arxiv.org/abs/2204.12670",
          "publishedOn": "2022-04-28T01:16:08.055Z",
          "wordCount": 707,
          "title": "SVD Perspectives for Augmenting DeepONet Flexibility and Interpretability. (arXiv:2204.12670v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12707",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ochoa_D/0/1/0/all/0/1\">Daniel E. Ochoa</a>, <a href=\"http://arxiv.org/find/math/1/au:+Poveda_J/0/1/0/all/0/1\">Jorge I. Poveda</a>",
          "description": "We introduce a new closed-loop architecture for the online solution of\napproximate optimal control problems in the context of continuous-time systems.\nSpecifically, we introduce the first algorithm that incorporates dynamic\nmomentum in actor-critic structures to control continuous-time dynamic plants\nwith an affine structure in the input. By incorporating dynamic momentum in our\nalgorithm, we are able to accelerate the convergence properties of the\nclosed-loop system, achieving superior transient performance compared to\ntraditional gradient-descent based techniques. In addition, by leveraging the\nexistence of past recorded data with sufficiently rich information properties,\nwe dispense with the persistence of excitation condition traditionally imposed\non the regressors of the critic and the actor. Given that our continuous-time\nmomentum-based dynamics also incorporate periodic discrete-time resets that\nemulate restarting techniques used in the machine learning literature, we\nleverage tools from hybrid dynamical systems theory to establish asymptotic\nstability properties for the closed-loop system. We illustrate our results with\na numerical example.",
          "link": "http://arxiv.org/abs/2204.12707",
          "publishedOn": "2022-04-28T01:16:08.049Z",
          "wordCount": 594,
          "title": "Accelerated Continuous-Time Approximate Dynamic Programming via Data-Assisted Hybrid Control. (arXiv:2204.12707v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guanhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Keyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhanhao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Gaoang Wang</a>",
          "description": "Recently, much progress has been made for self-supervised action recognition.\nMost existing approaches emphasize the contrastive relations among videos,\nincluding appearance and motion consistency. However, two main issues remain\nfor existing pre-training methods: 1) the learned representation is neutral and\nnot informative for a specific task; 2) multi-task learning-based pre-training\nsometimes leads to sub-optimal solutions due to inconsistent domains of\ndifferent tasks. To address the above issues, we propose a novel action\nrecognition pre-training framework, which exploits human-centered prior\nknowledge that generates more informative representation, and avoids the\nconflict between multiple tasks by using task-dependent representations.\nSpecifically, we distill knowledge from a human parsing model to enrich the\nsemantic capability of representation. In addition, we combine knowledge\ndistillation with contrastive learning to constitute a task-dependent\nmulti-task framework. We achieve state-of-the-art performance on two popular\nbenchmarks for action recognition task, i.e., UCF101 and HMDB51, verifying the\neffectiveness of our method.",
          "link": "http://arxiv.org/abs/2204.12729",
          "publishedOn": "2022-04-28T01:16:08.044Z",
          "wordCount": 607,
          "title": "Human-Centered Prior-Guided and Task-Dependent Multi-Task Representation Learning for Action Recognition Pre-Training. (arXiv:2204.12729v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trillos_N/0/1/0/all/0/1\">Nicolas Garcia Trillos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_M/0/1/0/all/0/1\">Matt Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jakwang Kim</a>",
          "description": "We study a family of adversarial multiclass classification problems and\nprovide equivalent reformulations in terms of: 1) a family of generalized\nbarycenter problems introduced in the paper and 2) a family of multimarginal\noptimal transport problems where the number of marginals is equal to the number\nof classes in the original classification problem. These new theoretical\nresults reveal a rich geometric structure of adversarial learning problems in\nmulticlass classification and extend recent results restricted to the binary\nclassification setting. A direct computational implication of our results is\nthat by solving either the barycenter problem and its dual, or the MOT problem\nand its dual, we can recover the optimal robust classification rule and the\noptimal adversarial strategy for the original adversarial problem. Examples\nwith synthetic and real data illustrate our results.",
          "link": "http://arxiv.org/abs/2204.12676",
          "publishedOn": "2022-04-28T01:16:08.038Z",
          "wordCount": 581,
          "title": "The Multimarginal Optimal Transport Formulation of Adversarial Multiclass Classification. (arXiv:2204.12676v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiahong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_M/0/1/0/all/0/1\">Meijun Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ye Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1\">Lihong Cao</a>",
          "description": "Recently, convolutional neural networks (CNNs) and attention mechanisms have\nbeen widely used in image denoising and achieved satisfactory performance.\nHowever, the previous works mostly use a single head to receive the noisy\nimage, limiting the richness of extracted features. Therefore, a novel CNN with\nmultiple heads (MH) named MHCNN is proposed in this paper, whose heads will\nreceive the input images rotated by different rotation angles. MH makes MHCNN\nsimultaneously utilize features of rotated images to remove noise. We also\npresent a novel multi-path attention mechanism (MPA) to integrate these\nfeatures effectively. Unlike previous attention mechanisms that handle\npixel-level, channel-level, and patch-level features, MPA focuses on features\nat the image level. Experiments show MHCNN surpasses other state-of-the-art CNN\nmodels on additive white Gaussian noise (AWGN) denoising and real-world image\ndenoising. Its peak signal-to-noise ratio (PSNR) results are higher than other\nnetworks, such as DnCNN, BRDNet, RIDNet, PAN-Net, and CSANN. It is also\ndemonstrated that the proposed MH with MPA mechanism can be used as a pluggable\ncomponent.",
          "link": "http://arxiv.org/abs/2204.12736",
          "publishedOn": "2022-04-28T01:16:08.021Z",
          "wordCount": 621,
          "title": "A Multi-Head Convolutional Neural Network With Multi-path Attention improves Image Denoising. (arXiv:2204.12736v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12750",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hojoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_D/0/1/0/all/0/1\">Dongyoon Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunseung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1\">Byungkun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jaegul Choo</a>",
          "description": "This paper presents a personalized character recommendation system for\nMultiplayer Online Battle Arena (MOBA) games which are considered as one of the\nmost popular online video game genres around the world. When playing MOBA\ngames, players go through a draft stage, where they alternately select a\nvirtual character to play. When drafting, players select characters by not only\nconsidering their character preferences, but also the synergy and competence of\ntheir team's character combination. However, the complexity of drafting induces\ndifficulties for beginners to choose the appropriate characters based on the\ncharacters of their team while considering their own champion preferences. To\nalleviate this problem, we propose DraftRec, a novel hierarchical model which\nrecommends characters by considering each player's champion preferences and the\ninteraction between the players. DraftRec consists of two networks: the player\nnetwork and the match network. The player network captures the individual\nplayer's champion preference, and the match network integrates the complex\nrelationship between the players and their respective champions. We train and\nevaluate our model from a manually collected 280,000 matches of League of\nLegends and a publicly available 50,000 matches of Dota2. Empirically, our\nmethod achieved state-of-the-art performance in character recommendation and\nmatch outcome prediction task. Furthermore, a comprehensive user survey\nconfirms that DraftRec provides convincing and satisfying recommendations. Our\ncode and dataset are available at https://github.com/dojeon-ai/DraftRec.",
          "link": "http://arxiv.org/abs/2204.12750",
          "publishedOn": "2022-04-28T01:16:08.015Z",
          "wordCount": 685,
          "title": "DraftRec: Personalized Draft Recommendation for Winning in Multi-Player Online Battle Arena Games. (arXiv:2204.12750v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1\">Yae Jee Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manoel_A/0/1/0/all/0/1\">Andre Manoel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_G/0/1/0/all/0/1\">Gauri Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1\">Robert Sim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitriadis_D/0/1/0/all/0/1\">Dimitrios Dimitriadis</a>",
          "description": "Federated learning (FL) enables edge-devices to collaboratively learn a model\nwithout disclosing their private data to a central aggregating server. Most\nexisting FL algorithms require models of identical architecture to be deployed\nacross the clients and server, making it infeasible to train large models due\nto clients' limited system resources. In this work, we propose a novel ensemble\nknowledge transfer method named Fed-ET in which small models (different in\narchitecture) are trained on clients, and used to train a larger model at the\nserver. Unlike in conventional ensemble learning, in FL the ensemble can be\ntrained on clients' highly heterogeneous data. Cognizant of this property,\nFed-ET uses a weighted consensus distillation scheme with diversity\nregularization that efficiently extracts reliable consensus from the ensemble\nwhile improving generalization by exploiting the diversity within the ensemble.\nWe show the generalization bound for the ensemble of weighted models trained on\nheterogeneous datasets that supports the intuition of Fed-ET. Our experiments\non image and language tasks show that Fed-ET significantly outperforms other\nstate-of-the-art FL algorithms with fewer communicated parameters, and is also\nrobust against high data-heterogeneity.",
          "link": "http://arxiv.org/abs/2204.12703",
          "publishedOn": "2022-04-28T01:16:08.009Z",
          "wordCount": 640,
          "title": "Heterogeneous Ensemble Knowledge Transfer for Training Large Models in Federated Learning. (arXiv:2204.12703v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Haitian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Ying Zhu</a>",
          "description": "This paper studies the gap between the classical pricing theory and the\ndata-based pricing theory. We focus on the problem of price discrimination with\na continuum of buyer types based on a finite sample of observations. Our first\nset of results provides sharp lower bounds in the worst-case scenario for the\ndiscrepancy between any data-based pricing strategies and the theoretical\noptimal third-degree price discrimination (3PD) strategy (respectively, uniform\npricing strategy) derived from the distribution (where the sample is drawn)\nranging over a large class of distributions. Consequently, there is an\ninevitable gap between revenues based on any data-based pricing strategy and\nthe revenue based on the theoretical optimal 3PD (respectively, uniform\npricing) strategy. We then propose easy-to-implement data-based 3PD and uniform\npricing strategies and show each strategy is minimax optimal in the sense that\nthe gap between their respective revenue and the revenue based on the\ntheoretical optimal 3PD (respectively, uniform pricing) strategy matches our\nworst-case lower bounds up to constant factors (that are independent of the\nsample size $n$). We show that 3PD strategies are revenue superior to uniform\npricing strategies if and only if the sample size $n$ is large enough. In other\nwords, if $n$ is below a threshold, uniform pricing strategies are revenue\nsuperior to 3PD strategies. We further provide upper bounds for the gaps\nbetween the welfare generated by our minimax optimal 3PD (respectively, uniform\npricing) strategy and the welfare based on the theoretical optimal 3PD\n(respectively, uniform pricing) strategy.",
          "link": "http://arxiv.org/abs/2204.12723",
          "publishedOn": "2022-04-28T01:16:08.001Z",
          "wordCount": 704,
          "title": "Data-based price discrimination: information theoretic limitations and a minimax optimal strategy. (arXiv:2204.12723v1 [cs.GT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12665",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karia_R/0/1/0/all/0/1\">Rushang Karia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Siddharth Srivastava</a>",
          "description": "Reinforcement learning in problems with symbolic state spaces is challenging\ndue to the need for reasoning over long horizons. This paper presents a new\napproach that utilizes relational abstractions in conjunction with deep\nlearning to learn a generalizable Q-function for such problems. The learned\nQ-function can be efficiently transferred to related problems that have\ndifferent object names and object quantities, and thus, entirely different\nstate spaces. We show that the learned generalized Q-function can be utilized\nfor zero-shot transfer to related problems without an explicit, hand-coded\ncurriculum. Empirical evaluations on a range of problems show that our method\nfacilitates efficient zero-shot transfer of learned knowledge to much larger\nproblem instances containing many objects.",
          "link": "http://arxiv.org/abs/2204.12665",
          "publishedOn": "2022-04-28T01:16:07.985Z",
          "wordCount": 553,
          "title": "Relational Abstractions for Generalized Reinforcement Learning on Symbolic Problems. (arXiv:2204.12665v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vertechi_P/0/1/0/all/0/1\">Pietro Vertechi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergomi_M/0/1/0/all/0/1\">Mattia G. Bergomi</a>",
          "description": "We provide a unifying framework where artificial neural networks and their\narchitectures can be formally described as particular cases of a general\nmathematical construction--machines of finite depth. Unlike neural networks,\nmachines have a precise definition, from which several properties follow\nnaturally. Machines of finite depth are modular (they can be combined),\nefficiently computable and differentiable. The backward pass of a machine is\nagain a machine and can be computed without overhead using the same procedure\nas the forward pass. We prove this statement theoretically and practically, via\na unified implementation that generalizes several classical\narchitectures--dense, convolutional, and recurrent neural networks with a rich\nshortcut structure--and their respective backpropagation rules.",
          "link": "http://arxiv.org/abs/2204.12786",
          "publishedOn": "2022-04-28T01:16:07.979Z",
          "wordCount": 554,
          "title": "Machines of finite depth: towards a formalization of neural networks. (arXiv:2204.12786v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Mingyi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elia_N/0/1/0/all/0/1\">Nicola Elia</a>",
          "description": "Distributed algorithms have been playing an increasingly important role in\nmany applications such as machine learning, signal processing, and control.\nSignificant research efforts have been devoted to developing and analyzing new\nalgorithms for various applications. In this work, we provide a fresh\nperspective to understand, analyze, and design distributed optimization\nalgorithms. Through the lens of multi-rate feedback control, we show that a\nwide class of distributed algorithms, including popular decentralized/federated\nschemes, can be viewed as discretizing a certain continuous-time feedback\ncontrol system, possibly with multiple sampling rates, such as decentralized\ngradient descent, gradient tracking, and federated averaging. This key\nobservation not only allows us to develop a generic framework to analyze the\nconvergence of the entire algorithm class. More importantly, it also leads to\nan interesting way of designing new distributed algorithms. We develop the\ntheory behind our framework and provide examples to highlight how the framework\ncan be used in practice.",
          "link": "http://arxiv.org/abs/2204.12663",
          "publishedOn": "2022-04-28T01:16:07.973Z",
          "wordCount": 600,
          "title": "Understanding A Class of Decentralized and Federated Optimization Algorithms: A Multi-Rate Feedback Control Perspective. (arXiv:2204.12663v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12629",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1\">Yue Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ayanoglu_E/0/1/0/all/0/1\">Ender Ayanoglu</a>",
          "description": "This paper discusses a special kind of a simple yet possibly powerful\nalgorithm, called single-kernel Gradraker (SKG), which is an adaptive learning\nmethod predicting unknown nodal values in a network using known nodal values\nand the network structure. We aim to find out how to configure the special kind\nof the model in applying the algorithm. To be more specific, we focus on SKG\nwith a Gaussian kernel and specify how to find a suitable variance for the\nkernel. To do so, we introduce two variables with which we are able to set up\nrequirements on the variance of the Gaussian kernel to achieve (near-) optimal\nperformance and can better understand how SKG works. Our contribution is that\nwe introduce two variables as analysis tools, illustrate how predictions will\nbe affected under different Gaussian kernels, and provide an algorithm finding\na suitable Gaussian kernel for SKG with knowledge about the training network.\nSimulation results on real datasets are provided.",
          "link": "http://arxiv.org/abs/2204.12629",
          "publishedOn": "2022-04-28T01:16:07.967Z",
          "wordCount": 615,
          "title": "Gaussian Kernel Variance For an Adaptive Learning Method on Signals Over Graphs. (arXiv:2204.12629v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1\">Zongqi Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaoming Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jialin Zhang</a>",
          "description": "We study the adversarial bandit problem with composite anonymous delayed\nfeedback. In this setting, losses of an action are split into $d$ components,\nspreading over consecutive rounds after the action is chosen. And in each\nround, the algorithm observes the aggregation of losses that come from the\nlatest $d$ rounds. Previous works focus on oblivious adversarial setting, while\nwe investigate the harder non-oblivious setting. We show non-oblivious setting\nincurs $\\Omega(T)$ pseudo regret even when the loss sequence is bounded memory.\nHowever, we propose a wrapper algorithm which enjoys $o(T)$ policy regret on\nmany adversarial bandit problems with the assumption that the loss sequence is\nbounded memory. Especially, for $K$-armed bandit and bandit convex\noptimization, we have $\\mathcal{O}(T^{2/3})$ policy regret bound. We also prove\na matching lower bound for $K$-armed bandit. Our lower bound works even when\nthe loss sequence is oblivious but the delay is non-oblivious. It answers the\nopen problem proposed in \\cite{wang2021adaptive}, showing that non-oblivious\ndelay is enough to incur $\\tilde{\\Omega}(T^{2/3})$ regret.",
          "link": "http://arxiv.org/abs/2204.12764",
          "publishedOn": "2022-04-28T01:16:07.961Z",
          "wordCount": 604,
          "title": "Bounded Memory Adversarial Bandits with Composite Anonymous Delayed Feedback. (arXiv:2204.12764v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulatilleke_G/0/1/0/all/0/1\">Gayan K. Kulatilleke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portmann_M/0/1/0/all/0/1\">Marius Portmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_S/0/1/0/all/0/1\">Shekhar S. Chandra</a>",
          "description": "Graph clustering discovers groups or communities within networks. Deep\nlearning methods such as autoencoders (AE) extract effective clustering and\ndownstream representations but cannot incorporate rich structural information.\nWhile Graph Neural Networks (GNN) have shown great success in encoding graph\nstructure, typical GNNs based on convolution or attention variants suffer from\nover-smoothing, noise, heterophily, are computationally expensive and typically\nrequire the complete graph being present. Instead, we propose Self-Supervised\nContrastive Graph Clustering (SCGC), which imposes graph-structure via\ncontrastive loss signals to learn discriminative node representations and\niteratively refined soft cluster labels. We also propose SCGC*, with a more\neffective, novel, Influence Augmented Contrastive (IAC) loss to fuse richer\nstructural information, and half the original model parameters. SCGC(*) is\nfaster with simple linear units, completely eliminate convolutions and\nattention of traditional GNNs, yet efficiently incorporates structure. It is\nimpervious to layer depth and robust to over-smoothing, incorrect edges and\nheterophily. It is scalable by batching, a limitation in many prior GNN models,\nand trivially parallelizable. We obtain significant improvements over\nstate-of-the-art on a wide range of benchmark graph datasets, including images,\nsensor data, text, and citation networks efficiently. Specifically, 20% on ARI\nand 18% on NMI for DBLP; overall 55% reduction in training time and overall,\n81% reduction on inference time. Our code is available at :\nhttps://github.com/gayanku/SCGC",
          "link": "http://arxiv.org/abs/2204.12656",
          "publishedOn": "2022-04-28T01:16:07.918Z",
          "wordCount": 661,
          "title": "SCGC : Self-Supervised Contrastive Graph Clustering. (arXiv:2204.12656v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Delazeri_B/0/1/0/all/0/1\">Bruna Delazeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veras_L/0/1/0/all/0/1\">Leonardo L. Veras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Britto_A/0/1/0/all/0/1\">Alceu de S. Britto Jr.</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barddal_J/0/1/0/all/0/1\">Jean Paul Barddal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koerich_A/0/1/0/all/0/1\">Alessandro L. Koerich</a>",
          "description": "This work describes different strategies to generate unsupervised\nrepresentations obtained through the concept of self-taught learning for facial\nemotion recognition (FER). The idea is to create complementary representations\npromoting diversity by varying the autoencoders' initialization, architecture,\nand training data. SVM, Bagging, Random Forest, and a dynamic ensemble\nselection method are evaluated as final classification methods. Experimental\nresults on Jaffe and Cohn-Kanade datasets using a leave-one-subject-out\nprotocol show that FER methods based on the proposed diverse representations\ncompare favorably against state-of-the-art approaches that also explore\nunsupervised feature learning.",
          "link": "http://arxiv.org/abs/2204.12624",
          "publishedOn": "2022-04-28T01:16:07.782Z",
          "wordCount": 543,
          "title": "Evaluation of Self-taught Learning-based Representations for Facial Emotion Recognition. (arXiv:2204.12624v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1\">Wenbin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Weiming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boulet_B/0/1/0/all/0/1\">Benoit Boulet</a>",
          "description": "Early fault detection (EFD) of rolling bearings can recognize slight\ndeviation of the health states and contribute to the stability of mechanical\nsystems. In practice, very limited target bearing data are available to conduct\nEFD, which makes it hard to adapt to the EFD task of new bearings. To address\nthis problem, many transfer learning based EFD methods utilize historical data\nto learn transferable domain knowledge and conduct early fault detection on new\ntarget bearings. However, most existing methods only consider the distribution\ndrift across different working conditions but ignore the difference between\nbearings under the same working condition, which is called Unit-to-Unit\nVariability (UtUV). The setting of EFD with limited target data considering\nUtUV can be formulated as a Few-shot Anomaly Detection task. Therefore, this\npaper proposes a novel EFD method based on meta-learning considering UtUV. The\nproposed method can learn a generic metric based on Relation Network (RN) to\nmeasure the similarity between normal data and the new arrival target bearing\ndata. Besides, the proposed method utilizes a health state embedding strategy\nto decrease false alarms. The performance of proposed method is tested on two\nbearing datasets. The results show that the proposed method can detect\nincipient faults earlier than the baselines with lower false alarms.",
          "link": "http://arxiv.org/abs/2204.12637",
          "publishedOn": "2022-04-28T01:16:07.777Z",
          "wordCount": 648,
          "title": "Meta-Learning Based Early Fault Detection for Rolling Bearings via Few-Shot Anomaly Detection. (arXiv:2204.12637v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bergamin_L/0/1/0/all/0/1\">Luca Bergamin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carraro_T/0/1/0/all/0/1\">Tommaso Carraro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polato_M/0/1/0/all/0/1\">Mirko Polato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aiolli_F/0/1/0/all/0/1\">Fabio Aiolli</a>",
          "description": "The recent rise in deep learning technologies fueled innovation and boosted\nscientific research. Their achievements enabled new research directions for\ndeep generative modeling (DGM), an increasingly popular approach that can\ncreate novel and unseen data, starting from a given data set. As the technology\nshows promising applications, many ethical issues also arise. For example,\ntheir misuse can enable disinformation campaigns and powerful phishing\nattempts. Research also indicates different biases affect deep learning models,\nleading to social issues such as misrepresentation. In this work, we formulate\na novel setting to deal with similar problems, showing that a repurposed\nanomaly detection system effectively generates novel data, avoiding generating\nspecified unwanted data. We propose Variational Auto-encoding Binary\nClassifiers (V-ABC): a novel model that repurposes and extends the\nAuto-encoding Binary Classifier (ABC) anomaly detector, using the Variational\nAuto-encoder (VAE). We survey the limitations of existing approaches and\nexplore many tools to show the model's inner workings in an interpretable way.\nThis proposal has excellent potential for generative applications: models that\nrely on user-generated data could automatically filter out unwanted content,\nsuch as offensive language, obscene images, and misleading information.",
          "link": "http://arxiv.org/abs/2204.12577",
          "publishedOn": "2022-04-28T01:16:07.760Z",
          "wordCount": 644,
          "title": "Novel Applications for VAE-based Anomaly Detection Systems. (arXiv:2204.12577v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gnanasambandam_R/0/1/0/all/0/1\">Raghav Gnanasambandam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1\">Bo Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1\">Jihoon Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xubo Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhenyu/0/1/0/all/0/1\">Zhenyu</a> (James) <a href=\"http://arxiv.org/find/cs/1/au:+Kong/0/1/0/all/0/1\">Kong</a>",
          "description": "Physics-informed Neural Networks (PINNs) are gaining attention in the\nengineering and scientific literature for solving a range of differential\nequations with applications in weather modeling, healthcare, manufacturing, and\nso on. Poor scalability is one of the barriers to utilizing PINNs for many\nreal-world problems. To address this, a Self-scalable tanh (Stan) activation\nfunction is proposed for the PINNs. The proposed Stan function is smooth,\nnon-saturating, and has a trainable parameter. During training, it can allow\neasy flow of gradients to compute the required derivatives and also enable\nsystematic scaling of the input-output mapping. It is also shown theoretically\nthat the PINN with the proposed Stan function has no spurious stationary points\nwhen using gradient descent algorithms. The proposed Stan is tested on a couple\nof numerical studies involving general regression problems. It is subsequently\nused for solving multiple forward problems, which involve second-order\nderivatives and multiple dimensions, and an inverse problem where the thermal\ndiffusivity is predicted through heat conduction in a rod. Our results of these\ncase studies establish empirically that the Stan activation function can\nachieve better training and more accurate predictions than the state-of-the-art\nactivation functions.",
          "link": "http://arxiv.org/abs/2204.12589",
          "publishedOn": "2022-04-28T01:16:07.749Z",
          "wordCount": 641,
          "title": "Self-scalable Tanh (Stan): Faster Convergence and Better Generalization in Physics-informed Neural Networks. (arXiv:2204.12589v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pase_F/0/1/0/all/0/1\">Francesco Pase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1\">Deniz G&#xfc;nd&#xfc;z</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zorzi_M/0/1/0/all/0/1\">Michele Zorzi</a>",
          "description": "We consider a rate-constrained contextual multi-armed bandit (RC-CMAB)\nproblem, in which a group of agents are solving the same contextual multi-armed\nbandit (CMAB) problem. However, the contexts are observed by a remotely\nconnected entity, i.e., the decision-maker, that updates the policy to maximize\nthe returned rewards, and communicates the arms to be sampled by the agents to\na controller over a rate-limited communications channel. This framework can be\napplied to personalized ad placement, whenever the content owner observes the\nwebsite visitors, and hence has the context, but needs to transmit the ads to\nbe shown to a controller that is in charge of placing the marketing content.\nConsequently, the rate-constrained CMAB (RC-CMAB) problem requires the study of\nlossy compression schemes for the policy to be employed whenever the constraint\non the channel rate does not allow the uncompressed transmission of the\ndecision-maker's intentions. We characterize the fundamental information\ntheoretic limits of this problem by letting the number of agents go to\ninfinity, and study the regret that can be achieved, identifying the two\ndistinct rate regions leading to linear and sub-linear regrets respectively. We\nthen analyze the optimal compression scheme achievable in the limit with\ninfinite agents, when using the forward and reverse KL divergence as distortion\nmetric. Based on this, we also propose a practical coding scheme, and provide\nnumerical results.",
          "link": "http://arxiv.org/abs/2204.12620",
          "publishedOn": "2022-04-28T01:16:07.718Z",
          "wordCount": 655,
          "title": "Rate-Constrained Remote Contextual Bandits. (arXiv:2204.12620v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rigter_M/0/1/0/all/0/1\">Marc Rigter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacerda_B/0/1/0/all/0/1\">Bruno Lacerda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hawes_N/0/1/0/all/0/1\">Nick Hawes</a>",
          "description": "Offline reinforcement learning (RL) aims to find near-optimal policies from\nlogged data without further environment interaction. Model-based algorithms,\nwhich learn a model of the environment from the dataset and perform\nconservative policy optimisation within that model, have emerged as a promising\napproach to this problem. In this work, we present Robust Adversarial\nModel-Based Offline RL (RAMBO), a novel approach to model-based offline RL. To\nachieve conservatism, we formulate the problem as a two-player zero sum game\nagainst an adversarial environment model. The model is trained minimise the\nvalue function while still accurately predicting the transitions in the\ndataset, forcing the policy to act conservatively in areas not covered by the\ndataset. To approximately solve the two-player game, we alternate between\noptimising the policy and optimising the model adversarially. The problem\nformulation that we address is theoretically grounded, resulting in a PAC\nperformance guarantee and a pessimistic value function which lower bounds the\nvalue function in the true environment. We evaluate our approach on widely\nstudied offline RL benchmarks, and demonstrate that our approach achieves state\nof the art performance.",
          "link": "http://arxiv.org/abs/2204.12581",
          "publishedOn": "2022-04-28T01:16:07.702Z",
          "wordCount": 612,
          "title": "RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning. (arXiv:2204.12581v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12587",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_M/0/1/0/all/0/1\">Mithun Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1\">Somnath Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Animesh Mukherjee</a>",
          "description": "Social media platforms often act as breeding grounds for various forms of\ntrolling or malicious content targeting users or communities. One way of\ntrolling users is by creating memes, which in most cases unites an image with a\nshort piece of text embedded on top of it. The situation is more complex for\nmultilingual(e.g., Tamil) memes due to the lack of benchmark datasets and\nmodels. We explore several models to detect Troll memes in Tamil based on the\nshared task, \"Troll Meme Classification in DravidianLangTech2022\" at ACL-2022.\nWe observe while the text-based model MURIL performs better for Non-troll meme\nclassification, the image-based model VGG16 performs better for Troll-meme\nclassification. Further fusing these two modalities help us achieve stable\noutcomes in both classes. Our fusion model achieved a 0.561 weighted average F1\nscore and ranked second in this task.",
          "link": "http://arxiv.org/abs/2204.12587",
          "publishedOn": "2022-04-28T01:16:07.696Z",
          "wordCount": 587,
          "title": "hate-alert@DravidianLangTech-ACL2022: Ensembling Multi-Modalities for Tamil TrollMeme Classification. (arXiv:2204.12587v1 [cs.MM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12586",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Guo_B/0/1/0/all/0/1\">Binjie Guo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zheng_H/0/1/0/all/0/1\">Hanyu Zheng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Huang_H/0/1/0/all/0/1\">Huan Huang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jiang_H/0/1/0/all/0/1\">Haohan Jiang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_X/0/1/0/all/0/1\">Xiaodan Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Guan_N/0/1/0/all/0/1\">Naiyu Guan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zuo_Y/0/1/0/all/0/1\">Yanming Zuo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_Y/0/1/0/all/0/1\">Yicheng Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yang_H/0/1/0/all/0/1\">Hengfu Yang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_X/0/1/0/all/0/1\">Xuhua Wang</a>",
          "description": "Theoretically, the accuracy of computational models in predicting\ncompound-protein binding affinities (CPAs) could be improved by the\nintroduction of protein 3D structure information. However, most of these models\nstill suffer from a low accuracy due to the lack of an efficient approach to\nencode informative protein features. The major challenge is how to combine the\nmulti-modal information such as the residue sequence of the protein, residue\natom coordinates and the torsion angles. To tackle this problem, we develop\nFast Evolutional Attention and Thoroughgoing-graph Neural Networks (FeatNN) to\nfacilitate the application of protein 3D structure information for predicting\nCPAs. Specifically, we established a novel end-to-end architecture to jointly\nembed torsion matrix, discrete distance matrix, and sequence information of\nprotein and extract compound features with deep graph convolution layers. In\naddition, a new pairwise mapping attention mechanism is introduced to\ncomprehensively learn potential interaction information between proteins and\ncompounds. FeatNN considerably outperforms various state-of-the-art baselines\nin CPA prediction with the Pearson value elevated by about 35.7%. Thus, FeatNN\nprovides an outstanding method for highly accurate CPA prediction and\nfacilitates high-throughput virtual screening of drug candidates.",
          "link": "http://arxiv.org/abs/2204.12586",
          "publishedOn": "2022-04-28T01:16:07.680Z",
          "wordCount": 648,
          "title": "Protein 3D structure-based neural networks highly improve the accuracy in compound-protein binding affinity prediction. (arXiv:2204.12586v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12561",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jayawardana_V/0/1/0/all/0/1\">Vindula Jayawardana</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_C/0/1/0/all/0/1\">Cathy Wu</a>",
          "description": "Signalized intersections in arterial roads result in persistent vehicle\nidling and excess accelerations, contributing to fuel consumption and CO2\nemissions. There has thus been a line of work studying eco-driving control\nstrategies to reduce fuel consumption and emission levels at intersections.\nHowever, methods to devise effective control strategies across a variety of\ntraffic settings remain elusive. In this paper, we propose a reinforcement\nlearning (RL) approach to learn effective eco-driving control strategies. We\nanalyze the potential impact of a learned strategy on fuel consumption, CO2\nemission, and travel time and compare with naturalistic driving and model-based\nbaselines. We further demonstrate the generalizability of the learned policies\nunder mixed traffic scenarios. Simulation results indicate that scenarios with\n100% penetration of connected autonomous vehicles (CAV) may yield as high as\n18% reduction in fuel consumption and 25% reduction in CO2 emission levels\nwhile even improving travel speed by 20%. Furthermore, results indicate that\neven 25% CAV penetration can bring at least 50% of the total fuel and emission\nreduction benefits.",
          "link": "http://arxiv.org/abs/2204.12561",
          "publishedOn": "2022-04-28T01:16:07.674Z",
          "wordCount": 611,
          "title": "Learning Eco-Driving Strategies at Signalized Intersections. (arXiv:2204.12561v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gitiaux_X/0/1/0/all/0/1\">Xavier Gitiaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangwala_H/0/1/0/all/0/1\">Huzefa Rangwala</a>",
          "description": "To avoid discriminatory uses of their data, organizations can learn to map\nthem into a representation that filters out information related to sensitive\nattributes. However, all existing methods in fair representation learning\ngenerate a fairness-information trade-off. To achieve different points on the\nfairness-information plane, one must train different models. In this paper, we\nfirst demonstrate that fairness-information trade-offs are fully characterized\nby rate-distortion trade-offs. Then, we use this key result and propose SoFaiR,\na single shot fair representation learning method that generates with one\ntrained model many points on the fairness-information plane. Besides its\ncomputational saving, our single-shot approach is, to the extent of our\nknowledge, the first fair representation learning method that explains what\ninformation is affected by changes in the fairness / distortion properties of\nthe representation. Empirically, we find on three datasets that SoFaiR achieves\nsimilar fairness-information trade-offs as its multi-shot counterparts.",
          "link": "http://arxiv.org/abs/2204.12556",
          "publishedOn": "2022-04-28T01:16:07.668Z",
          "wordCount": 573,
          "title": "SoFaiR: Single Shot Fair Representation Learning. (arXiv:2204.12556v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stander_L/0/1/0/all/0/1\">Liezl Stander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woolway_M/0/1/0/all/0/1\">Matthew Woolway</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zyl_T/0/1/0/all/0/1\">Terence L. Van Zyl</a>",
          "description": "Chemical plant design and optimisation have proven challenging due to the\ncomplexity of these real-world systems. The resulting complexity translates\ninto high computational costs for these systems' mathematical formulations and\nsimulation models. Research has illustrated the benefits of using machine\nlearning surrogate models as substitutes for computationally expensive models\nduring optimisation. This paper extends recent research into optimising\nchemical plant design and operation. The study further explores Surrogate\nAssisted Genetic Algorithms (SA-GA) in more complex variants of the original\nplant design and optimisation problems, such as the inclusion of parallel and\nfeedback components. The novel extension to the original algorithm proposed in\nthis study, Surrogate Assisted NSGA-\\Romannum{2} (SA-NSGA), was tested on a\npopular literature case, the Pressure Swing Adsorption (PSA) system. We further\nprovide extensive experimentation, comparing various meta-heuristic\noptimisation techniques and numerous machine learning models as surrogates. The\nresults for both sets of systems illustrate the benefits of using Genetic\nAlgorithms as an optimisation framework for complex chemical plant system\ndesign and optimisation for both single and multi-objective scenarios. We\nconfirm that Random Forest surrogate assisted Evolutionary Algorithms can be\nscaled to increasingly complex chemical systems with parallel and feedback\ncomponents. We further find that combining a Genetic Algorithm framework with\nMachine Learning Surrogate models as a substitute for long-running simulation\nmodels yields significant computational efficiency improvements, 1.7 - 1.84\ntimes speedup for the increased complexity examples and a 2.7 times speedup for\nthe Pressure Swing Adsorption system.",
          "link": "http://arxiv.org/abs/2204.12585",
          "publishedOn": "2022-04-28T01:16:07.663Z",
          "wordCount": 695,
          "title": "Surrogate Assisted Evolutionary Multi-objective Optimisation applied to a Pressure Swing Adsorption system. (arXiv:2204.12585v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boggess_K/0/1/0/all/0/1\">Kayla Boggess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraus_S/0/1/0/all/0/1\">Sarit Kraus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Lu Feng</a>",
          "description": "Advances in multi-agent reinforcement learning(MARL) enable sequential\ndecision making for a range of exciting multi-agent applications such as\ncooperative AI and autonomous driving. Explaining agent decisions are crucial\nfor improving system transparency, increasing user satisfaction, and\nfacilitating human-agent collaboration. However, existing works on explainable\nreinforcement learning mostly focus on the single-agent setting and are not\nsuitable for addressing challenges posed by multi-agent environments. We\npresent novel methods to generate two types of policy explanations for MARL:\n(i) policy summarization about the agent cooperation and task sequence, and\n(ii) language explanations to answer queries about agent behavior. Experimental\nresults on three MARL domains demonstrate the scalability of our methods. A\nuser study shows that the generated explanations significantly improve user\nperformance and increase subjective ratings on metrics such as user\nsatisfaction.",
          "link": "http://arxiv.org/abs/2204.12568",
          "publishedOn": "2022-04-28T01:16:07.578Z",
          "wordCount": 572,
          "title": "Toward Policy Explanations for Multi-Agent Reinforcement Learning. (arXiv:2204.12568v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1\">Kaushik Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaur_M/0/1/0/all/0/1\">Manas Gaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit Sheth</a>",
          "description": "Improving the performance and natural language explanations of deep learning\nalgorithms is a priority for adoption by humans in the real world. In several\ndomains, such as healthcare, such technology has significant potential to\nreduce the burden on humans by providing quality assistance at scale. However,\ncurrent methods rely on the traditional pipeline of predicting labels from\ndata, thus completely ignoring the process and guidelines used to obtain the\nlabels. Furthermore, post hoc explanations on the data to label prediction\nusing explainable AI (XAI) models, while satisfactory to computer scientists,\nleave much to be desired to the end-users due to lacking explanations of the\nprocess in terms of human-understandable concepts. We \\textit{introduce},\n\\textit{formalize}, and \\textit{develop} a novel Artificial Intelligence (A)\nparadigm -- Process Knowledge-infused Learning (PK-iL). PK-iL utilizes a\nstructured process knowledge that explicitly explains the underlying prediction\nprocess that makes sense to end-users. The qualitative human evaluation\nconfirms through a annotator agreement of 0.72, that humans are understand\nexplanations for the predictions. PK-iL also performs competitively with the\nstate-of-the-art (SOTA) baselines.",
          "link": "http://arxiv.org/abs/2204.12560",
          "publishedOn": "2022-04-28T01:16:07.507Z",
          "wordCount": 609,
          "title": "Process Knowledge-infused Learning for Suicidality Assessment on Social Media. (arXiv:2204.12560v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_M/0/1/0/all/0/1\">Mithun Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1\">Somnath Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Animesh Mukherjee</a>",
          "description": "Abusive language is a growing concern in many social media platforms.\nRepeated exposure to abusive speech has created physiological effects on the\ntarget users. Thus, the problem of abusive language should be addressed in all\nforms for online peace and safety. While extensive research exists in abusive\nspeech detection, most studies focus on English. Recently, many smearing\nincidents have occurred in India, which provoked diverse forms of abusive\nspeech in online space in various languages based on the geographic location.\nTherefore it is essential to deal with such malicious content. In this paper,\nto bridge the gap, we demonstrate a large-scale analysis of multilingual\nabusive speech in Indic languages. We examine different interlingual transfer\nmechanisms and observe the performance of various multilingual models for\nabusive speech detection for eight different Indic languages. We also\nexperiment to show how robust these models are on adversarial attacks. Finally,\nwe conduct an in-depth error analysis by looking into the models' misclassified\nposts across various settings. We have made our code and models public for\nother researchers.",
          "link": "http://arxiv.org/abs/2204.12543",
          "publishedOn": "2022-04-28T01:16:07.502Z",
          "wordCount": 632,
          "title": "Data Bootstrapping Approaches to Improve Low Resource Abusive Language Detection for Indic Languages. (arXiv:2204.12543v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12536",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Evangelou_N/0/1/0/all/0/1\">Nikolaos Evangelou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dietrich_F/0/1/0/all/0/1\">Felix Dietrich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chiavazzo_E/0/1/0/all/0/1\">Eliodoro Chiavazzo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lehmberg_D/0/1/0/all/0/1\">Daniel Lehmberg</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meila_M/0/1/0/all/0/1\">Marina Meila</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kevrekidis_I/0/1/0/all/0/1\">Ioannis G. Kevrekidis</a>",
          "description": "We introduce a data-driven approach to building reduced dynamical models\nthrough manifold learning; the reduced latent space is discovered using\nDiffusion Maps (a manifold learning technique) on time series data. A second\nround of Diffusion Maps on those latent coordinates allows the approximation of\nthe reduced dynamical models. This second round enables mapping the latent\nspace coordinates back to the full ambient space (what is called lifting); it\nalso enables the approximation of full state functions of interest in terms of\nthe reduced coordinates. In our work, we develop and test three different\nreduced numerical simulation methodologies, either through pre-tabulation in\nthe latent space and integration on the fly or by going back and forth between\nthe ambient space and the latent space. The data-driven latent space simulation\nresults, based on the three different approaches, are validated through (a) the\nlatent space observation of the full simulation through the Nystr\\\"om Extension\nformula, or through (b) lifting the reduced trajectory back to the full ambient\nspace, via Latent Harmonics. Latent space modeling often involves additional\nregularization to favor certain properties of the space over others, and the\nmapping back to the ambient space is then constructed mostly independently from\nthese properties; here, we use the same data-driven approach to construct the\nlatent space and then map back to the ambient space.",
          "link": "http://arxiv.org/abs/2204.12536",
          "publishedOn": "2022-04-28T01:16:07.474Z",
          "wordCount": 682,
          "title": "Double Diffusion Maps and their Latent Harmonics for Scientific Computations in Latent Space. (arXiv:2204.12536v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12526",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Hassan_S/0/1/0/all/0/1\">Syeda Sakira Hassan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mangayil_R/0/1/0/all/0/1\">Rahul Mangayil</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Aho_T/0/1/0/all/0/1\">Tommi Aho</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yli_Harja_O/0/1/0/all/0/1\">Olli Yli-Harja</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Karp_M/0/1/0/all/0/1\">Matti Karp</a>",
          "description": "In this paper, we utilize a machine learning approach to identify the\nsignificant pathways for c-di-GMP signaling proteins. The dataset involves gene\ncounts from 12 pathways and 5 essential c-di-GMP binding domains for 1024\nbacterial genomes. Two novel approaches, Least absolute shrinkage and selection\noperator (Lasso) and Random forests, have been applied for analyzing and\nmodeling the dataset. Both approaches show that bacterial chemotaxis is the\nmost essential pathway for c-di-GMP encoding domains. Though popular for\nfeature selection, the strong regularization of Lasso method fails to associate\nany pathway to MshE domain. Results from the analysis may help to understand\nand emphasize the supporting pathways involved in bacterial cellulose\nproduction. These findings demonstrate the need for a chassis to restrict the\nbehavior or functionality by deactivating the selective pathways in cellulose\nproduction.",
          "link": "http://arxiv.org/abs/2204.12526",
          "publishedOn": "2022-04-28T01:16:07.459Z",
          "wordCount": 600,
          "title": "Identification of feasible pathway information for c-di-GMP binding proteins in cellulose production. (arXiv:2204.12526v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12541",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dwivedi_C/0/1/0/all/0/1\">Chaitanya Dwivedi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nofallah_S/0/1/0/all/0/1\">Shima Nofallah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pouryahya_M/0/1/0/all/0/1\">Maryam Pouryahya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Iyer_J/0/1/0/all/0/1\">Janani Iyer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Leidal_K/0/1/0/all/0/1\">Kenneth Leidal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chung_C/0/1/0/all/0/1\">Chuhan Chung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Watkins_T/0/1/0/all/0/1\">Timothy Watkins</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Billin_A/0/1/0/all/0/1\">Andrew Billin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Myers_R/0/1/0/all/0/1\">Robert Myers</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abel_J/0/1/0/all/0/1\">John Abel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Behrooz_A/0/1/0/all/0/1\">Ali Behrooz</a>",
          "description": "In pathology, tissue samples are assessed using multiple staining techniques\nto enhance contrast in unique histologic features. In this paper, we introduce\na multimodal CNN-GNN based graph fusion approach that leverages complementary\ninformation from multiple non-registered histopathology images to predict\npathologic scores. We demonstrate this approach in nonalcoholic steatohepatitis\n(NASH) by predicting CRN fibrosis stage and NAFLD Activity Score (NAS). Primary\nassessment of NASH typically requires liver biopsy evaluation on two\nhistological stains: Trichrome (TC) and hematoxylin and eosin (H&E). Our\nmultimodal approach learns to extract complementary information from TC and H&E\ngraphs corresponding to each stain while simultaneously learning an optimal\npolicy to combine this information. We report up to 20% improvement in\npredicting fibrosis stage and NAS component grades over single-stain modeling\napproaches, measured by computing linearly weighted Cohen's kappa between\nmachine-derived vs. pathologist consensus scores. Broadly, this paper\ndemonstrates the value of leveraging diverse pathology images for improved\nML-powered histologic assessment.",
          "link": "http://arxiv.org/abs/2204.12541",
          "publishedOn": "2022-04-28T01:16:07.454Z",
          "wordCount": 620,
          "title": "Multi stain graph fusion for multimodal integration in pathology. (arXiv:2204.12541v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khodja_H/0/1/0/all/0/1\">Hichem Ammar Khodja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boudjeniba_O/0/1/0/all/0/1\">Oussama Boudjeniba</a>",
          "description": "Many neural-based recommender systems were proposed in recent years and part\nof them used Generative Adversarial Networks (GAN) to model user-item\ninteractions. However, the exploration of Wasserstein GAN with Gradient Penalty\n(WGAN-GP) on recommendation has received relatively less scrutiny. In this\npaper, we focus on two questions: 1- Can we successfully apply WGAN-GP on\nrecommendation and does this approach give an advantage compared to the best\nGAN models? 2- Are GAN-based recommender systems relevant? To answer the first\nquestion, we propose a recommender system based on WGAN-GP called CFWGAN-GP\nwhich is founded on a previous model (CFGAN). We successfully applied our\nmethod on real-world datasets on the top-k recommendation task and the\nempirical results show that it is competitive with state-of-the-art GAN\napproaches, but we found no evidence of significant advantage of using WGAN-GP\ninstead of the original GAN, at least from the accuracy point of view. As for\nthe second question, we conduct a simple experiment in which we show that a\nwell-tuned conceptually simpler method outperforms GAN-based models by a\nconsiderable margin, questioning the use of such models.",
          "link": "http://arxiv.org/abs/2204.12527",
          "publishedOn": "2022-04-28T01:16:07.114Z",
          "wordCount": 633,
          "title": "Application of WGAN-GP in recommendation and Questioning the relevance of GAN-based approaches. (arXiv:2204.12527v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shiye Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Changsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Ye Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoren Wang</a>",
          "description": "In this paper, we explore the problem of deep multi-view subspace clustering\nframework from an information-theoretic point of view. We extend the\ntraditional information bottleneck principle to learn common information among\ndifferent views in a self-supervised manner, and accordingly establish a new\nframework called Self-supervised Information Bottleneck based Multi-view\nSubspace Clustering (SIB-MSC). Inheriting the advantages from information\nbottleneck, SIB-MSC can learn a latent space for each view to capture common\ninformation among the latent representations of different views by removing\nsuperfluous information from the view itself while retaining sufficient\ninformation for the latent representations of other views. Actually, the latent\nrepresentation of each view provides a kind of self-supervised signal for\ntraining the latent representations of other views. Moreover, SIB-MSC attempts\nto learn the other latent space for each view to capture the view-specific\ninformation by introducing mutual information based regularization terms, so as\nto further improve the performance of multi-view subspace clustering. To the\nbest of our knowledge, this is the first work to explore information bottleneck\nfor multi-view subspace clustering. Extensive experiments on real-world\nmulti-view data demonstrate that our method achieves superior performance over\nthe related state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2204.12496",
          "publishedOn": "2022-04-28T01:16:07.075Z",
          "wordCount": 628,
          "title": "Self-Supervised Information Bottleneck for Deep Multi-View Subspace Clustering. (arXiv:2204.12496v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eloul_S/0/1/0/all/0/1\">Shaltiel Eloul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silavong_F/0/1/0/all/0/1\">Fran Silavong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamthe_S/0/1/0/all/0/1\">Sanket Kamthe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgiadis_A/0/1/0/all/0/1\">Antonios Georgiadis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1\">Sean J. Moran</a>",
          "description": "Federated learning reduces the risk of information leakage, but remains\nvulnerable to attacks. We investigate how several neural network design\ndecisions can defend against gradients inversion attacks. We show that\noverlapping gradients provides numerical resistance to gradient inversion on\nthe highly vulnerable dense layer. Specifically, we propose to leverage\nbatching to maximise mixing of gradients by choosing an appropriate loss\nfunction and drawing identical labels. We show that otherwise it is possible to\ndirectly recover all vectors in a mini-batch without any numerical optimisation\ndue to the de-mixing nature of the cross entropy loss. To accurately assess\ndata recovery, we introduce an absolute variation distance (AVD) metric for\ninformation leakage in images, derived from total variation. In contrast to\nstandard metrics, e.g. Mean Squared Error or Structural Similarity Index, AVD\noffers a continuous metric for extracting information in noisy images. Finally,\nour empirical results on information recovery from various inversion attacks\nand training performance supports our defense strategies. These strategies are\nalso shown to be useful for deep convolutional neural networks such as LeNET\nfor image recognition. We hope that this study will help guide the development\nof further strategies that achieve a trustful federation policy.",
          "link": "http://arxiv.org/abs/2204.12495",
          "publishedOn": "2022-04-28T01:16:07.024Z",
          "wordCount": 666,
          "title": "Enhancing Privacy against Inversion Attacks in Federated Learning by using Mixing Gradients Strategies. (arXiv:2204.12495v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1\">Guangyi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Qaraghuli_Y/0/1/0/all/0/1\">Yasir Al-Qaraghuli</a>",
          "description": "Artificial Intelligence (AI) has found its applications in a variety of\nenvironments ranging from data science to cybersecurity. AI helps break through\nthe limitations of traditional algorithms and provides more efficient and\nflexible methods for solving problems. In this paper, we focus on the\napplications of artificial intelligence in authentication, which is used in a\nwide range of scenarios including facial recognition to access buildings,\nkeystroke dynamics to unlock smartphones. With the emerging AI-assisted\nauthentication schemes, our comprehensive survey provides an overall\nunderstanding on a high level, which paves the way for future research in this\narea. In contrast to other relevant surveys, our research is the first of its\nkind to focus on the roles of AI in authentication.",
          "link": "http://arxiv.org/abs/2204.12492",
          "publishedOn": "2022-04-28T01:16:06.934Z",
          "wordCount": 561,
          "title": "AI-Assisted Authentication: State of the Art, Taxonomy and Future Roadmap. (arXiv:2204.12492v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12493",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1\">Shangchao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1\">Xiangyang Xue</a>",
          "description": "Federated Learning (FL) has recently made significant progress as a new\nmachine learning paradigm for privacy protection. Due to the high communication\ncost of traditional FL, one-shot federated learning is gaining popularity as a\nway to reduce communication cost between clients and the server. Most of the\nexisting one-shot FL methods are based on Knowledge Distillation; however,\ndistillation based approach requires an extra training phase and depends on\npublicly available data sets. In this work, we consider a novel and challenging\nsetting: performing a single round of parameter aggregation on the local models\nwithout server-side training on a public data set. In this new setting, we\npropose an effective algorithm for Model Aggregation via Exploring Common\nHarmonized Optima (MA-Echo), which iteratively updates the parameters of all\nlocal models to bring them close to a common low-loss area on the loss surface,\nwithout harming performance on their own data sets at the same time. Compared\nto the existing methods, MA-Echo can work well even in extremely non-identical\ndata distribution settings where the support categories of each local model\nhave no overlapped labels with those of the others. We conduct extensive\nexperiments on two popular image classification data sets to compare the\nproposed method with existing methods and demonstrate the effectiveness of\nMA-Echo, which clearly outperforms the state-of-the-arts.",
          "link": "http://arxiv.org/abs/2204.12493",
          "publishedOn": "2022-04-28T01:16:06.881Z",
          "wordCount": 646,
          "title": "One-shot Federated Learning without Server-side Training. (arXiv:2204.12493v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.01670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mason_E/0/1/0/all/0/1\">Eric Mason</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mhaskar_H/0/1/0/all/0/1\">Hrushikesh Mhaskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_A/0/1/0/all/0/1\">Adam Guo</a>",
          "description": "A recent paper (Neural Networks, {\\bf 132} (2020), 253-268) introduces a\nstraightforward and simple kernel based approximation for manifold learning\nthat does not require the knowledge of anything about the manifold, except for\nits dimension. In this paper, we examine how the pointwise error in\napproximation using least squares optimization based on similarly localized\nkernels depends upon the data characteristics and deteriorates as one goes away\nfrom the training data. The theory is presented with an abstract localized\nkernel, which can utilize any prior knowledge about the data being located on\nan unknown sub-manifold of a known manifold.\n\nWe demonstrate the performance of our approach using a publicly available\nmicro-Doppler data set, and investigate the use of different preprocessing\nmeasures, kernels, and manifold dimensions. Specifically, it is shown that the\nlocalized kernel introduced in the above mentioned paper when used with PCA\ncomponents leads to a near-competitive performance to deep neural networks, and\noffers significant improvements in training speed and memory requirements. To\ndemonstrate the fact that our methods are agnostic to the domain knowledge, we\nexamine the classification problem in a simple video data set.",
          "link": "http://arxiv.org/abs/2110.01670",
          "publishedOn": "2022-04-23T00:53:50.495Z",
          "wordCount": null,
          "title": "A manifold learning approach for gesture recognition from micro-Doppler radar measurements. (arXiv:2110.01670v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.10510",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ovsianas_A/0/1/0/all/0/1\">Andrius Ovsianas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fernandes_D/0/1/0/all/0/1\">David Fernandes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">Mark Girolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lawrence_N/0/1/0/all/0/1\">Neil D. Lawrence</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nusken_N/0/1/0/all/0/1\">Nikolas N&#xfc;sken</a>",
          "description": "In this work we explore a new framework for approximate Bayesian inference in\nlarge datasets based on stochastic control (i.e. Schr\\\"odinger bridges). We\nadvocate stochastic control as a finite time and low variance alternative to\npopular steady-state methods such as stochastic gradient Langevin dynamics\n(SGLD). Furthermore, we discuss and adapt the existing theoretical guarantees\nof this framework and establish connections to already existing VI routines in\nSDE-based models.",
          "link": "http://arxiv.org/abs/2111.10510",
          "publishedOn": "2022-04-23T00:53:50.493Z",
          "wordCount": null,
          "title": "Bayesian Learning via Neural Schr\\\"odinger-F\\\"ollmer Flows. (arXiv:2111.10510v8 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ivanov_O/0/1/0/all/0/1\">Oleksandr Ivanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molander_K/0/1/0/all/0/1\">Karin Molander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunne_R/0/1/0/all/0/1\">Robert Dunne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Stephen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masek_K/0/1/0/all/0/1\">Kevin Masek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_E/0/1/0/all/0/1\">Erica Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lisa Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Travers_D/0/1/0/all/0/1\">Debbie Travers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brecher_D/0/1/0/all/0/1\">Deena Brecher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delaney_D/0/1/0/all/0/1\">Deb Delaney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montgomery_K/0/1/0/all/0/1\">Kyla Montgomery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reilly_C/0/1/0/all/0/1\">Christian Reilly</a>",
          "description": "Sepsis is a life-threatening condition with organ dysfunction and is a\nleading cause of death and critical illness worldwide. Accurate detection of\nsepsis during emergency department triage would allow early initiation of lab\nanalysis, antibiotic administration, and other sepsis treatment protocols. The\npurpose of this study was to determine whether EHR data can be extracted and\nsynthesized with the latest machine learning algorithms (KATE Sepsis) and\nclinical natural language processing to produce accurate sepsis models, and\ncompare KATE Sepsis performance with existing sepsis screening protocols, such\nas SIRS and qSOFA. A machine learning model (KATE Sepsis) was developed using\npatient encounters with triage data from 16 participating hospitals. KATE\nSepsis, SIRS, standard screening (SIRS with source of infection) and qSOFA were\ntested in three settings. Cohort-A was a retrospective analysis on medical\nrecords from a single Site 1. Cohort-B was a prospective analysis of Site 1.\nCohort-C was a retrospective analysis on Site 1 with 15 additional sites.\nAcross all cohorts, KATE Sepsis demonstrates an AUC of 0.94-0.963 with\n73-74.87% TPR and 3.76-7.17% FPR. Standard screening demonstrates an AUC of\n0.682-0.726 with 39.39-51.19% TPR and 2.9-6.02% FPR. The qSOFA protocol\ndemonstrates an AUC of 0.544-0.56, with 10.52-13.18% TPR and 1.22-1.68% FPR.\nFor severe sepsis, across all cohorts, KATE Sepsis demonstrates an AUC of\n0.935-0.972 with 70-82.26% TPR and 4.64-8.62% FPR. For septic shock, across all\ncohorts, KATE Sepsis demonstrates an AUC of 0.96-0.981 with 85.71-89.66% TPR\nand 4.85-8.8% FPR. SIRS, standard screening, and qSOFA demonstrate low AUC and\nTPR for severe sepsis and septic shock detection. KATE Sepsis provided\nsubstantially better sepsis detection performance in triage than commonly used\nscreening protocols.",
          "link": "http://arxiv.org/abs/2204.07657",
          "publishedOn": "2022-04-23T00:53:50.488Z",
          "wordCount": null,
          "title": "Accurate detection of sepsis at ED triage using machine learning with clinical natural language processing. (arXiv:2204.07657v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hassanin_M/0/1/0/all/0/1\">Mohammed Hassanin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_S/0/1/0/all/0/1\">Saeed Anwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radwan_I/0/1/0/all/0/1\">Ibrahim Radwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad S Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1\">Ajmal Mian</a>",
          "description": "Inspired by the human cognitive system, attention is a mechanism that\nimitates the human cognitive awareness about specific information, amplifying\ncritical details to focus more on the essential aspects of data. Deep learning\nhas employed attention to boost performance for many applications.\nInterestingly, the same attention design can suit processing different data\nmodalities and can easily be incorporated into large networks. Furthermore,\nmultiple complementary attention mechanisms can be incorporated in one network.\nHence, attention techniques have become extremely attractive. However, the\nliterature lacks a comprehensive survey specific to attention techniques to\nguide researchers in employing attention in their deep models. Note that,\nbesides being demanding in terms of training data and computational resources,\ntransformers only cover a single category in self-attention out of the many\ncategories available. We fill this gap and provide an in-depth survey of 50\nattention techniques categorizing them by their most prominent features. We\ninitiate our discussion by introducing the fundamental concepts behind the\nsuccess of attention mechanism. Next, we furnish some essentials such as the\nstrengths and limitations of each attention category, describe their\nfundamental building blocks, basic formulations with primary usage, and\napplications specifically for computer vision. We also discuss the challenges\nand open questions related to attention mechanism in general. Finally, we\nrecommend possible future research directions for deep attention.",
          "link": "http://arxiv.org/abs/2204.07756",
          "publishedOn": "2022-04-23T00:53:50.486Z",
          "wordCount": null,
          "title": "Visual Attention Methods in Deep Learning: An In-Depth Survey. (arXiv:2204.07756v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jingxuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beurer_Kellner_L/0/1/0/all/0/1\">Luca Beurer-Kellner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Deep learning has recently achieved initial success in program analysis tasks\nsuch as bug detection. Lacking real bugs, most existing works construct\ntraining and test data by injecting synthetic bugs into correct programs.\nDespite achieving high test accuracy (e.g. >90%), the resulting bug detectors\nare found to be surprisingly unusable in practice, i.e., <10% precision when\nused to scan real software repositories. In this work, we argue that this\nmassive performance difference is caused by distribution shift, i.e., a\nfundamental mismatch between the real bug distribution and the synthetic bug\ndistribution used to train and evaluate the detectors. To address this key\nchallenge, we propose to train a bug detector in two phases, first on a\nsynthetic bug distribution to adapt the model to the bug detection domain, and\nthen on a real bug distribution to drive the model towards the real\ndistribution. During these two phases, we leverage a multi-task hierarchy,\nfocal loss, and contrastive learning to further boost performance. We evaluate\nour approach extensively on three widely studied bug types, for which we\nconstruct new datasets carefully designed to capture the real bug distribution.\nThe results demonstrate that our approach is practically effective and\nsuccessfully mitigates the distribution shift: our learned detectors are highly\nperformant on both our constructed test set and the latest version of open\nsource repositories.",
          "link": "http://arxiv.org/abs/2204.10049",
          "publishedOn": "2022-04-23T00:53:50.485Z",
          "wordCount": null,
          "title": "On Distribution Shift in Learning-based Bug Detectors. (arXiv:2204.10049v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Meng Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qian Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_F/0/1/0/all/0/1\">Fei Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojuan Ma</a>",
          "description": "Persuading people to change their opinions is a common practice in online\ndiscussion forums on topics ranging from political campaigns to relationship\nconsultation. Enhancing people's ability to write persuasive arguments could\nnot only practice their critical thinking and reasoning but also contribute to\nthe effectiveness and civility in online communication. It is, however, not an\neasy task in online discussion settings where written words are the primary\ncommunication channel. In this paper, we derived four design goals for a tool\nthat helps users improve the persuasiveness of arguments in online discussions\nthrough a survey with 123 online forum users and interviews with five debating\nexperts. To satisfy these design goals, we analyzed and built a labeled dataset\nof fine-grained persuasive strategies (i.e., logos, pathos, ethos, and\nevidence) in 164 arguments with high ratings on persuasiveness from\nChangeMyView, a popular online discussion forum. We then designed an\ninteractive visual system, Persua, which provides example-based guidance on\npersuasive strategies to enhance the persuasiveness of arguments. In\nparticular, the system constructs portfolios of arguments based on different\npersuasive strategies applied to a given discussion topic. It then presents\nconcrete examples based on the difference between the portfolios of user input\nand high-quality arguments in the dataset. A between-subjects study shows\nsuggestive evidence that Persua encourages users to submit more times for\nfeedback and helps users improve more on the persuasiveness of their arguments\nthan a baseline system. Finally, a set of design considerations was summarized\nto guide future intelligent systems that improve the persuasiveness in text.",
          "link": "http://arxiv.org/abs/2204.07741",
          "publishedOn": "2022-04-23T00:53:50.484Z",
          "wordCount": null,
          "title": "Persua: A Visual Interactive System to Enhance the Persuasiveness of Arguments in Online Discussion. (arXiv:2204.07741v2 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.13322",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jiaguo Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yuming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Menghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haofeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H.S. Torr</a>",
          "description": "Learning to hash pictures a list-wise sorting problem. Its testing metrics,\ne.g., mean-average precision, count on a sorted candidate list ordered by\npair-wise code similarity. However, scarcely does one train a deep hashing\nmodel with the sorted results end-to-end because of the non-differentiable\nnature of the sorting operation. This inconsistency in the objectives of\ntraining and test may lead to sub-optimal performance since the training loss\noften fails to reflect the actual retrieval metric. In this paper, we tackle\nthis problem by introducing Naturally-Sorted Hashing (NSH). We sort the Hamming\ndistances of samples' hash codes and accordingly gather their latent\nrepresentations for self-supervised training. Thanks to the recent advances in\ndifferentiable sorting approximations, the hash head receives gradients from\nthe sorter so that the hash encoder can be optimized along with the training\nprocedure. Additionally, we describe a novel Sorted Noise-Contrastive\nEstimation (SortedNCE) loss that selectively picks positive and negative\nsamples for contrastive learning, which allows NSH to mine data semantic\nrelations during training in an unsupervised manner. Our extensive experiments\nshow the proposed NSH model significantly outperforms the existing unsupervised\nhashing methods on three benchmarked datasets.",
          "link": "http://arxiv.org/abs/2201.13322",
          "publishedOn": "2022-04-23T00:53:50.483Z",
          "wordCount": null,
          "title": "Learning to Hash Naturally Sorts. (arXiv:2201.13322v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.13514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guillaume_A/0/1/0/all/0/1\">Antoine Guillaume</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vrain_C/0/1/0/all/0/1\">Christel Vrain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wael_E/0/1/0/all/0/1\">Elloumi Wael</a>",
          "description": "Shapelet-based algorithms are widely used for time series classification\nbecause of their ease of interpretation, but they are currently outperformed by\nrecent state-of-the-art approaches. We present a new formulation of time series\nshapelets including the notion of dilation, and we introduce a new shapelet\nfeature to enhance their discriminative power for classification. Experiments\nperformed on 112 datasets show that our method improves on the state-of-the-art\nshapelet algorithm, and achieves comparable accuracy to recent state-of-the-art\napproaches, without sacrificing neither scalability, nor interpretability.",
          "link": "http://arxiv.org/abs/2109.13514",
          "publishedOn": "2022-04-23T00:53:50.482Z",
          "wordCount": null,
          "title": "Random Dilated Shapelet Transform: A New Approach for Time Series Shapelets. (arXiv:2109.13514v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1807.06919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Resnick_C/0/1/0/all/0/1\">Cinjon Resnick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1\">Roberta Raileanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1\">Sanyam Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peysakhovich_A/0/1/0/all/0/1\">Alexander Peysakhovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>",
          "description": "Model-free reinforcement learning (RL) requires a large number of trials to\nlearn a good policy, especially in environments with sparse rewards. We explore\na method to improve the sample efficiency when we have access to\ndemonstrations. Our approach, Backplay, uses a single demonstration to\nconstruct a curriculum for a given task. Rather than starting each training\nepisode in the environment's fixed initial state, we start the agent near the\nend of the demonstration and move the starting point backwards during the\ncourse of training until we reach the initial state. Our contributions are that\nwe analytically characterize the types of environments where Backplay can\nimprove training speed, demonstrate the effectiveness of Backplay both in large\ngrid worlds and a complex four player zero-sum game (Pommerman), and show that\nBackplay compares favorably to other competitive methods known to improve\nsample efficiency. This includes reward shaping, behavioral cloning, and\nreverse curriculum generation.",
          "link": "http://arxiv.org/abs/1807.06919",
          "publishedOn": "2022-04-23T00:53:50.481Z",
          "wordCount": null,
          "title": "Backplay: \"Man muss immer umkehren\". (arXiv:1807.06919v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10277",
          "author": "<a href=\"http://arxiv.org/find/hep-ex/1/au:+Valsecchi_D/0/1/0/all/0/1\">Davide Valsecchi</a>",
          "description": "The reconstruction of electrons and photons in CMS depends on topological\nclustering of the energy deposited by an incident particle in different\ncrystals of the electromagnetic calorimeter (ECAL). These clusters are formed\nby aggregating neighbouring crystals according to the expected topology of an\nelectromagnetic shower in the ECAL. The presence of upstream material\n(beampipe, tracker and support structures) causes electrons and photons to\nstart showering before reaching the calorimeter. This effect, combined with the\n3.8T CMS magnetic field, leads to energy being spread in several clusters\naround the primary one. It is essential to recover the energy contained in\nthese satellite clusters in order to achieve the best possible energy\nresolution for physics analyses. Historically satellite clusters have been\nassociated to the primary cluster using a purely topological algorithm which\ndoes not attempt to remove spurious energy deposits from additional pileup\ninteractions (PU). The performance of this algorithm is expected to degrade\nduring LHC Run 3 (2022+) because of the larger average PU levels and the\nincreasing levels of noise due to the ageing of the ECAL detector. New methods\nare being investigated that exploit state-of-the-art deep learning\narchitectures like Graph Neural Networks (GNN) and self-attention algorithms.\nThese more sophisticated models improve the energy collection and are more\nresilient to PU and noise, helping to preserve the electron and photon energy\nresolution achieved during LHC Runs 1 and 2. This work will cover the\nchallenges of training the models as well the opportunity that this new\napproach offers to unify the ECAL energy measurement with the particle\nidentification steps used in the global CMS photon and electron reconstruction.",
          "link": "http://arxiv.org/abs/2204.10277",
          "publishedOn": "2022-04-23T00:53:50.480Z",
          "wordCount": null,
          "title": "Deep learning techniques for energy clustering in the CMS ECAL. (arXiv:2204.10277v1 [hep-ex])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maumela_J/0/1/0/all/0/1\">Joshua Tshifhiwa Maumela</a>",
          "description": "Dissolved Gas-in-oil analysis (DGA) is used to monitor the condition of\nbushings on large power transformers. There are different techniques used in\ndetermining the conditions from the data collected, but in this work the\nArtificial Intelligence techniques are investigated. This work investigates\nwhich gases in DGA are related to each other and which ones are important for\nmaking decisions. When the related and crucial gases are determined, the other\ngases are discarded thereby reducing the number of attributes in DGA. Hence a\nfurther investigation is done to see how these new datasets influence the\nperformance of the classifiers used to classify the DGA of full attributes. The\nclassifiers used in these experiments were Backpropagation Neural Networks\n(BPNN) and Support Vector Machines (SVM) whereas the Principal Component\nAnalysis (PCA), Rough Set (RS), Incremental Granular Ranking (GR++) and\nDecision Trees (DT) were used to reduce the attributes of the dataset. The\nparameters used when training the BPNN and SVM classifiers are kept fixed to\ncreate a controlled test environment when investigating the effects of reducing\nthe number of gases. This work further introduced a new classifier that can\nhandle high dimension dataset and noisy dataset, Rough Neural Network (RNN).",
          "link": "http://arxiv.org/abs/2204.10193",
          "publishedOn": "2022-04-23T00:53:50.475Z",
          "wordCount": null,
          "title": "Condition Monitoring of Transformer Bushings Using Computational Intelligence. (arXiv:2204.10193v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kogkalidis_K/0/1/0/all/0/1\">Konstantinos Kogkalidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moortgat_M/0/1/0/all/0/1\">Michael Moortgat</a>",
          "description": "The syntactic categories of categorial grammar formalisms are structured\nunits made of smaller, indivisible primitives, bound together by the underlying\ngrammar's category formation rules. In the trending approach of constructive\nsupertagging, neural models are increasingly made aware of the internal\ncategory structure, which in turn enables them to more reliably predict rare\nand out-of-vocabulary categories, with significant implications for grammars\npreviously deemed too complex to find practical use. In this work, we revisit\nconstructive supertagging from a graph-theoretic perspective, and propose a\nframework based on heterogeneous dynamic graph convolutions aimed at exploiting\nthe distinctive structure of a supertagger's output space. We test our approach\non a number of categorial grammar datasets spanning different languages and\ngrammar formalisms, achieving substantial improvements over previous state of\nthe art scores. Code will be made available at\nhttps://github.com/konstantinosKokos/dynamic-graph-supertagging",
          "link": "http://arxiv.org/abs/2203.12235",
          "publishedOn": "2022-04-23T00:53:50.448Z",
          "wordCount": null,
          "title": "Geometry-Aware Supertagging with Heterogeneous Dynamic Convolutions. (arXiv:2203.12235v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_W/0/1/0/all/0/1\">Weijie Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhai Wang</a>",
          "description": "Industrial control systems (ICSs) are facing increasing cyber-physical\nattacks that can cause catastrophes in the physical system. Efficient anomaly\ndetection models in the industrial sensor networks are essential for enhancing\nICS reliability and security, due to the sensor data is related to the\noperational state of the ICS. Considering the limited availability of computing\nresources, this paper proposes a hybrid anomaly detection approach in\ncloud-edge collaboration industrial sensor networks. The hybrid approach\nconsists of sensor data detection models deployed at the edges and a sensor\ndata analysis model deployed in the cloud. The sensor data detection model\nbased on Gaussian and Bayesian algorithms can detect the anomalous sensor data\nin real-time and upload them to the cloud for further analysis, filtering the\nnormal sensor data and reducing traffic load. The sensor data analysis model\nbased on Graph convolutional network, Residual algorithm and Long short-term\nmemory network (GCRL) can effectively extract the spatial and temporal features\nand then identify the attack precisely. The proposed hybrid anomaly detection\napproach is evaluated using a benchmark dataset and baseline anomaly detection\nmodels. The experimental results show that the proposed approach can achieve an\noverall 11.19% increase in Recall and an impressive 14.29% improvement in\nF1-score, compared with the existing models.",
          "link": "http://arxiv.org/abs/2204.09942",
          "publishedOn": "2022-04-23T00:53:50.447Z",
          "wordCount": null,
          "title": "Hybrid Cloud-Edge Collaborative Data Anomaly Detection in Industrial Sensor Networks. (arXiv:2204.09942v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.09139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pilault_J/0/1/0/all/0/1\">Jonathan Pilault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhattami_A/0/1/0/all/0/1\">Amine Elhattami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "Multi-Task Learning (MTL) networks have emerged as a promising method for\ntransferring learned knowledge across different tasks. However, MTL must deal\nwith challenges such as: overfitting to low resource tasks, catastrophic\nforgetting, and negative task transfer, or learning interference. Often, in\nNatural Language Processing (NLP), a separate model per task is needed to\nobtain the best performance. However, many fine-tuning approaches are both\nparameter inefficient, i.e., potentially involving one new model per task, and\nhighly susceptible to losing knowledge acquired during pretraining. We propose\na novel Transformer architecture consisting of a new conditional attention\nmechanism as well as a set of task-conditioned modules that facilitate weight\nsharing. Through this construction (a hypernetwork adapter), we achieve more\nefficient parameter sharing and mitigate forgetting by keeping half of the\nweights of a pretrained model fixed. We also use a new multi-task data sampling\nstrategy to mitigate the negative effects of data imbalance across tasks. Using\nthis approach, we are able to surpass single task fine-tuning methods while\nbeing parameter and data efficient (using around 66% of the data for weight\nupdates). Compared to other BERT Large methods on GLUE, our 8-task model\nsurpasses other Adapter methods by 2.8% and our 24-task model outperforms by\n0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger\nvariant of our single multi-task model approach performs competitively across\n26 NLP tasks and yields state-of-the-art results on a number of test and\ndevelopment sets. Our code is publicly available at\nhttps://github.com/CAMTL/CA-MTL.",
          "link": "http://arxiv.org/abs/2009.09139",
          "publishedOn": "2022-04-23T00:53:50.440Z",
          "wordCount": null,
          "title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data. (arXiv:2009.09139v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bennett_M/0/1/0/all/0/1\">Michele Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balusu_J/0/1/0/all/0/1\">Jaya Balusu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayes_K/0/1/0/all/0/1\">Karin Hayes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleczyk_E/0/1/0/all/0/1\">Ewa J. Kleczyk</a>",
          "description": "The COVID-19 pandemic has dramatically changed how healthcare is delivered to\npatients, how patients interact with healthcare providers, and how healthcare\ninformation is disseminated to both healthcare providers and patients.\nAnalytical models that were trained and tested pre-pandemic may no longer be\nperforming up to expectations, providing unreliable and irrelevant learning\n(ML) models given that ML depends on the basic principle that what happened in\nthe past are likely to repeat in the future. ML faced to two important\ndegradation principles, concept drift, when the underlying properties and\ncharacteristics of the variables change and data drift, when the data\ndistributions, probabilities, co-variates, and other variable relationships\nchange, both of which are prime culprits of model failure. Therefore, detecting\nand diagnosing drift in existing models is something that has become an\nimperative. And perhaps even more important is a shift in our mindset towards a\nconscious recognition that drift is inevitable, and model building must\nincorporate intentional resilience, the ability to offset and recover quickly\nfrom failure, and proactive robustness, avoiding failure by developing models\nthat are less vulnerable to drift and disruption.",
          "link": "http://arxiv.org/abs/2204.10227",
          "publishedOn": "2022-04-23T00:53:50.426Z",
          "wordCount": null,
          "title": "The Silent Problem -- Machine Learning Model Failure -- How to Diagnose and Fix Ailing Machine Learning Models. (arXiv:2204.10227v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_M/0/1/0/all/0/1\">Maxime Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verdier_J/0/1/0/all/0/1\">Jean-Charles Verdier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nkashama_D/0/1/0/all/0/1\">D&#x27;Jeff K. Nkashama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frappier_M/0/1/0/all/0/1\">Marc Frappier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tardif_P/0/1/0/all/0/1\">Pierre-Martin Tardif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabanza_F/0/1/0/all/0/1\">Froduald Kabanza</a>",
          "description": "Anomaly detection has many applications ranging from bank-fraud detection and\ncyber-threat detection to equipment maintenance and health monitoring. However,\nchoosing a suitable algorithm for a given application remains a challenging\ndesign decision, often informed by the literature on anomaly detection\nalgorithms. We extensively reviewed twelve of the most popular unsupervised\nanomaly detection methods. We observed that, so far, they have been compared\nusing inconsistent protocols - the choice of the class of interest or the\npositive class, the split of training and test data, and the choice of\nhyperparameters - leading to ambiguous evaluations. This observation led us to\ndefine a coherent evaluation protocol which we then used to produce an updated\nand more precise picture of the relative performance of the twelve methods on\nfive widely used tabular datasets. While our evaluation cannot pinpoint a\nmethod that outperforms all the others on all datasets, it identifies those\nthat stand out and revise misconceived knowledge about their relative\nperformances.",
          "link": "http://arxiv.org/abs/2204.09825",
          "publishedOn": "2022-04-23T00:53:50.405Z",
          "wordCount": null,
          "title": "A Revealing Large-Scale Evaluation of Unsupervised Anomaly Detection Algorithms. (arXiv:2204.09825v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allot_A/0/1/0/all/0/1\">Alexis Allot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leaman_R/0/1/0/all/0/1\">Robert Leaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dogan_R/0/1/0/all/0/1\">Rezarta Islamaj Do&#x11f;an</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jingcheng Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1\">Li Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kai_W/0/1/0/all/0/1\">Wang Kai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuefu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagherzadeh_P/0/1/0/all/0/1\">Parsa Bagherzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergler_S/0/1/0/all/0/1\">Sabine Bergler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatnagar_A/0/1/0/all/0/1\">Aakash Bhatnagar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhavsar_N/0/1/0/all/0/1\">Nidhir Bhavsar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yung-Chun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Sheng-Jie Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1\">Wentai Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavchioski_I/0/1/0/all/0/1\">Ilija Tavchioski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1\">Shubo Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otmakhova_Y/0/1/0/all/0/1\">Yulia Otmakhova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yepes_A/0/1/0/all/0/1\">Antonio Jimeno Yepes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Honghan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dufour_R/0/1/0/all/0/1\">Richard Dufour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labrak_Y/0/1/0/all/0/1\">Yanis Labrak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_N/0/1/0/all/0/1\">Niladri Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tandon_K/0/1/0/all/0/1\">Kushagri Tandon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laleye_F/0/1/0/all/0/1\">Fr&#xe9;jus Laleye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakotoson_L/0/1/0/all/0/1\">Lo&#xef;c Rakotoson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chersoni_E/0/1/0/all/0/1\">Emmanuele Chersoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinghang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedrich_A/0/1/0/all/0/1\">Annemarie Friedrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujari_S/0/1/0/all/0/1\">Subhash Chandra Pujari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chizhikova_M/0/1/0/all/0/1\">Mariia Chizhikova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivadasan_N/0/1/0/all/0/1\">Naveen Sivadasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivadasan_N/0/1/0/all/0/1\">Naveen Sivadasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>",
          "description": "The COVID-19 pandemic has been severely impacting global society since\nDecember 2019. Massive research has been undertaken to understand the\ncharacteristics of the virus and design vaccines and drugs. The related\nfindings have been reported in biomedical literature at a rate of about 10,000\narticles on COVID-19 per month. Such rapid growth significantly challenges\nmanual curation and interpretation. For instance, LitCovid is a literature\ndatabase of COVID-19-related articles in PubMed, which has accumulated more\nthan 200,000 articles with millions of accesses each month by users worldwide.\nOne primary curation task is to assign up to eight topics (e.g., Diagnosis and\nTreatment) to the articles in LitCovid. Despite the continuing advances in\nbiomedical text mining methods, few have been dedicated to topic annotations in\nCOVID-19 literature. To close the gap, we organized the BioCreative LitCovid\ntrack to call for a community effort to tackle automated topic annotation for\nCOVID-19 literature. The BioCreative LitCovid dataset, consisting of over\n30,000 articles with manually reviewed topics, was created for training and\ntesting. It is one of the largest multilabel classification datasets in\nbiomedical scientific literature. 19 teams worldwide participated and made 80\nsubmissions in total. Most teams used hybrid systems based on transformers. The\nhighest performing submissions achieved 0.8875, 0.9181, and 0.9394 for macro\nF1-score, micro F1-score, and instance-based F1-score, respectively. The level\nof participation and results demonstrate a successful track and help close the\ngap between dataset curation and method development. The dataset is publicly\navailable via https://ftp.ncbi.nlm.nih.gov/pub/lu/LitCovid/biocreative/ for\nbenchmarking and further development.",
          "link": "http://arxiv.org/abs/2204.09781",
          "publishedOn": "2022-04-23T00:53:50.402Z",
          "wordCount": null,
          "title": "Multi-label classification for biomedical literature: an overview of the BioCreative VII LitCovid Track for COVID-19 literature topic annotations. (arXiv:2204.09781v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09831",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Cheng_L/0/1/0/all/0/1\">Lixue Cheng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sun_J/0/1/0/all/0/1\">Jiace Sun</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Miller_T/0/1/0/all/0/1\">Thomas F. Miller III</a>",
          "description": "We introduce an unsupervised clustering algorithm to improve training\nefficiency and accuracy in predicting energies using molecular-orbital-based\nmachine learning (MOB-ML). This work determines clusters via the Gaussian\nmixture model (GMM) in an entirely automatic manner and simplifies an earlier\nsupervised clustering approach [J. Chem. Theory Comput., 15, 6668 (2019)] by\neliminating both the necessity for user-specified parameters and the training\nof an additional classifier. Unsupervised clustering results from GMM have the\nadvantage of accurately reproducing chemically intuitive groupings of frontier\nmolecular orbitals and having improved performance with an increasing number of\ntraining examples. The resulting clusters from supervised or unsupervised\nclustering is further combined with scalable Gaussian process regression (GPR)\nor linear regression (LR) to learn molecular energies accurately by generating\na local regression model in each cluster. Among all four combinations of\nregressors and clustering methods, GMM combined with scalable exact Gaussian\nprocess regression (GMM/GPR) is the most efficient training protocol for\nMOB-ML. The numerical tests of molecular energy learning on thermalized\ndatasets of drug-like molecules demonstrate the improved accuracy,\ntransferability, and learning efficiency of GMM/GPR over not only other\ntraining protocols for MOB-ML, i.e., supervised regression-clustering combined\nwith GPR(RC/GPR) and GPR without clustering. GMM/GPR also provide the best\nmolecular energy predictions compared with the ones from literature on the same\nbenchmark datasets. With a lower scaling, GMM/GPR has a 10.4-fold speedup in\nwall-clock training time compared with scalable exact GPR with a training size\nof 6500 QM7b-T molecules.",
          "link": "http://arxiv.org/abs/2204.09831",
          "publishedOn": "2022-04-23T00:53:50.402Z",
          "wordCount": null,
          "title": "Accurate Molecular-Orbital-Based Machine Learning Energies via Unsupervised Clustering of Chemical Space. (arXiv:2204.09831v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_V/0/1/0/all/0/1\">Vaidehi Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Ziyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Samson Zhou</a>",
          "description": "Online learning with expert advice is a fundamental problem of sequential\nprediction. In this problem, the algorithm has access to a set of $n$ \"experts\"\nwho make predictions on each day. The goal on each day is to process these\npredictions, and make a prediction with the minimum cost. After making a\nprediction, the algorithm sees the actual outcome on that day, updates its\nstate, and then moves on to the next day. An algorithm is judged by how well it\ndoes compared to the best expert in the set.\n\nThe classical algorithm for this problem is the multiplicative weights\nalgorithm. However, every application, to our knowledge, relies on storing\nweights for every expert, and uses $\\Omega(n)$ memory. There is little work on\nunderstanding the memory required to solve the online learning with expert\nadvice problem, or run standard sequential prediction algorithms, in natural\nstreaming models, which is especially important when the number of experts, as\nwell as the number of days on which the experts make predictions, is large.\n\nWe initiate the study of the learning with expert advice problem in the\nstreaming setting, and show lower and upper bounds. Our lower bound for i.i.d.,\nrandom order, and adversarial order streams uses a reduction to a custom-built\nproblem using a novel masking technique, to show a smooth trade-off for regret\nversus memory. Our upper bounds show novel ways to run standard sequential\nprediction algorithms in rounds on small \"pools\" of experts, thus reducing the\nnecessary memory. For random-order streams, we show that our upper bound is\ntight up to low order terms. We hope that these results and techniques will\nhave broad applications in online learning, and can inspire algorithms based on\nstandard sequential prediction techniques, like multiplicative weights, for a\nwide range of other problems in the memory-constrained setting.",
          "link": "http://arxiv.org/abs/2204.09837",
          "publishedOn": "2022-04-23T00:53:50.401Z",
          "wordCount": null,
          "title": "Memory Bounds for the Experts Problem. (arXiv:2204.09837v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09934",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_R/0/1/0/all/0/1\">Rongjie Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lam_M/0/1/0/all/0/1\">Max W. Y. Lam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ren_Y/0/1/0/all/0/1\">Yi Ren</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhou Zhao</a>",
          "description": "Denoising diffusion probabilistic models (DDPMs) have recently achieved\nleading performances in many generative tasks. However, the inherited iterative\nsampling process costs hindered their applications to speech synthesis. This\npaper proposes FastDiff, a fast conditional diffusion model for high-quality\nspeech synthesis. FastDiff employs a stack of time-aware location-variable\nconvolutions of diverse receptive field patterns to efficiently model long-term\ntime dependencies with adaptive conditions. A noise schedule predictor is also\nadopted to reduce the sampling steps without sacrificing the generation\nquality. Based on FastDiff, we design an end-to-end text-to-speech synthesizer,\nFastDiff-TTS, which generates high-fidelity speech waveforms without any\nintermediate feature (e.g., Mel-spectrogram). Our evaluation of FastDiff\ndemonstrates the state-of-the-art results with higher-quality (MOS 4.28) speech\nsamples. Also, FastDiff enables a sampling speed of 58x faster than real-time\non a V100 GPU, making diffusion models practically applicable to speech\nsynthesis deployment for the first time. We further show that FastDiff\ngeneralized well to the mel-spectrogram inversion of unseen speakers, and\nFastDiff-TTS outperformed other competing methods in end-to-end text-to-speech\nsynthesis. Audio samples are available at \\url{https://FastDiff.github.io/}.",
          "link": "http://arxiv.org/abs/2204.09934",
          "publishedOn": "2022-04-23T00:53:50.401Z",
          "wordCount": null,
          "title": "FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis. (arXiv:2204.09934v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09975",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1\">Jun Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Ting Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1\">Jieping Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xian Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingsong Chen</a>",
          "description": "Due to the prosperity of Artificial Intelligence (AI) techniques, more and\nmore backdoors are designed by adversaries to attack Deep Neural Networks\n(DNNs).Although the state-of-the-art method Neural Attention Distillation (NAD)\ncan effectively erase backdoor triggers from DNNs, it still suffers from\nnon-negligible Attack Success Rate (ASR) together with lowered classification\nACCuracy (ACC), since NAD focuses on backdoor defense using attention features\n(i.e., attention maps) of the same order. In this paper, we introduce a novel\nbackdoor defense framework named Attention Relation Graph Distillation (ARGD),\nwhich fully explores the correlation among attention features with different\norders using our proposed Attention Relation Graphs (ARGs). Based on the\nalignment of ARGs between both teacher and student models during knowledge\ndistillation, ARGD can eradicate more backdoor triggers than NAD. Comprehensive\nexperimental results show that, against six latest backdoor attacks, ARGD\noutperforms NAD by up to 94.85% reduction in ASR, while ACC can be improved by\nup to 3.23%.",
          "link": "http://arxiv.org/abs/2204.09975",
          "publishedOn": "2022-04-23T00:53:50.393Z",
          "wordCount": null,
          "title": "Eliminating Backdoor Triggers for Deep Neural Networks Using Attention Relation Graph Distillation. (arXiv:2204.09975v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raheman_A/0/1/0/all/0/1\">Ali Raheman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolonin_A/0/1/0/all/0/1\">Anton Kolonin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fridkins_I/0/1/0/all/0/1\">Igors Fridkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ansari_I/0/1/0/all/0/1\">Ikram Ansari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishwas_M/0/1/0/all/0/1\">Mukul Vishwas</a>",
          "description": "In this paper, we explore the usability of different natural language\nprocessing models for the sentiment analysis of social media applied to\nfinancial market prediction, using the cryptocurrency domain as a reference. We\nstudy how the different sentiment metrics are correlated with the price\nmovements of Bitcoin. For this purpose, we explore different methods to\ncalculate the sentiment metrics from a text finding most of them not very\naccurate for this prediction task. We find that one of the models outperforms\nmore than 20 other public ones and makes it possible to fine-tune it\nefficiently given its interpretable nature. Thus we confirm that interpretable\nartificial intelligence and natural language processing methods might be more\nvaluable practically than non-explainable and non-interpretable ones. In the\nend, we analyse potential causal connections between the different sentiment\nmetrics and the price movements.",
          "link": "http://arxiv.org/abs/2204.10185",
          "publishedOn": "2022-04-23T00:53:50.392Z",
          "wordCount": null,
          "title": "Social Media Sentiment Analysis for Cryptocurrency Market Prediction. (arXiv:2204.10185v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1\">Tao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>",
          "description": "Contrastive learning is widely used for recommendation model learning, where\nselecting representative and informative negative samples is critical. Existing\nmethods usually focus on centralized data, where abundant and high-quality\nnegative samples are easy to obtain. However, centralized user data storage and\nexploitation may lead to privacy risks and concerns, while decentralized user\ndata on a single client can be too sparse and biased for accurate contrastive\nlearning. In this paper, we propose a federated contrastive learning method\nnamed FedCL for privacy-preserving recommendation, which can exploit\nhigh-quality negative samples for effective model training with privacy well\nprotected. We first infer user embeddings from local user data through the\nlocal model on each client, and then perturb them with local differential\nprivacy (LDP) before sending them to a central server for hard negative\nsampling. Since individual user embedding contains heavy noise due to LDP, we\npropose to cluster user embeddings on the server to mitigate the influence of\nnoise, and the cluster centroids are used to retrieve hard negative samples\nfrom the item pool. These hard negative samples are delivered to user clients\nand mixed with the observed negative samples from local data as well as\nin-batch negatives constructed from positive samples for federated model\ntraining. Extensive experiments on four benchmark datasets show FedCL can\nempower various recommendation methods in a privacy-preserving way.",
          "link": "http://arxiv.org/abs/2204.09850",
          "publishedOn": "2022-04-23T00:53:50.390Z",
          "wordCount": null,
          "title": "FedCL: Federated Contrastive Learning for Privacy-Preserving Recommendation. (arXiv:2204.09850v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10314",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wahed_M/0/1/0/all/0/1\">Muntasir Wahed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabassum_A/0/1/0/all/0/1\">Afrina Tabassum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lourentzou_I/0/1/0/all/0/1\">Ismini Lourentzou</a>",
          "description": "Contrastive learning has gained popularity as an effective self-supervised\nrepresentation learning technique. Several research directions improve\ntraditional contrastive approaches, e.g., prototypical contrastive methods\nbetter capture the semantic similarity among instances and reduce the\ncomputational burden by considering cluster prototypes or cluster assignments,\nwhile adversarial instance-wise contrastive methods improve robustness against\na variety of attacks. To the best of our knowledge, no prior work jointly\nconsiders robustness, cluster-wise semantic similarity and computational\nefficiency. In this work, we propose SwARo, an adversarial contrastive\nframework that incorporates cluster assignment permutations to generate\nrepresentative adversarial samples. We evaluate SwARo on multiple benchmark\ndatasets and against various white-box and black-box attacks, obtaining\nconsistent improvements over state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2204.10314",
          "publishedOn": "2022-04-23T00:53:50.389Z",
          "wordCount": null,
          "title": "Adversarial Contrastive Learning by Permuting Cluster Assignments. (arXiv:2204.10314v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.03892",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_B/0/1/0/all/0/1\">Bo Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1\">Shiping Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kaibo Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Tingwen Huang</a>",
          "description": "Differentiable architecture search has gradually become the mainstream\nresearch topic in the field of Neural Architecture Search (NAS) for its high\nefficiency compared with the early NAS (EA-based, RL-based) methods. Recent\ndifferentiable NAS also aims at further improving the search performance and\nreducing the GPU-memory consumption. However, these methods are no longer\nnaturally capable of tackling the non-differentiable objectives, e.g., energy,\nresource-constrained efficiency, and other metrics, let alone the\nmulti-objective search demands. Researches in the multi-objective NAS field\ntarget this but requires vast computational resources cause of the sole\noptimization of each candidate architecture. In light of this discrepancy, we\npropose the TND-NAS, which is with the merits of the high efficiency in\ndifferentiable NAS framework and the compatibility among non-differentiable\nmetrics in Multi-objective NAS. Under the differentiable NAS framework, with\nthe continuous relaxation of the search space, TND-NAS has the architecture\nparameters ($\\alpha$) been optimized in discrete space, while resorting to the\nprogressive search space shrinking by $\\alpha$. Our representative experiment\ntakes two objectives (Parameters, Accuracy) as an example, we achieve a series\nof high-performance compact architectures on CIFAR10 (1.09M/3.3\\%, 2.4M/2.95\\%,\n9.57M/2.54\\%) and CIFAR100 (2.46M/18.3\\%, 5.46/16.73\\%, 12.88/15.20\\%)\ndatasets. Favorably, compared with other multi-objective NAS methods, TND-NAS\nis less time-consuming (1.3 GPU-days on NVIDIA 1080Ti, 1/6 of that in\nNSGA-Net), and can be conveniently adapted to real-world NAS scenarios\n(resource-constrained, platform-specialized).",
          "link": "http://arxiv.org/abs/2111.03892",
          "publishedOn": "2022-04-23T00:53:50.384Z",
          "wordCount": null,
          "title": "TND-NAS: Towards Non-Differentiable Objectives in Differentiable Neural Architecture Search. (arXiv:2111.03892v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sang Michael Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Pretrained language models have achieved state-of-the-art performance when\nadapted to a downstream NLP task. However, theoretical analysis of these models\nis scarce and challenging since the pretraining and downstream tasks can be\nvery different. We propose an analysis framework that links the pretraining and\ndownstream tasks with an underlying latent variable generative model of text --\nthe downstream classifier must recover a function of the posterior distribution\nover the latent variables. We analyze head tuning (learning a classifier on top\nof the frozen pretrained model) and prompt tuning in this setting. The\ngenerative model in our analysis is either a Hidden Markov Model (HMM) or an\nHMM augmented with a latent memory component, motivated by long-term\ndependencies in natural language. We show that 1) under certain non-degeneracy\nconditions on the HMM, simple classification heads can solve the downstream\ntask, 2) prompt tuning obtains downstream guarantees with weaker non-degeneracy\nconditions, and 3) our recovery guarantees for the memory-augmented HMM are\nstronger than for the vanilla HMM because task-relevant information is easier\nto recover from the long-term memory. Experiments on synthetically generated\ndata from HMMs back our theoretical findings.",
          "link": "http://arxiv.org/abs/2106.09226",
          "publishedOn": "2022-04-23T00:53:50.371Z",
          "wordCount": 669,
          "title": "Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning. (arXiv:2106.09226v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.06377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alexander Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawamura_R/0/1/0/all/0/1\">Rina Kawamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiangru Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tae_J/0/1/0/all/0/1\">Jaesung Tae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Sally Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mizutani_T/0/1/0/all/0/1\">Tomoe Mizutani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>",
          "description": "Fast-developing fields such as Artificial Intelligence (AI) often outpace the\nefforts of encyclopedic sources such as Wikipedia, which either do not\ncompletely cover recently-introduced topics or lack such content entirely. As a\nresult, methods for automatically producing content are valuable tools to\naddress this information overload. We show that recent advances in pretrained\nlanguage modeling can be combined for a two-stage extractive and abstractive\napproach for Wikipedia lead paragraph generation. We extend this approach to\ngenerate longer Wikipedia-style summaries with sections and examine how such\nmethods struggle in this application through detailed studies with 100\nreference human-collected surveys. This is the first study on utilizing web\nresources for long Wikipedia-style summaries to the best of our knowledge.",
          "link": "http://arxiv.org/abs/2112.06377",
          "publishedOn": "2022-04-23T00:53:50.364Z",
          "wordCount": 602,
          "title": "Surfer100: Generating Surveys From Web Resources on Wikipedia-style. (arXiv:2112.06377v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.05329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_P/0/1/0/all/0/1\">Pritam Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1\">Ali Etemad</a>",
          "description": "We present CrissCross, a self-supervised framework for learning audio-visual\nrepresentations. A novel notion is introduced in our framework whereby in\naddition to learning the intra-modal and standard synchronous cross-modal\nrelations, CrissCross also learns asynchronous cross-modal relationships. We\nshow that by relaxing the temporal synchronicity between the audio and visual\nmodalities, the network learns strong generalized representations. Our\nexperiments show that strong augmentations for both audio and visual modalities\nwith relaxation of cross-modal temporal synchronicity optimize performance. To\npretrain our proposed framework, we use 3 different datasets with varying\nsizes, Kinetics-Sound, Kinetics400, and AudioSet. The learned representations\nare evaluated on a number of downstream tasks namely action recognition, sound\nclassification, and retrieval. CrissCross shows state-of-the-art performances\non action recognition (UCF101 and HMDB51) and sound classification (ESC50 and\nDCASE). The codes and pretrained models will be made publicly available.",
          "link": "http://arxiv.org/abs/2111.05329",
          "publishedOn": "2022-04-23T00:53:50.357Z",
          "wordCount": 610,
          "title": "Self-Supervised Audio-Visual Representation Learning with Relaxed Cross-Modal Synchronicity. (arXiv:2111.05329v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Renzhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zheyan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1\">Peng Cui</a>",
          "description": "Despite the remarkable performance that modern deep neural networks have\nachieved on independent and identically distributed (I.I.D.) data, they can\ncrash under distribution shifts. Most current evaluation methods for domain\ngeneralization (DG) adopt the leave-one-out strategy as a compromise on the\nlimited number of domains. We propose a large-scale benchmark with extensive\nlabeled domains named NICO++ along with more rational evaluation methods for\ncomprehensively evaluating DG algorithms. To evaluate DG datasets, we propose\ntwo metrics to quantify covariate shift and concept shift, respectively. Two\nnovel generalization bounds from the perspective of data construction are\nproposed to prove that limited concept shift and significant covariate shift\nfavor the evaluation capability for generalization. Through extensive\nexperiments, NICO++ shows its superior evaluation capability compared with\ncurrent DG datasets and its contribution in alleviating unfairness caused by\nthe leak of oracle knowledge in model selection.",
          "link": "http://arxiv.org/abs/2204.08040",
          "publishedOn": "2022-04-23T00:53:50.357Z",
          "wordCount": null,
          "title": "NICO++: Towards Better Benchmarking for Domain Generalization. (arXiv:2204.08040v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grillotti_L/0/1/0/all/0/1\">Luca Grillotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cully_A/0/1/0/all/0/1\">Antoine Cully</a>",
          "description": "Quality-Diversity algorithms provide efficient mechanisms to generate large\ncollections of diverse and high-performing solutions, which have shown to be\ninstrumental for solving downstream tasks. However, most of those algorithms\nrely on a behavioural descriptor to characterise the diversity that is\nhand-coded, hence requiring prior knowledge about the considered tasks. In this\nwork, we introduce Relevance-guided Unsupervised Discovery of Abilities; a\nQuality-Diversity algorithm that autonomously finds a behavioural\ncharacterisation tailored to the task at hand. In particular, our method\nintroduces a custom diversity metric that leads to higher densities of\nsolutions near the areas of interest in the learnt behavioural descriptor\nspace. We evaluate our approach on a simulated robotic environment, where the\nrobot has to autonomously discover its abilities based on its full sensory\ndata. We evaluated the algorithms on three tasks: navigation to random targets,\nmoving forward with a high velocity, and performing half-rolls. The\nexperimental results show that our method manages to discover collections of\nsolutions that are not only diverse, but also well-adapted to the considered\ndownstream task.",
          "link": "http://arxiv.org/abs/2204.09828",
          "publishedOn": "2022-04-23T00:53:50.322Z",
          "wordCount": null,
          "title": "Relevance-guided Unsupervised Discovery of Abilities with Quality-Diversity Algorithms. (arXiv:2204.09828v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Min Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Sadaf Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhengyuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Naixing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiang Xu</a>",
          "description": "Applying deep learning (DL) techniques in the electronic design automation\n(EDA) field has become a trending topic. Most solutions apply well-developed DL\nmodels to solve specific EDA problems. While demonstrating promising results,\nthey require careful model tuning for every problem. The fundamental question\non \"How to obtain a general and effective neural representation of circuits?\"\nhas not been answered yet. In this work, we take the first step towards solving\nthis problem. We propose DeepGate, a novel representation learning solution\nthat effectively embeds both logic function and structural information of a\ncircuit as vectors on each gate. Specifically, we propose transforming circuits\ninto unified and-inverter graph format for learning and using signal\nprobabilities as the supervision task in DeepGate. We then introduce a novel\ngraph neural network that uses strong inductive biases in practical circuits as\nlearning priors for signal probability prediction. Our experimental results\nshow the efficacy and generalization capability of DeepGate.",
          "link": "http://arxiv.org/abs/2111.14616",
          "publishedOn": "2022-04-23T00:53:50.322Z",
          "wordCount": null,
          "title": "DeepGate: Learning Neural Representations of Logic Gates. (arXiv:2111.14616v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balakrishnan_K/0/1/0/all/0/1\">Kaushik Balakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_D/0/1/0/all/0/1\">Devesh Upadhyay</a>",
          "description": "The task of 2D human pose estimation is challenging as the number of\nkeypoints is typically large (~ 17) and this necessitates the use of robust\nneural network architectures and training pipelines that can capture the\nrelevant features from the input image. These features are then aggregated to\nmake accurate heatmap predictions from which the final keypoints of human body\nparts can be inferred. Many papers in literature use CNN-based architectures\nfor the backbone, and/or combine it with a transformer, after which the\nfeatures are aggregated to make the final keypoint predictions [1]. In this\npaper, we consider the recently proposed Bottleneck Transformers [2], which\ncombine CNN and multi-head self attention (MHSA) layers effectively, and we\nintegrate it with a Transformer encoder and apply it to the task of 2D human\npose estimation. We consider different backbone architectures and pre-train\nthem using the DINO self-supervised learning method [3], this pre-training is\nfound to improve the overall prediction accuracy. We call our model BTranspose,\nand experiments show that on the COCO validation set, our model achieves an AP\nof 76.4, which is competitive with other methods such as [1] and has fewer\nnetwork parameters. Furthermore, we also present the dependencies of the final\npredicted keypoints on both the MHSA block and the Transformer encoder layers,\nproviding clues on the image sub-regions the network attends to at the mid and\nhigh levels.",
          "link": "http://arxiv.org/abs/2204.10209",
          "publishedOn": "2022-04-23T00:53:50.321Z",
          "wordCount": null,
          "title": "BTranspose: Bottleneck Transformers for Human Pose Estimation with Self-Supervised Pre-Training. (arXiv:2204.10209v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Richter_J/0/1/0/all/0/1\">Jasmine Richter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faion_F/0/1/0/all/0/1\">Florian Faion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_D/0/1/0/all/0/1\">Di Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Becker_P/0/1/0/all/0/1\">Paul Benedikt Becker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sielecki_P/0/1/0/all/0/1\">Piotr Sielecki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glaeser_C/0/1/0/all/0/1\">Claudius Glaeser</a>",
          "description": "In order to make autonomous driving a reality, artificial neural networks\nhave to work reliably in the open-world. However, the open-world is vast and\ncontinuously changing, so it is not technically feasible to collect and\nannotate training datasets which accurately represent this domain. Therefore,\nthere are always domain gaps between training datasets and the open-world which\nmust be understood. In this work, we investigate the domain gaps between\nhigh-resolution and low-resolution LiDAR sensors in object detection networks.\nUsing a unique dataset, which enables us to study sensor resolution domain gaps\nindependent of other effects, we show two distinct domain gaps - an inference\ndomain gap and a training domain gap. The inference domain gap is characterised\nby a strong dependence on the number of LiDAR points per object, while the\ntraining gap shows no such dependence. These fndings show that different\napproaches are required to close these inference and training domain gaps.",
          "link": "http://arxiv.org/abs/2204.10024",
          "publishedOn": "2022-04-23T00:53:50.320Z",
          "wordCount": null,
          "title": "Understanding the Domain Gap in LiDAR Object Detection Networks. (arXiv:2204.10024v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09947",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Anderlini_L/0/1/0/all/0/1\">Lucio Anderlini</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Barbetti_M/0/1/0/all/0/1\">Matteo Barbetti</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Derkach_D/0/1/0/all/0/1\">Denis Derkach</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kazeev_N/0/1/0/all/0/1\">Nikita Kazeev</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Maevskiy_A/0/1/0/all/0/1\">Artem Maevskiy</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mokhnenko_S/0/1/0/all/0/1\">Sergei Mokhnenko</a>",
          "description": "The increasing luminosities of future data taking at Large Hadron Collider\nand next generation collider experiments require an unprecedented amount of\nsimulated events to be produced. Such large scale productions demand a\nsignificant amount of valuable computing resources. This brings a demand to use\nnew approaches to event generation and simulation of detector responses. In\nthis paper, we discuss the application of generative adversarial networks\n(GANs) to the simulation of the LHCb experiment events. We emphasize main\npitfalls in the application of GANs and study the systematic effects in detail.\nThe presented results are based on the Geant4 simulation of the LHCb Cherenkov\ndetector.",
          "link": "http://arxiv.org/abs/2204.09947",
          "publishedOn": "2022-04-23T00:53:50.318Z",
          "wordCount": null,
          "title": "Towards Reliable Neural Generative Modeling of Detectors. (arXiv:2204.09947v1 [physics.ins-det])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.10460",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_B/0/1/0/all/0/1\">Boyang Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishwar_P/0/1/0/all/0/1\">Prakash Ishwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheutz_M/0/1/0/all/0/1\">Matthias Scheutz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aeron_S/0/1/0/all/0/1\">Shuchin Aeron</a>",
          "description": "Invariance principle-based methods, for example, Invariant Risk Minimization\n(IRM), have recently emerged as promising approaches for Domain Generalization\n(DG). Despite the promising theory, invariance principle-based approaches fail\nin common classification tasks due to the mixture of the true invariant\nfeatures and the spurious invariant features. In this paper, we propose a\nframework based on the conditional entropy minimization principle to filter out\nthe spurious invariant features leading to a new algorithm with a better\ngeneralization capability. We theoretically prove that under some particular\nassumptions, the representation function can precisely recover the true\ninvariant features. In addition, we also show that the proposed approach is\nclosely related to the well-known Information Bottleneck (IB) framework. Both\nthe theoretical and numerical results are provided to justify our approach.",
          "link": "http://arxiv.org/abs/2201.10460",
          "publishedOn": "2022-04-23T00:53:50.317Z",
          "wordCount": null,
          "title": "Conditional entropy minimization principle for learning domain invariant representation features. (arXiv:2201.10460v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jesson_A/0/1/0/all/0/1\">Andrew Jesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Douglas_A/0/1/0/all/0/1\">Alyson Douglas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manshausen_P/0/1/0/all/0/1\">Peter Manshausen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinshausen_N/0/1/0/all/0/1\">Nicolai Meinshausen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stier_P/0/1/0/all/0/1\">Philip Stier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalit_U/0/1/0/all/0/1\">Uri Shalit</a>",
          "description": "Estimating the effects of continuous-valued interventions from observational\ndata is critically important in fields such as climate science, healthcare, and\neconomics. Recent work focuses on designing neural-network architectures and\nregularization functions to allow for scalable estimation of average and\nindividual-level dose response curves from high-dimensional, large-sample data.\nSuch methodologies assume ignorability (all confounding variables are observed)\nand positivity (all levels of treatment can be observed for every unit\ndescribed by a given covariate value), which are especially challenged in the\ncontinuous treatment regime. Developing scalable sensitivity and uncertainty\nanalyses that allow us to understand the ignorance induced in our estimates\nwhen these assumptions are relaxed receives less attention. Here, we develop a\ncontinuous treatment-effect marginal sensitivity model (CMSM) and derive bounds\nthat agree with both the observed data and a researcher-defined level of hidden\nconfounding. We introduce a scalable algorithm to derive the bounds and\nuncertainty-aware deep models to efficiently estimate these bounds for\nhigh-dimensional, large-sample observational data. We validate our methods\nusing both synthetic and real-world experiments. For the latter, we work in\nconcert with climate scientists interested in evaluating the climatological\nimpacts of human emissions on cloud properties using satellite observations\nfrom the past 15 years: a finite-data problem known to be complicated by the\npresence of a multitude of unobserved confounders.",
          "link": "http://arxiv.org/abs/2204.10022",
          "publishedOn": "2022-04-23T00:53:50.316Z",
          "wordCount": null,
          "title": "Scalable Sensitivity and Uncertainty Analysis for Causal-Effect Estimates of Continuous-Valued Interventions. (arXiv:2204.10022v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.06662",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_P/0/1/0/all/0/1\">Pengzhou Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fukumizu_K/0/1/0/all/0/1\">Kenji Fukumizu</a>",
          "description": "NOTE: This preprint has a flawed theoretical formulation. Please avoid it and\nrefer to the ICLR22 publication https://openreview.net/forum?id=q7n2RngwOM.\nAlso, arXiv:2109.15062 contains some new ideas on unobserved Confounding.\n\nAs an important problem of causal inference, we discuss the identification\nand estimation of treatment effects under unobserved confounding. Representing\nthe confounder as a latent variable, we propose Intact-VAE, a new variant of\nvariational autoencoder (VAE), motivated by the prognostic score that is\nsufficient for identifying treatment effects. We theoretically show that, under\ncertain settings, treatment effects are identified by our model, and further,\nbased on the identifiability of our model (i.e., determinacy of\nrepresentation), our VAE is a consistent estimator with representation balanced\nfor treatment groups. Experiments on (semi-)synthetic datasets show\nstate-of-the-art performance under diverse settings.",
          "link": "http://arxiv.org/abs/2101.06662",
          "publishedOn": "2022-04-23T00:53:50.316Z",
          "wordCount": null,
          "title": "Intact-VAE: Estimating Treatment Effects under Unobserved Confounding. (arXiv:2101.06662v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yunho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chanyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwangbo_J/0/1/0/all/0/1\">Jemin Hwangbo</a>",
          "description": "For autonomous quadruped robot navigation in various complex environments, a\ntypical SOTA system is composed of four main modules -- mapper, global planner,\nlocal planner, and command-tracking controller -- in a hierarchical manner. In\nthis paper, we build a robust and safe local planner which is designed to\ngenerate a velocity plan to track a coarsely planned path from the global\nplanner. Previous works used waypoint-based methods (e.g.\nProportional-Differential control and pure pursuit) which simplify the path\ntracking problem to local point-goal navigation. However, they suffer from\nfrequent collisions in geometrically complex and narrow environments because of\ntwo reasons; the global planner uses a coarse and inaccurate model and the\nlocal planner is unable to track the global plan sufficiently well. Currently,\ndeep learning methods are an appealing alternative because they can learn\nsafety and path feasibility from experience more accurately. However, existing\ndeep learning methods are not capable of planning for a long horizon. In this\nwork, we propose a learning-based fully autonomous navigation framework\ncomposed of three innovative elements: a learned forward dynamics model (FDM),\nan online sampling-based model-predictive controller, and an informed\ntrajectory sampler (ITS). Using our framework, a quadruped robot can\nautonomously navigate in various complex environments without a collision and\ngenerate a smoother command plan compared to the baseline method. Furthermore,\nour method can reactively handle unexpected obstacles on the planned path and\navoid them. Project page\nhttps://awesomericky.github.io/projects/FDM_ITS_navigation/.",
          "link": "http://arxiv.org/abs/2204.08647",
          "publishedOn": "2022-04-23T00:53:50.315Z",
          "wordCount": null,
          "title": "Learning Forward Dynamics Model and Informed Trajectory Sampler for Safe Quadruped Navigation. (arXiv:2204.08647v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bandara_W/0/1/0/all/0/1\">Wele Gedara Chaminda Bandara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1\">Vishal M. Patel</a>",
          "description": "Remote-sensing (RS) Change Detection (CD) aims to detect \"changes of\ninterest\" from co-registered bi-temporal images. The performance of existing\ndeep supervised CD methods is attributed to the large amounts of annotated data\nused to train the networks. However, annotating large amounts of remote sensing\nimages is labor-intensive and expensive, particularly with bi-temporal images,\nas it requires pixel-wise comparisons by a human expert. On the other hand, we\noften have access to unlimited unlabeled multi-temporal RS imagery thanks to\never-increasing earth observation programs. In this paper, we propose a simple\nyet effective way to leverage the information from unlabeled bi-temporal images\nto improve the performance of CD approaches. More specifically, we propose a\nsemi-supervised CD model in which we formulate an unsupervised CD loss in\naddition to the supervised Cross-Entropy (CE) loss by constraining the output\nchange probability map of a given unlabeled bi-temporal image pair to be\nconsistent under the small random perturbations applied on the deep feature\ndifference map that is obtained by subtracting their latent feature\nrepresentations. Experiments conducted on two publicly available CD datasets\nshow that the proposed semi-supervised CD method can reach closer to the\nperformance of supervised CD even with access to as little as 10% of the\nannotated training data. Code available at https://github.com/wgcban/SemiCD",
          "link": "http://arxiv.org/abs/2204.08454",
          "publishedOn": "2022-04-23T00:53:50.313Z",
          "wordCount": null,
          "title": "Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images. (arXiv:2204.08454v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09790",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Galaz_Garcia_F/0/1/0/all/0/1\">Fernando Galaz-Garcia</a>, <a href=\"http://arxiv.org/find/math/1/au:+Papamichalis_M/0/1/0/all/0/1\">Marios Papamichalis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Turnbull_K/0/1/0/all/0/1\">Kathryn Turnbull</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lunagomez_S/0/1/0/all/0/1\">Simon Lunagomez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Airoldi_E/0/1/0/all/0/1\">Edoardo Airoldi</a>",
          "description": "We provide a general framework for constructing probability distributions on\nRiemannian manifolds, taking advantage of area-preserving maps and isometries.\nControl over distributions' properties, such as parameters, symmetry and\nmodality yield a family of flexible distributions that are straightforward to\nsample from, suitable for use within Monte Carlo algorithms and latent variable\nmodels, such as autoencoders. As an illustration, we empirically validate our\napproach by utilizing our proposed distributions within a variational\nautoencoder and a latent space network model. Finally, we take advantage of the\ngeneralized description of this framework to posit questions for future work.",
          "link": "http://arxiv.org/abs/2204.09790",
          "publishedOn": "2022-04-23T00:53:50.312Z",
          "wordCount": null,
          "title": "Wrapped Distributions on homogeneous Riemannian manifolds. (arXiv:2204.09790v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.01490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xudong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhirong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_L/0/1/0/all/0/1\">Long Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Stella X. Yu</a>",
          "description": "Pseudo-labels are confident predictions made on unlabeled target data by a\nclassifier trained on labeled source data. They are widely used for adapting a\nmodel to unlabeled data, e.g., in a semi-supervised learning setting.\n\nOur key insight is that pseudo-labels are naturally imbalanced due to\nintrinsic data similarity, even when a model is trained on balanced source data\nand evaluated on balanced target data. If we address this previously unknown\nimbalanced classification problem arising from pseudo-labels instead of\nground-truth training labels, we could remove model biases towards false\nmajorities created by pseudo-labels.\n\nWe propose a novel and effective debiased learning method with pseudo-labels,\nbased on counterfactual reasoning and adaptive margins: The former removes the\nclassifier response bias, whereas the latter adjusts the margin of each class\naccording to the imbalance of pseudo-labels. Validated by extensive\nexperimentation, our simple debiased learning delivers significant accuracy\ngains over the state-of-the-art on ImageNet-1K: 26% for semi-supervised\nlearning with 0.2% annotations and 9% for zero-shot learning. Our code is\navailable at: https://github.com/frank-xwang/debiased-pseudo-labeling.",
          "link": "http://arxiv.org/abs/2201.01490",
          "publishedOn": "2022-04-23T00:53:50.311Z",
          "wordCount": null,
          "title": "Debiased Learning from Naturally Imbalanced Pseudo-Labels. (arXiv:2201.01490v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10020",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Terashima_R/0/1/0/all/0/1\">Ryo Terashima</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yamamoto_R/0/1/0/all/0/1\">Ryuichi Yamamoto</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_E/0/1/0/all/0/1\">Eunwoo Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shirahata_Y/0/1/0/all/0/1\">Yuma Shirahata</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yoon_H/0/1/0/all/0/1\">Hyun-Wook Yoon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Jae-Min Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tachibana_K/0/1/0/all/0/1\">Kentaro Tachibana</a>",
          "description": "Data augmentation via voice conversion (VC) has been successfully applied to\nlow-resource expressive text-to-speech (TTS) when only neutral data for the\ntarget speaker are available. Although the quality of VC is crucial for this\napproach, it is challenging to learn a stable VC model because the amount of\ndata is limited in low-resource scenarios, and highly expressive speech has\nlarge acoustic variety. To address this issue, we propose a novel data\naugmentation method that combines pitch-shifting and VC techniques. Because\npitch-shift data augmentation enables the coverage of a variety of pitch\ndynamics, it greatly stabilizes training for both VC and TTS models, even when\nonly 1,000 utterances of the target speaker's neutral data are available.\nSubjective test results showed that a FastSpeech 2-based emotional TTS system\nwith the proposed method improved naturalness and emotional similarity compared\nwith conventional methods.",
          "link": "http://arxiv.org/abs/2204.10020",
          "publishedOn": "2022-04-23T00:53:50.310Z",
          "wordCount": null,
          "title": "Cross-Speaker Emotion Transfer for Low-Resource Text-to-Speech Using Non-Parallel Voice Conversion with Pitch-Shift Data Augmentation. (arXiv:2204.10020v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.10325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yongquan Yang</a>",
          "description": "Recent studies have demonstrated the effectiveness of the combination of\nmachine learning and logical reasoning in inventing advanced artificial\nintelligence technologies. One-step abductive multi-target learning (OSAMTL),\nan approach that only combines machine learning and logical reasoning in a\none-step balanced way, has as well shown its effectiveness in handling complex\nnoisy labels of a single noisy sample in medical histopathology whole slide\nimage analysis (MHWSIA). However, OSAMTL is not suitable for the situation\nwhere diverse noisy samples (DiNS) are provided for a learning task. In this\npaper, giving definition of DiNS, we propose one-step abductive multi-target\nlearning with DiNS (OSAMTL-DiNS) to expand the original OSAMTL to handle\ncomplex noisy labels of DiNS. Applying OSAMTL-DiNS to tumour segmentation for\nbreast cancer in MHWSIA, we show that OSAMTL-DiNS is able to enable various\nstate-of-the-art approaches for learning from noisy labels to achieve more\nrational predictions.",
          "link": "http://arxiv.org/abs/2110.10325",
          "publishedOn": "2022-04-23T00:53:50.275Z",
          "wordCount": 640,
          "title": "One-Step Abductive Multi-Target Learning with Diverse Noisy Samples: An Application to Tumour Segmentation for Breast Cancer. (arXiv:2110.10325v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10269",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Gibbs_J/0/1/0/all/0/1\">Joe Gibbs</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Holmes_Z/0/1/0/all/0/1\">Zo&#xeb; Holmes</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1\">Matthias C. Caro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ezzell_N/0/1/0/all/0/1\">Nicholas Ezzell</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1\">Hsin-Yuan Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sornborger_A/0/1/0/all/0/1\">Andrew T. Sornborger</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>",
          "description": "Much attention has been paid to dynamical simulation and quantum machine\nlearning (QML) independently as applications for quantum advantage, while the\npossibility of using QML to enhance dynamical simulations has not been\nthoroughly investigated. Here we develop a framework for using QML methods to\nsimulate quantum dynamics on near-term quantum hardware. We use generalization\nbounds, which bound the error a machine learning model makes on unseen data, to\nrigorously analyze the training data requirements of an algorithm within this\nframework. This provides a guarantee that our algorithm is resource-efficient,\nboth in terms of qubit and data requirements. Our numerics exhibit efficient\nscaling with problem size, and we simulate 20 times longer than Trotterization\non IBMQ-Bogota.",
          "link": "http://arxiv.org/abs/2204.10269",
          "publishedOn": "2022-04-23T00:53:50.269Z",
          "wordCount": 582,
          "title": "Dynamical simulation via quantum machine learning with provable generalization. (arXiv:2204.10269v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10231",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosales_Perez_A/0/1/0/all/0/1\">Alejandro Rosales-P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_S/0/1/0/all/0/1\">Salvador Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herrera_F/0/1/0/all/0/1\">Francisco Herrera</a>",
          "description": "Support vector machines (SVMs) are popular learning algorithms to deal with\nbinary classification problems. They traditionally assume equal\nmisclassification costs for each class; however, real-world problems may have\nan uneven class distribution. This article introduces EBCS-SVM: evolutionary\nbilevel cost-sensitive SVMs. EBCS-SVM handles imbalanced classification\nproblems by simultaneously learning the support vectors and optimizing the SVM\nhyperparameters, which comprise the kernel parameter and misclassification\ncosts. The resulting optimization problem is a bilevel problem, where the lower\nlevel determines the support vectors and the upper level the hyperparameters.\nThis optimization problem is solved using an evolutionary algorithm (EA) at the\nupper level and sequential minimal optimization (SMO) at the lower level. These\ntwo methods work in a nested fashion, that is, the optimal support vectors help\nguide the search of the hyperparameters, and the lower level is initialized\nbased on previous successful solutions. The proposed method is assessed using\n70 datasets of imbalanced classification and compared with several\nstate-of-the-art methods. The experimental results, supported by a Bayesian\ntest, provided evidence of the effectiveness of EBCS-SVM when working with\nhighly imbalanced datasets.",
          "link": "http://arxiv.org/abs/2204.10231",
          "publishedOn": "2022-04-23T00:53:50.262Z",
          "wordCount": 716,
          "title": "Handling Imbalanced Classification Problems With Support Vector Machines via Evolutionary Bilevel Optimization. (arXiv:2204.10231v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frigo_O/0/1/0/all/0/1\">Oriel Frigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_Gaffe_L/0/1/0/all/0/1\">Lucien Martin-Gaff&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wacongne_C/0/1/0/all/0/1\">Catherine Wacongne</a>",
          "description": "In this paper we present a new approach for feature fusion between RGB and\nLWIR Thermal images for the task of semantic segmentation for driving\nperception. We propose DooDLeNet, a double DeepLab architecture with\nspecialized encoder-decoders for thermal and color modalities and a shared\ndecoder for final segmentation. We combine two strategies for feature fusion:\nconfidence weighting and correlation weighting. We report state-of-the-art mean\nIoU results on the MF dataset.",
          "link": "http://arxiv.org/abs/2204.10266",
          "publishedOn": "2022-04-23T00:53:50.242Z",
          "wordCount": 523,
          "title": "DooDLeNet: Double DeepLab Enhanced Feature Fusion for Thermal-color Semantic Segmentation. (arXiv:2204.10266v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.08916",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ding_K/0/1/0/all/0/1\">Kexin Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_M/0/1/0/all/0/1\">Mu Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1\">Zichen Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1\">Qiao Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arnold_C/0/1/0/all/0/1\">Corey W. Arnold</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1\">Shaoting Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Metaxas_D/0/1/0/all/0/1\">Dimitri N. Metaxas</a>",
          "description": "Image-based characterization and disease understanding involve integrative\nanalysis of morphological, spatial, and topological information across\nbiological scales. The development of graph convolutional networks (GCNs) has\ncreated the opportunity to address this information complexity via graph-driven\narchitectures, since GCNs can perform feature aggregation, interaction, and\nreasoning with remarkable flexibility and efficiency. These GCNs capabilities\nhave spawned a new wave of research in medical imaging analysis with the\noverarching goal of improving quantitative disease understanding, monitoring,\nand diagnosis. Yet daunting challenges remain for designing the important\nimage-to-graph transformation for multi-modality medical imaging and gaining\ninsights into model interpretation and enhanced clinical decision support. In\nthis review, we present recent GCNs developments in the context of medical\nimage analysis including imaging data from radiology and histopathology. We\ndiscuss the fast-growing use of graph network architectures in medical image\nanalysis to improve disease diagnosis and patient outcomes in clinical\npractice. To foster cross-disciplinary research, we present GCNs technical\nadvancements, emerging medical applications, identify common challenges in the\nuse of image-based GCNs and their extensions in model interpretation,\nlarge-scale benchmarks that promise to transform the scope of medical image\nstudies and related graph-driven medical research.",
          "link": "http://arxiv.org/abs/2202.08916",
          "publishedOn": "2022-04-23T00:53:50.227Z",
          "wordCount": 688,
          "title": "Graph Convolutional Networks for Multi-modality Medical Imaging: Methods, Architectures, and Clinical Applications. (arXiv:2202.08916v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10125",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parker_J/0/1/0/all/0/1\">Julian D. Parker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlecht_S/0/1/0/all/0/1\">Sebastian J. Schlecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabenstein_R/0/1/0/all/0/1\">Rudolf Rabenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schafer_M/0/1/0/all/0/1\">Maximilian Sch&#xe4;fer</a>",
          "description": "Discrete-time modeling of acoustic, mechanical and electrical systems is a\nprominent topic in the musical signal processing literature. Such models are\nmostly derived by discretizing a mathematical model, given in terms of ordinary\nor partial differential equations, using established techniques. Recent work\nhas applied the techniques of machine-learning to construct such models\nautomatically from data for the case of systems which have lumped states\ndescribed by scalar values, such as electrical circuits. In this work, we\nexamine how similar techniques are able to construct models of systems which\nhave spatially distributed rather than lumped states. We describe several novel\nrecurrent neural network structures, and show how they can be thought of as an\nextension of modal techniques. As a proof of concept, we generate synthetic\ndata for three physical systems and show that the proposed network structures\ncan be trained with this data to reproduce the behavior of these systems.",
          "link": "http://arxiv.org/abs/2204.10125",
          "publishedOn": "2022-04-23T00:53:50.219Z",
          "wordCount": null,
          "title": "Physical Modeling using Recurrent Neural Networks with Fast Convolutional Layers. (arXiv:2204.10125v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10212",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1\">Juhwan Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Justin N. Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gharaibeh_Y/0/1/0/all/0/1\">Yazan Gharaibeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zimin_V/0/1/0/all/0/1\">Vladislav N. Zimin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dallan_L/0/1/0/all/0/1\">Luis A. P. Dallan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pereira_G/0/1/0/all/0/1\">Gabriel T. R. Pereira</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vergara_Martel_A/0/1/0/all/0/1\">Armando Vergara-Martel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kolluru_C/0/1/0/all/0/1\">Chaitanya Kolluru</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hoori_A/0/1/0/all/0/1\">Ammar Hoori</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bezerra_H/0/1/0/all/0/1\">Hiram G. Bezerra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wilson_D/0/1/0/all/0/1\">David L. Wilson</a>",
          "description": "Compared with other imaging modalities, intravascular optical coherence\ntomography (IVOCT) has significant advantages for guiding percutaneous coronary\ninterventions. To aid IVOCT research studies, we developed the Optical\nCoherence TOmography PlaqUe and Stent (OCTOPUS) analysis software. To automate\nimage analysis results, the software includes several important algorithmic\nsteps: pre-processing, deep learning plaque segmentation, machine learning\nidentification of stent struts, and registration of pullbacks. Interactive\nvisualization and manual editing of segmentations were included in the\nsoftware. Quantifications include stent deployment characteristics (e.g., stent\nstrut malapposition), strut level analysis, calcium angle, and calcium\nthickness measurements. Interactive visualizations include (x,y) anatomical, en\nface, and longitudinal views with optional overlays. Underlying plaque\nsegmentation algorithm yielded excellent pixel-wise results (86.2% sensitivity\nand 0.781 F1 score). Using OCTOPUS on 34 new pullbacks, we determined that\nfollowing automated segmentation, only 13% and 23% of frames needed any manual\ntouch up for detailed lumen and calcification labeling, respectively. Only up\nto 3.8% of plaque pixels were modified, leading to an average editing time of\nonly 7.5 seconds/frame, an approximately 80% reduction compared to manual\nanalysis. Regarding stent analysis, sensitivity and precision were both greater\nthan 90%, and each strut was successfully classified as either covered or\nuncovered with high sensitivity (94%) and specificity (90%). We introduced and\nevaluated the clinical application of a highly automated software package,\nOCTOPUS, for quantitative plaque and stent analysis in IVOCT images. The\nsoftware is currently used as an offline tool for research purposes; however,\nthe software's embedded algorithms may also be useful for real-time treatment\nplanning.",
          "link": "http://arxiv.org/abs/2204.10212",
          "publishedOn": "2022-04-23T00:53:50.218Z",
          "wordCount": 734,
          "title": "OCTOPUS -- optical coherence tomography plaque and stent analysis software. (arXiv:2204.10212v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.09367",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhi Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1\">Hao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jabi_W/0/1/0/all/0/1\">Wassim Jabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Juyong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1\">Bailin Deng</a>",
          "description": "The freeform architectural modeling process often involves two important\nstages: concept design and digital modeling. In the first stage, architects\nusually sketch the overall 3D shape and the panel layout on a physical or\ndigital paper briefly. In the second stage, a digital 3D model is created using\nthe sketch as a reference. The digital model needs to incorporate geometric\nrequirements for its components, such as the planarity of panels due to\nconsideration of construction costs, which can make the modeling process more\nchallenging. In this work, we present a novel sketch-based system to bridge the\nconcept design and digital modeling of freeform roof-like shapes represented as\nplanar quadrilateral (PQ) meshes. Our system allows the user to sketch the\nsurface boundary and contour lines under axonometric projection and supports\nthe sketching of occluded regions. In addition, the user can sketch feature\nlines to provide directional guidance to the PQ mesh layout. Given the 2D\nsketch input, we propose a deep neural network to infer in real-time the\nunderlying surface shape along with a dense conjugate direction field, both of\nwhich are used to extract the final PQ mesh. To train and validate our network,\nwe generate a large synthetic dataset that mimics architect sketching of\nfreeform quadrilateral patches. The effectiveness and usability of our system\nare demonstrated with quantitative and qualitative evaluation as well as user\nstudies.",
          "link": "http://arxiv.org/abs/2201.09367",
          "publishedOn": "2022-04-23T00:53:50.210Z",
          "wordCount": 715,
          "title": "Sketch2PQ: Freeform Planar Quadrilateral Mesh Design via a Single Sketch. (arXiv:2201.09367v3 [cs.GR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09792",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rowe_F/0/1/0/all/0/1\">Francisco Rowe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mahony_M/0/1/0/all/0/1\">Michael Mahony</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tao_S/0/1/0/all/0/1\">Sui Tao</a>",
          "description": "Given an increasingly volatile climate, the relationship between weather and\ntransit ridership has drawn increasing interest. However, challenges stemming\nfrom spatio-temporal dependency and non-stationarity have not been fully\naddressed in modelling and predicting transit ridership under the influence of\nweather conditions especially with the traditional statistical approaches.\nDrawing on three-month smart card data in Brisbane, Australia, this research\nadopts and assesses a suite of machine-learning algorithms, i.e., random\nforest, eXtreme Gradient Boosting (XGBoost) and Tweedie XGBoost, to model and\npredict near real-time bus ridership in relation to sudden change of weather\nconditions. The study confirms that there indeed exists a significant level of\nspatio-temporal variability of weather-ridership relationship, which produces\nequally dynamic patterns of prediction errors. Further comparison of model\nperformance suggests that Tweedie XGBoost outperforms the other two\nmachine-learning algorithms in generating overall more accurate prediction\noutcomes in space and time. Future research may advance the current study by\ndrawing on larger data sets and applying more advanced machine and\ndeep-learning approaches to provide more enhanced evidence for real-time\noperation of transit systems.",
          "link": "http://arxiv.org/abs/2204.09792",
          "publishedOn": "2022-04-23T00:53:50.203Z",
          "wordCount": 623,
          "title": "Assessing Machine Learning Algorithms for Near-Real Time Bus Ridership Prediction During Extreme Weather. (arXiv:2204.09792v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10242",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sadjadi_S/0/1/0/all/0/1\">Seyed Omid Sadjadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greenberg_C/0/1/0/all/0/1\">Craig Greenberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singer_E/0/1/0/all/0/1\">Elliot Singer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mason_L/0/1/0/all/0/1\">Lisa Mason</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Reynolds_D/0/1/0/all/0/1\">Douglas Reynolds</a>",
          "description": "The 2021 Speaker Recognition Evaluation (SRE21) was the latest cycle of the\nongoing evaluation series conducted by the U.S. National Institute of Standards\nand Technology (NIST) since 1996. It was the second large-scale multimodal\nspeaker/person recognition evaluation organized by NIST (the first one being\nSRE19). Similar to SRE19, it featured two core evaluation tracks, namely audio\nand audio-visual, as well as an optional visual track. In addition to offering\nfixed and open training conditions, it also introduced new challenges for the\ncommunity, thanks to a new multimodal (i.e., audio, video, and selfie images)\nand multilingual (i.e., with multilingual speakers) corpus, termed WeCanTalk,\ncollected outside North America by the Linguistic Data Consortium (LDC). These\nchallenges included: 1) trials (target and non-target) with enrollment and test\nsegments originating from different domains (i.e., telephony versus video), and\n2) trials (target and non-target) with enrollment and test segments spoken in\ndifferent languages (i.e., cross-lingual trials). This paper presents an\noverview of SRE21 including the tasks, performance metric, data, evaluation\nprotocol, results and system performance analyses. A total of 23 organizations\n(forming 15 teams) from academia and industry participated in SRE21 and\nsubmitted 158 valid system outputs. Evaluation results indicate: audio-visual\nfusion produce substantial gains in performance over audio-only or visual-only\nsystems; top performing speaker and face recognition systems exhibited\ncomparable performance under the matched domain conditions present in this\nevaluation; and, the use of complex neural network architectures (e.g., ResNet)\nalong with angular losses with margin, data augmentation, as well as long\nduration fine-tuning contributed to notable performance improvements for the\naudio-only speaker recognition task.",
          "link": "http://arxiv.org/abs/2204.10242",
          "publishedOn": "2022-04-23T00:53:50.182Z",
          "wordCount": 713,
          "title": "The 2021 NIST Speaker Recognition Evaluation. (arXiv:2204.10242v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08816",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Slijepcevic_I/0/1/0/all/0/1\">Inigo V. Slijepcevic</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Scaife_A/0/1/0/all/0/1\">Anna M. M. Scaife</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Walmsley_M/0/1/0/all/0/1\">Mike Walmsley</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Bowles_M/0/1/0/all/0/1\">Micah Bowles</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wong_I/0/1/0/all/0/1\">Ivy Wong</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Shabala_S/0/1/0/all/0/1\">Stanislav S. Shabala</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Tang_H/0/1/0/all/0/1\">Hongming Tang</a>",
          "description": "In this work we examine the classification accuracy and robustness of a\nstate-of-the-art semi-supervised learning (SSL) algorithm applied to the\nmorphological classification of radio galaxies. We test if SSL with fewer\nlabels can achieve test accuracies comparable to the supervised\nstate-of-the-art and whether this holds when incorporating previously unseen\ndata. We find that for the radio galaxy classification problem considered, SSL\nprovides additional regularisation and outperforms the baseline test accuracy.\nHowever, in contrast to model performance metrics reported on computer science\nbenchmarking data-sets, we find that improvement is limited to a narrow range\nof label volumes, with performance falling off rapidly at low label volumes.\nAdditionally, we show that SSL does not improve model calibration, regardless\nof whether classification is improved. Moreover, we find that when different\nunderlying catalogues drawn from the same radio survey are used to provide the\nlabelled and unlabelled data-sets required for SSL, a significant drop in\nclassification performance is observered, highlighting the difficulty of\napplying SSL techniques under dataset shift. We show that a class-imbalanced\nunlabelled data pool negatively affects performance through prior probability\nshift, which we suggest may explain this performance drop, and that using the\nFrechet Distance between labelled and unlabelled data-sets as a measure of\ndata-set shift can provide a prediction of model performance, but that for\ntypical radio galaxy data-sets with labelled sample volumes of O(1000), the\nsample variance associated with this technique is high and the technique is in\ngeneral not sufficiently robust to replace a train-test cycle.",
          "link": "http://arxiv.org/abs/2204.08816",
          "publishedOn": "2022-04-23T00:53:50.175Z",
          "wordCount": 749,
          "title": "Radio Galaxy Zoo: Using semi-supervised learning to leverage large unlabelled data-sets for radio galaxy classification under data-set shift. (arXiv:2204.08816v3 [astro-ph.GA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11758",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Reisinger_C/0/1/0/all/0/1\">Christoph Reisinger</a>, <a href=\"http://arxiv.org/find/math/1/au:+Stockinger_W/0/1/0/all/0/1\">Wolfgang Stockinger</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1\">Yufei Zhang</a>",
          "description": "Despite its popularity in the reinforcement learning community, a provably\nconvergent policy gradient method for general continuous space-time stochastic\ncontrol problems has been elusive. This paper closes the gap by proposing a\nproximal gradient algorithm for feedback controls of finite-time horizon\nstochastic control problems. The state dynamics are continuous time nonlinear\ndiffusions with controlled drift and possibly degenerate noise, and the\nobjectives are nonconvex in the state and nonsmooth in the control. We prove\nunder suitable conditions that the algorithm converges linearly to a stationary\npoint of the control problem, and is stable with respect to policy updates by\napproximate gradient steps. The convergence result justifies the recent\nreinforcement learning heuristics that adding entropy regularization or a\nfictitious discount factor to the optimization objective accelerates the\nconvergence of policy gradient methods. The proof exploits careful regularity\nestimates of backward stochastic differential equations.",
          "link": "http://arxiv.org/abs/2203.11758",
          "publishedOn": "2022-04-23T00:53:50.161Z",
          "wordCount": 625,
          "title": "Linear convergence of a policy gradient method for finite horizon continuous time stochastic control problems. (arXiv:2203.11758v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.10461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clarke_R/0/1/0/all/0/1\">Ross M. Clarke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oldewage_E/0/1/0/all/0/1\">Elre T. Oldewage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1\">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>",
          "description": "Machine learning training methods depend plentifully and intricately on\nhyperparameters, motivating automated strategies for their optimisation. Many\nexisting algorithms restart training for each new hyperparameter choice, at\nconsiderable computational cost. Some hypergradient-based one-pass methods\nexist, but these either cannot be applied to arbitrary optimiser\nhyperparameters (such as learning rates and momenta) or take several times\nlonger to train than their base models. We extend these existing methods to\ndevelop an approximate hypergradient-based hyperparameter optimiser which is\napplicable to any continuous hyperparameter appearing in a differentiable model\nweight update, yet requires only one training episode, with no restarts. We\nalso provide a motivating argument for convergence to the true hypergradient,\nand perform tractable gradient-based optimisation of independent learning rates\nfor each model parameter. Our method performs competitively from varied random\nhyperparameter initialisations on several UCI datasets and Fashion-MNIST (using\na one-layer MLP), Penn Treebank (using an LSTM) and CIFAR-10 (using a\nResNet-18), in time only 2-3x greater than vanilla training.",
          "link": "http://arxiv.org/abs/2110.10461",
          "publishedOn": "2022-04-23T00:53:50.130Z",
          "wordCount": null,
          "title": "Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation. (arXiv:2110.10461v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11438",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Leoni_M/0/1/0/all/0/1\">Marco Leoni</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ishida_E/0/1/0/all/0/1\">Emille E. O. Ishida</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Peloton_J/0/1/0/all/0/1\">Julien Peloton</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Moller_A/0/1/0/all/0/1\">Anais M&#xf6;ller</a>",
          "description": "We describe how the Fink broker early supernova Ia classifier optimizes its\nML classifications by employing an active learning (AL) strategy. We\ndemonstrate the feasibility of implementation of such strategies in the current\nZwicky Transient Facility (ZTF) public alert data stream. We compare the\nperformance of two AL strategies: uncertainty sampling and random sampling. Our\npipeline consists of 3 stages: feature extraction, classification and learning\nstrategy. Starting from an initial sample of 10 alerts (5 SN Ia and 5 non-Ia),\nwe let the algorithm identify which alert should be added to the training\nsample. The system is allowed to evolve through 300 iterations. Our data set\nconsists of 23 840 alerts from the ZTF with confirmed classification via\ncross-match with SIMBAD database and the Transient name server (TNS), 1 600 of\nwhich were SNe Ia (1 021 unique objects). The data configuration, after the\nlearning cycle was completed, consists of 310 alerts for training and 23 530\nfor testing. Averaging over 100 realizations, the classifier achieved 89%\npurity and 54% efficiency. From 01/November/2020 to 31/October/2021 Fink has\napplied its early supernova Ia module to the ZTF stream and communicated\npromising SN Ia candidates to the TNS. From the 535 spectroscopically\nclassified Fink candidates, 459 (86%) were proven to be SNe Ia. Our results\nconfirm the effectiveness of active learning strategies for guiding the\nconstruction of optimal training samples for astronomical classifiers. It\ndemonstrates in real data that the performance of learning algorithms can be\nhighly improved without the need of extra computational resources or\noverwhelmingly large training samples. This is, to our knowledge, the first\napplication of AL to real alerts data.",
          "link": "http://arxiv.org/abs/2111.11438",
          "publishedOn": "2022-04-23T00:53:50.129Z",
          "wordCount": null,
          "title": "Fink: early supernovae Ia classification using active learning. (arXiv:2111.11438v2 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.00597",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Tsai_S/0/1/0/all/0/1\">Sun-Ting Tsai</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Fields_E/0/1/0/all/0/1\">Eric Fields</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Xu_Y/0/1/0/all/0/1\">Yijia Xu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kuo_E/0/1/0/all/0/1\">En-Jui Kuo</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Tiwary_P/0/1/0/all/0/1\">Pratyush Tiwary</a>",
          "description": "Recurrent neural networks have seen widespread use in modeling dynamical\nsystems in varied domains such as weather prediction, text prediction and\nseveral others. Often one wishes to supplement the experimentally observed\ndynamics with prior knowledge or intuition about the system. While the\nrecurrent nature of these networks allows them to model arbitrarily long\nmemories in the time series used in training, it makes it harder to impose\nprior knowledge or intuition through generic constraints. In this work, we\npresent a path sampling approach based on principle of Maximum Caliber that\nallows us to include generic thermodynamic or kinetic constraints into\nrecurrent neural networks. We show the method here for a widely used type of\nrecurrent neural network known as long short-term memory network in the context\nof supplementing time series collected from different application domains.\nThese include classical Molecular Dynamics of a protein and Monte Carlo\nsimulations of an open quantum system continuously losing photons to the\nenvironment and displaying Rabi oscillations. Our method can be easily\ngeneralized to other generative artificial intelligence models and to generic\ntime series in different areas of physical and social sciences, where one\nwishes to supplement limited data with intuition or theory based corrections.",
          "link": "http://arxiv.org/abs/2203.00597",
          "publishedOn": "2022-04-23T00:53:50.129Z",
          "wordCount": null,
          "title": "Path sampling of recurrent neural networks by incorporating known physics. (arXiv:2203.00597v2 [cond-mat.dis-nn] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>",
          "description": "We study the theory of neural network (NN) from the lens of classical\nnonparametric regression problems with a focus on NN's ability to adaptively\nestimate functions with heterogeneous smoothness -- a property of functions in\nBesov or Bounded Variation (BV) classes. Existing work on this problem requires\ntuning the NN architecture based on the function spaces and sample sizes. We\nconsider a \"Parallel NN\" variant of deep ReLU networks and show that the\nstandard weight decay is equivalent to promoting the $\\ell_p$-sparsity\n($0<p<1$) of the coefficient vector of an end-to-end learned function bases,\ni.e., a dictionary. Using this equivalence, we further establish that by tuning\nonly the weight decay, such Parallel NN achieves an estimation error\narbitrarily close to the minimax rates for both the Besov and BV classes.\nNotably, it gets exponentially closer to minimax optimal as the NN gets deeper.\nOur research sheds new lights on why depth matters and how NNs are more\npowerful than kernel methods.",
          "link": "http://arxiv.org/abs/2204.09664",
          "publishedOn": "2022-04-23T00:53:50.129Z",
          "wordCount": null,
          "title": "Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?. (arXiv:2204.09664v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.13629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1\">Pengfei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xinghua Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_Y/0/1/0/all/0/1\">Yew Soon Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zejun Ma</a>",
          "description": "Feature-based transfer is one of the most effective methodologies for\ntransfer learning. Existing studies usually assume that the learned new feature\nrepresentation is \\emph{domain-invariant}, and thus train a transfer model\n$\\mathcal{M}$ on the source domain. In this paper, we consider a more realistic\nscenario where the new feature representation is suboptimal and small\ndivergence still exists across domains. We propose a new transfer model called\nRandomized Transferable Machine (RTM) to handle such small divergence of\ndomains. Specifically, we work on the new source and target data learned from\nexisting feature-based transfer methods. The key idea is to enlarge source\ntraining data populations by randomly corrupting the new source data using some\nnoises, and then train a transfer model $\\widetilde{\\mathcal{M}}$ that performs\nwell on all the corrupted source data populations. In principle, the more\ncorruptions are made, the higher the probability of the new target data can be\ncovered by the constructed source data populations, and thus better transfer\nperformance can be achieved by $\\widetilde{\\mathcal{M}}$. An ideal case is with\ninfinite corruptions, which however is infeasible in reality. We develop a\nmarginalized solution that enables to train an $\\widetilde{\\mathcal{M}}$\nwithout conducting any corruption but equivalent to be trained using infinite\nsource noisy data populations. We further propose two instantiations of\n$\\widetilde{\\mathcal{M}}$, which theoretically show the transfer superiority\nover the conventional transfer model $\\mathcal{M}$. More importantly, both\ninstantiations have closed-form solutions, leading to a fast and efficient\ntraining process. Experiments on various real-world transfer tasks show that\nRTM is a promising transfer model.",
          "link": "http://arxiv.org/abs/2011.13629",
          "publishedOn": "2022-04-23T00:53:50.128Z",
          "wordCount": null,
          "title": "An Improved Transfer Model: Randomized Transferable Machine. (arXiv:2011.13629v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.03113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yayong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1\">Weitao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jie Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Richard Yi Da Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Ling Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Miao Zhang</a>",
          "description": "Graph convolutional networks (GCNs) and their variants have achieved great\nsuccess in dealing with graph-structured data. Nevertheless, it is well known\nthat deep GCNs suffer from the over-smoothing problem, where node\nrepresentations tend to be indistinguishable as more layers are stacked up. The\ntheoretical research to date on deep GCNs has focused primarily on expressive\npower rather than trainability, an optimization perspective. Compared to\nexpressivity, trainability attempts to address a more fundamental question:\nGiven a sufficiently expressive space of models, can we successfully find a\ngood solution via gradient descent-based optimizers? This work fills this gap\nby exploiting the Graph Neural Tangent Kernel (GNTK), which governs the\noptimization trajectory under gradient descent for wide GCNs. We formulate the\nasymptotic behaviors of GNTK in the large depth, which enables us to reveal the\ndropping trainability of wide and deep GCNs at an exponential rate in the\noptimization process. Additionally, we extend our theoretical framework to\nanalyze residual connection-based techniques, which are found to be merely able\nto mitigate the exponential decay of trainability mildly. Inspired by our\ntheoretical insights on trainability, we propose Critical DropEdge, a\nconnectivity-aware and graph-adaptive sampling method, to alleviate the\nexponential decay problem more fundamentally. Experimental evaluation\nconsistently confirms using our proposed method can achieve better results\ncompared to relevant counterparts with both infinite-width and finite-width.",
          "link": "http://arxiv.org/abs/2103.03113",
          "publishedOn": "2022-04-23T00:53:50.128Z",
          "wordCount": null,
          "title": "Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective. (arXiv:2103.03113v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.06393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Tuan Anh Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collins_K/0/1/0/all/0/1\">Katherine M. Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hewitt_L/0/1/0/all/0/1\">Luke Hewitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellis_K/0/1/0/all/0/1\">Kevin Ellis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddharth_N/0/1/0/all/0/1\">N. Siddharth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1\">Samuel J. Gershman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>",
          "description": "Modeling complex phenomena typically involves the use of both discrete and\ncontinuous variables. Such a setting applies across a wide range of problems,\nfrom identifying trends in time-series data to performing effective\ncompositional scene understanding in images. Here, we propose Hybrid Memoised\nWake-Sleep (HMWS), an algorithm for effective inference in such hybrid\ndiscrete-continuous models. Prior approaches to learning suffer as they need to\nperform repeated expensive inner-loop discrete inference. We build on a recent\napproach, Memoised Wake-Sleep (MWS), which alleviates part of the problem by\nmemoising discrete variables, and extend it to allow for a principled and\neffective way to handle continuous variables by learning a separate recognition\nmodel used for importance-sampling based approximate inference and\nmarginalization. We evaluate HMWS in the GP-kernel learning and 3D scene\nunderstanding domains, and show that it outperforms current state-of-the-art\ninference methods.",
          "link": "http://arxiv.org/abs/2107.06393",
          "publishedOn": "2022-04-23T00:53:50.128Z",
          "wordCount": null,
          "title": "Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface. (arXiv:2107.06393v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10268",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1\">Matthias C. Caro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1\">Hsin-Yuan Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ezzell_N/0/1/0/all/0/1\">Nicholas Ezzell</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gibbs_J/0/1/0/all/0/1\">Joe Gibbs</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sornborger_A/0/1/0/all/0/1\">Andrew T. Sornborger</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Holmes_Z/0/1/0/all/0/1\">Zo&#xeb; Holmes</a>",
          "description": "Generalization bounds are a critical tool to assess the training data\nrequirements of Quantum Machine Learning (QML). Recent work has established\nguarantees for in-distribution generalization of quantum neural networks\n(QNNs), where training and testing data are assumed to be drawn from the same\ndata distribution. However, there are currently no results on\nout-of-distribution generalization in QML, where we require a trained model to\nperform well even on data drawn from a distribution different from the training\ndistribution. In this work, we prove out-of-distribution generalization for the\ntask of learning an unknown unitary using a QNN and for a broad class of\ntraining and testing distributions. In particular, we show that one can learn\nthe action of a unitary on entangled states using only product state training\ndata. We numerically illustrate this by showing that the evolution of a\nHeisenberg spin chain can be learned using only product training states. Since\nproduct states can be prepared using only single-qubit gates, this advances the\nprospects of learning quantum dynamics using near term quantum computers and\nquantum experiments, and further opens up new methods for both the classical\nand quantum compilation of quantum circuits.",
          "link": "http://arxiv.org/abs/2204.10268",
          "publishedOn": "2022-04-23T00:53:50.127Z",
          "wordCount": 656,
          "title": "Out-of-distribution generalization for learning quantum dynamics. (arXiv:2204.10268v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11178",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Im_H/0/1/0/all/0/1\">Hyeon-Seong Im</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Si-Hyeon Lee</a>",
          "description": "For multi-band wireless ad hoc networks of multiple users, an anti-jamming\ngame between the users and a jammer is studied. In this game, the users (resp.\njammer) want to maximize (resp. minimize) the expected rewards of the users\ntaking into account various factors such as communication rate, hopping cost,\nand jamming loss. We analyze the arms race of the game and derive an optimal\nfrequency hopping policy at each stage of the arms race based on the Markov\ndecision process (MDP). It is analytically shown that the arms race reaches an\nequilibrium after a few rounds, and a frequency hopping policy and a jamming\nstrategy at the equilibrium are characterized. We propose two kinds of\ncollision avoidance protocols to ensure that at most one user communicates in\neach frequency band, and provide various numerical results that show the\neffects of the reward parameters and collision avoidance protocols on the\noptimal frequency hopping policy and the expected rewards at the equilibrium.\nMoreover, we discuss about equilibria for the case where the jammer adopts some\nunpredictable jamming strategies.",
          "link": "http://arxiv.org/abs/2111.11178",
          "publishedOn": "2022-04-23T00:53:49.552Z",
          "wordCount": null,
          "title": "Anti-Jamming Games in Multi-Band Wireless Ad Hoc Networks. (arXiv:2111.11178v2 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sroka_P/0/1/0/all/0/1\">Pawe\\{l} Sroka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kliks_A/0/1/0/all/0/1\">Adrian Kliks</a>",
          "description": "Reliable wireless communication between the autonomously driving cars is one\nof the fundamental needs for guaranteeing passenger safety and comfort.\nHowever, when the number of communicating cars increases, the transmission\nquality may be significantly degraded due to too high occupancy radio of the\nused frequency band. In this paper, we concentrate on the autonomous\nvehicle-platooning use-case, where intra-platoon communication is done in the\ndynamically selected frequency band, other than nominally devoted for such\npurposes. The carrier selection is done in a flexible manner with the support\nof the context database located at the roadside unit (edge of wireless\ncommunication infrastructure). However, as the database delivers only context\ninformation to the platoons' leaders, the final decision is made separately by\nthe individual platoons, following the suggestions made by the artificial\nintelligence algorithms. In this work, we concentrate on a lightweight\nQ-learning solution, that could be successfully implemented in each car for\ndynamic channel selection.",
          "link": "http://arxiv.org/abs/2204.10179",
          "publishedOn": "2022-04-23T00:53:49.515Z",
          "wordCount": null,
          "title": "Distributed Learning for Vehicular Dynamic Spectrum Access in Autonomous Driving. (arXiv:2204.10179v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pasen_M/0/1/0/all/0/1\">Martin Pa&#x161;en</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boza_V/0/1/0/all/0/1\">Vladim&#xed;r Bo&#x17e;a</a>",
          "description": "We propose a simple scheme for merging two neural networks trained with\ndifferent starting initialization into a single one with the same size as the\noriginal ones. We do this by carefully selecting channels from each input\nnetwork. Our procedure might be used as a finalization step after one tries\nmultiple starting seeds to avoid an unlucky one. We also show that training two\nnetworks and merging them leads to better performance than training a single\nnetwork for an extended period of time.\n\nAvailability: https://github.com/fmfi-compbio/neural-network-merging",
          "link": "http://arxiv.org/abs/2204.09973",
          "publishedOn": "2022-04-23T00:53:49.503Z",
          "wordCount": null,
          "title": "Merging of neural networks. (arXiv:2204.09973v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.13799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_D/0/1/0/all/0/1\">Donghwee Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Junseok Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Hayeong Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_M/0/1/0/all/0/1\">Minjae Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1\">Injung Kim</a>",
          "description": "We propose OUR-GAN, the first one-shot ultra-high-resolution (UHR) image\nsynthesis framework that generates non-repetitive images with 4K or higher\nresolution from a single training image. OUR-GAN generates a visually coherent\nimage at low resolution and then gradually increases the resolution by\nsuper-resolution. Since OUR-GAN learns from a real UHR image, it can synthesize\nlarge-scale shapes with fine details while maintaining long-range coherence,\nwhich is difficult with conventional generative models that generate large\nimages based on the patch distribution learned from relatively small images.\nOUR-GAN applies seamless subregion-wise super-resolution that synthesizes 4k or\nhigher UHR images with limited memory, preventing discontinuity at the\nboundary. Additionally, OUR-GAN improves visual coherence maintaining diversity\nby adding vertical positional embeddings to the feature maps. In experiments on\nthe ST4K and RAISE datasets, OUR-GAN exhibited improved fidelity, visual\ncoherency, and diversity compared with existing methods. The synthesized images\nare presented at https://anonymous-62348.github.io.",
          "link": "http://arxiv.org/abs/2202.13799",
          "publishedOn": "2022-04-23T00:53:49.497Z",
          "wordCount": null,
          "title": "OUR-GAN: One-shot Ultra-high-Resolution Generative Adversarial Networks. (arXiv:2202.13799v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hammar_K/0/1/0/all/0/1\">Kim Hammar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stadler_R/0/1/0/all/0/1\">Rolf Stadler</a>",
          "description": "We present a system for interactive examination of learned security policies.\nIt allows a user to traverse episodes of Markov decision processes in a\ncontrolled manner and to track the actions triggered by security policies.\nSimilar to a software debugger, a user can continue or or halt an episode at\nany time step and inspect parameters and probability distributions of interest.\nThe system enables insight into the structure of a given policy and in the\nbehavior of a policy in edge cases. We demonstrate the system with a network\nintrusion use case. We examine the evolution of an IT infrastructure's state\nand the actions prescribed by security policies while an attack occurs. The\npolicies for the demonstration have been obtained through a reinforcement\nlearning approach that includes a simulation system where policies are\nincrementally learned and an emulation system that produces statistics that\ndrive the simulation runs.",
          "link": "http://arxiv.org/abs/2204.01126",
          "publishedOn": "2022-04-23T00:53:49.458Z",
          "wordCount": null,
          "title": "A System for Interactive Examination of Learned Security Policies. (arXiv:2204.01126v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bardou_A/0/1/0/all/0/1\">Anthony Bardou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Begin_T/0/1/0/all/0/1\">Thomas Begin</a>",
          "description": "WLANs, which have overtaken wired networks to become the primary means of\nconnecting devices to the Internet, are prone to performance issues due to the\nscarcity of space in the radio spectrum. As a response, IEEE 802.11ax and\nsubsequent amendments aim at increasing the spatial reuse of a radio channel by\nallowing the dynamic update of two key parameters in wireless transmission: the\ntransmission power (TX_POWER) and the sensitivity threshold (OBSS_PD). In this\npaper, we present INSPIRE, a distributed solution performing local Bayesian\noptimizations based on Gaussian processes to improve the spatial reuse in\nWLANs. INSPIRE makes no explicit assumptions about the topology of WLANs and\nfavors altruistic behaviors of the access points, leading them to find adequate\nconfigurations of their TX_POWER and OBSS_PD parameters for the \"greater good\"\nof the WLANs. We demonstrate the superiority of INSPIRE over other\nstate-of-the-art strategies using the ns-3 simulator and two examples inspired\nby real-life deployments of dense WLANs. Our results show that, in only a few\nseconds, INSPIRE is able to drastically increase the quality of service of\noperational WLANs by improving their fairness and throughput.",
          "link": "http://arxiv.org/abs/2204.10184",
          "publishedOn": "2022-04-23T00:53:49.403Z",
          "wordCount": null,
          "title": "INSPIRE: Distributed Bayesian Optimization for ImproviNg SPatIal REuse in Dense WLANs. (arXiv:2204.10184v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yuexin Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1\">Yuchen Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_D/0/1/0/all/0/1\">Ding Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1\">Wei Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tiantian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qingqing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wenmao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1\">Tianqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_K/0/1/0/all/0/1\">Kim-Kwang Raymond Choo</a>",
          "description": "Cryptocurrencies are no longer just the preferred option for cybercriminal\nactivities on darknets, due to the increasing adoption in mainstream\napplications. This is partly due to the transparency associated with the\nunderpinning ledgers, where any individual can access the record of a\ntransaction record on the public ledger. In this paper, we build a dataset\ncomprising Bitcoin transactions between 12 July 2019 and 26 May 2021. This\ndataset (hereafter referred to as BABD-13) contains 13 types of Bitcoin\naddresses, 5 categories of indicators with 148 features, and 544,462 labeled\ndata. We then use our proposed dataset on common machine learning models,\nnamely: k-nearest neighbors algorithm, decision tree, random forest, multilayer\nperceptron, and XGBoost. The results show that the accuracy rates of these\nmachine learning models on our proposed dataset are between 93.24% and 96.71%.\nWe also analyze the proposed features and their relationships from the\nexperiments, and propose a k-hop subgraph generation algorithm to extract a\nk-hop subgraph from the entire Bitcoin transaction graph constructed by the\ndirected heterogeneous multigraph starting from a specific Bitcoin address node\n(e.g., a known transaction associated with a criminal investigation).",
          "link": "http://arxiv.org/abs/2204.05746",
          "publishedOn": "2022-04-23T00:53:49.401Z",
          "wordCount": null,
          "title": "BABD: A Bitcoin Address Behavior Dataset for Address Behavior Pattern Analysis. (arXiv:2204.05746v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.13445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iofinova_E/0/1/0/all/0/1\">Eugenia Iofinova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peste_A/0/1/0/all/0/1\">Alexandra Peste</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurtz_M/0/1/0/all/0/1\">Mark Kurtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>",
          "description": "Transfer learning is a classic paradigm by which models pretrained on large\n\"upstream\" datasets are adapted to yield good results on \"downstream\"\nspecialized datasets. Generally, more accurate models on the \"upstream\" dataset\ntend to provide better transfer accuracy \"downstream\". In this work, we perform\nan in-depth investigation of this phenomenon in the context of convolutional\nneural networks (CNNs) trained on the ImageNet dataset, which have been pruned\n- that is, compressed by sparsifying their connections. We consider transfer\nusing unstructured pruned models obtained by applying several state-of-the-art\npruning methods, including magnitude-based, second-order, re-growth,\nlottery-ticket, and regularization approaches, in the context of twelve\nstandard transfer tasks. In a nutshell, our study shows that sparse models can\nmatch or even outperform the transfer performance of dense models, even at high\nsparsities, and, while doing so, can lead to significant inference and even\ntraining speedups. At the same time, we observe and analyze significant\ndifferences in the behaviour of different pruning methods.",
          "link": "http://arxiv.org/abs/2111.13445",
          "publishedOn": "2022-04-23T00:53:49.387Z",
          "wordCount": null,
          "title": "How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v5 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.07295",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saito_Y/0/1/0/all/0/1\">Yuta Saito</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nomura_M/0/1/0/all/0/1\">Masahiro Nomura</a>",
          "description": "We study offline recommender learning from explicit rating feedback in the\npresence of selection bias. A current promising solution for the bias is the\ninverse propensity score (IPS) estimation. However, the performance of existing\npropensity-based methods can suffer significantly from the propensity\nestimation bias. In fact, most of the previous IPS-based methods require some\namount of missing-completely-at-random (MCAR) data to accurately estimate the\npropensity. This leads to a critical self-contradiction; IPS is ineffective\nwithout MCAR data, even though it originally aims to learn recommenders from\nonly missing-not-at-random feedback. To resolve this propensity contradiction,\nwe derive a propensity-independent generalization error bound and propose a\nnovel algorithm to minimize the theoretical bound via adversarial learning. Our\ntheory and algorithm do not require a propensity estimation procedure, thereby\nleading to a well-performing rating predictor without the true propensity\ninformation. Extensive experiments demonstrate that the proposed approach is\nsuperior to a range of existing methods both in rating prediction and ranking\nmetrics in practical settings without MCAR data.",
          "link": "http://arxiv.org/abs/1910.07295",
          "publishedOn": "2022-04-23T00:53:49.376Z",
          "wordCount": 656,
          "title": "Towards Resolving Propensity Contradiction in Offline Recommender Learning. (arXiv:1910.07295v6 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.08973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_Y/0/1/0/all/0/1\">Yoones Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Stephen Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mosse_D/0/1/0/all/0/1\">Daniel Mosse</a>",
          "description": "Advances in deep vision techniques and ubiquity of smart cameras will drive\nthe next generation of video analytics. However, video analytics applications\nconsume vast amounts of energy as both deep learning techniques and cameras are\npower-hungry. In this paper, we focus on a parking video analytics platform and\npropose RL-CamSleep, a deep reinforcement learning-based technique, to actuate\nthe cameras to reduce the energy footprint while retaining the system's\nutility. Our key insight is that many video-analytics applications do not\nalways need to be operational, and we can design policies to activate video\nanalytics only when necessary. Moreover, our work is complementary to existing\nwork that focuses on improving hardware and software efficiency. We evaluate\nour approach on a city-scale parking dataset having 76 streets spread across\nthe city. Our analysis demonstrates how streets have various parking patterns,\nhighlighting the importance of an adaptive policy. Our approach can learn such\nan adaptive policy that can reduce the average energy consumption by 76.38% and\nachieve an average accuracy of more than 98% in performing video analytics.",
          "link": "http://arxiv.org/abs/2202.08973",
          "publishedOn": "2022-04-23T00:53:49.347Z",
          "wordCount": null,
          "title": "Energy-Efficient Parking Analytics System using Deep Reinforcement Learning. (arXiv:2202.08973v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Csordas_R/0/1/0/all/0/1\">R&#xf3;bert Csord&#xe1;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1\">Kazuki Irie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>",
          "description": "Despite progress across a broad range of applications, Transformers have\nlimited success in systematic generalization. The situation is especially\nfrustrating in the case of algorithmic tasks, where they often fail to find\nintuitive solutions that route relevant information to the right node/operation\nat the right time in the grid represented by Transformer columns. To facilitate\nthe learning of useful control flow, we propose two modifications to the\nTransformer architecture, copy gate and geometric attention. Our novel Neural\nData Router (NDR) achieves 100% length generalization accuracy on the classic\ncompositional table lookup task, as well as near-perfect accuracy on the simple\narithmetic task and a new variant of ListOps testing for generalization across\ncomputational depths. NDR's attention and gating patterns tend to be\ninterpretable as an intuitive form of neural routing. Our code is public.",
          "link": "http://arxiv.org/abs/2110.07732",
          "publishedOn": "2022-04-23T00:53:49.319Z",
          "wordCount": null,
          "title": "The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization. (arXiv:2110.07732v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.10873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuolin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaojun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1\">Bhavya Kailkhura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Recent studies show that deep neural networks (DNN) are vulnerable to\nadversarial examples, which aim to mislead DNNs by adding perturbations with\nsmall magnitude. To defend against such attacks, both empirical and theoretical\ndefense approaches have been extensively studied for a single ML model. In this\nwork, we aim to analyze and provide the certified robustness for ensemble ML\nmodels, together with the sufficient and necessary conditions of robustness for\ndifferent ensemble protocols. Although ensemble models are shown more robust\nthan a single model empirically; surprisingly, we find that in terms of the\ncertified robustness the standard ensemble models only achieve marginal\nimprovement compared to a single model. Thus, to explore the conditions that\nguarantee to provide certifiably robust ensemble ML models, we first prove that\ndiversified gradient and large confidence margin are sufficient and necessary\nconditions for certifiably robust ensemble models under the model-smoothness\nassumption. We then provide the bounded model-smoothness analysis based on the\nproposed Ensemble-before-Smoothing strategy. We also prove that an ensemble\nmodel can always achieve higher certified robustness than a single base model\nunder mild conditions. Inspired by the theoretical findings, we propose the\nlightweight Diversity Regularized Training (DRT) to train certifiably robust\nensemble ML models. Extensive experiments show that our DRT enhanced ensembles\ncan consistently achieve higher certified robustness than existing single and\nensemble ML models, demonstrating the state-of-the-art certified L2-robustness\non MNIST, CIFAR-10, and ImageNet datasets.",
          "link": "http://arxiv.org/abs/2107.10873",
          "publishedOn": "2022-04-23T00:53:49.284Z",
          "wordCount": 733,
          "title": "On the Certified Robustness for Ensemble Models and Beyond. (arXiv:2107.10873v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koblah_D/0/1/0/all/0/1\">David Selasi Koblah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_R/0/1/0/all/0/1\">Rabin Yu Acharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Capecci_D/0/1/0/all/0/1\">Daniel Capecci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dizon_Paradis_O/0/1/0/all/0/1\">Olivia P. Dizon-Paradis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tajik_S/0/1/0/all/0/1\">Shahin Tajik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganji_F/0/1/0/all/0/1\">Fatemeh Ganji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodard_D/0/1/0/all/0/1\">Damon L. Woodard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forte_D/0/1/0/all/0/1\">Domenic Forte</a>",
          "description": "Artificial intelligence (AI) and machine learning (ML) techniques have been\nincreasingly used in several fields to improve performance and the level of\nautomation. In recent years, this use has exponentially increased due to the\nadvancement of high-performance computing and the ever increasing size of data.\nOne of such fields is that of hardware design; specifically the design of\ndigital and analog integrated circuits~(ICs), where AI/ ML techniques have been\nextensively used to address ever-increasing design complexity, aggressive\ntime-to-market, and the growing number of ubiquitous interconnected devices\n(IoT). However, the security concerns and issues related to IC design have been\nhighly overlooked. In this paper, we summarize the state-of-the-art in AL/ML\nfor circuit design/optimization, security and engineering challenges, research\nin security-aware CAD/EDA, and future research directions and needs for using\nAI/ML for security-aware circuit design.",
          "link": "http://arxiv.org/abs/2204.09579",
          "publishedOn": "2022-04-23T00:53:49.218Z",
          "wordCount": 603,
          "title": "A Survey and Perspective on Artificial Intelligence for Security-Aware Electronic Design Automation. (arXiv:2204.09579v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.10016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhaoning Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messikommer_N/0/1/0/all/0/1\">Nico Messikommer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehrig_D/0/1/0/all/0/1\">Daniel Gehrig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scaramuzza_D/0/1/0/all/0/1\">Davide Scaramuzza</a>",
          "description": "Retrieving accurate semantic information in challenging high dynamic range\n(HDR) and high-speed conditions remains an open challenge for image-based\nalgorithms due to severe image degradations. Event cameras promise to address\nthese challenges since they feature a much higher dynamic range and are\nresilient to motion blur. Nonetheless, semantic segmentation with event cameras\nis still in its infancy which is chiefly due to the novelty of the sensor, and\nthe lack of high-quality, labeled datasets. In this work, we introduce ESS,\nwhich tackles this problem by directly transferring the semantic segmentation\ntask from existing labeled image datasets to unlabeled events via unsupervised\ndomain adaptation (UDA). Compared to existing UDA methods, our approach aligns\nrecurrent, motion-invariant event embeddings with image embeddings. For this\nreason, our method neither requires video data nor per-pixel alignment between\nimages and events and, crucially, does not need to hallucinate motion from\nstill images. Additionally, to spur further research in event-based semantic\nsegmentation, we introduce DSEC-Semantic, the first large-scale event-based\ndataset with fine-grained labels. We show that using image labels alone, ESS\noutperforms existing UDA approaches, and when combined with event labels, it\neven outperforms state-of-the-art supervised approaches on both DDD17 and\nDSEC-Semantic. Finally, ESS is general-purpose, which unlocks the vast amount\nof existing labeled image datasets and paves the way for new and exciting\nresearch directions in new fields previously inaccessible for event cameras.",
          "link": "http://arxiv.org/abs/2203.10016",
          "publishedOn": "2022-04-23T00:53:49.205Z",
          "wordCount": 670,
          "title": "ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v1 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1811.02117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Sha Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huawei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xingxing Wei</a>",
          "description": "An ability to predict the popularity dynamics of individual items within a\ncomplex evolving system has important implications in a wide range of domains.\nHere we propose a deep learning attention mechanism to model the process\nthrough which individual items gain their popularity. We analyze the\ninterpretability of the model with the four key phenomena confirmed\nindependently in the previous studies of long-term popularity dynamics\nquantification, including the intrinsic quality, the aging effect, the recency\neffect and the Matthew effect. We analyze the effectiveness of introducing\nattention model in popularity dynamics prediction. Extensive experiments on a\nreal-large citation data set demonstrate that the designed deep learning\nattention mechanism possesses remarkable power at predicting the long-term\npopularity dynamics. It consistently outperforms the existing methods, and\nachieves a significant performance improvement.",
          "link": "http://arxiv.org/abs/1811.02117",
          "publishedOn": "2022-04-23T00:53:49.198Z",
          "wordCount": 622,
          "title": "Modeling and Predicting Popularity Dynamics via Deep Learning Attention Mechanism. (arXiv:1811.02117v2 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.08044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohamadi_S/0/1/0/all/0/1\">Salman Mohamadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amindavar_H/0/1/0/all/0/1\">Hamidreza Amindavar</a>",
          "description": "Active learning frameworks offer efficient data annotation without remarkable\naccuracy degradation. In other words, active learning starts training the model\nwith a small size of labeled data while exploring the space of unlabeled data\nin order to select most informative samples to be labeled. Generally speaking,\nrepresenting the uncertainty is crucial in any active learning framework,\nhowever, deep learning methods are not capable of either representing or\nmanipulating model uncertainty. On the other hand, from the real world\napplication perspective, uncertainty representation is getting more and more\nattention in the machine learning community. Deep Bayesian active learning\nframeworks and generally any Bayesian active learning settings, provide\npractical consideration in the model which allows training with small data\nwhile representing the model uncertainty for further efficient training. In\nthis paper, we briefly survey recent advances in Bayesian active learning and\nin particular deep Bayesian active learning frameworks.",
          "link": "http://arxiv.org/abs/2012.08044",
          "publishedOn": "2022-04-23T00:53:49.186Z",
          "wordCount": null,
          "title": "Deep Bayesian Active Learning, A Brief Survey on Recent Advances. (arXiv:2012.08044v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haq_A/0/1/0/all/0/1\">Aizaz Ul Haq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_N/0/1/0/all/0/1\">Niranjana Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ElSaid_A/0/1/0/all/0/1\">AbdElRahman ElSaid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desell_T/0/1/0/all/0/1\">Travis Desell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krutz_D/0/1/0/all/0/1\">Daniel E. Krutz</a>",
          "description": "Self-adaptive systems frequently use tactics to perform adaptations. Tactic\nexamples include the implementation of additional security measures when an\nintrusion is detected, or activating a cooling mechanism when temperature\nthresholds are surpassed. Tactic volatility occurs in real-world systems and is\ndefined as variable behavior in the attributes of a tactic, such as its latency\nor cost. A system's inability to effectively account for tactic volatility\nadversely impacts its efficiency and resiliency against the dynamics of\nreal-world environments. To enable systems' efficiency against tactic\nvolatility, we propose a Tactic Volatility Aware (TVA-E) process utilizing\nevolved Recurrent Neural Networks (eRNN) to provide accurate tactic\npredictions. TVA-E is also the first known process to take advantage of\nuncertainty reduction tactics to provide additional information to the\ndecision-making process and reduce uncertainty. TVA-E easily integrates into\npopular adaptation processes enabling it to immediately benefit a large number\nof existing self-adaptive systems. Simulations using 52,106 tactic records\ndemonstrate that: I) eRNN is an effective prediction mechanism, II) TVA-E\nrepresents an improvement over existing state-of-the-art processes in\naccounting for tactic volatility, and III) Uncertainty reduction tactics are\nbeneficial in accounting for tactic volatility. The developed dataset and tool\ncan be found at https://tacticvolatility.github.io/",
          "link": "http://arxiv.org/abs/2204.10308",
          "publishedOn": "2022-04-23T00:53:49.181Z",
          "wordCount": null,
          "title": "Addressing Tactic Volatility in Self-Adaptive Systems Using Evolved Recurrent Neural Networks and Uncertainty Reduction Tactics. (arXiv:2204.10308v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.06022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takase_S/0/1/0/all/0/1\">Sho Takase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiyono_S/0/1/0/all/0/1\">Shun Kiyono</a>",
          "description": "We propose a parameter sharing method for Transformers (Vaswani et al.,\n2017). The proposed approach relaxes a widely used technique, which shares\nparameters for one layer with all layers such as Universal Transformers\n(Dehghani et al., 2019), to increase the efficiency in the computational time.\nWe propose three strategies: Sequence, Cycle, and Cycle (rev) to assign\nparameters to each layer. Experimental results show that the proposed\nstrategies are efficient in the parameter size and computational time.\nMoreover, we indicate that the proposed strategies are also effective in the\nconfiguration where we use many training data such as the recent WMT\ncompetition.",
          "link": "http://arxiv.org/abs/2104.06022",
          "publishedOn": "2022-04-23T00:53:49.160Z",
          "wordCount": 572,
          "title": "Lessons on Parameter Sharing across Layers in Transformers. (arXiv:2104.06022v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Taoran Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Zhiqing Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chunping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiarong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>",
          "description": "Graph Neural Networks (GNNs) are powerful tools for graph representation\nlearning. Despite their rapid development, GNNs also faces some challenges,\nsuch as over-fitting, over-smoothing, and non-robustness. Previous works\nindicate that these problems can be alleviated by random dropping methods,\nwhich integrate noises into models by randomly masking parts of the input.\nHowever, some open-ended problems of random dropping on GNNs remain to solve.\nFirst, it is challenging to find a universal method that are suitable for all\ncases considering the divergence of different datasets and models. Second,\nrandom noises introduced to GNNs cause the incomplete coverage of parameters\nand unstable training process. In this paper, we propose a novel random\ndropping method called DropMessage, which performs dropping operations directly\non the message matrix and can be applied to any message-passing GNNs.\nFurthermore, we elaborate the superiority of DropMessage: it stabilizes the\ntraining process by reducing sample variance; it keeps information diversity\nfrom the perspective of information theory, which makes it a theoretical upper\nbound of other methods. Also, we unify existing random dropping methods into\nour framework and analyze their effects on GNNs. To evaluate our proposed\nmethod, we conduct experiments that aims for multiple tasks on five public\ndatasets and two industrial datasets with various backbone models. The\nexperimental results show that DropMessage has both advantages of effectiveness\nand generalization.",
          "link": "http://arxiv.org/abs/2204.10037",
          "publishedOn": "2022-04-23T00:53:49.136Z",
          "wordCount": 662,
          "title": "DropMessage: Unifying Random Dropping for Graph Neural Networks. (arXiv:2204.10037v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haitao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guojiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lirong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan Z. Li</a>",
          "description": "Graph-based spatio-temporal neural networks are effective to model the\nspatial dependency among discrete points sampled irregularly from unstructured\ngrids, thanks to the great expressiveness of graph neural networks. However,\nthese models are usually spatially-transductive -- only fitting the signals for\ndiscrete spatial nodes fed in models but unable to generalize to `unseen'\nspatial points with zero-shot. In comparison, for forecasting tasks on\ncontinuous space such as temperature prediction on the earth's surface, the\n\\textit{spatially-inductive} property allows the model to generalize to any\npoint in the spatial domain, demonstrating models' ability to learn the\nunderlying mechanisms or physics laws of the systems, rather than simply fit\nthe signals. Besides, in temporal domains, \\textit{irregularly-sampled} time\nseries, e.g. data with missing values, urge models to be temporally-continuous.\nMotivated by the two issues, we propose a spatio-temporal framework based on\nneural operators for PDEs, which learn the underlying mechanisms governing the\ndynamics of spatially-continuous physical quantities. Experiments show our\nmodel's improved performance on forecasting spatially-continuous physic\nquantities, and its superior generalization to unseen spatial points and\nability to handle temporally-irregular data.",
          "link": "http://arxiv.org/abs/2204.08414",
          "publishedOn": "2022-04-23T00:53:49.111Z",
          "wordCount": 624,
          "title": "STONet: A Neural-Operator-Driven Spatio-temporal Network. (arXiv:2204.08414v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amin_M/0/1/0/all/0/1\">Md Hasibul Amin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elbtity_M/0/1/0/all/0/1\">Mohammed Elbtity</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_M/0/1/0/all/0/1\">Mohammadreza Mohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zand_R/0/1/0/all/0/1\">Ramtin Zand</a>",
          "description": "We propose an analog implementation of the transcendental activation function\nleveraging two spin-orbit torque magnetoresistive random-access memory\n(SOT-MRAM) devices and a CMOS inverter. The proposed analog neuron circuit\nconsumes 1.8-27x less power, and occupies 2.5-4931x smaller area, compared to\nthe state-of-the-art analog and digital implementations. Moreover, the\ndeveloped neuron can be readily integrated with memristive crossbars without\nrequiring any intermediate signal conversion units. The architecture-level\nanalyses show that a fully-analog in-memory computing (IMC) circuit that use\nour SOT-MRAM neuron along with an SOT-MRAM based crossbar can achieve more than\n1.1x, 12x, and 13.3x reduction in power, latency, and energy, respectively,\ncompared to a mixed-signal implementation with analog memristive crossbars and\ndigital neurons. Finally, through cross-layer analyses, we provide a guide on\nhow varying the device-level parameters in our neuron can affect the accuracy\nof multilayer perceptron (MLP) for MNIST classification.",
          "link": "http://arxiv.org/abs/2204.09918",
          "publishedOn": "2022-04-23T00:53:49.066Z",
          "wordCount": 582,
          "title": "MRAM-based Analog Sigmoid Function for In-memory Computing. (arXiv:2204.09918v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10177",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Morel_R/0/1/0/all/0/1\">Rudy Morel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rochette_G/0/1/0/all/0/1\">Gaspar Rochette</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Leonarduzzi_R/0/1/0/all/0/1\">Roberto Leonarduzzi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bouchaud_J/0/1/0/all/0/1\">Jean-Philippe Bouchaud</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mallat_S/0/1/0/all/0/1\">St&#xe9;phane Mallat</a>",
          "description": "We introduce a scattering covariance matrix which provides non-Gaussian\nmodels of time-series having stationary increments. A complex wavelet transform\ncomputes signal variations at each scale. Dependencies across scales are\ncaptured by the joint covariance across time and scales of complex wavelet\ncoefficients and their modulus. This covariance is nearly diagonalized by a\nsecond wavelet transform, which defines the scattering covariance. We show that\nthis set of moments characterizes a wide range of non-Gaussian properties of\nmulti-scale processes. This is analyzed for a variety of processes, including\nfractional Brownian motions, Poisson, multifractal random walks and Hawkes\nprocesses. We prove that self-similar processes have a scattering covariance\nmatrix which is scale invariant. This property can be estimated numerically and\ndefines a class of wide-sense self-similar processes. We build maximum entropy\nmodels conditioned by scattering covariance coefficients, and generate new\ntime-series with a microcanonical sampling algorithm. Applications are shown\nfor highly non-Gaussian financial and turbulence time-series.",
          "link": "http://arxiv.org/abs/2204.10177",
          "publishedOn": "2022-04-23T00:53:49.059Z",
          "wordCount": 622,
          "title": "Scale Dependencies and Self-Similarity Through Wavelet Scattering Covariance. (arXiv:2204.10177v1 [physics.data-an])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haoyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patras_P/0/1/0/all/0/1\">Paul Patras</a>",
          "description": "Machine Learning (ML) techniques are increasingly adopted to tackle\never-evolving high-profile network attacks, including DDoS, botnet, and\nransomware, due to their unique ability to extract complex patterns hidden in\ndata streams. These approaches are however routinely validated with data\ncollected in the same environment, and their performance degrades when deployed\nin different network topologies and/or applied on previously unseen traffic, as\nwe uncover. This suggests malicious/benign behaviors are largely learned\nsuperficially and ML-based Network Intrusion Detection System (NIDS) need\nrevisiting, to be effective in practice. In this paper we dive into the\nmechanics of large-scale network attacks, with a view to understanding how to\nuse ML for Network Intrusion Detection (NID) in a principled way. We reveal\nthat, although cyberattacks vary significantly in terms of payloads, vectors\nand targets, their early stages, which are critical to successful attack\noutcomes, share many similarities and exhibit important temporal correlations.\nTherefore, we treat NID as a time-sensitive task and propose NetSentry, perhaps\nthe first of its kind NIDS that builds on Bidirectional Asymmetric LSTM\n(Bi-ALSTM), an original ensemble of sequential neural models, to detect network\nthreats before they spread. We cross-evaluate NetSentry using two practical\ndatasets, training on one and testing on the other, and demonstrate F1 score\ngains above 33% over the state-of-the-art, as well as up to 3 times higher\nrates of detecting attacks such as XSS and web bruteforce. Further, we put\nforward a novel data augmentation technique that boosts the generalization\nabilities of a broad range of supervised deep learning algorithms, leading to\naverage F1 score gains above 35%.",
          "link": "http://arxiv.org/abs/2202.09873",
          "publishedOn": "2022-04-23T00:53:49.051Z",
          "wordCount": 724,
          "title": "NetSentry: A Deep Learning Approach to Detecting Incipient Large-scale Network Attacks. (arXiv:2202.09873v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_A/0/1/0/all/0/1\">Anjul Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_P/0/1/0/all/0/1\">Pushkar Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Swasti Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_K/0/1/0/all/0/1\">Klaus Mueller</a>",
          "description": "Infographics are an aesthetic visual representation of information following\nspecific design principles of human perception. Designing infographics can be a\ntedious process for non-experts and time-consuming, even for professional\ndesigners. With the help of designers, we propose a semi-automated infographic\nframework for general structured and flow-based infographic design generation.\nFor novice designers, our framework automatically creates and ranks infographic\ndesigns for a user-provided text with no requirement for design input. However,\nexpert designers can still provide custom design inputs to customize the\ninfographics. We will also contribute an individual visual group (VG) designs\ndataset (in SVG), along with a 1k complete infographic image dataset with\nsegmented VGs in this work. Evaluation results confirm that by using our\nframework, designers from all expertise levels can generate generic infographic\ndesigns faster than existing methods while maintaining the same quality as\nhand-designed infographics templates.",
          "link": "http://arxiv.org/abs/2204.09904",
          "publishedOn": "2022-04-23T00:53:49.035Z",
          "wordCount": 616,
          "title": "Infographics Wizard: Flexible Infographics Authoring and Design Exploration. (arXiv:2204.09904v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lingxiao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Wei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1\">Leman Akoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>",
          "description": "Message Passing Neural Networks (MPNNs) are a common type of Graph Neural\nNetwork (GNN), in which each node's representation is computed recursively by\naggregating representations (messages) from its immediate neighbors akin to a\nstar-shaped pattern. MPNNs are appealing for being efficient and scalable,\nhow-ever their expressiveness is upper-bounded by the 1st-order\nWeisfeiler-Lehman isomorphism test (1-WL). In response, prior works propose\nhighly expressive models at the cost of scalability and sometimes\ngeneralization performance. Our work stands between these two regimes: we\nintroduce a general framework to uplift any MPNN to be more expressive, with\nlimited scalability overhead and greatly improved practical performance. We\nachieve this by extending local aggregation in MPNNs from star patterns to\ngeneral subgraph patterns (e.g.,k-egonets):in our framework, each node\nrepresentation is computed as the encoding of a surrounding induced subgraph\nrather than encoding of immediate neighbors only (i.e. a star). We choose the\nsubgraph encoder to be a GNN (mainly MPNNs, considering scalability) to design\na general framework that serves as a wrapper to up-lift any GNN. We call our\nproposed method GNN-AK(GNN As Kernel), as the framework resembles a\nconvolutional neural network by replacing the kernel with GNNs. Theoretically,\nwe show that our framework is strictly more powerful than 1&2-WL, and is not\nless powerful than 3-WL. We also design subgraph sampling strategies which\ngreatly reduce memory footprint and improve speed while maintaining\nperformance. Our method sets new state-of-the-art performance by large margins\nfor several well-known graph ML tasks; specifically, 0.08 MAE on ZINC,74.79%\nand 86.887% accuracy on CIFAR10 and PATTERN respectively.",
          "link": "http://arxiv.org/abs/2110.03753",
          "publishedOn": "2022-04-23T00:53:48.951Z",
          "wordCount": 740,
          "title": "From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness. (arXiv:2110.03753v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karim_N/0/1/0/all/0/1\">Nazmul Karim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalid_U/0/1/0/all/0/1\">Umar Khalid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmaeili_A/0/1/0/all/0/1\">Ashkan Esmaeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahnavard_N/0/1/0/all/0/1\">Nazanin Rahnavard</a>",
          "description": "The task of continual learning requires careful design of algorithms that can\ntackle catastrophic forgetting. However, the noisy label, which is inevitable\nin a real-world scenario, seems to exacerbate the situation. While very few\nstudies have addressed the issue of continual learning under noisy labels, long\ntraining time and complicated training schemes limit their applications in most\ncases. In contrast, we propose a simple purification technique to effectively\ncleanse the online data stream that is both cost-effective and more accurate.\nAfter purification, we perform fine-tuning in a semi-supervised fashion that\nensures the participation of all available samples. Training in this fashion\nhelps us learn a better representation that results in state-of-the-art (SOTA)\nperformance. Through extensive experimentation on 3 benchmark datasets, MNIST,\nCIFAR10 and CIFAR100, we show the effectiveness of our proposed approach. We\nachieve a 24.8% performance gain for CIFAR10 with 20% noise over previous SOTA\nmethods. Our code is publicly available.",
          "link": "http://arxiv.org/abs/2204.09881",
          "publishedOn": "2022-04-23T00:53:48.170Z",
          "wordCount": 620,
          "title": "CNLL: A Semi-supervised Approach For Continual Noisy Label Learning. (arXiv:2204.09881v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.08044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Peilun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_F/0/1/0/all/0/1\">Fan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hui Guo</a>",
          "description": "Email threat is a serious issue for enterprise security, which consists of\nvarious malicious scenarios, such as phishing, fraud, blackmail and\nmalvertisement. Traditional anti-spam gateway commonly requires to maintain a\ngreylist to filter out unexpected emails based on suspicious vocabularies\nexisted in the mail subject and content. However, the signature-based approach\ncannot effectively discover novel and unknown suspicious emails that utilize\nvarious hot topics at present, such as COVID-19 and US election. To address the\nproblem, in this paper, we present Holmes, an efficient and lightweight\nsemantic based engine for anomalous email detection. Holmes can convert each\nevent log of email to a sentence through word embedding then extract\ninteresting items among them by novelty detection. Based on our observations,\nwe claim that, in an enterprise environment, there is a stable relation between\nsenders and receivers, but suspicious emails are commonly from unusual sources,\nwhich can be detected through the rareness selection. We evaluate the\nperformance of Holmes in a real-world enterprise environment, in which it sends\nand receives around 5,000 emails each day. As a result, Holmes can achieve a\nhigh detection rate (output around 200 suspicious emails per day) and maintain\na low false alarm rate for anomaly detection.",
          "link": "http://arxiv.org/abs/2104.08044",
          "publishedOn": "2022-04-23T00:53:48.091Z",
          "wordCount": 793,
          "title": "Holmes: An Efficient and Lightweight Semantic Based Anomalous Email Detector. (arXiv:2104.08044v11 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Baihan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouneffouf_D/0/1/0/all/0/1\">Djallel Bouneffouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cecchi_G/0/1/0/all/0/1\">Guillermo Cecchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tejwani_R/0/1/0/all/0/1\">Ravi Tejwani</a>",
          "description": "In this work, we compare different neural topic modeling methods in learning\nthe topical propensities of different psychiatric conditions from the\npsychotherapy session transcripts parsed from speech recordings. We also\nincorporate temporal modeling to put this additional interpretability to action\nby parsing out topic similarities as a time series in a turn-level resolution.\nWe believe this topic modeling framework can offer interpretable insights for\nthe therapist to optimally decide his or her strategy and improve the\npsychotherapy effectiveness.",
          "link": "http://arxiv.org/abs/2204.10189",
          "publishedOn": "2022-04-23T00:53:48.060Z",
          "wordCount": 546,
          "title": "Neural Topic Modeling of Psychotherapy Sessions. (arXiv:2204.10189v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.03622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1\">Kendrick Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yining Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Self-training algorithms, which train a model to fit pseudolabels predicted\nby another previously-learned model, have been very successful for learning\nwith unlabeled data using neural networks. However, the current theoretical\nunderstanding of self-training only applies to linear models. This work\nprovides a unified theoretical analysis of self-training with deep networks for\nsemi-supervised learning, unsupervised domain adaptation, and unsupervised\nlearning. At the core of our analysis is a simple but realistic \"expansion\"\nassumption, which states that a low probability subset of the data must expand\nto a neighborhood with large probability relative to the subset. We also assume\nthat neighborhoods of examples in different classes have minimal overlap. We\nprove that under these assumptions, the minimizers of population objectives\nbased on self-training and input-consistency regularization will achieve high\naccuracy with respect to ground-truth labels. By using off-the-shelf\ngeneralization bounds, we immediately convert this result to sample complexity\nguarantees for neural nets that are polynomial in the margin and Lipschitzness.\nOur results help explain the empirical successes of recently proposed\nself-training algorithms which use input consistency regularization.",
          "link": "http://arxiv.org/abs/2010.03622",
          "publishedOn": "2022-04-23T00:53:48.046Z",
          "wordCount": 677,
          "title": "Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. (arXiv:2010.03622v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.05094",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhaubhadel_S/0/1/0/all/0/1\">Sayera Dhaubhadel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohd_Yusof_J/0/1/0/all/0/1\">Jamaludin Mohd-Yusof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_K/0/1/0/all/0/1\">Kumkum Ganguly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chennupati_G/0/1/0/all/0/1\">Gopinath Chennupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thulasidasan_S/0/1/0/all/0/1\">Sunil Thulasidasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengartner_N/0/1/0/all/0/1\">Nicolas W. Hengartner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mumphrey_B/0/1/0/all/0/1\">Brent J. Mumphrey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durbin_E/0/1/0/all/0/1\">Eric B. Durbin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doherty_J/0/1/0/all/0/1\">Jennifer A. Doherty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemieux_M/0/1/0/all/0/1\">Mireille Lemieux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaefferkoetter_N/0/1/0/all/0/1\">Noah Schaefferkoetter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tourassi_G/0/1/0/all/0/1\">Georgia Tourassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coyle_L/0/1/0/all/0/1\">Linda Coyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Penberthy_L/0/1/0/all/0/1\">Lynne Penberthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McMahon_B/0/1/0/all/0/1\">Benjamin H. McMahon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_T/0/1/0/all/0/1\">Tanmoy Bhattacharya</a>",
          "description": "Safe deployment of deep learning systems in critical real world applications\nrequires models to make very few mistakes, and only under predictable\ncircumstances. In this work, we address this problem using an abstaining\nclassifier that is tuned to have $>$95% accuracy, and then identify the\ndeterminants of abstention using LIME. Essentially, we are training our model\nto learn the attributes of pathology reports that are likely to lead to\nincorrect classifications, albeit at the cost of reduced sensitivity. We\ndemonstrate an abstaining classifier in a multitask setting for classifying\ncancer pathology reports from the NCI SEER cancer registries on six tasks of\ninterest. For these tasks, we reduce the classification error rate by factors\nof 2--5 by abstaining on 25--45% of the reports. For the specific task of\nclassifying cancer site, we are able to identify metastasis, reports involving\nlymph nodes, and discussion of multiple cancer sites as responsible for many of\nthe classification mistakes, and observe that the extent and types of mistakes\nvary systematically with cancer site (e.g., breast, lung, and prostate). When\ncombining across three of the tasks, our model classifies 50% of the reports\nwith an accuracy greater than 95% for three of the six tasks\\edit, and greater\nthan 85% for all six tasks on the retained samples. Furthermore, we show that\nLIME provides a better determinant of classification than measures of word\noccurrence alone. By combining a deep abstaining classifier with feature\nidentification using LIME, we are able to identify concepts responsible for\nboth correctness and abstention when classifying cancer sites from pathology\nreports. The improvement of LIME over keyword searches is statistically\nsignificant, presumably because words are assessed in context and have been\nidentified as a local determinant of classification.",
          "link": "http://arxiv.org/abs/2009.05094",
          "publishedOn": "2022-04-23T00:53:48.022Z",
          "wordCount": 823,
          "title": "Why I'm not Answering: Understanding Determinants of Classification of an Abstaining Classifier for Cancer Pathology Reports. (arXiv:2009.05094v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10128",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yongjing Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pengpeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xian_X/0/1/0/all/0/1\">Xuefeng Xian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guanfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Deqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lei Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yanchi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_V/0/1/0/all/0/1\">Victor S. Sheng</a>",
          "description": "Sequential Recommendation aims to predict the next item based on user\nbehaviour. Recently, Self-Supervised Learning (SSL) has been proposed to\nimprove recommendation performance. However, most of existing SSL methods use a\nuniform data augmentation scheme, which loses the sequence correlation of an\noriginal sequence. To this end, in this paper, we propose a Learnable Model\nAugmentation self-supervised learning for sequential Recommendation (LMA4Rec).\nSpecifically, LMA4Rec first takes model augmentation as a supplementary method\nfor data augmentation to generate views. Then, LMA4Rec uses learnable Bernoulli\ndropout to implement model augmentation learnable operations. Next,\nself-supervised learning is used between the contrastive views to extract\nself-supervised signals from an original sequence. Finally, experiments on\nthree public datasets show that the LMA4Rec method effectively improves\nsequential recommendation performance compared with baseline methods.",
          "link": "http://arxiv.org/abs/2204.10128",
          "publishedOn": "2022-04-23T00:53:47.986Z",
          "wordCount": 573,
          "title": "Learnable Model Augmentation Self-Supervised Learning for Sequential Recommendation. (arXiv:2204.10128v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haotian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhijian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yujun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>",
          "description": "Deep learning on point clouds has received increased attention thanks to its\nwide applications in AR/VR and autonomous driving. These applications require\nlow latency and high accuracy to provide real-time user experience and ensure\nuser safety. Unlike conventional dense workloads, the sparse and irregular\nnature of point clouds poses severe challenges to running sparse CNNs\nefficiently on the general-purpose hardware. Furthermore, existing sparse\nacceleration techniques for 2D images do not translate to 3D point clouds. In\nthis paper, we introduce TorchSparse, a high-performance point cloud inference\nengine that accelerates the sparse convolution computation on GPUs. TorchSparse\ndirectly optimizes the two bottlenecks of sparse convolution: irregular\ncomputation and data movement. It applies adaptive matrix multiplication\ngrouping to trade computation for better regularity, achieving 1.4-1.5x speedup\nfor matrix multiplication. It also optimizes the data movement by adopting\nvectorized, quantized and fused locality-aware memory access, reducing the\nmemory movement cost by 2.7x. Evaluated on seven representative models across\nthree benchmark datasets, TorchSparse achieves 1.6x and 1.5x measured\nend-to-end speedup over the state-of-the-art MinkowskiEngine and SpConv,\nrespectively.",
          "link": "http://arxiv.org/abs/2204.10319",
          "publishedOn": "2022-04-23T00:53:47.979Z",
          "wordCount": 631,
          "title": "TorchSparse: Efficient Point Cloud Inference Engine. (arXiv:2204.10319v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tonderski_A/0/1/0/all/0/1\">Adam Tonderski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnander_J/0/1/0/all/0/1\">Joakim Johnander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petersson_C/0/1/0/all/0/1\">Christoffer Petersson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+%7B%5CAA%7Dstrom_K/0/1/0/all/0/1\">Kalle &#xc5;str&#xf6;m</a>",
          "description": "We explore future object prediction -- a challenging problem where all\nobjects visible in a future video frame are to be predicted. We propose to\ntackle this problem end-to-end by training a detection transformer to directly\noutput future objects. In order to make accurate predictions about the future,\nit is necessary to capture the dynamics in the scene, both of other objects and\nof the ego-camera. We extend existing detection transformers in two ways to\ncapture the scene dynamics. First, we experiment with three different\nmechanisms that enable the model to spatiotemporally process multiple frames.\nSecond, we feed ego-motion information to the model via cross-attention. We\nshow that both of these cues substantially improve future object prediction\nperformance. Our final approach learns to capture the dynamics and make\npredictions on par with an oracle for 100 ms prediction horizons, and\noutperform baselines for longer prediction horizons.",
          "link": "http://arxiv.org/abs/2204.10321",
          "publishedOn": "2022-04-23T00:53:47.972Z",
          "wordCount": 595,
          "title": "Learning Future Object Prediction with a Spatiotemporal Detection Transformer. (arXiv:2204.10321v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1905.09449",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanwei Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Donghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1\">Zuyuan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xinwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jinshan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>",
          "description": "The great success of deep neural networks is built upon their\nover-parameterization, which smooths the optimization landscape without\ndegrading the generalization ability. Despite the benefits of\nover-parameterization, a huge amount of parameters makes deep networks\ncumbersome in daily life applications. Though techniques such as pruning and\ndistillation are developed, they are expensive in fully training a dense\nnetwork as backward selection methods, and there is still a void on\nsystematically exploring forward selection methods for learning structural\nsparsity in deep networks. To fill in this gap, this paper proposes a new\napproach based on differential inclusions of inverse scale spaces, which\ngenerate a family of models from simple to complex ones along the dynamics via\ncoupling a pair of parameters, such that over-parameterized deep models and\ntheir structural sparsity can be explored simultaneously. This kind of\ndifferential inclusion scheme has a simple discretization, dubbed Deep\nstructure splitting Linearized Bregman Iteration (DessiLBI), whose global\nconvergence in learning deep networks could be established under the\nKurdyka-Lojasiewicz framework. Experimental evidence shows that our method\nachieves comparable and even better performance than the competitive optimizers\nin exploring the sparse structure of several widely used backbones on the\nbenchmark datasets. Remarkably, with early stopping, our method unveils\n`winning tickets' in early epochs: the effective sparse network structures with\ncomparable test accuracy to fully trained over-parameterized models, that are\nfurther transferable to similar alternative tasks. Furthermore, our method is\nable to grow networks efficiently with adaptive filter configurations,\ndemonstrating a good performance with much less computational cost. Codes and\nmodels can be downloaded at {https://github.com/DessiLBI2020/DessiLBI}.",
          "link": "http://arxiv.org/abs/1905.09449",
          "publishedOn": "2022-04-23T00:53:47.951Z",
          "wordCount": 811,
          "title": "Exploring Structural Sparsity of Deep Networks via Inverse Scale Spaces. (arXiv:1905.09449v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sudharsan_B/0/1/0/all/0/1\">Bharath Sudharsan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_D/0/1/0/all/0/1\">Dineshkumar Sundaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_P/0/1/0/all/0/1\">Pankesh Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breslin_J/0/1/0/all/0/1\">John G. Breslin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1\">Muhammad Intizar Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dustdar_S/0/1/0/all/0/1\">Schahram Dustdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zomaya_A/0/1/0/all/0/1\">Albert Zomaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranjan_R/0/1/0/all/0/1\">Rajiv Ranjan</a>",
          "description": "The majority of IoT devices like smartwatches, smart plugs, HVAC controllers,\netc., are powered by hardware with a constrained specification (low memory,\nclock speed and processor) which is insufficient to accommodate and execute\nlarge, high-quality models. On such resource-constrained devices, manufacturers\nstill manage to provide attractive functionalities (to boost sales) by\nfollowing the traditional approach of programming IoT devices/products to\ncollect and transmit data (image, audio, sensor readings, etc.) to their\ncloud-based ML analytics platforms. For decades, this online approach has been\nfacing issues such as compromised data streams, non-real-time analytics due to\nlatency, bandwidth constraints, costly subscriptions, recent privacy issues\nraised by users and the GDPR guidelines, etc. In this paper, to enable\nultra-fast and accurate AI-based offline analytics on resource-constrained IoT\ndevices, we present an end-to-end multi-component model optimization sequence\nand open-source its implementation. Researchers and developers can use our\noptimization sequence to optimize high memory, computation demanding models in\nmultiple aspects in order to produce small size, low latency, low-power\nconsuming models that can comfortably fit and execute on resource-constrained\nhardware. The experimental results show that our optimization components can\nproduce models that are; (i) 12.06 x times compressed; (ii) 0.13% to 0.27% more\naccurate; (iii) Orders of magnitude faster unit inference at 0.06 ms. Our\noptimization sequence is generic and can be applied to any state-of-the-art\nmodels trained for anomaly detection, predictive maintenance, robotics, voice\nrecognition, and machine vision.",
          "link": "http://arxiv.org/abs/2204.10183",
          "publishedOn": "2022-04-23T00:53:47.902Z",
          "wordCount": 689,
          "title": "Multi-Component Optimization and Efficient Deployment of Neural-Networks on Resource-Constrained IoT Hardware. (arXiv:2204.10183v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akpinar_N/0/1/0/all/0/1\">Nil-Jana Akpinar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagireddy_M/0/1/0/all/0/1\">Manish Nagireddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stapleton_L/0/1/0/all/0/1\">Logan Stapleton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao-Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Haiyi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Steven Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidari_H/0/1/0/all/0/1\">Hoda Heidari</a>",
          "description": "Motivated by the growing importance of reducing unfairness in ML predictions,\nFair-ML researchers have presented an extensive suite of algorithmic\n\"fairness-enhancing\" remedies. Most existing algorithms, however, are agnostic\nto the sources of the observed unfairness. As a result, the literature\ncurrently lacks guiding frameworks to specify conditions under which each\nalgorithmic intervention can potentially alleviate the underpinning cause of\nunfairness. To close this gap, we scrutinize the underlying biases (e.g., in\nthe training data or design choices) that cause observational unfairness. We\npresent a bias-injection sandbox tool to investigate fairness consequences of\nvarious biases and assess the effectiveness of algorithmic remedies in the\npresence of specific types of bias. We call this process the\nbias(stress)-testing of algorithmic interventions. Unlike existing toolkits,\nours provides a controlled environment to counterfactually inject biases in the\nML pipeline. This stylized setup offers the distinct capability of testing\nfairness interventions beyond observational data and against an unbiased\nbenchmark. In particular, we can test whether a given remedy can alleviate the\ninjected bias by comparing the predictions resulting after the intervention in\nthe biased setting with true labels in the unbiased regime -- that is, before\nany bias injection. We illustrate the utility of our toolkit via a\nproof-of-concept case study on synthetic data. Our empirical analysis showcases\nthe type of insights that can be obtained through our simulations.",
          "link": "http://arxiv.org/abs/2204.10233",
          "publishedOn": "2022-04-23T00:53:47.893Z",
          "wordCount": 665,
          "title": "A Sandbox Tool to Bias(Stress)-Test Fairness Algorithms. (arXiv:2204.10233v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garland_A/0/1/0/all/0/1\">Anthony Garland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potter_K/0/1/0/all/0/1\">Kevin Potter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Matt Smith</a>",
          "description": "Anomaly detection is important for industrial automation and part quality\nassurance, and while humans can easily detect anomalies in components given a\nfew examples, designing a generic automated system that can perform at human or\nabove human capabilities remains a challenge. In this work, we present a simple\nnew anomaly detection algorithm called FADS (feature-based anomaly detection\nsystem) which leverages pretrained convolutional neural networks (CNN) to\ngenerate a statistical model of nominal inputs by observing the activation of\nthe convolutional filters. During inference the system compares the\nconvolutional filter activation of the new input to the statistical model and\nflags activations that are outside the expected range of values and therefore\nlikely an anomaly. By using a pretrained network, FADS demonstrates excellent\nperformance similar to or better than other machine learning approaches to\nanomaly detection while at the same time FADS requires no tuning of the CNN\nweights. We demonstrate FADS ability by detecting process parameter changes on\na custom dataset of additively manufactured lattices. The FADS localization\nalgorithm shows that textural differences that are visible on the surface can\nbe used to detect process parameter changes. In addition, we test FADS on\nbenchmark datasets, such as the MVTec Anomaly Detection dataset, and report\ngood results.",
          "link": "http://arxiv.org/abs/2204.10318",
          "publishedOn": "2022-04-23T00:53:47.834Z",
          "wordCount": 649,
          "title": "Feature anomaly detection system (FADS) for intelligent manufacturing. (arXiv:2204.10318v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10083",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamaide_V/0/1/0/all/0/1\">Valentin Hamaide</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joassin_D/0/1/0/all/0/1\">Denis Joassin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castin_L/0/1/0/all/0/1\">Lauriane Castin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glineur_F/0/1/0/all/0/1\">Fran&#xe7;ois Glineur</a>",
          "description": "Predicting incoming failures and scheduling maintenance based on sensors\ninformation in industrial machines is increasingly important to avoid downtime\nand machine failure. Different machine learning formulations can be used to\nsolve the predictive maintenance problem. However, many of the approaches\nstudied in the literature are not directly applicable to real-life scenarios.\nIndeed, many of those approaches usually either rely on labelled machine\nmalfunctions in the case of classification and fault detection, or rely on\nfinding a monotonic health indicator on which a prediction can be made in the\ncase of regression and remaining useful life estimation, which is not always\nfeasible. Moreover, the decision-making part of the problem is not always\nstudied in conjunction with the prediction phase. This paper aims to design and\ncompare different formulations for predictive maintenance in a two-level\nframework and design metrics that quantify both the failure detection\nperformance as well as the timing of the maintenance decision. The first level\nis responsible for building a health indicator by aggregating features using a\nlearning algorithm. The second level consists of a decision-making system that\ncan trigger an alarm based on this health indicator. Three degrees of\nrefinements are compared in the first level of the framework, from simple\nthreshold-based univariate predictive technique to supervised learning methods\nbased on the remaining time before failure. We choose to use the Support Vector\nMachine (SVM) and its variations as the common algorithm used in all the\nformulations. We apply and compare the different strategies on a real-world\nrotating machine case study and observe that while a simple model can already\nperform well, more sophisticated refinements enhance the predictions for\nwell-chosen parameters.",
          "link": "http://arxiv.org/abs/2204.10083",
          "publishedOn": "2022-04-23T00:53:47.780Z",
          "wordCount": 718,
          "title": "A two-level machine learning framework for predictive maintenance: comparison of learning formulations. (arXiv:2204.10083v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghazi_M/0/1/0/all/0/1\">Mehdi Mehdipour Ghazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramezani_A/0/1/0/all/0/1\">Amin Ramezani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siahi_M/0/1/0/all/0/1\">Mehdi Siahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghazi_M/0/1/0/all/0/1\">Mostafa Mehdipour Ghazi</a>",
          "description": "Urban traffic flow prediction using data-driven models can play an important\nrole in route planning and preventing congestion on highways. These methods\nutilize data collected from traffic recording stations at different timestamps\nto predict the future status of traffic. Hence, data collection, transmission,\nstorage, and extraction techniques can have a significant impact on the\nperformance of the traffic flow model. On the other hand, a comprehensive\ndatabase can provide the opportunity for using complex, yet reliable predictive\nmodels such as deep learning methods. However, most of these methods have\ndifficulties in handling missing values and outliers. This study focuses on\nhybrid deep neural networks to predict traffic flow in the California Freeway\nPerformance Measurement System (PeMS) with missing values. The proposed\nnetworks are based on a combination of recurrent neural networks (RNNs) to\nconsider the temporal dependencies in the data recorded in each station and\nconvolutional neural networks (CNNs) to take the spatial correlations in the\nadjacent stations into account. Various architecture configurations with series\nand parallel connections are considered based on RNNs and CNNs, and several\nprevalent data imputation techniques are used to examine the robustness of the\nhybrid networks to missing values. A comprehensive analysis performed on two\ndifferent datasets from PeMS indicates that the proposed series-parallel hybrid\nnetwork with the mean imputation technique achieves the lowest error in\npredicting the traffic flow and is robust to missing values up until 21%\nmissing ratio in both complete and incomplete training data scenarios when\napplied to an incomplete test data.",
          "link": "http://arxiv.org/abs/2204.10222",
          "publishedOn": "2022-04-23T00:53:47.772Z",
          "wordCount": 705,
          "title": "Learning spatiotemporal features from incomplete data for traffic flow prediction using hybrid deep neural networks. (arXiv:2204.10222v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juhwan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1\">Gabriel T. R. Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gharaibeh_Y/0/1/0/all/0/1\">Yazan Gharaibeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolluru_C/0/1/0/all/0/1\">Chaitanya Kolluru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimin_V/0/1/0/all/0/1\">Vladislav N. Zimin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dallan_L/0/1/0/all/0/1\">Luis A. P. Dallan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Justin N. Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoori_A/0/1/0/all/0/1\">Ammar Hoori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Kindi_S/0/1/0/all/0/1\">Sadeer G. Al-Kindi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guagliumi_G/0/1/0/all/0/1\">Giulio Guagliumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezerra_H/0/1/0/all/0/1\">Hiram G. Bezerra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1\">David L. Wilson</a>",
          "description": "Thin-cap fibroatheroma (TCFA) and plaque rupture have been recognized as the\nmost frequent risk factor for thrombosis and acute coronary syndrome.\nIntravascular optical coherence tomography (IVOCT) can identify TCFA and assess\ncap thickness, which provides an opportunity to assess plaque vulnerability. We\ndeveloped an automated method that can detect lipidous plaque and assess\nfibrous cap thickness in IVOCT images. This study analyzed a total of 4,360\nIVOCT image frames of 77 lesions among 41 patients. To improve segmentation\nperformance, preprocessing included lumen segmentation, pixel-shifting, and\nnoise filtering on the raw polar (r, theta) IVOCT images. We used the\nDeepLab-v3 plus deep learning model to classify lipidous plaque pixels. After\nlipid detection, we automatically detected the outer border of the fibrous cap\nusing a special dynamic programming algorithm and assessed the cap thickness.\nOur method provided excellent discriminability of lipid plaque with a\nsensitivity of 85.8% and A-line Dice coefficient of 0.837. By comparing lipid\nangle measurements between two analysts following editing of our automated\nsoftware, we found good agreement by Bland-Altman analysis (difference 6.7+/-17\ndegree; mean 196 degree). Our method accurately detected the fibrous cap from\nthe detected lipid plaque. Automated analysis required a significant\nmodification for only 5.5% frames. Furthermore, our method showed a good\nagreement of fibrous cap thickness between two analysts with Bland-Altman\nanalysis (4.2+/-14.6 micron; mean 175 micron), indicating little bias between\nusers and good reproducibility of the measurement. We developed a fully\nautomated method for fibrous cap quantification in IVOCT images, resulting in\ngood agreement with determinations by analysts. The method has great potential\nto enable highly automated, repeatable, and comprehensive evaluations of TCFAs.",
          "link": "http://arxiv.org/abs/2204.10162",
          "publishedOn": "2022-04-23T00:53:47.766Z",
          "wordCount": 749,
          "title": "Automated analysis of fibrous cap in intravascular optical coherence tomography images of coronary arteries. (arXiv:2204.10162v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10228",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sadjadi_S/0/1/0/all/0/1\">Seyed Omid Sadjadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greenberg_C/0/1/0/all/0/1\">Craig Greenberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singer_E/0/1/0/all/0/1\">Elliot Singer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mason_L/0/1/0/all/0/1\">Lisa Mason</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Reynolds_D/0/1/0/all/0/1\">Douglas Reynolds</a>",
          "description": "The US National Institute of Standards and Technology (NIST) has been\nconducting a second iteration of the CTS challenge since August 2020. The\ncurrent iteration of the CTS Challenge is a leaderboard-style speaker\nrecognition evaluation using telephony data extracted from the unexposed\nportions of the Call My Net 2 (CMN2) and Multi-Language Speech (MLS) corpora\ncollected by the LDC. The CTS Challenge is currently organized in a similar\nmanner to the SRE19 CTS Challenge, offering only an open training condition\nusing two evaluation subsets, namely Progress and Test. Unlike in the SRE19\nChallenge, no training or development set was initially released, and NIST has\npublicly released the leaderboards on both subsets for the CTS Challenge. Which\nsubset (i.e., Progress or Test) a trial belongs to is unknown to challenge\nparticipants, and each system submission needs to contain outputs for all of\nthe trials. The CTS Challenge has also served, and will continue to do so, as a\nprerequisite for entrance to the regular SREs (such as SRE21). Since August\n2020, a total of 53 organizations (forming 33 teams) from academia and industry\nhave participated in the CTS Challenge and submitted more than 4400 valid\nsystem outputs. This paper presents an overview of the evaluation and several\nanalyses of system performance for some primary conditions in the CTS\nChallenge. The CTS Challenge results thus far indicate remarkable improvements\nin performance due to 1) speaker embeddings extracted using large-scale and\ncomplex neural network architectures such as ResNets along with angular margin\nlosses for speaker embedding extraction, 2) extensive data augmentation, 3) the\nuse of large amounts of in-house proprietary data from a large number of\nlabeled speakers, 4) long-duration fine-tuning.",
          "link": "http://arxiv.org/abs/2204.10228",
          "publishedOn": "2022-04-23T00:53:47.759Z",
          "wordCount": 729,
          "title": "The NIST CTS Speaker Recognition Challenge. (arXiv:2204.10228v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shahriari_B/0/1/0/all/0/1\">Bobak Shahriari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdolmaleki_A/0/1/0/all/0/1\">Abbas Abdolmaleki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byravan_A/0/1/0/all/0/1\">Arunkumar Byravan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friesen_A/0/1/0/all/0/1\">Abe Friesen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Springenberg_J/0/1/0/all/0/1\">Jost Tobias Springenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1\">Nicolas Heess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_M/0/1/0/all/0/1\">Matt Hoffman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedmiller_M/0/1/0/all/0/1\">Martin Riedmiller</a>",
          "description": "Actor-critic algorithms that make use of distributional policy evaluation\nhave frequently been shown to outperform their non-distributional counterparts\non many challenging control tasks. Examples of this behavior include the D4PG\nand DMPO algorithms as compared to DDPG and MPO, respectively [Barth-Maron et\nal., 2018; Hoffman et al., 2020]. However, both agents rely on the C51 critic\nfor value estimation.One major drawback of the C51 approach is its requirement\nof prior knowledge about the minimum andmaximum values a policy can attain as\nwell as the number of bins used, which fixes the resolution ofthe\ndistributional estimate. While the DeepMind control suite of tasks utilizes\nstandardized rewards and episode lengths, thus enabling the entire suite to be\nsolved with a single setting of these hyperparameters, this is often not the\ncase. This paper revisits a natural alternative that removes this requirement,\nnamelya mixture of Gaussians, and a simple sample-based loss function to train\nit in an off-policy regime. We empirically evaluate its performance on a broad\nrange of continuous control tasks and demonstrate that it eliminates the need\nfor these distributional hyperparameters and achieves state-of-the-art\nperformance on a variety of challenging tasks (e.g. the humanoid, dog,\nquadruped, and manipulator domains). Finallywe provide an implementation in the\nAcme agent repository.",
          "link": "http://arxiv.org/abs/2204.10256",
          "publishedOn": "2022-04-23T00:53:47.734Z",
          "wordCount": 660,
          "title": "Revisiting Gaussian mixture critic in off-policy reinforcement learning: a sample-based approach. (arXiv:2204.10256v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biradar_S/0/1/0/all/0/1\">Shankar Biradar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saumya_S/0/1/0/all/0/1\">Sunil Saumya</a>",
          "description": "In recent years, there has been a lot of focus on offensive content. The\namount of offensive content generated by social media is increasing at an\nalarming rate. This created a greater need to address this issue than ever\nbefore. To address these issues, the organizers of \"Dravidian-Code Mixed\nHASOC-2020\" have created two challenges. Task 1 involves identifying offensive\ncontent in Malayalam data, whereas Task 2 includes Malayalam and Tamil Code\nMixed Sentences. Our team participated in Task 2. In our suggested model, we\nexperiment with multilingual BERT to extract features, and three different\nclassifiers are used on extracted features. Our model received a weighted F1\nscore of 0.70 for Malayalam data and was ranked fifth; we also received a\nweighted F1 score of 0.573 for Tamil Code Mixed data and were ranked eleventh.",
          "link": "http://arxiv.org/abs/2204.10195",
          "publishedOn": "2022-04-23T00:53:47.727Z",
          "wordCount": 587,
          "title": "IIITDWD-ShankarB@ Dravidian-CodeMixi-HASOC2021: mBERT based model for identification of offensive content in south Indian languages. (arXiv:2204.10195v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10202",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tanwar_A/0/1/0/all/0/1\">Ashwani Tanwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ive_J/0/1/0/all/0/1\">Julia Ive</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vibhor Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yike Guo</a>",
          "description": "Extracting phenotypes from clinical text has been shown to be useful for a\nvariety of clinical use cases such as identifying patients with rare diseases.\nHowever, reasoning with numerical values remains challenging for phenotyping in\nclinical text, for example, temperature 102F representing Fever. Current\nstate-of-the-art phenotyping models are able to detect general phenotypes, but\nperform poorly when they detect phenotypes requiring numerical reasoning. We\npresent a novel unsupervised methodology leveraging external knowledge and\ncontextualized word embeddings from ClinicalBERT for numerical reasoning in a\nvariety of phenotypic contexts. Comparing against unsupervised benchmarks, it\nshows a substantial performance improvement with absolute gains on generalized\nRecall and F1 scores up to 79% and 71%, respectively. In the supervised\nsetting, it also surpasses the performance of alternative approaches with\nabsolute gains on generalized Recall and F1 scores up to 70% and 44%,\nrespectively.",
          "link": "http://arxiv.org/abs/2204.10202",
          "publishedOn": "2022-04-23T00:53:47.698Z",
          "wordCount": 589,
          "title": "Unsupervised Numerical Reasoning to Extract Phenotypes from Clinical Text by Leveraging External Knowledge. (arXiv:2204.10202v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pavlitskaya_S/0/1/0/all/0/1\">Svetlana Pavlitskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yikmis_S/0/1/0/all/0/1\">&#x15e;iyar Y&#x131;km&#x131;&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zollner_J/0/1/0/all/0/1\">J. Marius Z&#xf6;llner</a>",
          "description": "The growing use of deep neural networks (DNNs) in safety- and\nsecurity-critical areas like autonomous driving raises the need for their\nsystematic testing. Coverage-guided testing (CGT) is an approach that applies\nmutation or fuzzing according to a predefined coverage metric to find inputs\nthat cause misbehavior. With the introduction of a neuron coverage metric, CGT\nhas also recently been applied to DNNs. In this work, we apply CGT to the task\nof person detection in crowded scenes. The proposed pipeline uses YOLOv3 for\nperson detection and includes finding DNN bugs via sampling and mutation, and\nsubsequent DNN retraining on the updated training set. To be a bug, we require\na mutated image to cause a significant performance drop compared to a clean\ninput. In accordance with the CGT, we also consider an additional requirement\nof increased coverage in the bug definition. In order to explore several types\nof robustness, our approach includes natural image transformations,\ncorruptions, and adversarial examples generated with the Daedalus attack. The\nproposed framework has uncovered several thousand cases of incorrect DNN\nbehavior. The relative change in mAP performance of the retrained models\nreached on average between 26.21\\% and 64.24\\% for different robustness types.\nHowever, we have found no evidence that the investigated coverage metrics can\nbe advantageously used to improve robustness.",
          "link": "http://arxiv.org/abs/2204.10027",
          "publishedOn": "2022-04-23T00:53:47.691Z",
          "wordCount": 670,
          "title": "Is Neuron Coverage Needed to Make Person Detection More Robust?. (arXiv:2204.10027v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barahona_I/0/1/0/all/0/1\">Igor Barahona</a>",
          "description": "Here I present an investigation on the evolution and use of vocabulary in\ndata science in the last 13 years. Based on a rigorous statistical analysis, a\ndatabase with 12,787 documents containing the words \"data science\" in the\ntitle, abstract or keywords is analyzed. It is proposed to classify the\nevolution of this discipline in three periods: emergence, growth and boom.\nCharacteristic words and pioneering documents are identified for each period.\nBy proposing the distinctive vocabulary and relevant topics of data science and\nclassified in time periods, these results add value to the scientific community\nof this discipline.",
          "link": "http://arxiv.org/abs/2204.10174",
          "publishedOn": "2022-04-23T00:53:47.685Z",
          "wordCount": 550,
          "title": "Evolution and use of data science vocabulary. How much have we changed in 13 years?. (arXiv:2204.10174v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Senrong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Feng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1\">Hanghang Tong</a>",
          "description": "Graph neural networks (GNNs) have been widely used in many real applications,\nand recent studies have revealed their vulnerabilities against topology\nattacks. To address this issue, existing efforts have mainly been dedicated to\nimproving the robustness of GNNs, while little attention has been paid to the\ndetection of such attacks. In this work, we study the victim node detection\nproblem under topology attacks against GNNs. Our approach is built upon the key\nobservation rooted in the intrinsic message passing nature of GNNs. That is,\nthe neighborhood of a victim node tends to have two competing group forces,\npushing the node classification results towards the original label and the\ntargeted label, respectively. Based on this observation, we propose to detect\nvictim nodes by deliberately designing an effective measurement of the\nneighborhood variance for each node. Extensive experimental results on four\nreal-world datasets and five existing topology attacks show the effectiveness\nand efficiency of the proposed detection approach.",
          "link": "http://arxiv.org/abs/2204.10072",
          "publishedOn": "2022-04-23T00:53:47.664Z",
          "wordCount": 594,
          "title": "Detecting Topology Attacks against Graph Neural Networks. (arXiv:2204.10072v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Binjie Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Haohao Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yueqi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1\">Song Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xu Chen</a>",
          "description": "Video decomposition is very important to extract moving foreground objects\nfrom complex backgrounds in computer vision, machine learning, and medical\nimaging, e.g., extracting moving contrast-filled vessels from the complex and\nnoisy backgrounds of X-ray coronary angiography (XCA). However, the challenges\ncaused by dynamic backgrounds, overlapping heterogeneous environments and\ncomplex noises still exist in video decomposition. To solve these problems,\nthis study is the first to introduce a flexible visual working memory model in\nvideo decomposition tasks to provide interpretable and high-performance\nhierarchical deep architecture, integrating the transformative representations\nbetween sensory and control layers from the perspective of visual and cognitive\nneuroscience. Specifically, robust PCA unrolling networks acting as a\nstructure-regularized sensor layer decompose XCA into sparse/low-rank\nstructured representations to separate moving contrast-filled vessels from\nnoisy and complex backgrounds. Then, patch recurrent convolutional LSTM\nnetworks with a backprojection module embody unstructured random\nrepresentations of the control layer in working memory, recurrently projecting\nspatiotemporally decomposed nonlocal patches into orthogonal subspaces for\nheterogeneous vessel retrieval and interference suppression. This video\ndecomposition deep architecture effectively restores the heterogeneous profiles\nof intensity and the geometries of moving objects against the complex\nbackground interferences. Experiments show that the proposed method\nsignificantly outperforms state-of-the-art methods in accurate moving\ncontrast-filled vessel extraction with excellent flexibility and computational\nefficiency.",
          "link": "http://arxiv.org/abs/2204.10105",
          "publishedOn": "2022-04-23T00:53:47.640Z",
          "wordCount": 667,
          "title": "Working memory inspired hierarchical video decomposition with transformative representations. (arXiv:2204.10105v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scher_S/0/1/0/all/0/1\">Sebastian Scher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trugler_A/0/1/0/all/0/1\">Andreas Tr&#xfc;gler</a>",
          "description": "Correctly quantifying the robustness of machine learning models is a central\naspect in judging their suitability for specific tasks, and thus, ultimately,\nfor generating trust in the models. We show that the widely used concept of\nadversarial robustness and closely related metrics based on counterfactuals are\nnot necessarily valid metrics for determining the robustness of ML models\nagainst perturbations that occur \"naturally\", outside specific adversarial\nattack scenarios. Additionally, we argue that generic robustness metrics in\nprinciple are insufficient for determining real-world-robustness. Instead we\npropose a flexible approach that models possible perturbations in input data\nindividually for each application. This is then combined with a probabilistic\napproach that computes the likelihood that a real-world perturbation will\nchange a prediction, thus giving quantitative information of the robustness of\nthe trained machine learning model. The method does not require access to the\ninternals of the classifier and thus in principle works for any black-box\nmodel. It is, however, based on Monte-Carlo sampling and thus only suited for\ninput spaces with small dimensions. We illustrate our approach on two dataset,\nas well as on analytically solvable cases. Finally, we discuss ideas on how\nreal-world robustness could be computed or estimated in high-dimensional input\nspaces.",
          "link": "http://arxiv.org/abs/2204.10046",
          "publishedOn": "2022-04-23T00:53:47.625Z",
          "wordCount": 634,
          "title": "Robustness of Machine Learning Models Beyond Adversarial Attacks. (arXiv:2204.10046v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xusheng Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_E/0/1/0/all/0/1\">Enguang Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhenzhen He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jiong Yu</a>",
          "description": "Outlier detection is an important topic in machine learning and has been used\nin a wide range of applications. Outliers are objects that are few in number\nand deviate from the majority of objects. As a result of these two properties,\nwe show that outliers are susceptible to a mechanism called fluctuation. This\narticle proposes a method called fluctuation-based outlier detection (FBOD)\nthat achieves a low linear time complexity and detects outliers purely based on\nthe concept of fluctuation without employing any distance, density or isolation\nmeasure. Fundamentally different from all existing methods. FBOD first converts\nthe Euclidean structure datasets into graphs by using random links, then\npropagates the feature value according to the connection of the graph. Finally,\nby comparing the difference between the fluctuation of an object and its\nneighbors, FBOD determines the object with a larger difference as an outlier.\nThe results of experiments comparing FBOD with seven state-of-the-art\nalgorithms on eight real-world tabular datasets and three video datasets show\nthat FBOD outperforms its competitors in the majority of cases and that FBOD\nhas only 5% of the execution time of the fastest algorithm. The experiment\ncodes are available at:\nhttps://github.com/FluctuationOD/Fluctuation-based-Outlier-Detection.",
          "link": "http://arxiv.org/abs/2204.10007",
          "publishedOn": "2022-04-23T00:53:47.604Z",
          "wordCount": 627,
          "title": "Fluctuation-based Outlier Detection. (arXiv:2204.10007v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09840",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_L/0/1/0/all/0/1\">Lingwei Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Ziwei Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_R/0/1/0/all/0/1\">Renyuan Zhang</a>",
          "description": "An end-to-end platform assembling multiple tiers is built for precisely\ncognizing brain activities. Being fed massive electroencephalogram (EEG) data,\nthe time-frequency spectrograms are conventionally projected into the\nepisode-wise feature matrices (seen as tier-1). A spiking neural network (SNN)\nbased tier is designed to distill the principle information in terms of\nspike-streams from the rare features, which maintains the temporal implication\nin the nature of EEGs. The proposed tier-3 transposes time- and space-domain of\nspike patterns from the SNN; and feeds the transposed pattern-matrices into an\nartificial neural network (ANN, Transformer specifically) known as tier-4,\nwhere a special spanning topology is proposed to match the two-dimensional\ninput form. In this manner, cognition such as classification is conducted with\nhigh accuracy. For proof-of-concept, the sleep stage scoring problem is\ndemonstrated by introducing multiple EEG datasets with the largest comprising\n42,560 hours recorded from 5,793 subjects. From experiment results, our\nplatform achieves the general cognition overall accuracy of 87% by leveraging\nsole EEG, which is 2% superior to the state-of-the-art. Moreover, our developed\nmulti-tier methodology offers visible and graphical interpretations of the\ntemporal characteristics of EEG by identifying the critical episodes, which is\ndemanded in neurodynamics but hardly appears in conventional cognition\nscenarios.",
          "link": "http://arxiv.org/abs/2204.09840",
          "publishedOn": "2022-04-23T00:53:47.570Z",
          "wordCount": 649,
          "title": "Multi-Tier Platform for Cognizing Massive Electroencephalogram. (arXiv:2204.09840v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tzoumpas_K/0/1/0/all/0/1\">Kostas Tzoumpas</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Estrada_A/0/1/0/all/0/1\">Aaron Estrada</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Miraglio_P/0/1/0/all/0/1\">Pietro Miraglio</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Zambelli_P/0/1/0/all/0/1\">Pietro Zambelli</a> (1) ((1) Eurac Research - Institute for Renewable Energy, Bolzano, Italy (2) Centro Euro-Mediterraneo sui Cambiamenti Climatici, Bologna, Italy)",
          "description": "In the process of collecting data from sensors, several circumstances can\naffect their continuity and validity, resulting in alterations of the data or\nloss of information. Although classical methods of statistics, such as\ninterpolation-like techniques, can be used to approximate the missing data in a\ntime series, the recent developments in Deep Learning (DL) have given impetus\nto innovative and much more accurate forecasting techniques. In the present\npaper, we develop two DL models aimed at filling data gaps, for the specific\ncase of internal temperature time series obtained from monitored apartments\nlocated in Bolzano, Italy. The DL models developed in the present work are\nbased on the combination of Convolutional Neural Networks (CNNs), Long\nShort-Term Memory Neural Networks (LSTMs), and Bidirectional LSTMs (BiLSTMs).\nTwo key features of our models are the use of both pre- and post-gap data, and\nthe exploitation of a correlated time series (the external temperature) in\norder to predict the target one (the internal temperature). Our approach\nmanages to capture the fluctuating nature of the data and shows good accuracy\nin reconstructing the target time series. In addition, our models significantly\nimprove the already good results from another DL architecture that is used as a\nbaseline for the present work.",
          "link": "http://arxiv.org/abs/2204.09994",
          "publishedOn": "2022-04-23T00:53:47.517Z",
          "wordCount": 671,
          "title": "A data filling methodology for time series based on CNN and (Bi)LSTM neural networks. (arXiv:2204.09994v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_T/0/1/0/all/0/1\">Tingyun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kai Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiaofang Zhou</a>",
          "description": "Indexing is an effective way to support efficient query processing in large\ndatabases. Recently the concept of learned index has been explored actively to\nreplace or supplement traditional index structures with machine learning models\nto reduce storage and search costs. However, accurate and efficient similarity\nquery processing in high-dimensional metric spaces remains to be an open\nchallenge. In this paper, a novel indexing approach called LIMS is proposed to\nuse data clustering and pivot-based data transformation techniques to build\nlearned indexes for efficient similarity query processing in metric spaces. The\nunderlying data is partitioned into clusters such that each cluster follows a\nrelatively uniform data distribution. Data redistribution is achieved by\nutilizing a small number of pivots for each cluster. Similar data are mapped\ninto compact regions and the mapped values are totally ordinal. Machine\nlearning models are developed to approximate the position of each data record\non the disk. Efficient algorithms are designed for processing range queries and\nnearest neighbor queries based on LIMS, and for index maintenance with dynamic\nupdates. Extensive experiments on real-world and synthetic datasets demonstrate\nthe superiority of LIMS compared with traditional indexes and state-of-the-art\nlearned indexes.",
          "link": "http://arxiv.org/abs/2204.10028",
          "publishedOn": "2022-04-23T00:53:47.501Z",
          "wordCount": 646,
          "title": "A Learned Index for Exact Similarity Search in Metric Spaces. (arXiv:2204.10028v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tibo_A/0/1/0/all/0/1\">Alessandro Tibo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_T/0/1/0/all/0/1\">Thomas Dyhre Nielsen</a>",
          "description": "Gaussian processes (GPs) are powerful but computationally expensive machine\nlearning models, requiring an estimate of the kernel covariance matrix for\nevery prediction. In large and complex domains, such as graphs, sets, or\nimages, the choice of suitable kernel can also be non-trivial to determine,\nproviding an additional obstacle to the learning task. Over the last decade,\nthese challenges have resulted in significant advances being made in terms of\nscalability and expressivity, exemplified by, e.g., the use of inducing points\nand neural network kernel approximations. In this paper, we propose inducing\nGaussian process networks (IGN), a simple framework for simultaneously learning\nthe feature space as well as the inducing points. The inducing points, in\nparticular, are learned directly in the feature space, enabling a seamless\nrepresentation of complex structured domains while also facilitating scalable\ngradient-based learning methods. We consider both regression and (binary)\nclassification tasks and report on experimental results for real-world data\nsets showing that IGNs provide significant advances over state-of-the-art\nmethods. We also demonstrate how IGNs can be used to effectively model complex\ndomains using neural network architectures.",
          "link": "http://arxiv.org/abs/2204.09889",
          "publishedOn": "2022-04-23T00:53:47.493Z",
          "wordCount": 605,
          "title": "Inducing Gaussian Process Networks. (arXiv:2204.09889v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goswami_S/0/1/0/all/0/1\">Somdatta Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kontolati_K/0/1/0/all/0/1\">Katiana Kontolati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shields_M/0/1/0/all/0/1\">Michael D. Shields</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Traditional machine learning algorithms are designed to learn in isolation,\ni.e. address single tasks. The core idea of transfer learning (TL) is that\nknowledge gained in learning to perform one task (source) can be leveraged to\nimprove learning performance in a related, but different, task (target). TL\nleverages and transfers previously acquired knowledge to address the expense of\ndata acquisition and labeling, potential computational power limitations, and\nthe dataset distribution mismatches. Although significant progress has been\nmade in the fields of image processing, speech recognition, and natural\nlanguage processing (for classification and regression) for TL, little work has\nbeen done in the field of scientific machine learning for functional regression\nand uncertainty quantification in partial differential equations. In this work,\nwe propose a novel TL framework for task-specific learning under conditional\nshift with a deep operator network (DeepONet). Inspired by the conditional\nembedding operator theory, we measure the statistical distance between the\nsource domain and the target feature domain by embedding conditional\ndistributions onto a reproducing kernel Hilbert space. Task-specific operator\nlearning is accomplished by fine-tuning task-specific layers of the target\nDeepONet using a hybrid loss function that allows for the matching of\nindividual target samples while also preserving the global properties of the\nconditional distribution of target data. We demonstrate the advantages of our\napproach for various TL scenarios involving nonlinear PDEs under conditional\nshift. Our results include geometry domain adaptation and show that the\nproposed TL framework enables fast and efficient multi-task operator learning,\ndespite significant differences between the source and target domains.",
          "link": "http://arxiv.org/abs/2204.09810",
          "publishedOn": "2022-04-23T00:53:47.446Z",
          "wordCount": 703,
          "title": "Deep transfer learning for partial differential equations under conditional shift with DeepONet. (arXiv:2204.09810v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yushun Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>",
          "description": "Graph mining algorithms have been playing a significant role in myriad fields\nover the years. However, despite their promising performance on various graph\nanalytical tasks, most of these algorithms lack fairness considerations. As a\nconsequence, they could lead to discrimination towards certain populations when\nexploited in human-centered applications. Recently, algorithmic fairness has\nbeen extensively studied in graph-based applications. In contrast to\nalgorithmic fairness on independent and identically distributed (i.i.d.) data,\nfairness in graph mining has exclusive backgrounds, taxonomies, and fulfilling\ntechniques. In this survey, we provide a comprehensive and up-to-date\nintroduction of existing literature under the context of fair graph mining.\nSpecifically, we propose a novel taxonomy of fairness notions on graphs, which\nsheds light on their connections and differences. We further present an\norganized summary of existing techniques that promote fairness in graph mining.\nFinally, we summarize the widely used datasets in this emerging research field\nand provide insights on current research challenges and open questions, aiming\nat encouraging cross-breeding ideas and further advances.",
          "link": "http://arxiv.org/abs/2204.09888",
          "publishedOn": "2022-04-23T00:53:47.378Z",
          "wordCount": 599,
          "title": "Fairness in Graph Mining: A Survey. (arXiv:2204.09888v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09938",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Janssen_J/0/1/0/all/0/1\">Joseph Janssen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Guan_V/0/1/0/all/0/1\">Vincent Guan</a>",
          "description": "Scientists frequently prioritize learning from data rather than training the\nbest possible model; however, research in machine learning often prioritizes\nthe latter. The development of marginal feature importance methods, such as\nmarginal contribution feature importance, attempts to break this trend by\nproviding a useful framework for explaining relationships in data in an\ninterpretable fashion. In this work, we generalize the framework of marginal\ncontribution feature importance to improve performance with regards to\ndetecting correlated interactions and reducing runtime. To do so, we consider\n\"information subsets\" of the set of features $F$ and show that our importance\nmetric can be computed directly after applying fair representation learning\nmethods from the AI fairness literature. The methods of optimal transport and\nlinear regression are considered and explored experimentally for removing all\nthe information of our feature of interest $f$ from the feature set $F$. Given\nthese implementations, we show on real and simulated data that ultra marginal\nfeature importance performs at least as well as marginal contribution feature\nimportance, with substantially faster computation time and better performance\nin the presence of correlated interactions and unrelated features.",
          "link": "http://arxiv.org/abs/2204.09938",
          "publishedOn": "2022-04-23T00:53:47.372Z",
          "wordCount": 616,
          "title": "Ultra Marginal Feature Importance. (arXiv:2204.09938v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giulivi_L/0/1/0/all/0/1\">Loris Giulivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carman_M/0/1/0/all/0/1\">Mark James Carman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boracchi_G/0/1/0/all/0/1\">Giacomo Boracchi</a>",
          "description": "Artificial intelligence (AI) systems power the world we live in. Deep neural\nnetworks (DNNs) are able to solve tasks in an ever-expanding landscape of\nscenarios, but our eagerness to apply these powerful models leads us to focus\non their performance and deprioritises our ability to understand them. Current\nresearch in the field of explainable AI tries to bridge this gap by developing\nvarious perturbation or gradient-based explanation techniques. For images,\nthese techniques fail to fully capture and convey the semantic information\nneeded to elucidate why the model makes the predictions it does. In this work,\nwe develop a new form of explanation that is radically different in nature from\ncurrent explanation methods, such as Grad-CAM. Perception visualization\nprovides a visual representation of what the DNN perceives in the input image\nby depicting what visual patterns the latent representation corresponds to.\nVisualizations are obtained through a reconstruction model that inverts the\nencoded features, such that the parameters and predictions of the original\nmodels are not modified. Results of our user study demonstrate that humans can\nbetter understand and predict the system's decisions when perception\nvisualizations are available, thus easing the debugging and deployment of deep\nmodels as trusted systems.",
          "link": "http://arxiv.org/abs/2204.09920",
          "publishedOn": "2022-04-23T00:53:47.335Z",
          "wordCount": 660,
          "title": "Perception Visualization: Seeing Through the Eyes of a DNN. (arXiv:2204.09920v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jintang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_J/0/1/0/all/0/1\">Jie Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Ruofan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Changhua Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zibin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiqiang Wang</a>",
          "description": "Recently, graph convolutional networks (GCNs) have shown to be vulnerable to\nsmall adversarial perturbations, which becomes a severe threat and largely\nlimits their applications in security-critical scenarios. To mitigate such a\nthreat, considerable research efforts have been devoted to increasing the\nrobustness of GCNs against adversarial attacks. However, current approaches for\ndefense are typically designed for the whole graph and consider the global\nperformance, posing challenges in protecting important local nodes from\nstronger adversarial targeted attacks. In this work, we present a simple yet\neffective method, named \\textbf{\\underline{G}}raph\n\\textbf{\\underline{U}}niversal\n\\textbf{\\underline{A}}dve\\textbf{\\underline{R}}sarial\n\\textbf{\\underline{D}}efense (GUARD). Unlike previous works, GUARD protects\neach individual node from attacks with a universal defensive patch, which is\ngenerated once and can be applied to any node (node-agnostic) in a graph.\nExtensive experiments on four benchmark datasets demonstrate that our method\nsignificantly improves robustness for several established GCNs against multiple\nadversarial attacks and outperforms existing adversarial defense methods by\nlarge margins. Our code is publicly available at\nhttps://github.com/EdisonLeeeee/GUARD.",
          "link": "http://arxiv.org/abs/2204.09803",
          "publishedOn": "2022-04-23T00:53:47.328Z",
          "wordCount": 612,
          "title": "GUARD: Graph Universal Adversarial Defense. (arXiv:2204.09803v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1\">Xu Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasha Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hailong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Liantao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1\">Wen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junfeng Zhao</a>",
          "description": "In healthcare prediction tasks, it is essential to exploit the correlations\nbetween medical features and learn better patient health representations.\nExisting methods try to estimate feature correlations only from data, or\nincrease the quality of estimation by introducing task-specific medical\nknowledge. However, such methods either are difficult to estimate the feature\ncorrelations due to insufficient training samples, or cannot be generalized to\nother tasks due to reliance on specific knowledge. There are medical research\nrevealing that not all the medical features are strongly correlated. Thus, to\naddress the issues, we expect to group up strongly correlated features and\nlearn feature correlations in a group-wise manner to reduce the learning\ncomplexity without losing generality. In this paper, we propose a general\npatient health representation learning framework MedFACT. We estimate\ncorrelations via measuring similarity between temporal patterns of medical\nfeatures with kernel methods, and cluster features with strong correlations\ninto groups. The feature group is further formulated as a correlation graph,\nand we employ graph convolutional networks to conduct group-wise feature\ninteractions for better representation learning. Experiments on two real-world\ndatasets demonstrate the superiority of MedFACT. The discovered medical\nfindings are also confirmed by literature, providing valuable medical insights\nand explanations.",
          "link": "http://arxiv.org/abs/2204.10011",
          "publishedOn": "2022-04-23T00:53:47.293Z",
          "wordCount": 652,
          "title": "MedFACT: Modeling Medical Feature Correlations in Patient Health Representation Learning via Feature Clustering. (arXiv:2204.10011v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1\">Ahsan Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_H/0/1/0/all/0/1\">Hemant Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kettimuthu_R/0/1/0/all/0/1\">Rajkumar Kettimuthu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenesei_P/0/1/0/all/0/1\">Peter Kenesei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trujillo_D/0/1/0/all/0/1\">Dennis Trujillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miceli_A/0/1/0/all/0/1\">Antonino Miceli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1\">Ian Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coffee_R/0/1/0/all/0/1\">Ryan Coffee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thayer_J/0/1/0/all/0/1\">Jana Thayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengchun Liu</a>",
          "description": "Extracting actionable information from data sources such as the Linac\nCoherent Light Source (LCLS-II) and Advanced Photon Source Upgrade (APS-U) is\nbecoming more challenging due to the fast-growing data generation rate. The\nrapid analysis possible with ML methods can enable fast feedback loops that can\nbe used to adjust experimental setups in real-time, for example when errors\noccur or interesting events are detected. However, to avoid degradation in ML\nperformance over time due to changes in an instrument or sample, we need a way\nto update ML models rapidly while an experiment is running. We present here a\ndata service and model service to accelerate deep neural network training with\na focus on ML-based scientific applications. Our proposed data service achieves\n100x speedup in terms of data labeling compare to the current state-of-the-art.\nFurther, our model service achieves up to 200x improvement in training speed.\nOverall, fairDMS achieves up to 92x speedup in terms of end-to-end model\nupdating time.",
          "link": "http://arxiv.org/abs/2204.09805",
          "publishedOn": "2022-04-23T00:53:47.287Z",
          "wordCount": 606,
          "title": "fairDMS: Rapid Model Training by Data and Model Reuse. (arXiv:2204.09805v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1\">Qi Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>",
          "description": "Despite the success of reinforcement learning (RL) for Markov decision\nprocesses (MDPs) with function approximation, most RL algorithms easily fail if\nthe agent only has partial observations of the state. Such a setting is often\nmodeled as a partially observable Markov decision process (POMDP). Existing\nsample-efficient algorithms for POMDPs are restricted to the tabular setting\nwhere the state and observation spaces are finite. In this paper, we make the\nfirst attempt at tackling the tension between function approximation and\npartial observability. In specific, we focus on a class of undercomplete POMDPs\nwith linear function approximations, which allows the state and observation\nspaces to be infinite. For such POMDPs, we show that the optimal policy and\nvalue function can be characterized by a sequence of finite-memory Bellman\noperators. We propose an RL algorithm that constructs optimistic estimators of\nthese operators via reproducing kernel Hilbert space (RKHS) embedding.\nMoreover, we theoretically prove that the proposed algorithm finds an\n$\\varepsilon$-optimal policy with $\\tilde O (1/\\varepsilon^2)$ episodes of\nexploration. Also, this sample complexity only depends on the intrinsic\ndimension of the POMDP polynomially and is independent of the size of the state\nand observation spaces. To our best knowledge, we develop the first provably\nsample-efficient algorithm for POMDPs with function approximation.",
          "link": "http://arxiv.org/abs/2204.09787",
          "publishedOn": "2022-04-23T00:53:47.278Z",
          "wordCount": 651,
          "title": "Sample-Efficient Reinforcement Learning for POMDPs with Linear Function Approximations. (arXiv:2204.09787v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09715",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ro_J/0/1/0/all/0/1\">Jae Hun Ro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breiner_T/0/1/0/all/0/1\">Theresa Breiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McConnaughey_L/0/1/0/all/0/1\">Lara McConnaughey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingqing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1\">Ananda Theertha Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shankar Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathews_R/0/1/0/all/0/1\">Rajiv Mathews</a>",
          "description": "Most studies in cross-device federated learning focus on small models, due to\nthe server-client communication and on-device computation bottlenecks. In this\nwork, we leverage various techniques for mitigating these bottlenecks to train\nlarger language models in cross-device federated learning. With systematic\napplications of partial model training, quantization, efficient transfer\nlearning, and communication-efficient optimizers, we are able to train a $21$M\nparameter Transformer that achieves the same perplexity as that of a similarly\nsized LSTM with $\\sim10\\times$ smaller client-to-server communication cost and\n$11\\%$ lower perplexity than smaller LSTMs commonly studied in literature.",
          "link": "http://arxiv.org/abs/2204.09715",
          "publishedOn": "2022-04-23T00:53:47.272Z",
          "wordCount": 538,
          "title": "Scaling Language Model Size in Cross-Device Federated Learning. (arXiv:2204.09715v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09772",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Weichao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenchao Li</a>",
          "description": "A misspecified reward can degrade sample efficiency and induce undesired\nbehaviors in reinforcement learning (RL) problems. We propose symbolic reward\nmachines for incorporating high-level task knowledge when specifying the reward\nsignals. Symbolic reward machines augment existing reward machine formalism by\nallowing transitions to carry predicates and symbolic reward outputs. This\nformalism lends itself well to inverse reinforcement learning, whereby the key\nchallenge is determining appropriate assignments to the symbolic values from a\nfew expert demonstrations. We propose a hierarchical Bayesian approach for\ninferring the most likely assignments such that the concretized reward machine\ncan discriminate expert demonstrated trajectories from other trajectories with\nhigh accuracy. Experimental results show that learned reward machines can\nsignificantly improve training efficiency for complex RL tasks and generalize\nwell across different task environment configurations.",
          "link": "http://arxiv.org/abs/2204.09772",
          "publishedOn": "2022-04-23T00:53:47.263Z",
          "wordCount": 568,
          "title": "A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines. (arXiv:2204.09772v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhixiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_W/0/1/0/all/0/1\">Wenqiang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nallanathan_A/0/1/0/all/0/1\">Arumugam Nallanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Geoffrey Ye Li</a>",
          "description": "The limited communication resources, e.g., bandwidth and energy, and data\nheterogeneity across devices are two of the main bottlenecks for federated\nlearning (FL). To tackle these challenges, we first devise a novel FL framework\nwith partial model aggregation (PMA), which only aggregates the lower layers of\nneural networks responsible for feature extraction while the upper layers\ncorresponding to complex pattern recognition remain at devices for\npersonalization. The proposed PMA-FL is able to address the data heterogeneity\nand reduce the transmitted information in wireless channels. We then obtain a\nconvergence bound of the framework under a non-convex loss function setting.\nWith the aid of this bound, we define a new objective function, named the\nscheduled data sample volume, to transfer the original inexplicit optimization\nproblem into a tractable one for device scheduling, bandwidth allocation,\ncomputation and communication time division. Our analysis reveals that the\noptimal time division is achieved when the communication and computation parts\nof PMA-FL have the same power. We also develop a bisection method to solve the\noptimal bandwidth allocation policy and use the set expansion algorithm to\naddress the optimal device scheduling. Compared with the state-of-the-art\nbenchmarks, the proposed PMA-FL improves 2.72% and 11.6% accuracy on two\ntypical heterogeneous datasets, i.e., MINIST and CIFAR-10, respectively. In\naddition, the proposed joint dynamic device scheduling and resource\noptimization approach achieve slightly higher accuracy than the considered\nbenchmarks, but they provide a satisfactory energy and time reduction: 29%\nenergy or 20% time reduction on the MNIST; and 25% energy or 12.5% time\nreduction on the CIFAR-10.",
          "link": "http://arxiv.org/abs/2204.09746",
          "publishedOn": "2022-04-23T00:53:47.240Z",
          "wordCount": 701,
          "title": "Federated Learning for Energy-limited Wireless Networks: A Partial Model Aggregation Approach. (arXiv:2204.09746v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xingang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Bin Hu</a>",
          "description": "In this paper, we consider the policy evaluation problem in multi-agent\nreinforcement learning (MARL) and derive exact closed-form formulas for the\nfinite-time mean-squared estimation errors of decentralized temporal difference\n(TD) learning with linear function approximation. Our analysis hinges upon the\nfact that the decentralized TD learning method can be viewed as a Markov jump\nlinear system (MJLS). Then standard MJLS theory can be applied to quantify the\nmean and covariance matrix of the estimation error of the decentralized TD\nmethod at every time step. Various implications of our exact formulas on the\nalgorithm performance are also discussed. An interesting finding is that under\na necessary and sufficient stability condition, the mean-squared TD estimation\nerror will converge to an exact limit at a specific exponential rate.",
          "link": "http://arxiv.org/abs/2204.09801",
          "publishedOn": "2022-04-23T00:53:47.233Z",
          "wordCount": 581,
          "title": "Exact Formulas for Finite-Time Estimation Errors of Decentralized Temporal Difference Learning with Linear Function Approximation. (arXiv:2204.09801v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Darapaneni_N/0/1/0/all/0/1\">Narayana Darapaneni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhakuni_C/0/1/0/all/0/1\">Chandrashekhar Bhakuni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatt_U/0/1/0/all/0/1\">Ujjval Bhatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purohit_K/0/1/0/all/0/1\">Khamir Purohit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sardna_V/0/1/0/all/0/1\">Vikas Sardna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_P/0/1/0/all/0/1\">Prabir Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paduri_A/0/1/0/all/0/1\">Anwesh Reddy Paduri</a>",
          "description": "Businesses need content. In various forms and formats and for varied\npurposes. In fact, the content marketing industry is set to be worth $412.88\nbillion by the end of 2021. However, according to the Content Marketing\nInstitute, creating engaging content is the #1 challenge that marketers face\ntoday. We under-stand that producing great content requires great writers who\nunderstand the business and can weave their message into reader (and search\nengine) friendly content. In this project, the team has attempted to bridge the\ngap between writers and projects by using AI and ML tools. We used NLP\ntechniques to analyze thou-sands of publicly available business articles\n(corpora) to extract various defining factors for each writing sample. Through\nthis project we aim to automate the highly time-consuming, and often biased\ntask of manually shortlisting the most suitable writer for a given content\nwriting requirement. We believe that a tool like this will have far reaching\npositive implications for both parties - businesses looking for suitable talent\nfor niche writing jobs as well as experienced writers and Subject Matter\nExperts (SMEs) wanting to lend their services to content marketing projects.\nThe business gets the content they need, the content writer/ SME gets a chance\nto leverage his or her talent, while the reader gets authentic content that\nadds real value.",
          "link": "http://arxiv.org/abs/2204.09718",
          "publishedOn": "2022-04-23T00:53:47.176Z",
          "wordCount": 663,
          "title": "Matching Writers to Content Writing Tasks. (arXiv:2204.09718v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qihao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianxi Luo</a>",
          "description": "Biological systems in nature have evolved for millions of years to adapt and\nsurvive the environment. Many features they developed can be inspirational and\nbeneficial for solving technical problems in modern industries. This leads to a\nnovel form of design-by-analogy called bio-inspired design (BID). Although BID\nas a design method has been proven beneficial, the gap between biology and\nengineering continuously hinders designers from effectively applying the\nmethod. Therefore, we explore the recent advance of artificial intelligence\n(AI) for a computational approach to bridge the gap. This paper proposes a\ngenerative design approach based on the pre-trained language model (PLM) to\nautomatically retrieve and map biological analogy and generate BID in the form\nof natural language. The latest generative pre-trained transformer, namely\nGPT-3, is used as the base PLM. Three types of design concept generators are\nidentified and fine-tuned from the PLM according to the looseness of the\nproblem space representation. Machine evaluators are also fine-tuned to assess\nthe correlation between the domains within the generated BID concepts. The\napproach is then tested via a case study in which the fine-tuned models are\napplied to generate and evaluate light-weighted flying car concepts inspired by\nnature. The results show our approach can generate BID concepts with good\nperformance.",
          "link": "http://arxiv.org/abs/2204.09714",
          "publishedOn": "2022-04-23T00:53:47.168Z",
          "wordCount": 655,
          "title": "Generative Pre-Trained Transformers for Biologically Inspired Design. (arXiv:2204.09714v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Magron_P/0/1/0/all/0/1\">Paul Magron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fevotte_C/0/1/0/all/0/1\">C&#xe9;dric F&#xe9;votte</a>",
          "description": "This paper tackles the problem of decomposing binary data using matrix\nfactorization. We consider the family of mean-parametrized Bernoulli models, a\nclass of generative models that are well suited for modeling binary data and\nenables interpretability of the factors. We factorize the Bernoulli parameter\nand consider an additional Beta prior on one of the factors to further improve\nthe model's expressive power. While similar models have been proposed in the\nliterature, they only exploit the Beta prior as a proxy to ensure a valid\nBernoulli parameter in a Bayesian setting; in practice it reduces to a uniform\nor uninformative prior. Besides, estimation in these models has focused on\ncostly Bayesian inference. In this paper, we propose a simple yet very\nefficient majorization-minimization algorithm for maximum a posteriori\nestimation. Our approach leverages the Beta prior whose parameters can be tuned\nto improve performance in matrix completion tasks. Experiments conducted on\nthree public binary datasets show that our approach offers an excellent\ntrade-off between prediction performance, computational complexity, and\ninterpretability.",
          "link": "http://arxiv.org/abs/2204.09741",
          "publishedOn": "2022-04-23T00:53:47.140Z",
          "wordCount": 603,
          "title": "A majorization-minimization algorithm for nonnegative binary matrix factorization. (arXiv:2204.09741v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Ki-Ung Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shim_D/0/1/0/all/0/1\">Dongseok Shim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kang-wook Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-young Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Younggeun Kim</a>",
          "description": "Super-resolution suffers from an innate ill-posed problem that a single\nlow-resolution (LR) image can be from multiple high-resolution (HR) images.\nRecent studies on the flow-based algorithm solve this ill-posedness by learning\nthe super-resolution space and predicting diverse HR outputs. Unfortunately,\nthe diversity of the super-resolution outputs is still unsatisfactory, and the\noutputs from the flow-based model usually suffer from undesired artifacts which\ncauses low-quality outputs. In this paper, we propose FS-NCSR which produces\ndiverse and high-quality super-resolution outputs using frequency separation\nand noise conditioning compared to the existing flow-based approaches. As the\nsharpness and high-quality detail of the image rely on its high-frequency\ninformation, FS-NCSR only estimates the high-frequency information of the\nhigh-resolution outputs without redundant low-frequency components. Through\nthis, FS-NCSR significantly improves the diversity score without significant\nimage quality degradation compared to the NCSR, the winner of the previous\nNTIRE 2021 challenge.",
          "link": "http://arxiv.org/abs/2204.09679",
          "publishedOn": "2022-04-23T00:53:47.021Z",
          "wordCount": 615,
          "title": "FS-NCSR: Increasing Diversity of the Super-Resolution Space via Frequency Separation and Noise-Conditioned Normalizing Flow. (arXiv:2204.09679v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_W/0/1/0/all/0/1\">Wasifur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Masum Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md Saiful Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olubajo_T/0/1/0/all/0/1\">Titilayo Olubajo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thaker_J/0/1/0/all/0/1\">Jeet Thaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelkader_A/0/1/0/all/0/1\">Abdelrahman Abdelkader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Phillip Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashizawa_T/0/1/0/all/0/1\">Tetsuo Ashizawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoque_E/0/1/0/all/0/1\">Ehsan Hoque</a>",
          "description": "In this paper, we investigated whether we can 1) detect participants with\nataxia-specific gait characteristics (risk-prediction), and 2) assess severity\nof ataxia from gait (severity-assessment) using computer vision. We created a\ndataset of 155 videos from 89 participants, 24 controls and 65 diagnosed with\n(or are pre-manifest) spinocerebellar ataxias (SCAs), performing the gait task\nof the Scale for the Assessment and Rating of Ataxia (SARA) from 11 medical\nsites located in 8 different states across the United States. We develop a\ncomputer vision pipeline to detect, track, and separate out the participants\nfrom their surroundings and construct several features from their body pose\ncoordinates to capture gait characteristics like step width, step length,\nswing, stability, speed, etc. Our risk-prediction model achieves 83.06%\naccuracy and an 80.23% F1 score. Similarly, our severity-assessment model\nachieves a mean absolute error (MAE) score of 0.6225 and a Pearson's\ncorrelation coefficient score of 0.7268. Our models still performed\ncompetitively when evaluated on data from sites not used during training.\nFurthermore, through feature importance analysis, we found that our models\nassociate wider steps, decreased walking speed, and increased instability with\ngreater ataxia severity, which is consistent with previously established\nclinical knowledge. Our models create possibilities for remote ataxia\nassessment in non-clinical settings in the future, which could significantly\nimprove accessibility of ataxia care. Furthermore, our underlying dataset was\nassembled from a geographically diverse cohort, highlighting its potential to\nfurther increase equity. The code used in this study is open to the public, and\nthe anonymized body pose landmark dataset is also available upon request.",
          "link": "http://arxiv.org/abs/2203.08215",
          "publishedOn": "2022-04-18T00:59:14.071Z",
          "wordCount": null,
          "title": "Auto-Gait: Automatic Ataxia Risk Assessment with Computer Vision on Gait Task Videos. (arXiv:2203.08215v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyungyung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sungjin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Edward Choi</a>",
          "description": "Though deep generative models have gained a lot of attention, most of the\nexisting works are designed for the unimodal generation task. In this paper, we\nexplore a new method for unconditional image-text pair generation. We propose\nMXQ-VAE, a vector quantization method for multimodal image-text representation.\nMXQ-VAE accepts a paired image and text as input, and learns a joint quantized\nrepresentation space, so that the image-text pair can be converted to a\nsequence of unified indices. Then we can use autoregressive generative models\nto model the joint image-text representation, and even perform unconditional\nimage-text pair generation. Extensive experimental results demonstrate that our\napproach effectively generates semantically consistent image-text pair and also\nenhances meaningful alignment between image and text.",
          "link": "http://arxiv.org/abs/2204.07537",
          "publishedOn": "2022-04-18T00:59:14.070Z",
          "wordCount": 571,
          "title": "Unconditional Image-Text Pair Generation with Multimodal Cross Quantizer. (arXiv:2204.07537v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.01746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruocheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candan_K/0/1/0/all/0/1\">Kasim Selcuk Candan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>",
          "description": "Online review systems are the primary means through which many businesses\nseek to build the brand and spread their messages. Prior research studying the\neffects of online reviews has been mainly focused on a single numerical cause,\ne.g., ratings or sentiment scores. We argue that such notions of causes entail\nthree key limitations: they solely consider the effects of single numerical\ncauses and ignore different effects of multiple aspects -- e.g., Food, Service\n-- embedded in the textual reviews; they assume the absence of hidden\nconfounders in observational studies, e.g., consumers' personal preferences;\nand they overlook the indirect effects of numerical causes that can potentially\ncancel out the effect of textual reviews on business revenue. We thereby\npropose an alternative perspective to this single-cause-based effect estimation\nof online reviews: in the presence of hidden confounders, we consider\nmulti-aspect textual reviews, particularly, their total effects on business\nrevenue and direct effects with the numerical cause -- ratings -- being the\nmediator. We draw on recent advances in machine learning and causal inference\nto together estimate the hidden confounders and causal effects. We present\nempirical evaluations using real-world examples to discuss the importance and\nimplications of differentiating the multi-aspect effects in strategizing\nbusiness operations.",
          "link": "http://arxiv.org/abs/2110.01746",
          "publishedOn": "2022-04-18T00:59:14.063Z",
          "wordCount": 688,
          "title": "Effects of Multi-Aspect Online Reviews with Unobserved Confounders: Estimation and Implication. (arXiv:2110.01746v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14831",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pan_J/0/1/0/all/0/1\">Jiayi Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1\">Heye Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_W/0/1/0/all/0/1\">Weifei Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_Z/0/1/0/all/0/1\">Zhifan Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_W/0/1/0/all/0/1\">Weiwen Wu</a>",
          "description": "Decreasing projection views to lower X-ray radiation dose usually leads to\nsevere streak artifacts. To improve image quality from sparse-view data, a\nMulti-domain Integrative Swin Transformer network (MIST-net) was developed in\nthis article. First, MIST-net incorporated lavish domain features from data,\nresidual-data, image, and residual-image using flexible network architectures,\nwhere residual-data and residual-image sub-network was considered as data\nconsistency module to eliminate interpolation and reconstruction errors.\nSecond, a trainable edge enhancement filter was incorporated to detect and\nprotect image edges. Third, a high-quality reconstruction Swin transformer\n(i.e., Recformer) was designed to capture image global features. The experiment\nresults on numerical and real cardiac clinical datasets with 48-views\ndemonstrated that our proposed MIST-net provided better image quality with more\nsmall features and sharp edges than other competitors.",
          "link": "http://arxiv.org/abs/2111.14831",
          "publishedOn": "2022-04-18T00:59:14.055Z",
          "wordCount": null,
          "title": "Multi-domain Integrative Swin Transformer network for Sparse-View Tomographic Reconstruction. (arXiv:2111.14831v7 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_R/0/1/0/all/0/1\">Rishabh Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">Krishnateja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_P/0/1/0/all/0/1\">Pradeep Shenoy</a>",
          "description": "Continual learning (CL) aims to develop techniques by which a single model\nadapts to an increasing number of tasks encountered sequentially, thereby\npotentially leveraging learnings across tasks in a resource-efficient manner. A\nmajor challenge for CL systems is catastrophic forgetting, where earlier tasks\nare forgotten while learning a new task. To address this, replay-based CL\napproaches maintain and repeatedly retrain on a small buffer of data selected\nacross encountered tasks. We propose Gradient Coreset Replay (GCR), a novel\nstrategy for replay buffer selection and update using a carefully designed\noptimization criterion. Specifically, we select and maintain a \"coreset\" that\nclosely approximates the gradient of all the data seen so far with respect to\ncurrent model parameters, and discuss key strategies needed for its effective\napplication to the continual learning setting. We show significant gains (2%-4%\nabsolute) over the state-of-the-art in the well-studied offline continual\nlearning setting. Our findings also effectively transfer to online / streaming\nCL settings, showing upto 5% gains over existing approaches. Finally, we\ndemonstrate the value of supervised contrastive loss for continual learning,\nwhich yields a cumulative gain of up to 5% accuracy when combined with our\nsubset selection strategy.",
          "link": "http://arxiv.org/abs/2111.11210",
          "publishedOn": "2022-04-18T00:59:14.054Z",
          "wordCount": null,
          "title": "GCR: Gradient Coreset Based Replay Buffer Selection For Continual Learning. (arXiv:2111.11210v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01705",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Hengshuai Yao</a>",
          "description": "Gradient descent is slow to converge for ill-conditioned problems and\nnon-convex problems. An important technique for acceleration is step-size\nadaptation. The first part of this paper contains a detailed review of\nstep-size adaptation methods, including Polyak step-size, L4, LossGrad, Adam,\nIDBD, and Hypergradient descent, and the relation of step-size adaptation to\nmeta-gradient methods. In the second part of this paper, we propose a new class\nof methods of accelerating gradient descent that have some distinctiveness from\nexisting techniques. The new methods, which we call {\\em step-size planning},\nuse the {\\em update experience} to learn an improved way of updating the\nparameters. The methods organize the experience into $K$ steps away from each\nother to facilitate planning. From the past experience, our planning algorithm,\nCsawg, learns a step-size model which is a form of multi-step machine that\npredicts future updates. We extends Csawg to applying step-size planning\nmultiple steps, which leads to further speedup. We discuss and highlight the\nprojection power of the diagonal-matrix step-size for future large scale\napplications. We show for a convex problem, our methods can surpass the\nconvergence rate of Nesterov's accelerated gradient, $1 - \\sqrt{\\mu/L}$, where\n$\\mu, L$ are the strongly convex factor of the loss function $F$ and the\nLipschitz constant of $F'$, which is the theoretical limit for the convergence\nrate of first-order methods. On the well-known non-convex Rosenbrock function,\nour planning methods achieve zero error below 500 gradient evaluations, while\ngradient descent takes about 10000 gradient evaluations to reach a $10^{-3}$\naccuracy. We discuss the connection of step-size planing to planning in\nreinforcement learning, in particular, Dyna architectures.",
          "link": "http://arxiv.org/abs/2204.01705",
          "publishedOn": "2022-04-18T00:59:14.053Z",
          "wordCount": 725,
          "title": "Learning to Accelerate by the Methods of Step-size Planning. (arXiv:2204.01705v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaikumar_P/0/1/0/all/0/1\">Punitha Jaikumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandaele_R/0/1/0/all/0/1\">Remy Vandaele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ojha_V/0/1/0/all/0/1\">Varun Ojha</a>",
          "description": "This paper proposes a methodological approach with a transfer learning scheme\nfor plastic waste bottle detection and instance segmentation using the\n\\textit{mask region proposal convolutional neural network} (Mask R-CNN).\nPlastic bottles constitute one of the major pollutants posing a serious threat\nto the environment both in oceans and on land. The automated identification and\nsegregation of bottles can facilitate plastic waste recycling. We prepare a\ncustom-made dataset of 192 bottle images with pixel-by pixel-polygon annotation\nfor the automatic segmentation task. The proposed transfer learning scheme\nmakes use of a Mask R-CNN model pre-trained on the Microsoft COCO dataset. We\npresent a comprehensive scheme for fine-tuning the base pre-trained Mask-RCNN\nmodel on our custom dataset. Our final fine-tuned model has achieved 59.4\n\\textit{mean average precision} (mAP), which corresponds to the MS COCO metric.\nThe results indicate a promising application of deep learning for detecting\nwaste bottles.",
          "link": "http://arxiv.org/abs/2204.07437",
          "publishedOn": "2022-04-18T00:59:14.028Z",
          "wordCount": 614,
          "title": "Transfer Learning for Instance Segmentation of Waste Bottles using Mask R-CNN Algorithm. (arXiv:2204.07437v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mussabayev_R/0/1/0/all/0/1\">Rustam Mussabayev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mladenovic_N/0/1/0/all/0/1\">Nenad Mladenovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarboui_B/0/1/0/all/0/1\">Bassem Jarboui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mussabayev_R/0/1/0/all/0/1\">Ravil Mussabayev</a>",
          "description": "K-means clustering plays a vital role in data mining. However, its\nperformance drastically drops when applied to huge amounts of data. We propose\na new heuristic that is built on the basis of regular K-means for faster and\nmore accurate big data clustering using the \"less is more\" and MSSC\ndecomposition approaches. The main advantage of the proposed algorithm is that\nit naturally turns the K-means local search into global one through the process\nof decomposition of the MSSC problem. On one hand, decomposition of the MSSC\nproblem into smaller subproblems reduces the computational complexity and\nallows for their parallel processing. On the other hand, the MSSC decomposition\nprovides a new method for the natural data-driven shaking of the incumbent\nsolution while introducing a new neighborhood structure for the solution of the\nMSSC problem. This leads to a new heuristic that improves K-means in big data\nconditions. The scalability of the algorithm to big data can be easily adjusted\nby choosing the appropriate number of subproblems and their size. The proposed\nalgorithm is both scalable and accurate. In our experiments it outperforms all\nrecent state-of-the-art algorithms for the MSSC in terms of time as well as the\nsolution quality.",
          "link": "http://arxiv.org/abs/2204.07485",
          "publishedOn": "2022-04-18T00:59:14.020Z",
          "wordCount": 630,
          "title": "Big-means: Less is More for K-means Clustering. (arXiv:2204.07485v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangdon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1\">Xiayan Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Accurately detecting and tracking multi-objects is important for\nsafety-critical applications such as autonomous navigation. However, it remains\nchallenging to provide guarantees on the performance of state-of-the-art\ntechniques based on deep learning. We consider a strategy known as conformal\nprediction, which predicts sets of labels instead of a single label; in the\nclassification and regression settings, these algorithms can guarantee that the\ntrue label lies within the prediction set with high probability. Building on\nthese ideas, we propose multi-object detection and tracking algorithms that\ncome with probably approximately correct (PAC) guarantees. They do so by\nconstructing both a prediction set around each object detection as well as\naround the set of edge transitions; given an object, the detection prediction\nset contains its true bounding box with high probability, and the edge\nprediction set contains its true transition across frames with high\nprobability. We empirically demonstrate that our method can detect and track\nobjects with PAC guarantees on the COCO and MOT-17 datasets.",
          "link": "http://arxiv.org/abs/2204.07482",
          "publishedOn": "2022-04-18T00:59:14.012Z",
          "wordCount": null,
          "title": "Towards PAC Multi-Object Detection and Tracking. (arXiv:2204.07482v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.11991",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zeng_S/0/1/0/all/0/1\">Sihan Zeng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kody_A/0/1/0/all/0/1\">Alyssa Kody</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_Y/0/1/0/all/0/1\">Youngdae Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_K/0/1/0/all/0/1\">Kibaek Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Molzahn_D/0/1/0/all/0/1\">Daniel K. Molzahn</a>",
          "description": "With the increasing penetration of distributed energy resources, distributed\noptimization algorithms have attracted significant attention for power systems\napplications due to their potential for superior scalability, privacy, and\nrobustness to a single point-of-failure. The Alternating Direction Method of\nMultipliers (ADMM) is a popular distributed optimization algorithm; however,\nits convergence performance is highly dependent on the selection of penalty\nparameters, which are usually chosen heuristically. In this work, we use\nreinforcement learning (RL) to develop an adaptive penalty parameter selection\npolicy for the AC optimal power flow (ACOPF) problem solved via ADMM with the\ngoal of minimizing the number of iterations until convergence. We train our RL\npolicy using deep Q-learning, and show that this policy can result in\nsignificantly accelerated convergence (up to a 59% reduction in the number of\niterations compared to existing, curvature-informed penalty parameter selection\nmethods). Furthermore, we show that our RL policy demonstrates promise for\ngeneralizability, performing well under unseen loading schemes as well as under\nunseen losses of lines and generators (up to a 50% reduction in iterations).\nThis work thus provides a proof-of-concept for using RL for parameter selection\nin ADMM for power systems applications.",
          "link": "http://arxiv.org/abs/2110.11991",
          "publishedOn": "2022-04-18T00:59:14.012Z",
          "wordCount": null,
          "title": "A Reinforcement Learning Approach to Parameter Selection for Distributed Optimal Power Flow. (arXiv:2110.11991v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.06483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mostafa_H/0/1/0/all/0/1\">Hesham Mostafa</a>",
          "description": "We present the Sequential Aggregation and Rematerialization (SAR) scheme for\ndistributed full-batch training of Graph Neural Networks (GNNs) on large\ngraphs. Large-scale training of GNNs has recently been dominated by\nsampling-based methods and methods based on non-learnable message passing. SAR\non the other hand is a distributed technique that can train any GNN type\ndirectly on an entire large graph. The key innovation in SAR is the distributed\nsequential rematerialization scheme which sequentially re-constructs then frees\npieces of the prohibitively large GNN computational graph during the backward\npass. This results in excellent memory scaling behavior where the memory\nconsumption per worker goes down linearly with the number of workers, even for\ndensely connected graphs. Using SAR, we report the largest applications of\nfull-batch GNN training to-date, and demonstrate large memory savings as the\nnumber of workers increases. We also present a general technique based on\nkernel fusion and attention-matrix rematerialization to optimize both the\nruntime and memory efficiency of attention-based models. We show that, coupled\nwith SAR, our optimized attention kernels lead to significant speedups and\nmemory savings in attention-based GNNs.We made the SAR GNN training library\npublicy available: \\url{https://github.com/IntelLabs/SAR}.",
          "link": "http://arxiv.org/abs/2111.06483",
          "publishedOn": "2022-04-18T00:59:14.011Z",
          "wordCount": null,
          "title": "Sequential Aggregation and Rematerialization: Distributed Full-batch Training of Graph Neural Networks on Large Graphs. (arXiv:2111.06483v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Daeyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1\">Seongsu Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Edward Choi</a>",
          "description": "Question Answering on Electronic Health Records (EHR-QA) has a significant\nimpact on the healthcare domain, and it is being actively studied. Previous\nresearch on structured EHR-QA focuses on converting natural language queries\ninto query language such as SQL or SPARQL (NLQ2Query), so the problem scope is\nlimited to pre-defined data types by the specific query language. In order to\nexpand the EHR-QA task beyond this limitation to handle multi-modal medical\ndata and solve complex inference in the future, more primitive systemic\nlanguage is needed. In this paper, we design the program-based model\n(NLQ2Program) for EHR-QA as the first step towards the future direction. We\ntackle MIMICSPARQL*, the graph-based EHR-QA dataset, via a program-based\napproach in a semi-supervised manner in order to overcome the absence of gold\nprograms. Without the gold program, our proposed model shows comparable\nperformance to the previous state-of-the-art model, which is an NLQ2Query model\n(0.9% gain). In addition, for a reliable EHR-QA model, we apply the uncertainty\ndecomposition method to measure the ambiguity in the input question. We\nempirically confirmed data uncertainty is most indicative of the ambiguity in\nthe input question.",
          "link": "http://arxiv.org/abs/2203.06918",
          "publishedOn": "2022-04-18T00:59:14.011Z",
          "wordCount": null,
          "title": "Uncertainty-Aware Text-to-Program for Question Answering on Structured Electronic Health Records. (arXiv:2203.06918v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kostovska_A/0/1/0/all/0/1\">Ana Kostovska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vermetten_D/0/1/0/all/0/1\">Diederick Vermetten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dzeroski_S/0/1/0/all/0/1\">Sa&#x161;o D&#x17e;eroski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doerr_C/0/1/0/all/0/1\">Carola Doerr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korosec_P/0/1/0/all/0/1\">Peter Koro&#x161;ec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eftimov_T/0/1/0/all/0/1\">Tome Eftimov</a>",
          "description": "Selecting the most suitable algorithm and determining its hyperparameters for\na given optimization problem is a challenging task. Accurately predicting how\nwell a certain algorithm could solve the problem is hence desirable. Recent\nstudies in single-objective numerical optimization show that supervised machine\nlearning methods can predict algorithm performance using landscape features\nextracted from the problem instances.\n\nExisting approaches typically treat the algorithms as black-boxes, without\nconsideration of their characteristics. To investigate in this work if a\nselection of landscape features that depends on algorithms properties could\nfurther improve regression accuracy, we regard the modular CMA-ES framework and\nestimate how much each landscape feature contributes to the best algorithm\nperformance regression models. Exploratory data analysis performed on this data\nindicate that the set of most relevant features does not depend on the\nconfiguration of individual modules, but the influence that these features have\non regression accuracy does. In addition, we have shown that by using\nclassifiers that take the features relevance on the model accuracy, we are able\nto predict the status of individual modules in the CMA-ES configurations.",
          "link": "http://arxiv.org/abs/2204.07431",
          "publishedOn": "2022-04-18T00:59:14.010Z",
          "wordCount": 631,
          "title": "The Importance of Landscape Features for Performance Prediction of Modular CMA-ES Variants. (arXiv:2204.07431v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.10545",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vaiciukynas_E/0/1/0/all/0/1\">Evaldas Vaiciukynas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Danenas_P/0/1/0/all/0/1\">Paulius Danenas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kontrimas_V/0/1/0/all/0/1\">Vilius Kontrimas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Butleris_R/0/1/0/all/0/1\">Rimantas Butleris</a>",
          "description": "Amounts of historical data collected increase and business intelligence\napplicability with automatic forecasting of time series are in high demand.\nWhile no single time series modeling method is universal to all types of\ndynamics, forecasting using an ensemble of several methods is often seen as a\ncompromise. Instead of fixing ensemble diversity and size, we propose to\npredict these aspects adaptively using meta-learning. Meta-learning here\nconsiders two separate random forest regression models, built on 390\ntime-series features, to rank 22 univariate forecasting methods and recommend\nensemble size. The forecasting ensemble is consequently formed from methods\nranked as the best, and forecasts are pooled using either simple or weighted\naverage (with a weight corresponding to reciprocal rank). The proposed approach\nwas tested on 12561 micro-economic time-series (expanded to 38633 for various\nforecasting horizons) of M4 competition where meta-learning outperformed Theta\nand Comb benchmarks by relative forecasting errors for all data types and\nhorizons. Best overall results were achieved by weighted pooling with a\nsymmetric mean absolute percentage error of 9.21% versus 11.05% obtained using\nthe Theta method.",
          "link": "http://arxiv.org/abs/2011.10545",
          "publishedOn": "2022-04-18T00:59:14.002Z",
          "wordCount": 669,
          "title": "Two-Step Meta-Learning for Time-Series Forecasting Ensemble. (arXiv:2011.10545v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.02529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghaffari_S/0/1/0/all/0/1\">Saba Ghaffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saleh_E/0/1/0/all/0/1\">Ehsan Saleh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forsyth_D/0/1/0/all/0/1\">David Forsyth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-xiong Wang</a>",
          "description": "Learning accurate classifiers for novel categories from very few examples,\nknown as few-shot image classification, is a challenging task in statistical\nmachine learning and computer vision. The performance in few-shot\nclassification suffers from the bias in the estimation of classifier\nparameters; however, an effective underlying bias reduction technique that\ncould alleviate this issue in training few-shot classifiers has been\noverlooked. In this work, we demonstrate the effectiveness of Firth bias\nreduction in few-shot classification. Theoretically, Firth bias reduction\nremoves the $O(N^{-1})$ first order term from the small-sample bias of the\nMaximum Likelihood Estimator. Here we show that the general Firth bias\nreduction technique simplifies to encouraging uniform class assignment\nprobabilities for multinomial logistic classification, and almost has the same\neffect in cosine classifiers. We derive an easy-to-implement optimization\nobjective for Firth penalized multinomial logistic and cosine classifiers,\nwhich is equivalent to penalizing the cross-entropy loss with a KL-divergence\nbetween the uniform label distribution and the predictions. Then, we\nempirically evaluate that it is consistently effective across the board for\nfew-shot image classification, regardless of (1) the feature representations\nfrom different backbones, (2) the number of samples per class, and (3) the\nnumber of classes. Finally, we show the robustness of Firth bias reduction, in\nthe case of imbalanced data distribution. Our implementation is available at\nhttps://github.com/ehsansaleh/firth_bias_reduction",
          "link": "http://arxiv.org/abs/2110.02529",
          "publishedOn": "2022-04-18T00:59:13.994Z",
          "wordCount": null,
          "title": "On the Importance of Firth Bias Reduction in Few-Shot Classification. (arXiv:2110.02529v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Junhong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khodak_M/0/1/0/all/0/1\">Mikhail Khodak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1\">Ameet Talwalkar</a>",
          "description": "While neural architecture search (NAS) has enabled automated machine learning\n(AutoML) for well-researched areas, its application to tasks beyond computer\nvision is still under-explored. As less-studied domains are precisely those\nwhere we expect AutoML to have the greatest impact, in this work we study NAS\nfor efficiently solving diverse problems. Seeking an approach that is fast,\nsimple, and broadly applicable, we fix a standard convolutional network (CNN)\ntopology and propose to search for the right kernel sizes and dilations its\noperations should take on. This dramatically expands the model's capacity to\nextract features at multiple resolutions for different types of data while only\nrequiring search over the operation space. To overcome the efficiency\nchallenges of naive weight-sharing in this search space, we introduce DASH, a\ndifferentiable NAS algorithm that computes the mixture-of-operations using the\nFourier diagonalization of convolution, achieving both a better asymptotic\ncomplexity and an up-to-10x search time speedup in practice. We evaluate DASH\non NAS-Bench-360, a suite of ten tasks designed for benchmarking NAS in diverse\ndomains. DASH outperforms state-of-the-art methods in aggregate, attaining the\nbest-known automated performance on seven tasks. Meanwhile, on six of the ten\ntasks, the combined search and retraining time is less than 2x slower than\nsimply training a CNN backbone that is far less accurate.",
          "link": "http://arxiv.org/abs/2204.07554",
          "publishedOn": "2022-04-18T00:59:13.993Z",
          "wordCount": null,
          "title": "Efficient Architecture Search for Diverse Tasks. (arXiv:2204.07554v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Q/0/1/0/all/0/1\">Quanfu Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yilai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuguang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohn_J/0/1/0/all/0/1\">John Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vos_S/0/1/0/all/0/1\">Seychelle M. Vos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cianfrocco_M/0/1/0/all/0/1\">Michael A. Cianfrocco</a>",
          "description": "Single-particle cryo-electron microscopy (cryo-EM) has become one of the\nmainstream structural biology techniques because of its ability to determine\nhigh-resolution structures of dynamic bio-molecules. However, cryo-EM data\nacquisition remains expensive and labor-intensive, requiring substantial\nexpertise. Structural biologists need a more efficient and objective method to\ncollect the best data in a limited time frame. We formulate the cryo-EM data\ncollection task as an optimization problem in this work. The goal is to\nmaximize the total number of good images taken within a specified period. We\nshow that reinforcement learning offers an effective way to plan cryo-EM data\ncollection, successfully navigating heterogenous cryo-EM grids. The approach we\ndeveloped, cryoRL, demonstrates better performance than average users for data\ncollection under similar settings.",
          "link": "http://arxiv.org/abs/2204.07543",
          "publishedOn": "2022-04-18T00:59:13.992Z",
          "wordCount": null,
          "title": "CryoRL: Reinforcement Learning Enables Efficient Cryo-EM Data Collection. (arXiv:2204.07543v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1\">Tal Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buthpitiya_S/0/1/0/all/0/1\">Senaka Buthpitiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabrikant_A/0/1/0/all/0/1\">Alex Fabrikant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1\">Donald Metzler</a>",
          "description": "Natural Language Inference (NLI) has been extensively studied by the NLP\ncommunity as a framework for estimating the semantic relation between sentence\npairs. While early work identified certain biases in NLI models, recent\nadvancements in modeling and datasets demonstrated promising performance. In\nthis work, we further explore the direct zero-shot applicability of NLI models\nto real applications, beyond the sentence-pair setting they were trained on.\nFirst, we analyze the robustness of these models to longer and out-of-domain\ninputs. Then, we develop new aggregation methods to allow operating over full\ndocuments, reaching state-of-the-art performance on the ContractNLI dataset.\nInterestingly, we find NLI scores to provide strong retrieval signals, leading\nto more relevant evidence extractions compared to common similarity-based\nmethods. Finally, we go further and investigate whole document clusters to\nidentify both discrepancies and consensus among sources. In a test case, we\nfind real inconsistencies between Wikipedia pages in different languages about\nthe same topic.",
          "link": "http://arxiv.org/abs/2204.07447",
          "publishedOn": "2022-04-18T00:59:13.976Z",
          "wordCount": 600,
          "title": "Stretching Sentence-pair NLI Models to Reason over Long Documents and Clusters. (arXiv:2204.07447v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.05527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dongjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seungjae Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kyungwoo Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wanmo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_I/0/1/0/all/0/1\">Il-Chul Moon</a>",
          "description": "Recent advances in diffusion models bring the state-of-the art performance on\nimage generation tasks. However, empirical results on previous research in\ndiffusion models imply that there is an inverse correlation on performances for\ndensity estimation and sample generation. This paper analyzes that the inverse\ncorrelation arises because density estimation is mostly contributed from small\ndiffusion time, whereas sample generation mainly depends on large diffusion\ntime. However, training score network on both small and large diffusion time is\ndemanding because of the loss imbalance issue. To successfully train the score\nnetwork on both small and large diffusion time, this paper introduces a\ntraining technique, Soft Truncation, that softens the truncation time for every\nmini-batch update, which is universally applicable to any types of diffusion\nmodels. It turns out that Soft Truncation is equivalent to a diffusion model\nwith a general weight, and we prove the variational bound of the general\nweighted diffusion model. In view of this variational bound, Soft Truncation\nbecomes a natural way to train the score network. In experiments, Soft\nTruncation achieves the state-of-the-art performance on CIFAR-10, CelebA,\nCelebA-HQ $256\\times 256$, and STL-10 datasets.",
          "link": "http://arxiv.org/abs/2106.05527",
          "publishedOn": "2022-04-18T00:59:13.968Z",
          "wordCount": 695,
          "title": "Soft Truncation: A Universal Training Technique of Score-based Diffusion Model for High Precision Score Estimation. (arXiv:2106.05527v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stepikin_A/0/1/0/all/0/1\">Alexander Stepikin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romanenkova_E/0/1/0/all/0/1\">Evgenia Romanenkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1\">Alexey Zaytsev</a>",
          "description": "A change points detection aims to catch an abrupt disorder in data\ndistribution. Common approaches assume that there are only two fixed\ndistributions for data: one before and another after a change point. Real-world\ndata are richer than this assumption. There can be multiple different\ndistributions before and after a change. We propose an approach that works in\nthe multiple-distributions scenario. Our approach learn representations for\nsemi-structured data suitable for change point detection, while a common\nclassifiers-based approach fails. Moreover, our model is more robust, when\npredicting change points. The datasets used for benchmarking are sequences of\nimages with and without change points in them.",
          "link": "http://arxiv.org/abs/2204.07403",
          "publishedOn": "2022-04-18T00:59:13.960Z",
          "wordCount": 541,
          "title": "Deep learning model solves change point detection for multiple change types. (arXiv:2204.07403v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07391",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Novelli_P/0/1/0/all/0/1\">Pietro Novelli</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bonati_L/0/1/0/all/0/1\">Luigi Bonati</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pontil_M/0/1/0/all/0/1\">Massimiliano Pontil</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Parrinello_M/0/1/0/all/0/1\">Michele Parrinello</a>",
          "description": "Present-day atomistic simulations generate long trajectories of ever more\ncomplex systems. Analyzing these data, discovering metastable states, and\nuncovering their nature is becoming increasingly challenging. In this paper, we\nfirst use the variational approach to conformation dynamics to discover the\nslowest dynamical modes of the simulations. This allows the different\nmetastable states of the system to be located and organized hierarchically. The\nphysical descriptors that characterize metastable states are discovered by\nmeans of a machine learning method. We show in the cases of two proteins,\nChignolin and Bovine Pancreatic Trypsin Inhibitor, how such analysis can be\neffortlessly performed in a matter of seconds. Another strength of our approach\nis that it can be applied to the analysis of both unbiased and biased\nsimulations.",
          "link": "http://arxiv.org/abs/2204.07391",
          "publishedOn": "2022-04-18T00:59:13.953Z",
          "wordCount": 579,
          "title": "Characterizing metastable states with the help of machine learning. (arXiv:2204.07391v1 [physics.comp-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.08604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Galvez_B/0/1/0/all/0/1\">Borja Rodr&#xed;guez-G&#xe1;lvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granqvist_F/0/1/0/all/0/1\">Filip Granqvist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalen_R/0/1/0/all/0/1\">Rogier van Dalen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seigel_M/0/1/0/all/0/1\">Matt Seigel</a>",
          "description": "Federated learning with differential privacy, or private federated learning,\nprovides a strategy to train machine learning models while respecting users'\nprivacy. However, differential privacy can disproportionately degrade the\nperformance of the models on under-represented groups, as these parts of the\ndistribution are difficult to learn in the presence of noise. Existing\napproaches for enforcing fairness in machine learning models have considered\nthe centralized setting, in which the algorithm has access to the users' data.\nThis paper introduces an algorithm to enforce group fairness in private\nfederated learning, where users' data does not leave their devices. First, the\npaper extends the modified method of differential multipliers to empirical risk\nminimization with fairness constraints, thus providing an algorithm to enforce\nfairness in the central setting. Then, this algorithm is extended to the\nprivate federated learning setting. The proposed algorithm, \\texttt{FPFL}, is\ntested on a federated version of the Adult dataset and an \"unfair\" version of\nthe FEMNIST dataset. The experiments on these datasets show how private\nfederated learning accentuates unfairness in the trained models, and how FPFL\nis able to mitigate such unfairness.",
          "link": "http://arxiv.org/abs/2109.08604",
          "publishedOn": "2022-04-18T00:59:13.945Z",
          "wordCount": 677,
          "title": "Enforcing fairness in private federated learning via the modified method of differential multipliers. (arXiv:2109.08604v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.03259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biedenkapp_A/0/1/0/all/0/1\">Andr&#xe9; Biedenkapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_N/0/1/0/all/0/1\">Nguyen Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krejca_M/0/1/0/all/0/1\">Martin S. Krejca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doerr_C/0/1/0/all/0/1\">Carola Doerr</a>",
          "description": "It has long been observed that the performance of evolutionary algorithms and\nother randomized search heuristics can benefit from a non-static choice of the\nparameters that steer their optimization behavior. Mechanisms that identify\nsuitable configurations on the fly (\"parameter control\") or via a dedicated\ntraining process (\"dynamic algorithm configuration\") are therefore an important\ncomponent of modern evolutionary computation frameworks. Several approaches to\naddress the dynamic parameter setting problem exist, but we barely understand\nwhich ones to prefer for which applications. As in classical benchmarking,\nproblem collections with a known ground truth can offer very meaningful\ninsights in this context. Unfortunately, settings with well-understood control\npolicies are very rare.\n\nOne of the few exceptions for which we know which parameter settings minimize\nthe expected runtime is the LeadingOnes problem. We extend this benchmark by\nanalyzing optimal control policies that can select the parameters only from a\ngiven portfolio of possible values. This also allows us to compute optimal\nparameter portfolios of a given size. We demonstrate the usefulness of our\nbenchmarks by analyzing the behavior of the DDQN reinforcement learning\napproach for dynamic algorithm configuration.",
          "link": "http://arxiv.org/abs/2202.03259",
          "publishedOn": "2022-04-18T00:59:13.922Z",
          "wordCount": null,
          "title": "Theory-inspired Parameter Control Benchmarks for Dynamic Algorithm Configuration. (arXiv:2202.03259v2 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khandelwal_A/0/1/0/all/0/1\">Apoorv Khandelwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weihs_L/0/1/0/all/0/1\">Luca Weihs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mottaghi_R/0/1/0/all/0/1\">Roozbeh Mottaghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kembhavi_A/0/1/0/all/0/1\">Aniruddha Kembhavi</a>",
          "description": "Contrastive language image pretraining (CLIP) encoders have been shown to be\nbeneficial for a range of visual tasks from classification and detection to\ncaptioning and image manipulation. We investigate the effectiveness of CLIP\nvisual backbones for Embodied AI tasks. We build incredibly simple baselines,\nnamed EmbCLIP, with no task specific architectures, inductive biases (such as\nthe use of semantic maps), auxiliary tasks during training, or depth maps --\nyet we find that our improved baselines perform very well across a range of\ntasks and simulators. EmbCLIP tops the RoboTHOR ObjectNav leaderboard by a huge\nmargin of 20 pts (Success Rate). It tops the iTHOR 1-Phase Rearrangement\nleaderboard, beating the next best submission, which employs Active Neural\nMapping, and more than doubling the % Fixed Strict metric (0.08 to 0.17). It\nalso beats the winners of the 2021 Habitat ObjectNav Challenge, which employ\nauxiliary tasks, depth maps, and human demonstrations, and those of the 2019\nHabitat PointNav Challenge. We evaluate the ability of CLIP's visual\nrepresentations at capturing semantic information about input observations --\nprimitives that are useful for navigation-heavy embodied tasks -- and find that\nCLIP's representations encode these primitives more effectively than\nImageNet-pretrained backbones. Finally, we extend one of our baselines,\nproducing an agent capable of zero-shot object navigation that can navigate to\nobjects that were not used as targets during training. Our code and models are\navailable at https://github.com/allenai/embodied-clip",
          "link": "http://arxiv.org/abs/2111.09888",
          "publishedOn": "2022-04-18T00:59:13.921Z",
          "wordCount": 709,
          "title": "Simple but Effective: CLIP Embeddings for Embodied AI. (arXiv:2111.09888v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xinyu Zhou</a>",
          "description": "Although nanorobots have been used as clinical prescriptions for work such as\ngastroscopy, and even photoacoustic tomography technology has been proposed to\ncontrol nanorobots to deliver drugs at designated delivery points in real time,\nand there are cases of eliminating \"superbacteria\" in blood through nanorobots,\nmost technologies are immature, either with low efficiency or low accuracy,\nEither it can not be mass produced, so the most effective way to treat cancer\ndiseases at this stage is through chemotherapy and radiotherapy. Patients are\nsuffering and can not be cured. Therefore, this paper proposes an ideal model\nof a treatment method that can completely cure cancer, a cooperative treatment\nmethod based on nano robot queue through team member communication and computer\nvision image classification (target detection).",
          "link": "http://arxiv.org/abs/2111.11236",
          "publishedOn": "2022-04-18T00:59:13.896Z",
          "wordCount": null,
          "title": "Nanorobot queue: Cooperative treatment of cancer based on team member communication and image processing. (arXiv:2111.11236v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2001.11419",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gilman_K/0/1/0/all/0/1\">Kyle Gilman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tarzanagh_D/0/1/0/all/0/1\">Davoud Ataee Tarzanagh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Balzano_L/0/1/0/all/0/1\">Laura Balzano</a>",
          "description": "We propose a new fast streaming algorithm for the tensor completion problem\nof imputing missing entries of a low-tubal-rank tensor using the tensor\nsingular value decomposition (t-SVD) algebraic framework. We show the t-SVD is\na specialization of the well-studied block-term decomposition for third-order\ntensors, and we present an algorithm under this model that can track changing\nfree submodules from incomplete streaming 2-D data. The proposed algorithm uses\nprinciples from incremental gradient descent on the Grassmann manifold of\nsubspaces to solve the tensor completion problem with linear complexity and\nconstant memory in the number of time samples. We provide a local expected\nlinear convergence result for our algorithm. Our empirical results are\ncompetitive in accuracy but much faster in compute time than state-of-the-art\ntensor completion algorithms on real applications to recover temporal\nchemo-sensing and MRI data under limited sampling.",
          "link": "http://arxiv.org/abs/2001.11419",
          "publishedOn": "2022-04-18T00:59:13.894Z",
          "wordCount": null,
          "title": "Grassmannian Optimization for Online Tensor Completion and Tracking with the t-SVD. (arXiv:2001.11419v4 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Knyazev_N/0/1/0/all/0/1\">Nick Knyazev</a>",
          "description": "This paper is devoted to a practical method for ferroalloys consumption\nmodeling and optimization. We consider the problem of selecting the optimal\nprocess control parameters based on the analysis of historical data from\nsensors. We developed approach, which predicts results of chemical reactions\nand give ferroalloys consumption recommendation. The main features of our\nmethod are easy interpretation and noise resistance. Our approach is based on\nk-means clustering algorithm, decision trees and linear regression. The main\nidea of the method is to identify situations where processes go similarly. For\nthis, we propose using a k-means based dataset clustering algorithm and a\nclassification algorithm to determine the cluster. This algorithm can be also\napplied to various technological processes, in this article, we demonstrate its\napplication in metallurgy. To test the application of the proposed method, we\nused it to optimize ferroalloys consumption in Basic Oxygen Furnace steelmaking\nwhen finishing steel in a ladle furnace. The minimum required element content\nfor a given steel grade was selected as the predictive model's target variable,\nand the required amount of the element to be added to the melt as the optimized\nvariable. Keywords: Clustering, Machine Learning, Linear Regression,\nSteelmaking, Optimization, Gradient Boosting, Artificial Intelligence, Decision\nTrees, Recommendation services",
          "link": "http://arxiv.org/abs/2204.07421",
          "publishedOn": "2022-04-18T00:59:13.893Z",
          "wordCount": null,
          "title": "An interpretable machine learning approach for ferroalloys consumptions. (arXiv:2204.07421v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1909.04746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khaled_A/0/1/0/all/0/1\">Ahmed Khaled</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>",
          "description": "We provide a new analysis of local SGD, removing unnecessary assumptions and\nelaborating on the difference between two data regimes: identical and\nheterogeneous. In both cases, we improve the existing theory and provide values\nof the optimal stepsize and optimal number of local iterations. Our bounds are\nbased on a new notion of variance that is specific to local SGD methods with\ndifferent data. The tightness of our results is guaranteed by recovering known\nstatements when we plug $H=1$, where $H$ is the number of local steps. The\nempirical evidence further validates the severe impact of data heterogeneity on\nthe performance of local SGD.",
          "link": "http://arxiv.org/abs/1909.04746",
          "publishedOn": "2022-04-18T00:59:13.893Z",
          "wordCount": null,
          "title": "Tighter Theory for Local SGD on Identical and Heterogeneous Data. (arXiv:1909.04746v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.07029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Keqian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yifan Hu</a>",
          "description": "We study the problem of user segmentation: given a set of users and one or\nmore predefined groups or segments, assign users to their corresponding\nsegments. As an example, for a segment indicating particular interest in a\ncertain area of sports or entertainment, the task will be to predict whether\neach single user will belong to the segment. However, there may exist numerous\nlong tail prediction tasks that suffer from data availability and may be of\nheterogeneous nature, which make it hard to capture using single off the shelf\nmodel architectures. In this work, we present SuperCone, our unified\npredicative segments system that addresses the above challenges. It builds on\ntop of a flat concept representation that summarizes each user's heterogeneous\ndigital footprints, and uniformly models each of the prediction task using an\napproach called \"super learning \", that is, combining prediction models with\ndiverse architectures or learning method that are not compatible with each\nother. Following this, we provide an end to end approach that learns to\nflexibly attend to best suited heterogeneous experts adaptively, while at the\nsame time incorporating deep representations of the input concepts that\naugments the above experts. Experiments show that SuperCone significantly\noutperform state-of-the-art recommendation and ranking algorithms on a wide\nrange of predicative segment tasks and public structured data learning\nbenchmarks.",
          "link": "http://arxiv.org/abs/2203.07029",
          "publishedOn": "2022-04-18T00:59:13.893Z",
          "wordCount": null,
          "title": "SuperCone: Unified User Segmentation over Heterogeneous Experts via Concept Meta-learning. (arXiv:2203.07029v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Selim_M/0/1/0/all/0/1\">Mahmoud Selim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alanwar_A/0/1/0/all/0/1\">Amr Alanwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kousik_S/0/1/0/all/0/1\">Shreyas Kousik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Grace Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_K/0/1/0/all/0/1\">Karl H. Johansson</a>",
          "description": "Reinforcement learning (RL) is capable of sophisticated motion planning and\ncontrol for robots in uncertain environments. However, state-of-the-art deep RL\napproaches typically lack safety guarantees, especially when the robot and\nenvironment models are unknown. To justify widespread deployment, robots must\nrespect safety constraints without sacrificing performance. Thus, we propose a\nBlack-box Reachability-based Safety Layer (BRSL) with three main components:\n(1) data-driven reachability analysis for a black-box robot model, (2) a\ntrajectory rollout planner that predicts future actions and observations using\nan ensemble of neural networks trained online, and (3) a differentiable\npolytope collision check between the reachable set and obstacles that enables\ncorrecting unsafe actions. In simulation, BRSL outperforms other\nstate-of-the-art safe RL methods on a Turtlebot 3, a quadrotor, and a\ntrajectory-tracking point mass with an unsafe set adjacent to the area of\nhighest reward.",
          "link": "http://arxiv.org/abs/2204.07417",
          "publishedOn": "2022-04-18T00:59:13.892Z",
          "wordCount": null,
          "title": "Safe Reinforcement Learning Using Black-Box Reachability Analysis. (arXiv:2204.07417v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07457",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Neskorniuk_V/0/1/0/all/0/1\">Vladislav Neskorniuk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Carnio_A/0/1/0/all/0/1\">Andrea Carnio</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Marsella_D/0/1/0/all/0/1\">Domenico Marsella</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Turitsyn_S/0/1/0/all/0/1\">Sergei K. Turitsyn</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prilepsky_J/0/1/0/all/0/1\">Jaroslaw E. Prilepsky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aref_V/0/1/0/all/0/1\">Vahid Aref</a>",
          "description": "Autoencoder-based deep learning is applied to jointly optimize geometric and\nprobabilistic constellation shaping for optical coherent communication. The\noptimized constellation shaping outperforms the 256 QAM Maxwell-Boltzmann\nprobabilistic distribution with extra 0.05 bits/4D-symbol mutual information\nfor 64 GBd transmission over 170 km SMF link.",
          "link": "http://arxiv.org/abs/2204.07457",
          "publishedOn": "2022-04-18T00:59:13.892Z",
          "wordCount": null,
          "title": "Model-Based Deep Learning of Joint Probabilistic and Geometric Shaping for Optical Communication. (arXiv:2204.07457v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07492",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Chase_R/0/1/0/all/0/1\">Randy J. Chase</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Harrison_D/0/1/0/all/0/1\">David R. Harrison</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Burke_A/0/1/0/all/0/1\">Amanda Burke</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lackmann_G/0/1/0/all/0/1\">Gary M. Lackmann</a>, <a href=\"http://arxiv.org/find/physics/1/au:+McGovern_A/0/1/0/all/0/1\">Amy McGovern</a>",
          "description": "Recently, the use of machine learning in meteorology has increased greatly.\nWhile many machine learning methods are not new, university classes on machine\nlearning are largely unavailable to meteorology students and are not required\nto become a meteorologist. The lack of formal instruction has contributed to\nperception that machine learning methods are 'black boxes' and thus end-users\nare hesitant to apply the machine learning methods in their every day workflow.\nTo reduce the opaqueness of machine learning methods and lower hesitancy\ntowards machine learning in meteorology, this paper provides a survey of some\nof the most common machine learning methods. A familiar meteorological example\nis used to contextualize the machine learning methods while also discussing\nmachine learning topics using plain language. The following machine learning\nmethods are demonstrated: linear regression; logistic regression; decision\ntrees; random forest; gradient boosted decision trees; naive Bayes; and support\nvector machines. Beyond discussing the different methods, the paper also\ncontains discussions on the general machine learning process as well as best\npractices to enable readers to apply machine learning to their own datasets.\nFurthermore, all code (in the form of Jupyter notebooks and Google Colaboratory\nnotebooks) used to make the examples in the paper is provided in an effort to\ncatalyse the use of machine learning in meteorology.",
          "link": "http://arxiv.org/abs/2204.07492",
          "publishedOn": "2022-04-18T00:59:13.892Z",
          "wordCount": null,
          "title": "A Machine Learning Tutorial for Operational Meteorology, Part I: Traditional Machine Learning. (arXiv:2204.07492v1 [physics.ao-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.08966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sigrist_F/0/1/0/all/0/1\">Fabio Sigrist</a>",
          "description": "Latent Gaussian models and boosting are widely used techniques in statistics\nand machine learning. Tree-boosting shows excellent prediction accuracy on many\ndata sets, but potential drawbacks are that it assumes conditional independence\nof samples, produces discontinuous predictions for, e.g., spatial data, and it\ncan have difficulty with high-cardinality categorical variables. Latent\nGaussian models, such as Gaussian process and grouped random effects models,\nare flexible prior models which explicitly model dependence among samples and\nwhich allow for efficient learning of predictor functions and for making\nprobabilistic predictions. However, existing latent Gaussian models usually\nassume either a zero or a linear prior mean function which can be an\nunrealistic assumption. This article introduces a novel approach that combines\nboosting and latent Gaussian models to remedy the above-mentioned drawbacks and\nto leverage the advantages of both techniques. We obtain increased prediction\naccuracy compared to existing approaches in both simulated and real-world data\nexperiments.",
          "link": "http://arxiv.org/abs/2105.08966",
          "publishedOn": "2022-04-18T00:59:13.891Z",
          "wordCount": null,
          "title": "Latent Gaussian Model Boosting. (arXiv:2105.08966v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07413",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Zayats_M/0/1/0/all/0/1\">Mykhaylo Zayats</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zimon_M/0/1/0/all/0/1\">Ma&#x142;gorzata J. Zimo&#x144;</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yeo_K/0/1/0/all/0/1\">Kyongmin Yeo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhuk_S/0/1/0/all/0/1\">Sergiy Zhuk</a>",
          "description": "We propose a new design of a neural network for solving a zero shot super\nresolution problem for turbulent flows. We embed Luenberger-type observer into\nthe network's architecture to inform the network of the physics of the process,\nand to provide error correction and stabilization mechanisms. In addition, to\ncompensate for decrease of observer's performance due to the presence of\nunknown destabilizing forcing, the network is designed to estimate the\ncontribution of the unknown forcing implicitly from the data over the course of\ntraining. By running a set of numerical experiments, we demonstrate that the\nproposed network does recover unknown forcing from data and is capable of\npredicting turbulent flows in high resolution from low resolution noisy\nobservations.",
          "link": "http://arxiv.org/abs/2204.07413",
          "publishedOn": "2022-04-18T00:59:13.890Z",
          "wordCount": 575,
          "title": "Super Resolution for Turbulent Flows in 2D: Stabilized Physics Informed Neural Networks. (arXiv:2204.07413v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoneda_T/0/1/0/all/0/1\">Takuma Yoneda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Ge Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walter_M/0/1/0/all/0/1\">Matthew R. Walter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stadie_B/0/1/0/all/0/1\">Bradly Stadie</a>",
          "description": "We introduce a general approach, called Invariance through Inference, for\nimproving the test-time performance of an agent in deployment environments with\nunknown perceptual variations. Instead of producing invariant visual features\nthrough interpolation, invariance through inference turns adaptation at\ndeployment-time into an unsupervised learning problem. This is achieved in\npractice by deploying a straightforward algorithm that tries to match the\ndistribution of latent features to the agent's prior experience, without\nrelying on paired data. Although simple, we show that this idea leads to\nsurprising improvements on a variety of adaptation scenarios without access to\ndeployment-time rewards, including changes in scene content, camera poses, and\nlighting conditions. We present results on challenging domains including\ndistractor control suite and sim-to-real transfer for image-based robot\nmanipulation.",
          "link": "http://arxiv.org/abs/2112.08526",
          "publishedOn": "2022-04-18T00:59:13.882Z",
          "wordCount": null,
          "title": "Invariance Through Inference. (arXiv:2112.08526v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_M/0/1/0/all/0/1\">Minzhou Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Just_H/0/1/0/all/0/1\">Hoang Anh Just</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1\">Lingjuan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_M/0/1/0/all/0/1\">Meikang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>",
          "description": "Backdoor attacks insert malicious data into a training set so that, during\ninference time, it misclassifies inputs that have been patched with a backdoor\ntrigger as the malware specified label. For backdoor attacks to bypass human\ninspection, it is essential that the injected data appear to be correctly\nlabeled. The attacks with such property are often referred to as \"clean-label\nattacks.\" Existing clean-label backdoor attacks require knowledge of the entire\ntraining set to be effective. Obtaining such knowledge is difficult or\nimpossible because training data are often gathered from multiple sources\n(e.g., face images from different users). It remains a question whether\nbackdoor attacks still present a real threat.\n\nThis paper provides an affirmative answer to this question by designing an\nalgorithm to mount clean-label backdoor attacks based only on the knowledge of\nrepresentative examples from the target class. With poisoning equal to or less\nthan 0.5% of the target-class data and 0.05% of the training set, we can train\na model to classify test examples from arbitrary classes into the target class\nwhen the examples are patched with a backdoor trigger. Our attack works well\nacross datasets and models, even when the trigger presents in the physical\nworld.\n\nWe explore the space of defenses and find that, surprisingly, our attack can\nevade the latest state-of-the-art defenses in their vanilla form, or after a\nsimple twist, we can adapt to the downstream defenses. We study the cause of\nthe intriguing effectiveness and find that because the trigger synthesized by\nour attack contains features as persistent as the original semantic features of\nthe target class, any attempt to remove such triggers would inevitably hurt the\nmodel accuracy first.",
          "link": "http://arxiv.org/abs/2204.05255",
          "publishedOn": "2022-04-18T00:59:13.882Z",
          "wordCount": null,
          "title": "Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information. (arXiv:2204.05255v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_R/0/1/0/all/0/1\">Ruibin Mao</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Wen_B/0/1/0/all/0/1\">Bo Wen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yahui Zhao</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1\">Arman Kazemi</a> (2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Laguna_A/0/1/0/all/0/1\">Ann Franchesca Laguna</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Neimier_M/0/1/0/all/0/1\">Michael Neimier</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">X. Sharon Hu</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1\">Xia Sheng</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Graves_C/0/1/0/all/0/1\">Catherine E. Graves</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Strachan_J/0/1/0/all/0/1\">John Paul Strachan</a> (4, 5), <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Can Li</a> (1) ((1) The University of Hong Kong, (2) Hewlett Packard Labs, (3) University of Notre Dame, (4) Peter Gr&#xfc;nberg Institut (PGI-14), (5) RWTH Aachen University)",
          "description": "Lifelong on-device learning is a key challenge for machine intelligence, and\nthis requires learning from few, often single, samples. Memory augmented neural\nnetwork has been proposed to achieve the goal, but the memory module has to be\nstored in an off-chip memory due to its size. Therefore the practical use has\nbeen heavily limited. Previous works on emerging memory-based implementation\nhave difficulties in scaling up because different modules with various\nstructures are difficult to integrate on the same chip and the small sense\nmargin of the content addressable memory for the memory module heavily limited\nthe degree of mismatch calculation. In this work, we implement the entire\nmemory augmented neural network architecture in a fully integrated memristive\ncrossbar platform and achieve an accuracy that closely matches standard\nsoftware on digital hardware for the Omniglot dataset. The successful\ndemonstration is supported by implementing new functions in crossbars in\naddition to widely reported matrix multiplications. For example, the\nlocality-sensitive hashing operation is implemented in crossbar arrays by\nexploiting the intrinsic stochasticity of memristor devices. Besides, the\ncontent-addressable memory module is realized in crossbars, which also supports\nthe degree of mismatches. Simulations based on experimentally validated models\nshow such an implementation can be efficiently scaled up for one-shot learning\non the Mini-ImageNet dataset. The successful demonstration paves the way for\npractical on-device lifelong learning and opens possibilities for novel\nattention-based algorithms not possible in conventional hardware.",
          "link": "http://arxiv.org/abs/2204.07429",
          "publishedOn": "2022-04-18T00:59:13.881Z",
          "wordCount": null,
          "title": "Experimentally realized memristive memory augmented neural network. (arXiv:2204.07429v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05205",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Javed_S/0/1/0/all/0/1\">Syed Ashar Javed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Juyal_D/0/1/0/all/0/1\">Dinkar Juyal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shanis_Z/0/1/0/all/0/1\">Zahil Shanis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chakraborty_S/0/1/0/all/0/1\">Shreya Chakraborty</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pokkalla_H/0/1/0/all/0/1\">Harsha Pokkalla</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prakash_A/0/1/0/all/0/1\">Aaditya Prakash</a>",
          "description": "Machine Learning has been applied to pathology images in research and\nclinical practice with promising outcomes. However, standard ML models often\nlack the rigorous evaluation required for clinical decisions. Machine learning\ntechniques for natural images are ill-equipped to deal with pathology images\nthat are significantly large and noisy, require expensive labeling, are hard to\ninterpret, and are susceptible to spurious correlations. We propose a set of\npractical guidelines for ML evaluation in pathology that address the above\nconcerns. The paper includes measures for setting up the evaluation framework,\neffectively dealing with variability in labels, and a recommended suite of\ntests to address issues related to domain shift, robustness, and confounding\nvariables. We hope that the proposed framework will bridge the gap between ML\nresearchers and domain experts, leading to wider adoption of ML techniques in\npathology and improving patient outcomes.",
          "link": "http://arxiv.org/abs/2204.05205",
          "publishedOn": "2022-04-18T00:59:13.879Z",
          "wordCount": null,
          "title": "Rethinking Machine Learning Model Evaluation in Pathology. (arXiv:2204.05205v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Bo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1\">Hakan Bilen</a>",
          "description": "Remarkable progress has been achieved in synthesizing photo-realistic images\nwith generative adversarial neural networks (GANs). Recently, GANs are utilized\nas the training sample generator when obtaining or storing real training data\nis expensive even infeasible. However, traditional GANs generated images are\nnot as informative as the real training samples when being used to train deep\nneural networks. In this paper, we propose a novel method to synthesize\nInformative Training samples with GAN (IT-GAN). Specifically, we freeze a\npre-trained GAN model and learn the informative latent vectors that corresponds\nto informative training samples. The synthesized images are required to\npreserve information for training deep neural networks rather than visual\nreality or fidelity. Experiments verify that the deep neural networks can learn\nfaster and achieve better performance when being trained with our IT-GAN\ngenerated images. We also show that our method is a promising solution to\ndataset condensation problem.",
          "link": "http://arxiv.org/abs/2204.07513",
          "publishedOn": "2022-04-18T00:59:13.876Z",
          "wordCount": null,
          "title": "Synthesizing Informative Training Samples with GAN. (arXiv:2204.07513v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1\">Ke Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>",
          "description": "We propose a streaming non-autoregressive (non-AR) decoding algorithm to\ndeliberate the hypothesis alignment of a streaming RNN-T model. Our algorithm\nfacilitates a simple greedy decoding procedure, and at the same time is capable\nof producing the decoding result at each frame with limited right context, thus\nenjoying both high efficiency and low latency. These advantages are achieved by\nconverting the offline Align-Refine algorithm to be streaming-compatible, with\na novel transformer decoder architecture that performs local self-attentions\nfor both text and audio, and a time-aligned cross-attention at each layer.\nFurthermore, we perform discriminative training of our model with the minimum\nword error rate (MWER) criterion, which has not been done in the non-AR\ndecoding literature. Experiments on voice search datasets and Librispeech show\nthat with reasonable right context, our streaming model performs as well as the\noffline counterpart, and discriminative training leads to further WER gain when\nthe first-pass model has small capacity.",
          "link": "http://arxiv.org/abs/2204.07556",
          "publishedOn": "2022-04-18T00:59:13.876Z",
          "wordCount": null,
          "title": "Streaming Align-Refine for Non-autoregressive Deliberation. (arXiv:2204.07556v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1911.12426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sandler_A/0/1/0/all/0/1\">Adam Sandler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1\">Diego Klabjan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yuan Luo</a>",
          "description": "We develop methods for reducing the dimensionality of large data sets, common\nin biomedical applications. Learning about patients using genetic data often\nincludes more features than observations, which makes direct supervised\nlearning difficult. One method of reducing the feature space is to use latent\nDirichlet allocation to group genetic variants in an unsupervised manner.\nLatent Dirichlet allocation describes a patient as a mixture of topics\ncorresponding to genetic variants. This can be generalized as a Bayesian tensor\ndecomposition to account for multiple feature variables. Our most significant\ncontributions are with hierarchical topic modeling. We design distinct methods\nof incorporating hierarchical topic modeling, based on nested Chinese\nrestaurant processes and Pachinko Allocation Machine, into Bayesian tensor\ndecomposition. We apply these models to examine patients with one of four\ncommon types of cancer (breast, lung, prostate, and colorectal) and siblings\nwith and without autism spectrum disorder. We linked the genes with their\nbiological pathways and combine this information into a tensor of patients,\ncounts of their genetic variants, and the genes' membership in pathways. We\nfind that our trained models outperform baseline models, with respect to\ncoherence, by up to 40%.",
          "link": "http://arxiv.org/abs/1911.12426",
          "publishedOn": "2022-04-18T00:59:13.876Z",
          "wordCount": null,
          "title": "Conditional Hierarchical Bayesian Tucker Decomposition for Genetic Data Analysis. (arXiv:1911.12426v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.13579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ruo Yu Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francois_Lavet_V/0/1/0/all/0/1\">Vincent Fran&#xe7;ois-Lavet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>",
          "description": "We present a new approach for efficient exploration which leverages a\nlow-dimensional encoding of the environment learned with a combination of\nmodel-based and model-free objectives. Our approach uses intrinsic rewards that\nare based on the distance of nearest neighbors in the low dimensional\nrepresentational space to gauge novelty. We then leverage these intrinsic\nrewards for sample-efficient exploration with planning routines in\nrepresentational space for hard exploration tasks with sparse rewards. One key\nelement of our approach is the use of information theoretic principles to shape\nour representations in a way so that our novelty reward goes beyond pixel\nsimilarity. We test our approach on a number of maze tasks, as well as a\ncontrol problem and show that our exploration approach is more sample-efficient\ncompared to strong baselines.",
          "link": "http://arxiv.org/abs/2009.13579",
          "publishedOn": "2022-04-18T00:59:13.876Z",
          "wordCount": null,
          "title": "Novelty Search in Representational Space for Sample Efficient Exploration. (arXiv:2009.13579v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Changhun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyungjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1\">Eunhyeok Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jae-Joon Kim</a>",
          "description": "Binary Neural Networks (BNNs) have emerged as a promising solution for\nreducing the memory footprint and compute costs of deep neural networks. BNNs,\non the other hand, suffer from information loss because binary activations are\nlimited to only two values, resulting in reduced accuracy. To improve the\naccuracy, previous studies have attempted to control the distribution of binary\nactivation by manually shifting the threshold of the activation function or\nmaking the shift amount trainable. During the process, they usually depended on\nstatistical information computed from a batch. We argue that using statistical\ndata from a batch fails to capture the crucial information for each input\ninstance in BNN computations, and the differences between statistical\ninformation computed from each instance need to be considered when determining\nthe binary activation threshold of each instance. Based on the concept, we\npropose the Binary Neural Network with INSTAnce-aware threshold (INSTA-BNN),\nwhich decides the activation threshold value considering the difference between\nstatistical data computed from a batch and each instance. The proposed\nINSTA-BNN outperforms the baseline by 2.5% and 2.3% on the ImageNet\nclassification task with comparable computing cost, achieving 68.0% and 71.7%\ntop-1 accuracy on ResNet-18 and MobileNetV1 based models, respectively.",
          "link": "http://arxiv.org/abs/2204.07439",
          "publishedOn": "2022-04-18T00:59:13.875Z",
          "wordCount": null,
          "title": "INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold. (arXiv:2204.07439v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_M/0/1/0/all/0/1\">Meng Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Huiyu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "This paper studies node classification in the inductive setting, i.e., aiming\nto learn a model on labeled training graphs and generalize it to infer node\nlabels on unlabeled test graphs. This problem has been extensively studied with\ngraph neural networks (GNNs) by learning effective node representations, as\nwell as traditional structured prediction methods for modeling the structured\noutput of node labels, e.g., conditional random fields (CRFs). In this paper,\nwe present a new approach called the Structured Proxy Network (SPN), which\ncombines the advantages of both worlds. SPN defines flexible potential\nfunctions of CRFs with GNNs. However, learning such a model is nontrivial as it\ninvolves optimizing a maximin game with high-cost inference. Inspired by the\nunderlying connection between joint and marginal distributions defined by\nMarkov networks, we propose to solve an approximate version of the optimization\nproblem as a proxy, which yields a near-optimal solution, making learning more\nefficient. Extensive experiments on two settings show that our approach\noutperforms many competitive baselines.",
          "link": "http://arxiv.org/abs/2204.07524",
          "publishedOn": "2022-04-18T00:59:13.875Z",
          "wordCount": null,
          "title": "Neural Structured Prediction for Inductive Node Classification. (arXiv:2204.07524v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Davis_Q/0/1/0/all/0/1\">Q. Tyrell Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bongard_J/0/1/0/all/0/1\">Josh Bongard</a>",
          "description": "Substantial efforts have been applied to engineer CA with desired emergent\nproperties, such as supporting gliders. Recent work in continuous CA has\ngenerated a wide variety of compelling bioreminescent patterns, and the\nexpansion of CA research into continuous numbers, multiple channels, and higher\ndimensions complicates their study. In this work we devise a strategy for\nevolving CA and CA patterns in two steps, based on the simple idea that CA are\nlikely to be complex and computationally capable if they support patterns that\ngrow indefinitely as well as patterns that vanish completely, and are difficult\nto predict the difference in advance. The second part of our strategy evolves\npatterns by selecting for mobility and conservation of mean cell value. We\nvalidate our pattern evolution method by re-discovering gliders in 17 of 17\nLenia CA, and also report 5 new evolved CA that support evolved glider\npatterns, differing from previously reported Lenia patterns. The CA reported\nhere share neighborhood kernels with previously described Lenia CA, but exhibit\na wider range of typical dynamics than their Lenia counterparts. Code for\nevolving continuous CA is made available under an MIT License.",
          "link": "http://arxiv.org/abs/2204.07541",
          "publishedOn": "2022-04-18T00:59:13.875Z",
          "wordCount": null,
          "title": "Selecting Continuous Life-Like Cellular Automata for Halting Unpredictability: Evolving for Abiogenesis. (arXiv:2204.07541v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abbasi_S/0/1/0/all/0/1\">Sina Abbasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bedeer_E/0/1/0/all/0/1\">Ebrahim Bedeer</a>",
          "description": "Faster-than-Nyquist (FTN) signaling is a candidate non-orthonormal\ntransmission technique to improve the spectral efficiency (SE) of future\ncommunication systems. However, such improvements of the SE are at the cost of\nadditional computational complexity to remove the intentionally introduced\nintersymbol interference. In this paper, we investigate the use of deep\nlearning (DL) to reduce the detection complexity of FTN signaling. To eliminate\nthe need of having a noise whitening filter at the receiver, we first present\nan equivalent FTN signaling model based on using a set of orthonormal basis\nfunctions and identify its operation region. Second, we propose a DL-based list\nsphere decoding (DL-LSD) algorithm that selects and updates the initial radius\nof the original LSD to guarantee a pre-defined number $N_{\\text{L}}$ of lattice\npoints inside the hypersphere. This is achieved by training a neural network to\noutput an approximate initial radius that includes $N_{\\text{L}}$ lattice\npoints. At the testing phase, if the hypersphere has more than $N_{\\text{L}}$\nlattice points, we keep the $N_{\\text{L}}$ closest points to the point\ncorresponding to the received FTN signal; however, if the hypersphere has less\nthan $N_{\\text{L}}$ points, we increase the approximate initial radius by a\nvalue that depends on the standard deviation of the distribution of the output\nradii from the training phase. Then, the approximate value of the\nlog-likelihood ratio (LLR) is calculated based on the obtained $N_{\\text{L}}$\npoints. Simulation results show that the computational complexity of the\nproposed DL-LSD is lower than its counterpart of the original LSD by orders of\nmagnitude.",
          "link": "http://arxiv.org/abs/2204.07569",
          "publishedOn": "2022-04-18T00:59:13.874Z",
          "wordCount": null,
          "title": "Deep Learning-based List Sphere Decoding for Faster-than-Nyquist (FTN) Signaling Detection. (arXiv:2204.07569v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07532",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Tian_H/0/1/0/all/0/1\">Hao Tian</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ketkar_R/0/1/0/all/0/1\">Rajas Ketkar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tao_P/0/1/0/all/0/1\">Peng Tao</a>",
          "description": "The absorption, distribution, metabolism, excretion, and toxicity (ADMET)\nproperties are important in drug discovery as they define efficacy and safety.\nHere, we apply an ensemble of features, including fingerprints and descriptors,\nand a tree-based machine learning model, extreme gradient boosting, for\naccurate ADMET prediction. Our model performs well in the Therapeutics Data\nCommons ADMET benchmark group. For 22 tasks, our model is ranked first in 10\ntasks and top 3 in 18 tasks.",
          "link": "http://arxiv.org/abs/2204.07532",
          "publishedOn": "2022-04-18T00:59:13.872Z",
          "wordCount": 504,
          "title": "Accurate ADMET Prediction with XGBoost. (arXiv:2204.07532v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.00009",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kocour_M/0/1/0/all/0/1\">Martin Kocour</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zmolikova_K/0/1/0/all/0/1\">Kate&#x159;ina &#x17d;mol&#xed;kov&#xe1;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ondel_L/0/1/0/all/0/1\">Lucas Ondel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Svec_J/0/1/0/all/0/1\">J&#xe1;n &#x160;vec</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Delcroix_M/0/1/0/all/0/1\">Marc Delcroix</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ochiai_T/0/1/0/all/0/1\">Tsubasa Ochiai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burget_L/0/1/0/all/0/1\">Luk&#xe1;&#x161; Burget</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cernocky_J/0/1/0/all/0/1\">Jan &#x10c;ernock&#xfd;</a>",
          "description": "In typical multi-talker speech recognition systems, a neural network-based\nacoustic model predicts senone state posteriors for each speaker. These are\nlater used by a single-talker decoder which is applied on each speaker-specific\noutput stream separately. In this work, we argue that such a scheme is\nsub-optimal and propose a principled solution that decodes all speakers\njointly. We modify the acoustic model to predict joint state posteriors for all\nspeakers, enabling the network to express uncertainty about the attribution of\nparts of the speech signal to the speakers. We employ a joint decoder that can\nmake use of this uncertainty together with higher-level language information.\nFor this, we revisit decoding algorithms used in factorial generative models in\nearly multi-talker speech recognition systems. In contrast with these early\nworks, we replace the GMM acoustic model with DNN, which provides greater\nmodeling power and simplifies part of the inference. We demonstrate the\nadvantage of joint decoding in proof of concept experiments on a mixed-TIDIGITS\ndataset.",
          "link": "http://arxiv.org/abs/2111.00009",
          "publishedOn": "2022-04-18T00:59:13.865Z",
          "wordCount": null,
          "title": "Revisiting joint decoding based multi-talker speech recognition with DNN acoustic model. (arXiv:2111.00009v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.05624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nath_U/0/1/0/all/0/1\">Utkarsh Nath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kushagra_S/0/1/0/all/0/1\">Shrinu Kushagra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yingzhen Yang</a>",
          "description": "Compressing deep neural networks while maintaining accuracy is important when\nwe want to deploy large, powerful models in production and/or edge devices. One\ncommon technique used to achieve this goal is knowledge distillation.\nTypically, the output of a static pre-defined teacher (a large base network) is\nused as soft labels to train and transfer information to a student (or smaller)\nnetwork. In this paper, we introduce Adjoined Networks, or AN, a learning\nparadigm that trains both the original base network and the smaller compressed\nnetwork together. In our training approach, the parameters of the smaller\nnetwork are shared across both the base and the compressed networks. Using our\ntraining paradigm, we can simultaneously compress (the student network) and\nregularize (the teacher network) any architecture. In this paper, we focus on\npopular CNN-based architectures used for computer vision tasks. We conduct an\nextensive experimental evaluation of our training paradigm on various\nlarge-scale datasets. Using ResNet-50 as the base network, AN achieves 71.8%\ntop-1 accuracy with only 1.8M parameters and 1.6 GFLOPs on the ImageNet\ndata-set. We further propose Differentiable Adjoined Networks (DAN), a training\nparadigm that augments AN by using neural architecture search to jointly learn\nboth the width and the weights for each layer of the smaller network. DAN\nachieves ResNet-50 level accuracy on ImageNet with $3.8\\times$ fewer parameters\nand $2.2\\times$ fewer FLOPs.",
          "link": "http://arxiv.org/abs/2006.05624",
          "publishedOn": "2022-04-18T00:59:13.864Z",
          "wordCount": 744,
          "title": "Adjoined Networks: A Training Paradigm with Applications to Network Compression. (arXiv:2006.05624v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marmoret_A/0/1/0/all/0/1\">Axel Marmoret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;my E. Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bimbot_F/0/1/0/all/0/1\">Fr&#xe9;d&#xe9;ric Bimbot</a>",
          "description": "Music Structure Analysis (MSA) consists in segmenting a music piece in\nseveral distinct sections. We approach MSA within a compression framework,\nunder the hypothesis that the structure is more easily revealed by a simplified\nrepresentation of the original content of the song. More specifically, under\nthe hypothesis that MSA is correlated with similarities occurring at the bar\nscale, this article introduces the use of linear and non-linear compression\nschemes on barwise audio signals. Compressed representations capture the most\nsalient components of the different bars in the song and are then used to infer\nthe song structure using a dynamic programming algorithm. This work explores\nboth low-rank approximation models such as Principal Component Analysis or\nNonnegative Matrix Factorization and \"piece-specific\" Auto-Encoding Neural\nNetworks, with the objective to learn latent representations specific to a\ngiven song. Such approaches do not rely on supervision nor annotations, which\nare well-known to be tedious to collect and possibly ambiguous in MSA\ndescription. In our experiments, several unsupervised compression schemes\nachieve a level of performance comparable to that of state-of-the-art\nsupervised methods (for 3s tolerance) on the RWC-Pop dataset, showcasing the\nimportance of the barwise compression processing for MSA.",
          "link": "http://arxiv.org/abs/2202.04981",
          "publishedOn": "2022-04-18T00:59:13.855Z",
          "wordCount": 684,
          "title": "Barwise Compression Schemes for Audio-Based Music Structure Analysis. (arXiv:2202.04981v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.07258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hulsebos_M/0/1/0/all/0/1\">Madelon Hulsebos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demiralp_C/0/1/0/all/0/1\">&#xc7;a&#x11f;atay Demiralp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groth_P/0/1/0/all/0/1\">Paul Groth</a>",
          "description": "The success of deep learning has sparked interest in improving relational\ntable tasks, like data preparation and search, with table representation models\ntrained on large table corpora. Existing table corpora primarily contain tables\nextracted from HTML pages, limiting the capability to represent offline\ndatabase tables. To train and evaluate high-capacity models for applications\nbeyond the Web, we need resources with tables that resemble relational database\ntables. Here we introduce GitTables, a corpus of 1M relational tables extracted\nfrom GitHub. Our continuing curation aims at growing the corpus to at least 10M\ntables. Analyses of GitTables show that its structure, content, and topical\ncoverage differ significantly from existing table corpora. We annotate table\ncolumns in GitTables with semantic types, hierarchical relations and\ndescriptions from Schema.org and DBpedia. The evaluation of our annotation\npipeline on the T2Dv2 benchmark illustrates that our approach provides results\non par with human annotations. We present three applications of GitTables,\ndemonstrating its value for learned semantic type detection models, schema\ncompletion methods, and benchmarks for table-to-KG matching, data search, and\npreparation. We make the corpus and code available at\nhttps://gittables.github.io.",
          "link": "http://arxiv.org/abs/2106.07258",
          "publishedOn": "2022-04-18T00:59:13.834Z",
          "wordCount": 662,
          "title": "GitTables: A Large-Scale Corpus of Relational Tables. (arXiv:2106.07258v4 [cs.DB] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.12171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kenworthy_L/0/1/0/all/0/1\">Luke Kenworthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayak_S/0/1/0/all/0/1\">Siddharth Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_C/0/1/0/all/0/1\">Christopher Chin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishnan_H/0/1/0/all/0/1\">Hamsa Balakrishnan</a>",
          "description": "Integer programs provide a powerful abstraction for representing a wide range\nof real-world scheduling problems. Despite their ability to model general\nscheduling problems, solving large-scale integer programs (IP) remains a\ncomputational challenge in practice. The incorporation of more complex\nobjectives such as robustness to disruptions further exacerbates the\ncomputational challenge. We present NICE (Neural network IP Coefficient\nExtraction), a novel technique that combines reinforcement learning and integer\nprogramming to tackle the problem of robust scheduling. More specifically, NICE\nuses reinforcement learning to approximately represent complex objectives in an\ninteger programming formulation. We use NICE to determine assignments of pilots\nto a flight crew schedule so as to reduce the impact of disruptions. We compare\nNICE with (1) a baseline integer programming formulation that produces a\nfeasible crew schedule, and (2) a robust integer programming formulation that\nexplicitly tries to minimize the impact of disruptions. Our experiments show\nthat, across a variety of scenarios, NICE produces schedules resulting in 33%\nto 48% fewer disruptions than the baseline formulation. Moreover, in more\nseverely constrained scheduling scenarios in which the robust integer program\nfails to produce a schedule within 90 minutes, NICE is able to build robust\nschedules in less than 2 seconds on average.",
          "link": "http://arxiv.org/abs/2109.12171",
          "publishedOn": "2022-04-18T00:59:13.825Z",
          "wordCount": 691,
          "title": "NICE: Robust Scheduling through Reinforcement Learning-Guided Integer Programming. (arXiv:2109.12171v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.03666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tjanaka_B/0/1/0/all/0/1\">Bryon Tjanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fontaine_M/0/1/0/all/0/1\">Matthew C. Fontaine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1\">Julian Togelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolaidis_S/0/1/0/all/0/1\">Stefanos Nikolaidis</a>",
          "description": "Consider the problem of training robustly capable agents. One approach is to\ngenerate a diverse collection of agent polices. Training can then be viewed as\na quality diversity (QD) optimization problem, where we search for a collection\nof performant policies that are diverse with respect to quantified behavior.\nRecent work shows that differentiable quality diversity (DQD) algorithms\ngreatly accelerate QD optimization when exact gradients are available. However,\nagent policies typically assume that the environment is not differentiable. To\napply DQD algorithms to training agent policies, we must approximate gradients\nfor performance and behavior. We propose two variants of the current\nstate-of-the-art DQD algorithm that compute gradients via approximation methods\ncommon in reinforcement learning (RL). We evaluate our approach on four\nsimulated locomotion tasks. One variant achieves results comparable to the\ncurrent state-of-the-art in combining QD and RL, while the other performs\ncomparably in two locomotion tasks. These results provide insight into the\nlimitations of current DQD algorithms in domains where gradients must be\napproximated. Source code is available at https://github.com/icaros-usc/dqd-rl",
          "link": "http://arxiv.org/abs/2202.03666",
          "publishedOn": "2022-04-18T00:59:13.817Z",
          "wordCount": null,
          "title": "Approximating Gradients for Differentiable Quality Diversity in Reinforcement Learning. (arXiv:2202.03666v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teshima_T/0/1/0/all/0/1\">Takeshi Teshima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tojo_K/0/1/0/all/0/1\">Koichi Tojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oono_K/0/1/0/all/0/1\">Kenta Oono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Invertible neural networks (INNs) are neural network architectures with\ninvertibility by design. Thanks to their invertibility and the tractability of\nJacobian, INNs have various machine learning applications such as probabilistic\nmodeling, generative modeling, and representation learning. However, their\nattractive properties often come at the cost of restricting the layer designs,\nwhich poses a question on their representation power: can we use these models\nto approximate sufficiently diverse functions? To answer this question, we have\ndeveloped a general theoretical framework to investigate the representation\npower of INNs, building on a structure theorem of differential geometry. The\nframework simplifies the approximation problem of diffeomorphisms, which\nenables us to show the universal approximation properties of INNs. We apply the\nframework to two representative classes of INNs, namely Coupling-Flow-based\nINNs (CF-INNs) and Neural Ordinary Differential Equations (NODEs), and\nelucidate their high representation power despite the restrictions on their\narchitectures.",
          "link": "http://arxiv.org/abs/2204.07415",
          "publishedOn": "2022-04-18T00:59:13.816Z",
          "wordCount": null,
          "title": "Universal approximation property of invertible neural networks. (arXiv:2204.07415v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.00909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lutzeyer_J/0/1/0/all/0/1\">Johannes F. Lutzeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Changmin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1\">Michalis Vazirgiannis</a>",
          "description": "Message-Passing Neural Networks (MPNNs), the most prominent Graph Neural\nNetwork (GNN) framework, celebrate much success in the analysis of\ngraph-structured data. Concurrently, the sparsification of Neural Network\nmodels attracts a great amount of academic and industrial interest. In this\npaper we conduct a structured, empirical study of the effect of sparsification\non the trainable part of MPNNs known as the Update step. To this end, we design\na series of models to successively sparsify the linear transform in the Update\nstep. Specifically, we propose the ExpanderGNN model with a tuneable\nsparsification rate and the Activation-Only GNN, which has no linear transform\nin the Update step. In agreement with a growing trend in the literature the\nsparsification paradigm is changed by initialising sparse neural network\narchitectures rather than expensively sparsifying already trained\narchitectures. Our novel benchmark models enable a better understanding of the\ninfluence of the Update step on model performance and outperform existing\nsimplified benchmark models such as the Simple Graph Convolution. The\nExpanderGNNs, and in some cases the Activation-Only models, achieve performance\non par with their vanilla counterparts on several downstream tasks, while\ncontaining significantly fewer trainable parameters. Our code is publicly\navailable at: https://github.com/ChangminWu/ExpanderGNN.",
          "link": "http://arxiv.org/abs/2109.00909",
          "publishedOn": "2022-04-18T00:59:13.814Z",
          "wordCount": null,
          "title": "Sparsifying the Update Step in Graph Neural Networks. (arXiv:2109.00909v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sean Bin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chenjuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jilin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jensen_C/0/1/0/all/0/1\">Christian S. Jensen</a>",
          "description": "In step with the digitalization of transportation, we are witnessing a\ngrowing range of path-based smart-city applications, e.g., travel-time\nestimation and travel path ranking. A temporal path(TP) that includes temporal\ninformation, e.g., departure time, into the path is fundamental to enable such\napplications. In this setting, it is essential to learn generic temporal path\nrepresentations(TPRs) that consider spatial and temporal correlations\nsimultaneously and that can be used in different applications, i.e., downstream\ntasks. Existing methods fail to achieve the goal since (i) supervised methods\nrequire large amounts of task-specific labels when training and thus fail to\ngeneralize the obtained TPRs to other tasks; (ii) through unsupervised methods\ncan learn generic representations, they disregard the temporal aspect, leading\nto sub-optimal results. To contend with the limitations of existing solutions,\nwe propose a Weakly-Supervised Contrastive (WSC) learning model. We first\npropose a temporal path encoder that encodes both the spatial and temporal\ninformation of a temporal path into a TPR. To train the encoder, we introduce\nweak labels that are easy and inexpensive to obtain and are relevant to\ndifferent tasks, e.g., temporal labels indicating peak vs. off-peak hours from\ndeparture times. Based on the weak labels, we construct meaningful positive and\nnegative temporal path samples by considering both spatial and temporal\ninformation, which facilities training the encoder using contrastive learning\nby pulling closer to the positive samples' representations while pushing away\nthe negative samples' representations. To better guide contrastive learning, we\npropose a learning strategy based on Curriculum Learning such that the learning\nperforms from easy to hard training instances. Experiments studies verify the\neffectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2203.16110",
          "publishedOn": "2022-04-18T00:59:13.814Z",
          "wordCount": null,
          "title": "Weakly-supervised Temporal Path Representation Learning with Contrastive Curriculum Learning -- Extended Version. (arXiv:2203.16110v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.10629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "In data-rich domains such as vision, language, and speech, deep learning\nprevails to deliver high-performance task-specific models and can even learn\ngeneral task-agnostic representations for efficient finetuning to downstream\ntasks. However, deep learning in resource-limited domains still faces the\nfollowing challenges including (i) limited data, (ii) constrained model\ndevelopment cost, and (iii) lack of adequate pre-trained models for effective\nfinetuning. This paper introduces a new technique called model reprogramming to\nbridge this gap. Model reprogramming enables resource-efficient cross-domain\nmachine learning by repurposing and reusing a well-developed pre-trained model\nfrom a source domain to solve tasks in a target domain without model\nfinetuning, where the source and target domains can be vastly different. In\nmany applications, model reprogramming outperforms transfer learning and\ntraining from scratch. This paper elucidates the methodology of model\nreprogramming, summarizes existing use cases, provides a theoretical\nexplanation on the success of model reprogramming, and concludes with a\ndiscussion on open-ended research questions and opportunities. A list of model\nreprogramming studies is actively maintained and updated at\nhttps://github.com/IBM/model-reprogramming.",
          "link": "http://arxiv.org/abs/2202.10629",
          "publishedOn": "2022-04-18T00:59:13.811Z",
          "wordCount": 627,
          "title": "Model Reprogramming: Resource-Efficient Cross-Domain Machine Learning. (arXiv:2202.10629v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07526",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Dudeja_R/0/1/0/all/0/1\">Rishabh Dudeja</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hsu_D/0/1/0/all/0/1\">Daniel Hsu</a>",
          "description": "Tensor PCA is a stylized statistical inference problem introduced by\nMontanari and Richard to study the computational difficulty of estimating an\nunknown parameter from higher-order moment tensors. Unlike its matrix\ncounterpart, Tensor PCA exhibits a statistical-computational gap, i.e., a\nsample size regime where the problem is information-theoretically solvable but\nconjectured to be computationally hard. This paper derives computational lower\nbounds on the run-time of memory bounded algorithms for Tensor PCA using\ncommunication complexity. These lower bounds specify a trade-off among the\nnumber of passes through the data sample, the sample size, and the memory\nrequired by any algorithm that successfully solves Tensor PCA. While the lower\nbounds do not rule out polynomial-time algorithms, they do imply that many\ncommonly-used algorithms, such as gradient descent and power method, must have\na higher iteration count when the sample size is not large enough. Similar\nlower bounds are obtained for Non-Gaussian Component Analysis, a family of\nstatistical estimation problems in which low-order moment tensors carry no\ninformation about the unknown parameter. Finally, stronger lower bounds are\nobtained for an asymmetric variant of Tensor PCA and related statistical\nestimation problems. These results explain why many estimators for these\nproblems use a memory state that is significantly larger than the effective\ndimensionality of the parameter of interest.",
          "link": "http://arxiv.org/abs/2204.07526",
          "publishedOn": "2022-04-18T00:59:13.757Z",
          "wordCount": null,
          "title": "Statistical-Computational Trade-offs in Tensor PCA and Related Problems via Communication Complexity. (arXiv:2204.07526v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07576",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kieran A. Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bassett_D/0/1/0/all/0/1\">Dani S. Bassett</a>",
          "description": "The fruits of science are relationships made comprehensible, often by way of\napproximation. While deep learning is an extremely powerful way to find\nrelationships in data, its use in science has been hindered by the difficulty\nof understanding the learned relationships. The Information Bottleneck (IB) is\nan information theoretic framework for understanding a relationship between an\ninput and an output in terms of a trade-off between the fidelity and complexity\nof approximations to the relationship. Here we show that a crucial modification\n-- distributing bottlenecks across multiple components of the input -- opens\nfundamentally new avenues for interpretable deep learning in science. The\nDistributed Information Bottleneck throttles the downstream complexity of\ninteractions between the components of the input, deconstructing a relationship\ninto meaningful approximations found through deep learning without requiring\ncustom-made datasets or neural network architectures. Applied to a complex\nsystem, the approximations illuminate aspects of the system's nature by\nrestricting -- and monitoring -- the information about different components\nincorporated into the approximation. We demonstrate the Distributed IB's\nexplanatory utility in systems drawn from applied mathematics and condensed\nmatter physics. In the former, we deconstruct a Boolean circuit into\napproximations that isolate the most informative subsets of input components\nwithout requiring exhaustive search. In the latter, we localize information\nabout future plastic rearrangement in the static structure of a sheared glass,\nand find the information to be more or less diffuse depending on the system's\npreparation. By way of a principled scheme of approximations, the Distributed\nIB brings much-needed interpretability to deep learning and enables\nunprecedented analysis of information flow through a system.",
          "link": "http://arxiv.org/abs/2204.07576",
          "publishedOn": "2022-04-18T00:59:13.757Z",
          "wordCount": null,
          "title": "The Distributed Information Bottleneck reveals the explanatory structure of complex systems. (arXiv:2204.07576v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03310",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nystrom_K/0/1/0/all/0/1\">Kaj Nystr&#xf6;m</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vestberg_M/0/1/0/all/0/1\">Matias Vestberg</a>",
          "description": "The Monge-Amp\\`ere equation is a fully nonlinear partial differential\nequation (PDE) of fundamental importance in analysis, geometry and in the\napplied sciences. In this paper we solve the Dirichlet problem associated with\nthe Monge-Amp\\`ere equation using neural networks and we show that an ansatz\nusing deep input convex neural networks can be used to find the unique convex\nsolution. As part of our analysis we study the effect of singularities,\ndiscontinuities and noise in the source function, we consider nontrivial\ndomains, and we investigate how the method performs in higher dimensions. We\nalso compare this method to an alternative approach in which standard\nfeed-forward networks are used together with a loss function which penalizes\nlack of convexity.",
          "link": "http://arxiv.org/abs/2110.03310",
          "publishedOn": "2022-04-18T00:59:13.757Z",
          "wordCount": null,
          "title": "Solving the Dirichlet problem for the Monge-Amp\\`ere equation using neural networks. (arXiv:2110.03310v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.04629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_L/0/1/0/all/0/1\">Luana Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chamon_L/0/1/0/all/0/1\">Luiz F. O. Chamon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>",
          "description": "Graph neural networks (GNNs) are composed of layers consisting of graph\nconvolutions and pointwise nonlinearities. Due to their invariance and\nstability properties, GNNs are provably successful at learning representations\nfrom data supported on moderate-scale graphs. However, they are difficult to\nlearn on large-scale graphs. In this paper, we study the problem of training\nGNNs on graphs of moderate size and transferring them to large-scale graphs. We\nuse graph limits called graphons to define limit objects for graph filters and\nGNNs -- graphon filters and graphon neural networks (WNNs) -- which we\ninterpret as generative models for graph filters and GNNs. We then show that\ngraphon filters and WNNs can be approximated by graph filters and GNNs sampled\nfrom them on weighted and stochastic graphs. Because the error of these\napproximations can be upper bounded, by a triangle inequality argument we can\nfurther bound the error of transferring a graph filter or a GNN across graphs.\nOur results show that (i) the transference error decreases with the graph size,\nand (ii) that graph filters have a transferability-discriminability tradeoff\nthat in GNNs is alleviated by the scattering behavior of the nonlinearity.\nThese findings are demonstrated empirically in a movie recommendation problem\nand in a decentralized control task.",
          "link": "http://arxiv.org/abs/2112.04629",
          "publishedOn": "2022-04-18T00:59:13.757Z",
          "wordCount": null,
          "title": "Transferability Properties of Graph Neural Networks. (arXiv:2112.04629v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luther_K/0/1/0/all/0/1\">Kyle Luther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seung_H/0/1/0/all/0/1\">H. Sebastian Seung</a>",
          "description": "Recent works have derived neural networks with online correlation-based\nlearning rules to perform \\textit{kernel similarity matching}. These works\napplied existing linear similarity matching algorithms to nonlinear features\ngenerated with random Fourier methods. In this paper attempt to perform kernel\nsimilarity matching by directly learning the nonlinear features. Our algorithm\nproceeds by deriving and then minimizing an upper bound for the sum of squared\nerrors between output and input kernel similarities. The construction of our\nupper bound leads to online correlation-based learning rules which can be\nimplemented with a 1 layer recurrent neural network. In addition to generating\nhigh-dimensional linearly separable representations, we show that our upper\nbound naturally yields representations which are sparse and selective for\nspecific input patterns. We compare the approximation quality of our method to\nneural random Fourier method and variants of the popular but non-biological\n\"Nystr{\\\"o}m\" method for approximating the kernel matrix. Our method appears to\nbe comparable or better than randomly sampled Nystr{\\\"o}m methods when the\noutputs are relatively low dimensional (although still potentially higher\ndimensional than the inputs) but less faithful when the outputs are very high\ndimensional.",
          "link": "http://arxiv.org/abs/2204.07475",
          "publishedOn": "2022-04-18T00:59:13.730Z",
          "wordCount": null,
          "title": "Kernel similarity matching with Hebbian neural networks. (arXiv:2204.07475v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07358",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Musellim_S/0/1/0/all/0/1\">Serkan Musellim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_D/0/1/0/all/0/1\">Dong-Kyun Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jeong_J/0/1/0/all/0/1\">Ji-Hoon Jeong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Brain-computer interface (BCI) is challenging to use in practice due to the\ninter/intra-subject variability of electroencephalography (EEG). The BCI\nsystem, in general, necessitates a calibration technique to obtain\nsubject/session-specific data in order to tune the model each time the system\nis utilized. This issue is acknowledged as a key hindrance to BCI, and a new\nstrategy based on domain generalization has recently evolved to address it. In\nlight of this, we've concentrated on developing an EEG classification framework\nthat can be applied directly to data from unknown domains (i.e. subjects),\nusing only data acquired from separate subjects previously. For this purpose,\nin this paper, we proposed a framework that employs the open-set recognition\ntechnique as an auxiliary task to learn subject-specific style features from\nthe source dataset while helping the shared feature extractor with mapping the\nfeatures of the unseen target dataset as a new unseen domain. Our aim is to\nimpose cross-instance style in-variance in the same domain and reduce the open\nspace risk on the potential unseen subject in order to improve the\ngeneralization ability of the shared feature extractor. Our experiments showed\nthat using the domain information as an auxiliary network increases the\ngeneralization performance.",
          "link": "http://arxiv.org/abs/2204.07358",
          "publishedOn": "2022-04-18T00:59:13.676Z",
          "wordCount": 648,
          "title": "Prototype-based Domain Generalization Framework for Subject-Independent Brain-Computer Interfaces. (arXiv:2204.07358v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Babaiee_Z/0/1/0/all/0/1\">Zahra Babaiee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liebenwein_L/0/1/0/all/0/1\">Lucas Liebenwein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasani_R/0/1/0/all/0/1\">Ramin Hasani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosu_R/0/1/0/all/0/1\">Radu Grosu</a>",
          "description": "In this paper, we present a novel sensitivity-based filter pruning algorithm\n(SbF-Pruner) to learn the importance scores of filters of each layer\nend-to-end. Our method learns the scores from the filter weights, enabling it\nto account for the correlations between the filters of each layer. Moreover, by\ntraining the pruning scores of all layers simultaneously our method can account\nfor layer interdependencies, which is essential to find a performant sparse\nsub-network. Our proposed method can train and generate a pruned network from\nscratch in a straightforward, one-stage training process without requiring a\npretrained network. Ultimately, we do not need layer-specific hyperparameters\nand pre-defined layer budgets, since SbF-Pruner can implicitly determine the\nappropriate number of channels in each layer. Our experimental results on\ndifferent network architectures suggest that SbF-Pruner outperforms advanced\npruning methods. Notably, on CIFAR-10, without requiring a pretrained baseline\nnetwork, we obtain 1.02% and 1.19% accuracy gain on ResNet56 and ResNet110,\ncompared to the baseline reported for state-of-the-art pruning algorithms. This\nis while SbF-Pruner reduces parameter-count by 52.3% (for ResNet56) and 54%\n(for ResNet101), which is better than the state-of-the-art pruning algorithms\nwith a high margin of 9.5% and 6.6%.",
          "link": "http://arxiv.org/abs/2204.07412",
          "publishedOn": "2022-04-18T00:59:13.669Z",
          "wordCount": 631,
          "title": "End-to-End Sensitivity-Based Filter Pruning. (arXiv:2204.07412v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zavrak_S/0/1/0/all/0/1\">Sultan Zavrak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yilmaz_S/0/1/0/all/0/1\">Seyhmus Yilmaz</a>",
          "description": "Email is one of the most widely used ways to communicate, with millions of\npeople and businesses relying on it to communicate and share knowledge and\ninformation on a daily basis. Nevertheless, the rise in email users has\noccurred a dramatic increase in spam emails in recent years. Processing and\nmanaging emails properly for individuals and companies are getting increasingly\ndifficult. This article proposes a novel technique for email spam detection\nthat is based on a combination of convolutional neural networks, gated\nrecurrent units, and attention mechanisms. During system training, the network\nis selectively focused on necessary parts of the email text. The usage of\nconvolution layers to extract more meaningful, abstract, and generalizable\nfeatures by hierarchical representation is the major contribution of this\nstudy. Additionally, this contribution incorporates cross-dataset evaluation,\nwhich enables the generation of more independent performance results from the\nmodel's training dataset. According to cross-dataset evaluation results, the\nproposed technique advances the results of the present attention-based\ntechniques by utilizing temporal convolutions, which give us more flexible\nreceptive field sizes are utilized. The suggested technique's findings are\ncompared to those of state-of-the-art models and show that our approach\noutperforms them.",
          "link": "http://arxiv.org/abs/2204.07390",
          "publishedOn": "2022-04-18T00:59:13.661Z",
          "wordCount": 639,
          "title": "Email Spam Detection Using Hierarchical Attention Hybrid Deep Learning Method. (arXiv:2204.07390v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_I/0/1/0/all/0/1\">Itsugun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dongyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_R/0/1/0/all/0/1\">Ryota Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saito_H/0/1/0/all/0/1\">Hiroaki Saito</a>",
          "description": "Current works in the generation of personalized dialogue primarily contribute\nto the agent avoiding contradictory persona and driving the response more\ninformative. However, we found that the generated responses from these models\nare mostly self-centered with little care for the other party since they ignore\nthe user's persona. Moreover, we consider high-quality transmission is\nessentially built based on apprehending the persona of the other party.\nMotivated by this, we propose a novel personalized dialogue generator by\ndetecting implicit user persona. Because it's difficult to collect a large\nnumber of personas for each user, we attempt to model the user's potential\npersona and its representation from the dialogue absence of any external\ninformation. Perception variable and fader variable are conceived utilizing\nConditional Variational Inference. The two latent variables simulate the\nprocess of people being aware of the other party's persona and producing the\ncorresponding expression in conversation. Finally, Posterior-discriminated\nRegularization is presented to enhance the training procedure. Empirical\nstudies demonstrate that compared with the state-of-the-art methods, ours is\nmore concerned with the user's persona and outperforms in evaluations.",
          "link": "http://arxiv.org/abs/2204.07372",
          "publishedOn": "2022-04-18T00:59:13.653Z",
          "wordCount": 631,
          "title": "Towards Building a Personalized Dialogue Generator via Implicit User Persona Detection. (arXiv:2204.07372v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07353",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Nishida_T/0/1/0/all/0/1\">Tomoya Nishida</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dohi_K/0/1/0/all/0/1\">Kota Dohi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Endo_T/0/1/0/all/0/1\">Takashi Endo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yamamoto_M/0/1/0/all/0/1\">Masaaki Yamamoto</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kawaguchi_Y/0/1/0/all/0/1\">Yohei Kawaguchi</a>",
          "description": "We have developed an unsupervised anomalous sound detection method for\nmachine condition monitoring that utilizes an auxiliary task -- detecting when\nthe target machine is active. First, we train a model that detects machine\nactivity by using normal data with machine activity labels and then use the\nactivity-detection error as the anomaly score for a given sound clip if we have\naccess to the ground-truth activity labels in the inference phase. If these\nlabels are not available, the anomaly score is calculated through outlier\ndetection on the embedding vectors obtained by the activity-detection model.\nSolving this auxiliary task enables the model to learn the difference between\nthe target machine sounds and similar background noise, which makes it possible\nto identify small deviations in the target sounds. Experimental results showed\nthat the proposed method improves the anomaly-detection performance of the\nconventional method complementarily by means of an ensemble.",
          "link": "http://arxiv.org/abs/2204.07353",
          "publishedOn": "2022-04-18T00:59:13.632Z",
          "wordCount": 605,
          "title": "Anomalous Sound Detection Based on Machine Activity Detection. (arXiv:2204.07353v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kewei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Wen Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zengfu Wang</a>",
          "description": "Crowd counting based on density maps is generally regarded as a regression\ntask.Deep learning is used to learn the mapping between image content and crowd\ndensity distribution. Although great success has been achieved, some\npedestrians far away from the camera are difficult to be detected. And the\nnumber of hard examples is often larger. Existing methods with simple Euclidean\ndistance algorithm indiscriminately optimize the hard and easy examples so that\nthe densities of hard examples are usually incorrectly predicted to be lower or\neven zero, which results in large counting errors. To address this problem, we\nare the first to propose the Hard Example Focusing(HEF) algorithm for the\nregression task of crowd counting. The HEF algorithm makes our model rapidly\nfocus on hard examples by attenuating the contribution of easy examples.Then\nhigher importance will be given to the hard examples with wrong estimations.\nMoreover, the scale variations in crowd scenes are large, and the scale\nannotations are labor-intensive and expensive. By proposing a multi-Scale\nSemantic Refining (SSR) strategy, lower layers of our model can break through\nthe limitation of deep learning to capture semantic features of different\nscales to sufficiently deal with the scale variation. We perform extensive\nexperiments on six benchmark datasets to verify the proposed method. Results\nindicate the superiority of our proposed method over the state-of-the-art\nmethods. Moreover, our designed model is smaller and faster.",
          "link": "http://arxiv.org/abs/2204.07406",
          "publishedOn": "2022-04-18T00:59:13.610Z",
          "wordCount": 704,
          "title": "SSR-HEF: Crowd Counting with Multi-Scale Semantic Refining and Hard Example Focusing. (arXiv:2204.07406v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07380",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zengfu Wang</a>",
          "description": "Deep learning occupies an undisputed dominance in crowd counting. In this\npaper, we propose a novel convolutional neural network (CNN) architecture\ncalled SegCrowdNet. Despite the complex background in crowd scenes, the\nproposeSegCrowdNet still adaptively highlights the human head region and\nsuppresses the non-head region by segmentation. With the guidance of an\nattention mechanism, the proposed SegCrowdNet pays more attention to the human\nhead region and automatically encodes the highly refined density map. The crowd\ncount can be obtained by integrating the density map. To adapt the variation of\ncrowd counts, SegCrowdNet intelligently classifies the crowd count of each\nimage into several groups. In addition, the multi-scale features are learned\nand extracted in the proposed SegCrowdNet to overcome the scale variations of\nthe crowd. To verify the effectiveness of our proposed method, extensive\nexperiments are conducted on four challenging datasets. The results demonstrate\nthat our proposed SegCrowdNet achieves excellent performance compared with the\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2204.07380",
          "publishedOn": "2022-04-18T00:59:13.602Z",
          "wordCount": 620,
          "title": "Crowd counting with segmentation attention convolutional neural network. (arXiv:2204.07380v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07293",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Deng_W/0/1/0/all/0/1\">Wenying Deng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Coker_B/0/1/0/all/0/1\">Beau Coker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jeremiah Zhe Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Coull_B/0/1/0/all/0/1\">Brent A. Coull</a>",
          "description": "We develop a simple and unified framework for nonlinear variable selection\nthat incorporates model uncertainty and is compatible with a wide range of\nmachine learning models (e.g., tree ensembles, kernel methods and neural\nnetwork). In particular, for a learned nonlinear model $f(\\mathbf{x})$, we\nconsider quantifying the importance of an input variable $\\mathbf{x}^j$ using\nthe integrated gradient measure $\\psi_j = \\Vert \\frac{\\partial}{\\partial\n\\mathbf{x}^j} f(\\mathbf{x})\\Vert^2_2$. We then (1) provide a principled\napproach for quantifying variable selection uncertainty by deriving its\nposterior distribution, and (2) show that the approach is generalizable even to\nnon-differentiable models such as tree ensembles. Rigorous Bayesian\nnonparametric theorems are derived to guarantee the posterior consistency and\nasymptotic uncertainty of the proposed approach. Extensive simulation confirms\nthat the proposed algorithm outperforms existing classic and recent variable\nselection methods.",
          "link": "http://arxiv.org/abs/2204.07293",
          "publishedOn": "2022-04-18T00:59:13.594Z",
          "wordCount": 580,
          "title": "Towards a Unified Framework for Uncertainty-aware Nonlinear Variable Selection with Theoretical Guarantees. (arXiv:2204.07293v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07360",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Meng_H/0/1/0/all/0/1\">Han Meng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_Y/0/1/0/all/0/1\">Yuexing Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1\">Wenbo Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_P/0/1/0/all/0/1\">Peng Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yonghui Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xiang_W/0/1/0/all/0/1\">Wei Xiang</a>",
          "description": "This paper proposes a knowledge-and-data-driven graph neural network-based\ncollaboration learning model for reliable aircraft recognition in a\nheterogeneous radar network. The aircraft recognizability analysis shows that:\n(1) the semantic feature of an aircraft is motion patterns driven by the\nkinetic characteristics, and (2) the grammatical features contained in the\nradar cross-section (RCS) signals present spatial-temporal-frequency (STF)\ndiversity decided by both the electromagnetic radiation shape and motion\npattern of the aircraft. Then a STF graph attention convolutional network\n(STFGACN) is developed to distill semantic features from the RCS signals\nreceived by the heterogeneous radar network. Extensive experiment results\nverify that the STFGACN outperforms the baseline methods in terms of detection\naccuracy, and ablation experiments are carried out to further show that the\nexpansion of the information dimension can gain considerable benefits to\nperform robustly in the low signal-to-noise ratio region.",
          "link": "http://arxiv.org/abs/2204.07360",
          "publishedOn": "2022-04-18T00:59:13.586Z",
          "wordCount": 599,
          "title": "Spatio-Temporal-Frequency Graph Attention Convolutional Network for Aircraft Recognition Based on Heterogeneous Radar Network. (arXiv:2204.07360v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07312",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Balcan_M/0/1/0/all/0/1\">Maria-Florina Balcan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Prasad_S/0/1/0/all/0/1\">Siddharth Prasad</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sandholm_T/0/1/0/all/0/1\">Tuomas Sandholm</a>, <a href=\"http://arxiv.org/find/math/1/au:+Vitercik_E/0/1/0/all/0/1\">Ellen Vitercik</a>",
          "description": "The incorporation of cutting planes within the branch-and-bound algorithm,\nknown as branch-and-cut, forms the backbone of modern integer programming\nsolvers. These solvers are the foremost method for solving discrete\noptimization problems and thus have a vast array of applications in machine\nlearning, operations research, and many other fields. Choosing cutting planes\neffectively is a major research topic in the theory and practice of integer\nprogramming. We conduct a novel structural analysis of branch-and-cut that pins\ndown how every step of the algorithm is affected by changes in the parameters\ndefining the cutting planes added to the input integer program. Our main\napplication of this analysis is to derive sample complexity guarantees for\nusing machine learning to determine which cutting planes to apply during\nbranch-and-cut. These guarantees apply to infinite families of cutting planes,\nsuch as the family of Gomory mixed integer cuts, which are responsible for the\nmain breakthrough speedups of integer programming solvers. We exploit geometric\nand combinatorial structure of branch-and-cut in our analysis, which provides a\nkey missing piece for the recent generalization theory of branch-and-cut.",
          "link": "http://arxiv.org/abs/2204.07312",
          "publishedOn": "2022-04-18T00:59:13.578Z",
          "wordCount": 630,
          "title": "Structural Analysis of Branch-and-Cut and the Learnability of Gomory Mixed Integer Cuts. (arXiv:2204.07312v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_L/0/1/0/all/0/1\">Long Sha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Engelbrecht_J/0/1/0/all/0/1\">Jan Engelbrecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_P/0/1/0/all/0/1\">Pengyu Hong</a>",
          "description": "Knowledge graph (KG) representation learning aims to encode entities and\nrelations into dense continuous vector spaces such that knowledge contained in\na dataset could be consistently represented. Dense embeddings trained from KG\ndatasets benefit a variety of downstream tasks such as KG completion and link\nprediction. However, existing KG embedding methods fell short to provide a\nsystematic solution for the global consistency of knowledge representation. We\ndeveloped a mathematical language for KG based on an observation of their\ninherent algebraic structure, which we termed as Knowledgebra. By analyzing\nfive distinct algebraic properties, we proved that the semigroup is the most\nreasonable algebraic structure for the relation embedding of a general\nknowledge graph. We implemented an instantiation model, SemE, using simple\nmatrix semigroups, which exhibits state-of-the-art performance on standard\ndatasets. Moreover, we proposed a regularization-based method to integrate\nchain-like logic rules derived from human knowledge into embedding training,\nwhich further demonstrates the power of the developed language. As far as we\nknow, by applying abstract algebra in statistical learning, this work develops\nthe first formal language for general knowledge graphs, and also sheds light on\nthe problem of neural-symbolic integration from an algebraic perspective.",
          "link": "http://arxiv.org/abs/2204.07328",
          "publishedOn": "2022-04-18T00:59:13.546Z",
          "wordCount": 635,
          "title": "Knowledgebra: An Algebraic Learning Framework for Knowledge Graph. (arXiv:2204.07328v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chan-Jan Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Transformer-based models are widely used in natural language understanding\n(NLU) tasks, and multimodal transformers have been effective in visual-language\ntasks. This study explores distilling visual information from pretrained\nmultimodal transformers to pretrained language encoders. Our framework is\ninspired by cross-modal encoders' success in visual-language tasks while we\nalter the learning objective to cater to the language-heavy characteristics of\nNLU. After training with a small number of extra adapting steps and finetuned,\nthe proposed XDBERT (cross-modal distilled BERT) outperforms pretrained-BERT in\ngeneral language understanding evaluation (GLUE), situations with adversarial\ngenerations (SWAG) benchmarks, and readability benchmarks. We analyze the\nperformance of XDBERT on GLUE to show that the improvement is likely visually\ngrounded.",
          "link": "http://arxiv.org/abs/2204.07316",
          "publishedOn": "2022-04-18T00:59:13.538Z",
          "wordCount": 564,
          "title": "XDBERT: Distilling Visual Information to BERT from Cross-Modal Systems to Improve Language Understanding. (arXiv:2204.07316v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kuangen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiahong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinxing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_Y/0/1/0/all/0/1\">Yuquan Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_C/0/1/0/all/0/1\">Clarence W. de Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Chenglong Fu</a>",
          "description": "Recognizing human locomotion intent and activities is important for\ncontrolling the wearable robots while walking in complex environments. However,\nhuman-robot interface signals are usually user-dependent, which causes that the\nclassifier trained on source subjects performs poorly on new subjects. To\naddress this issue, this paper designs the ensemble diverse hypotheses and\nknowledge distillation (EDHKD) method to realize unsupervised cross-subject\nadaptation. EDH mitigates the divergence between labeled data of source\nsubjects and unlabeled data of target subjects to accurately classify the\nlocomotion modes of target subjects without labeling data. Compared to previous\ndomain adaptation methods based on the single learner, which may only learn a\nsubset of features from input signals, EDH can learn diverse features by\nincorporating multiple diverse feature generators and thus increases the\naccuracy and decreases the variance of classifying target data, but it\nsacrifices the efficiency. To solve this problem, EDHKD (student) distills the\nknowledge from the EDH (teacher) to a single network to remain efficient and\naccurate. The performance of the EDHKD is theoretically proved and\nexperimentally validated on a 2D moon dataset and two public human locomotion\ndatasets. Experimental results show that the EDHKD outperforms all other\nmethods. The EDHKD can classify target data with 96.9%, 94.4%, and 97.4%\naverage accuracy on the above three datasets with a short computing time (1\nms). Compared to a benchmark (BM) method, the EDHKD increases 1.3% and 7.1%\naverage accuracy for classifying the locomotion modes of target subjects. The\nEDHKD also stabilizes the learning curves. Therefore, the EDHKD is significant\nfor increasing the generalization ability and efficiency of the human intent\nprediction and human activity recognition system, which will improve\nhuman-robot interactions.",
          "link": "http://arxiv.org/abs/2204.07308",
          "publishedOn": "2022-04-18T00:59:13.530Z",
          "wordCount": 741,
          "title": "Ensemble diverse hypotheses and knowledge distillation for unsupervised cross-subject adaptation. (arXiv:2204.07308v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahir/0/1/0/all/0/1\">Sahir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilhan_E/0/1/0/all/0/1\">Erc&#xfc;ment &#x130;lhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Srijita Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1\">Matthew E. Taylor</a>",
          "description": "Reinforcement learning (RL) has shown great success in solving many\nchallenging tasks via use of deep neural networks. Although using deep learning\nfor RL brings immense representational power, it also causes a well-known\nsample-inefficiency problem. This means that the algorithms are data-hungry and\nrequire millions of training samples to converge to an adequate policy. One way\nto combat this issue is to use action advising in a teacher-student framework,\nwhere a knowledgeable teacher provides action advice to help the student. This\nwork considers how to better leverage uncertainties about when a student should\nask for advice and if the student can model the teacher to ask for less advice.\nThe student could decide to ask for advice when it is uncertain or when both it\nand its model of the teacher are uncertain. In addition to this investigation,\nthis paper introduces a new method to compute uncertainty for a deep RL agent\nusing a secondary neural network. Our empirical results show that using dual\nuncertainties to drive advice collection and reuse may improve learning\nperformance across several Atari games.",
          "link": "http://arxiv.org/abs/2204.07254",
          "publishedOn": "2022-04-18T00:59:13.521Z",
          "wordCount": 636,
          "title": "Methodical Advice Collection and Reuse in Deep Reinforcement Learning. (arXiv:2204.07254v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07352",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balelli_I/0/1/0/all/0/1\">Irene Balelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_S/0/1/0/all/0/1\">Santiago Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenzi_M/0/1/0/all/0/1\">Marco Lorenzi</a>",
          "description": "We propose a novel federated learning paradigm to model data variability\namong heterogeneous clients in multi-centric studies. Our method is expressed\nthrough a hierarchical Bayesian latent variable model, where client-specific\nparameters are assumed to be realization from a global distribution at the\nmaster level, which is in turn estimated to account for data bias and\nvariability across clients. We show that our framework can be effectively\noptimized through expectation maximization (EM) over latent master's\ndistribution and clients' parameters. We also introduce formal differential\nprivacy (DP) guarantees compatibly with our EM optimization scheme. We tested\nour method on the analysis of multi-modal medical imaging data and clinical\nscores from distributed clinical datasets of patients affected by Alzheimer's\ndisease. We demonstrate that our method is robust when data is distributed\neither in iid and non-iid manners, even when local parameters perturbation is\nincluded to provide DP guarantees. Moreover, the variability of data, views and\ncenters can be quantified in an interpretable manner, while guaranteeing\nhigh-quality data reconstruction as compared to state-of-the-art autoencoding\nmodels and federated learning schemes. The code is available at\nhttps://gitlab.inria.fr/epione/federated-multi-views-ppca.",
          "link": "http://arxiv.org/abs/2204.07352",
          "publishedOn": "2022-04-18T00:59:13.498Z",
          "wordCount": 664,
          "title": "A Differentially Private Probabilistic Framework for Modeling the Variability Across Federated Datasets of Heterogeneous Multi-View Observations. (arXiv:2204.07352v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07347",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Wen Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zengfu Wang</a>",
          "description": "Crowd counting is a challenging problem due to the scene complexity and scale\nvariation. Although deep learning has achieved great improvement in crowd\ncounting, scene complexity affects the judgement of these methods and they\nusually regard some objects as people mistakenly; causing potentially enormous\nerrors in the crowd counting result. To address the problem, we propose a novel\nend-to-end model called Crowd Attention Convolutional Neural Network (CAT-CNN).\nOur CAT-CNN can adaptively assess the importance of a human head at each pixel\nlocation by automatically encoding a confidence map. With the guidance of the\nconfidence map, the position of human head in estimated density map gets more\nattention to encode the final density map, which can avoid enormous\nmisjudgements effectively. The crowd count can be obtained by integrating the\nfinal density map. To encode a highly refined density map, the total crowd\ncount of each image is classified in a designed classification task and we\nfirst explicitly map the prior of the population-level category to feature\nmaps. To verify the efficiency of our proposed method, extensive experiments\nare conducted on three highly challenging datasets. Results establish the\nsuperiority of our method over many state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2204.07347",
          "publishedOn": "2022-04-18T00:59:13.489Z",
          "wordCount": 664,
          "title": "Crowd counting with crowd attention convolutional neural network. (arXiv:2204.07347v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chuang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_Y/0/1/0/all/0/1\">Yibing Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wenbin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Graph neural networks have emerged as a leading architecture for many\ngraph-level tasks such as graph classification and graph generation with a\nnotable improvement. Among these tasks, graph pooling is an essential component\nof graph neural network architectures for obtaining a holistic graph-level\nrepresentation of the entire graph. Although a great variety of methods have\nbeen proposed in this promising and fast-developing research field, to the best\nof our knowledge, little effort has been made to systematically summarize these\nmethods. To set the stage for the development of future works, in this paper,\nwe attempt to fill this gap by providing a broad review of recent methods on\ngraph pooling. Specifically, 1) we first propose a taxonomy of existing graph\npooling methods and provide a mathematical summary for each category; 2) next,\nwe provide an overview of the libraries related to graph pooling, including the\ncommonly used datasets, model architectures for downstream tasks, and\nopen-source implementations; 3) then, we further outline in brief the\napplications that incorporate the idea of graph pooling in a number of domains;\n4) and finally, we discuss some critical challenges faced by the current\nstudies and share our insights on potential directions for improving graph\npooling in the future.",
          "link": "http://arxiv.org/abs/2204.07321",
          "publishedOn": "2022-04-18T00:59:13.480Z",
          "wordCount": 654,
          "title": "Graph Pooling for Graph Neural Networks: Progress, Challenges, and Opportunities. (arXiv:2204.07321v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lechner_M/0/1/0/all/0/1\">Mathias Lechner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Alexander Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henzinger_T/0/1/0/all/0/1\">Thomas A. Henzinger</a>",
          "description": "Adversarial training (i.e., training on adversarially perturbed input data)\nis a well-studied method for making neural networks robust to potential\nadversarial attacks during inference. However, the improved robustness does not\ncome for free but rather is accompanied by a decrease in overall model accuracy\nand performance. Recent work has shown that, in practical robot learning\napplications, the effects of adversarial training do not pose a fair trade-off\nbut inflict a net loss when measured in holistic robot performance. This work\nrevisits the robustness-accuracy trade-off in robot learning by systematically\nanalyzing if recent advances in robust training methods and theory in\nconjunction with adversarial robot learning can make adversarial training\nsuitable for real-world robot applications. We evaluate a wide variety of robot\nlearning tasks ranging from autonomous driving in a high-fidelity environment\namenable to sim-to-real deployment, to mobile robot gesture recognition. Our\nresults demonstrate that, while these techniques make incremental improvements\non the trade-off on a relative scale, the negative side-effects caused by\nadversarial training still outweigh the improvements by an order of magnitude.\nWe conclude that more substantial advances in robust learning methods are\nnecessary before they can benefit robot learning tasks in practice.",
          "link": "http://arxiv.org/abs/2204.07373",
          "publishedOn": "2022-04-18T00:59:13.456Z",
          "wordCount": 636,
          "title": "Revisiting the Adversarial Robustness-Accuracy Tradeoff in Robot Learning. (arXiv:2204.07373v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shell Xu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Da Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stuhmer_J/0/1/0/all/0/1\">Jan St&#xfc;hmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1\">Timothy M. Hospedales</a>",
          "description": "Few-shot learning (FSL) is an important and topical problem in computer\nvision that has motivated extensive research into numerous methods spanning\nfrom sophisticated meta-learning methods to simple transfer learning baselines.\nWe seek to push the limits of a simple-but-effective pipeline for more\nrealistic and practical settings of few-shot image classification. To this end,\nwe explore few-shot learning from the perspective of neural network\narchitecture, as well as a three stage pipeline of network updates under\ndifferent data supplies, where unsupervised external data is considered for\npre-training, base categories are used to simulate few-shot tasks for\nmeta-training, and the scarcely labelled data of an novel task is taken for\nfine-tuning. We investigate questions such as: (1) How pre-training on external\ndata benefits FSL? (2) How state-of-the-art transformer architectures can be\nexploited? and (3) How fine-tuning mitigates domain shift? Ultimately, we show\nthat a simple transformer-based pipeline yields surprisingly good performance\non standard benchmarks such as Mini-ImageNet, CIFAR-FS, CDFSL and Meta-Dataset.\nOur code and demo are available at https://hushell.github.io/pmf.",
          "link": "http://arxiv.org/abs/2204.07305",
          "publishedOn": "2022-04-18T00:59:13.446Z",
          "wordCount": 635,
          "title": "Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference. (arXiv:2204.07305v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1\">Chirag Nagpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potosnak_W/0/1/0/all/0/1\">Willa Potosnak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1\">Artur Dubrawski</a>",
          "description": "Applications of machine learning in healthcare often require working with\ntime-to-event prediction tasks including prognostication of an adverse event,\nre-hospitalization or death. Such outcomes are typically subject to censoring\ndue to loss of follow up. Standard machine learning methods cannot be applied\nin a straightforward manner to datasets with censored outcomes. In this paper,\nwe present auton-survival, an open-source repository of tools to streamline\nworking with censored time-to-event or survival data. auton-survival includes\ntools for survival regression, adjustment in the presence of domain shift,\ncounterfactual estimation, phenotyping for risk stratification, evaluation, as\nwell as estimation of treatment effects. Through real world case studies\nemploying a large subset of the SEER oncology incidence data, we demonstrate\nthe ability of auton-survival to rapidly support data scientists in answering\ncomplex health and epidemiological questions.",
          "link": "http://arxiv.org/abs/2204.07276",
          "publishedOn": "2022-04-18T00:59:13.421Z",
          "wordCount": 585,
          "title": "auton-survival: an Open-Source Package for Regression, Counterfactual Estimation, Evaluation and Phenotyping with Censored Time-to-Event Data. (arXiv:2204.07276v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaplan_A/0/1/0/all/0/1\">Alan D. Kaplan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greene_J/0/1/0/all/0/1\">John D. Greene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_V/0/1/0/all/0/1\">Vincent X. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_P/0/1/0/all/0/1\">Priyadip Ray</a>",
          "description": "We develop an unsupervised probabilistic model for heterogeneous Electronic\nHealth Record (EHR) data. Utilizing a mixture model formulation, our approach\ndirectly models sequences of arbitrary length, such as medications and\nlaboratory results. This allows for subgrouping and incorporation of the\ndynamics underlying heterogeneous data types. The model consists of a layered\nset of latent variables that encode underlying structure in the data. These\nvariables represent subject subgroups at the top layer, and unobserved states\nfor sequences in the second layer. We train this model on episodic data from\nsubjects receiving medical care in the Kaiser Permanente Northern California\nintegrated healthcare delivery system. The resulting properties of the trained\nmodel generate novel insight from these complex and multifaceted data. In\naddition, we show how the model can be used to analyze sequences that\ncontribute to assessment of mortality likelihood.",
          "link": "http://arxiv.org/abs/2204.07292",
          "publishedOn": "2022-04-18T00:59:08.559Z",
          "wordCount": 579,
          "title": "Unsupervised Probabilistic Models for Sequential Electronic Health Records. (arXiv:2204.07292v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Melnychuk_V/0/1/0/all/0/1\">Valentyn Melnychuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frauen_D/0/1/0/all/0/1\">Dennis Frauen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>",
          "description": "Estimating counterfactual outcomes over time from observational data is\nrelevant for many applications (e.g., personalized medicine). Yet,\nstate-of-the-art methods build upon simple long short-term memory (LSTM)\nnetworks, thus rendering inferences for complex, long-range dependencies\nchallenging. In this paper, we develop a novel Causal Transformer for\nestimating counterfactual outcomes over time. Our model is specifically\ndesigned to capture complex, long-range dependencies among time-varying\nconfounders. For this, we combine three transformer subnetworks with separate\ninputs for time-varying covariates, previous treatments, and previous outcomes\ninto a joint network with in-between cross-attentions. We further develop a\ncustom, end-to-end training procedure for our Causal Transformer. Specifically,\nwe propose a novel counterfactual domain confusion loss to address confounding\nbias: it aims to learn adversarial balanced representations, so that they are\npredictive of the next outcome but non-predictive of the current treatment\nassignment. We evaluate our Causal Transformer based on synthetic and\nreal-world datasets, where it achieves superior performance over current\nbaselines. To the best of our knowledge, this is the first work proposing\ntransformer-based architecture for estimating counterfactual outcomes from\nlongitudinal data.",
          "link": "http://arxiv.org/abs/2204.07258",
          "publishedOn": "2022-04-18T00:59:08.543Z",
          "wordCount": 608,
          "title": "Causal Transformer for Estimating Counterfactual Outcomes. (arXiv:2204.07258v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07288",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ang_P/0/1/0/all/0/1\">Phyllis Ang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1\">Bhuwan Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wills_L/0/1/0/all/0/1\">Lisa Wu Wills</a>",
          "description": "With many real-world applications of Natural Language Processing (NLP)\ncomprising of long texts, there has been a rise in NLP benchmarks that measure\nthe accuracy of models that can handle longer input sequences. However, these\nbenchmarks do not consider the trade-offs between accuracy, speed, and power\nconsumption as input sizes or model sizes are varied. In this work, we perform\na systematic study of this accuracy vs. efficiency trade-off on two widely used\nlong-sequence models - Longformer-Encoder-Decoder (LED) and Big Bird - during\nfine-tuning and inference on four datasets from the SCROLLS benchmark. To study\nhow this trade-off differs across hyperparameter settings, we compare the\nmodels across four sequence lengths (1024, 2048, 3072, 4096) and two model\nsizes (base and large) under a fixed resource budget. We find that LED\nconsistently achieves better accuracy at lower energy costs than Big Bird. For\nsummarization, we find that increasing model size is more energy efficient than\nincreasing sequence length for higher accuracy. However, this comes at the cost\nof a large drop in inference speed. For question answering, we find that\nsmaller models are both more efficient and more accurate due to the larger\ntraining batch sizes possible under a fixed resource budget.",
          "link": "http://arxiv.org/abs/2204.07288",
          "publishedOn": "2022-04-18T00:59:08.524Z",
          "wordCount": 655,
          "title": "Characterizing the Efficiency vs. Accuracy Trade-off for Long-Context NLP Models. (arXiv:2204.07288v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bemporad_A/0/1/0/all/0/1\">Alberto Bemporad</a>",
          "description": "This paper proposes an active learning algorithm for solving regression and\nclassification problems based on inverse-distance weighting functions for\nselecting the feature vectors to query. The algorithm has the following\nfeatures: (i) supports both pool-based and population-based sampling; (ii) is\nindependent of the type of predictor used; (iii) can handle known and unknown\nconstraints on the queryable feature vectors; and (iv) can run either\nsequentially, or in batch mode, depending on how often the predictor is\nretrained. The method's potential is shown in numerical tests on illustrative\nsynthetic problems and real-world regression and classification datasets from\nthe UCI repository. A Python implementation of the algorithm that we call IDEAL\n(Inverse-Distance based Exploration for Active Learning), is available at\n\\url{this http URL}.",
          "link": "http://arxiv.org/abs/2204.07177",
          "publishedOn": "2022-04-18T00:59:08.513Z",
          "wordCount": 560,
          "title": "Active Learning for Regression and Classification by Inverse Distance Weighting. (arXiv:2204.07177v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07207",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wundervald_B/0/1/0/all/0/1\">Bruna Wundervald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Parnell_A/0/1/0/all/0/1\">Andrew Parnell</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Domijan_K/0/1/0/all/0/1\">Katarina Domijan</a>",
          "description": "We propose a simple yet powerful extension of Bayesian Additive Regression\nTrees which we name Hierarchical Embedded BART (HE-BART). The model allows for\nrandom effects to be included at the terminal node level of a set of regression\ntrees, making HE-BART a non-parametric alternative to mixed effects models\nwhich avoids the need for the user to specify the structure of the random\neffects in the model, whilst maintaining the prediction and uncertainty\ncalibration properties of standard BART. Using simulated and real-world\nexamples, we demonstrate that this new extension yields superior predictions\nfor many of the standard mixed effects models' example data sets, and yet still\nprovides consistent estimates of the random effect variances. In a future\nversion of this paper, we outline its use in larger, more advanced data sets\nand structures.",
          "link": "http://arxiv.org/abs/2204.07207",
          "publishedOn": "2022-04-18T00:59:08.505Z",
          "wordCount": 560,
          "title": "Hierarchical Embedded Bayesian Additive Regression Trees. (arXiv:2204.07207v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07162",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Delvigne_V/0/1/0/all/0/1\">Victor Delvigne</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wannous_H/0/1/0/all/0/1\">Hazem Wannous</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Vandeborre_J/0/1/0/all/0/1\">Jean-Philippe Vandeborre</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ris_L/0/1/0/all/0/1\">Laurence Ris</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dutoit_T/0/1/0/all/0/1\">Thierry Dutoit</a>",
          "description": "For many years now, understanding the brain mechanism has been a great\nresearch subject in many different fields. Brain signal processing and\nespecially electroencephalogram (EEG) has recently known a growing interest\nboth in academia and industry. One of the main examples is the increasing\nnumber of Brain-Computer Interfaces (BCI) aiming to link brains and computers.\nIn this paper, we present a novel framework allowing us to retrieve the\nattention state, i.e degree of attention given to a specific task, from EEG\nsignals. While previous methods often consider the spatial relationship in EEG\nthrough electrodes and process them in recurrent or convolutional based\narchitecture, we propose here to also exploit the spatial and temporal\ninformation with a transformer-based network that has already shown its\nsupremacy in many machine-learning (ML) related studies, e.g. machine\ntranslation. In addition to this novel architecture, an extensive study on the\nfeature extraction methods, frequential bands and temporal windows length has\nalso been carried out. The proposed network has been trained and validated on\ntwo public datasets and achieves higher results compared to state-of-the-art\nmodels. As well as proposing better results, the framework could be used in\nreal applications, e.g. Attention Deficit Hyperactivity Disorder (ADHD)\nsymptoms or vigilance during a driving assessment.",
          "link": "http://arxiv.org/abs/2204.07162",
          "publishedOn": "2022-04-18T00:59:08.481Z",
          "wordCount": 662,
          "title": "Spatio-Temporal Analysis of Transformer based Architecture for Attention Estimation from EEG. (arXiv:2204.07162v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rubinfeld_R/0/1/0/all/0/1\">Ronitt Rubinfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasilyan_A/0/1/0/all/0/1\">Arsen Vasilyan</a>",
          "description": "There are many important high dimensional function classes that have fast\nagnostic learning algorithms when strong assumptions on the distribution of\nexamples can be made, such as Gaussianity or uniformity over the domain. But\nhow can one be sufficiently confident that the data indeed satisfies the\ndistributional assumption, so that one can trust in the output quality of the\nagnostic learning algorithm? We propose a model by which to systematically\nstudy the design of tester-learner pairs $(\\mathcal{A},\\mathcal{T})$, such that\nif the distribution on examples in the data passes the tester $\\mathcal{T}$\nthen one can safely trust the output of the agnostic learner $\\mathcal{A}$ on\nthe data.\n\nTo demonstrate the power of the model, we apply it to the classical problem\nof agnostically learning halfspaces under the standard Gaussian distribution\nand present a tester-learner pair with a combined run-time of\n$n^{\\tilde{O}(1/\\epsilon^4)}$. This qualitatively matches that of the best\nknown ordinary agnostic learning algorithms for this task. In contrast, finite\nsample Gaussian distribution testers do not exist for the $L_1$ and EMD\ndistance measures. A key step in the analysis is a novel characterization of\nconcentration and anti-concentration properties of a distribution whose\nlow-degree moments approximately match those of a Gaussian. We also use tools\nfrom polynomial approximation theory.\n\nIn contrast, we show strong lower bounds on the combined run-times of\ntester-learner pairs for the problems of agnostically learning convex sets\nunder the Gaussian distribution and for monotone Boolean functions under the\nuniform distribution over $\\{0,1\\}^n$. Through these lower bounds we exhibit\nnatural problems where there is a dramatic gap between standard agnostic\nlearning run-time and the run-time of the best tester-learner pair.",
          "link": "http://arxiv.org/abs/2204.07196",
          "publishedOn": "2022-04-18T00:59:08.447Z",
          "wordCount": 706,
          "title": "Testing distributional assumptions of learning algorithms. (arXiv:2204.07196v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1\">Paras Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruocheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candan_K/0/1/0/all/0/1\">K. Sel&#xe7;uk Candan</a>",
          "description": "Recommender systems aim to recommend new items to users by learning user and\nitem representations. In practice, these representations are highly entangled\nas they consist of information about multiple factors, including user's\ninterests, item attributes along with confounding factors such as user\nconformity, and item popularity. Considering these entangled representations\nfor inferring user preference may lead to biased recommendations (e.g., when\nthe recommender model recommends popular items even if they do not align with\nthe user's interests).\n\nRecent research proposes to debias by modeling a recommender system from a\ncausal perspective. The exposure and the ratings are analogous to the treatment\nand the outcome in the causal inference framework, respectively. The critical\nchallenge in this setting is accounting for the hidden confounders. These\nconfounders are unobserved, making it hard to measure them. On the other hand,\nsince these confounders affect both the exposure and the ratings, it is\nessential to account for them in generating debiased recommendations. To better\napproximate hidden confounders, we propose to leverage network information\n(i.e., user-social and user-item networks), which are shown to influence how\nusers discover and interact with an item. Aside from the user conformity,\naspects of confounding such as item popularity present in the network\ninformation is also captured in our method with the aid of \\textit{causal\ndisentanglement} which unravels the learned representations into independent\nfactors that are responsible for (a) modeling the exposure of an item to the\nuser, (b) predicting the ratings, and (c) controlling the hidden confounders.\nExperiments on real-world datasets validate the effectiveness of the proposed\nmodel for debiasing recommender systems.",
          "link": "http://arxiv.org/abs/2204.07221",
          "publishedOn": "2022-04-18T00:59:08.439Z",
          "wordCount": 706,
          "title": "Causal Disentanglement with Network Information for Debiased Recommendations. (arXiv:2204.07221v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bird_J/0/1/0/all/0/1\">Jordan J. Bird</a>",
          "description": "This study explores how robots and generative approaches can be used to mount\nsuccessful false-acceptance adversarial attacks on signature verification\nsystems. Initially, a convolutional neural network topology and data\naugmentation strategy are explored and tuned, producing an 87.12% accurate\nmodel for the verification of 2,640 human signatures. Two robots are then\ntasked with forging 50 signatures, where 25 are used for the verification\nattack, and the remaining 25 are used for tuning of the model to defend against\nthem. Adversarial attacks on the system show that there exists an information\nsecurity risk; the Line-us robotic arm can fool the system 24% of the time and\nthe iDraw 2.0 robot 32% of the time. A conditional GAN finds similar success,\nwith around 30% forged signatures misclassified as genuine. Following fine-tune\ntransfer learning of robotic and generative data, adversarial attacks are\nreduced below the model threshold by both robots and the GAN. It is observed\nthat tuning the model reduces the risk of attack by robots to 8% and 12%, and\nthat conditional generative adversarial attacks can be reduced to 4% when 25\nimages are presented and 5% when 1000 images are presented.",
          "link": "http://arxiv.org/abs/2204.07246",
          "publishedOn": "2022-04-18T00:59:08.419Z",
          "wordCount": 632,
          "title": "Robotic and Generative Adversarial Attacks in Offline Writer-independent Signature Verification. (arXiv:2204.07246v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07291",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Nakazato_K/0/1/0/all/0/1\">Kenichi Nakazato</a>",
          "description": "Deep neural network is the widely applied technology in this decade. In spite\nof the fruitful applications, the mechanism behind that is still to be\nelucidated. We study the learning process with a very simple supervised\nlearning encoding problem. As a result, we found a simple law, in the training\nresponse, which describes neural tangent kernel. The response consists of a\npower law like decay multiplied by a simple response kernel. We can construct a\nsimple mean-field dynamical model with the law, which explains how the network\nlearns. In the learning, the input space is split into sub-spaces along\ncompetition between the kernels. With the iterated splits and the aging, the\nnetwork gets more complexity, but finally loses its plasticity.",
          "link": "http://arxiv.org/abs/2204.07291",
          "publishedOn": "2022-04-18T00:59:08.412Z",
          "wordCount": 563,
          "title": "The training response law explains how deep neural networks learn. (arXiv:2204.07291v1 [cond-mat.dis-nn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cont_R/0/1/0/all/0/1\">Rama Cont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossier_A/0/1/0/all/0/1\">Alain Rossier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">RenYuan Xu</a>",
          "description": "We prove linear convergence of gradient descent to a global minimum for the\ntraining of deep residual networks with constant layer width and smooth\nactivation function. We further show that the trained weights, as a function of\nthe layer index, admits a scaling limit which is H\\\"older continuous as the\ndepth of the network tends to infinity. The proofs are based on non-asymptotic\nestimates of the loss function and of norms of the network weights along the\ngradient descent path. We illustrate the relevance of our theoretical results\nto practical settings using detailed numerical experiments on supervised\nlearning problems.",
          "link": "http://arxiv.org/abs/2204.07261",
          "publishedOn": "2022-04-18T00:59:08.404Z",
          "wordCount": 549,
          "title": "Convergence and Implicit Regularization Properties of Gradient Descent for Deep Residual Networks. (arXiv:2204.07261v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07230",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Oommen_V/0/1/0/all/0/1\">Vivek Oommen</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Shukla_K/0/1/0/all/0/1\">Khemraj Shukla</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Goswami_S/0/1/0/all/0/1\">Somdatta Goswami</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Dingreville_R/0/1/0/all/0/1\">Remi Dingreville</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Phase-field modeling is an effective mesoscale method for capturing the\nevolution dynamics of materials, e.g., in spinodal decomposition of a two-phase\nmixture. However, the accuracy of high-fidelity phase field models comes at a\nsubstantial computational cost. Hence, fast and generalizable surrogate models\nare needed to alleviate the cost in computationally taxing processes such as in\noptimization and design of materials. The intrinsic discontinuous nature of the\nphysical phenomena incurred by the presence of sharp phase boundaries makes the\ntraining of the surrogate model cumbersome. We develop a new framework that\nintegrates a convolutional autoencoder architecture with a deep neural operator\n(DeepONet) to learn the dynamic evolution of a two-phase mixture. We utilize\nthe convolutional autoencoder to provide a compact representation of the\nmicrostructure data in a low-dimensional latent space. DeepONet, which consists\nof two sub-networks, one for encoding the input function at a fixed number of\nsensors locations (branch net) and another for encoding the locations for the\noutput functions (trunk net), learns the mesoscale dynamics of the\nmicrostructure evolution in the latent space. The decoder part of the\nconvolutional autoencoder can then reconstruct the time-evolved microstructure\nfrom the DeepONet predictions. The result is an efficient and accurate\naccelerated phase-field framework that outperforms other neural-network-based\napproaches while at the same time being robust to noisy inputs.",
          "link": "http://arxiv.org/abs/2204.07230",
          "publishedOn": "2022-04-18T00:59:08.397Z",
          "wordCount": 665,
          "title": "Learning two-phase microstructure evolution using neural operators and autoencoder architectures. (arXiv:2204.07230v1 [cond-mat.mtrl-sci])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meulemans_A/0/1/0/all/0/1\">Alexander Meulemans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farinha_M/0/1/0/all/0/1\">Matilde Tristany Farinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cervera_M/0/1/0/all/0/1\">Maria R. Cervera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sacramento_J/0/1/0/all/0/1\">Jo&#xe3;o Sacramento</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grewe_B/0/1/0/all/0/1\">Benjamin F. Grewe</a>",
          "description": "The success of deep learning attracted interest in whether the brain learns\nhierarchical representations using gradient-based learning. However, current\nbiologically plausible methods for gradient-based credit assignment in deep\nneural networks need infinitesimally small feedback signals, which is\nproblematic in biologically realistic noisy environments and at odds with\nexperimental evidence in neuroscience showing that top-down feedback can\nsignificantly influence neural activity. Building upon deep feedback control\n(DFC), a recently proposed credit assignment method, we combine strong feedback\ninfluences on neural activity with gradient-based learning and show that this\nnaturally leads to a novel view on neural network optimization. Instead of\ngradually changing the network weights towards configurations with low output\nloss, weight updates gradually minimize the amount of feedback required from a\ncontroller that drives the network to the supervised output label. Moreover, we\nshow that the use of strong feedback in DFC allows learning forward and\nfeedback connections simultaneously, using a learning rule fully local in space\nand time. We complement our theoretical results with experiments on standard\ncomputer-vision benchmarks, showing competitive performance to backpropagation\nas well as robustness to noise. Overall, our work presents a fundamentally\nnovel view of learning as control minimization, while sidestepping biologically\nunrealistic assumptions.",
          "link": "http://arxiv.org/abs/2204.07249",
          "publishedOn": "2022-04-18T00:59:08.387Z",
          "wordCount": 655,
          "title": "Minimizing Control for Credit Assignment with Strong Feedback. (arXiv:2204.07249v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_R/0/1/0/all/0/1\">Raphael Souza de Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nascimento_E/0/1/0/all/0/1\">Erick Giovani Sperandio Nascimento</a>",
          "description": "Recent advances in Artificial intelligence (AI) have leveraged promising\nresults in solving complex problems in the area of Natural Language Processing\n(NLP), being an important tool to help in the expeditious resolution of\njudicial proceedings in the legal area. In this context, this work targets the\nproblem of detecting the degree of similarity between judicial documents that\ncan be achieved in the inference group, by applying six NLP techniques based on\ntransformers, namely BERT, GPT-2 and RoBERTa pre-trained in the Brazilian\nPortuguese language and the same specialized using 210,000 legal proceedings.\nDocuments were pre-processed and had their content transformed into a vector\nrepresentation using these NLP techniques. Unsupervised learning was used to\ncluster the lawsuits, calculating the quality of the model based on the cosine\nof the distance between the elements of the group to its centroid. We noticed\nthat models based on transformers present better performance when compared to\nprevious research, highlighting the RoBERTa model specialized in the Brazilian\nPortuguese language, making it possible to advance in the current state of the\nart in the area of NLP applied to the legal sector.",
          "link": "http://arxiv.org/abs/2204.07182",
          "publishedOn": "2022-04-18T00:59:08.353Z",
          "wordCount": 639,
          "title": "Brazilian Court Documents Clustered by Similarity Together Using Natural Language Processing Approaches with Transformers. (arXiv:2204.07182v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07178",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ouderaa_T/0/1/0/all/0/1\">Tycho F.A. van der Ouderaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_D/0/1/0/all/0/1\">David W. Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilk_M/0/1/0/all/0/1\">Mark van der Wilk</a>",
          "description": "Equivariances provide useful inductive biases in neural network modeling,\nwith the translation equivariance of convolutional neural networks being a\ncanonical example. Equivariances can be embedded in architectures through\nweight-sharing and place symmetry constraints on the functions a neural network\ncan represent. The type of symmetry is typically fixed and has to be chosen in\nadvance. Although some tasks are inherently equivariant, many tasks do not\nstrictly follow such symmetries. In such cases, equivariance constraints can be\noverly restrictive. In this work, we propose a parameter-efficient relaxation\nof equivariance that can effectively interpolate between a (i) non-equivariant\nlinear product, (ii) a strict-equivariant convolution, and (iii) a\nstrictly-invariant mapping. The proposed parameterization can be thought of as\na building block to allow adjustable symmetry structure in neural networks.\nCompared to non-equivariant or strict-equivariant baselines, we experimentally\nverify that soft equivariance leads to improved performance in terms of test\naccuracy on CIFAR-10 and CIFAR-100 image classification tasks.",
          "link": "http://arxiv.org/abs/2204.07178",
          "publishedOn": "2022-04-18T00:59:08.337Z",
          "wordCount": 591,
          "title": "Relaxing Equivariance Constraints with Non-stationary Continuous Filters. (arXiv:2204.07178v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_N/0/1/0/all/0/1\">Navjot Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solomonik_E/0/1/0/all/0/1\">Edgar Solomonik</a>",
          "description": "CP decomposition (CPD) is prevalent in chemometrics, signal processing, data\nmining and many more fields. While many algorithms have been proposed to\ncompute the CPD, alternating least squares (ALS) remains one of the most widely\nused algorithm for computing the decomposition. Recent works have introduced\nthe notion of eigenvalues and singular values of a tensor and explored\napplications of eigenvectors and singular vectors in areas like signal\nprocessing, data analytics and in various other fields. We introduce a new\nformulation for deriving singular values and vectors of a tensor by considering\nthe critical points of a function different from what is used in the previous\nwork. Computing these critical points in an alternating manner motivates an\nalternating optimization algorithm which corresponds to alternating least\nsquares algorithm in the matrix case. However, for tensors with order greater\nthan equal to $3$, it minimizes an objective function which is different from\nthe commonly used least squares loss. Alternating optimization of this new\nobjective leads to simple updates to the factor matrices with the same\nasymptotic computational cost as ALS. We show that a subsweep of this algorithm\ncan achieve a superlinear convergence rate for exact CPD with known rank and\nverify it experimentally. We then view the algorithm as optimizing a\nMahalanobis distance with respect to each factor with ground metric dependent\non the other factors. This perspective allows us to generalize our approach to\ninterpolate between updates corresponding to the ALS and the new algorithm to\nmanage the tradeoff between stability and fitness of the decomposition. Our\nexperimental results show that for approximating synthetic and real-world\ntensors, this algorithm and its variants converge to a better conditioned\ndecomposition with comparable and sometimes better fitness as compared to the\nALS algorithm.",
          "link": "http://arxiv.org/abs/2204.07208",
          "publishedOn": "2022-04-18T00:59:08.330Z",
          "wordCount": 728,
          "title": "Alternating Mahalanobis Distance Minimization for Stable and Accurate CP Decomposition. (arXiv:2204.07208v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07235",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Zhu_Y/0/1/0/all/0/1\">Yi Zhu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Filipov_E/0/1/0/all/0/1\">Evgueni T. Filipov</a>",
          "description": "Engineering design of origami systems is challenging because comparing\ndifferent origami patterns requires using categorical features and evaluating\nmulti-physics behavior targets introduces multi-objective problems. This work\nshows that a decision tree machine learning method is particularly suitable for\nthe inverse design of origami. This interpretable machine learning method can\nreveal complex interactions between categorical features and continuous\nfeatures for comparing different origami patterns, can tackle multi-objective\nproblems for designing active origami with multi-physics performance targets,\nand can extend existing origami shape fitting algorithms to further consider\nnon-geometrical performances of origami systems. The proposed framework shows a\nholistic way of designing active origami systems for various applications such\nas metamaterials, deployable structures, soft robots, biomedical devices, and\nmany more.",
          "link": "http://arxiv.org/abs/2204.07235",
          "publishedOn": "2022-04-18T00:59:08.295Z",
          "wordCount": 564,
          "title": "Harnessing Interpretable Machine Learning for Origami Feature Design and Pattern Selection. (arXiv:2204.07235v1 [cond-mat.soft])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07234",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Nguyen_P/0/1/0/all/0/1\">Phong C.H. Nguyen</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Choi_J/0/1/0/all/0/1\">Joseph B. Choi</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Nguyen_Y/0/1/0/all/0/1\">Yen-Thi Nguyen</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Seshadri_P/0/1/0/all/0/1\">Pradeep K. Seshadri</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Udaykumar_H/0/1/0/all/0/1\">H.S. Udaykumar</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Baek_S/0/1/0/all/0/1\">Stephen Baek</a>",
          "description": "The thermomechanical properties of energetic materials (EM) are known to be a\nfunction of their microscopic structures, i.e., morphological configurations of\ncrystals and pores. This microstructural dependency has motivated vigorous\nresearch in the EM community, seeking to engineer material microstructures with\ntargeted properties and performance under the materials-by-design paradigm.\nHowever, establishing the complex structure-property-performance (SPP)\nrelationships of EMs demands extensive experimental and simulation efforts, and\nassimilating and encapsulating these relationships in usable models is a\nchallenge. Here, we present a novel deep learning method, Physics-Aware\nRecurrent Convolutional (PARC) Neural Network, that can \"learn\" the mesoscale\nthermo-mechanics of EM microstructures during the shock-to-detonation\ntransition (SDT). We show that this new approach can produce accurate\nhigh-fidelity predictions of time-evolving temperature and pressure fields of\nthe same quality as the state-of-the-art direct numerical simulations (DNS),\ndespite the dramatic reduction of computing time, from hours and days on a\nhigh-performance computing cluster (HPC) to a little more than a second on a\ncommodity laptop. We also demonstrate that PARC can provide physical insights,\ni.e., the artificial neurons can illuminate the underlying physics by\nidentifying which microstructural features led to critical hotspots and what\nare the characteristics of \"critical\" versus \"non-critical\" microstructures.\nThis new knowledge generated alongside the capacity to conduct high-throughput\nexperiments will broaden our theoretical understanding of the initiation\nmechanisms of EM detonation, as a step towards engineering EMs with specific\nproperties.",
          "link": "http://arxiv.org/abs/2204.07234",
          "publishedOn": "2022-04-18T00:59:08.286Z",
          "wordCount": 684,
          "title": "Physics-Aware Recurrent Convolutional (PARC) Neural Networks to Assimilate Meso-scale Reactive Mechanics of Energetic Materials. (arXiv:2204.07234v1 [cond-mat.mtrl-sci])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07172",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Loaiza_Ganem_G/0/1/0/all/0/1\">Gabriel Loaiza-Ganem</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ross_B/0/1/0/all/0/1\">Brendan Leigh Ross</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cresswell_J/0/1/0/all/0/1\">Jesse C. Cresswell</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Caterini_A/0/1/0/all/0/1\">Anthony L. Caterini</a>",
          "description": "Likelihood-based, or explicit, deep generative models use neural networks to\nconstruct flexible high-dimensional densities. This formulation directly\ncontradicts the manifold hypothesis, which states that observed data lies on a\nlow-dimensional manifold embedded in high-dimensional ambient space. In this\npaper we investigate the pathologies of maximum-likelihood training in the\npresence of this dimensionality mismatch. We formally prove that degenerate\noptima are achieved wherein the manifold itself is learned but not the\ndistribution on it, a phenomenon we call manifold overfitting. We propose a\nclass of two-step procedures consisting of a dimensionality reduction step\nfollowed by maximum-likelihood density estimation, and prove that they recover\nthe data-generating distribution in the nonparametric regime, thus avoiding\nmanifold overfitting. We also show that these procedures enable density\nestimation on the manifolds learned by implicit models, such as generative\nadversarial networks, hence addressing a major shortcoming of these models.\nSeveral recently proposed methods are instances of our two-step procedures; we\nthus unify, extend, and theoretically justify a large class of models.",
          "link": "http://arxiv.org/abs/2204.07172",
          "publishedOn": "2022-04-18T00:59:08.277Z",
          "wordCount": 613,
          "title": "Diagnosing and Fixing Manifold Overfitting in Deep Generative Models. (arXiv:2204.07172v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelli_K/0/1/0/all/0/1\">Khouloud Abdelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1\">Joo Yeon Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azendorf_F/0/1/0/all/0/1\">Florian Azendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griesser_H/0/1/0/all/0/1\">Helmut Griesser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tropschug_C/0/1/0/all/0/1\">Carsten Tropschug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pachnicke_S/0/1/0/all/0/1\">Stephan Pachnicke</a>",
          "description": "Secure and reliable data communication in optical networks is critical for\nhigh-speed Internet. However, optical fibers, serving as the data transmission\nmedium providing connectivity to billons of users worldwide, are prone to a\nvariety of anomalies resulting from hard failures (e.g., fiber cuts) and\nmalicious physical attacks (e.g., optical eavesdropping (fiber tapping)) etc.\nSuch anomalies may cause network disruption and thereby inducing huge financial\nand data losses, or compromise the confidentiality of optical networks by\ngaining unauthorized access to the carried data, or gradually degrade the\nnetwork operations. Therefore, it is highly required to implement efficient\nanomaly detection, diagnosis, and localization schemes for enhancing the\navailability and reliability of optical networks. In this paper, we propose a\ndata driven approach to accurately and quickly detect, diagnose, and localize\nfiber anomalies including fiber cuts, and optical eavesdropping attacks. The\nproposed method combines an autoencoder-based anomaly detection and an\nattention-based bidirectional gated recurrent unit algorithm, whereby the\nformer is used for fault detection and the latter is adopted for fault\ndiagnosis and localization once an anomaly is detected by the autoencoder. We\nverify the efficiency of our proposed approach by experiments under various\nanomaly scenarios using real operational data. The experimental results\ndemonstrate that: (i) the autoencoder detects any fiber fault or anomaly with\nan F1 score of 96.86%; and (ii) the attention-based bidirectional gated\nrecurrent unit algorithm identifies the the detected anomalies with an average\naccuracy of 98.2%, and localizes the faults with an average root mean square\nerror of 0.19 m.",
          "link": "http://arxiv.org/abs/2204.07059",
          "publishedOn": "2022-04-16T00:51:47.045Z",
          "wordCount": 731,
          "title": "Machine Learning-based Anomaly Detection in Optical Fiber Monitoring. (arXiv:2204.07059v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.14126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goktas_D/0/1/0/all/0/1\">Denizalp Goktas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiayi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenwald_A/0/1/0/all/0/1\">Amy Greenwald</a>",
          "description": "The behavior of no-regret learning algorithms is well understood in\ntwo-player min-max (i.e, zero-sum) games. In this paper, we investigate the\nbehavior of no-regret learning in min-max games with dependent strategy sets,\nwhere the strategy of the first player constrains the behavior of the second.\nSuch games are best understood as sequential, i.e., min-max Stackelberg, games.\nWe consider two settings, one in which only the first player chooses their\nactions using a no-regret algorithm while the second player best responds, and\none in which both players use no-regret algorithms. For the former case, we\nshow that no-regret dynamics converge to a Stackelberg equilibrium. For the\nlatter case, we introduce a new type of regret, which we call Lagrangian\nregret, and show that if both players minimize their Lagrangian regrets, then\nplay converges to a Stackelberg equilibrium. We then observe that online mirror\ndescent (OMD) dynamics in these two settings correspond respectively to a known\nnested (i.e., sequential) gradient descent-ascent (GDA) algorithm and a new\nsimultaneous GDA-like algorithm, thereby establishing convergence of these\nalgorithms to Stackelberg equilibrium. Finally, we analyze the robustness of\nOMD dynamics to perturbations by investigating online min-max Stackelberg\ngames. We prove that OMD dynamics are robust for a large class of online\nmin-max games with independent strategy sets. In the dependent case, we\ndemonstrate the robustness of OMD dynamics experimentally by simulating them in\nonline Fisher markets, a canonical example of a min-max Stackelberg game with\ndependent strategy sets.",
          "link": "http://arxiv.org/abs/2203.14126",
          "publishedOn": "2022-04-16T00:51:46.878Z",
          "wordCount": 721,
          "title": "Robust No-Regret Learning in Min-Max Stackelberg Games. (arXiv:2203.14126v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.06207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vaze_S/0/1/0/all/0/1\">Sagar Vaze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1\">Andrea Vedaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1\">Andrew Zisserman</a>",
          "description": "The ability to identify whether or not a test sample belongs to one of the\nsemantic classes in a classifier's training set is critical to practical\ndeployment of the model. This task is termed open-set recognition (OSR) and has\nreceived significant attention in recent years. In this paper, we first\ndemonstrate that the ability of a classifier to make the 'none-of-above'\ndecision is highly correlated with its accuracy on the closed-set classes. We\nfind that this relationship holds across loss objectives and architectures, and\nfurther demonstrate the trend both on the standard OSR benchmarks as well as on\na large-scale ImageNet evaluation. Second, we use this correlation to boost the\nperformance of a maximum logit score OSR 'baseline' by improving its closed-set\naccuracy, and with this strong baseline achieve state-of-the-art on a number of\nOSR benchmarks. Similarly, we boost the performance of the existing\nstate-of-the-art method by improving its closed-set accuracy, but the resulting\ndiscrepancy with the strong baseline is marginal. Our third contribution is to\npresent the 'Semantic Shift Benchmark' (SSB), which better respects the task of\ndetecting semantic novelty, in contrast to other forms of distribution shift\nalso considered in related sub-fields, such as out-of-distribution detection.\nOn this new evaluation, we again demonstrate that there is negligible\ndifference between the strong baseline and the existing state-of-the-art.\nProject Page: https://www.robots.ox.ac.uk/~vgg/research/osr/",
          "link": "http://arxiv.org/abs/2110.06207",
          "publishedOn": "2022-04-16T00:51:46.866Z",
          "wordCount": 708,
          "title": "Open-Set Recognition: a Good Closed-Set Classifier is All You Need?. (arXiv:2110.06207v2 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Butler_A/0/1/0/all/0/1\">Andrew Butler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_R/0/1/0/all/0/1\">Roy H. Kwon</a>",
          "description": "Many problems in engineering and statistics involve both predictive\nforecasting and decision-based optimization. Traditionally, predictive models\nare optimized independently from the final decision-based optimization problem.\nIn contrast, a `smart, predict then optimize' (SPO) framework optimizes\nprediction models to explicitly minimize the final downstream decision loss. In\nthis paper we present dboost, a gradient boosting algorithm for training\nprediction model ensembles to minimize decision regret. The dboost framework\nsupports any convex optimization program that can be cast as convex quadratic\ncone program and gradient boosting is performed by implicit differentiation of\na custom fixed-point mapping. To our knowledge, the dboost framework is the\nfirst general purpose implementation of gradient boosting to predict and\noptimize problems. Experimental results comparing with state-of-the-art SPO\nmethods show that dboost can further reduce out-of-sample decision regret.",
          "link": "http://arxiv.org/abs/2204.06895",
          "publishedOn": "2022-04-16T00:51:45.646Z",
          "wordCount": 573,
          "title": "Gradient boosting for convex cone predict and optimize problems. (arXiv:2204.06895v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06806",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maji_D/0/1/0/all/0/1\">Debapriya Maji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagori_S/0/1/0/all/0/1\">Soyeb Nagori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathew_M/0/1/0/all/0/1\">Manu Mathew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poddar_D/0/1/0/all/0/1\">Deepak Poddar</a>",
          "description": "We introduce YOLO-pose, a novel heatmap-free approach for joint detection,\nand 2D multi-person pose estimation in an image based on the popular YOLO\nobject detection framework. Existing heatmap based two-stage approaches are\nsub-optimal as they are not end-to-end trainable and training relies on a\nsurrogate L1 loss that is not equivalent to maximizing the evaluation metric,\ni.e. Object Keypoint Similarity (OKS). Our framework allows us to train the\nmodel end-to-end and optimize the OKS metric itself. The proposed model learns\nto jointly detect bounding boxes for multiple persons and their corresponding\n2D poses in a single forward pass and thus bringing in the best of both\ntop-down and bottom-up approaches. Proposed approach doesn't require the\npostprocessing of bottom-up approaches to group detected keypoints into a\nskeleton as each bounding box has an associated pose, resulting in an inherent\ngrouping of the keypoints. Unlike top-down approaches, multiple forward passes\nare done away with since all persons are localized along with their pose in a\nsingle inference. YOLO-pose achieves new state-of-the-art results on COCO\nvalidation (90.2% AP50) and test-dev set (90.3% AP50), surpassing all existing\nbottom-up approaches in a single forward pass without flip test, multi-scale\ntesting, or any other test time augmentation. All experiments and results\nreported in this paper are without any test time augmentation, unlike\ntraditional approaches that use flip-test and multi-scale testing to boost\nperformance. Our training codes will be made publicly available at\nhttps://github.com/TexasInstruments/edgeai-yolov5 and\nhttps://github.com/TexasInstruments/edgeai-yolox",
          "link": "http://arxiv.org/abs/2204.06806",
          "publishedOn": "2022-04-16T00:51:44.991Z",
          "wordCount": 698,
          "title": "YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss. (arXiv:2204.06806v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianxi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1\">Feng Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_A/0/1/0/all/0/1\">Anlong Ming</a>",
          "description": "For the 2D laser-based tasks, e.g., people detection and people tracking, leg\ndetection is usually the first step. Thus, it carries great weight in\ndetermining the performance of people detection and people tracking. However,\nmany leg detectors ignore the inevitable noise and the multiscale\ncharacteristics of the laser scan, which makes them sensitive to the unreliable\nfeatures of point cloud and further degrades the performance of the leg\ndetector. In this paper, we propose a multiscale adaptive-switch Random Forest\n(MARF) to overcome these two challenges. Firstly, the adaptive-switch decision\ntree is designed to use noisesensitive features to conduct weighted\nclassification and noiseinvariant features to conduct binary classification,\nwhich makes our detector perform more robust to noise. Secondly, considering\nthe multiscale property that the sparsity of the 2D point cloud is proportional\nto the length of laser beams, we design a multiscale random forest structure to\ndetect legs at different distances. Moreover, the proposed approach allows us\nto discover a sparser human leg from point clouds than others. Consequently,\nour method shows an improved performance compared to other state-of-the-art leg\ndetectors on the challenging Moving Legs dataset and retains the whole pipeline\nat a speed of 60+ FPS on lowcomputational laptops. Moreover, we further apply\nthe proposed MARF to the people detection and tracking system, achieving a\nconsiderable gain in all metrics.",
          "link": "http://arxiv.org/abs/2204.06833",
          "publishedOn": "2022-04-16T00:51:44.983Z",
          "wordCount": 671,
          "title": "MARF: Multiscale Adaptive-switch Random Forest for Leg Detection with 2D Laser Scanners. (arXiv:2204.06833v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Youwei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_C/0/1/0/all/0/1\">Chongjian Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Z/0/1/0/all/0/1\">Zhan Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yibing Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengtao Xie</a>",
          "description": "Vision Transformers (ViTs) take all the image patches as tokens and construct\nmulti-head self-attention (MHSA) among them. Complete leverage of these image\ntokens brings redundant computations since not all the tokens are attentive in\nMHSA. Examples include that tokens containing semantically meaningless or\ndistractive image backgrounds do not positively contribute to the ViT\npredictions. In this work, we propose to reorganize image tokens during the\nfeed-forward process of ViT models, which is integrated into ViT during\ntraining. For each forward inference, we identify the attentive image tokens\nbetween MHSA and FFN (i.e., feed-forward network) modules, which is guided by\nthe corresponding class token attention. Then, we reorganize image tokens by\npreserving attentive image tokens and fusing inattentive ones to expedite\nsubsequent MHSA and FFN computations. To this end, our method EViT improves\nViTs from two perspectives. First, under the same amount of input image tokens,\nour method reduces MHSA and FFN computation for efficient inference. For\ninstance, the inference speed of DeiT-S is increased by 50% while its\nrecognition accuracy is decreased by only 0.3% for ImageNet classification.\nSecond, by maintaining the same computational cost, our method empowers ViTs to\ntake more image tokens as input for recognition accuracy improvement, where the\nimage tokens are from higher resolution images. An example is that we improve\nthe recognition accuracy of DeiT-S by 1% for ImageNet classification at the\nsame computational cost of a vanilla DeiT-S. Meanwhile, our method does not\nintroduce more parameters to ViTs. Experiments on the standard benchmarks show\nthe effectiveness of our method. The code is available at\nhttps://github.com/youweiliang/evit",
          "link": "http://arxiv.org/abs/2202.07800",
          "publishedOn": "2022-04-16T00:51:44.888Z",
          "wordCount": 741,
          "title": "Not All Patches are What You Need: Expediting Vision Transformers via Token Reorganizations. (arXiv:2202.07800v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruohong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yize Chen</a>",
          "description": "We consider the problem of learning the energy disaggregation signals for\nresidential load data. Such task is referred as non-intrusive load monitoring\n(NILM), and in order to find individual devices' power consumption profiles\nbased on aggregated meter measurements, a machine learning model is usually\ntrained based on large amount of training data coming from a number of\nresidential homes. Yet collecting such residential load datasets require both\nhuge efforts and customers' approval on sharing metering data, while load data\ncoming from different regions or electricity users may exhibit heterogeneous\nusage patterns. Both practical concerns make training a single, centralized\nNILM model challenging. In this paper, we propose a decentralized and\ntask-adaptive learning scheme for NILM tasks, where nested meta learning and\nfederated learning steps are designed for learning task-specific models\ncollectively. Simulation results on benchmark dataset validate proposed\nalgorithm's performance on efficiently inferring appliance-level consumption\nfor a variety of homes and appliances.",
          "link": "http://arxiv.org/abs/2204.06767",
          "publishedOn": "2022-04-16T00:51:44.878Z",
          "wordCount": 585,
          "title": "Learning Task-Aware Energy Disaggregation: a Federated Approach. (arXiv:2204.06767v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jenul_A/0/1/0/all/0/1\">Anna Jenul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schrunner_S/0/1/0/all/0/1\">Stefan Schrunner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_B/0/1/0/all/0/1\">Bao Ngoc Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helin_R/0/1/0/all/0/1\">Runar Helin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Futsaether_C/0/1/0/all/0/1\">Cecilia Marie Futs&#xe6;ther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liland_K/0/1/0/all/0/1\">Kristian Hovde Liland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomic_O/0/1/0/all/0/1\">Oliver Tomic</a>",
          "description": "In artificial neural networks, understanding the contributions of input\nfeatures on the prediction fosters model explainability and delivers relevant\ninformation about the dataset. While typical setups for feature importance\nranking assess input features individually, in this study, we go one step\nfurther and rank the importance of groups of features, denoted as\nfeature-blocks. A feature-block can contain features of a specific type or\nfeatures derived from a particular source, which are presented to the neural\nnetwork in separate input branches (multiblock ANNs). This work presents three\nmethods pursuing distinct strategies to rank features in multiblock ANNs by\ntheir importance: (1) a composite strategy building on individual feature\nimportance rankings, (2) a knock-in, and (3) a knock-out strategy. While the\ncomposite strategy builds on state-of-the-art feature importance rankings,\nknock-in and knock-out strategies evaluate the block as a whole via a mutual\ninformation criterion. Our experiments consist of a simulation study validating\nall three approaches, followed by a case study on two distinct real-world\ndatasets to compare the strategies. We conclude that each strategy has its\nmerits for specific application scenarios.",
          "link": "http://arxiv.org/abs/2109.10279",
          "publishedOn": "2022-04-16T00:51:44.870Z",
          "wordCount": 650,
          "title": "Ranking Feature-Block Importance in Artificial Multiblock Neural Networks. (arXiv:2109.10279v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yun Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yufei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Ting Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1\">Michael Backes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stringhini_G/0/1/0/all/0/1\">Gianluca Stringhini</a>",
          "description": "Previous security research efforts orbiting around graphs have been\nexclusively focusing on either (de-)anonymizing the graphs or understanding the\nsecurity and privacy issues of graph neural networks. Little attention has been\npaid to understand the privacy risks of integrating the output from graph\nembedding models (e.g., node embeddings) with complex downstream machine\nlearning pipelines. In this paper, we fill this gap and propose a novel\nmodel-agnostic graph recovery attack that exploits the implicit graph\nstructural information preserved in the embeddings of graph nodes. We show that\nan adversary can recover edges with decent accuracy by only gaining access to\nthe node embedding matrix of the original graph without interactions with the\nnode embedding models. We demonstrate the effectiveness and applicability of\nour graph recovery attack through extensive experiments.",
          "link": "http://arxiv.org/abs/2204.06963",
          "publishedOn": "2022-04-16T00:51:44.862Z",
          "wordCount": 594,
          "title": "Finding MNEMON: Reviving Memories of Node Embeddings. (arXiv:2204.06963v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chandrasekhar_A/0/1/0/all/0/1\">Aaditya Chandrasekhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridhara_S/0/1/0/all/0/1\">Saketh Sridhara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_K/0/1/0/all/0/1\">Krishnan Suresh</a>",
          "description": "Multiscale topology optimization (M-TO) entails generating an optimal global\ntopology, and an optimal set of microstructures at a smaller scale, for a\nphysics-constrained problem. With the advent of additive manufacturing, M-TO\nhas gained significant prominence. However, generating optimal microstructures\nat various locations can be computationally very expensive. As an alternate,\ngraded multiscale topology optimization (GM-TO) has been proposed where one or\nmore pre-selected and graded (parameterized) microstructural topologies are\nused to fill the domain optimally. This leads to a significant reduction in\ncomputation while retaining many of the benefits of M-TO.\n\nA successful GM-TO framework must: (1) be capable of efficiently handling\nnumerous pre-selected microstructures, (2) be able to continuously switch\nbetween these microstructures during optimization, (3) ensure that the\npartition of unity is satisfied, and (4) discourage microstructure mixing at\ntermination.\n\nIn this paper, we propose to meet these requirements by exploiting the unique\nclassification capacity of neural networks. Specifically, we propose a graded\nmultiscale topology optimization using neural-network (GM-TOuNN) framework with\nthe following features: (1) the number of design variables is only weakly\ndependent on the number of pre-selected microstructures, (2) it guarantees\npartition of unity while discouraging microstructure mixing, and (3) it\nsupports automatic differentiation, thereby eliminating manual sensitivity\nanalysis. The proposed framework is illustrated through several examples.",
          "link": "http://arxiv.org/abs/2204.06682",
          "publishedOn": "2022-04-16T00:51:44.853Z",
          "wordCount": 658,
          "title": "GM-TOuNN: Graded Multiscale Topology Optimization using Neural Networks. (arXiv:2204.06682v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07004",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Thiery_A/0/1/0/all/0/1\">Alexandre H. Thiery</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Braeu_F/0/1/0/all/0/1\">Fabian Braeu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tun_T/0/1/0/all/0/1\">Tin A. Tun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aung_T/0/1/0/all/0/1\">Tin Aung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Girard_M/0/1/0/all/0/1\">Michael J.A. Girard</a>",
          "description": "Purpose: (1) To assess the performance of geometric deep learning (PointNet)\nin diagnosing glaucoma from a single optical coherence tomography (OCT) 3D scan\nof the optic nerve head (ONH); (2) To compare its performance to that obtained\nwith a standard 3D convolutional neural network (CNN), and with a gold-standard\nglaucoma parameter, i.e. retinal nerve fiber layer (RNFL) thickness.\n\nMethods: 3D raster scans of the ONH were acquired with Spectralis OCT for 477\nglaucoma and 2,296 non-glaucoma subjects at the Singapore National Eye Centre.\nAll volumes were automatically segmented using deep learning to identify 7\nmajor neural and connective tissues including the RNFL, the prelamina, and the\nlamina cribrosa (LC). Each ONH was then represented as a 3D point cloud with\n1,000 points chosen randomly from all tissue boundaries. To simplify the\nproblem, all ONH point clouds were aligned with respect to the plane and center\nof Bruch's membrane opening. Geometric deep learning (PointNet) was then used\nto provide a glaucoma diagnosis from a single OCT point cloud. The performance\nof our approach was compared to that obtained with a 3D CNN, and with RNFL\nthickness.\n\nResults: PointNet was able to provide a robust glaucoma diagnosis solely from\nthe ONH represented as a 3D point cloud (AUC=95%). The performance of PointNet\nwas superior to that obtained with a standard 3D CNN (AUC=87%) and with that\nobtained from RNFL thickness alone (AUC=80%).\n\nDiscussion: We provide a proof-of-principle for the application of geometric\ndeep learning in the field of glaucoma. Our technique requires significantly\nless information as input to perform better than a 3D CNN, and with an AUC\nsuperior to that obtained from RNFL thickness alone. Geometric deep learning\nmay have wide applicability in the field of Ophthalmology.",
          "link": "http://arxiv.org/abs/2204.07004",
          "publishedOn": "2022-04-16T00:51:44.827Z",
          "wordCount": 748,
          "title": "Medical Application of Geometric Deep Learning for the Diagnosis of Glaucoma. (arXiv:2204.07004v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06664",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Niss_L/0/1/0/all/0/1\">Laura Niss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yuekai Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1\">Ambuj Tewari</a>",
          "description": "Sampling biases in training data are a major source of algorithmic biases in\nmachine learning systems. Although there are many methods that attempt to\nmitigate such algorithmic biases during training, the most direct and obvious\nway is simply collecting more representative training data. In this paper, we\nconsider the task of assembling a training dataset in which minority groups are\nadequately represented from a given set of data sources. In essence, this is an\nadaptive sampling problem to determine if a given point lies in the convex hull\nof the means from a set of unknown distributions. We present adaptive sampling\nmethods to determine, with high confidence, whether it is possible to assemble\na representative dataset from the given data sources. We also demonstrate the\nefficacy of our policies in simulations in the Bernoulli and a multinomial\nsetting.",
          "link": "http://arxiv.org/abs/2204.06664",
          "publishedOn": "2022-04-16T00:51:44.820Z",
          "wordCount": 575,
          "title": "Achieving Representative Data via Convex Hull Feasibility Sampling Algorithms. (arXiv:2204.06664v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_H/0/1/0/all/0/1\">Hosein Rezaei</a>",
          "description": "Word embedding systems such as Word2Vec and GloVe are well-known in deep\nlearning approaches to NLP. This is largely due to their ability to capture\nsemantic relationships between words. In this work we investigated their\nusefulness in capturing rhythmic similarity of words instead. The results show\nthat vectors these embeddings assign to rhyming words are more similar to each\nother, compared to the other words. It is also revealed that GloVe performs\nrelatively better than Word2Vec in this regard. We also proposed a first of its\nkind metric for quantifying rhythmic similarity of a pair of words.",
          "link": "http://arxiv.org/abs/2204.04833",
          "publishedOn": "2022-04-16T00:51:44.812Z",
          "wordCount": 550,
          "title": "Word Embeddings Are Capable of Capturing Rhythmic Similarity of Words. (arXiv:2204.04833v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07054",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Cui_H/0/1/0/all/0/1\">Hejie Cui</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dai_W/0/1/0/all/0/1\">Wei Dai</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kan_X/0/1/0/all/0/1\">Xuan Kan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gu_A/0/1/0/all/0/1\">Antonio Aodong Chen Gu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lukemire_J/0/1/0/all/0/1\">Joshua Lukemire</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhan_L/0/1/0/all/0/1\">Liang Zhan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+He_L/0/1/0/all/0/1\">Lifang He</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Guo_Y/0/1/0/all/0/1\">Ying Guo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yang_C/0/1/0/all/0/1\">Carl Yang</a>",
          "description": "Mapping the connectome of the human brain using structural or functional\nconnectivity has become one of the most pervasive paradigms for neuroimaging\nanalysis. Recently, Graph Neural Networks (GNNs) motivated from geometric deep\nlearning have attracted broad interest due to their established power for\nmodeling complex networked data. Despite their established performance in other\nfields, there has not yet been a systematic study of how to design effective\nGNNs for brain network analysis. To bridge this gap, we present BrainGB, a\nbenchmark for brain network analysis with GNNs. BrainGB standardizes the\nprocess by 1) summarizing brain network construction pipelines for both\nfunctional and structural neuroimaging modalities and 2) modularizing the\nimplementation of GNN designs. We conduct extensive experiments on datasets\nacross cohorts and modalities and recommend a set of general recipes for\neffective GNN designs on brain networks. To support open and reproducible\nresearch on GNN-based brain network analysis, we also host the BrainGB website\nat https:// brainnet.us/ with models, tutorials, examples, as well as an\nout-of-box Python package. We hope that this work will provide useful empirical\nevidence and offer insights for future research in this novel and promising\ndirection.",
          "link": "http://arxiv.org/abs/2204.07054",
          "publishedOn": "2022-04-16T00:51:44.804Z",
          "wordCount": 667,
          "title": "BrainGB: A Benchmark for Brain Network Analysis with Graph Neural Networks. (arXiv:2204.07054v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makoviychuk_V/0/1/0/all/0/1\">Viktor Makoviychuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narang_Y/0/1/0/all/0/1\">Yashraj Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1\">Fabio Ramos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matusik_W/0/1/0/all/0/1\">Wojciech Matusik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1\">Animesh Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macklin_M/0/1/0/all/0/1\">Miles Macklin</a>",
          "description": "Deep reinforcement learning can generate complex control policies, but\nrequires large amounts of training data to work effectively. Recent work has\nattempted to address this issue by leveraging differentiable simulators.\nHowever, inherent problems such as local minima and exploding/vanishing\nnumerical gradients prevent these methods from being generally applied to\ncontrol tasks with complex contact-rich dynamics, such as humanoid locomotion\nin classical RL benchmarks. In this work we present a high-performance\ndifferentiable simulator and a new policy learning algorithm (SHAC) that can\neffectively leverage simulation gradients, even in the presence of\nnon-smoothness. Our learning algorithm alleviates problems with local minima\nthrough a smooth critic function, avoids vanishing/exploding gradients through\na truncated learning window, and allows many physical environments to be run in\nparallel. We evaluate our method on classical RL control tasks, and show\nsubstantial improvements in sample efficiency and wall-clock time over\nstate-of-the-art RL and differentiable simulation-based algorithms. In\naddition, we demonstrate the scalability of our method by applying it to the\nchallenging high-dimensional problem of muscle-actuated locomotion with a large\naction space, achieving a greater than 17x reduction in training time over the\nbest-performing established RL algorithm.",
          "link": "http://arxiv.org/abs/2204.07137",
          "publishedOn": "2022-04-16T00:51:44.796Z",
          "wordCount": 641,
          "title": "Accelerated Policy Learning with Parallel Differentiable Simulation. (arXiv:2204.07137v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.08928",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_K/0/1/0/all/0/1\">Kan Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_X/0/1/0/all/0/1\">Xuanyi Zhao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bastani_H/0/1/0/all/0/1\">Hamsa Bastani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Unstructured text provides decision-makers with a rich data source in many\ndomains, ranging from product reviews in retailing to nursing notes in\nhealthcare. To leverage this information, words are typically translated into\nword embeddings -- vectors that encode the semantic relationships between words\n-- through unsupervised learning algorithms such as matrix factorization.\nHowever, learning word embeddings from new domains with limited training data\ncan be challenging, because the meaning/usage may be different in the new\ndomain, e.g., the word \"positive\" typically has positive sentiment, but often\nhas negative sentiment in medical notes since it may imply that a patient is\ntested positive for a disease. Intuitively, we expect that only a small number\nof domain-specific words may have new meanings/usages. We propose an intuitive\ntwo-stage estimator that exploits this structure via a group-sparse penalty to\nefficiently transfer learn domain-specific word embeddings by combining\nlarge-scale text corpora (such as Wikipedia) with limited domain-specific text\ndata. We bound the generalization error of our estimator, proving that it can\nachieve the same accuracy (compared to not transfer learning) with\nsubstantially less domain-specific data when only a small number of embeddings\nare altered between domains. Our results provide the first bounds on\ngroup-sparse matrix factorization, which may be of independent interest. We\nempirically evaluate the effectiveness of our approach compared to\nstate-of-the-art fine-tuning heuristics from natural language processing.",
          "link": "http://arxiv.org/abs/2104.08928",
          "publishedOn": "2022-04-16T00:51:44.773Z",
          "wordCount": 685,
          "title": "Group-Sparse Matrix Factorization for Transfer Learning of Word Embeddings. (arXiv:2104.08928v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Forouhesh_M/0/1/0/all/0/1\">Mohammad Forouhesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansouri_A/0/1/0/all/0/1\">Arash Mansouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fani_H/0/1/0/all/0/1\">Hossein Fani</a>",
          "description": "Within the context of review analytics, aspects are the features of products\nand services at which customers target their opinions and sentiments. Aspect\ndetection helps product owners and service providers to identify shortcomings\nand prioritize customers' needs, and hence, maintain revenues and mitigate\ncustomer churn. Existing methods focus on detecting the surface form of an\naspect by training supervised learning methods that fall short when aspects are\nlatent in reviews. In this paper, we propose an unsupervised method to extract\nlatent occurrences of aspects. Specifically, we assume that a customer\nundergoes a two-stage hypothetical generative process when writing a review:\n(1) deciding on an aspect amongst the set of aspects available for the product\nor service, and (2) writing the opinion words that are more interrelated to the\nchosen aspect from the set of all words available in a language. We employ\nlatent Dirichlet allocation to learn the latent aspects distributions for\ngenerating the reviews. Experimental results on benchmark datasets show that\nour proposed method is able to improve the state of the art when the aspects\nare latent with no surface form in reviews.",
          "link": "http://arxiv.org/abs/2204.06964",
          "publishedOn": "2022-04-16T00:51:44.765Z",
          "wordCount": 638,
          "title": "Latent Aspect Detection from Online Unsolicited Customer Reviews. (arXiv:2204.06964v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hassani_A/0/1/0/all/0/1\">Ali Hassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walton_S/0/1/0/all/0/1\">Steven Walton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Humphrey Shi</a>",
          "description": "We present Neighborhood Attention Transformer (NAT), an efficient, accurate\nand scalable hierarchical transformer that works well on both image\nclassification and downstream vision tasks. It is built upon Neighborhood\nAttention (NA), a simple and flexible attention mechanism that localizes the\nreceptive field for each query to its nearest neighboring pixels. NA is a\nlocalization of self-attention, and approaches it as the receptive field size\nincreases. It is also equivalent in FLOPs and memory usage to Swin\nTransformer's shifted window attention given the same receptive field size,\nwhile being less constrained. Furthermore, NA includes local inductive biases,\nwhich eliminate the need for extra operations such as pixel shifts.\nExperimental results on NAT are competitive; NAT-Tiny reaches 83.2% top-1\naccuracy on ImageNet with only 4.3 GFLOPs and 28M parameters, 51.4% mAP on\nMS-COCO and 48.4% mIoU on ADE20k. We will open-source our checkpoints, training\nscript, configurations, and our CUDA kernel at:\nhttps://github.com/SHI-Labs/Neighborhood-Attention-Transformer .",
          "link": "http://arxiv.org/abs/2204.07143",
          "publishedOn": "2022-04-16T00:51:44.742Z",
          "wordCount": 592,
          "title": "Neighborhood Attention Transformer. (arXiv:2204.07143v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06643",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yaojie Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xingjian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qiang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pike_L/0/1/0/all/0/1\">Lee Pike</a>",
          "description": "We introduce NSEdit (neural-symbolic edit), a novel Transformer-based code\nrepair method. Given only the source code that contains bugs, NSEdit predicts\nan editing sequence that can fix the bugs. The edit grammar is formulated as a\nregular language, and the Transformer uses it as a neural-symbolic scripting\ninterface to generate editing programs. We modify the Transformer and add a\npointer network to select the edit locations. An ensemble of rerankers are\ntrained to re-rank the editing sequences generated by beam search. We fine-tune\nthe rerankers on the validation set to reduce over-fitting. NSEdit is evaluated\non various code repair datasets and achieved a new state-of-the-art accuracy\n($24.04\\%$) on the Tufano small dataset of the CodeXGLUE benchmark. NSEdit\nperforms robustly when programs vary from packages to packages and when buggy\nprograms are concrete. We conduct detailed analysis on our methods and\ndemonstrate the effectiveness of each component.",
          "link": "http://arxiv.org/abs/2204.06643",
          "publishedOn": "2022-04-16T00:51:44.733Z",
          "wordCount": 600,
          "title": "Fix Bugs with Transformer through a Neural-Symbolic Edit Grammar. (arXiv:2204.06643v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelli_K/0/1/0/all/0/1\">Khouloud Abdelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griesser_H/0/1/0/all/0/1\">Helmut Griesser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ehrle_P/0/1/0/all/0/1\">Peter Ehrle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tropschug_C/0/1/0/all/0/1\">Carsten Tropschug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pachnicke_S/0/1/0/all/0/1\">Stephan Pachnicke</a>",
          "description": "To reduce operation-and-maintenance expenses (OPEX) and to ensure optical\nnetwork survivability, optical network operators need to detect and diagnose\nfaults in a timely manner and with high accuracy. With the rapid advancement of\ntelemetry technology and data analysis techniques, data-driven approaches\nleveraging telemetry data to tackle the fault diagnosis problem have been\ngaining popularity due to their quick implementation and deployment. In this\npaper, we propose a novel multi-task learning model based on long short-term\nmemory (LSTM) to detect, locate, and estimate the reflectance of fiber\nreflective faults (events) including the connectors and the mechanical splices\nby extracting insights from monitored data obtained by the optical time domain\nreflectometry (OTDR) principle commonly used for troubleshooting of fiber optic\ncables or links. The experimental results prove that the proposed method: (i)\nachieves a good detection capability and high localization accuracy within\nshort measurement time even for low SNR values; and (ii) outperforms\nconventionally employed techniques.",
          "link": "http://arxiv.org/abs/2204.07058",
          "publishedOn": "2022-04-16T00:51:44.726Z",
          "wordCount": null,
          "title": "Reflective Fiber Faults Detection and Characterization Using Long-Short-Term Memory. (arXiv:2204.07058v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1802.03308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stolzenburg_F/0/1/0/all/0/1\">Frieder Stolzenburg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litz_S/0/1/0/all/0/1\">Sandra Litz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michael_O/0/1/0/all/0/1\">Olivia Michael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Obst_O/0/1/0/all/0/1\">Oliver Obst</a>",
          "description": "Recurrent neural networks are a powerful means to cope with time series. We\nshow how linear, i.e., linearly activated recurrent neural networks (LRNNs) can\napproximate any time-dependent function f(t) given by a number of function\nvalues. The approximation can effectively be learned by simply solving a linear\nequation system; no backpropagation or similar methods are needed. Furthermore,\nthe size of an LRNN can be reduced significantly in one step, after inspecting\nthe eigenvalues of the network transition matrix, by taking only the most\nrelevant components. Therefore, in contrast to others, we do not only learn\nnetwork weights but also the network architecture. LRNNs have interesting\nproperties: They end up in ellipse trajectories in the long run and allow the\nprediction of further values and compact representations of functions. We\ndemonstrate this by several experiments, among them multiple superimposed\noscillators (MSO), robotic soccer, and predicting stock prices. LRNNs\noutperform the previous state-of-the-art for the MSO task with a minimal number\nof units.",
          "link": "http://arxiv.org/abs/1802.03308",
          "publishedOn": "2022-04-16T00:51:44.702Z",
          "wordCount": 677,
          "title": "The Power of Linear Recurrent Neural Networks. (arXiv:1802.03308v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07136",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pozdnyakov_S/0/1/0/all/0/1\">Sergey N. Pozdnyakov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ceriotti_M/0/1/0/all/0/1\">Michele Ceriotti</a>",
          "description": "Graph neural networks (GNN) are very popular methods in machine learning and\nhave been applied very successfully to the prediction of the properties of\nmolecules and materials. First-order GNNs are well known to be incomplete,\ni.e., there exist graphs that are distinct but appear identical when seen\nthrough the lens of the GNN. More complicated schemes have thus been designed\nto increase their resolving power. Applications to molecules (and more\ngenerally, point clouds), however, add a geometric dimension to the problem.\nThe most straightforward and prevalent approach to construct graph\nrepresentation for molecules regards atoms as vertices in a graph and draws a\nbond between each pair of atoms within a chosen cutoff. Bonds can be decorated\nwith the distance between atoms, and the resulting \"distance graph NNs\" (dGNN)\nhave empirically demonstrated excellent resolving power and are widely used in\nchemical ML, with all known indistinguishable graphs being resolved in the\nfully-connected limit. Here we show that even for the restricted case of\nfully-connected graphs induced by 3D atom clouds dGNNs are not complete. We\nconstruct pairs of distinct point clouds that generate graphs that, for any\ncutoff radius, are equivalent based on a first-order Weisfeiler-Lehman test.\nThis class of degenerate structures includes chemically-plausible\nconfigurations, setting an ultimate limit to the expressive power of some of\nthe well-established GNN architectures for atomistic machine learning. Models\nthat explicitly use angular or directional information in the description of\natomic environments can resolve these degeneracies.",
          "link": "http://arxiv.org/abs/2201.07136",
          "publishedOn": "2022-04-16T00:51:44.678Z",
          "wordCount": 706,
          "title": "Incompleteness of graph convolutional neural networks for points clouds in three dimensions. (arXiv:2201.07136v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thibeau_Sutre_E/0/1/0/all/0/1\">Elina Thibeau-Sutre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collin_S/0/1/0/all/0/1\">Sasha Collin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burgos_N/0/1/0/all/0/1\">Ninon Burgos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colliot_O/0/1/0/all/0/1\">Olivier Colliot</a>",
          "description": "Deep learning methods have become very popular for the processing of natural\nimages, and were then successfully adapted to the neuroimaging field. As these\nmethods are non-transparent, interpretability methods are needed to validate\nthem and ensure their reliability. Indeed, it has been shown that deep learning\nmodels may obtain high performance even when using irrelevant features, by\nexploiting biases in the training set. Such undesirable situations can\npotentially be detected by using interpretability methods. Recently, many\nmethods have been proposed to interpret neural networks. However, this domain\nis not mature yet. Machine learning users face two major issues when aiming to\ninterpret their models: which method to choose, and how to assess its\nreliability? Here, we aim at providing answers to these questions by presenting\nthe most common interpretability methods and metrics developed to assess their\nreliability, as well as their applications and benchmarks in the neuroimaging\ncontext. Note that this is not an exhaustive survey: we aimed to focus on the\nstudies which we found to be the most representative and relevant.",
          "link": "http://arxiv.org/abs/2204.07005",
          "publishedOn": "2022-04-16T00:51:44.637Z",
          "wordCount": 637,
          "title": "Interpretability of Machine Learning Methods Applied to Neuroimaging. (arXiv:2204.07005v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05839",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Benny J. Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qiqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_M/0/1/0/all/0/1\">Matthew L. Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frey_N/0/1/0/all/0/1\">Nathan Frey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_J/0/1/0/all/0/1\">Joseph McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bestor_D/0/1/0/all/0/1\">David Bestor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yee_C/0/1/0/all/0/1\">Charles Yee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcand_W/0/1/0/all/0/1\">William Arcand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byun_C/0/1/0/all/0/1\">Chansup Byun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edelman_D/0/1/0/all/0/1\">Daniel Edelman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hubbell_M/0/1/0/all/0/1\">Matthew Hubbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1\">Michael Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kepner_J/0/1/0/all/0/1\">Jeremy Kepner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_A/0/1/0/all/0/1\">Anna Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michaleas_A/0/1/0/all/0/1\">Adam Michaleas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michaleas_P/0/1/0/all/0/1\">Peter Michaleas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milechin_L/0/1/0/all/0/1\">Lauren Milechin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mullen_J/0/1/0/all/0/1\">Julia Mullen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prout_A/0/1/0/all/0/1\">Andrew Prout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reuther_A/0/1/0/all/0/1\">Albert Reuther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosa_A/0/1/0/all/0/1\">Antonio Rosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowne_A/0/1/0/all/0/1\">Andrew Bowne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McEvoy_L/0/1/0/all/0/1\">Lindsey McEvoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Baolin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_D/0/1/0/all/0/1\">Devesh Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadepally_V/0/1/0/all/0/1\">Vijay Gadepally</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samsi_S/0/1/0/all/0/1\">Siddharth Samsi</a>",
          "description": "High-Performance Computing (HPC) centers and cloud providers support an\nincreasingly diverse set of applications on heterogenous hardware. As\nArtificial Intelligence (AI) and Machine Learning (ML) workloads have become an\nincreasingly larger share of the compute workloads, new approaches to optimized\nresource usage, allocation, and deployment of new AI frameworks are needed. By\nidentifying compute workloads and their utilization characteristics, HPC\nsystems may be able to better match available resources with the application\ndemand. By leveraging datacenter instrumentation, it may be possible to develop\nAI-based approaches that can identify workloads and provide feedback to\nresearchers and datacenter operators for improving operational efficiency. To\nenable this research, we released the MIT Supercloud Dataset, which provides\ndetailed monitoring logs from the MIT Supercloud cluster. This dataset includes\nCPU and GPU usage by jobs, memory usage, and file system logs. In this paper,\nwe present a workload classification challenge based on this dataset. We\nintroduce a labelled dataset that can be used to develop new approaches to\nworkload classification and present initial results based on existing\napproaches. The goal of this challenge is to foster algorithmic innovations in\nthe analysis of compute workloads that can achieve higher accuracy than\nexisting methods. Data and code will be made publicly available via the\nDatacenter Challenge website : https://dcc.mit.edu.",
          "link": "http://arxiv.org/abs/2204.05839",
          "publishedOn": "2022-04-16T00:51:44.629Z",
          "wordCount": 715,
          "title": "The MIT Supercloud Workload Classification Challenge. (arXiv:2204.05839v2 [cs.DC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadok_S/0/1/0/all/0/1\">Samir Sadok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leglaive_S/0/1/0/all/0/1\">Simon Leglaive</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Girin_L/0/1/0/all/0/1\">Laurent Girin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alameda_Pineda_X/0/1/0/all/0/1\">Xavier Alameda-Pineda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seguier_R/0/1/0/all/0/1\">Renaud S&#xe9;guier</a>",
          "description": "Understanding and controlling latent representations in deep generative\nmodels is a challenging yet important problem for analyzing, transforming and\ngenerating various types of data. In speech processing, inspiring from the\nanatomical mechanisms of phonation, the source-filter model considers that\nspeech signals are produced from a few independent and physically meaningful\ncontinuous latent factors, among which the fundamental frequency $f_0$ and the\nformants are of primary importance. In this work, we show that the\nsource-filter model of speech production naturally arises in the latent space\nof a variational autoencoder (VAE) trained in an unsupervised manner on a\ndataset of natural speech signals. Using only a few seconds of labeled speech\nsignals generated with an artificial speech synthesizer, we experimentally\nillustrate that $f_0$ and the formant frequencies are encoded in orthogonal\nsubspaces of the VAE latent space and we develop a weakly-supervised method to\naccurately and independently control these speech factors of variation within\nthe learned latent subspaces. Without requiring additional information such as\ntext or human-labeled data, this results in a deep generative model of speech\nspectrograms that is conditioned on $f_0$ and the formant frequencies, and\nwhich is applied to the transformation of speech signals.",
          "link": "http://arxiv.org/abs/2204.07075",
          "publishedOn": "2022-04-16T00:51:44.607Z",
          "wordCount": 657,
          "title": "Learning and controlling the source-filter representation of speech with a variational autoencoder. (arXiv:2204.07075v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07000",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bottcher_L/0/1/0/all/0/1\">Luis B&#xf6;ttcher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_H/0/1/0/all/0/1\">Hinrikus Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_B/0/1/0/all/0/1\">Bastian Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutat_P/0/1/0/all/0/1\">Philipp Lutat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trageser_M/0/1/0/all/0/1\">Marc Trageser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pohl_O/0/1/0/all/0/1\">Oliver Pohl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ulbig_A/0/1/0/all/0/1\">Andreas Ulbig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1\">Martin Grohe</a>",
          "description": "In this paper we propose a graph neural network architecture solving the AC\npower flow problem under realistic constraints. While the energy transition is\nchanging the energy industry to a digitalized and decentralized energy system,\nthe challenges are increasingly shifting to the distribution grid level to\nintegrate new loads and generation technologies. To ensure a save and resilient\noperation of distribution grids, AC power flow calculations are the means of\nchoice to determine grid operating limits or analyze grid asset utilization in\nplanning procedures. In our approach we demonstrate the development of a\nframework which makes use of graph neural networks to learn the physical\nconstraints of the power flow. We present our model architecture on which we\nperform unsupervised training to learn a general solution of the AC power flow\nformulation that is independent of the specific topologies and supply tasks\nused for training. Finally, we demonstrate, validate and discuss our results on\nmedium voltage benchmark grids.",
          "link": "http://arxiv.org/abs/2204.07000",
          "publishedOn": "2022-04-16T00:51:44.597Z",
          "wordCount": 605,
          "title": "Solving AC Power Flow with Graph Neural Networks under Realistic Constraints. (arXiv:2204.07000v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07110",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Sgarbossa_D/0/1/0/all/0/1\">Damiano Sgarbossa</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lupo_U/0/1/0/all/0/1\">Umberto Lupo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bitbol_A/0/1/0/all/0/1\">Anne-Florence Bitbol</a>",
          "description": "Computational models starting from large ensembles of evolutionarily related\nprotein sequences capture a representation of protein families and learn\nconstraints associated to protein structure and function. They thus open the\npossibility for generating novel sequences belonging to protein families.\nProtein language models trained on multiple sequence alignments, such as MSA\nTransformer, are highly attractive candidates to this end. We propose and test\nan iterative method that directly uses the masked language modeling objective\nto generate sequences using MSA Transformer. We demonstrate that the resulting\nsequences generally score better than those generated by Potts models, and even\nthan natural sequences, for homology, coevolution and structure-based measures.\nMoreover, MSA Transformer better reproduces the higher-order statistics and the\ndistribution of sequences in sequence space of natural data than Potts models,\nalthough Potts models better reproduce first- and second-order statistics. MSA\nTransformer is thus a strong candidate for protein sequence generation and\nprotein design.",
          "link": "http://arxiv.org/abs/2204.07110",
          "publishedOn": "2022-04-16T00:51:44.577Z",
          "wordCount": null,
          "title": "Generative power of a protein language model trained on multiple sequence alignments. (arXiv:2204.07110v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramazanli_I/0/1/0/all/0/1\">Ilqar Ramazanli</a>",
          "description": "The matrix completion problem has been studied broadly under many underlying\nconditions. The problem has been explored under adaptive or non-adaptive, exact\nor estimation, single-phase or multi-phase, and many other categories. In most\nof these cases, the observation cost of each entry is uniform and has the same\ncost across the columns. However, in many real-life scenarios, we could expect\nelements from distinct columns or distinct positions to have a different cost.\nIn this paper, we explore this generalization under adaptive conditions. We\napproach the problem under two different cost models. The first one is that\nentries from different columns have different observation costs, but, within\nthe same column, each entry has a uniform cost. The second one is any two entry\nhas different observation cost, despite being the same or different columns. We\nprovide complexity analysis of our algorithms and provide tightness guarantees.",
          "link": "http://arxiv.org/abs/2203.12120",
          "publishedOn": "2022-04-16T00:51:44.576Z",
          "wordCount": null,
          "title": "Matrix Completion with Heterogonous Cost. (arXiv:2203.12120v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haoran Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marmoret_A/0/1/0/all/0/1\">Axel Marmoret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;my E. Cohen</a>",
          "description": "Automatic Music Transcription, which consists in transforming an audio\nrecording of a musical performance into symbolic format, remains a difficult\nMusic Information Retrieval task. In this work, which focuses on piano\ntranscription, we propose a semi-supervised approach using low-rank matrix\nfactorization techniques, in particular Convolutive Nonnegative Matrix\nFactorization. In the semi-supervised setting, only a single recording of each\nindividual notes is required. We show on the MAPS dataset that the proposed\nsemi-supervised CNMF method performs better than state-of-the-art low-rank\nfactorization techniques and a little worse than supervised deep learning\nstate-of-the-art methods, while however suffering from generalization issues.",
          "link": "http://arxiv.org/abs/2202.04989",
          "publishedOn": "2022-04-16T00:51:44.570Z",
          "wordCount": null,
          "title": "Semi-Supervised Convolutive NMF for Automatic Piano Transcription. (arXiv:2202.04989v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Minh-Duong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang-Min Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1\">Quoc-Viet Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1\">Dinh Thai Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Diep N. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1\">Won-Joo Hwang</a>",
          "description": "Federated learning (FL) is a new artificial intelligence concept that enables\nInternet-of-Things (IoT) devices to learn a collaborative model without sending\nthe raw data to centralized nodes for processing. Despite numerous advantages,\nlow computing resources at IoT devices and high communication costs for\nexchanging model parameters make applications of FL in massive IoT networks\nvery limited. In this work, we develop a novel compression scheme for FL,\ncalled high-compression federated learning (HCFL), for very large scale IoT\nnetworks. HCFL can reduce the data load for FL processes without changing their\nstructure and hyperparameters. In this way, we not only can significantly\nreduce communication costs, but also make intensive learning processes more\nadaptable on low-computing resource IoT devices. Furthermore, we investigate a\nrelationship between the number of IoT devices and the convergence level of the\nFL model and thereby better assess the quality of the FL process. We\ndemonstrate our HCFL scheme in both simulations and mathematical analyses. Our\nproposed theoretical research can be used as a minimum level of satisfaction,\nproving that the FL process can achieve good performance when a determined\nconfiguration is met. Therefore, we show that HCFL is applicable in any\nFL-integrated networks with numerous IoT devices.",
          "link": "http://arxiv.org/abs/2204.06760",
          "publishedOn": "2022-04-16T00:51:44.567Z",
          "wordCount": null,
          "title": "HCFL: A High Compression Approach for Communication-Efficient Federated Learning in Very Large Scale IoT Networks. (arXiv:2204.06760v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07134",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Brini_A/0/1/0/all/0/1\">Alessio Brini</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Tedeschi_G/0/1/0/all/0/1\">Gabriele Tedeschi</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Tantari_D/0/1/0/all/0/1\">Daniele Tantari</a>",
          "description": "In this paper we analyze the effect of a policy recommendation on the\nperformances of an artificial interbank market. Financial institutions\nstipulate lending agreements following a public recommendation and their\nindividual information. The former, modeled by a reinforcement learning optimal\npolicy trying to maximize the long term fitness of the system, gathers\ninformation on the economic environment and directs economic actors to create\ncredit relationships based on the optimal choice between a low interest rate or\nhigh liquidity supply. The latter, based on the agents' balance sheet, allows\nto determine the liquidity supply and interest rate that the banks optimally\noffer on the market. Based on the combination between the public and the\nprivate signal, financial institutions create or cut their credit connections\nover time via a preferential attachment evolving procedure able to generate a\ndynamic network. Our results show that the emergence of a core-periphery\ninterbank network, combined with a certain level of homogeneity on the size of\nlenders and borrowers, are essential features to ensure the resilience of the\nsystem. Moreover, the reinforcement learning optimal policy recommendation\nplays a crucial role in mitigating systemic risk with respect to alternative\npolicy instruments.",
          "link": "http://arxiv.org/abs/2204.07134",
          "publishedOn": "2022-04-16T00:51:44.565Z",
          "wordCount": null,
          "title": "Reinforcement Learning Policy Recommendation for Interbank Network Stability. (arXiv:2204.07134v1 [econ.GN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.10610",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gao_L/0/1/0/all/0/1\">Long Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arefan_D/0/1/0/all/0/1\">Dooman Arefan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Panigrahy_A/0/1/0/all/0/1\">Ashok Panigrahy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_S/0/1/0/all/0/1\">Shandong Wu</a>",
          "description": "Medical image data are usually imbalanced across different classes. One-class\nclassification has attracted increasing attention to address the data imbalance\nproblem by distinguishing the samples of the minority class from the majority\nclass. Previous methods generally aim to either learn a new feature space to\nmap training samples together or to fit training samples by autoencoder-like\nmodels. These methods mainly focus on capturing either compact or descriptive\nfeatures, where the information of the samples of a given one class is not\nsufficiently utilized. In this paper, we propose a novel deep learning-based\nmethod to learn compact features by adding constraints on the bottleneck\nfeatures, and to preserve descriptive features by training an autoencoder at\nthe same time. Through jointly optimizing the constraining loss and the\nautoencoder's reconstruction loss, our method can learn more relevant features\nassociated with the given class, making the majority and minority samples more\ndistinguishable. Experimental results on three clinical datasets (including the\nMRI breast images, FFDM breast images and chest X-ray images) obtains\nstate-of-art performance compared to previous methods.",
          "link": "http://arxiv.org/abs/2111.10610",
          "publishedOn": "2022-04-16T00:51:44.564Z",
          "wordCount": null,
          "title": "Constrained Deep One-Class Feature Learning For Classifying Imbalanced Medical Images. (arXiv:2111.10610v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clinkinbeard_N/0/1/0/all/0/1\">Nicholus R. Clinkinbeard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_P/0/1/0/all/0/1\">Prof. Nicole N. Hashemi</a>",
          "description": "To improve predictive models for STEM applications, supplemental\nphysics-based features computed from input parameters are introduced into\nsingle and multiple layers of a deep neural network (DNN). While many studies\nfocus on informing DNNs with physics through differential equations or\nnumerical simulation, much may be gained through integration of simplified\nrelationships. To evaluate this hypothesis, a number of thin rectangular plates\nsimply-supported on all edges are simulated for five materials. With plate\ndimensions and material properties as input features and fundamental natural\nfrequency as the sole output, predictive performance of a purely data-driven\nDNN-based model is compared with models using additional inputs computed from\nsimplified physical relationships among baseline parameters, namely plate\nweight, modulus of rigidity, and shear modulus. To better understand the\nbenefit to model accuracy, these additional features are injected into various\nsingle and multiple DNN layers, and trained with four different dataset sizes.\nWhen these physics-enhanced models are evaluated against independent data of\nthe same materials and similar dimensions to the training sets, supplementation\nwith simplified physics-based parameters provides little reduction in\nprediction error over the baseline for models trained with dataset sizes of 60\nand greater, although small improvement from 19.3% to 16.1% occurs when trained\nwith a sparse size of 30. Conversely, notable accuracy gains occur when the\nindependent test data is of material and dimensions not conforming to the\ntraining set. Specifically, when physics-enhanced data is injected into\nmultiple DNN layers, reductions in error from 33.2% to 19.6%, 34.9% to 19.9%,\n35.8% to 22.4%, and 43.0% to 28.4% are achieved for training dataset sizes of\n261, 117, 60, and 30, respectively, demonstrating attainment of a degree of\ngeneralizability.",
          "link": "http://arxiv.org/abs/2204.06764",
          "publishedOn": "2022-04-16T00:51:44.563Z",
          "wordCount": null,
          "title": "Supplementation of deep neural networks with simplified physics-based features to increase model prediction accuracy. (arXiv:2204.06764v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sajnani_R/0/1/0/all/0/1\">Rahul Sajnani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poulenard_A/0/1/0/all/0/1\">Adrien Poulenard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_J/0/1/0/all/0/1\">Jivitesh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dua_R/0/1/0/all/0/1\">Radhika Dua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas J. Guibas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_S/0/1/0/all/0/1\">Srinath Sridhar</a>",
          "description": "Progress in 3D object understanding has relied on manually canonicalized\nshape datasets that contain instances with consistent position and orientation\n(3D pose). This has made it hard to generalize these methods to in-the-wild\nshapes, eg., from internet model collections or depth sensors. ConDor is a\nself-supervised method that learns to Canonicalize the 3D orientation and\nposition for full and partial 3D point clouds. We build on top of Tensor Field\nNetworks (TFNs), a class of permutation- and rotation-equivariant, and\ntranslation-invariant 3D networks. During inference, our method takes an unseen\nfull or partial 3D point cloud at an arbitrary pose and outputs an equivariant\ncanonical pose. During training, this network uses self-supervision losses to\nlearn the canonical pose from an un-canonicalized collection of full and\npartial 3D point clouds. ConDor can also learn to consistently co-segment\nobject parts without any supervision. Extensive quantitative results on four\nnew metrics show that our approach outperforms existing methods while enabling\nnew applications such as operation on depth images and annotation transfer.",
          "link": "http://arxiv.org/abs/2201.07788",
          "publishedOn": "2022-04-16T00:51:44.561Z",
          "wordCount": null,
          "title": "ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes. (arXiv:2201.07788v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06935",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1\">Zhijun Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schaeffer_H/0/1/0/all/0/1\">Hayden Schaeffer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ward_R/0/1/0/all/0/1\">Rachel Ward</a>",
          "description": "The spectra of random feature matrices provide essential information on the\nconditioning of the linear system used in random feature regression problems\nand are thus connected to the consistency and generalization of random feature\nmodels. Random feature matrices are asymmetric rectangular nonlinear matrices\ndepending on two input variables, the data and the weights, which can make\ntheir characterization challenging. We consider two settings for the two input\nvariables, either both are random variables or one is a random variable and the\nother is well-separated, i.e. there is a minimum distance between points. With\nconditions on the dimension, the complexity ratio, and the sampling variance,\nwe show that the singular values of these matrices concentrate near their full\nexpectation and near one with high-probability. In particular, since the\ndimension depends only on the logarithm of the number of random weights or the\nnumber of data points, our complexity bounds can be achieved even in moderate\ndimensions for many practical setting. The theoretical results are verified\nwith numerical experiments.",
          "link": "http://arxiv.org/abs/2204.06935",
          "publishedOn": "2022-04-16T00:51:44.559Z",
          "wordCount": null,
          "title": "Concentration of Random Feature Matrices in High-Dimensions. (arXiv:2204.06935v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Glushkovsky_A/0/1/0/all/0/1\">Alex Glushkovsky</a>",
          "description": "The research paper addresses linear decomposition of time series of\nnon-additive metrics that allows for the identification and interpretation of\ncontributing factors (input features) of variance. Non-additive metrics, such\nas ratios, are widely used in a variety of domains. It commonly requires\npreceding aggregations of underlying variables that are used to calculate the\nmetric of interest. The latest poses a dimensionality challenge when the input\nfeatures and underlying variables are formed as two-dimensional arrays along\nelements, such as account or customer identifications, and time points. It\nrules out direct modeling of the time series of a non-additive metric as a\nfunction of input features. The article discusses a five-step approach: (1)\nsegmentations of input features and the underlying variables of the metric that\nare supported by unsupervised autoencoders, (2) univariate or joint fittings of\nthe metric by the aggregated input features on the segmented domains, (3)\ntransformations of pre-screened input features according to the fitted models,\n(4) aggregation of the transformed features as time series, and (5) modelling\nof the metric time series as a sum of constrained linear effects of the\naggregated features. Alternatively, approximation by numerical differentiation\nhas been considered to linearize the metric. It allows for element level\nunivariate or joint modeling of step (2). The process of these analytical steps\nallows for a backward-looking explanatory decomposition of the metric as a sum\nof time series of the survived input features. The paper includes a synthetic\nexample that studies loss-to-balance monthly rates of a hypothetical retail\ncredit portfolio. To validate that no latent factors other than the survived\ninput features have significant impacts on the metric, Statistical Process\nControl has been introduced for the residual time series.",
          "link": "http://arxiv.org/abs/2204.06688",
          "publishedOn": "2022-04-16T00:51:44.558Z",
          "wordCount": null,
          "title": "Time Series of Non-Additive Metrics: Identification and Interpretation of Contributing Factors of Variance by Linear Decomposition. (arXiv:2204.06688v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01681",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Qasim_S/0/1/0/all/0/1\">Shah Rukh Qasim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chernyavskaya_N/0/1/0/all/0/1\">Nadezda Chernyavskaya</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kieseler_J/0/1/0/all/0/1\">Jan Kieseler</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Long_K/0/1/0/all/0/1\">Kenneth Long</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Viazlo_O/0/1/0/all/0/1\">Oleksandr Viazlo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pierini_M/0/1/0/all/0/1\">Maurizio Pierini</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nawaz_R/0/1/0/all/0/1\">Raheel Nawaz</a>",
          "description": "We present an end-to-end reconstruction algorithm to build particle\ncandidates from detector hits in next-generation granular calorimeters similar\nto that foreseen for the high-luminosity upgrade of the CMS detector. The\nalgorithm exploits a distance-weighted graph neural network, trained with\nobject condensation, a graph segmentation technique. Through a single-shot\napproach, the reconstruction task is paired with energy regression. We describe\nthe reconstruction performance in terms of efficiency as well as in terms of\nenergy resolution. In addition, we show the jet reconstruction performance of\nour method and discuss its inference computational cost. To our knowledge, this\nwork is the first-ever example of single-shot calorimetric reconstruction of\n${\\cal O}(1000)$ particles in high-luminosity conditions with 200 pileup.",
          "link": "http://arxiv.org/abs/2204.01681",
          "publishedOn": "2022-04-16T00:51:44.558Z",
          "wordCount": null,
          "title": "End-to-end multi-particle reconstruction in high occupancy imaging calorimeters with graph neural networks. (arXiv:2204.01681v2 [physics.ins-det] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Steinbach_P/0/1/0/all/0/1\">Peter Steinbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gernhardt_F/0/1/0/all/0/1\">Felicita Gernhardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanveer_M/0/1/0/all/0/1\">Mahnoor Tanveer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmerler_S/0/1/0/all/0/1\">Steve Schmerler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Starke_S/0/1/0/all/0/1\">Sebastian Starke</a>",
          "description": "With the availability of data, hardware, software ecosystem and relevant\nskill sets, the machine learning community is undergoing a rapid development\nwith new architectures and approaches appearing at high frequency every year.\nIn this article, we conduct an exemplary image classification study in order to\ndemonstrate how confidence intervals around accuracy measurements can greatly\nenhance the communication of research results as well as impact the reviewing\nprocess. In addition, we explore the hallmarks and limitations of this\napproximation. We discuss the relevance of this approach reflecting on a\nspotlight publication of ICLR22. A reproducible workflow is made available as\nan open-source adjoint to this publication. Based on our discussion, we make\nsuggestions for improving the authoring and reviewing process of machine\nlearning articles.",
          "link": "http://arxiv.org/abs/2204.05173",
          "publishedOn": "2022-04-16T00:51:44.558Z",
          "wordCount": null,
          "title": "Machine Learning State-of-the-Art with Uncertainties. (arXiv:2204.05173v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.03386",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadeghi_B/0/1/0/all/0/1\">Bashir Sadeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehdashtian_S/0/1/0/all/0/1\">Sepehr Dehdashtian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boddeti_V/0/1/0/all/0/1\">Vishnu Boddeti</a>",
          "description": "Many applications of representation learning, such as privacy-preservation,\nalgorithmic fairness, and domain adaptation, desire explicit control over\nsemantic information being discarded. This goal is formulated as satisfying two\nobjectives: maximizing utility for predicting a target attribute while\nsimultaneously being independent or invariant with respect to a known semantic\nattribute. Solutions to such problems lead to trade-offs between the two\nobjectives when they are competing with each other. While existing works study\nbounds on these trade-offs, three questions still remain outstanding:\n\\emph{What are the exact fundamental trade-offs between utility and\ninvariance?}, 2) \\emph{What is the optimal dimensionality of the\nrepresentation?}, and 3) \\emph{What are the encoders (mapping data to a\nrepresentation) that achieve the exact fundamental trade-offs and how can we\nestimate them from data?} This paper addresses these questions. We adopt a\nfunctional analysis perspective and derive closed-form solutions for the global\noptima of the underlying optimization problems under mild assumptions, which in\nturn yields closed formulae for the exact trade-offs, optimal representation\ndimensionality, and the corresponding encoders. We also numerically quantify\nthe trade-offs on representative problems and compare them to those achieved by\nbaseline invariant representation learning algorithms.",
          "link": "http://arxiv.org/abs/2109.03386",
          "publishedOn": "2022-04-16T00:51:44.557Z",
          "wordCount": null,
          "title": "Characterizing the Fundamental Trade-offs in Learning Invariant Representations. (arXiv:2109.03386v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.14683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skorokhodov_I/0/1/0/all/0/1\">Ivan Skorokhodov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tulyakov_S/0/1/0/all/0/1\">Sergey Tulyakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhoseiny_M/0/1/0/all/0/1\">Mohamed Elhoseiny</a>",
          "description": "Videos show continuous events, yet most $-$ if not all $-$ video synthesis\nframeworks treat them discretely in time. In this work, we think of videos of\nwhat they should be $-$ time-continuous signals, and extend the paradigm of\nneural representations to build a continuous-time video generator. For this, we\nfirst design continuous motion representations through the lens of positional\nembeddings. Then, we explore the question of training on very sparse videos and\ndemonstrate that a good generator can be learned by using as few as 2 frames\nper clip. After that, we rethink the traditional image + video discriminators\npair and design a holistic discriminator that aggregates temporal information\nby simply concatenating frames' features. This decreases the training cost and\nprovides richer learning signal to the generator, making it possible to train\ndirectly on 1024$^2$ videos for the first time. We build our model on top of\nStyleGAN2 and it is just ${\\approx}5\\%$ more expensive to train at the same\nresolution while achieving almost the same image quality. Moreover, our latent\nspace features similar properties, enabling spatial manipulations that our\nmethod can propagate in time. We can generate arbitrarily long videos at\narbitrary high frame rate, while prior work struggles to generate even 64\nframes at a fixed rate. Our model is tested on four modern 256$^2$ and one\n1024$^2$-resolution video synthesis benchmarks. In terms of sheer metrics, it\nperforms on average ${\\approx}30\\%$ better than the closest runner-up. Project\nwebsite: https://universome.github.io.",
          "link": "http://arxiv.org/abs/2112.14683",
          "publishedOn": "2022-04-16T00:51:44.556Z",
          "wordCount": null,
          "title": "StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.05842",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dwivedi_R/0/1/0/all/0/1\">Raaz Dwivedi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "We introduce kernel thinning, a new procedure for compressing a distribution\n$\\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given\na suitable reproducing kernel $\\mathbf{k}$ and $\\mathcal{O}(n^2)$ time, kernel\nthinning compresses an $n$-point approximation to $\\mathbb{P}$ into a\n$\\sqrt{n}$-point approximation with comparable worst-case integration error\nacross the associated reproducing kernel Hilbert space. With high probability,\nthe maximum discrepancy in integration error is\n$\\mathcal{O}_d(n^{-1/2}\\sqrt{\\log n})$ for compactly supported $\\mathbb{P}$ and\n$\\mathcal{O}_d(n^{-\\frac{1}{2}} (\\log n)^{(d+1)/2}\\sqrt{\\log\\log n})$ for\nsub-exponential $\\mathbb{P}$ on $\\mathbb{R}^d$. In contrast, an equal-sized\ni.i.d. sample from $\\mathbb{P}$ suffers $\\Omega(n^{-1/4})$ integration error.\nOur sub-exponential guarantees resemble the classical quasi-Monte Carlo error\nrates for uniform $\\mathbb{P}$ on $[0,1]^d$ but apply to general distributions\non $\\mathbb{R}^d$ and a wide range of common kernels. We use our results to\nderive explicit non-asymptotic maximum mean discrepancy bounds for Gaussian,\nMat\\'ern, and B-spline kernels and present two vignettes illustrating the\npractical benefits of kernel thinning over i.i.d. sampling and standard Markov\nchain Monte Carlo thinning, in dimensions $d=2$ through $100$.",
          "link": "http://arxiv.org/abs/2105.05842",
          "publishedOn": "2022-04-16T00:51:44.554Z",
          "wordCount": null,
          "title": "Kernel Thinning. (arXiv:2105.05842v7 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07034",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Leal_T/0/1/0/all/0/1\">Tiago Leal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lopes_F/0/1/0/all/0/1\">Fabio Lopes</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Teixeira_C/0/1/0/all/0/1\">Cesar Teixeira</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dourado_A/0/1/0/all/0/1\">Antonio Dourado</a>",
          "description": "Refractory epileptic patients can suffer a seizure at any moment. Seizure\nprediction would substantially improve their lives. In this work, based on\nscalp EEG and its transformation into images, the likelihood of an epileptic\nseizure occurring at any moment is computed using an average of the softmax\nlayer output (the likelihood) of a CNN, instead of the output of the\nclassification layer. Results show that by analyzing the likelihood and\nthresholding it, prediction has higher sensitivity or a lower FPR/h. The best\nthreshold for the likelihood was higher than 50% for 5 patients, and was lower\nfor the remaining 36. However, more testing is needed, especially in new\nseizures, to better assess the real performance of this method. This work is a\nproof of concept with a positive outlook.",
          "link": "http://arxiv.org/abs/2204.07034",
          "publishedOn": "2022-04-16T00:51:44.543Z",
          "wordCount": null,
          "title": "Epileptic Seizure Risk Assessment by Multi-Channel Imaging of the EEG. (arXiv:2204.07034v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.00514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moschella_L/0/1/0/all/0/1\">Luca Moschella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melzi_S/0/1/0/all/0/1\">Simone Melzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cosmo_L/0/1/0/all/0/1\">Luca Cosmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maggioli_F/0/1/0/all/0/1\">Filippo Maggioli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litany_O/0/1/0/all/0/1\">Or Litany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ovsjanikov_M/0/1/0/all/0/1\">Maks Ovsjanikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas Guibas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodola_E/0/1/0/all/0/1\">Emanuele Rodol&#xe0;</a>",
          "description": "Spectral geometric methods have brought revolutionary changes to the field of\ngeometry processing. Of particular interest is the study of the Laplacian\nspectrum as a compact, isometry and permutation-invariant representation of a\nshape. Some recent works show how the intrinsic geometry of a full shape can be\nrecovered from its spectrum, but there are approaches that consider the more\nchallenging problem of recovering the geometry from the spectral information of\npartial shapes. In this paper, we propose a possible way to fill this gap. We\nintroduce a learning-based method to estimate the Laplacian spectrum of the\nunion of partial non-rigid 3D shapes, without actually computing the 3D\ngeometry of the union or any correspondence between those partial shapes. We do\nso by operating purely in the spectral domain and by defining the union\noperation between short sequences of eigenvalues. We show that the approximated\nunion spectrum can be used as-is to reconstruct the complete geometry [MRC*19],\nperform region localization on a template [RTO*19] and retrieve shapes from a\ndatabase, generalizing ShapeDNA [RWP06] to work with partialities. Working with\neigenvalues allows us to deal with unknown correspondence, different sampling,\nand different discretizations (point clouds and meshes alike), making this\noperation especially robust and general. Our approach is data-driven and can\ngeneralize to isometric and non-isometric deformations of the surface, as long\nas these stay within the same semantic class (e.g., human bodies or horses), as\nwell as to partiality artifacts not seen at training time.",
          "link": "http://arxiv.org/abs/2104.00514",
          "publishedOn": "2022-04-16T00:51:44.543Z",
          "wordCount": null,
          "title": "Learning Spectral Unions of Partial Deformable 3D Shapes. (arXiv:2104.00514v2 [cs.GR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04517",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khan_Z/0/1/0/all/0/1\">Zohaib Amjad Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beghdadi_A/0/1/0/all/0/1\">Azeddine Beghdadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kaaniche_M/0/1/0/all/0/1\">Mounir Kaaniche</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheikh_F/0/1/0/all/0/1\">Faouzi Alaya Cheikh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gharbi_O/0/1/0/all/0/1\">Osama Gharbi</a>",
          "description": "Video quality assessment is a challenging problem having a critical\nsignificance in the context of medical imaging. For instance, in laparoscopic\nsurgery, the acquired video data suffers from different kinds of distortion\nthat not only hinder surgery performance but also affect the execution of\nsubsequent tasks in surgical navigation and robotic surgeries. For this reason,\nwe propose in this paper neural network-based approaches for distortion\nclassification as well as quality prediction. More precisely, a Residual\nNetwork (ResNet) based approach is firstly developed for simultaneous ranking\nand classification task. Then, this architecture is extended to make it\nappropriate for the quality prediction task by using an additional Fully\nConnected Neural Network (FCNN). To train the overall architecture (ResNet and\nFCNN models), transfer learning and end-to-end learning approaches are\ninvestigated. Experimental results, carried out on a new laparoscopic video\nquality database, have shown the efficiency of the proposed methods compared to\nrecent conventional and deep learning based approaches.",
          "link": "http://arxiv.org/abs/2202.04517",
          "publishedOn": "2022-04-16T00:51:44.542Z",
          "wordCount": null,
          "title": "A Neural Network based Framework for Effective Laparoscopic Video Quality Assessment. (arXiv:2202.04517v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blau_A/0/1/0/all/0/1\">Ari Blau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gebhardt_C/0/1/0/all/0/1\">Christoph Gebhardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendesky_A/0/1/0/all/0/1\">Andres Bendesky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paninski_L/0/1/0/all/0/1\">Liam Paninski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Anqi Wu</a>",
          "description": "Multi-animal pose estimation is essential for studying animals' social\nbehaviors in neuroscience and neuroethology. Advanced approaches have been\nproposed to support multi-animal estimation and achieve state-of-the-art\nperformance. However, these models rarely exploit unlabeled data during\ntraining even though real world applications have exponentially more unlabeled\nframes than labeled frames. Manually adding dense annotations for a large\nnumber of images or videos is costly and labor-intensive, especially for\nmultiple instances. Given these deficiencies, we propose a novel\nsemi-supervised architecture for multi-animal pose estimation, leveraging the\nabundant structures pervasive in unlabeled frames in behavior videos to enhance\ntraining, which is critical for sparsely-labeled problems. The resulting\nalgorithm will provide superior multi-animal pose estimation results on three\nanimal experiments compared to the state-of-the-art baseline and exhibits more\npredictive power in sparsely-labeled data regimes.",
          "link": "http://arxiv.org/abs/2204.07072",
          "publishedOn": "2022-04-16T00:51:44.541Z",
          "wordCount": null,
          "title": "SemiMultiPose: A Semi-supervised Multi-animal Pose Estimation Framework. (arXiv:2204.07072v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wysocki_O/0/1/0/all/0/1\">Oskar Wysocki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zili Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ORegan_P/0/1/0/all/0/1\">Paul O&#x27;Regan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_D/0/1/0/all/0/1\">Deborah Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wysocka_M/0/1/0/all/0/1\">Magdalena Wysocka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1\">D&#xf3;nal Landers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andr&#xe9; Freitas</a>",
          "description": "BioBERT and BioMegatron are Transformers models adapted for the biomedical\ndomain based on publicly available biomedical corpora. As such, they have the\npotential to encode large-scale biological knowledge. We investigate the\nencoding and representation of biological knowledge in these models, and its\npotential utility to support inference in cancer precision medicine - namely,\nthe interpretation of the clinical significance of genomic alterations. We\ncompare the performance of different transformer baselines; we use probing to\ndetermine the consistency of encodings for distinct entities; and we use\nclustering methods to compare and contrast the internal properties of the\nembeddings for genes, variants, drugs and diseases. We show that these models\ndo indeed encode biological knowledge, although some of this is lost in\nfine-tuning for specific tasks. Finally, we analyse how the models behave with\nregard to biases and imbalances in the dataset.",
          "link": "http://arxiv.org/abs/2202.02432",
          "publishedOn": "2022-04-16T00:51:44.530Z",
          "wordCount": null,
          "title": "Transformers and the representation of biomedical background knowledge. (arXiv:2202.02432v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_M/0/1/0/all/0/1\">Madan Ravi Ganesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sekeh_S/0/1/0/all/0/1\">Salimeh Yasaei Sekeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corso_J/0/1/0/all/0/1\">Jason J. Corso</a>",
          "description": "Raw deep neural network (DNN) performance is not enough; in real-world\nsettings, computational load, training efficiency and adversarial security are\njust as or even more important. We propose to simultaneously tackle\nPerformance, Efficiency, and Robustness, using our proposed algorithm Q-TART,\nQuickly Train for Adversarial Robustness and in-Transferability. Q-TART follows\nthe intuition that samples highly susceptible to noise strongly affect the\ndecision boundaries learned by DNNs, which in turn degrades their performance\nand adversarial susceptibility. By identifying and removing such samples, we\ndemonstrate improved performance and adversarial robustness while using only a\nsubset of the training data. Through our experiments we highlight Q-TART's high\nperformance across multiple Dataset-DNN combinations, including ImageNet, and\nprovide insights into the complementary behavior of Q-TART alongside existing\nadversarial training approaches to increase robustness by over 1.3% while using\nup to 17.9% less training time.",
          "link": "http://arxiv.org/abs/2204.07024",
          "publishedOn": "2022-04-16T00:51:44.527Z",
          "wordCount": null,
          "title": "Q-TART: Quickly Training for Adversarial Robustness and in-Transferability. (arXiv:2204.07024v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jikuan Qian</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Rui Li</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mingyuan Luo</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zehui Lin</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Hong_W/0/1/0/all/0/1\">Wenhui Hong</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ruobing Huang</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Haining Fan</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Ni_D/0/1/0/all/0/1\">Dong Ni</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jun Cheng</a> (1,2 and 3) ((1) aNational-Regional Key Technology Engineering Laboratory for Medical Ultrasound, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China, (2) Medical Ultrasound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, China, (3) Marshall Laboratory of Biomedical Engineering, Shenzhen University, Shenzhen, China, (4) Qinghai University Affiliated Hospital, Xining, Qinghai, China)",
          "description": "Different from handcrafted features, deep neural networks can automatically\nlearn task-specific features from data. Due to this data-driven nature, they\nhave achieved remarkable success in various areas. However, manual design and\nselection of suitable network architectures are time-consuming and require\nsubstantial effort of human experts. To address this problem, researchers have\nproposed neural architecture search (NAS) algorithms which can automatically\ngenerate network architectures but suffer from heavy computational cost and\ninstability if searching from scratch. In this paper, we propose a hybrid NAS\nframework for ultrasound (US) image classification and segmentation. The hybrid\nframework consists of a pre-trained backbone and several searched cells (i.e.,\nnetwork building blocks), which takes advantage of the strengths of both NAS\nand the expert knowledge from existing convolutional neural networks.\nSpecifically, two effective and lightweight operations, a mixed depth-wise\nconvolution operator and a squeeze-and-excitation block, are introduced into\nthe candidate operations to enhance the variety and capacity of the searched\ncells. These two operations not only decrease model parameters but also boost\nnetwork performance. Moreover, we propose a re-aggregation strategy for the\nsearched cells, aiming to further improve the performance for different vision\ntasks. We tested our method on two large US image datasets, including a 9-class\nechinococcosis dataset containing 9566 images for classification and an ovary\ndataset containing 3204 images for segmentation. Ablation experiments and\ncomparison with other handcrafted or automatically searched architectures\ndemonstrate that our method can generate more powerful and lightweight models\nfor the above US image classification and segmentation tasks.",
          "link": "http://arxiv.org/abs/2204.06697",
          "publishedOn": "2022-04-16T00:51:44.490Z",
          "wordCount": null,
          "title": "HASA: Hybrid Architecture Search with Aggregation Strategy for Echinococcosis Classification and Ovary Segmentation in Ultrasound Images. (arXiv:2204.06697v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caillon_A/0/1/0/all/0/1\">Antoine Caillon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esling_P/0/1/0/all/0/1\">Philippe Esling</a>",
          "description": "Deep learning models are mostly used in an offline inference fashion.\nHowever, this strongly limits the use of these models inside audio generation\nsetups, as most creative workflows are based on real-time digital signal\nprocessing. Although approaches based on recurrent networks can be naturally\nadapted to this buffer-based computation, the use of convolutions still poses\nsome serious challenges. To tackle this issue, the use of causal streaming\nconvolutions have been proposed. However, this requires specific complexified\ntraining and can impact the resulting audio quality.\n\nIn this paper, we introduce a new method allowing to produce non-causal\nstreaming models. This allows to make any convolutional model compatible with\nreal-time buffer-based processing. As our method is based on a post-training\nreconfiguration of the model, we show that it is able to transform models\ntrained without causal constraints into a streaming model. We show how our\nmethod can be adapted to fit complex architectures with parallel branches. To\nevaluate our method, we apply it on the recent RAVE model, which provides\nhigh-quality real-time audio synthesis. We test our approach on multiple music\nand speech datasets and show that it is faster than overlap-add methods, while\nhaving no impact on the generation quality. Finally, we introduce two\nopen-source implementation of our work as Max/MSP and PureData externals, and\nas a VST audio plugin. This allows to endow traditional digital audio\nworkstation with real-time neural audio synthesis on a laptop CPU.",
          "link": "http://arxiv.org/abs/2204.07064",
          "publishedOn": "2022-04-16T00:51:44.489Z",
          "wordCount": null,
          "title": "Streamable Neural Audio Synthesis With Non-Causal Convolutions. (arXiv:2204.07064v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06931",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Braeu_F/0/1/0/all/0/1\">Fabian A. Braeu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thiery_A/0/1/0/all/0/1\">Alexandre H. Thi&#xe9;ry</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tun_T/0/1/0/all/0/1\">Tin A. Tun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kadziauskiene_A/0/1/0/all/0/1\">Aiste Kadziauskiene</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barbastathis_G/0/1/0/all/0/1\">George Barbastathis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aung_T/0/1/0/all/0/1\">Tin Aung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Girard_M/0/1/0/all/0/1\">Micha&#xeb;l J.A. Girard</a>",
          "description": "Purpose: The optic nerve head (ONH) undergoes complex and deep 3D\nmorphological changes during the development and progression of glaucoma.\nOptical coherence tomography (OCT) is the current gold standard to visualize\nand quantify these changes, however the resulting 3D deep-tissue information\nhas not yet been fully exploited for the diagnosis and prognosis of glaucoma.\nTo this end, we aimed: (1) To compare the performance of two relatively recent\ngeometric deep learning techniques in diagnosing glaucoma from a single OCT\nscan of the ONH; and (2) To identify the 3D structural features of the ONH that\nare critical for the diagnosis of glaucoma.\n\nMethods: In this study, we included a total of 2,247 non-glaucoma and 2,259\nglaucoma scans from 1,725 subjects. All subjects had their ONHs imaged in 3D\nwith Spectralis OCT. All OCT scans were automatically segmented using deep\nlearning to identify major neural and connective tissues. Each ONH was then\nrepresented as a 3D point cloud. We used PointNet and dynamic graph\nconvolutional neural network (DGCNN) to diagnose glaucoma from such 3D ONH\npoint clouds and to identify the critical 3D structural features of the ONH for\nglaucoma diagnosis.\n\nResults: Both the DGCNN (AUC: 0.97$\\pm$0.01) and PointNet (AUC:\n0.95$\\pm$0.02) were able to accurately detect glaucoma from 3D ONH point\nclouds. The critical points formed an hourglass pattern with most of them\nlocated in the inferior and superior quadrant of the ONH.\n\nDiscussion: The diagnostic accuracy of both geometric deep learning\napproaches was excellent. Moreover, we were able to identify the critical 3D\nstructural features of the ONH for glaucoma diagnosis that tremendously\nimproved the transparency and interpretability of our method. Consequently, our\napproach may have strong potential to be used in clinical applications for the\ndiagnosis and prognosis of a wide range of ophthalmic disorders.",
          "link": "http://arxiv.org/abs/2204.06931",
          "publishedOn": "2022-04-16T00:51:44.422Z",
          "wordCount": null,
          "title": "Geometric Deep Learning to Identify the Critical 3D Structural Features of the Optic Nerve Head for Glaucoma Diagnosis. (arXiv:2204.06931v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guodao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Band_S/0/1/0/all/0/1\">Shahab S. Band</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ardabili_S/0/1/0/all/0/1\">Sina Ardabili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_K/0/1/0/all/0/1\">Kwok-Wing Chau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mosavi_A/0/1/0/all/0/1\">Amir Mosavi</a>",
          "description": "In this research, dew point temperature (DPT) is simulated using the\ndata-driven approach. Adaptive Neuro-Fuzzy Inference System (ANFIS) is utilized\nas a data-driven technique to forecast this parameter at Tabriz in East\nAzerbaijan. Various input patterns, namely T min, T max, and T mean, are\nutilized for training the architecture whilst DPT is the model's output. The\nfindings indicate that, in general, ANFIS method is capable of identifying data\npatterns with a high degree of accuracy. However, the approach demonstrates\nthat processing time and computer resources may substantially increase by\nadding additional functions. Based on the results, the number of iterations and\ncomputing resources might change dramatically if new functionalities are\nincluded. As a result, tuning parameters have to be optimized inside the method\nframework. The findings demonstrate a high agreement between results by the\ndata-driven technique (machine learning method) and the observed data. Using\nthis prediction toolkit, DPT can be adequately forecasted solely based on the\ntemperature distribution of Tabriz. This kind of modeling is extremely\npromising for predicting DPT at various sites. Besides, this study thoroughly\ncompares the Bilayered Neural Network (BNN) and ANFIS models on various scales.\nWhilst the ANFIS model is extremely stable for almost all numbers of membership\nfunctions, the BNN model is highly sensitive to this scale factor to predict\nDPT.",
          "link": "http://arxiv.org/abs/2202.12256",
          "publishedOn": "2022-04-16T00:51:44.422Z",
          "wordCount": null,
          "title": "Integration of neural network and fuzzy logic decision making compared with bilayered neural network in the simulation of daily dew point temperature. (arXiv:2202.12256v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_G/0/1/0/all/0/1\">Geunseob Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_R/0/1/0/all/0/1\">Rahul Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hidey_C/0/1/0/all/0/1\">Chris Hidey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1\">Shachi Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Aditya Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_P/0/1/0/all/0/1\">Pararth Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rushin Shah</a>",
          "description": "Semantic parsing (SP) is a core component of modern virtual assistants like\nGoogle Assistant and Amazon Alexa. While sequence-to-sequence-based\nauto-regressive (AR) approaches are common for conversational semantic parsing,\nrecent studies employ non-autoregressive (NAR) decoders and reduce inference\nlatency while maintaining competitive parsing quality. However, a major\ndrawback of NAR decoders is the difficulty of generating top-k (i.e., k-best)\noutputs with approaches such as beam search. To address this challenge, we\npropose a novel NAR semantic parser that introduces intent conditioning on the\ndecoder. Inspired by the traditional intent and slot tagging parsers, we\ndecouple the top-level intent prediction from the rest of a parse. As the\ntop-level intent largely governs the syntax and semantics of a parse, the\nintent conditioning allows the model to better control beam search and improves\nthe quality and diversity of top-k outputs. We introduce a hybrid\nteacher-forcing approach to avoid training and inference mismatch. We evaluate\nthe proposed NAR on conversational SP datasets, TOP & TOPv2. Like the existing\nNAR models, we maintain the O(1) decoding time complexity while generating more\ndiverse outputs and improving the top-3 exact match (EM) by 2.4 points. In\ncomparison with AR models, our model speeds up beam search inference by 6.7\ntimes on CPU with competitive top-k EM.",
          "link": "http://arxiv.org/abs/2204.06748",
          "publishedOn": "2022-04-16T00:51:44.421Z",
          "wordCount": null,
          "title": "Improving Top-K Decoding for Non-Autoregressive Semantic Parsing via Intent Conditioning. (arXiv:2204.06748v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seiler_M/0/1/0/all/0/1\">Moritz Vinzent Seiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prager_R/0/1/0/all/0/1\">Raphael Patrick Prager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerschke_P/0/1/0/all/0/1\">Pascal Kerschke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trautmann_H/0/1/0/all/0/1\">Heike Trautmann</a>",
          "description": "Exploratory Landscape Analysis is a powerful technique for numerically\ncharacterizing landscapes of single-objective continuous optimization problems.\nLandscape insights are crucial both for problem understanding as well as for\nassessing benchmark set diversity and composition. Despite the irrefutable\nusefulness of these features, they suffer from their own ailments and\ndownsides. Hence, in this work we provide a collection of different approaches\nto characterize optimization landscapes. Similar to conventional landscape\nfeatures, we require a small initial sample. However, instead of computing\nfeatures based on that sample, we develop alternative representations of the\noriginal sample. These range from point clouds to 2D images and, therefore, are\nentirely feature-free. We demonstrate and validate our devised methods on the\nBBOB testbed and predict, with the help of Deep Learning, the high-level,\nexpert-based landscape properties such as the degree of multimodality and the\nexistence of funnel structures. The quality of our approaches is on par with\nmethods relying on the traditional landscape features. Thereby, we provide an\nexciting new perspective on every research area which utilizes problem\ninformation such as problem understanding and algorithm design as well as\nautomated algorithm configuration and selection.",
          "link": "http://arxiv.org/abs/2204.05752",
          "publishedOn": "2022-04-16T00:51:44.417Z",
          "wordCount": null,
          "title": "A Collection of Deep Learning-based Feature-Free Approaches for Characterizing Single-Objective Continuous Fitness Landscapes. (arXiv:2204.05752v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01142",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Darling_R/0/1/0/all/0/1\">R. W. R. Darling</a>, <a href=\"http://arxiv.org/find/math/1/au:+Emanuello_J/0/1/0/all/0/1\">John A. Emanuello</a>, <a href=\"http://arxiv.org/find/math/1/au:+Purvine_E/0/1/0/all/0/1\">Emilie Purvine</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ridley_A/0/1/0/all/0/1\">Ahmad Ridley</a>",
          "description": "Topological Data Analysis (TDA) is a rigorous framework that borrows\ntechniques from geometric and algebraic topology, category theory, and\ncombinatorics in order to study the \"shape\" of such complex high-dimensional\ndata. Research in this area has grown significantly over the last several years\nbringing a deeply rooted theory to bear on practical applications in areas such\nas genomics, natural language processing, medicine, cybersecurity, energy, and\nclimate change. Within some of these areas, TDA has also been used to augment\nAI and ML techniques.\n\nWe believe there is further utility to be gained in this space that can be\nfacilitated by a workshop bringing together experts (both theorists and\npractitioners) and non-experts. Currently there is an active community of pure\nmathematicians with research interests in developing and exploring the\ntheoretical and computational aspects of TDA. Applied mathematicians and other\npractitioners are also present in community but do not represent a majority.\nThis speaks to the primary aim of this workshop which is to grow a wider\ncommunity of interest in TDA. By fostering meaningful exchanges between these\ngroups, from across the government, academia, and industry, we hope to create\nnew synergies that can only come through building a mutual comprehensive\nawareness of the problem and solution spaces.",
          "link": "http://arxiv.org/abs/2204.01142",
          "publishedOn": "2022-04-16T00:51:44.416Z",
          "wordCount": null,
          "title": "Proceedings of TDA: Applications of Topological Data Analysis to Data Science, Artificial Intelligence, and Machine Learning Workshop at SDM 2022. (arXiv:2204.01142v2 [math.AT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sedova_A/0/1/0/all/0/1\">Anastasiia Sedova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1\">Benjamin Roth</a>",
          "description": "A way to overcome expensive and time-consuming manual data labeling is weak\nsupervision - automatic annotation of data samples via a predefined set of\nlabeling functions (LFs), rule-based mechanisms that generate potentially\nerroneous labels. In this work, we investigate noise reduction techniques for\nweak supervision based on the principle of k-fold cross-validation. In\nparticular, we extend two frameworks for detecting the erroneous samples in\nmanually annotated data to the weakly supervised setting. Our methods profit\nfrom leveraging the information about matching LFs and detect noisy samples\nmore accurately. We also introduce a new algorithm for denoising the weakly\nannotated data called ULF, that refines the allocation of LFs to classes by\nestimating the reliable LFs-to-classes joint matrix. Evaluation on several\ndatasets shows that ULF successfully improves weakly supervised learning\nwithout using any manually labeled data.",
          "link": "http://arxiv.org/abs/2204.06863",
          "publishedOn": "2022-04-16T00:51:44.414Z",
          "wordCount": null,
          "title": "ULF: Unsupervised Labeling Function Correction using Cross-Validation for Weak Supervision. (arXiv:2204.06863v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.06546",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Choi_S/0/1/0/all/0/1\">Soonbeom Choi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nam_J/0/1/0/all/0/1\">Juhan Nam</a>",
          "description": "Recent studies in singing voice synthesis have achieved high-quality results\nleveraging advances in text-to-speech models based on deep neural networks. One\nof the main issues in training singing voice synthesis models is that they\nrequire melody and lyric labels to be temporally aligned with audio data. The\ntemporal alignment is a time-exhausting manual work in preparing for the\ntraining data. To address the issue, we propose a melody-unsupervision model\nthat requires only audio-and-lyrics pairs without temporal alignment in\ntraining time but generates singing voice audio given a melody and lyrics input\nin inference time. The proposed model is composed of a phoneme classifier and a\nsinging voice generator jointly trained in an end-to-end manner. The model can\nbe fine-tuned by adjusting the amount of supervision with temporally aligned\nmelody labels. Through experiments in melody-unsupervision and semi-supervision\nsettings, we compare the audio quality of synthesized singing voice. We also\nshow that the proposed model is capable of being trained with speech audio and\ntext labels but can generate singing voice in inference time.",
          "link": "http://arxiv.org/abs/2110.06546",
          "publishedOn": "2022-04-16T00:51:44.414Z",
          "wordCount": null,
          "title": "A Melody-Unsupervision Model for Singing Voice Synthesis. (arXiv:2110.06546v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.01511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Honari_S/0/1/0/all/0/1\">Sina Honari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constantin_V/0/1/0/all/0/1\">Victor Constantin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhodin_H/0/1/0/all/0/1\">Helge Rhodin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1\">Mathieu Salzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "In this paper we propose an unsupervised learning method to extract temporal\ninformation on monocular videos, where we detect and encode subject of interest\nin each frame and leverage contrastive self-supervised (CSS) learning to\nextract rich latent vectors. Instead of simply treating the latent features of\nnearby frames as positive pairs and those of temporally-distant ones as\nnegative pairs as in other CSS approaches, we explicitly disentangle each\nlatent vector into a time-variant component and a time-invariant one. We then\nshow that applying CSS only to the time-variant features and encouraging a\ngradual transition on them between nearby and away frames while also\nreconstructing the input, extract rich temporal features into the time-variant\ncomponent, well-suited for human pose estimation. Our approach reduces error by\nabout 50\\% compared to the standard CSS strategies, outperforms other\nunsupervised single-view methods and matches the performance of multi-view\ntechniques.",
          "link": "http://arxiv.org/abs/2012.01511",
          "publishedOn": "2022-04-16T00:51:44.412Z",
          "wordCount": null,
          "title": "Unsupervised Temporal Learning on Monocular Videos for 3D Human Pose Estimation. (arXiv:2012.01511v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1\">Haewon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>",
          "description": "We investigate the fairness concerns of training a machine learning model\nusing data with missing values. Even though there are a number of fairness\nintervention methods in the literature, most of them require a complete\ntraining set as input. In practice, data can have missing values, and data\nmissing patterns can depend on group attributes (e.g. gender or race). Simply\napplying off-the-shelf fair learning algorithms to an imputed dataset may lead\nto an unfair model. In this paper, we first theoretically analyze different\nsources of discrimination risks when training with an imputed dataset. Then, we\npropose an integrated approach based on decision trees that does not require a\nseparate process of imputation and learning. Instead, we train a tree with\nmissing incorporated as attribute (MIA), which does not require explicit\nimputation, and we optimize a fairness-regularized objective function. We\ndemonstrate that our approach outperforms existing fairness intervention\nmethods applied to an imputed dataset, through several experiments on\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2109.10431",
          "publishedOn": "2022-04-16T00:51:44.410Z",
          "wordCount": null,
          "title": "Fairness without Imputation: A Decision Tree Approach for Fair Prediction with Missing Values. (arXiv:2109.10431v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05745",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lew_T/0/1/0/all/0/1\">Thomas Lew</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Janson_L/0/1/0/all/0/1\">Lucas Janson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bonalli_R/0/1/0/all/0/1\">Riccardo Bonalli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>",
          "description": "In this work, we analyze an efficient sampling-based algorithm for\ngeneral-purpose reachability analysis, which remains a notoriously challenging\nproblem with applications ranging from neural network verification to safety\nanalysis of dynamical systems. By sampling inputs, evaluating their images in\nthe true reachable set, and taking their $\\epsilon$-padded convex hull as a set\nestimator, this algorithm applies to general problem settings and is simple to\nimplement. Our main contribution is the derivation of asymptotic and\nfinite-sample accuracy guarantees using random set theory. This analysis\ninforms algorithmic design to obtain an $\\epsilon$-close reachable set\napproximation with high probability, provides insights into which reachability\nproblems are most challenging, and motivates safety-critical applications of\nthe technique. On a neural network verification task, we show that this\napproach is more accurate and significantly faster than prior work. Informed by\nour analysis, we also design a robust model predictive controller that we\ndemonstrate in hardware experiments.",
          "link": "http://arxiv.org/abs/2112.05745",
          "publishedOn": "2022-04-16T00:51:44.410Z",
          "wordCount": null,
          "title": "A Simple and Efficient Sampling-based Algorithm for General Reachability Analysis. (arXiv:2112.05745v3 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junxiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_D/0/1/0/all/0/1\">Debabrota Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trummer_I/0/1/0/all/0/1\">Immanuel Trummer</a>",
          "description": "In black-box optimization problems, we aim to maximize an unknown objective\nfunction, where the function is only accessible through feedbacks of an\nevaluation or simulation oracle. In real-life, the feedbacks of such oracles\nare often noisy and available after some unknown delay that may depend on the\ncomputation time of the oracle. Additionally, if the exact evaluations are\nexpensive but coarse approximations are available at a lower cost, the\nfeedbacks can have multi-fidelity. In order to address this problem, we propose\na generic extension of hierarchical optimistic tree search (HOO), called\nProCrastinated Tree Search (PCTS), that flexibly accommodates a delay and\nnoise-tolerant bandit algorithm. We provide a generic proof technique to\nquantify regret of PCTS under delayed, noisy, and multi-fidelity feedbacks.\nSpecifically, we derive regret bounds of PCTS enabled with delayed-UCB1 (DUCB1)\nand delayed-UCB-V (DUCBV) algorithms. Given a horizon $T$, PCTS retains the\nregret bound of non-delayed HOO for expected delay of $O(\\log T)$ and worsens\nby $O(T^{\\frac{1-\\alpha}{d+2}})$ for expected delays of $O(T^{1-\\alpha})$ for\n$\\alpha \\in (0,1]$. We experimentally validate on multiple synthetic functions\nand hyperparameter tuning problems that PCTS outperforms the state-of-the-art\nblack-box optimization methods for feedbacks with different noise levels,\ndelays, and fidelity.",
          "link": "http://arxiv.org/abs/2110.07232",
          "publishedOn": "2022-04-16T00:51:44.409Z",
          "wordCount": null,
          "title": "Procrastinated Tree Search: Black-box Optimization with Delayed, Noisy, and Multi-Fidelity Feedback. (arXiv:2110.07232v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.05821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huaulme_A/0/1/0/all/0/1\">Arnaud Huaulm&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harada_K/0/1/0/all/0/1\">Kanako Harada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quang-Minh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1\">Bogyu Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Seungbum Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1\">Min-Kook Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peven_M/0/1/0/all/0/1\">Michael Peven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunshuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1\">Yonghao Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Satyadwyoom Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalithkumar_S/0/1/0/all/0/1\">Seenivasan Lalithkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hongliang_R/0/1/0/all/0/1\">Ren Hongliang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuzaki_H/0/1/0/all/0/1\">Hiroki Matsuzaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_Y/0/1/0/all/0/1\">Yuto Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harai_Y/0/1/0/all/0/1\">Yuriko Harai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondo_S/0/1/0/all/0/1\">Satoshi Kondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsuishi_M/0/1/0/all/0/1\">Mamoru Mitsuishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannin_P/0/1/0/all/0/1\">Pierre Jannin</a>",
          "description": "This paper presents the design and results of the \"PEg TRAnsfert Workflow\nrecognition\" (PETRAW) challenge whose objective was to develop surgical\nworkflow recognition methods based on one or several modalities, among video,\nkinematic, and segmentation data, in order to study their added value. The\nPETRAW challenge provided a data set of 150 peg transfer sequences performed on\na virtual simulator. This data set was composed of videos, kinematics, semantic\nsegmentation, and workflow annotations which described the sequences at three\ndifferent granularity levels: phase, step, and activity. Five tasks were\nproposed to the participants: three of them were related to the recognition of\nall granularities with one of the available modalities, while the others\naddressed the recognition with a combination of modalities. Average\napplication-dependent balanced accuracy (AD-Accuracy) was used as evaluation\nmetric to take unbalanced classes into account and because it is more\nclinically relevant than a frame-by-frame score. Seven teams participated in at\nleast one task and four of them in all tasks. Best results are obtained with\nthe use of the video and the kinematics data with an AD-Accuracy between 93%\nand 90% for the four teams who participated in all tasks. The improvement\nbetween video/kinematic-based methods and the uni-modality ones was significant\nfor all of the teams. However, the difference in testing execution time between\nthe video/kinematic-based and the kinematic-based methods has to be taken into\nconsideration. Is it relevant to spend 20 to 200 times more computing time for\nless than 3% of improvement? The PETRAW data set is publicly available at\nwww.synapse.org/PETRAW to encourage further research in surgical workflow\nrecognition.",
          "link": "http://arxiv.org/abs/2202.05821",
          "publishedOn": "2022-04-16T00:51:44.407Z",
          "wordCount": null,
          "title": "PEg TRAnsfer Workflow recognition challenge report: Does multi-modal data improve recognition?. (arXiv:2202.05821v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06997",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bruinsma_W/0/1/0/all/0/1\">Wessel P. Bruinsma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tegner_M/0/1/0/all/0/1\">Martin Tegn&#xe9;r</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>",
          "description": "The Gaussian Process Convolution Model (GPCM; Tobar et al., 2015a) is a model\nfor signals with complex spectral structure. A significant limitation of the\nGPCM is that it assumes a rapidly decaying spectrum: it can only model smooth\nsignals. Moreover, inference in the GPCM currently requires (1) a mean-field\nassumption, resulting in poorly calibrated uncertainties, and (2) a tedious\nvariational optimisation of large covariance matrices. We redesign the GPCM\nmodel to induce a richer distribution over the spectrum with relaxed\nassumptions about smoothness: the Causal Gaussian Process Convolution Model\n(CGPCM) introduces a causality assumption into the GPCM, and the Rough Gaussian\nProcess Convolution Model (RGPCM) can be interpreted as a Bayesian\nnonparametric generalisation of the fractional Ornstein-Uhlenbeck process. We\nalso propose a more effective variational inference scheme, going beyond the\nmean-field assumption: we design a Gibbs sampler which directly samples from\nthe optimal variational solution, circumventing any variational optimisation\nentirely. The proposed variations of the GPCM are validated in experiments on\nsynthetic and real-world data, showing promising results.",
          "link": "http://arxiv.org/abs/2203.06997",
          "publishedOn": "2022-04-16T00:51:44.404Z",
          "wordCount": null,
          "title": "Modelling Non-Smooth Signals with Complex Spectral Structure. (arXiv:2203.06997v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.02889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Ruixuan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xuancheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1\">Qi Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>",
          "description": "Previous studies demonstrate DNNs' vulnerability to adversarial examples and\nadversarial training can establish a defense to adversarial examples. In\naddition, recent studies show that deep neural networks also exhibit\nvulnerability to parameter corruptions. The vulnerability of model parameters\nis of crucial value to the study of model robustness and generalization. In\nthis work, we introduce the concept of parameter corruption and propose to\nleverage the loss change indicators for measuring the flatness of the loss\nbasin and the parameter robustness of neural network parameters. On such basis,\nwe analyze parameter corruptions and propose the multi-step adversarial\ncorruption algorithm. To enhance neural networks, we propose the adversarial\nparameter defense algorithm that minimizes the average risk of multiple\nadversarial parameter corruptions. Experimental results show that the proposed\nalgorithm can improve both the parameter robustness and accuracy of neural\nnetworks.",
          "link": "http://arxiv.org/abs/2109.02889",
          "publishedOn": "2022-04-16T00:51:43.895Z",
          "wordCount": null,
          "title": "Adversarial Parameter Defense by Multi-Step Risk Minimization. (arXiv:2109.02889v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.07140",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Weiss_M/0/1/0/all/0/1\">Matthew L. Weiss</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Frey_N/0/1/0/all/0/1\">Nathan C. Frey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Samsi_S/0/1/0/all/0/1\">Siddharth Samsi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Paffenroth_R/0/1/0/all/0/1\">Randy C. Paffenroth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gadepally_V/0/1/0/all/0/1\">Vijay Gadepally</a>",
          "description": "Traditional frequency based projection filters, or projection operators (PO),\nseparate signal and noise through a series of transformations which remove\nfrequencies where noise is present. However, this technique relies on a priori\nknowledge of what frequencies contain signal and noise and that these\nfrequencies do not overlap, which is difficult to achieve in practice. To\naddress these issues, we introduce a PO-neural network hybrid model, the Pseudo\nProjection Operator (PPO), which leverages a neural network to perform\nfrequency selection. We compare the filtering capabilities of a PPO, PO, and\ndenoising autoencoder (DAE) on the University of Rochester Multi-Modal Music\nPerformance Dataset with a variety of added noise types. In the majority of\nexperiments, the PPO outperforms both the PO and DAE. Based upon these results,\nwe suggest future application of the PPO to filtering problems in the physical\nand biological sciences.",
          "link": "http://arxiv.org/abs/2111.07140",
          "publishedOn": "2022-04-16T00:51:43.894Z",
          "wordCount": null,
          "title": "The Pseudo Projection Operator: Applications of Deep Learning to Projection Based Filtering in Non-Trivial Frequency Regimes. (arXiv:2111.07140v3 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_S/0/1/0/all/0/1\">Shafi Goldwasser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Michael P. Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaikuntanathan_V/0/1/0/all/0/1\">Vinod Vaikuntanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamir_O/0/1/0/all/0/1\">Or Zamir</a>",
          "description": "Given the computational cost and technical expertise required to train\nmachine learning models, users may delegate the task of learning to a service\nprovider. We show how a malicious learner can plant an undetectable backdoor\ninto a classifier. On the surface, such a backdoored classifier behaves\nnormally, but in reality, the learner maintains a mechanism for changing the\nclassification of any input, with only a slight perturbation. Importantly,\nwithout the appropriate \"backdoor key\", the mechanism is hidden and cannot be\ndetected by any computationally-bounded observer. We demonstrate two frameworks\nfor planting undetectable backdoors, with incomparable guarantees.\n\nFirst, we show how to plant a backdoor in any model, using digital signature\nschemes. The construction guarantees that given black-box access to the\noriginal model and the backdoored version, it is computationally infeasible to\nfind even a single input where they differ. This property implies that the\nbackdoored model has generalization error comparable with the original model.\nSecond, we demonstrate how to insert undetectable backdoors in models trained\nusing the Random Fourier Features (RFF) learning paradigm or in Random ReLU\nnetworks. In this construction, undetectability holds against powerful\nwhite-box distinguishers: given a complete description of the network and the\ntraining data, no efficient distinguisher can guess whether the model is\n\"clean\" or contains a backdoor.\n\nOur construction of undetectable backdoors also sheds light on the related\nissue of robustness to adversarial examples. In particular, our construction\ncan produce a classifier that is indistinguishable from an \"adversarially\nrobust\" classifier, but where every input has an adversarial example! In\nsummary, the existence of undetectable backdoors represent a significant\ntheoretical roadblock to certifying adversarial robustness.",
          "link": "http://arxiv.org/abs/2204.06974",
          "publishedOn": "2022-04-16T00:51:43.878Z",
          "wordCount": null,
          "title": "Planting Undetectable Backdoors in Machine Learning Models. (arXiv:2204.06974v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.01250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baldini_I/0/1/0/all/0/1\">Ioana Baldini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Dennis Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramamurthy_K/0/1/0/all/0/1\">Karthikeyan Natesan Ramamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yurochkin_M/0/1/0/all/0/1\">Mikhail Yurochkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Moninder Singh</a>",
          "description": "The popularity of pretrained language models in natural language processing\nsystems calls for a careful evaluation of such models in down-stream tasks,\nwhich have a higher potential for societal impact. The evaluation of such\nsystems usually focuses on accuracy measures. Our findings in this paper call\nfor attention to be paid to fairness measures as well. Through the analysis of\nmore than a dozen pretrained language models of varying sizes on two toxic text\nclassification tasks (English), we demonstrate that focusing on accuracy\nmeasures alone can lead to models with wide variation in fairness\ncharacteristics. Specifically, we observe that fairness can vary even more than\naccuracy with increasing training data size and different random\ninitializations. At the same time, we find that little of the fairness\nvariation is explained by model size, despite claims in the literature. To\nimprove model fairness without retraining, we show that two post-processing\nmethods developed for structured, tabular data can be successfully applied to a\nrange of pretrained language models. Warning: This paper contains samples of\noffensive text.",
          "link": "http://arxiv.org/abs/2108.01250",
          "publishedOn": "2022-04-16T00:51:43.878Z",
          "wordCount": null,
          "title": "Your fairness may vary: Pretrained language model fairness in toxic text classification. (arXiv:2108.01250v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.06047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuyin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingda Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Feifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1\">Ehsan Adeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>",
          "description": "Federated learning is an emerging research paradigm enabling collaborative\ntraining of machine learning models among different organizations while keeping\ndata private at each institution. Despite recent progress, there remain\nfundamental challenges such as the lack of convergence and the potential for\ncatastrophic forgetting across real-world heterogeneous devices. In this paper,\nwe demonstrate that self-attention-based architectures (e.g., Transformers) are\nmore robust to distribution shifts and hence improve federated learning over\nheterogeneous data. Concretely, we conduct the first rigorous empirical\ninvestigation of different neural architectures across a range of federated\nalgorithms, real-world benchmarks, and heterogeneous data splits. Our\nexperiments show that simply replacing convolutional networks with Transformers\ncan greatly reduce catastrophic forgetting of previous devices, accelerate\nconvergence, and reach a better global model, especially when dealing with\nheterogeneous data. We release our code and pretrained models at\nhttps://github.com/Liangqiong/ViT-FL-main to encourage future exploration in\nrobust architectures as an alternative to current research efforts on the\noptimization front.",
          "link": "http://arxiv.org/abs/2106.06047",
          "publishedOn": "2022-04-16T00:51:43.877Z",
          "wordCount": null,
          "title": "Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning. (arXiv:2106.06047v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07037",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Toit_J/0/1/0/all/0/1\">J du Toit</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Preez_J/0/1/0/all/0/1\">J du Preez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wolhuter_R/0/1/0/all/0/1\">R Wolhuter</a>",
          "description": "We present a sequential Bayesian learning method for tracking non-stationary\nsignal-to-noise ratios in LDPC codes using probabilistic graphical models. We\nrepresent the LDPC code as a cluster graph using a general purpose cluster\ngraph construction algorithm called the layered trees running intersection\nproperty (LTRIP) algorithm. The channel noise estimator is a global Gamma\ncluster, which we extend to allow for Bayesian tracking of non-stationary noise\nvariation. We evaluate our proposed model on real-world 5G drive test data. Our\nresults show that our model is capable of tracking non-stationary channel\nnoise, which outperforms an LDPC code with a fixed knowledge of the actual\naverage channel noise.",
          "link": "http://arxiv.org/abs/2204.07037",
          "publishedOn": "2022-04-16T00:51:43.875Z",
          "wordCount": null,
          "title": "LDPC codes: tracking non-stationary channel noise using sequential variational Bayesian estimates. (arXiv:2204.07037v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zhe Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jianmo Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bikel_D/0/1/0/all/0/1\">Dan Bikel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfonseca_E/0/1/0/all/0/1\">Enrique Alfonseca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_C/0/1/0/all/0/1\">Chen Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zitouni_I/0/1/0/all/0/1\">Imed Zitouni</a>",
          "description": "Dual encoders have been used for question-answering (QA) and information\nretrieval (IR) tasks with good results. There are two major types of dual\nencoders, Siamese Dual Encoders (SDE), with parameters shared across two\nencoders, and Asymmetric Dual Encoder (ADE), with two distinctly parameterized\nencoders. In this work, we explore the dual encoder architectures for QA\nretrieval tasks. By evaluating on MS MARCO and the MultiReQA benchmark, we show\nthat SDE performs significantly better than ADE. We further propose three\ndifferent improved versions of ADEs. Based on the evaluation of QA retrieval\ntasks and direct analysis of the embeddings, we demonstrate that sharing\nparameters in projection layers would enable ADEs to perform competitively with\nSDEs.",
          "link": "http://arxiv.org/abs/2204.07120",
          "publishedOn": "2022-04-16T00:51:43.875Z",
          "wordCount": null,
          "title": "Exploring Dual Encoder Architectures for Question Answering. (arXiv:2204.07120v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ardeshir_S/0/1/0/all/0/1\">Shervin Ardeshir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamath_N/0/1/0/all/0/1\">Nagendra Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taghavi_H/0/1/0/all/0/1\">Hossein Taghavi</a>",
          "description": "We explore retrieving character-focused video frames as candidates for being\nvideo thumbnails. To evaluate each frame of the video based on the character(s)\npresent in it, characters (faces) are evaluated in two aspects:\nFacial-expression: We train a CNN model to measure whether a face has an\nacceptable facial expression for being in a video thumbnail. This model is\ntrained to distinguish faces extracted from artworks/thumbnails, from faces\nextracted from random frames of videos. Prominence and interactions:\nCharacter(s) in the thumbnail should be important character(s) in the video, to\nprevent the algorithm from suggesting non-representative frames as candidates.\nWe use face clustering to identify the characters in the video, and form a\ngraph in which the prominence (frequency of appearance) of the character(s),\nand their interactions (co-occurrence) are captured. We use this graph to infer\nthe relevance of the characters present in each candidate frame. Once every\nface is scored based on the two criteria above, we infer frame level scores by\ncombining the scores for all the faces within a frame.",
          "link": "http://arxiv.org/abs/2204.06563",
          "publishedOn": "2022-04-16T00:51:43.869Z",
          "wordCount": null,
          "title": "Character-focused Video Thumbnail Retrieval. (arXiv:2204.06563v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>",
          "description": "Model ensemble is a popular approach to produce a low-variance and\nwell-generalized model. However, it induces large memory and inference costs,\nwhich are often not affordable for real-world deployment. Existing work has\nresorted to sharing weights among models. However, when increasing the\nproportion of the shared weights, the resulting models tend to be similar, and\nthe benefits of using model ensemble diminish. To retain ensemble benefits\nwhile maintaining a low memory cost, we propose a consistency-regularized\nensemble learning approach based on perturbed models, named CAMERO.\nSpecifically, we share the weights of bottom layers across all models and apply\ndifferent perturbations to the hidden representations for different models,\nwhich can effectively promote the model diversity. Meanwhile, we apply a\nprediction consistency regularizer across the perturbed models to control the\nvariance due to the model diversity. Our experiments using large language\nmodels demonstrate that CAMERO significantly improves the generalization\nperformance of the ensemble model. Specifically, CAMERO outperforms the\nstandard ensemble of 8 BERT-base models on the GLUE benchmark by 0.7 with a\nsignificantly smaller model size (114.2M vs. 880.6M).",
          "link": "http://arxiv.org/abs/2204.06625",
          "publishedOn": "2022-04-16T00:51:43.869Z",
          "wordCount": null,
          "title": "CAMERO: Consistency Regularized Ensemble of Perturbed Language Models with Weight Sharing. (arXiv:2204.06625v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gokcesu_K/0/1/0/all/0/1\">Kaan Gokcesu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokcesu_H/0/1/0/all/0/1\">Hakan Gokcesu</a>",
          "description": "We study the problem of expert advice under partial bandit feedback setting\nand create a sequential minimax optimal algorithm. Our algorithm works with a\nmore general partial monitoring setting, where, in contrast to the classical\nbandit feedback, the losses can be revealed in an adversarial manner. Our\nalgorithm adopts a universal prediction perspective, whose performance is\nanalyzed with regret against a general expert selection sequence. The regret we\nstudy is against a general competition class that covers many settings (such as\nthe switching or contextual experts settings) and the expert selection\nsequences in the competition class are determined by the application at hand.\nOur regret bounds are second order bounds in terms of the sum of squared losses\nand the normalized regret of our algorithm is invariant under arbitrary affine\ntransforms of the loss sequence. Our algorithm is truly online and does not use\nany preliminary information about the loss sequences.",
          "link": "http://arxiv.org/abs/2204.06660",
          "publishedOn": "2022-04-16T00:51:43.869Z",
          "wordCount": null,
          "title": "Second Order Regret Bounds Against Generalized Expert Sequences under Partial Bandit Feedback. (arXiv:2204.06660v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07071",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xing Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maranzatto_T/0/1/0/all/0/1\">Thomas Maranzatto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reyzin_L/0/1/0/all/0/1\">Lev Reyzin</a>",
          "description": "In this paper we investigate the problem of learning evolving concepts over a\ncombinatorial structure. Previous work by Emamjomeh-Zadeh et al. [2020]\nintroduced dynamics into interactive learning as a way to model non-static user\npreferences in clustering problems or recommender systems. We provide many\nuseful contributions to this problem. First, we give a framework that captures\nboth of the models analyzed by [Emamjomeh-Zadeh et al., 2020], which allows us\nto study any type of concept evolution and matches the same query complexity\nbounds and running time guarantees of the previous models. Using this general\nmodel we solve the open problem of closing the gap between the upper and lower\nbounds on query complexity. Finally, we study an efficient algorithm where the\nlearner simply follows the feedback at each round, and we provide mistake\nbounds for low diameter graphs such as cliques, stars, and general o(log n)\ndiameter graphs by using a Markov Chain model.",
          "link": "http://arxiv.org/abs/2204.07071",
          "publishedOn": "2022-04-16T00:51:43.869Z",
          "wordCount": null,
          "title": "A Unified Analysis of Dynamic Interactive Learning. (arXiv:2204.07071v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04219",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ren_T/0/1/0/all/0/1\">Tongzheng Ren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhuo_J/0/1/0/all/0/1\">Jiacheng Zhuo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sanghavi_S/0/1/0/all/0/1\">Sujay Sanghavi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>",
          "description": "It is known that when the statistical models are singular, i.e., the Fisher\ninformation matrix at the true parameter is degenerate, the fixed step-size\ngradient descent algorithm takes polynomial number of steps in terms of the\nsample size $n$ to converge to a final statistical radius around the true\nparameter, which can be unsatisfactory for the application. To further improve\nthat computational complexity, we consider the utilization of the second-order\ninformation in the design of optimization algorithms. Specifically, we study\nthe normalized gradient descent (NormGD) algorithm for solving parameter\nestimation in parametric statistical models, which is a variant of gradient\ndescent algorithm whose step size is scaled by the maximum eigenvalue of the\nHessian matrix of the empirical loss function of statistical models. When the\npopulation loss function, i.e., the limit of the empirical loss function when\n$n$ goes to infinity, is homogeneous in all directions, we demonstrate that the\nNormGD iterates reach a final statistical radius around the true parameter\nafter a logarithmic number of iterations in terms of $n$. Therefore, for fixed\ndimension $d$, the NormGD algorithm achieves the optimal overall computational\ncomplexity $\\mathcal{O}(n)$ to reach the final statistical radius. This\ncomputational complexity is cheaper than that of the fixed step-size gradient\ndescent algorithm, which is of the order $\\mathcal{O}(n^{\\tau})$ for some $\\tau\n> 1$, to reach the same statistical radius. We illustrate our general theory\nunder two statistical models: generalized linear models and mixture models, and\nexperimental results support our prediction with general theory.",
          "link": "http://arxiv.org/abs/2202.04219",
          "publishedOn": "2022-04-16T00:51:43.867Z",
          "wordCount": null,
          "title": "Improving Computational Complexity in Statistical Models with Second-Order Information. (arXiv:2202.04219v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kacham_P/0/1/0/all/0/1\">Praneeth Kacham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "We give a sketching-based iterative algorithm that computes $1+\\varepsilon$\napproximate solutions for the ridge regression problem $\\min_x \\|{Ax-b}\\|_2^2\n+\\lambda\\|{x}\\|_2^2$ where $A \\in \\mathbb{R}^{n \\times d}$ with $d \\ge n$. Our\nalgorithm, for a constant number of iterations (requiring a constant number of\npasses over the input), improves upon earlier work of Chowdhury et al., by\nrequiring that the sketching matrix only has a weaker Approximate Matrix\nMultiplication (AMM) guarantee that depends on $\\epsilon$, along with a\nconstant subspace embedding guarantee. The earlier work instead requires that\nthe sketching matrix have a subspace embedding guarantee that depends on\n$\\epsilon$. For example, to produce a $1+\\varepsilon$ approximate solution in\n$1$ iteration, which requires $2$ passes over the input, our algorithm requires\nthe OSNAP embedding to have $m= O(n\\sigma^2/\\lambda\\varepsilon)$ rows with a\nsparsity parameter $s = O(\\log(n))$, whereas the earlier algorithm of Chowdhury\net al., with the same number of rows of OSNAP requires a sparsity $s =\nO(\\sqrt{\\sigma^2/\\lambda\\varepsilon} \\cdot \\log(n))$, where $\\sigma =\n\\|{A}\\|_2$ is the spectral norm of the matrix $A$. We also show that this\nalgorithm can be used to give faster algorithms for kernel ridge regression.\nFinally, we show that the sketch size required for our algorithm is essentially\noptimal for a natural framework of algorithms for ridge regression by proving\nlower bounds on oblivious sketching matrices for AMM. The sketch size lower\nbounds for AMM may be of independent interest.",
          "link": "http://arxiv.org/abs/2204.06653",
          "publishedOn": "2022-04-16T00:51:43.865Z",
          "wordCount": null,
          "title": "Sketching Algorithms and Lower Bounds for Ridge Regression. (arXiv:2204.06653v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khanna_S/0/1/0/all/0/1\">Samar Khanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Bram Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bala_K/0/1/0/all/0/1\">Kavita Bala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hariharan_B/0/1/0/all/0/1\">Bharath Hariharan</a>",
          "description": "Geographic variance in satellite imagery impacts the ability of machine\nlearning models to generalise to new regions. In this paper, we model\ngeographic generalisation in medium resolution Landsat-8 satellite imagery as a\ncontinuous domain adaptation problem, demonstrating how models generalise\nbetter with appropriate domain knowledge. We develop a dataset spatially\ndistributed across the entire continental United States, providing macroscopic\ninsight into the effects of geography on crop classification in multi-spectral\nand temporally distributed satellite imagery. Our method demonstrates improved\ngeneralisability from 1) passing geographically correlated climate variables\nalong with the satellite data to a Transformer model and 2) regressing on the\nmodel features to reconstruct these domain variables. Combined, we provide a\nnovel perspective on geographic generalisation in satellite imagery and a\nsimple-yet-effective approach to leverage domain knowledge. Code is available\nat: \\url{https://github.com/samar-khanna/cropmap}",
          "link": "http://arxiv.org/abs/2204.07030",
          "publishedOn": "2022-04-16T00:51:43.865Z",
          "wordCount": null,
          "title": "Activation Regression for Continuous Domain Generalization with Applications to Crop Classification. (arXiv:2204.07030v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chai_L/0/1/0/all/0/1\">Lucy Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gharbi_M/0/1/0/all/0/1\">Michael Gharbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shechtman_E/0/1/0/all/0/1\">Eli Shechtman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Richard Zhang</a>",
          "description": "Generative models operate at fixed resolution, even though natural images\ncome in a variety of sizes. As high-resolution details are downsampled away,\nand low-resolution images are discarded altogether, precious supervision is\nlost. We argue that every pixel matters and create datasets with variable-size\nimages, collected at their native resolutions. Taking advantage of this data is\nchallenging; high-resolution processing is costly, and current architectures\ncan only process fixed-resolution data. We introduce continuous-scale training,\na process that samples patches at random scales to train a new generator with\nvariable output resolutions. First, conditioning the generator on a target\nscale allows us to generate higher resolutions images than previously possible,\nwithout adding layers to the model. Second, by conditioning on continuous\ncoordinates, we can sample patches that still obey a consistent global layout,\nwhich also allows for scalable training at higher resolutions. Controlled FFHQ\nexperiments show our method takes advantage of the multi-resolution training\ndata better than discrete multi-scale approaches, achieving better FID scores\nand cleaner high-frequency details. We also train on other natural image\ndomains including churches, mountains, and birds, and demonstrate arbitrary\nscale synthesis with both coherent global layouts and realistic local details,\ngoing beyond 2K resolution in our experiments. Our project page is available\nat: https://chail.github.io/anyres-gan/.",
          "link": "http://arxiv.org/abs/2204.07156",
          "publishedOn": "2022-04-16T00:51:43.864Z",
          "wordCount": null,
          "title": "Any-resolution Training for High-resolution Image Synthesis. (arXiv:2204.07156v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.07467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sitaula_C/0/1/0/all/0/1\">Chiranjibi Sitaula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jinyuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priyadarshi_A/0/1/0/all/0/1\">Archana Priyadarshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tracy_M/0/1/0/all/0/1\">Mark Tracy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kavehei_O/0/1/0/all/0/1\">Omid Kavehei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hinder_M/0/1/0/all/0/1\">Murray Hinder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Withana_A/0/1/0/all/0/1\">Anusha Withana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McEwan_A/0/1/0/all/0/1\">Alistair McEwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marzbanrad_F/0/1/0/all/0/1\">Faezeh Marzbanrad</a>",
          "description": "Abdominal auscultation is a convenient, safe and inexpensive method to assess\nbowel conditions, which is essential in neonatal care. It helps early detection\nof neonatal bowel dysfunctions and allows timely intervention. This paper\npresents a neonatal bowel sound detection method to assist the auscultation.\nSpecifically, a Convolutional Neural Network (CNN) is proposed to classify\nperistalsis and non-peristalsis sounds. The classification is then optimized\nusing a Laplace Hidden Semi-Markov Model (HSMM). The proposed method is\nvalidated on abdominal sounds from 49 newborn infants admitted to our tertiary\nNeonatal Intensive Care Unit (NICU). The results show that the method can\neffectively detect bowel sounds with accuracy and area under curve (AUC) score\nbeing 89.81% and 83.96% respectively, outperforming 13 baseline methods.\nFurthermore, the proposed Laplace HSMM refinement strategy is proven capable to\nenhance other bowel sound detection models. The outcomes of this work have the\npotential to facilitate future telehealth applications for neonatal care. The\nsource code of our work can be found at:\nhttps://bitbucket.org/chirudeakin/neonatal-bowel-sound-classification/",
          "link": "http://arxiv.org/abs/2108.07467",
          "publishedOn": "2022-04-16T00:51:43.864Z",
          "wordCount": null,
          "title": "Neonatal Bowel Sound Detection Using Convolutional Neural Network and Laplace Hidden Semi-Markov Model. (arXiv:2108.07467v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.04109",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nabi_R/0/1/0/all/0/1\">Razieh Nabi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Malinsky_D/0/1/0/all/0/1\">Daniel Malinsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shpitser_I/0/1/0/all/0/1\">Ilya Shpitser</a>",
          "description": "Recently there has been sustained interest in modifying prediction algorithms\nto satisfy fairness constraints. These constraints are typically complex\nnonlinear functionals of the observed data distribution. Focusing on the\npath-specific causal constraints proposed by Nabi and Shpitser (2018), we\nintroduce new theoretical results and optimization techniques to make model\ntraining easier and more accurate. Specifically, we show how to reparameterize\nthe observed data likelihood such that fairness constraints correspond directly\nto parameters that appear in the likelihood, transforming a complex constrained\noptimization objective into a simple optimization problem with box constraints.\nWe also exploit methods from empirical likelihood theory in statistics to\nimprove predictive performance by constraining baseline covariates, without\nrequiring parametric models. We combine the merits of both proposals to\noptimize a hybrid reparameterized likelihood. The techniques presented here\nshould be applicable more broadly to fair prediction proposals that impose\nconstraints on predictive models.",
          "link": "http://arxiv.org/abs/1910.04109",
          "publishedOn": "2022-04-16T00:51:43.863Z",
          "wordCount": null,
          "title": "Optimal Training of Fair Predictive Models. (arXiv:1910.04109v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Assran_M/0/1/0/all/0/1\">Mahmoud Assran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caron_M/0/1/0/all/0/1\">Mathilde Caron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_I/0/1/0/all/0/1\">Ishan Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bojanowski_P/0/1/0/all/0/1\">Piotr Bojanowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bordes_F/0/1/0/all/0/1\">Florian Bordes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1\">Pascal Vincent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1\">Armand Joulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1\">Michael Rabbat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1\">Nicolas Ballas</a>",
          "description": "We propose Masked Siamese Networks (MSN), a self-supervised learning\nframework for learning image representations. Our approach matches the\nrepresentation of an image view containing randomly masked patches to the\nrepresentation of the original unmasked image. This self-supervised\npre-training strategy is particularly scalable when applied to Vision\nTransformers since only the unmasked patches are processed by the network. As a\nresult, MSNs improve the scalability of joint-embedding architectures, while\nproducing representations of a high semantic level that perform competitively\non low-shot image classification. For instance, on ImageNet-1K, with only 5,000\nannotated images, our base MSN model achieves 72.4% top-1 accuracy, and with 1%\nof ImageNet-1K labels, we achieve 75.7% top-1 accuracy, setting a new\nstate-of-the-art for self-supervised learning on this benchmark. Our code is\npublicly available.",
          "link": "http://arxiv.org/abs/2204.07141",
          "publishedOn": "2022-04-16T00:51:43.862Z",
          "wordCount": null,
          "title": "Masked Siamese Networks for Label-Efficient Learning. (arXiv:2204.07141v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.13500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Hong Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Minghao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1\">Chupeng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zongmin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1\">Xinhui Xue</a>",
          "description": "Model compression becomes a recent trend due to the requirement of deploying\nneural networks on embedded and mobile devices. Hence, both accuracy and\nefficiency are of critical importance. To explore a balance between them, a\nknowledge distillation strategy is proposed for general visual representation\nlearning. It utilizes our well-designed activation map adaptive module to\nreplace some blocks of the teacher network, exploring the most appropriate\nsupervisory features adaptively during the training process. Using the\nteacher's hidden layer output to prompt the student network to train so as to\ntransfer effective semantic information.To verify the effectiveness of our\nstrategy, this paper applied our method to cifar-10 dataset. Results\ndemonstrate that the method can boost the accuracy of the student network by\n0.6% with 6.5% loss reduction, and significantly improve its training speed.",
          "link": "http://arxiv.org/abs/2010.13500",
          "publishedOn": "2022-04-16T00:51:43.862Z",
          "wordCount": null,
          "title": "Activation Map Adaptation for Effective Knowledge Distillation. (arXiv:2010.13500v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Youngjin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_E/0/1/0/all/0/1\">Eugene Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yongjae Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seungwon Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1\">Jin-Woo Chung</a>",
          "description": "The hidden nature and the limited accessibility of the Dark Web, combined\nwith the lack of public datasets in this domain, make it difficult to study its\ninherent characteristics such as linguistic properties. Previous works on text\nclassification of Dark Web domain have suggested that the use of deep neural\nmodels may be ineffective, potentially due to the linguistic differences\nbetween the Dark and Surface Webs. However, not much work has been done to\nuncover the linguistic characteristics of the Dark Web. This paper introduces\nCoDA, a publicly available Dark Web dataset consisting of 10000 web documents\ntailored towards text-based Dark Web analysis. By leveraging CoDA, we conduct a\nthorough linguistic analysis of the Dark Web and examine the textual\ndifferences between the Dark Web and the Surface Web. We also assess the\nperformance of various methods of Dark Web page classification. Finally, we\ncompare CoDA with an existing public Dark Web dataset and evaluate their\nsuitability for various use cases.",
          "link": "http://arxiv.org/abs/2204.06885",
          "publishedOn": "2022-04-16T00:51:43.861Z",
          "wordCount": null,
          "title": "Shedding New Light on the Language of the Dark Web. (arXiv:2204.06885v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ardeshir_S/0/1/0/all/0/1\">Shervin Ardeshir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segalin_C/0/1/0/all/0/1\">Cristina Segalin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kallus_N/0/1/0/all/0/1\">Nathan Kallus</a>",
          "description": "In machine learning, disparity metrics are often defined by measuring the\ndifference in the performance or outcome of a model, across different\nsub-populations (groups) of datapoints. Thus, the inputs to disparity\nquantification consist of a model's predictions $\\hat{y}$, the ground-truth\nlabels for the predictions $y$, and group labels $g$ for the data points.\nPerformance of the model for each group is calculated by comparing $\\hat{y}$\nand $y$ for the datapoints within a specific group, and as a result, disparity\nof performance across the different groups can be calculated. In many real\nworld scenarios however, group labels ($g$) may not be available at scale\nduring training and validation time, or collecting them might not be feasible\nor desirable as they could often be sensitive information. As a result,\nevaluating disparity metrics across categorical groups would not be feasible.\nOn the other hand, in many scenarios noisy groupings may be obtainable using\nsome form of a proxy, which would allow measuring disparity metrics across\nsub-populations. Here we explore performing such analysis on computer vision\nmodels trained on human faces, and on tasks such as face attribute prediction\nand affect estimation. Our experiments indicate that embeddings resulting from\nan off-the-shelf face recognition model, could meaningfully serve as a proxy\nfor such estimation.",
          "link": "http://arxiv.org/abs/2204.06562",
          "publishedOn": "2022-04-16T00:51:43.859Z",
          "wordCount": null,
          "title": "Estimating Structural Disparities for Face Models. (arXiv:2204.06562v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.01299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kariyappa_S/0/1/0/all/0/1\">Sanjay Kariyappa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qureshi_M/0/1/0/all/0/1\">Moinuddin K Qureshi</a>",
          "description": "Split learning is a popular technique used for vertical federated learning\n(VFL), where the goal is to jointly train a model on the private input and\nlabel data held by two parties. This technique uses a split-model, trained\nend-to-end, by exchanging the intermediate representations (IR) of the inputs\nand gradients of the IR between the two parties. We propose ExPLoit - a\nlabel-leakage attack that allows an adversarial input-owner to extract the\nprivate labels of the label-owner during split-learning. ExPLoit frames the\nattack as a supervised learning problem by using a novel loss function that\ncombines gradient-matching and several regularization terms developed using key\nproperties of the dataset and models. Our evaluations show that ExPLoit can\nuncover the private labels with near-perfect accuracy of up to 99.96%. Our\nfindings underscore the need for better training techniques for VFL.",
          "link": "http://arxiv.org/abs/2112.01299",
          "publishedOn": "2022-04-16T00:51:43.859Z",
          "wordCount": null,
          "title": "ExPLoit: Extracting Private Labels in Split Learning. (arXiv:2112.01299v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tien_J/0/1/0/all/0/1\">Jeremy Tien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jerry Zhi-Yang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erickson_Z/0/1/0/all/0/1\">Zackory Erickson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca D. Dragan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel Brown</a>",
          "description": "Learning robot policies via preference-based reward learning is an\nincreasingly popular method for customizing robot behavior. However, in recent\nyears, there has been a growing body of anecdotal evidence that learning reward\nfunctions from preferences is prone to spurious correlations and reward gaming\nor hacking behaviors. While there is much anecdotal, empirical, and theoretical\nanalysis of causal confusion and reward gaming behaviors both in reinforcement\nlearning and imitation learning approaches that directly map from states to\nactions, we provide the first systematic study of causal confusion in the\ncontext of learning reward functions from preferences. To facilitate this\nstudy, we identify a set of three preference learning benchmark domains where\nwe observe causal confusion when learning from offline datasets of pairwise\ntrajectory preferences: a simple reacher domain, an assistive feeding domain,\nand an itch-scratching domain. To gain insight into this observed causal\nconfusion, we present a sensitivity analysis that explores the effect of\ndifferent factors--including the type of training data, reward model capacity,\nand feature dimensionality--on the robustness of rewards learned from\npreferences. We find evidence that learning rewards from pairwise trajectory\npreferences is highly sensitive and non-robust to spurious features and\nincreasing model capacity, but not as sensitive to the type of training data.\nVideos, code, and supplemental results are available at\nhttps://sites.google.com/view/causal-reward-confusion.",
          "link": "http://arxiv.org/abs/2204.06601",
          "publishedOn": "2022-04-16T00:51:43.858Z",
          "wordCount": null,
          "title": "A Study of Causal Confusion in Preference-Based Reward Learning. (arXiv:2204.06601v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1\">Dennis Ulmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardmeier_C/0/1/0/all/0/1\">Christian Hardmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1\">Jes Frellsen</a>",
          "description": "A lot of Machine Learning (ML) and Deep Learning (DL) research is of an\nempirical nature. Nevertheless, statistical significance testing (SST) is still\nnot widely used. This endangers true progress, as seeming improvements over a\nbaseline might be statistical flukes, leading follow-up research astray while\nwasting human and computational resources. Here, we provide an easy-to-use\npackage containing different significance tests and utility functions\nspecifically tailored towards research needs and usability.",
          "link": "http://arxiv.org/abs/2204.06815",
          "publishedOn": "2022-04-16T00:51:43.814Z",
          "wordCount": null,
          "title": "deep-significance - Easy and Meaningful Statistical Significance Testing in the Age of Neural Networks. (arXiv:2204.06815v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.04788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_H/0/1/0/all/0/1\">Hsiang Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1\">Mario Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>",
          "description": "Disparate treatment occurs when a machine learning model yields different\ndecisions for individuals based on a sensitive attribute (e.g., age, sex). In\ndomains where prediction accuracy is paramount, it could potentially be\nacceptable to fit a model which exhibits disparate treatment. To evaluate the\neffect of disparate treatment, we compare the performance of split classifiers\n(i.e., classifiers trained and deployed separately on each group) with\ngroup-blind classifiers (i.e., classifiers which do not use a sensitive\nattribute). We introduce the benefit-of-splitting for quantifying the\nperformance improvement by splitting classifiers. Computing the\nbenefit-of-splitting directly from its definition could be intractable since it\ninvolves solving optimization problems over an infinite-dimensional functional\nspace. Under different performance measures, we (i) prove an equivalent\nexpression for the benefit-of-splitting which can be efficiently computed by\nsolving small-scale convex programs; (ii) provide sharp upper and lower bounds\nfor the benefit-of-splitting which reveal precise conditions where a\ngroup-blind classifier will always suffer from a non-trivial performance gap\nfrom the split classifiers. In the finite sample regime, splitting is not\nnecessarily beneficial and we provide data-dependent bounds to understand this\neffect. Finally, we validate our theoretical results through numerical\nexperiments on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2002.04788",
          "publishedOn": "2022-04-16T00:51:43.813Z",
          "wordCount": null,
          "title": "To Split or Not to Split: The Impact of Disparate Treatment in Classification. (arXiv:2002.04788v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.07963",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gassner_A/0/1/0/all/0/1\">Arthur Gassner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Musat_C/0/1/0/all/0/1\">Claudiu Musat</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rusu_A/0/1/0/all/0/1\">Alexandru Rusu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burg_A/0/1/0/all/0/1\">Andreas Burg</a>",
          "description": "Many applications require accurate indoor localization. Fingerprint-based\nlocalization methods propose a solution to this problem, but rely on a radio\nmap that is effort-intensive to acquire. We automate the radio map acquisition\nphase using a software-defined radio (SDR) and a wheeled robot. Furthermore, we\nopen-source a radio map acquired with our automated tool for a 3GPP Long-Term\nEvolution (LTE) wireless link. To the best of our knowledge, this is the first\npublicly available radio map containing channel state information (CSI).\nFinally, we describe first localization experiments on this radio map using a\nconvolutional neural network to regress for location coordinates.",
          "link": "http://arxiv.org/abs/2104.07963",
          "publishedOn": "2022-04-16T00:51:43.811Z",
          "wordCount": null,
          "title": "OpenCSI: An Open-Source Dataset for Indoor Localization Using CSI-Based Fingerprinting. (arXiv:2104.07963v3 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07155",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Chen_S/0/1/0/all/0/1\">Sitan Chen</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_B/0/1/0/all/0/1\">Brice Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_A/0/1/0/all/0/1\">Allen Liu</a>",
          "description": "We consider the problem of quantum state certification, where we are given\nthe description of a mixed state $\\sigma \\in \\mathbb{C}^{d \\times d}$, $n$\ncopies of a mixed state $\\rho \\in \\mathbb{C}^{d \\times d}$, and $\\varepsilon >\n0$, and we are asked to determine whether $\\rho = \\sigma$ or whether $\\| \\rho -\n\\sigma \\|_1 > \\varepsilon$. When $\\sigma$ is the maximally mixed state\n$\\frac{1}{d} I_d$, this is known as mixedness testing. We focus on algorithms\nwhich use incoherent measurements, i.e. which only measure one copy of $\\rho$\nat a time. Unlike those that use entangled, multi-copy measurements, these can\nbe implemented without persistent quantum memory and thus represent a large\nclass of protocols that can be run on current or near-term devices.\n\nFor mixedness testing, there is a folklore algorithm which uses incoherent\nmeasurements and only needs $O(d^{3/2} / \\varepsilon^2)$ copies. The algorithm\nis non-adaptive, that is, its measurements are fixed ahead of time, and is\nknown to be optimal for non-adaptive algorithms. However, when the algorithm\ncan make arbitrary incoherent measurements, the best known lower bound is only\n$\\Omega (d^{4/3} / \\varepsilon^2)$ [Bubeck-Chen-Li '20], and it has been an\noutstanding open problem to close this polynomial gap. In this work, 1) we\nsettle the copy complexity of mixedness testing with incoherent measurements\nand show that $\\Omega (d^{3/2} / \\varepsilon^2)$ copies are necessary, and 2)\nwe show the instance-optimal bounds for state certification to general $\\sigma$\nfirst derived by [Chen-Li-O'Donnell '21] for non-adaptive measurements also\nhold for arbitrary incoherent measurements.\n\nQualitatively, our results say that adaptivity does not help at all for these\nproblems. Our results are based on new techniques that allow us to reduce the\nproblem to understanding certain matrix martingales, which we believe may be of\nindependent interest.",
          "link": "http://arxiv.org/abs/2204.07155",
          "publishedOn": "2022-04-16T00:51:43.809Z",
          "wordCount": null,
          "title": "Tight Bounds for Quantum State Certification with Incoherent Measurements. (arXiv:2204.07155v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Menon_R/0/1/0/all/0/1\">Rakesh R Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sayan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Shashank Srivastava</a>",
          "description": "Supervised learning has traditionally focused on inductive learning by\nobserving labeled examples of a task. In contrast, humans have the ability to\nlearn new concepts from language. Here, we explore training zero-shot\nclassifiers for structured data purely from language. For this, we introduce\nCLUES, a benchmark for Classifier Learning Using natural language ExplanationS,\nconsisting of a range of classification tasks over structured data along with\nnatural language supervision in the form of explanations. CLUES consists of 36\nreal-world and 144 synthetic classification tasks. It contains crowdsourced\nexplanations describing real-world tasks from multiple teachers and\nprogrammatically generated explanations for the synthetic tasks. To model the\ninfluence of explanations in classifying an example, we develop ExEnt, an\nentailment-based model that learns classifiers using explanations. ExEnt\ngeneralizes up to 18% better (relative) on novel tasks than a baseline that\ndoes not use explanations. We delineate key challenges for automated learning\nfrom explanations, addressing which can lead to progress on CLUES in the\nfuture. Code and datasets are available at: https://clues-benchmark.github.io.",
          "link": "http://arxiv.org/abs/2204.07142",
          "publishedOn": "2022-04-16T00:51:43.808Z",
          "wordCount": null,
          "title": "CLUES: A Benchmark for Learning Classifiers using Natural Language Explanations. (arXiv:2204.07142v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.07259",
          "author": "<a href=\"http://arxiv.org/find/nlin/1/au:+Barfuss_W/0/1/0/all/0/1\">Wolfram Barfuss</a>, <a href=\"http://arxiv.org/find/nlin/1/au:+Mann_R/0/1/0/all/0/1\">Richard P. Mann</a>",
          "description": "Assessing the systemic effects of uncertainty that arises from agents'\npartial observation of the true states of the world is critical for\nunderstanding a wide range of scenarios. Yet, previous modeling work on agent\nlearning and decision-making either lacks a systematic way to describe this\nsource of uncertainty or puts the focus on obtaining optimal policies using\ncomplex models of the world that would impose an unrealistically high cognitive\ndemand on real agents. In this work we aim to efficiently describe the emergent\nbehavior of biologically plausible and parsimonious learning agents faced with\npartially observable worlds. Therefore we derive and present deterministic\nreinforcement learning dynamics where the agents observe the true state of the\nenvironment only partially. We showcase the broad applicability of our dynamics\nacross different classes of partially observable agent-environment systems. We\nfind that partial observability creates unintuitive benefits in a number of\nspecific contexts, pointing the way to further research on a general\nunderstanding of such effects. For instance, partially observant agents can\nlearn better outcomes faster, in a more stable way and even overcome social\ndilemmas. Furthermore, our method allows the application of dynamical systems\ntheory to partially observable multiagent leaning. In this regard we find the\nemergence of catastrophic limit cycles, a critical slowing down of the learning\nprocesses between reward regimes and the separation of the learning dynamics\ninto fast and slow directions, all caused by partial observability. Therefore,\nthe presented dynamics have the potential to become a formal, yet practical,\nlightweight and robust tool for researchers in biology, social science and\nmachine learning to systematically investigate the effects of interacting\npartially observant agents.",
          "link": "http://arxiv.org/abs/2109.07259",
          "publishedOn": "2022-04-16T00:51:43.808Z",
          "wordCount": null,
          "title": "Modeling the effects of environmental and perceptual uncertainty using deterministic reinforcement learning dynamics with partial observability. (arXiv:2109.07259v2 [nlin.AO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tariq_A/0/1/0/all/0/1\">Amara Tariq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunnmon_J/0/1/0/all/0/1\">Jared Dunnmon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_U/0/1/0/all/0/1\">Umesh Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elugunti_P/0/1/0/all/0/1\">Praneetha Elugunti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_B/0/1/0/all/0/1\">Bhavik N. Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_I/0/1/0/all/0/1\">Imon Banerjee</a>",
          "description": "Measures to predict 30-day readmission are considered an important quality\nfactor for hospitals as accurate predictions can reduce the overall cost of\ncare by identifying high risk patients before they are discharged. While recent\ndeep learning-based studies have shown promising empirical results on\nreadmission prediction, several limitations exist that may hinder widespread\nclinical utility, such as (a) only patients with certain conditions are\nconsidered, (b) existing approaches do not leverage data temporality, (c)\nindividual admissions are assumed independent of each other, which is\nunrealistic, (d) prior studies are usually limited to single source of data and\nsingle center data. To address these limitations, we propose a multimodal,\nmodality-agnostic spatiotemporal graph neural network (MM-STGNN) for prediction\nof 30-day all-cause hospital readmission that fuses multimodal in-patient\nlongitudinal data. By training and evaluating our methods using longitudinal\nchest radiographs and electronic health records from two independent centers,\nwe demonstrate that MM-STGNN achieves AUROC of 0.79 on both primary and\nexternal datasets. Furthermore, MM-STGNN significantly outperforms the current\nclinical reference standard, LACE+ score (AUROC=0.61), on the primary dataset.\nFor subset populations of patients with heart and vascular disease, our model\nalso outperforms baselines on predicting 30-day readmission (e.g., 3.7 point\nimprovement in AUROC in patients with heart disease). Lastly, qualitative model\ninterpretability analysis indicates that while patients' primary diagnoses were\nnot explicitly used to train the model, node features crucial for model\nprediction directly reflect patients' primary diagnoses. Importantly, our\nMM-STGNN is agnostic to node feature modalities and could be utilized to\nintegrate multimodal data for triaging patients in various downstream resource\nallocation tasks.",
          "link": "http://arxiv.org/abs/2204.06766",
          "publishedOn": "2022-04-16T00:51:43.807Z",
          "wordCount": null,
          "title": "Multimodal spatiotemporal graph neural networks for improved prediction of 30-day all-cause hospital readmission. (arXiv:2204.06766v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moyer_E/0/1/0/all/0/1\">Ethan Jacob Moyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augustin_A/0/1/0/all/0/1\">Alisha Isabelle Augustin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1\">Satvik Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dholakia_A/0/1/0/all/0/1\">Ansh Aashish Dholakia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Andy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isozaki_I/0/1/0/all/0/1\">Isamu Mclean Isozaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_D/0/1/0/all/0/1\">Daniel Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1\">Edward Kim</a>",
          "description": "In this work, we highlight our novel evolutionary sparse time-series\nforecasting algorithm also known as EvoSTS. The algorithm attempts to\nevolutionary prioritize weights of Long Short-Term Memory (LSTM) Network that\nbest minimize the reconstruction loss of a predicted signal using a learned\nsparse coded dictionary. In each generation of our evolutionary algorithm, a\nset number of children with the same initial weights are spawned. Each child\nundergoes a training step and adjusts their weights on the same data. Due to\nstochastic back-propagation, the set of children has a variety of weights with\ndifferent levels of performance. The weights that best minimize the\nreconstruction loss with a given signal dictionary are passed to the next\ngeneration. The predictions from the best-performing weights of the first and\nlast generation are compared. We found improvements while comparing the weights\nof these two generations. However, due to several confounding parameters and\nhyperparameter limitations, some of the weights had negligible improvements. To\nthe best of our knowledge, this is the first attempt to use sparse coding in\nthis way to optimize time series forecasting model weights, such as those of an\nLSTM network.",
          "link": "http://arxiv.org/abs/2204.07066",
          "publishedOn": "2022-04-16T00:51:43.807Z",
          "wordCount": null,
          "title": "EvoSTS Forecasting: Evolutionary Sparse Time-Series Forecasting. (arXiv:2204.07066v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pedemonte_S/0/1/0/all/0/1\">Stefano Pedemonte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsue_T/0/1/0/all/0/1\">Trevor Tsue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mombourquette_B/0/1/0/all/0/1\">Brent Mombourquette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_Y/0/1/0/all/0/1\">Yen Nhi Truong Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthews_T/0/1/0/all/0/1\">Thomas Matthews</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoil_R/0/1/0/all/0/1\">Rodrigo Morales Hoil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Meet Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghare_N/0/1/0/all/0/1\">Nikita Ghare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zingman_Daniels_N/0/1/0/all/0/1\">Naomi Zingman-Daniels</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holley_S/0/1/0/all/0/1\">Susan Holley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Appleton_C/0/1/0/all/0/1\">Catherine M. Appleton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jason Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wahl_R/0/1/0/all/0/1\">Richard L. Wahl</a>",
          "description": "Screening mammography improves breast cancer outcomes by enabling early\ndetection and treatment. However, false positive callbacks for additional\nimaging from screening exams cause unnecessary procedures, patient anxiety, and\nfinancial burden. This work demonstrates an AI algorithm that reduces false\npositives by identifying mammograms not suspicious for breast cancer. We\ntrained the algorithm to determine the absence of cancer using 123,248 2D\ndigital mammograms (6,161 cancers) and performed a retrospective study on\n14,831 screening exams (1,026 cancers) from 15 US and 3 UK sites. Retrospective\nevaluation of the algorithm on the largest of the US sites (11,592 mammograms,\n101 cancers) a) left the cancer detection rate unaffected (p=0.02,\nnon-inferiority margin 0.25 cancers per 1000 exams), b) reduced callbacks for\ndiagnostic exams by 31.1% compared to standard clinical readings, c) reduced\nbenign needle biopsies by 7.4%, and d) reduced screening exams requiring\nradiologist interpretation by 41.6% in the simulated clinical workflow. This\nwork lays the foundation for semi-autonomous breast cancer screening systems\nthat could benefit patients and healthcare systems by reducing false positives,\nunnecessary procedures, patient anxiety, and expenses.",
          "link": "http://arxiv.org/abs/2204.06671",
          "publishedOn": "2022-04-16T00:51:43.806Z",
          "wordCount": null,
          "title": "A deep learning algorithm for reducing false positives in screening mammography. (arXiv:2204.06671v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06699",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tiezheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mak_T/0/1/0/all/0/1\">Tiffany T.W. Mak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiaopu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ip_N/0/1/0/all/0/1\">Nancy Y. Ip</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>",
          "description": "Self-supervised pre-training methods have brought remarkable breakthroughs in\nthe understanding of text, image, and speech. Recent developments in genomics\nhas also adopted these pre-training methods for genome understanding. However,\nthey focus only on understanding haploid sequences, which hinders their\napplicability towards understanding genetic variations, also known as single\nnucleotide polymorphisms (SNPs), which is crucial for genome-wide association\nstudy. In this paper, we introduce SNP2Vec, a scalable self-supervised\npre-training approach for understanding SNP. We apply SNP2Vec to perform\nlong-sequence genomics modeling, and we evaluate the effectiveness of our\napproach on predicting Alzheimer's disease risk in a Chinese cohort. Our\napproach significantly outperforms existing polygenic risk score methods and\nall other baselines, including the model that is trained entirely with haploid\nsequences. We release our code and dataset on\nhttps://github.com/HLTCHKUST/snp2vec.",
          "link": "http://arxiv.org/abs/2204.06699",
          "publishedOn": "2022-04-16T00:51:43.806Z",
          "wordCount": null,
          "title": "SNP2Vec: Scalable Self-Supervised Pre-Training for Genome-Wide Association Study. (arXiv:2204.06699v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1903.09668",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yuexi Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Polson_N/0/1/0/all/0/1\">Nicholas G. Polson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolov_V/0/1/0/all/0/1\">Vadim O. Sokolov</a>",
          "description": "Deep Learning (DL) methods have emerged as one of the most powerful tools for\nfunctional approximation and prediction. While the representation properties of\nDL have been well studied, uncertainty quantification remains challenging and\nlargely unexplored. Data augmentation techniques are a natural approach to\nprovide uncertainty quantification and to incorporate stochastic Monte Carlo\nsearch into stochastic gradient descent (SGD) methods. The purpose of our paper\nis to show that training DL architectures with data augmentation leads to\nefficiency gains. We use the theory of scale mixtures of normals to derive data\naugmentation strategies for deep learning. This allows variants of the\nexpectation-maximization and MCMC algorithms to be brought to bear on these\nhigh dimensional nonlinear deep learning models. To demonstrate our\nmethodology, we develop data augmentation algorithms for a variety of commonly\nused activation functions: logit, ReLU, leaky ReLU and SVM. Our methodology is\ncompared to traditional stochastic gradient descent with back-propagation. Our\noptimization procedure leads to a version of iteratively re-weighted least\nsquares and can be implemented at scale with accelerated linear algebra methods\nproviding substantial improvement in speed. We illustrate our methodology on a\nnumber of standard datasets. Finally, we conclude with directions for future\nresearch.",
          "link": "http://arxiv.org/abs/1903.09668",
          "publishedOn": "2022-04-16T00:51:43.805Z",
          "wordCount": null,
          "title": "Data Augmentation for Bayesian Deep Learning. (arXiv:1903.09668v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.08988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1\">Tunazzina Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_D/0/1/0/all/0/1\">Dan Goldwasser</a>",
          "description": "Social media platforms provide convenient means for users to participate in\nmultiple online activities on various contents and create fast widespread\ninteractions. However, this rapidly growing access has also increased the\ndiverse information, and characterizing user types to understand people's\nlifestyle decisions shared in social media is challenging. In this paper, we\npropose a weakly supervised graph embedding based framework for understanding\nuser types. We evaluate the user embedding learned using weak supervision over\nwell-being related tweets from Twitter, focusing on 'Yoga', 'Keto diet'.\nExperiments on real-world datasets demonstrate that the proposed framework\noutperforms the baselines for detecting user types. Finally, we illustrate data\nanalysis on different types of users (e.g., practitioner vs. promotional) from\nour dataset. While we focus on lifestyle-related tweets (i.e., yoga, keto), our\nmethod for constructing user representation readily generalizes to other\ndomains.",
          "link": "http://arxiv.org/abs/2108.08988",
          "publishedOn": "2022-04-16T00:51:43.805Z",
          "wordCount": null,
          "title": "Twitter User Representation Using Weakly Supervised Graph Embedding. (arXiv:2108.08988v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.10075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Doumanidis_C/0/1/0/all/0/1\">Constantine Doumanidis</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Rajput_P/0/1/0/all/0/1\">Prashant Hari Narayan Rajput</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Maniatakos_M/0/1/0/all/0/1\">Michail Maniatakos</a> (1) ((1) New York University Abu Dhabi, (2) NYU Tandon School of Engineering)",
          "description": "Industrial Control Systems (ICS) have played a catalytic role in enabling the\n4th Industrial Revolution. ICS devices like Programmable Logic Controllers\n(PLCs), automate, monitor, and control critical processes in industrial,\nenergy, and commercial environments. The convergence of traditional Operational\nTechnology (OT) with Information Technology (IT) has opened a new and unique\nthreat landscape. This has inspired defense research that focuses heavily on\nMachine Learning (ML) based anomaly detection methods that run on external IT\nhardware, which means an increase in costs and the further expansion of the\nthreat landscape. To remove this requirement, we introduce the ICS machine\nlearning inference framework (ICSML) which enables the execution of ML model\ninference natively on the PLC. ICSML is implemented in IEC 61131-3 code and\nprovides several optimizations to bypass the limitations imposed by the\ndomain-specific languages. Therefore, it works \\emph{on every PLC without the\nneed for vendor support}. ICSML provides a complete set of components for the\ncreation of full ML models similarly to established ML frameworks. We run a\nseries of benchmarks studying memory and performance and compare our solution\nto the TFLite inference framework. At the same time, we develop domain-specific\nmodel optimizations to improve the efficiency of ICSML. To demonstrate the\nabilities of ICSML, we evaluate a case study of a real defense for\nprocess-aware attacks targeting a desalination plant.",
          "link": "http://arxiv.org/abs/2202.10075",
          "publishedOn": "2022-04-16T00:51:43.804Z",
          "wordCount": null,
          "title": "ICSML: Industrial Control Systems Machine Learning Inference Framework natively executing on IEC 61131-3 compliant devices. (arXiv:2202.10075v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lindstaahl_S/0/1/0/all/0/1\">Simon Lindst&#xe5;hl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Proutiere_A/0/1/0/all/0/1\">Alexandre Proutiere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonsson_A/0/1/0/all/0/1\">Andreas Jonsson</a>",
          "description": "In sliced networks, the shared tenancy of slices requires adaptive admission\ncontrol of data flows, based on measurements of network resources. In this\npaper, we investigate the design of measurement-based admission control\nschemes, deciding whether a new data flow can be admitted and in this case, on\nwhich slice. The objective is to devise a joint measurement and decision\nstrategy that returns a correct decision (e.g., the least loaded slice) with a\ncertain level of confidence while minimizing the measurement cost (the number\nof measurements made before committing to the decision). We study the design of\nsuch strategies for several natural admission criteria specifying what a\ncorrect decision is. For each of these criteria, using tools from best arm\nidentification in bandits, we first derive an explicit information-theoretical\nlower bound on the cost of any algorithm returning the correct decision with\nfixed confidence. We then devise a joint measurement and decision strategy\nachieving this theoretical limit. We compare empirically the measurement costs\nof these strategies, and compare them both to the lower bounds as well as a\nnaive measurement scheme. We find that our algorithm significantly outperforms\nthe naive scheme (by a factor $2-8$).",
          "link": "http://arxiv.org/abs/2204.06910",
          "publishedOn": "2022-04-16T00:51:43.799Z",
          "wordCount": null,
          "title": "Measurement-based Admission Control in Sliced Networks: A Best Arm Identification Approach. (arXiv:2204.06910v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wedler_M/0/1/0/all/0/1\">Mathies Wedler</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Stender_M/0/1/0/all/0/1\">Merten Stender</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Klein_M/0/1/0/all/0/1\">Marco Klein</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ehlers_S/0/1/0/all/0/1\">Svenja Ehlers</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hoffmann_N/0/1/0/all/0/1\">Norbert Hoffmann</a> (1 and 2) ((1) Hamburg University of Technology, (2) Imperial College London)",
          "description": "Supervised machine learning approaches require the formulation of a loss\nfunctional to be minimized in the training phase. Sequential data are\nubiquitous across many fields of research, and are often treated with Euclidean\ndistance-based loss functions that were designed for tabular data. For smooth\noscillatory data, those conventional approaches lack the ability to penalize\namplitude, frequency and phase prediction errors at the same time, and tend to\nbe biased towards amplitude errors. We introduce the surface similarity\nparameter (SSP) as a novel loss function that is especially useful for training\nmachine learning models on smooth oscillatory sequences. Our extensive\nexperiments on chaotic spatio-temporal dynamical systems indicate that the SSP\nis beneficial for shaping gradients, thereby accelerating the training process,\nreducing the final prediction error, and implementing a stronger regularization\neffect compared to using classical loss functions. The results indicate the\npotential of the novel loss metric particularly for highly complex and chaotic\ndata, such as data stemming from the nonlinear two-dimensional\nKuramoto-Sivashinsky equation and the linear propagation of dispersive surface\ngravity waves in fluids.",
          "link": "http://arxiv.org/abs/2204.06843",
          "publishedOn": "2022-04-16T00:51:43.796Z",
          "wordCount": null,
          "title": "Surface Similarity Parameter: A New Machine Learning Loss Metric for Oscillatory Spatio-Temporal Data. (arXiv:2204.06843v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Sheng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Min Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qingxiang Liu</a>",
          "description": "Federated learning (FL) is a distributed machine learning paradigm in which\nthe server periodically aggregates local model parameters from clients without\nassembling their private data. User-constrained communication bandwidth and the\nrequirement for personalized models pose severe challenges to FL. Federated\ndistillation (FD) is proposed to simultaneously address the two problems, which\nexchanges knowledge between the server and clients, supporting heterogeneous\nlocal models while significantly reducing communication overhead. However, most\nexisting FD methods require a proxy dataset, which is often unavailable.\nProxy-data-free FD approaches eliminate the need for additional public data\nbeyond clients' private data, but suffer from remarkable discrepancy among\nlocal knowledge due to model heterogeneity, leading to ambiguous representation\non the server and inevitable accuracy degradation. To tackle this issue, we\npropose a proxy-data-free FD algorithm based on distributed knowledge\ncongruence (FedDKC). FedDKC leverages well-designed refinement strategies to\nnarrow local knowledge differences into an acceptable upper bound to mitigate\nthe negative effects of knowledge incongruence. Specifically, from perspectives\nof peak probability and Shannon entropy of local knowledge, we design\nkernel-based knowledge refinement (KKR) and searching-based knowledge\nrefinement (SKR) respectively, and theoretically guarantee the refined-local\nknowledge can satisfy an approximately-similar distribution and be regarded as\ncongruent. Extensive experiments conducted on three common datasets demonstrate\nthat our proposed FedDKC method outperforms the state-of-the-art in 93.33% of\ncomparisons, and achieves faster convergence without increasing communication\noverhead.",
          "link": "http://arxiv.org/abs/2204.07028",
          "publishedOn": "2022-04-16T00:51:43.796Z",
          "wordCount": null,
          "title": "Exploring the Distributed Knowledge Congruence in Proxy-data-free Federated Distillation. (arXiv:2204.07028v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wysocki_O/0/1/0/all/0/1\">Oskar Wysocki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davies_J/0/1/0/all/0/1\">Jessica Katharine Davies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vigo_M/0/1/0/all/0/1\">Markel Vigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armstrong_A/0/1/0/all/0/1\">Anne Caroline Armstrong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1\">D&#xf3;nal Landers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1\">Rebecca Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andr&#xe9; Freitas</a>",
          "description": "This paper contributes with a pragmatic evaluation framework for explainable\nMachine Learning (ML) models for clinical decision support. The study revealed\na more nuanced role for ML explanation models, when these are pragmatically\nembedded in the clinical context. Despite the general positive attitude of\nhealthcare professionals (HCPs) towards explanations as a safety and trust\nmechanism, for a significant set of participants there were negative effects\nassociated with confirmation bias, accentuating model over-reliance and\nincreased effort to interact with the model. Also, contradicting one of its\nmain intended functions, standard explanatory models showed limited ability to\nsupport a critical understanding of the limitations of the model. However, we\nfound new significant positive effects which repositions the role of\nexplanations within a clinical context: these include reduction of automation\nbias, addressing ambiguous clinical cases (cases where HCPs were not certain\nabout their decision) and support of less experienced HCPs in the acquisition\nof new domain knowledge.",
          "link": "http://arxiv.org/abs/2204.05030",
          "publishedOn": "2022-04-16T00:51:43.795Z",
          "wordCount": null,
          "title": "Assessing the communication gap between AI models and healthcare professionals: explainability, utility and trust in AI-driven clinical decision-making. (arXiv:2204.05030v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skenderi_G/0/1/0/all/0/1\">Geri Skenderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joppi_C/0/1/0/all/0/1\">Christian Joppi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denitto_M/0/1/0/all/0/1\">Matteo Denitto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarpa_B/0/1/0/all/0/1\">Berniero Scarpa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cristani_M/0/1/0/all/0/1\">Marco Cristani</a>",
          "description": "We present Visuelle 2.0, the first dataset useful for facing diverse\nprediction problems that a fast-fashion company has to manage routinely.\nFurthermore, we demonstrate how the use of computer vision is substantial in\nthis scenario. Visuelle 2.0 contains data for 6 seasons / 5355 clothing\nproducts of Nuna Lie, a famous Italian company with hundreds of shops located\nin different areas within the country. In particular, we focus on a specific\nprediction problem, namely short-observation new product sale forecasting\n(SO-fore). SO-fore assumes that the season has started and a set of new\nproducts is on the shelves of the different stores. The goal is to forecast the\nsales for a particular horizon, given a short, available past (few weeks),\nsince no earlier statistics are available. To be successful, SO-fore approaches\nshould capture this short past and exploit other modalities or exogenous data.\nTo these aims, Visuelle 2.0 is equipped with disaggregated data at the\nitem-shop level and multi-modal information for each clothing item, allowing\ncomputer vision approaches to come into play. The main message that we deliver\nis that the use of image data with deep networks boosts performances obtained\nwhen using the time series in long-term forecasting scenarios, ameliorating the\nWAPE by 8.2% and the MAE by 7.7%. The dataset is available at:\nhttps://humaticslab.github.io/forecasting/visuelle.",
          "link": "http://arxiv.org/abs/2204.06972",
          "publishedOn": "2022-04-16T00:51:43.772Z",
          "wordCount": null,
          "title": "The multi-modal universe of fast-fashion: the Visuelle 2.0 benchmark. (arXiv:2204.06972v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.13669",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Herrera_C/0/1/0/all/0/1\">Calypso Herrera</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krach_F/0/1/0/all/0/1\">Florian Krach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ruyssen_P/0/1/0/all/0/1\">Pierre Ruyssen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teichmann_J/0/1/0/all/0/1\">Josef Teichmann</a>",
          "description": "This paper presents new machine learning approaches to approximate the\nsolutions of optimal stopping problems. The key idea of these methods is to use\nneural networks, where the parameters of the hidden layers are generated\nrandomly and only the last layer is trained, in order to approximate the\ncontinuation value. Our approaches are applicable to high dimensional problems\nwhere the existing approaches become increasingly impractical. In addition,\nsince our approaches can be optimized using simple linear regression, they are\neasy to implement and theoretical guarantees are provided. Our randomized\nreinforcement learning approach and randomized recurrent neural network\napproach outperform the state-of-the-art and other relevant machine learning\napproaches in Markovian and non-Markovian examples, respectively. In\nparticular, we test our approaches on Black-Scholes, Heston, rough Heston and\nfractional Brownian motion. Moreover, we show that they can also be used to\nefficiently compute Greeks of American options.",
          "link": "http://arxiv.org/abs/2104.13669",
          "publishedOn": "2022-04-16T00:51:43.772Z",
          "wordCount": null,
          "title": "Optimal Stopping via Randomized Neural Networks. (arXiv:2104.13669v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.06663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1\">Vinod Kumar Chauhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sukhdeep Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Anuj Sharma</a>",
          "description": "Despite being studied extensively for a few decades, handwritten character\nrecognition (HCR) is considered a challenging learning problem in pattern\nrecognition and there is very limited research on script independent models.\nThis is mainly because of diversity of scripts, focus of the conventional\nresearch on handcrafted feature extraction techniques, and unavailability of\npublic datasets and codes to reproduce the results. On the other hand, deep\nlearning has witnessed huge success in different areas of pattern recognition,\nincluding HCR, and provides end-to-end learning but it has been studied for\nspecific scripts only. In this paper, we have proposed a novel deep learning\narchitecture which exploits transfer learning and image-augmentation for\nend-to-end learning for script independent handwritten character recognition,\ncalled HCR-Net. HCR-Net is based on a novel transfer learning approach for HCR,\nwhere some of lower layers of a pre-trained network are utilized. Due to\ntransfer learning and image-augmentation, HCR-Net provides faster training,\nbetter performance and better generalizations, and can achieve up to 99\\%\nresults of its final accuracy in just first epoch. The experimental results on\npublicly available datasets of Bangla, Punjabi, Hindi, English, Swedish, Urdu,\nFarsi, Tibetan, Kannada, Malayalam, Telugu, Marathi, Nepali and Arabic\nlanguages prove the efficacy of HCR-Net and establishes several new benchmarks.\nFor reproducibility of the results and for the advancements of the HCR\nresearch, complete code is publicly released at\nhttps://github.com/jmdvinodjmd/HCR-Net.",
          "link": "http://arxiv.org/abs/2108.06663",
          "publishedOn": "2022-04-16T00:51:43.771Z",
          "wordCount": null,
          "title": "HCR-Net: A deep learning based script independent handwritten character recognition network. (arXiv:2108.06663v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03894",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yen_H/0/1/0/all/0/1\">Hao Yen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ku_P/0/1/0/all/0/1\">Pin-Jui Ku</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_C/0/1/0/all/0/1\">Chao-Han Huck Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_H/0/1/0/all/0/1\">Hu Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Siniscalchi_S/0/1/0/all/0/1\">Sabato Marco Siniscalchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "In this study, we propose a novel adversarial reprogramming (AR) approach for\nlow-resource spoken command recognition (SCR), and build an AR-SCR system. The\nAR procedure aims to modify the acoustic signals (from the target domain) to\nrepurpose a pretrained SCR model (from the source domain). To solve the label\nmismatches between source and target domains, and further improve the stability\nof AR, we propose a novel similarity-based label mapping technique to align\nclasses. In addition, the transfer learning (TL) technique is combined with the\noriginal AR process to improve the model adaptation capability. We evaluate the\nproposed AR-SCR system on three low-resource SCR datasets, including Arabic,\nLithuanian, and dysarthric Mandarin speech. Experimental results show that with\na pretrained AM trained on a large-scale English dataset, the proposed AR-SCR\nsystem outperforms the current state-of-the-art results on Arabic and\nLithuanian speech commands datasets, with only a limited amount of training\ndata.",
          "link": "http://arxiv.org/abs/2110.03894",
          "publishedOn": "2022-04-16T00:51:43.771Z",
          "wordCount": null,
          "title": "A Study of Low-Resource Speech Commands Recognition based on Adversarial Reprogramming. (arXiv:2110.03894v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.06246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cen_S/0/1/0/all/0/1\">Sarah H. Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>",
          "description": "Making an informed decision -- for example, when choosing a career or housing\n-- requires knowledge about the available options. Such knowledge is generally\nacquired through costly trial and error, but this learning process can be\ndisrupted by competition. In this work, we study how competition affects the\nlong-term outcomes of individuals as they learn. We build on a line of work\nthat models this setting as a two-sided matching market with bandit learners. A\nrecent result in this area states that it is impossible to simultaneously\nguarantee two natural desiderata: stability and low optimal regret for all\nagents. Resource-allocating platforms can point to this result as a\njustification for assigning good long-term outcomes to some agents and poor\nones to others. We show that this impossibility need not hold true. In\nparticular, by modeling two additional components of competition -- namely,\ncosts and transfers -- we prove that it is possible to simultaneously guarantee\nfour desiderata: stability, low optimal regret, fairness in the distribution of\nregret, and high social welfare.",
          "link": "http://arxiv.org/abs/2102.06246",
          "publishedOn": "2022-04-16T00:51:43.751Z",
          "wordCount": null,
          "title": "Regret, stability & fairness in matching markets with bandit learners. (arXiv:2102.06246v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.08746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tekgul_B/0/1/0/all/0/1\">Buse G. A. Tekgul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shelly Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marchal_S/0/1/0/all/0/1\">Samuel Marchal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asokan_N/0/1/0/all/0/1\">N. Asokan</a>",
          "description": "Recent work has shown that deep reinforcement learning (DRL) policies are\nvulnerable to adversarial perturbations. Adversaries can mislead policies of\nDRL agents by perturbing the state of the environment observed by the agents.\nExisting attacks are feasible in principle but face challenges in practice,\neither by being too slow to fool DRL policies in real time or by modifying past\nobservations stored in the agent's memory. We show that using the Universal\nAdversarial Perturbation (UAP) method to compute perturbations, independent of\nthe individual inputs to which they are applied to, can fool DRL policies\neffectively and in real time. We describe three such attack variants. Via an\nextensive evaluation using three Atari 2600 games, we show that our attacks are\neffective, as they fully degrade the performance of three different DRL agents\n(up to 100%, even when the $l_\\infty$ bound on the perturbation is as small as\n0.01). It is faster compared to the response time (0.6ms on average) of\ndifferent DRL policies, and considerably faster than prior attacks using\nadversarial perturbations (1.8ms on average). We also show that our attack\ntechnique is efficient, incurring an online computational cost of 0.027ms on\naverage. Using two further tasks involving robotic movement, we confirm that\nour results generalize to more complex DRL tasks. Furthermore, we demonstrate\nthat the effectiveness of known defenses diminishes against universal\nperturbations. We propose an effective technique that detects all known\nadversarial perturbations against DRL policies, including all the universal\nperturbations presented in this paper.",
          "link": "http://arxiv.org/abs/2106.08746",
          "publishedOn": "2022-04-16T00:51:43.737Z",
          "wordCount": null,
          "title": "Real-time Adversarial Perturbations against Deep Reinforcement Learning Policies: Attacks and Defenses. (arXiv:2106.08746v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.12451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1\">William Merrill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsilivis_N/0/1/0/all/0/1\">Nikolaos Tsilivis</a>",
          "description": "One way to interpret the behavior of a blackbox recurrent neural network\n(RNN) is to extract from it a more interpretable discrete computational model,\nlike a finite state machine, that captures its behavior. In this work, we\npropose a new method for extracting finite automata from RNNs inspired by the\nstate merging paradigm from grammatical inference. We demonstrate the\neffectiveness of our method on the Tomita languages benchmark, where we find\nthat it is able to extract faithful automata from RNNs trained on all languages\nin the benchmark. We find that extraction performance is aided by the number of\ndata provided during the extraction process, as well as, curiously, whether the\nRNN model is trained for additional epochs after perfectly learning its target\nlanguage. We use our method to analyze this phenomenon, finding that training\nbeyond convergence is useful because it leads to compression of the internal\nstate space of the RNN. This finding demonstrates how our method can be used\nfor interpretability and analysis of trained RNN models.",
          "link": "http://arxiv.org/abs/2201.12451",
          "publishedOn": "2022-04-16T00:51:43.737Z",
          "wordCount": null,
          "title": "Extracting Finite Automata from RNNs Using State Merging. (arXiv:2201.12451v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.03312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_D/0/1/0/all/0/1\">Duyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Cong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shuangzhi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>",
          "description": "Prevailing deep models are single-purpose and overspecialize at individual\ntasks. However, when being extended to new tasks, they typically forget\npreviously learned skills and learn from scratch. We address this issue by\nintroducing SkillNet, a general-purpose model that stitches together existing\nskills to learn new tasks more effectively. The key feature of our approach is\nthat it is sparsely activated guided by predefined skills. Different from\ntraditional dense models that always activate all the model parameters,\nSkillNet only activates parts of the model parameters whose skills are relevant\nto the target task. When learning for a new task, our approach precisely\nactivates required skills and also provides an option to add new skills. We\nevaluate on natural language understandings tasks and have the following\nfindings. First, with only one model checkpoint, SkillNet performs better than\ntask-specific fine-tuning and two multi-task learning baselines (i.e., dense\nmodel and Mixture-of-Experts model) on six tasks. Second, sparsely activated\npre-training further improves the overall performance. Third, SkillNet\nsignificantly outperforms baseline systems when being extended to new tasks.",
          "link": "http://arxiv.org/abs/2203.03312",
          "publishedOn": "2022-04-16T00:51:43.736Z",
          "wordCount": null,
          "title": "SkillNet: A Sparsely Activated Model for General-Purpose Natural Language Understanding. (arXiv:2203.03312v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.06257",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_P/0/1/0/all/0/1\">Pengyue Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Ling Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_D/0/1/0/all/0/1\">Dandan Lyu</a>",
          "description": "Predicting the number of infections in the anti-epidemic process is extremely\nbeneficial to the government in developing anti-epidemic strategies, especially\nin fine-grained geographic units. Previous works focus on low spatial\nresolution prediction, e.g., county-level, and preprocess data to the same\ngeographic level, which loses some useful information. In this paper, we\npropose a fine-grained population mobility data-based model (FGC-COVID)\nutilizing data of two geographic levels for community-level COVID-19\nprediction. We use the population mobility data between Census Block Groups\n(CBGs), which is a finer-grained geographic level than community, to build the\ngraph and capture the dependencies between CBGs using graph neural networks\n(GNNs). To mine as finer-grained patterns as possible for prediction, a spatial\nweighted aggregation module is introduced to aggregate the embeddings of CBGs\nto community level based on their geographic affiliation and spatial\nautocorrelation. Extensive experiments on 300 days LA city COVID-19 data\nindicate our model outperforms existing forecasting models on community-level\nCOVID-19 prediction.",
          "link": "http://arxiv.org/abs/2202.06257",
          "publishedOn": "2022-04-16T00:51:43.731Z",
          "wordCount": null,
          "title": "Fine-Grained Population Mobility Data-Based Community-Level COVID-19 Prediction Model. (arXiv:2202.06257v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.11234",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Diethe_T/0/1/0/all/0/1\">Tom Diethe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Flach_P/0/1/0/all/0/1\">Peter Flach</a>",
          "description": "The use of episodic memory in continual learning has demonstrated\neffectiveness for alleviating catastrophic forgetting. In recent studies,\ngradient-based approaches have been developed to make more efficient use of\ncompact episodic memory. Such approaches refine the gradients resulting from\nnew samples by those from memorized samples, aiming to reduce the diversity of\ngradients from different tasks. In this paper, we clarify the relation between\ndiversity of gradients and discriminativeness of representations, showing\nshared as well as conflicting interests between Deep Metric Learning and\ncontinual learning, thus demonstrating pros and cons of learning discriminative\nrepresentations in continual learning. Based on these findings, we propose a\nsimple method -- Semi-Discriminative Representation Loss (SDRL) -- for\ncontinual learning. In comparison with state-of-the-art methods, SDRL shows\nbetter performance with low computational cost on multiple benchmark tasks in\nthe setting of online continual learning.",
          "link": "http://arxiv.org/abs/2006.11234",
          "publishedOn": "2022-04-16T00:51:43.712Z",
          "wordCount": null,
          "title": "Semi-Discriminative Representation Loss for Online Continual Learning. (arXiv:2006.11234v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.14798",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Fang_L/0/1/0/all/0/1\">Lidong Fang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ge_P/0/1/0/all/0/1\">Pei Ge</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+E_W/0/1/0/all/0/1\">Weinan E</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lei_H/0/1/0/all/0/1\">Huan Lei</a>",
          "description": "A long standing problem in the modeling of non-Newtonian hydrodynamics of\npolymeric flows is the availability of reliable and interpretable hydrodynamic\nmodels that faithfully encode the underlying micro-scale polymer dynamics. The\nmain complication arises from the long polymer relaxation time, the complex\nmolecular structure and heterogeneous interaction. DeePN$^2$, a deep\nlearning-based non-Newtonian hydrodynamic model, has been proposed and has\nshown some success in systematically passing the micro-scale structural\nmechanics information to the macro-scale hydrodynamics for suspensions with\nsimple polymer conformation and bond potential. The model retains a\nmulti-scaled nature by mapping the polymer configurations into a set of\nsymmetry-preserving macro-scale features. The extended constitutive laws for\nthese macro-scale features can be directly learned from the kinetics of their\nmicro-scale counterparts. In this paper, we develop DeePN$^2$ using more\ncomplex micro-structural models. We show that DeePN$^2$ can faithfully capture\nthe broadly overlooked viscoelastic differences arising from the specific\nmolecular structural mechanics without human intervention.",
          "link": "http://arxiv.org/abs/2112.14798",
          "publishedOn": "2022-04-16T00:51:43.711Z",
          "wordCount": null,
          "title": "DeePN$^2$: A deep learning-based non-Newtonian hydrodynamic model. (arXiv:2112.14798v3 [physics.comp-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castellani_A/0/1/0/all/0/1\">Andrea Castellani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmitt_S/0/1/0/all/0/1\">Sebastian Schmitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hammer_B/0/1/0/all/0/1\">Barbara Hammer</a>",
          "description": "Data stream classification is an important problem in the field of machine\nlearning. Due to the non-stationary nature of the data where the underlying\ndistribution changes over time (concept drift), the model needs to continuously\nadapt to new data statistics. Stream-based Active Learning (AL) approaches\naddress this problem by interactively querying a human expert to provide new\ndata labels for the most recent samples, within a limited budget. Existing AL\nstrategies assume that labels are immediately available, while in a real-world\nscenario the expert requires time to provide a queried label (verification\nlatency), and by the time the requested labels arrive they may not be relevant\nanymore. In this article, we investigate the influence of finite,\ntime-variable, and unknown verification delay, in the presence of concept drift\non AL approaches. We propose PRopagate (PR), a latency independent utility\nestimator which also predicts the requested, but not yet known, labels.\nFurthermore, we propose a drift-dependent dynamic budget strategy, which uses a\nvariable distribution of the labelling budget over time, after a detected\ndrift. Thorough experimental evaluation, with both synthetic and real-world\nnon-stationary datasets, and different settings of verification latency and\nbudget are conducted and analyzed. We empirically show that the proposed method\nconsistently outperforms the state-of-the-art. Additionally, we demonstrate\nthat with variable budget allocation in time, it is possible to boost the\nperformance of AL strategies, without increasing the overall labeling budget.",
          "link": "http://arxiv.org/abs/2204.06822",
          "publishedOn": "2022-04-16T00:51:43.708Z",
          "wordCount": null,
          "title": "Stream-based Active Learning with Verification Latency in Non-stationary Environments. (arXiv:2204.06822v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06955",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sitnik_D/0/1/0/all/0/1\">Dario Sitnik</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kopriva_I/0/1/0/all/0/1\">Ivica Kopriva</a>",
          "description": "Accurate segmentation of medical images is essential for diagnosis and\ntreatment of diseases. These problems are solved by highly complex models, such\nas deep networks (DN), requiring a large amount of labeled data for training.\nThereby, many DNs possess task- or imaging modality specific architectures with\na decision-making process that is often hard to explain and interpret. Here, we\npropose a framework that embeds existing DNs into a low-dimensional subspace\ninduced by the learnable explicit feature map (LEFM) layer. Compared to the\nexisting DN, the framework adds one hyperparameter and only modestly increase\nthe number of learnable parameters. The method is aimed at, but not limited to,\nsegmentation of low-dimensional medical images, such as color histopathological\nimages of stained frozen sections. Since features in the LEFM layer are\npolynomial functions of the original features, proposed LEFM-Nets contribute to\nthe interpretability of network decisions. In this work, we combined LEFM with\nthe known networks: DeepLabv3+, UNet, UNet++ and MA-net. New LEFM-Nets are\napplied to the segmentation of adenocarcinoma of a colon in a liver from images\nof hematoxylin and eosin (H&E) stained frozen sections. LEFM-Nets are also\ntested on nuclei segmentation from images of H&E stained frozen sections of ten\nhuman organs. On the first problem, LEFM-Nets achieved statistically\nsignificant performance improvement in terms of micro balanced accuracy and\n$F_1$ score than original networks. LEFM-Nets achieved only better performance\nin comparison with the original networks on the second problem. The source code\nis available at https://github.com/dsitnik/lefm.",
          "link": "http://arxiv.org/abs/2204.06955",
          "publishedOn": "2022-04-16T00:51:43.708Z",
          "wordCount": null,
          "title": "LEFM-Nets: Learnable Explicit Feature Map Deep Networks for Segmentation of Histopathological Images of Frozen Sections. (arXiv:2204.06955v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mehta_I/0/1/0/all/0/1\">Ishit Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandraker_M/0/1/0/all/0/1\">Manmohan Chandraker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramamoorthi_R/0/1/0/all/0/1\">Ravi Ramamoorthi</a>",
          "description": "Coordinate-based neural networks parameterizing implicit surfaces have\nemerged as efficient representations of geometry. They effectively act as\nparametric level sets with the zero-level set defining the surface of interest.\nWe present a framework that allows applying deformation operations defined for\ntriangle meshes onto such implicit surfaces. Several of these operations can be\nviewed as energy-minimization problems that induce an instantaneous flow field\non the explicit surface. Our method uses the flow field to deform parametric\nimplicit surfaces by extending the classical theory of level sets. We also\nderive a consolidated view for existing methods on differentiable surface\nextraction and rendering, by formalizing connections to the level-set theory.\nWe show that these methods drift from the theory and that our approach exhibits\nimprovements for applications like surface smoothing, mean-curvature flow,\ninverse rendering and user-defined editing on implicit geometry.",
          "link": "http://arxiv.org/abs/2204.07159",
          "publishedOn": "2022-04-16T00:51:43.708Z",
          "wordCount": null,
          "title": "A Level Set Theory for Neural Implicit Evolution under Explicit Flows. (arXiv:2204.07159v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gorinova_M/0/1/0/all/0/1\">Maria I. Gorinova</a>",
          "description": "Probabilistic programming is a growing area that strives to make statistical\nanalysis more accessible, by separating probabilistic modelling from\nprobabilistic inference. In practice this decoupling is difficult. No single\ninference algorithm can be used as a probabilistic programming back-end that is\nsimultaneously reliable, efficient, black-box, and general. Probabilistic\nprogramming languages often choose a single algorithm to apply to a given\nproblem, thus inheriting its limitations. While substantial work has been done\nboth to formalise probabilistic programming and to improve efficiency of\ninference, there has been little work that makes use of the available program\nstructure, by formally analysing it, to better utilise the underlying inference\nalgorithm.\n\nThis dissertation presents three novel techniques (both static and dynamic),\nwhich aim to improve probabilistic programming using program analysis. The\ntechniques analyse a probabilistic program and adapt it to make inference more\nefficient, sometimes in a way that would have been tedious or impossible to do\nby hand.",
          "link": "http://arxiv.org/abs/2204.06868",
          "publishedOn": "2022-04-16T00:51:43.700Z",
          "wordCount": null,
          "title": "Program Analysis of Probabilistic Programs. (arXiv:2204.06868v1 [cs.PL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ley_D/0/1/0/all/0/1\">Dan Ley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Saumitra Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1\">Daniele Magazzeni</a>",
          "description": "Counterfactual explanations have been widely studied in explainability, with\na range of application dependent methods emerging in fairness, recourse and\nmodel understanding. However, the major shortcoming associated with these\nmethods is their inability to provide explanations beyond the local or\ninstance-level. While some works touch upon the notion of a global explanation,\ntypically suggesting to aggregate masses of local explanations in the hope of\nascertaining global properties, few provide frameworks that are either reliable\nor computationally tractable. Meanwhile, practitioners are requesting more\nefficient and interactive explainability tools. We take this opportunity to\ninvestigate existing global methods, with a focus on implementing and improving\nActionable Recourse Summaries (AReS), the only known global counterfactual\nexplanation framework for recourse.",
          "link": "http://arxiv.org/abs/2204.06917",
          "publishedOn": "2022-04-16T00:51:43.700Z",
          "wordCount": null,
          "title": "Global Counterfactual Explanations: Investigations, Implementations and Improvements. (arXiv:2204.06917v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1\">Payal Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Chenyan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_G/0/1/0/all/0/1\">Guolin Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwary_S/0/1/0/all/0/1\">Saurabh Tiwary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1\">Paul Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xia Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "We present an efficient method of pretraining large-scale autoencoding\nlanguage models using training signals generated by an auxiliary model.\nOriginated in ELECTRA, this training strategy has demonstrated\nsample-efficiency to pretrain models at the scale of hundreds of millions of\nparameters. In this work, we conduct a comprehensive empirical study, and\npropose a recipe, namely \"Model generated dEnoising TRaining Objective\"\n(METRO), which incorporates some of the best modeling techniques developed\nrecently to speed up, stabilize, and enhance pretrained language models without\ncompromising model effectiveness. The resultant models, METRO-LM, consisting of\nup to 5.4 billion parameters, achieve new state-of-the-art on the GLUE,\nSuperGLUE, and SQuAD benchmarks. More importantly, METRO-LM are efficient in\nthat they often outperform previous large models with significantly smaller\nmodel sizes and lower pretraining cost.",
          "link": "http://arxiv.org/abs/2204.06644",
          "publishedOn": "2022-04-16T00:51:43.699Z",
          "wordCount": null,
          "title": "METRO: Efficient Denoising Pretraining of Large Scale Autoencoding Language Models with Model Generated Signals. (arXiv:2204.06644v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06627",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muench_S/0/1/0/all/0/1\">Stefan Muench</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_D/0/1/0/all/0/1\">Darshankumar Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heindel_L/0/1/0/all/0/1\">Leonhard Heindel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hantschke_P/0/1/0/all/0/1\">Peter Hantschke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roellig_M/0/1/0/all/0/1\">Mike Roellig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaestner_M/0/1/0/all/0/1\">Markus Kaestner</a>",
          "description": "This paper proposes a computationally efficient methodology to predict the\ndamage progression in solder contacts of electronic components using\ntemperature-time curves. For this purpose, two machine learning algorithms, a\nMultilayer Perceptron and a Long Short-Term Memory network, are trained and\ncompared with respect to their prediction accuracy and the required amount of\ntraining data. The training is performed using synthetic, normally distributed\ndata that is realistic for automotive applications. A finite element model of a\nsimple bipolar chip resistor in surface mount technology configuration is used\nto numerically compute the synthetic data. As a result, both machine learning\nalgorithms show a relevant accuracy for the prediction of accumulated creep\nstrains. With a training data length of 350 hours (12.5% of the available\ntraining data), both models show a constantly good fitting performance of $R^2$\nof 0.72 for the Multilayer Perceptron and $R^2$ of 0.87 for the Long Short-Term\nMemory network. The prediction errors of the accumulated creep strains are less\nthan 10% with an amount of 350 hours training data and decreases to less than 5\n% when using further data. Therefore, both approaches are promising for the\nlifetime prediction directly on the electronic device.",
          "link": "http://arxiv.org/abs/2204.06627",
          "publishedOn": "2022-04-16T00:51:43.698Z",
          "wordCount": null,
          "title": "Performance Assessment of different Machine Learning Algorithm for Life-Time Prediction of Solder Joints based on Synthetic Data. (arXiv:2204.06627v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamm_K/0/1/0/all/0/1\">Keaton Hamm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henscheid_N/0/1/0/all/0/1\">Nick Henscheid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">Shujie Kang</a>",
          "description": "In this paper, we propose Wasserstein Isometric Mapping (Wassmap), a\nparameter-free nonlinear dimensionality reduction technique that provides\nsolutions to some drawbacks in existing global nonlinear dimensionality\nreduction algorithms in imaging applications. Wassmap represents images via\nprobability measures in Wasserstein space, then uses pairwise quadratic\nWasserstein distances between the associated measures to produce a\nlow-dimensional, approximately isometric embedding. We show that the algorithm\nis able to exactly recover parameters of some image manifolds including those\ngenerated by translations or dilations of a fixed generating measure.\nAdditionally, we show that a discrete version of the algorithm retrieves\nparameters from manifolds generated from discrete measures by providing a\ntheoretical bridge to transfer recovery results from functional data to\ndiscrete data. Testing of the proposed algorithms on various image data\nmanifolds show that Wassmap yields good embeddings compared with other global\ntechniques.",
          "link": "http://arxiv.org/abs/2204.06645",
          "publishedOn": "2022-04-16T00:51:43.697Z",
          "wordCount": null,
          "title": "Wassmap: Wasserstein Isometric Mapping for Image Manifold Learning. (arXiv:2204.06645v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.09146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raposo_G/0/1/0/all/0/1\">Gon&#xe7;alo Raposo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_R/0/1/0/all/0/1\">Rui Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_B/0/1/0/all/0/1\">Bruno Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coheur_L/0/1/0/all/0/1\">Lu&#xed;sa Coheur</a>",
          "description": "In conversational question answering, systems must correctly interpret the\ninterconnected interactions and generate knowledgeable answers, which may\nrequire the retrieval of relevant information from a background repository.\nRecent approaches to this problem leverage neural language models, although\ndifferent alternatives can be considered in terms of modules for (a)\nrepresenting user questions in context, (b) retrieving the relevant background\ninformation, and (c) generating the answer. This work presents a conversational\nquestion answering system designed specifically for the Search-Oriented\nConversational AI (SCAI) shared task, and reports on a detailed analysis of its\nquestion rewriting module. In particular, we considered different variations of\nthe question rewriting module to evaluate the influence on the subsequent\ncomponents, and performed a careful analysis of the results obtained with the\nbest system configuration. Our system achieved the best performance in the\nshared task and our analysis emphasizes the importance of the conversation\ncontext representation for the overall system performance.",
          "link": "http://arxiv.org/abs/2201.09146",
          "publishedOn": "2022-04-16T00:51:43.697Z",
          "wordCount": null,
          "title": "Question rewriting? Assessing its importance for conversational question answering. (arXiv:2201.09146v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.13001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1\">MohammadJavad Azizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_T/0/1/0/all/0/1\">Thang Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1\">Yasin Abbasi-Yadkori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andr&#xe1;s Gy&#xf6;rgy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vernade_C/0/1/0/all/0/1\">Claire Vernade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>",
          "description": "We study a sequential decision problem where the learner faces a sequence of\n$K$-armed stochastic bandit tasks. The tasks may be designed by an adversary,\nbut the adversary is constrained to choose the optimal arm of each task in a\nsmaller (but unknown) subset of $M$ arms. The task boundaries might be known\n(the bandit meta-learning setting), or unknown (the non-stationary bandit\nsetting), and the number of tasks $N$ as well as the total number of rounds $T$\nare known ($N$ could be unknown in the meta-learning setting). We design an\nalgorithm based on a reduction to bandit submodular maximization, and show that\nits regret in both settings is smaller than the simple baseline of\n$\\tilde{O}(\\sqrt{KNT})$ that can be obtained by using standard algorithms\ndesigned for non-stationary bandit problems. For the bandit meta-learning\nproblem with fixed task length $\\tau$, we show that the regret of the algorithm\nis bounded as $\\tilde{O}(N\\sqrt{M \\tau}+N^{2/3})$. Under additional assumptions\non the identifiability of the optimal arms in each task, we show a bandit\nmeta-learning algorithm with an improved $\\tilde{O}(N\\sqrt{M \\tau}+N^{1/2})$\nregret.",
          "link": "http://arxiv.org/abs/2202.13001",
          "publishedOn": "2022-04-16T00:51:43.696Z",
          "wordCount": null,
          "title": "Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms. (arXiv:2202.13001v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yuanyuan Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_Jaccard_J/0/1/0/all/0/1\">Julian Jang-Jaccard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabrina_F/0/1/0/all/0/1\">Fariza Sabrina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camtepe_S/0/1/0/all/0/1\">Seyit Camtepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boulic_M/0/1/0/all/0/1\">Mikael Boulic</a>",
          "description": "Anomaly detection for indoor air quality (IAQ) data has become an important\narea of research as the quality of air is closely related to human health and\nwell-being. However, traditional statistics and shallow machine learning-based\napproaches in anomaly detection in the IAQ area could not detect anomalies\ninvolving the observation of correlations across several data points (i.e.,\noften referred to as long-term dependences). We propose a hybrid deep learning\nmodel that combines LSTM with Autoencoder for anomaly detection tasks in IAQ to\naddress this issue. In our approach, the LSTM network is comprised of multiple\nLSTM cells that work with each other to learn the long-term dependences of the\ndata in a time-series sequence. Autoencoder identifies the optimal threshold\nbased on the reconstruction loss rates evaluated on every data across all\ntime-series sequences. Our experimental results, based on the Dunedin CO2\ntime-series dataset obtained through a real-world deployment of the schools in\nNew Zealand, demonstrate a very high and robust accuracy rate (99.50%) that\noutperforms other similar models.",
          "link": "http://arxiv.org/abs/2204.06701",
          "publishedOn": "2022-04-16T00:51:43.629Z",
          "wordCount": null,
          "title": "LSTM-Autoencoder based Anomaly Detection for Indoor Air Quality Time Series Data. (arXiv:2204.06701v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.02693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsubara_Y/0/1/0/all/0/1\">Yoshitomo Matsubara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callegaro_D/0/1/0/all/0/1\">Davide Callegaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levorato_M/0/1/0/all/0/1\">Marco Levorato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Restuccia_F/0/1/0/all/0/1\">Francesco Restuccia</a>",
          "description": "Although mission-critical applications require the use of deep neural\nnetworks (DNNs), their continuous execution at mobile devices results in a\nsignificant increase in energy consumption. While edge offloading can decrease\nenergy consumption, erratic patterns in channel quality, network and edge\nserver load can lead to severe disruption of the system's key operations. An\nalternative approach, called split computing, generates compressed\nrepresentations within the model (called \"bottlenecks\"), to reduce bandwidth\nusage and energy consumption. Prior work has proposed approaches that introduce\nadditional layers, to the detriment of energy consumption and latency. For this\nreason, we propose a new framework called BottleFit, which, in addition to\ntargeted DNN architecture modifications, includes a novel training strategy to\nachieve high accuracy even with strong compression rates. We apply BottleFit on\ncutting-edge DNN models in image classification, and show that BottleFit\nachieves 77.1% data compression with up to 0.6% accuracy loss on ImageNet\ndataset, while state of the art such as SPINN loses up to 6% in accuracy. We\nexperimentally measure the power consumption and latency of an image\nclassification application running on an NVIDIA Jetson Nano board (GPU-based)\nand a Raspberry PI board (GPU-less). We show that BottleFit decreases power\nconsumption and latency respectively by up to 49% and 89% with respect to\n(w.r.t.) local computing and by 37% and 55% w.r.t. edge offloading. We also\ncompare BottleFit with state-of-the-art autoencoders-based approaches, and show\nthat (i) BottleFit reduces power consumption and execution time respectively by\nup to 54% and 44% on the Jetson and 40% and 62% on Raspberry PI; (ii) the size\nof the head model executed on the mobile device is 83 times smaller. We publish\nthe code repository for reproducibility of the results in this study.",
          "link": "http://arxiv.org/abs/2201.02693",
          "publishedOn": "2022-04-16T00:51:43.629Z",
          "wordCount": null,
          "title": "BottleFit: Learning Compressed Representations in Deep Neural Networks for Effective and Efficient Split Computing. (arXiv:2201.02693v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahabandu_D/0/1/0/all/0/1\">Dinuka Sahabandu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mertoguno_S/0/1/0/all/0/1\">Sukarno Mertoguno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poovendran_R/0/1/0/all/0/1\">Radha Poovendran</a>",
          "description": "Binary analysis of software is a critical step in cyber forensics\napplications such as program vulnerability assessment and malware detection.\nThis involves interpreting instructions executed by software and often\nnecessitates converting the software's binary file data to assembly language.\nThe conversion process requires information about the binary file's target\ninstruction set architecture (ISA). However, ISA information might not be\nincluded in binary files due to compilation errors, partial downloads, or\nadversarial corruption of file metadata. Machine learning (ML) is a promising\nmethodology that can be used to identify the target ISA using binary data in\nthe object code section of binary files. In this paper we propose a binary code\nfeature extraction model to improve the accuracy and scalability of ML-based\nISA identification methods. Our feature extraction model can be used in the\nabsence of domain knowledge about the ISAs. Specifically, we adapt models from\nnatural language processing (NLP) to i) identify successive byte patterns\ncommonly observed in binary codes, ii) estimate the significance of each byte\npattern to a binary file, and iii) estimate the relevance of each byte pattern\nin distinguishing between ISAs. We introduce character-level features of\nencoded binaries to identify fine-grained bit patterns inherent to each ISA. We\nuse a dataset with binaries from 12 different ISAs to evaluate our approach.\nEmpirical evaluations show that using our byte-level features in ML-based ISA\nidentification results in an 8% higher accuracy than the state-of-the-art\nfeatures based on byte-histograms and byte pattern signatures. We observe that\ncharacter-level features allow reducing the size of the feature set by up to\n16x while maintaining accuracy above 97%.",
          "link": "http://arxiv.org/abs/2204.06624",
          "publishedOn": "2022-04-16T00:51:43.628Z",
          "wordCount": null,
          "title": "A Natural Language Processing Approach for Instruction Set Architecture Identification. (arXiv:2204.06624v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feijie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shiqi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Song Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Z/0/1/0/all/0/1\">Zhihao Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1\">Weihua Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jie Zhang</a>",
          "description": "Traditional one-bit compressed stochastic gradient descent can not be\ndirectly employed in multi-hop all-reduce, a widely adopted distributed\ntraining paradigm in network-intensive high-performance computing systems such\nas public clouds. According to our theoretical findings, due to the cascading\ncompression, the training process has considerable deterioration on the\nconvergence performance. To overcome this limitation, we implement a sign-bit\ncompression-based learning synchronization framework, Marsit. It prevents\ncascading compression via an elaborate bit-wise operation for unbiased sign\naggregation and its specific global compensation mechanism for mitigating\ncompression deviation. The proposed framework retains the same theoretical\nconvergence rate as non-compression mechanisms. Experimental results\ndemonstrate that Marsit reduces up to 35% training time while preserving the\nsame accuracy as training without compression.",
          "link": "http://arxiv.org/abs/2204.06787",
          "publishedOn": "2022-04-16T00:51:43.628Z",
          "wordCount": null,
          "title": "Sign Bit is Enough: A Learning Synchronization Framework for Multi-hop All-reduce with Ultimate Compression. (arXiv:2204.06787v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06904",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Chen_Q/0/1/0/all/0/1\">Qiuhao Chen</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Du_Y/0/1/0/all/0/1\">Yuxuan Du</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhao_Q/0/1/0/all/0/1\">Qi Zhao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jiao_Y/0/1/0/all/0/1\">Yuling Jiao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lu_X/0/1/0/all/0/1\">Xiliang Lu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wu_X/0/1/0/all/0/1\">Xingyao Wu</a>",
          "description": "Efficient quantum compiling tactics greatly enhance the capability of quantum\ncomputers to execute complicated quantum algorithms. Due to its fundamental\nimportance, a plethora of quantum compilers has been designed in past years.\nHowever, there are several caveats to current protocols, which are low\noptimality, high inference time, limited scalability, and lack of universality.\nTo compensate for these defects, here we devise an efficient and practical\nquantum compiler assisted by advanced deep reinforcement learning (RL)\ntechniques, i.e., data generation, deep Q-learning, and AQ* search. In this\nway, our protocol is compatible with various quantum machines and can be used\nto compile multi-qubit operators. We systematically evaluate the performance of\nour proposal in compiling quantum operators with both inverse-closed and\ninverse-free universal basis sets. In the task of single-qubit operator\ncompiling, our proposal outperforms other RL-based quantum compilers in the\nmeasure of compiling sequence length and inference time. Meanwhile, the output\nsolution is near-optimal, guaranteed by the Solovay-Kitaev theorem. Notably,\nfor the inverse-free universal basis set, the achieved sequence length\ncomplexity is comparable with the inverse-based setting and dramatically\nadvances previous methods. These empirical results contribute to improving the\ninverse-free Solovay-Kitaev theorem. In addition, for the first time, we\ndemonstrate how to leverage RL-based quantum compilers to accomplish two-qubit\noperator compiling. The achieved results open an avenue for integrating RL with\nquantum compiling to unify efficiency and practicality and thus facilitate the\nexploration of quantum advantages.",
          "link": "http://arxiv.org/abs/2204.06904",
          "publishedOn": "2022-04-16T00:51:43.628Z",
          "wordCount": null,
          "title": "Efficient and practical quantum compiler towards multi-qubit systems with deep reinforcement learning. (arXiv:2204.06904v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07122",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Arvinte_M/0/1/0/all/0/1\">Marius Arvinte</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tamir_J/0/1/0/all/0/1\">Jonathan I Tamir</a>",
          "description": "Channel estimation is a critical task in multiple-input multiple-output\ndigital communications that has effects on end-to-end system performance. In\nthis work, we introduce a novel approach for channel estimation using deep\nscore-based generative models. These models are trained to estimate the\ngradient of the log-prior distribution, and can be used to iteratively refine\nestimates, given observed measurements of a signal. We introduce a framework\nfor training score-based generative models for wireless channels, as well as\nperforming channel estimation using posterior sampling at test time. We derive\ntheoretical robustness guarantees of channel estimation with posterior sampling\nin single-input single-output scenarios, and show that the observations\nregarding estimation performance are verified experimentally in MIMO channels.\nOur results in simulated clustered delay line channels show competitive\nin-distribution performance without error floors in the high signal-to-noise\nratio regime, and robust out-of-distribution performance, outperforming\ncompeting deep learning methods by up to 5 dB in end-to-end communication\nperformance, while the complexity analysis reveals how model architecture can\nefficiently trade performance for estimation latency.",
          "link": "http://arxiv.org/abs/2204.07122",
          "publishedOn": "2022-04-16T00:51:43.628Z",
          "wordCount": null,
          "title": "MIMO Channel Estimation using Score-Based Generative Models. (arXiv:2204.07122v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.03555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1\">Alexei Baevski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiantong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babu_A/0/1/0/all/0/1\">Arun Babu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiatao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1\">Michael Auli</a>",
          "description": "While the general idea of self-supervised learning is identical across\nmodalities, the actual algorithms and objectives differ widely because they\nwere developed with a single modality in mind. To get us closer to general\nself-supervised learning, we present data2vec, a framework that uses the same\nlearning method for either speech, NLP or computer vision. The core idea is to\npredict latent representations of the full input data based on a masked view of\nthe input in a self-distillation setup using a standard Transformer\narchitecture. Instead of predicting modality-specific targets such as words,\nvisual tokens or units of human speech which are local in nature, data2vec\npredicts contextualized latent representations that contain information from\nthe entire input. Experiments on the major benchmarks of speech recognition,\nimage classification, and natural language understanding demonstrate a new\nstate of the art or competitive performance to predominant approaches.",
          "link": "http://arxiv.org/abs/2202.03555",
          "publishedOn": "2022-04-16T00:51:43.627Z",
          "wordCount": null,
          "title": "data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language. (arXiv:2202.03555v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Esmaeilpour_M/0/1/0/all/0/1\">Mohammad Esmaeilpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cardinal_P/0/1/0/all/0/1\">Patrick Cardinal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koerich_A/0/1/0/all/0/1\">Alessandro Lameiras Koerich</a>",
          "description": "This paper investigates the impact of different standard environmental sound\nrepresentations (spectrograms) on the recognition performance and adversarial\nattack robustness of a victim residual convolutional neural network, namely\nResNet-18. Our main motivation for focusing on such a front-end classifier\nrather than other complex architectures is balancing recognition accuracy and\nthe total number of training parameters. Herein, we measure the impact of\ndifferent settings required for generating more informative Mel-frequency\ncepstral coefficient (MFCC), short-time Fourier transform (STFT), and discrete\nwavelet transform (DWT) representations on our front-end model. This\nmeasurement involves comparing the classification performance over the\nadversarial robustness. We demonstrate an inverse relationship between\nrecognition accuracy and model robustness against six benchmarking attack\nalgorithms on the balance of average budgets allocated by the adversary and the\nattack cost. Moreover, our experimental results have shown that while the\nResNet-18 model trained on DWT spectrograms achieves a high recognition\naccuracy, attacking this model is relatively more costly for the adversary than\nother 2D representations. We also report some results on different\nconvolutional neural network architectures such as ResNet-34, ResNet-56,\nAlexNet, and GoogLeNet, SB-CNN, and LSTM-based.",
          "link": "http://arxiv.org/abs/2204.07018",
          "publishedOn": "2022-04-16T00:51:43.560Z",
          "wordCount": 664,
          "title": "From Environmental Sound Representation to Robustness of 2D CNN Models Against Adversarial Attacks. (arXiv:2204.07018v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1\">Hengyue Pan</a>",
          "description": "Convolutional neural network (CNN) achieves impressive success in the field\nof computer vision during the past few decades. As the core of CNNs, image\nconvolution operation helps CNNs to achieve good performance on image-related\ntasks. However, image convolution is hard to be implemented and parallelized.\nIn this paper, we propose a novel neural network model, namely CEMNet, that can\nbe trained in frequency domain. The most important motivation of this research\nis that we can use the very simple element-wise multiplication operation to\nreplace the image convolution in frequency domain based on Cross-Correlation\nTheorem. We further introduce Weight Fixation Mechanism to alleviate\nover-fitting, and analyze the working behavior of Batch Normalization, Leaky\nReLU and Dropout in frequency domain to design their counterparts for CEMNet.\nAlso, to deal with complex inputs brought by DFT, we design two branch network\nstructure for CEMNet. Experimental results imply that CEMNet works well in\nfrequency domain, and achieve good performance on MNIST and CIFAR-10 databases.\nTo our knowledge, CEMNet is the first model trained in Fourier Domain that\nachieves more than 70\\% validation accuracy on CIFAR-10 database.",
          "link": "http://arxiv.org/abs/2204.06718",
          "publishedOn": "2022-04-16T00:51:43.226Z",
          "wordCount": 621,
          "title": "Learning Convolutional Neural Networks in Frequency Domain. (arXiv:2204.06718v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07124",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Blumlein_T/0/1/0/all/0/1\">Theresa Bl&#xfc;mlein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Persson_J/0/1/0/all/0/1\">Joel Persson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>",
          "description": "Dynamic treatment regimes (DTRs) are used in medicine to tailor sequential\ntreatment decisions to patients by considering patient heterogeneity. Common\nmethods for learning optimal DTRs, however, have shortcomings: they are\ntypically based on outcome prediction and not treatment effect estimation, or\nthey use linear models that are restrictive for patient data from modern\nelectronic health records. To address these shortcomings, we develop two novel\nmethods for learning optimal DTRs that effectively handle complex patient data.\nWe call our methods DTR-CT and DTR-CF. Our methods are based on a data-driven\nestimation of heterogeneous treatment effects using causal tree methods,\nspecifically causal trees and causal forests, that learn non-linear\nrelationships, control for time-varying confounding, are doubly robust, and\nexplainable. To the best of our knowledge, our paper is the first that adapts\ncausal tree methods for learning optimal DTRs. We evaluate our proposed methods\nusing synthetic data and then apply them to real-world data from intensive care\nunits. Our methods outperform state-of-the-art baselines in terms of cumulative\nregret and percentage of optimal decisions by a considerable margin. Our work\nimproves treatment recommendations from electronic health record and is thus of\ndirect relevance for personalized medicine.",
          "link": "http://arxiv.org/abs/2204.07124",
          "publishedOn": "2022-04-16T00:51:43.078Z",
          "wordCount": 644,
          "title": "Learning Optimal Dynamic Treatment Regimes Using Causal Tree Methods in Medicine. (arXiv:2204.07124v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06652",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanlin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shiqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Ting He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_V/0/1/0/all/0/1\">Vijay Narayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kevin S. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasteris_S/0/1/0/all/0/1\">Stephen Pasteris</a>",
          "description": "Coresets are small, weighted summaries of larger datasets, aiming at\nproviding provable error bounds for machine learning (ML) tasks while\nsignificantly reducing the communication and computation costs. To achieve a\nbetter trade-off between ML error bounds and costs, we propose the first\nframework to incorporate quantization techniques into the process of coreset\nconstruction. Specifically, we theoretically analyze the ML error bounds caused\nby a combination of coreset construction and quantization. Based on that, we\nformulate an optimization problem to minimize the ML error under a fixed budget\nof communication cost. To improve the scalability for large datasets, we\nidentify two proxies of the original objective function, for which efficient\nalgorithms are developed. For the case of data on multiple nodes, we further\ndesign a novel algorithm to allocate the communication budget to the nodes\nwhile minimizing the overall ML error. Through extensive experiments on\nmultiple real-world datasets, we demonstrate the effectiveness and efficiency\nof our proposed algorithms for a variety of ML tasks. In particular, our\nalgorithms have achieved more than 90% data reduction with less than 10%\ndegradation in ML performance in most cases.",
          "link": "http://arxiv.org/abs/2204.06652",
          "publishedOn": "2022-04-16T00:51:43.069Z",
          "wordCount": 627,
          "title": "Joint Coreset Construction and Quantization for Distributed Machine Learning. (arXiv:2204.06652v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Richards_S/0/1/0/all/0/1\">Spencer M. Richards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizan_N/0/1/0/all/0/1\">Navid Azizan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slotine_J/0/1/0/all/0/1\">Jean-Jacques Slotine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>",
          "description": "Real-time adaptation is imperative to the control of robots operating in\ncomplex, dynamic environments. Adaptive control laws can endow even nonlinear\nsystems with good trajectory tracking performance, provided that any uncertain\ndynamics terms are linearly parameterizable with known nonlinear features.\nHowever, it is often difficult to specify such features a priori, such as for\naerodynamic disturbances on rotorcraft or interaction forces between a\nmanipulator arm and various objects. In this paper, we turn to data-driven\nmodeling with neural networks to learn, offline from past data, an adaptive\ncontroller with an internal parametric model of these nonlinear features. Our\nkey insight is that we can better prepare the controller for deployment with\ncontrol-oriented meta-learning of features in closed-loop simulation, rather\nthan regression-oriented meta-learning of features to fit input-output data.\nSpecifically, we meta-learn the adaptive controller with closed-loop tracking\nsimulation as the base-learner and the average tracking error as the\nmeta-objective. With both fully-actuated and underactuated nonlinear planar\nrotorcraft subject to wind, we demonstrate that our adaptive controller\noutperforms other controllers trained with regression-oriented meta-learning\nwhen deployed in closed-loop for trajectory tracking control.",
          "link": "http://arxiv.org/abs/2204.06716",
          "publishedOn": "2022-04-16T00:51:43.046Z",
          "wordCount": 649,
          "title": "Control-oriented meta-learning. (arXiv:2204.06716v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06698",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nakamura_A/0/1/0/all/0/1\">Angelica Tiemi Mizuno Nakamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_D/0/1/0/all/0/1\">Denis Fernando Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grassi_V/0/1/0/all/0/1\">Valdir Grassi Jr</a>",
          "description": "Multi-Task Learning is a learning paradigm that uses correlated tasks to\nimprove performance generalization. A common way to learn multiple tasks is\nthrough the hard parameter sharing approach, in which a single architecture is\nused to share the same subset of parameters, creating an inductive bias between\nthem during the training process. Due to its simplicity, potential to improve\ngeneralization, and reduce computational cost, it has gained the attention of\nthe scientific and industrial communities. However, tasks often conflict with\neach other, which makes it challenging to define how the gradients of multiple\ntasks should be combined to allow simultaneous learning. To address this\nproblem, we use the idea of multi-objective optimization to propose a method\nthat takes into account temporal behaviour of the gradients to create a dynamic\nbias that adjust the importance of each task during the backpropagation. The\nresult of this method is to give more attention to the tasks that are diverging\nor that are not being benefited during the last iterations, allowing to ensure\nthat the simultaneous learning is heading to the performance maximization of\nall tasks. As a result, we empirically show that the proposed method\noutperforms the state-of-art approaches on learning conflicting tasks. Unlike\nthe adopted baselines, our method ensures that all tasks reach good\ngeneralization performances.",
          "link": "http://arxiv.org/abs/2204.06698",
          "publishedOn": "2022-04-16T00:51:43.009Z",
          "wordCount": 658,
          "title": "Leveraging convergence behavior to balance conflicting tasks in multi-task learning. (arXiv:2204.06698v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06684",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lu_L/0/1/0/all/0/1\">Lu Lu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pestourie_R/0/1/0/all/0/1\">Raphael Pestourie</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Johnson_S/0/1/0/all/0/1\">Steven G. Johnson</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Romano_G/0/1/0/all/0/1\">Giuseppe Romano</a>",
          "description": "Deep neural operators can learn operators mapping between\ninfinite-dimensional function spaces via deep neural networks and have become\nan emerging paradigm of scientific machine learning. However, training neural\noperators usually requires a large amount of high-fidelity data, which is often\ndifficult to obtain in real engineering problems. Here, we address this\nchallenge by using multifidelity learning, i.e., learning from multifidelity\ndatasets. We develop a multifidelity neural operator based on a deep operator\nnetwork (DeepONet). A multifidelity DeepONet includes two standard DeepONets\ncoupled by residual learning and input augmentation. Multifidelity DeepONet\nsignificantly reduces the required amount of high-fidelity data and achieves\none order of magnitude smaller error when using the same amount of\nhigh-fidelity data. We apply a multifidelity DeepONet to learn the phonon\nBoltzmann transport equation (BTE), a framework to compute nanoscale heat\ntransport. By combining a trained multifidelity DeepONet with genetic algorithm\nor topology optimization, we demonstrate a fast solver for the inverse design\nof BTE problems.",
          "link": "http://arxiv.org/abs/2204.06684",
          "publishedOn": "2022-04-16T00:51:43.000Z",
          "wordCount": 621,
          "title": "Multifidelity deep neural operators for efficient learning of partial differential equations with application to fast inverse design of nanoscale heat transport. (arXiv:2204.06684v1 [physics.comp-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Ankita Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thirunarayan_K/0/1/0/all/0/1\">Krishnaprasad Thirunarayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romine_W/0/1/0/all/0/1\">William L. Romine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alambo_A/0/1/0/all/0/1\">Amanuel Alambo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cajita_M/0/1/0/all/0/1\">Mia Cajita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_T/0/1/0/all/0/1\">Tanvi Banerjee</a>",
          "description": "Heart failure occurs when the heart is not able to pump blood and oxygen to\nsupport other organs in the body as it should. Treatments include medications\nand sometimes hospitalization. Patients with heart failure can have both\ncardiovascular as well as non-cardiovascular comorbidities. Clinical notes of\npatients with heart failure can be analyzed to gain insight into the topics\ndiscussed in these notes and the major comorbidities in these patients. In this\nregard, we apply machine learning techniques, such as topic modeling, to\nidentify the major themes found in the clinical notes specific to the\nprocedures performed on 1,200 patients admitted for heart failure at the\nUniversity of Illinois Hospital and Health Sciences System (UI Health). Topic\nmodeling revealed five hidden themes in these clinical notes, including one\nrelated to heart disease comorbidities.",
          "link": "http://arxiv.org/abs/2204.07074",
          "publishedOn": "2022-04-16T00:51:42.949Z",
          "wordCount": 605,
          "title": "Leveraging Natural Learning Processing to Uncover Themes in Clinical Notes of Patients Admitted for Heart Failure. (arXiv:2204.07074v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weyns_D/0/1/0/all/0/1\">Danny Weyns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baeck_T/0/1/0/all/0/1\">Thomas Baeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Rene Vidal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1\">Xin Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belbachir_A/0/1/0/all/0/1\">Ahmed Nabil Belbachir</a>",
          "description": "Computing systems are omnipresent; their sustainability has become crucial\nfor our society. A key aspect of this sustainability is the ability of\ncomputing systems to cope with the continuous change they face, ranging from\ndynamic operating conditions, to changing goals, and technological progress.\nWhile we are able to engineer smart computing systems that autonomously deal\nwith various types of changes, handling unanticipated changes requires system\nevolution, which remains in essence a human-centered process. This will\neventually become unmanageable. To break through the status quo, we put forward\nan arguable opinion for the vision of self-evolving computing systems that are\nequipped with an evolutionary engine enabling them to evolve autonomously.\nSpecifically, when a self-evolving computing system detects conditions outside\nits operational domain, such as an anomaly or a new goal, it activates an\nevolutionary engine that runs online experiments to determine how the system\nneeds to evolve to deal with the changes, thereby evolving its architecture.\nDuring this process the engine can integrate new computing elements that are\nprovided by computing warehouses. These computing elements provide\nspecifications and procedures enabling their automatic integration. We motivate\nthe need for self-evolving computing systems in light of the state of the art,\noutline a conceptual architecture of self-evolving computing systems, and\nillustrate the architecture for a future smart city mobility system that needs\nto evolve continuously with changing conditions. To conclude, we highlight key\nresearch challenges to realize the vision of self-evolving computing systems.",
          "link": "http://arxiv.org/abs/2204.06825",
          "publishedOn": "2022-04-16T00:51:42.941Z",
          "wordCount": 678,
          "title": "The Vision of Self-Evolving Computing Systems. (arXiv:2204.06825v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Rui Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_S/0/1/0/all/0/1\">Stephen James</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yichuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yun-Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>",
          "description": "In this paper, we propose an iterative self-training framework for\nsim-to-real 6D object pose estimation to facilitate cost-effective robotic\ngrasping. Given a bin-picking scenario, we establish a photo-realistic\nsimulator to synthesize abundant virtual data, and use this to train an initial\npose estimation network. This network then takes the role of a teacher model,\nwhich generates pose predictions for unlabeled real data. With these\npredictions, we further design a comprehensive adaptive selection scheme to\ndistinguish reliable results, and leverage them as pseudo labels to update a\nstudent model for pose estimation on real data. To continuously improve the\nquality of pseudo labels, we iterate the above steps by taking the trained\nstudent model as a new teacher and re-label real data using the refined teacher\nmodel. We evaluate our method on a public benchmark and our newly-released\ndataset, achieving an ADD(-S) improvement of 11.49% and 22.62% respectively.\nOur method is also able to improve robotic bin-picking success by 19.54%,\ndemonstrating the potential of iterative sim-to-real solutions for robotic\napplications.",
          "link": "http://arxiv.org/abs/2204.07049",
          "publishedOn": "2022-04-16T00:51:42.899Z",
          "wordCount": 637,
          "title": "Sim-to-Real 6D Object Pose Estimation via Iterative Self-training for Robotic Bin-picking. (arXiv:2204.07049v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.11442",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Chen_D/0/1/0/all/0/1\">Dicheng Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hu_W/0/1/0/all/0/1\">Wanqi Hu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_H/0/1/0/all/0/1\">Huiting Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhou_Y/0/1/0/all/0/1\">Yirong Zhou</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Qiu_T/0/1/0/all/0/1\">Tianyu Qiu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Huang_Y/0/1/0/all/0/1\">Yihui Huang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_J/0/1/0/all/0/1\">Jiazheng Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lin_L/0/1/0/all/0/1\">Liangjie Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wu_Z/0/1/0/all/0/1\">Zhigang Wu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yan_G/0/1/0/all/0/1\">Gen Yan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Guo_D/0/1/0/all/0/1\">Di Guo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lin_J/0/1/0/all/0/1\">Jianzhong Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Qu_X/0/1/0/all/0/1\">Xiaobo Qu</a>",
          "description": "Magnetic Resonance Spectroscopy (MRS) is a noninvasive tool to reveal\nmetabolic information. One challenge of 1H-MRS is the low Signal-Noise Ratio\n(SNR). To improve the SNR, a typical approach is to perform Signal Averaging\n(SA) with M repeated samples. The data acquisition time, however, is increased\nby M times accordingly, and a complete clinical MRS scan takes approximately 10\nminutes at a common setting M=128. Recently, deep learning has been introduced\nto improve the SNR but most of them use the simulated data as the training set.\nThis may hinder the MRS applications since some potential differences, such as\nacquisition system imperfections, and physiological and psychologic conditions\nmay exist between the simulated and in vivo data. Here, we proposed a new\nscheme that purely used the repeated samples of realistic data. A deep learning\nmodel, Refusion Long Short-Term Memory (ReLSTM), was designed to learn the\nmapping from the low SNR time-domain data (24 SA) to the high SNR one (128 SA).\nExperiments on the in vivo brain spectra of 7 healthy subjects, 2 brain tumor\npatients and 1 cerebral infarction patient showed that only using 20% repeated\nsamples, the denoised spectra by ReLSTM could provide comparable estimated\nconcentrations of metabolites to 128 SA. Compared with the state-of-the-art\nlow-rank denoising method, the ReLSTM achieved the lower relative error and the\nCram\\'er-Rao lower bounds in quantifying some important biomarkers. In summary,\nReLSTM can perform high-fidelity denoising of the spectra under fast\nacquisition (24 SA), which would be valuable to MRS clinical studies.",
          "link": "http://arxiv.org/abs/2101.11442",
          "publishedOn": "2022-04-16T00:51:42.878Z",
          "wordCount": 740,
          "title": "Magnetic Resonance Spectroscopy Deep Learning Denoising Using Few In Vivo Data. (arXiv:2101.11442v2 [physics.med-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yiding Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angluin_D/0/1/0/all/0/1\">Dana Angluin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_R/0/1/0/all/0/1\">Robert Frank</a>",
          "description": "This paper analyzes three formal models of Transformer encoders that differ\nin the form of their self-attention mechanism: unique hard attention (UHAT);\ngeneralized unique hard attention (GUHAT), which generalizes UHAT; and\naveraging hard attention (AHAT). We show that UHAT and GUHAT Transformers,\nviewed as string acceptors, can only recognize formal languages in the\ncomplexity class AC$^0$, the class of languages recognizable by families of\nBoolean circuits of constant depth and polynomial size. This upper bound\nsubsumes Hahn's (2020) results that GUHAT cannot recognize the DYCK languages\nor the PARITY language, since those languages are outside AC$^0$ (Furst et al.,\n1984). In contrast, the non-AC$^0$ languages MAJORITY and DYCK-1 are\nrecognizable by AHAT networks, implying that AHAT can recognize languages that\nUHAT and GUHAT cannot.",
          "link": "http://arxiv.org/abs/2204.06618",
          "publishedOn": "2022-04-16T00:51:42.870Z",
          "wordCount": 593,
          "title": "Formal Language Recognition by Hard Attention Transformers: Perspectives from Circuit Complexity. (arXiv:2204.06618v1 [cs.CC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+G_R/0/1/0/all/0/1\">Renith G</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warrier_H/0/1/0/all/0/1\">Harikrishna Warrier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_Y/0/1/0/all/0/1\">Yogesh Gupta</a>",
          "description": "Content based providers transmits real time complex signal such as video data\nfrom one region to another. During this transmission process, the signals\nusually end up distorted or degraded where the actual information present in\nthe video is lost. This normally happens in the streaming video services\napplications. Hence there is a need to know the level of degradation that\nhappened in the receiver side. This video degradation can be estimated by\nnetwork state parameters like data rate and packet loss values. Our proposed\nsolution vQoS GAN (video Quality of Service Generative Adversarial Network) can\nestimate the network state parameters from the degraded received video data\nusing a deep learning approach of semi supervised generative adversarial\nnetwork algorithm. A robust and unique design of deep learning network model\nhas been trained with the video data along with data rate and packet loss class\nlabels and achieves over 95 percent of training accuracy. The proposed semi\nsupervised generative adversarial network can additionally reconstruct the\ndegraded video data to its original form for a better end user experience.",
          "link": "http://arxiv.org/abs/2204.07062",
          "publishedOn": "2022-04-16T00:51:42.825Z",
          "wordCount": 629,
          "title": "Network state Estimation using Raw Video Analysis: vQoS-GAN based non-intrusive Deep Learning Approach. (arXiv:2204.07062v1 [cs.MM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06638",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Liang_D/0/1/0/all/0/1\">Daniel Liang</a>",
          "description": "Given a dataset of input states, measurements, and probabilities, is it\npossible to efficiently predict the measurement probabilities associated with a\nquantum circuit? Recent work of Caro and Datta (2020) studied the problem of\nPAC learning quantum circuits in an information theoretic sense, leaving open\nquestions of computational efficiency. In particular, one candidate class of\ncircuits for which an efficient learner might have been possible was that of\nClifford circuits, since the corresponding set of states generated by such\ncircuits, called stabilizer states, are known to be efficiently PAC learnable\n(Rocchetto 2018). Here we provide a negative result, showing that proper\nlearning of CNOT circuits is hard for classical learners unless $\\textsf{RP} =\n\\textsf{NP}$. As the classical analogue and subset of Clifford circuits, this\nnaturally leads to a hardness result for Clifford circuits as well.\nAdditionally, we show that if $\\textsf{RP} = \\textsf{NP}$ then there would\nexist efficient proper learning algorithms for CNOT and Clifford circuits. By\nsimilar arguments, we also find that an efficient proper quantum learner for\nsuch circuits exists if and only if $\\textsf{NP} \\subseteq \\textsf{RQP}$.",
          "link": "http://arxiv.org/abs/2204.06638",
          "publishedOn": "2022-04-16T00:51:42.752Z",
          "wordCount": 625,
          "title": "Clifford Circuits can be Properly PAC Learned if and only if $\\textsf{RP}=\\textsf{NP}$. (arXiv:2204.06638v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Salami_A/0/1/0/all/0/1\">Abbas Salami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreu_Perez_J/0/1/0/all/0/1\">Javier Andreu-Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gillmeister_H/0/1/0/all/0/1\">Helge Gillmeister</a>",
          "description": "In recent years, neural networks and especially deep architectures have\nreceived substantial attention for EEG signal analysis in the field of\nbrain-computer interfaces (BCIs). In this ongoing research area, the end-to-end\nmodels are more favoured than traditional approaches requiring signal\ntransformation pre-classification. They can eliminate the need for prior\ninformation from experts and the extraction of handcrafted features. However,\nalthough several deep learning algorithms have been already proposed in the\nliterature, achieving high accuracies for classifying motor movements or mental\ntasks, they often face a lack of interpretability and therefore are not quite\nfavoured by the neuroscience community. The reasons behind this issue can be\nthe high number of parameters and the sensitivity of deep neural networks to\ncapture tiny yet unrelated discriminative features. We propose an end-to-end\ndeep learning architecture called EEG-ITNet and a more comprehensible method to\nvisualise the network learned patterns. Using inception modules and causal\nconvolutions with dilation, our model can extract rich spectral, spatial, and\ntemporal information from multi-channel EEG signals with less complexity (in\nterms of the number of trainable parameters) than other existing end-to-end\narchitectures, such as EEG-Inception and EEG-TCNet. By an exhaustive evaluation\non dataset 2a from BCI competition IV and OpenBMI motor imagery dataset,\nEEG-ITNet shows up to 5.9\\% improvement in the classification accuracy in\ndifferent scenarios with statistical significance compared to its competitors.\nWe also comprehensively explain and support the validity of network\nillustration from a neuroscientific perspective. We have also made our code\nopen at https://github.com/AbbasSalami/EEG-ITNet",
          "link": "http://arxiv.org/abs/2204.06947",
          "publishedOn": "2022-04-16T00:51:42.725Z",
          "wordCount": 712,
          "title": "EEG-ITNet: An Explainable Inception Temporal Convolutional Network for Motor Imagery Classification. (arXiv:2204.06947v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06929",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liang_J/0/1/0/all/0/1\">Jiamin Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">Haoming Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_S/0/1/0/all/0/1\">Shuangchi He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_X/0/1/0/all/0/1\">Xindi Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zejian Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_W/0/1/0/all/0/1\">Wufeng Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_J/0/1/0/all/0/1\">Jun Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ni_D/0/1/0/all/0/1\">Dong Ni</a>",
          "description": "Ultrasound (US) imaging is widely used for anatomical structure inspection in\nclinical diagnosis. The training of new sonographers and deep learning based\nalgorithms for US image analysis usually requires a large amount of data.\nHowever, obtaining and labeling large-scale US imaging data are not easy tasks,\nespecially for diseases with low incidence. Realistic US image synthesis can\nalleviate this problem to a great extent. In this paper, we propose a\ngenerative adversarial network (GAN) based image synthesis framework. Our main\ncontributions include: 1) we present the first work that can synthesize\nrealistic B-mode US images with high-resolution and customized texture editing\nfeatures; 2) to enhance structural details of generated images, we propose to\nintroduce auxiliary sketch guidance into a conditional GAN. We superpose the\nedge sketch onto the object mask and use the composite mask as the network\ninput; 3) to generate high-resolution US images, we adopt a progressive\ntraining strategy to gradually generate high-resolution images from\nlow-resolution images. In addition, a feature loss is proposed to minimize the\ndifference of high-level features between the generated and real images, which\nfurther improves the quality of generated images; 4) the proposed US image\nsynthesis method is quite universal and can also be generalized to the US\nimages of other anatomical structures besides the three ones tested in our\nstudy (lung, hip joint, and ovary); 5) extensive experiments on three large US\nimage datasets are conducted to validate our method. Ablation studies,\ncustomized texture editing, user studies, and segmentation tests demonstrate\npromising results of our method in synthesizing realistic US images.",
          "link": "http://arxiv.org/abs/2204.06929",
          "publishedOn": "2022-04-16T00:51:42.686Z",
          "wordCount": 743,
          "title": "Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis. (arXiv:2204.06929v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dulberg_Z/0/1/0/all/0/1\">Zack Dulberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_R/0/1/0/all/0/1\">Rachit Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berwian_I/0/1/0/all/0/1\">Isabel M. Berwian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">Jonathan D. Cohen</a>",
          "description": "The problem of balancing conflicting needs is fundamental to intelligence.\nStandard reinforcement learning algorithms maximize a scalar reward, which\nrequires combining different objective-specific rewards into a single number.\nAlternatively, different objectives could also be combined at the level of\naction value, such that specialist modules responsible for different objectives\nsubmit different action suggestions to a decision process, each based on\nrewards that are independent of one another. In this work, we explore the\npotential benefits of this alternative strategy. We investigate a biologically\nrelevant multi-objective problem, the continual homeostasis of a set of\nvariables, and compare a monolithic deep Q-network to a modular network with a\ndedicated Q-learner for each variable. We find that the modular agent: a)\nrequires minimal exogenously determined exploration; b) has improved sample\nefficiency; and c) is more robust to out-of-domain perturbation.",
          "link": "http://arxiv.org/abs/2204.06608",
          "publishedOn": "2022-04-16T00:51:42.629Z",
          "wordCount": 589,
          "title": "Modularity benefits reinforcement learning agents with competing homeostatic drives. (arXiv:2204.06608v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nesterov_V/0/1/0/all/0/1\">Vitali Nesterov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torres_F/0/1/0/all/0/1\">Fabricio Arend Torres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagy_Huber_M/0/1/0/all/0/1\">Monika Nagy-Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samarin_M/0/1/0/all/0/1\">Maxim Samarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_V/0/1/0/all/0/1\">Volker Roth</a>",
          "description": "Considering smooth mappings from input vectors to continuous targets, our\ngoal is to characterise subspaces of the input domain, which are invariant\nunder such mappings. Thus, we want to characterise manifolds implicitly defined\nby level sets. Specifically, this characterisation should be of a global\nparametric form, which is especially useful for different informed data\nexploration tasks, such as building grid-based approximations, sampling points\nalong the level curves, or finding trajectories on the manifold. However,\nglobal parameterisations can only exist if the level sets are connected. For\nthis purpose, we introduce a novel and flexible class of neural networks that\ngeneralise input-convex networks. These networks represent functions that are\nguaranteed to have connected level sets forming smooth manifolds on the input\nspace. We further show that global parameterisations of these level sets can be\nalways found efficiently. Lastly, we demonstrate that our novel technique for\ncharacterising invariances is a powerful generative data exploration tool in\nreal-world applications, such as computational chemistry.",
          "link": "http://arxiv.org/abs/2204.07009",
          "publishedOn": "2022-04-16T00:51:42.621Z",
          "wordCount": 593,
          "title": "Learning Invariances with Generalised Input-Convex Neural Networks. (arXiv:2204.07009v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kachuee_M/0/1/0/all/0/1\">Mohammad Kachuee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nam_J/0/1/0/all/0/1\">Jinseok Nam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_S/0/1/0/all/0/1\">Sarthak Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Won_J/0/1/0/all/0/1\">Jin-Myung Won</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungjin Lee</a>",
          "description": "Skill routing is an important component in large-scale conversational\nsystems. In contrast to traditional rule-based skill routing, state-of-the-art\nsystems use a model-based approach to enable natural conversations. To provide\nsupervision signal required to train such models, ideas such as human\nannotation, replication of a rule-based system, relabeling based on user\nparaphrases, and bandit-based learning were suggested. However, these\napproaches: (a) do not scale in terms of the number of skills and skill\non-boarding, (b) require a very costly expert annotation/rule-design, (c)\nintroduce risks in the user experience with each model update. In this paper,\nwe present a scalable self-learning approach to explore routing alternatives\nwithout causing abrupt policy changes that break the user experience, learn\nfrom the user interaction, and incrementally improve the routing via frequent\nmodel refreshes. To enable such robust frequent model updates, we suggest a\nsimple and effective approach that ensures controlled policy updates for\nindividual domains, followed by an off-policy evaluation for making deployment\ndecisions without any need for lengthy A/B experimentation. We conduct various\noffline and online A/B experiments on a commercial large-scale conversational\nsystem to demonstrate the effectiveness of the proposed method in real-world\nproduction settings.",
          "link": "http://arxiv.org/abs/2204.07135",
          "publishedOn": "2022-04-16T00:51:42.512Z",
          "wordCount": null,
          "title": "Scalable and Robust Self-Learning for Skill Routing in Large-Scale Conversational AI Systems. (arXiv:2204.07135v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.06252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md Jahidul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruobing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattar_J/0/1/0/all/0/1\">Junaed Sattar</a>",
          "description": "This paper presents a holistic approach to saliency-guided visual attention\nmodeling (SVAM) for use by autonomous underwater robots. Our proposed model,\nnamed SVAM-Net, integrates deep visual features at various scales and semantics\nfor effective salient object detection (SOD) in natural underwater images. The\nSVAM-Net architecture is configured in a unique way to jointly accommodate\nbottom-up and top-down learning within two separate branches of the network\nwhile sharing the same encoding layers. We design dedicated spatial attention\nmodules (SAMs) along these learning pathways to exploit the coarse-level and\nfine-level semantic features for SOD at four stages of abstractions. The\nbottom-up branch performs a rough yet reasonably accurate saliency estimation\nat a fast rate, whereas the deeper top-down branch incorporates a residual\nrefinement module (RRM) that provides fine-grained localization of the salient\nobjects. Extensive performance evaluation of SVAM-Net on benchmark datasets\nclearly demonstrates its effectiveness for underwater SOD. We also validate its\ngeneralization performance by several ocean trials' data that include test\nimages of diverse underwater scenes and waterbodies, and also images with\nunseen natural objects. Moreover, we analyze its computational feasibility for\nrobotic deployments and demonstrate its utility in several important use cases\nof visual attention modeling.",
          "link": "http://arxiv.org/abs/2011.06252",
          "publishedOn": "2022-04-16T00:51:42.448Z",
          "wordCount": null,
          "title": "SVAM: Saliency-guided Visual Attention Modeling by Autonomous Underwater Robots. (arXiv:2011.06252v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07043",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Borovac_A/0/1/0/all/0/1\">Ana Borovac</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gudmundsson_S/0/1/0/all/0/1\">Steinn Gudmundsson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thorvardsson_G/0/1/0/all/0/1\">Gardar Thorvardsson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moghadam_S/0/1/0/all/0/1\">Saeed M. Moghadam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nevalainen_P/0/1/0/all/0/1\">P&#xe4;ivi Nevalainen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stevenson_N/0/1/0/all/0/1\">Nathan Stevenson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vanhatalo_S/0/1/0/all/0/1\">Sampsa Vanhatalo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Runarsson_T/0/1/0/all/0/1\">Thomas P. Runarsson</a>",
          "description": "Sharing medical data between institutions is difficult in practice due to\ndata protection laws and official procedures within institutions. Therefore,\nmost existing algorithms are trained on relatively small electroencephalogram\n(EEG) data sets which is likely to be detrimental to prediction accuracy. In\nthis work, we simulate a case when the data can not be shared by splitting the\npublicly available data set into disjoint sets representing data in individual\ninstitutions. We propose to train a (local) detector in each institution and\naggregate their individual predictions into one final prediction. Four\naggregation schemes are compared, namely, the majority vote, the mean, the\nweighted mean and the Dawid-Skene method. The approach allows different\ndetector architectures amongst the institutions. The method was validated on an\nindependent data set using only a subset of EEG channels. The ensemble reaches\naccuracy comparable to a single detector trained on all the data when\nsufficient amount of data is available in each institution. The weighted mean\naggregation scheme showed best overall performance, it was only marginally\noutperformed by the Dawid-Skene method when local detectors approach\nperformance of a single detector trained on all available data.",
          "link": "http://arxiv.org/abs/2204.07043",
          "publishedOn": "2022-04-16T00:51:42.371Z",
          "wordCount": null,
          "title": "Ensemble learning using individual neonatal data for seizure detection. (arXiv:2204.07043v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.09777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zela_A/0/1/0/all/0/1\">Arber Zela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siems_J/0/1/0/all/0/1\">Julien Siems</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmer_L/0/1/0/all/0/1\">Lucas Zimmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasik_J/0/1/0/all/0/1\">Jovita Lukasik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1\">Margret Keuper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>",
          "description": "The most significant barrier to the advancement of Neural Architecture Search\n(NAS) is its demand for large computational resources, which hinders\nscientifically sound empirical evaluations of NAS methods. Tabular NAS\nbenchmarks have alleviated this problem substantially, making it possible to\nproperly evaluate NAS methods in seconds on commodity machines. However, an\nunintended consequence of tabular NAS benchmarks has been a focus on extremely\nsmall architectural search spaces since their construction relies on exhaustive\nevaluations of the space. This leads to unrealistic results that do not\ntransfer to larger spaces. To overcome this fundamental limitation, we propose\na methodology to create cheap NAS surrogate benchmarks for arbitrary search\nspaces. We exemplify this approach by creating surrogate NAS benchmarks on the\nexisting tabular NAS-Bench-101 and on two widely used NAS search spaces with up\nto $10^{21}$ architectures ($10^{13}$ times larger than any previous tabular\nNAS benchmark). We show that surrogate NAS benchmarks can model the true\nperformance of architectures better than tabular benchmarks (at a small\nfraction of the cost), that they lead to faithful estimates of how well\ndifferent NAS methods work on the original non-surrogate benchmark, and that\nthey can generate new scientific insight. We open-source all our code and\nbelieve that surrogate NAS benchmarks are an indispensable tool to extend\nscientifically sound work on NAS to large and exciting search spaces.",
          "link": "http://arxiv.org/abs/2008.09777",
          "publishedOn": "2022-04-16T00:51:42.371Z",
          "wordCount": null,
          "title": "Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks. (arXiv:2008.09777v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1\">Thomas M. Moerland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preuss_M/0/1/0/all/0/1\">Mike Preuss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>",
          "description": "Go-Explore achieved breakthrough performance on challenging reinforcement\nlearning (RL) tasks with sparse rewards. The key insight of Go-Explore was that\nsuccessful exploration requires an agent to first return to an interesting\nstate ('Go'), and only then explore into unknown terrain ('Explore'). We refer\nto such exploration after a goal is reached as 'post-exploration'. In this\npaper we present a systematic study of post-exploration, answering open\nquestions that the Go-Explore paper did not answer yet. First, we study the\nisolated potential of post-exploration, by turning it on and off within the\nsame algorithm. Subsequently, we introduce new methodology to adaptively decide\nwhen to post-explore and for how long to post-explore. Experiments on a range\nof MiniGrid environments show that post-exploration indeed boosts performance\n(with a bigger impact than tuning regular exploration parameters), and this\neffect is further enhanced by adaptively deciding when and for how long to\npost-explore. In short, our work identifies adaptive post-exploration as a\npromising direction for RL exploration research.",
          "link": "http://arxiv.org/abs/2203.16311",
          "publishedOn": "2022-04-14T00:58:52.151Z",
          "wordCount": null,
          "title": "When to Go, and When to Explore: The Benefit of Post-Exploration in Intrinsic Motivation. (arXiv:2203.16311v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12363",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saad_F/0/1/0/all/0/1\">Feras A. Saad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cusumano_Towner_M/0/1/0/all/0/1\">Marco Cusumano-Towner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mansinghka_V/0/1/0/all/0/1\">Vikash K. Mansinghka</a>",
          "description": "Estimating information-theoretic quantities such as entropy and mutual\ninformation is central to many problems in statistics and machine learning, but\nchallenging in high dimensions. This paper presents estimators of entropy via\ninference (EEVI), which deliver upper and lower bounds on many information\nquantities for arbitrary variables in a probabilistic generative model. These\nestimators use importance sampling with proposal distribution families that\ninclude amortized variational inference and sequential Monte Carlo, which can\nbe tailored to the target model and used to squeeze true information values\nwith high accuracy. We present several theoretical properties of EEVI and\ndemonstrate scalability and efficacy on two problems from the medical domain:\n(i) in an expert system for diagnosing liver disorders, we rank medical tests\naccording to how informative they are about latent diseases, given a pattern of\nobserved symptoms and patient attributes; and (ii) in a differential equation\nmodel of carbohydrate metabolism, we find optimal times to take blood glucose\nmeasurements that maximize information about a diabetic patient's insulin\nsensitivity, given their meal and medication schedule.",
          "link": "http://arxiv.org/abs/2202.12363",
          "publishedOn": "2022-04-14T00:58:52.150Z",
          "wordCount": null,
          "title": "Estimators of Entropy and Information via Inference in Probabilistic Models. (arXiv:2202.12363v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.01818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garttner_S/0/1/0/all/0/1\">Stephan G&#xe4;rttner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alpak_F/0/1/0/all/0/1\">Faruk O. Alpak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meier_A/0/1/0/all/0/1\">Andreas Meier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_N/0/1/0/all/0/1\">Nadja Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_F/0/1/0/all/0/1\">Florian Frank</a>",
          "description": "In recent years, convolutional neural networks (CNNs) have experienced an\nincreasing interest in their ability to perform a fast approximation of\neffective hydrodynamic parameters in porous media research and applications.\nThis paper presents a novel methodology for permeability prediction from\nmicro-CT scans of geological rock samples. The training data set for CNNs\ndedicated to permeability prediction consists of permeability labels that are\ntypically generated by classical lattice Boltzmann methods (LBM) that simulate\nthe flow through the pore space of the segmented image data. We instead perform\ndirect numerical simulation (DNS) by solving the stationary Stokes equation in\nan efficient and distributed-parallel manner. As such, we circumvent the\nconvergence issues of LBM that frequently are observed on complex pore\ngeometries, and therefore, improve the generality and accuracy of our training\ndata set. Using the DNS-computed permeabilities, a physics-informed CNN PhyCNN)\nis trained by additionally providing a tailored characteristic quantity of the\npore space. More precisely, by exploiting the connection to flow problems on a\ngraph representation of the pore space, additional information about confined\nstructures is provided to the network in terms of the maximum flow value, which\nis the key innovative component of our workflow. The robustness of this\napproach is reflected by very high prediction accuracy, which is observed for a\nvariety of sandstone samples from archetypal rock formations.",
          "link": "http://arxiv.org/abs/2109.01818",
          "publishedOn": "2022-04-14T00:58:52.138Z",
          "wordCount": null,
          "title": "Estimating permeability of 3D micro-CT images by physics-informed CNNs based on DNS. (arXiv:2109.01818v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06098",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aminpour_M/0/1/0/all/0/1\">Mohammad Aminpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alaie_R/0/1/0/all/0/1\">Reza Alaie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kardani_N/0/1/0/all/0/1\">Navid Kardani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moridpour_S/0/1/0/all/0/1\">Sara Moridpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nazem_M/0/1/0/all/0/1\">Majidreza Nazem</a>",
          "description": "Machine Learning (ML) algorithms are increasingly used as surrogate models to\nincrease the efficiency of stochastic reliability analyses in geotechnical\nengineering. This paper presents a highly efficient ML aided reliability\ntechnique that is able to accurately predict the results of a Monte Carlo (MC)\nreliability study, and yet performs 500 times faster. A complete MC reliability\nanalysis on anisotropic heterogeneous slopes consisting of 120,000 simulated\nsamples is conducted in parallel to the proposed ML aided stochastic technique.\nComparing the results of the complete MC study and the proposed ML aided\ntechnique, the expected errors of the proposed method are realistically\nexamined. Circumventing the time-consuming computation of factors of safety for\nthe training datasets, the proposed technique is more efficient than previous\nmethods. Different ML models, including Random Forest (RF), Support Vector\nMachine (SVM) and Artificial Neural Networks (ANN) are presented, optimised and\ncompared. The effects of the size and type of training and testing datasets are\ndiscussed. The expected errors of the ML predicted probability of failure are\ncharacterised by different levels of soil heterogeneity and anisotropy. Using\nonly 1% of MC samples to train ML surrogate models, the proposed technique can\naccurately predict the probability of failure with mean errors limited to 0.7%.\nThe proposed technique reduces the computational time required for our study\nfrom 306 days to only 14 hours, providing 500 times higher efficiency.",
          "link": "http://arxiv.org/abs/2204.06098",
          "publishedOn": "2022-04-14T00:58:52.137Z",
          "wordCount": null,
          "title": "Highly efficient reliability analysis of anisotropic heterogeneous slopes: Machine Learning aided Monte Carlo method. (arXiv:2204.06098v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.11147",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liang_X/0/1/0/all/0/1\">Xiaozhuan Liang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cheng_S/0/1/0/all/0/1\">Siyuan Cheng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hong_H/0/1/0/all/0/1\">Haosen Hong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lian_J/0/1/0/all/0/1\">Jiazhang Lian</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiang Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>",
          "description": "Self-supervised protein language models have proved their effectiveness in\nlearning the proteins representations. With the increasing computational power,\ncurrent protein language models pre-trained with millions of diverse sequences\ncan advance the parameter scale from million-level to billion-level and achieve\nremarkable improvement. However, those prevailing approaches rarely consider\nincorporating knowledge graphs (KGs), which can provide rich structured\nknowledge facts for better protein representations. We argue that informative\nbiology knowledge in KGs can enhance protein representation with external\nknowledge. In this work, we propose OntoProtein, the first general framework\nthat makes use of structure in GO (Gene Ontology) into protein pre-training\nmodels. We construct a novel large-scale knowledge graph that consists of GO\nand its related proteins, and gene annotation texts or protein sequences\ndescribe all nodes in the graph. We propose novel contrastive learning with\nknowledge-aware negative sampling to jointly optimize the knowledge graph and\nprotein embedding during pre-training. Experimental results show that\nOntoProtein can surpass state-of-the-art methods with pre-trained protein\nlanguage models in TAPE benchmark and yield better performance compared with\nbaselines in protein-protein interaction and protein function prediction. Code\nand datasets are available in https://github.com/zjunlp/OntoProtein.",
          "link": "http://arxiv.org/abs/2201.11147",
          "publishedOn": "2022-04-14T00:58:52.137Z",
          "wordCount": null,
          "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding. (arXiv:2201.11147v3 [q-bio.BM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.02552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Truong_D/0/1/0/all/0/1\">Dung Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_M/0/1/0/all/0/1\">Manisha Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkataraju_K/0/1/0/all/0/1\">Kannan Umadevi Venkataraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milham_M/0/1/0/all/0/1\">Michael Milham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delorme_A/0/1/0/all/0/1\">Arnaud Delorme</a>",
          "description": "Deep Learning has revolutionized various fields, including Computer Vision,\nNatural Language Processing, as well as Biomedical research. Within the field\nof neuroscience, specifically in electrophysiological neuroimaging, researchers\nare starting to explore leveraging deep learning to make predictions on their\ndata without extensive feature engineering. The availability of large-scale\ndatasets is a crucial aspect of allowing the experimentation of Deep Learning\nmodels. We are publishing the first large-scale clinical EEG dataset that\nsimplifies data access and management for Deep Learning. This dataset contains\neyes-closed EEG data prepared from a collection of 1,574 juvenile participants\nfrom the Healthy Brain Network. We demonstrate a use case integrating this\nframework, and discuss why providing such neuroinformatics infrastructure to\nthe community is critical for future scientific discoveries.",
          "link": "http://arxiv.org/abs/2203.02552",
          "publishedOn": "2022-04-14T00:58:52.137Z",
          "wordCount": null,
          "title": "A streamable large-scale clinical EEG dataset for Deep Learning. (arXiv:2203.02552v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yingxia Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>",
          "description": "In the era of big data, intellectual property-oriented scientific and\ntechnological resources show the trend of large data scale, high information\ndensity and low value density, which brings severe challenges to the effective\nuse of intellectual property resources, and the demand for mining hidden\ninformation in intellectual property is increasing. This makes intellectual\nproperty-oriented science and technology resource portraits and analysis of\nevolution become the current research hotspot. This paper sorts out the\nconstruction method of intellectual property resource intellectual portrait and\nits pre-work property entity extraction and entity completion from the aspects\nof algorithm classification and general process, and directions for improvement\nof future methods.",
          "link": "http://arxiv.org/abs/2204.06221",
          "publishedOn": "2022-04-14T00:58:52.136Z",
          "wordCount": null,
          "title": "Research on Intellectual Property Resource Profile and Evolution Law. (arXiv:2204.06221v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.00213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianren Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shangqi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1\">Tian Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaolin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>",
          "description": "Goal-conditioned Hierarchical Reinforcement Learning (HRL) is a promising\napproach for scaling up reinforcement learning (RL) techniques. However, it\noften suffers from training inefficiency as the action space of the high-level,\ni.e., the goal space, is large. Searching in a large goal space poses\ndifficulty for both high-level subgoal generation and low-level policy\nlearning. In this paper, we show that this problem can be effectively\nalleviated by restricting the high-level action space from the whole goal space\nto a $k$-step adjacent region of the current state using an adjacency\nconstraint. We theoretically prove that in a deterministic Markov Decision\nProcess (MDP), the proposed adjacency constraint preserves the optimal\nhierarchical policy, while in a stochastic MDP the adjacency constraint induces\na bounded state-value suboptimality determined by the MDP's transition\nstructure. We further show that this constraint can be practically implemented\nby training an adjacency network that can discriminate between adjacent and\nnon-adjacent subgoals. Experimental results on discrete and continuous control\ntasks including challenging simulated robot locomotion and manipulation tasks\nshow that incorporating the adjacency constraint significantly boosts the\nperformance of state-of-the-art goal-conditioned HRL approaches.",
          "link": "http://arxiv.org/abs/2111.00213",
          "publishedOn": "2022-04-14T00:58:52.136Z",
          "wordCount": null,
          "title": "Adjacency constraint for efficient hierarchical reinforcement learning. (arXiv:2111.00213v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krahenbuhl_P/0/1/0/all/0/1\">Philipp Kr&#xe4;henb&#xfc;hl</a>",
          "description": "In this paper, we present a system to train driving policies from experiences\ncollected not just from the ego-vehicle, but all vehicles that it observes.\nThis system uses the behaviors of other agents to create more diverse driving\nscenarios without collecting additional data. The main difficulty in learning\nfrom other vehicles is that there is no sensor information. We use a set of\nsupervisory tasks to learn an intermediate representation that is invariant to\nthe viewpoint of the controlling vehicle. This not only provides a richer\nsignal at training time but also allows more complex reasoning during\ninference. Learning how all vehicles drive helps predict their behavior at test\ntime and can avoid collisions. We evaluate this system in closed-loop driving\nsimulations. Our system outperforms all prior methods on the public CARLA\nLeaderboard by a wide margin, improving driving score by 25 and route\ncompletion rate by 24 points. Our method won the 2021 CARLA Autonomous Driving\nchallenge. Code and data are available at https://github.com/dotchen/LAV.",
          "link": "http://arxiv.org/abs/2203.11934",
          "publishedOn": "2022-04-14T00:58:52.135Z",
          "wordCount": null,
          "title": "Learning from All Vehicles. (arXiv:2203.11934v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahloujifar_S/0/1/0/all/0/1\">Saeed Mahloujifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sablayrolles_A/0/1/0/all/0/1\">Alexandre Sablayrolles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1\">Graham Cormode</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Somesh Jha</a>",
          "description": "Given a trained model and a data sample, membership-inference (MI) attacks\npredict whether the sample was in the model's training set. A common\ncountermeasure against MI attacks is to utilize differential privacy (DP)\nduring model training to mask the presence of individual examples. While this\nuse of DP is a principled approach to limit the efficacy of MI attacks, there\nis a gap between the bounds provided by DP and the empirical performance of MI\nattacks. In this paper, we derive bounds for the \\textit{advantage} of an\nadversary mounting a MI attack, and demonstrate tightness for the widely-used\nGaussian mechanism. We further show bounds on the \\textit{confidence} of MI\nattacks. Our bounds are much stronger than those obtained by DP analysis. For\nexample, analyzing a setting of DP-SGD with $\\epsilon=4$ would obtain an upper\nbound on the advantage of $\\approx0.36$ based on our analyses, while getting\nbound of $\\approx 0.97$ using the analysis of previous work that convert\n$\\epsilon$ to membership inference bounds.\n\nFinally, using our analysis, we provide MI metrics for models trained on\nCIFAR10 dataset. To the best of our knowledge, our analysis provides the\nstate-of-the-art membership inference bounds for the privacy.",
          "link": "http://arxiv.org/abs/2204.06106",
          "publishedOn": "2022-04-14T00:58:52.134Z",
          "wordCount": null,
          "title": "Optimal Membership Inference Bounds for Adaptive Composition of Sampled Gaussian Mechanisms. (arXiv:2204.06106v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toit_J/0/1/0/all/0/1\">J du Toit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preez_J/0/1/0/all/0/1\">J du Preez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolhuter_R/0/1/0/all/0/1\">R Wolhuter</a>",
          "description": "We present a comparison study between a cluster and factor graph\nrepresentation of LDPC codes. In probabilistic graphical models, cluster graphs\nretain useful dependence between random variables during inference, which are\nadvantageous in terms of computational cost, convergence speed, and accuracy of\nmarginal probabilities. This study investigates these benefits in the context\nof LDPC codes and shows that a cluster graph representation outperforms the\ntraditional factor graph representation.",
          "link": "http://arxiv.org/abs/2204.06350",
          "publishedOn": "2022-04-14T00:58:52.134Z",
          "wordCount": null,
          "title": "LDPC codes: comparing cluster graphs to factor graphs. (arXiv:2204.06350v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06310",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wodzinski_M/0/1/0/all/0/1\">Marek Wodzinski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Daniol_M/0/1/0/all/0/1\">Mateusz Daniol</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Socha_M/0/1/0/all/0/1\">Miroslaw Socha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hemmerling_D/0/1/0/all/0/1\">Daria Hemmerling</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stanuch_M/0/1/0/all/0/1\">Maciej Stanuch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Skalski_A/0/1/0/all/0/1\">Andrzej Skalski</a>",
          "description": "The goal of this work is to propose a robust, fast, and fully automatic\nmethod for personalized cranial defect reconstruction and implant modeling.\n\nWe propose a two-step deep learning-based method using a modified U-Net\narchitecture to perform the defect reconstruction, and a dedicated iterative\nprocedure to improve the implant geometry, followed by automatic generation of\nmodels ready for 3-D printing. We propose a cross-case augmentation based on\nimperfect image registration combining cases from different datasets. We\nperform ablation studies regarding different augmentation strategies and\ncompare them to other state-of-the-art methods.\n\nWe evaluate the method on three datasets introduced during the AutoImplant\n2021 challenge, organized jointly with the MICCAI conference. We perform the\nquantitative evaluation using the Dice and boundary Dice coefficients, and the\nHausdorff distance. The average Dice coefficient, boundary Dice coefficient,\nand the 95th percentile of Hausdorff distance are 0.91, 0.94, and 1.53 mm\nrespectively. We perform an additional qualitative evaluation by 3-D printing\nand visualization in mixed reality to confirm the implant's usefulness.\n\nWe propose a complete pipeline that enables one to create the cranial implant\nmodel ready for 3-D printing. The described method is a greatly extended\nversion of the method that scored 1st place in all AutoImplant 2021 challenge\ntasks. We freely release the source code, that together with the open datasets,\nmakes the results fully reproducible. The automatic reconstruction of cranial\ndefects may enable manufacturing personalized implants in a significantly\nshorter time, possibly allowing one to perform the 3-D printing process\ndirectly during a given intervention. Moreover, we show the usability of the\ndefect reconstruction in mixed reality that may further reduce the surgery\ntime.",
          "link": "http://arxiv.org/abs/2204.06310",
          "publishedOn": "2022-04-14T00:58:52.121Z",
          "wordCount": null,
          "title": "Deep Learning-based Framework for Automatic Cranial Defect Reconstruction and Implant Modeling. (arXiv:2204.06310v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michel_P/0/1/0/all/0/1\">Paul Michel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1\">Tatsunori Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>",
          "description": "As machine learning models are deployed ever more broadly, it becomes\nincreasingly important that they are not only able to perform well on their\ntraining distribution, but also yield accurate predictions when confronted with\ndistribution shift. The Distributionally Robust Optimization (DRO) framework\nproposes to address this issue by training models to minimize their expected\nrisk under a collection of distributions, to imitate test-time shifts. This is\nmost commonly achieved by instance-level re-weighting of the training objective\nto emulate the likelihood ratio with possible test distributions, which allows\nfor estimating their empirical risk via importance sampling (assuming that they\nare subpopulations of the training distribution). However, re-weighting schemes\nin the literature are usually limited due to the difficulty of keeping the\noptimization problem tractable and the complexity of enforcing normalization\nconstraints. In this paper, we show that three simple ideas -- mini-batch level\nnormalization, a KL penalty and simultaneous gradient updates -- allow us to\ntrain models with DRO using a broader class of parametric likelihood ratios. In\na series of experiments on both image and text classification benchmarks, we\nfind that models trained with the resulting parametric adversaries are\nconsistently more robust to subpopulation shifts when compared to other DRO\napproaches, and that the method performs reliably well with little\nhyper-parameter tuning. Code to reproduce our experiments can be found at\nhttps://github.com/pmichel31415/P-DRO.",
          "link": "http://arxiv.org/abs/2204.06340",
          "publishedOn": "2022-04-14T00:58:52.121Z",
          "wordCount": null,
          "title": "Distributionally Robust Models with Parametric Likelihood Ratios. (arXiv:2204.06340v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wallin_E/0/1/0/all/0/1\">Erik Wallin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiberg_V/0/1/0/all/0/1\">Viktor Wiberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vesterlund_F/0/1/0/all/0/1\">Folke Vesterlund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmgren_J/0/1/0/all/0/1\">Johan Holmgren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Persson_H/0/1/0/all/0/1\">Henrik Persson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Servin_M/0/1/0/all/0/1\">Martin Servin</a>",
          "description": "We present a method that uses high-resolution topography data of rough\nterrain, and ground vehicle simulation, to predict traversability.\nTraversability is expressed as three independent measures: the ability to\ntraverse the terrain at a target speed, energy consumption, and acceleration.\nThe measures are continuous and reflect different objectives for planning that\ngo beyond binary classification. A deep neural network is trained to predict\nthe traversability measures from the local heightmap and target speed. To\nproduce training data, we use an articulated vehicle with wheeled bogie\nsuspensions and procedurally generated terrains. We evaluate the model on\nlaser-scanned forest terrains, previously unseen by the model. The model\npredicts traversability with an accuracy of 90%. Predictions rely on features\nfrom the high-dimensional terrain data that surpass local roughness and slope\nrelative to the heading. Correlations show that the three traversability\nmeasures are complementary to each other. With an inference speed 3000 times\nfaster than the ground truth simulation and trivially parallelizable, the model\nis well suited for traversability analysis and optimal path planning over large\nareas.",
          "link": "http://arxiv.org/abs/2203.16354",
          "publishedOn": "2022-04-14T00:58:52.121Z",
          "wordCount": null,
          "title": "Learning multiobjective rough terrain traversability. (arXiv:2203.16354v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaoli Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jun Han</a>",
          "description": "Since 2016, we have witnessed the tremendous growth of artificial\nintelligence+visualization (AI+VIS) research. However, existing survey papers\non AI+VIS focus on visual analytics and information visualization, not\nscientific visualization (SciVis). In this paper, we survey related deep\nlearning (DL) works in SciVis, specifically in the direction of DL4SciVis:\ndesigning DL solutions for solving SciVis problems. To stay focused, we\nprimarily consider works that handle scalar and vector field data but exclude\nmesh data. We classify and discuss these works along six dimensions: domain\nsetting, research task, learning type, network architecture, loss function, and\nevaluation metric. The paper concludes with a discussion of the remaining gaps\nto fill along the discussed dimensions and the grand challenges we need to\ntackle as a community. This state-of-the-art survey guides SciVis researchers\nin gaining an overview of this emerging topic and points out future directions\nto grow this research.",
          "link": "http://arxiv.org/abs/2204.06504",
          "publishedOn": "2022-04-14T00:58:52.118Z",
          "wordCount": null,
          "title": "DL4SciVis: A State-of-the-Art Survey on Deep Learning for Scientific Visualization. (arXiv:2204.06504v1 [cs.GR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1\">Joanna Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perlin_K/0/1/0/all/0/1\">Kuba Perlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamalakara_S/0/1/0/all/0/1\">Siddhartha Rao Kamalakara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Araujo_J/0/1/0/all/0/1\">Jo&#xe3;o G.M. Ara&#xfa;jo</a>",
          "description": "Modern large language models require distributed training strategies due to\ntheir size. The challenges of efficiently and robustly training them are met\nwith rapid developments on both software and hardware frontiers. In this\ntechnical report, we explore challenges and design decisions associated with\ndeveloping a scalable training framework, and present a quantitative analysis\nof efficiency improvements coming from adopting new software and hardware\nsolutions.",
          "link": "http://arxiv.org/abs/2204.06514",
          "publishedOn": "2022-04-14T00:58:52.118Z",
          "wordCount": null,
          "title": "Scalable Training of Language Models using JAX pjit and TPUv4. (arXiv:2204.06514v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gangwar_A/0/1/0/all/0/1\">Amisha Gangwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_T/0/1/0/all/0/1\">Tanvi Mehta</a>",
          "description": "Sentiment Analysis is a vital research topic in the field of Computer\nScience. With the accelerated development of Information Technology and social\nnetworks, a massive amount of data related to comment texts has been generated\non web applications or social media platforms like Twitter. Due to this, people\nhave actively started proliferating general information and the information\nrelated to political opinions, which becomes an important reason for analyzing\npublic reactions. Most researchers have used social media specifics or contents\nto analyze and predict public opinion concerning political events. This\nresearch proposes an analytical study using Israeli political Twitter data to\ninterpret public opinion towards the Palestinian-Israeli conflict. The\nattitudes of ethnic groups and opinion leaders in the form of tweets are\nanalyzed using Machine Learning algorithms like Support Vector Classifier\n(SVC), Decision Tree (DT), and Naive Bayes (NB). Finally, a comparative\nanalysis is done based on experimental results from different models.",
          "link": "http://arxiv.org/abs/2204.06515",
          "publishedOn": "2022-04-14T00:58:52.118Z",
          "wordCount": null,
          "title": "Sentiment Analysis of Political Tweets for Israel using Machine Learning. (arXiv:2204.06515v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.05848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changjun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaomo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xudong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuhua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaofang Wang</a>",
          "description": "The demand of probabilistic time series forecasting has been recently raised\nin various dynamic system scenarios, for example, system identification and\nprognostic and health management of machines. To this end, we combine the\nadvances in both deep generative models and state space model (SSM) to come up\nwith a novel, data-driven deep probabilistic sequence model. Specifically, we\nfollow the popular encoder-decoder generative structure to build the recurrent\nneural networks (RNN) assisted variational sequence model on an augmented\nrecurrent input space, which could induce rich stochastic sequence dependency.\nBesides, in order to alleviate the inconsistency issue of the posterior between\ntraining and predicting as well as improving the mining of dynamic patterns, we\n(i) propose using a lagged hybrid output as input for the posterior at next\ntime step, which brings training and predicting into alignment; and (ii)\nfurther devise a generalized auto-regressive strategy that encodes all the\nhistorical dependencies for the posterior. Thereafter, we first investigate the\nmethodological characteristics of the proposed deep probabilistic sequence\nmodel on toy cases, and then comprehensively demonstrate the superiority of our\nmodel against existing deep probabilistic SSM models through extensive\nnumerical experiments on eight system identification benchmarks from various\ndynamic systems. Finally, we apply our sequence model to a real-world\ncentrifugal compressor forecasting problem, and again verify its outstanding\nperformance by quantifying the time series predictive distribution.",
          "link": "http://arxiv.org/abs/2106.05848",
          "publishedOn": "2022-04-14T00:58:52.117Z",
          "wordCount": null,
          "title": "Deep Probabilistic Time Series Forecasting using Augmented Recurrent Input for Dynamic Systems. (arXiv:2106.05848v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02163",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bentley_P/0/1/0/all/0/1\">Peter J Bentley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Soo Ling Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaier_A/0/1/0/all/0/1\">Adam Gaier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_L/0/1/0/all/0/1\">Linh Tran</a>",
          "description": "Constrained optimization problems can be difficult because their search\nspaces have properties not conducive to search, e.g., multimodality,\ndiscontinuities, or deception. To address such difficulties, considerable\nresearch has been performed on creating novel evolutionary algorithms or\nspecialized genetic operators. However, if the representation that defined the\nsearch space could be altered such that it only permitted valid solutions that\nsatisfied the constraints, the task of finding the optimal would be made more\nfeasible without any need for specialized optimization algorithms. We propose\nConstrained Optimization in Latent Space (COIL), which uses a VAE to generate a\nlearned latent representation from a dataset comprising samples from the valid\nregion of the search space according to a constraint, thus enabling the\noptimizer to find the objective in the new space defined by the learned\nrepresentation. Preliminary experiments show promise: compared to an identical\nGA using a standard representation that cannot meet the constraints or find fit\nsolutions, COIL with its learned latent representation can perfectly satisfy\ndifferent types of constraints while finding high-fitness solutions.",
          "link": "http://arxiv.org/abs/2202.02163",
          "publishedOn": "2022-04-14T00:58:52.117Z",
          "wordCount": null,
          "title": "COIL: Constrained Optimization in Learned Latent Space -- Learning Representations for Valid Solutions. (arXiv:2202.02163v3 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.02194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yibo Zhou</a>",
          "description": "In some scenarios, classifier requires detecting out-of-distribution samples\nfar from its training data. With desirable characteristics, reconstruction\nautoencoder-based methods deal with this problem by using input reconstruction\nerror as a metric of novelty vs. normality. We formulate the essence of such\napproach as a quadruplet domain translation with an intrinsic bias to only\nquery for a proxy of conditional data uncertainty. Accordingly, an improvement\ndirection is formalized as maximumly compressing the autoencoder's latent space\nwhile ensuring its reconstructive power for acting as a described domain\ntranslator. From it, strategies are introduced including semantic\nreconstruction, data certainty decomposition and normalized L2 distance to\nsubstantially improve original methods, which together establish\nstate-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of\nCIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method\nworks without any additional data, hard-to-implement structure, time-consuming\npipeline, and even harming the classification accuracy of known classes.",
          "link": "http://arxiv.org/abs/2203.02194",
          "publishedOn": "2022-04-14T00:58:52.117Z",
          "wordCount": null,
          "title": "Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection. (arXiv:2203.02194v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_J/0/1/0/all/0/1\">Jibing Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yao Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuewen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1\">Wenzheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Massive open online courses (MOOCs), which provide a large-scale interactive\nparticipation and open access via the web, are becoming a modish way for online\nand distance education. To help users have a better study experience, many MOOC\nplatforms have provided the services of recommending courses to users. However,\nwe argue that directly recommending a course to users will ignore the expertise\nlevels of different users. To fill this gap, this paper studies the problem of\nconcept recommendation in a more fine-grained view. We propose a novel\nHeterogeneous Information Networks based Concept Recommender with Reinforcement\nLearning (HinCRec-RL) incorporated for concept recommendation in MOOCs.\nSpecifically, we first formulate the concept recommendation in MOOCs as a\nreinforcement learning problem to better model the dynamic interaction among\nusers and knowledge concepts. In addition, to mitigate the data sparsity issue\nwhich also exists in many other recommendation tasks, we consider a\nheterogeneous information network (HIN) among users, courses, videos and\nconcepts, to better learn the semantic representation of users. In particular,\nwe use the meta-paths on HIN to guide the propagation of users' preferences and\npropose a heterogeneous graph attention network to represent the meta-paths. To\nvalidate the effectiveness of our proposed approach, we conduct comprehensive\nexperiments on a real-world dataset from XuetangX, a popular MOOC platform from\nChina. The promising results show that our proposed approach can outperform\nother baselines.",
          "link": "http://arxiv.org/abs/2203.11011",
          "publishedOn": "2022-04-14T00:58:52.117Z",
          "wordCount": null,
          "title": "Reinforced MOOCs Concept Recommendation in Heterogeneous Information Networks. (arXiv:2203.11011v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06164",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ding_S/0/1/0/all/0/1\">Shaojin Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1\">Weiran Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yanzhang He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+David_R/0/1/0/all/0/1\">Robert David</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Botros_R/0/1/0/all/0/1\">Rami Botros</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Panigrahy_R/0/1/0/all/0/1\">Rina Panigrahy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_Q/0/1/0/all/0/1\">Qiao Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hwang_D/0/1/0/all/0/1\">Dongseong Hwang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McGraw_I/0/1/0/all/0/1\">Ian McGraw</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prabhavalkar_R/0/1/0/all/0/1\">Rohit Prabhavalkar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Strohman_T/0/1/0/all/0/1\">Trevor Strohman</a>",
          "description": "In this paper, we propose a dynamic cascaded encoder Automatic Speech\nRecognition (ASR) model, which unifies models for different deployment\nscenarios. Moreover, the model can significantly reduce model size and power\nconsumption without loss of quality. Namely, with the dynamic cascaded encoder\nmodel, we explore three techniques to maximally boost the performance of each\nmodel size: 1) Use separate decoders for each sub-model while sharing the\nencoders; 2) Use funnel-pooling to improve the encoder efficiency; 3) Balance\nthe size of causal and non-causal encoders to improve quality and fit\ndeployment constraints. Overall, the proposed large-medium model has 30%\nsmaller size and reduces power consumption by 33%, compared to the baseline\ncascaded encoder model. The triple-size model that unifies the large, medium,\nand small models achieves 37% total size reduction with minimal quality loss,\nwhile substantially reducing the engineering efforts of having separate models.",
          "link": "http://arxiv.org/abs/2204.06164",
          "publishedOn": "2022-04-14T00:58:52.116Z",
          "wordCount": null,
          "title": "A Unified Cascaded Encoder ASR Model for Dynamic Model Sizes. (arXiv:2204.06164v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.13695",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fonseca_E/0/1/0/all/0/1\">Erika Fonseca</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Galkin_B/0/1/0/all/0/1\">Boris Galkin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Amer_R/0/1/0/all/0/1\">Ramy Amer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+DaSilva_L/0/1/0/all/0/1\">Luiz A. DaSilva</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dusparic_I/0/1/0/all/0/1\">Ivana Dusparic</a>",
          "description": "Providing reliable connectivity to cellular-connected UAV can be very\nchallenging; their performance highly depends on the nature of the surrounding\nenvironment, such as density and heights of the ground BSs. On the other hand,\ntall buildings might block undesired interference signals from ground BSs,\nthereby improving the connectivity between the UAVs and their serving BSs. To\naddress the connectivity of UAVs in such environments, this paper proposes a RL\nalgorithm to dynamically optimise the height of a UAV as it moves through the\nenvironment, with the goal of increasing the throughput or spectrum efficiency\nthat it experiences. The proposed solution is evaluated in two settings: using\na series of generated environments where we vary the number of BS and building\ndensities, and in a scenario using real-world data obtained from an experiment\nin Dublin, Ireland. Results show that our proposed RL-based solution improves\nUAVs QoS by 6% to 41%, depending on the scenario. We also conclude that, when\nflying at heights higher than the buildings, building density variation has no\nimpact on UAV QoS. On the other hand, BS density can negatively impact UAV QoS,\nwith higher numbers of BSs generating more interference and deteriorating UAV\nperformance.",
          "link": "http://arxiv.org/abs/2007.13695",
          "publishedOn": "2022-04-14T00:58:52.116Z",
          "wordCount": null,
          "title": "Adaptive Height Optimisation for Cellular-Connected UAVs using Reinforcement Learning. (arXiv:2007.13695v3 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.14181",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Roychowdhury_S/0/1/0/all/0/1\">Sohini Roychowdhury</a>",
          "description": "Automated segmentation of pathological regions of interest aids medical image\ndiagnostics and follow-up care. However, accurate pathological segmentations\nrequire high quality of annotated data that can be both cost and time intensive\nto generate. In this work, we propose an automated two-step method that detects\na minimal image subset required to train segmentation models by evaluating the\nquality of medical images from 3D image stacks using a U-net++ model. These\nimages that represent a lack of quality training can then be annotated and used\nto fully train a U-net-based segmentation model. The proposed QU-net++ model\ndetects this lack of quality training based on the disagreement in\nsegmentations produced from the final two output layers. The proposed model\nisolates around 10% of the slices per 3D image stack and can scale across\nimaging modalities to segment cysts in OCT images and ground glass opacity\n(GGO) in lung CT images with Dice scores in the range 0.56-0.72. Thus, the\nproposed method can be applied for cost effective multi-modal pathology\nsegmentation tasks.",
          "link": "http://arxiv.org/abs/2110.14181",
          "publishedOn": "2022-04-14T00:58:52.116Z",
          "wordCount": null,
          "title": "QU-net++: Image Quality Detection Framework for Segmentation of Medical 3D Image Stacks. (arXiv:2110.14181v4 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.13858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenhua Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1\">Dong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haozhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fanglin Liu</a>",
          "description": "Deep learning oriented named entity recognition (DNER) has gradually become\nthe paradigm of knowledge discovery, which greatly promotes domain\nintelligence. However, the current activation function of DNER fails to treat\ngradient vanishing, no negative output or non-differentiable existence, which\nmay impede knowledge exploration caused by the omission and incomplete\nrepresentation of latent semantics. To break through the dilemma, we present a\nnovel activation function termed KDAC. Detailly, KDAC is an aggregation\nfunction with multiple conversion modes. The backbone of the activation region\nis the interaction between exponent and linearity, and the both ends extend\nthrough adaptive linear divergence, which surmounts the obstacle of gradient\nvanishing and no negative output. Crucially, the non-differentiable points are\nalerted and eliminated by an approximate smoothing algorithm. KDAC has a series\nof brilliant properties, including nonlinear, stable near-linear transformation\nand derivative, as well as dynamic style, etc. We perform experiments based on\nBERT-BiLSTM-CNN-CRF model on six benchmark datasets containing different domain\nknowledge, such as Weibo, Clinical, E-commerce, Resume, HAZOP and People's\ndaily. The evaluation results show that KDAC is advanced and effective, and can\nprovide more generalized activation to stimulate the performance of DNER. We\nhope that KDAC can be exploited as a promising activation function to devote\nitself to the construction of knowledge.",
          "link": "http://arxiv.org/abs/2111.13858",
          "publishedOn": "2022-04-14T00:58:52.116Z",
          "wordCount": null,
          "title": "Why KDAC? A general activation function for knowledge discovery. (arXiv:2111.13858v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhat_A/0/1/0/all/0/1\">Avinash Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coursey_A/0/1/0/all/0/1\">Austin Coursey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1\">Grace Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sixian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nahar_N/0/1/0/all/0/1\">Nadia Nahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shurui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kastner_C/0/1/0/all/0/1\">Christian K&#xe4;stner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jin L.C. Guo</a>",
          "description": "Machine learning models have been widely developed, released, and adopted in\nnumerous applications. Meanwhile, the documentation practice for machine\nlearning models often falls short of established practices for traditional\nsoftware components, which impedes model accountability, inadvertently abets\ninappropriate or misuse of models, and may trigger negative social impact.\nRecently, model cards, a template for documenting machine learning models, have\nattracted notable attention, but their impact on the practice of model\ndocumentation is unclear. In this work, we examine publicly available model\ncards and other similar documentation. Our analysis reveals a substantial gap\nbetween the suggestions made in the original model card work and the content in\nactual documentation. Motivated by this observation and literature on fields\nsuch as software documentation, interaction design, and traceability, we\nfurther propose a set of design guidelines that aim to support the\ndocumentation practice for machine learning models including (1) the\ncollocation of documentation environment with the coding environment, (2)\nnudging the consideration of model card sections during model development, and\n(3) documentation derived from and traced to the source. We designed a\nprototype tool named DocML following those guidelines to support model\ndevelopment in computational notebooks. A lab study reveals the benefit of our\ntool to shift the behavior of data scientists towards documentation quality and\naccountability.",
          "link": "http://arxiv.org/abs/2204.06425",
          "publishedOn": "2022-04-14T00:58:52.115Z",
          "wordCount": null,
          "title": "Aspirations and Practice of Model Documentation: Moving the Needle with Nudging and Traceability. (arXiv:2204.06425v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Le Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1\">Tongyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Leilei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bowen Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_W/0/1/0/all/0/1\">Weifeng Lv</a>",
          "description": "Given a sequence of sets, where each set is associated with a timestamp and\ncontains an arbitrary number of elements, the task of temporal sets prediction\naims to predict the elements in the subsequent set. Previous studies for\ntemporal sets prediction mainly capture each user's evolutionary preference by\nlearning from his/her own sequence. Although insightful, we argue that: 1) the\ncollaborative signals latent in different users' sequences are essential but\nhave not been exploited; 2) users also tend to show stationary preferences\nwhile existing methods fail to consider. To this end, we propose an integrated\nlearning framework to model both the evolutionary and the stationary\npreferences of users for temporal sets prediction, which first constructs a\nuniversal sequence by chronologically arranging all the user-set interactions,\nand then learns on each user-set interaction. In particular, for each user-set\ninteraction, we first design an evolutionary user preference modelling\ncomponent to track the user's time-evolving preference and exploit the latent\ncollaborative signals among different users. This component maintains a memory\nbank to store memories of the related user and elements, and continuously\nupdates their memories based on the currently encoded messages and the past\nmemories. Then, we devise a stationary user preference modelling module to\ndiscover each user's personalized characteristics according to the historical\nsequence, which adaptively aggregates the previously interacted elements from\ndual perspectives with the guidance of the user's and elements' embeddings.\nFinally, we develop a set-batch algorithm to improve the model efficiency,\nwhich can create time-consistent batches in advance and achieve 3.5x training\nspeedups on average. Experiments on real-world datasets demonstrate the\neffectiveness and good interpretability of our approach.",
          "link": "http://arxiv.org/abs/2204.05490",
          "publishedOn": "2022-04-14T00:58:52.115Z",
          "wordCount": null,
          "title": "Modelling Evolutionary and Stationary User Preferences for Temporal Sets Prediction. (arXiv:2204.05490v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_H/0/1/0/all/0/1\">Hyunjin Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seungwoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chanyoung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1\">Kijung Shin</a>",
          "description": "Hypergraphs (i.e., sets of hyperedges) naturally represent group relations\n(e.g., researchers co-authoring a paper and ingredients used together in a\nrecipe), each of which corresponds to a hyperedge (i.e., a subset of nodes).\nPredicting future or missing hyperedges bears significant implication for many\napplications (e.g., collaboration and recipe recommendation). What makes\nhyperedge prediction particularly challenging is the vast number of\nnon-hyperedge subsets, which grows exponentially with the number of nodes.\nSince it is prohibitive to use all of them as negative examples for model\ntraining, it is inevitable to sample a very small portion of them, and to this\nend, heuristic sampling schemes have been employed. However, trained models\nsuffer from poor generalization capability for examples of different natures.\nIn this paper, we propose AHP, an adversarial training-based\nhyperedge-prediction method. It learns to sample negative examples without\nrelying on any heuristic schemes. Using six real hypergraphs, we show that AHP\ngeneralizes better to negative examples of various natures. It yields up to\n28.2% higher AUROC than best existing methods and often even outperforms its\nvariants with sampling schemes tailored to test sets.",
          "link": "http://arxiv.org/abs/2204.06353",
          "publishedOn": "2022-04-14T00:58:52.114Z",
          "wordCount": null,
          "title": "AHP: Learning to Negative Sample for Hyperedge Prediction. (arXiv:2204.06353v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Solmaz_G/0/1/0/all/0/1\">G&#xfc;rkan Solmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cirillo_F/0/1/0/all/0/1\">Flavio Cirillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maresca_F/0/1/0/all/0/1\">Fabio Maresca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Anagha Gode Anil Kumar</a>",
          "description": "Weak supervision (WS) is an alternative to the traditional supervised\nlearning to address the need for ground truth. Data programming is a practical\nWS approach that allows programmatic labeling data samples using labeling\nfunctions (LFs) instead of hand-labeling each data point. However, the existing\napproach fails to fully exploit the domain knowledge encoded into LFs,\nespecially when the LFs' coverage is low. This is due to the common data\nprogramming pipeline that neglects to utilize data features during the\ngenerative process. This paper proposes a new approach called reinforced\nlabeling (RL). Given an unlabeled dataset and a set of LFs, RL augments the\nLFs' outputs to cases not covered by LFs based on similarities among samples.\nThus, RL can lead to higher labeling coverage for training an end classifier.\nThe experiments on several domains (classification of YouTube comments, wine\nquality, and weather prediction) result in considerable gains. The new approach\nproduces significant performance improvement, leading up to +21 points in\naccuracy and +61 points in F1 scores compared to the state-of-the-art data\nprogramming approach.",
          "link": "http://arxiv.org/abs/2204.06436",
          "publishedOn": "2022-04-14T00:58:52.114Z",
          "wordCount": null,
          "title": "Label Augmentation with Reinforced Labeling for Weak Supervision. (arXiv:2204.06436v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srinivasa_R/0/1/0/all/0/1\">Rakshith S Srinivasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Cheng Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_B/0/1/0/all/0/1\">Brandon Theodorou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spaeder_J/0/1/0/all/0/1\">Jeffrey Spaeder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Cao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_L/0/1/0/all/0/1\">Lucas Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>",
          "description": "The ongoing pandemic has highlighted the importance of reliable and efficient\nclinical trials in healthcare. Trial sites, where the trials are conducted, are\nchosen mainly based on feasibility in terms of medical expertise and access to\na large group of patients. More recently, the issue of diversity and inclusion\nin clinical trials is gaining importance. Different patient groups may\nexperience the effects of a medical drug/ treatment differently and hence need\nto be included in the clinical trials. These groups could be based on\nethnicity, co-morbidities, age, or economic factors. Thus, designing a method\nfor trial site selection that accounts for both feasibility and diversity is a\ncrucial and urgent goal. In this paper, we formulate this problem as a ranking\nproblem with fairness constraints. Using principles of fairness in machine\nlearning, we learn a model that maps a clinical trial description to a ranked\nlist of potential trial sites. Unlike existing fairness frameworks, the group\nmembership of each trial site is non-binary: each trial site may have access to\npatients from multiple groups. We propose fairness criteria based on\ndemographic parity to address such a multi-group membership scenario. We test\nour method on 480 real-world clinical trials and show that our model results in\na list of potential trial sites that provides access to a diverse set of\npatients while also ensuing a high number of enrolled patients.",
          "link": "http://arxiv.org/abs/2204.06501",
          "publishedOn": "2022-04-14T00:58:52.114Z",
          "wordCount": null,
          "title": "Clinical trial site matching with improved diversity using fair policy learning. (arXiv:2204.06501v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.12650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avram_A/0/1/0/all/0/1\">Andrei-Marius Avram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catrina_D/0/1/0/all/0/1\">Darius Catrina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cercel_D/0/1/0/all/0/1\">Dumitru-Clementin Cercel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dascalu_M/0/1/0/all/0/1\">Mihai Dasc&#x103;lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rebedea_T/0/1/0/all/0/1\">Traian Rebedea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pais_V/0/1/0/all/0/1\">Vasile P&#x103;i&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tufis_D/0/1/0/all/0/1\">Dan Tufi&#x15f;</a>",
          "description": "Running large-scale pre-trained language models in computationally\nconstrained environments remains a challenging problem yet to be addressed,\nwhile transfer learning from these models has become prevalent in Natural\nLanguage Processing tasks. Several solutions, including knowledge distillation,\nnetwork quantization, or network pruning have been previously proposed;\nhowever, these approaches focus mostly on the English language, thus widening\nthe gap when considering low-resource languages. In this work, we introduce\nthree light and fast versions of distilled BERT models for the Romanian\nlanguage: Distil-BERT-base-ro, Distil-RoBERT-base, and\nDistilMulti-BERT-base-ro. The first two models resulted from the individual\ndistillation of knowledge from two base versions of Romanian BERTs available in\nliterature, while the last one was obtained by distilling their ensemble. To\nour knowledge, this is the first attempt to create publicly available Romanian\ndistilled BERT models, which were thoroughly evaluated on five tasks:\npart-of-speech tagging, named entity recognition, sentiment analysis, semantic\ntextual similarity, and dialect identification. Our experimental results argue\nthat the three distilled models offer performance comparable to their teachers,\nwhile being twice as fast on a GPU and ~35% smaller. In addition, we further\ntest the similarity between the predictions of our students versus their\nteachers by measuring their label and probability loyalty, together with\nregression loyalty - a new metric introduced in this work.",
          "link": "http://arxiv.org/abs/2112.12650",
          "publishedOn": "2022-04-14T00:58:52.114Z",
          "wordCount": null,
          "title": "Distilling the Knowledge of Romanian BERTs Using Multiple Teachers. (arXiv:2112.12650v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06301",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Li_X/0/1/0/all/0/1\">Xiangru Li</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wang_Z/0/1/0/all/0/1\">Zhu Wang</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Zeng_S/0/1/0/all/0/1\">Si Zeng</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Liao_C/0/1/0/all/0/1\">Caixiu Liao</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Du_B/0/1/0/all/0/1\">Bing Du</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kong_X/0/1/0/all/0/1\">X. Kong</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Li_H/0/1/0/all/0/1\">Haining Li</a>",
          "description": "The accuracy of the estimated stellar atmospheric parameter decreases\nevidently with the decreasing of spectral signal-to-noise ratio (SNR) and there\nare a huge amount of this kind observations, especially in case of SNR$<$30.\nTherefore, it is helpful to improve the parameter estimation performance for\nthese spectra and this work studied the ($T_\\texttt{eff}, \\log~g$, [Fe/H])\nestimation problem for LAMOST DR8 low-resolution spectra with 20$\\leq$SNR$<$30.\nWe proposed a data-driven method based on machine learning techniques. Firstly,\nthis scheme detected stellar atmospheric parameter-sensitive features from\nspectra by the Least Absolute Shrinkage and Selection Operator (LASSO),\nrejected ineffective data components and irrelevant data. Secondly, a\nMulti-layer Perceptron (MLP) method was used to estimate stellar atmospheric\nparameters from the LASSO features. Finally, the performance of the LASSO-MLP\nwas evaluated by computing and analyzing the consistency between its estimation\nand the reference from the APOGEE (Apache Point Observatory Galactic Evolution\nExperiment) high-resolution spectra. Experiments show that the Mean Absolute\nErrors (MAE) of $T_\\texttt{eff}, \\log~g$, [Fe/H] are reduced from the LASP\n(137.6 K, 0.195 dex, 0.091 dex) to LASSO-MLP (84.32 K, 0.137 dex, 0.063 dex),\nwhich indicate evident improvements on stellar atmospheric parameter\nestimation. In addition, this work estimated the stellar atmospheric parameters\nfor 1,162,760 low-resolution spectra with 20$\\leq$SNR$<$30 from LAMOST DR8\nusing LASSO-MLP, and released the estimation catalog, learned model,\nexperimental code, trained model, training data and test data for scientific\nexploration and algorithm study.",
          "link": "http://arxiv.org/abs/2204.06301",
          "publishedOn": "2022-04-14T00:58:52.113Z",
          "wordCount": null,
          "title": "Estimation of stellar atmospheric parameters from LAMOST DR8 low-resolution spectra with 20$\\leq$SNR$<$30. (arXiv:2204.06301v1 [astro-ph.GA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.12109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sachdeva_R/0/1/0/all/0/1\">Ragav Sachdeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hammond_R/0/1/0/all/0/1\">Ravi Hammond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bockman_J/0/1/0/all/0/1\">James Bockman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arthur_A/0/1/0/all/0/1\">Alec Arthur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smart_B/0/1/0/all/0/1\">Brandon Smart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Craggs_D/0/1/0/all/0/1\">Dustin Craggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doan_A/0/1/0/all/0/1\">Anh-Dzung Doan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rowntree_T/0/1/0/all/0/1\">Thomas Rowntree</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutz_E/0/1/0/all/0/1\">Elijah Schutz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orenstein_A/0/1/0/all/0/1\">Adrian Orenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1\">Andy Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_T/0/1/0/all/0/1\">Tat-Jun Chin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1\">Ian Reid</a>",
          "description": "Future Moon bases will likely be constructed using resources mined from the\nsurface of the Moon. The difficulty of maintaining a human workforce on the\nMoon and communications lag with Earth means that mining will need to be\nconducted using collaborative robots with a high degree of autonomy. In this\npaper, we describe our solution for Phase 2 of the NASA Space Robotics\nChallenge, which provided a simulated lunar environment in which teams were\ntasked to develop software systems to achieve autonomous collaborative robots\nfor mining on the Moon. Our 3rd place and innovation award winning solution\nshows how machine learning-enabled vision could alleviate major challenges\nposed by the lunar environment towards autonomous space mining, chiefly the\nlack of satellite positioning systems, hazardous terrain, and delicate robot\ninteractions. A robust multi-robot coordinator was also developed to achieve\nlong-term operation and effective collaboration between robots.",
          "link": "http://arxiv.org/abs/2109.12109",
          "publishedOn": "2022-04-14T00:58:52.113Z",
          "wordCount": null,
          "title": "Autonomy and Perception for Space Mining. (arXiv:2109.12109v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07365",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Siviero_E/0/1/0/all/0/1\">Emilia Siviero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chautru_E/0/1/0/all/0/1\">Emilie Chautru</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Clemencon_S/0/1/0/all/0/1\">Stephan Cl&#xe9;men&#xe7;on</a>",
          "description": "In the Big Data era, with the ubiquity of geolocation sensors in particular,\nmassive datasets exhibiting a possibly complex spatial dependence structure are\nbecoming increasingly available. In this context, the standard probabilistic\ntheory of statistical learning does not apply directly and guarantees of the\ngeneralization capacity of predictive rules learned from such data are left to\nestablish. We analyze here the simple Kriging task, the flagship problem in\nGeostatistics: the values of a square integrable random field $X=\\{X_s\\}_{s\\in\nS}$, $S\\subset \\mathbb{R}^2$, with unknown covariance structure are to be\npredicted with minimum quadratic risk, based upon observing a single\nrealization of the spatial process at a finite number of locations $s_1,\\;\n\\ldots,\\; s_n$ in $S$. Despite the connection of this minimization problem with\nkernel ridge regression, establishing the generalization capacity of empirical\nrisk minimizers is far from straightforward, due to the non i.i.d. nature of\nthe spatial data $X_{s_1},\\; \\ldots,\\; X_{s_n}$ involved. In this article,\nnonasymptotic bounds of order $O_{\\mathbb{P}}(1/n)$ are proved for the excess\nrisk of a plug-in predictive rule mimicking the true minimizer in the case of\nisotropic stationary Gaussian processes observed at locations forming a regular\ngrid. These theoretical results, as well as the role played by the technical\nconditions required to establish them, are illustrated by various numerical\nexperiments and hopefully pave the way for further developments in statistical\nlearning based on spatial data.",
          "link": "http://arxiv.org/abs/2202.07365",
          "publishedOn": "2022-04-14T00:58:52.113Z",
          "wordCount": null,
          "title": "A Statistical Learning View of Simple Kriging. (arXiv:2202.07365v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06264",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Levy_T/0/1/0/all/0/1\">Tomer Levy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Abramovich_F/0/1/0/all/0/1\">Felix Abramovich</a>",
          "description": "We consider high-dimensional multiclass classification by sparse multinomial\nlogistic regression. Unlike binary classification, in the multiclass setup one\ncan think about an entire spectrum of possible notions of sparsity associated\nwith different structural assumptions on the regression coefficients matrix. We\npropose a computationally feasible feature selection procedure based on\npenalized maximum likelihood with convex penalties capturing a specific type of\nsparsity at hand. In particular, we consider global sparsity, double row-wise\nsparsity, and low-rank sparsity, and show that with the properly chosen tuning\nparameters the derived plug-in classifiers attain the minimax generalization\nerror bounds (in terms of misclassification excess risk) within the\ncorresponding classes of multiclass sparse linear classifiers. The developed\napproach is general and can be adapted to other types of sparsity as well.",
          "link": "http://arxiv.org/abs/2204.06264",
          "publishedOn": "2022-04-14T00:58:52.112Z",
          "wordCount": null,
          "title": "Generalization Error Bounds for Multiclass Sparse Linear Classifiers. (arXiv:2204.06264v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cha_J/0/1/0/all/0/1\">Jaehoon Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiyagalingam_J/0/1/0/all/0/1\">Jeyan Thiyagalingam</a>",
          "description": "Noting the importance of factorizing (or disentangling) the latent space, we\npropose a novel, non-probabilistic disentangling framework for autoencoders,\nbased on the principles of symmetry transformations in group-theory. To the\nbest of our knowledge, this is the first deterministic model that is aiming to\nachieve disentanglement based on autoencoders without regularizers. The\nproposed model is compared to seven state-of-the-art generative models based on\nautoencoders and evaluated based on five supervised disentanglement metrics.\nThe experimental results show that the proposed model can have better\ndisentanglement when variances of each features are different. We believe that\nthis model leads to a new field for disentanglement learning based on\nautoencoders without regularizers.",
          "link": "http://arxiv.org/abs/2202.09926",
          "publishedOn": "2022-04-14T00:58:52.112Z",
          "wordCount": null,
          "title": "Disentangling Autoencoders (DAE). (arXiv:2202.09926v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mingshuo_N/0/1/0/all/0/1\">Nie Mingshuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dongming_C/0/1/0/all/0/1\">Chen Dongming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dongqi_W/0/1/0/all/0/1\">Wang Dongqi</a>",
          "description": "Graph mining tasks arise from many different application domains, ranging\nfrom social networks, transportation, E-commerce, etc., which have been\nreceiving great attention from the theoretical and algorithm design communities\nin recent years, and there has been some pioneering work using the hotly\nresearched reinforcement learning (RL) techniques to address graph data mining\ntasks. However, these graph mining algorithms and RL models are dispersed in\ndifferent research areas, which makes it hard to compare different algorithms\nwith each other. In this survey, we provide a comprehensive overview of RL\nmodels and graph mining and generalize these algorithms to Graph Reinforcement\nLearning (GRL) as a unified formulation. We further discuss the applications of\nGRL methods across various domains and summarize the method description,\nopen-source codes, and benchmark datasets of GRL methods. Finally, we propose\npossible important directions and challenges to be solved in the future. This\nis the latest work on a comprehensive survey of GRL literature, and this work\nprovides a global view for researchers as well as a learning resource for\nresearchers outside the domain. In addition, we create an online open-source\nfor both interested researchers who want to enter this rapidly developing\ndomain and experts who would like to compare GRL methods.",
          "link": "http://arxiv.org/abs/2204.06127",
          "publishedOn": "2022-04-14T00:58:52.109Z",
          "wordCount": null,
          "title": "Reinforcement Learning on Graph: A Survey. (arXiv:2204.06127v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06322",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hard_A/0/1/0/all/0/1\">Andrew Hard</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Partridge_K/0/1/0/all/0/1\">Kurt Partridge</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_N/0/1/0/all/0/1\">Neng Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Augenstein_S/0/1/0/all/0/1\">Sean Augenstein</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shah_A/0/1/0/all/0/1\">Aishanee Shah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Park_H/0/1/0/all/0/1\">Hyun Jin Park</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Park_A/0/1/0/all/0/1\">Alex Park</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ng_S/0/1/0/all/0/1\">Sara Ng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nguyen_J/0/1/0/all/0/1\">Jessica Nguyen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moreno_I/0/1/0/all/0/1\">Ignacio Lopez Moreno</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mathews_R/0/1/0/all/0/1\">Rajiv Mathews</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beaufays_F/0/1/0/all/0/1\">Fran&#xe7;oise Beaufays</a>",
          "description": "We trained a keyword spotting model using federated learning on real user\ndevices and observed significant improvements when the model was deployed for\ninference on phones. To compensate for data domains that are missing from\non-device training caches, we employed joint federated-centralized training.\nAnd to learn in the absence of curated labels on-device, we formulated a\nconfidence filtering strategy based on user-feedback signals for federated\ndistillation. These techniques created models that significantly improved\nquality metrics in offline evaluations and user-experience metrics in live A/B\nexperiments.",
          "link": "http://arxiv.org/abs/2204.06322",
          "publishedOn": "2022-04-14T00:58:52.109Z",
          "wordCount": null,
          "title": "Production federated keyword spotting via distillation, filtering, and joint federated-centralized training. (arXiv:2204.06322v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chun-Hung Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Di-Chun Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gau_R/0/1/0/all/0/1\">Rung-Hung Gau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Lu Wei</a>",
          "description": "Federated learning (FL) is a promising distributed learning technique\nparticularly suitable for wireless learning scenarios since it can accomplish a\nlearning task without raw data transportation so as to preserve data privacy\nand lower network resource consumption. However, current works on FL over\nwireless networks do not profoundly study the fundamental performance of FL\nover wireless networks that suffers from communication outage due to channel\nimpairment and network interference. To accurately exploit the performance of\nFL over wireless networks, this paper proposes a novel intermittent FL model\nover a cellular-connected unmanned aerial vehicle (UAV) network, which\ncharacterizes communication outage from UAV (clients) to their server and data\nheterogeneity among the datasets at UAVs. We propose an analytically tractable\nframework to derive the uplink outage probability and use it to devise a\nsimulation-based approach so as to evaluate the performance of the proposed\nintermittent FL model. Our findings reveal how the intermittent FL model is\nimpacted by uplink communication outage and UAV deployment. Extensive numerical\nsimulations are provided to show the consistency between the simulated and\nanalytical performances of the proposed intermittent FL model.",
          "link": "http://arxiv.org/abs/2110.07077",
          "publishedOn": "2022-04-14T00:58:52.109Z",
          "wordCount": null,
          "title": "Modeling and Analysis of Intermittent Federated Learning Over Cellular-Connected UAV Networks. (arXiv:2110.07077v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_W/0/1/0/all/0/1\">Weirui Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuexiang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1\">Liuyi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bolin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>",
          "description": "The incredible development of federated learning (FL) has benefited various\ntasks in the domains of computer vision and natural language processing, and\nthe existing frameworks such as TFF and FATE has made the deployment easy in\nreal-world applications. However, federated graph learning (FGL), even though\ngraph data are prevalent, has not been well supported due to its unique\ncharacteristics and requirements. The lack of FGL-related framework increases\nthe efforts for accomplishing reproducible research and deploying in real-world\napplications. Motivated by such strong demand, in this paper, we first discuss\nthe challenges in creating an easy-to-use FGL package and accordingly present\nour implemented package FederatedScope-GNN (FS-G), which provides (1) a unified\nview for modularizing and expressing FGL algorithms; (2) comprehensive DataZoo\nand ModelZoo for out-of-the-box FGL capability; (3) an efficient model\nauto-tuning component; and (4) off-the-shelf privacy attack and defense\nabilities. We validate the effectiveness of FS-G by conducting extensive\nexperiments, which simultaneously gains many valuable insights about FGL for\nthe community. Moreover, we employ FS-G to serve the FGL application in\nreal-world E-commerce scenarios, where the attained improvements indicate great\npotential business benefits. We publicly release FS-G, as submodules of\nFederatedScope, at https://github.com/alibaba/FederatedScope to promote FGL's\nresearch and enable broad applications that would otherwise be infeasible due\nto the lack of a dedicated package.",
          "link": "http://arxiv.org/abs/2204.05562",
          "publishedOn": "2022-04-14T00:58:52.109Z",
          "wordCount": null,
          "title": "FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient Package for Federated Graph Learning. (arXiv:2204.05562v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lerma_M/0/1/0/all/0/1\">Miguel Lerma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucas_M/0/1/0/all/0/1\">Mirtha Lucas</a>",
          "description": "We discuss a way to find a well behaved baseline for attribution methods that\nwork by feeding a neural network with a sequence of interpolated inputs between\ntwo given inputs. Then, we test it with our novel Riemann-Stieltjes Integrated\nGradient-weighted Class Activation Mapping (RSI-Grad-CAM) attribution method.",
          "link": "http://arxiv.org/abs/2204.06120",
          "publishedOn": "2022-04-14T00:58:52.108Z",
          "wordCount": null,
          "title": "Baseline Computation for Attribution Methods Based on Interpolated Inputs. (arXiv:2204.06120v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06242",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qoku_A/0/1/0/all/0/1\">Arber Qoku</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Buettner_F/0/1/0/all/0/1\">Florian Buettner</a>",
          "description": "Many real-world systems are described not only by data from a single source\nbut via multiple data views. For example, in genomic medicine, a patient can be\ndescribed by data from different molecular layers. This raises the need for\nmulti-view models that are able to disentangle variation within and across data\nviews in an interpretable manner. Latent variable models with structured\nsparsity are a commonly used tool to address this modeling task but\ninterpretability is cumbersome since it requires a direct inspection and\ninterpretation of each factor via a specialized domain expert. Here, we propose\nMuVI, a novel approach for domain-informed multi-view latent variable models,\nfacilitating the analysis of multi-view data in an inherently explainable\nmanner. We demonstrate that our model (i) is able to integrate noisy domain\nexpertise in form of feature sets, (ii) is robust to noise in the encoded\ndomain knowledge, (iii) results in identifiable factors and (iv) is able to\ninfer interpretable and biologically meaningful axes of variation in a\nreal-world multi-view dataset of cancer patients.",
          "link": "http://arxiv.org/abs/2204.06242",
          "publishedOn": "2022-04-14T00:58:52.108Z",
          "wordCount": null,
          "title": "Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity. (arXiv:2204.06242v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06150",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Horowitz_H/0/1/0/all/0/1\">Haim Horowitz</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Rao_P/0/1/0/all/0/1\">Pooja Rao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Radha_S/0/1/0/all/0/1\">Santosh Kumar Radha</a>",
          "description": "Synthetic data generation has proven to be a promising solution for\naddressing data availability issues in various domains. Even more challenging\nis the generation of synthetic time series data, where one has to preserve\ntemporal dynamics, i.e., the generated time series must respect the original\nrelationships between variables across time. Recently proposed techniques such\nas generative adversarial networks (GANs) and quantum-GANs lack the ability to\nattend to the time series specific temporal correlations adequately. We propose\nusing the inherent nature of quantum computers to simulate quantum dynamics as\na technique to encode such features. We start by assuming that a given time\nseries can be generated by a quantum process, after which we proceed to learn\nthat quantum process using quantum machine learning. We then use the learned\nmodel to generate out-of-sample time series and show that it captures unique\nand complex features of the learned time series. We also study the class of\ntime series that can be modeled using this technique. Finally, we\nexperimentally demonstrate the proposed algorithm on an 11-qubit trapped-ion\nquantum machine.",
          "link": "http://arxiv.org/abs/2204.06150",
          "publishedOn": "2022-04-14T00:58:52.104Z",
          "wordCount": null,
          "title": "A quantum generative model for multi-dimensional time series using Hamiltonian learning. (arXiv:2204.06150v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.01852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kojima_H/0/1/0/all/0/1\">Hiroki Kojima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikegami_T/0/1/0/all/0/1\">Takashi Ikegami</a>",
          "description": "We present a novel artificial cognitive mapping system using generative deep\nneural networks, called variational autoencoder/generative adversarial network\n(VAE/GAN), which can map input images to latent vectors and generate temporal\nsequences internally. The results show that the distance of the predicted image\nis reflected in the distance of the corresponding latent vector after training.\nThis indicates that the latent space is self-organized to reflect the proximity\nstructure of the dataset and may provide a mechanism through which many aspects\nof cognition are spatially represented. The present study allows the network to\ninternally generate temporal sequences that are analogous to the hippocampal\nreplay/pre-play ability, where VAE produces only near-accurate replays of past\nexperiences, but by introducing GANs, the generated sequences are coupled with\ninstability and novelty.",
          "link": "http://arxiv.org/abs/2102.01852",
          "publishedOn": "2022-04-14T00:58:52.104Z",
          "wordCount": null,
          "title": "Organization of a Latent Space structure in VAE/GAN trained by navigation data. (arXiv:2102.01852v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_L/0/1/0/all/0/1\">Leonardo F. R. Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mengwen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dreyer_M/0/1/0/all/0/1\">Markus Dreyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Despite recent improvements in abstractive summarization, most current\napproaches generate summaries that are not factually consistent with the source\ndocument, severely restricting their trust and usage in real-world\napplications. Recent works have shown promising improvements in factuality\nerror identification using text or dependency arc entailments; however, they do\nnot consider the entire semantic graph simultaneously. To this end, we propose\nFactGraph, a method that decomposes the document and the summary into\nstructured meaning representations (MR), which are more suitable for factuality\nevaluation. MRs describe core semantic concepts and their relations,\naggregating the main content in both document and summary in a canonical form,\nand reducing data sparsity. FactGraph encodes such graphs using a graph encoder\naugmented with structure-aware adapters to capture interactions among the\nconcepts based on the graph connectivity, along with text representations using\nan adapter-based text encoder. Experiments on different benchmarks for\nevaluating factuality show that FactGraph outperforms previous approaches by up\nto 15%. Furthermore, FactGraph improves performance on identifying content\nverifiability errors and better captures subsentence-level factual\ninconsistencies.",
          "link": "http://arxiv.org/abs/2204.06508",
          "publishedOn": "2022-04-14T00:58:52.093Z",
          "wordCount": null,
          "title": "FactGraph: Evaluating Factuality in Summarization with Semantic Graph Representations. (arXiv:2204.06508v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shaeri_M/0/1/0/all/0/1\">MohammadAli Shaeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afzal_A/0/1/0/all/0/1\">Arshia Afzal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoaran_M/0/1/0/all/0/1\">Mahsa Shoaran</a>",
          "description": "Neuroscience and neurotechnology are currently being revolutionized by\nartificial intelligence (AI) and machine learning. AI is widely used to study\nand interpret neural signals (analytical applications), assist people with\ndisabilities (prosthetic applications), and treat underlying neurological\nsymptoms (therapeutic applications). In this brief, we will review the emerging\nopportunities of on-chip AI for the next-generation implantable brain-machine\ninterfaces (BMIs), with a focus on state-of-the-art prosthetic BMIs. Major\ntechnological challenges for the effectiveness of AI models will be discussed.\nFinally, we will present algorithmic and IC design solutions to enable a new\ngeneration of AI-enhanced and high-channel-count BMIs.",
          "link": "http://arxiv.org/abs/2204.02362",
          "publishedOn": "2022-04-14T00:58:52.093Z",
          "wordCount": null,
          "title": "Challenges and Opportunities of Edge AI for Next-Generation Implantable BMIs. (arXiv:2204.02362v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Munoz_Cancino_R/0/1/0/all/0/1\">Ricardo Mu&#xf1;oz-Cancino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bravo_C/0/1/0/all/0/1\">Cristi&#xe1;n Bravo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_S/0/1/0/all/0/1\">Sebasti&#xe1;n A. R&#xed;os</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grana_M/0/1/0/all/0/1\">Manuel Gra&#xf1;a</a>",
          "description": "For more than a half-century, credit risk management has used credit scoring\nmodels in each of its well-defined stages to manage credit risk. Application\nscoring is used to decide whether to grant a credit or not, while behavioral\nscoring is used mainly for portfolio management and to take preventive actions\nin case of default signals. In both cases, network data has recently been shown\nto be valuable to increase the predictive power of these models, especially\nwhen the borrower's historical data is scarce or not available. This study aims\nto understand the creditworthiness assessment performance dynamics and how it\nis influenced by the credit history, repayment behavior, and social network\nfeatures. To accomplish this, we introduced a machine learning classification\nframework to analyze 97.000 individuals and companies from the moment they\nobtained their first loan to 12 months afterward. Our novel and massive dataset\nallow us to characterize each borrower according to their credit behavior, and\nsocial and economic relationships. Our research shows that borrowers' history\nincreases performance at a decreasing rate during the first six months and then\nstabilizes. The most notable effect on perfomance of social networks features\noccurs at loan application; in personal scoring, this effect prevails a few\nmonths, while in business scoring adds value throughout the study period. These\nfindings are of great value to improve credit risk management and optimize the\nuse of traditional information and alternative data sources.",
          "link": "http://arxiv.org/abs/2204.06122",
          "publishedOn": "2022-04-14T00:58:52.092Z",
          "wordCount": null,
          "title": "On the dynamics of credit history and social interaction features, and their impact on creditworthiness assessment performance. (arXiv:2204.06122v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ravenscroft_W/0/1/0/all/0/1\">William Ravenscroft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goetze_S/0/1/0/all/0/1\">Stefan Goetze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hain_T/0/1/0/all/0/1\">Thomas Hain</a>",
          "description": "Speech dereverberation is often an important requirement in robust speech\nprocessing tasks. Supervised deep learning (DL) models give state-of-the-art\nperformance for single-channel speech dereverberation. Temporal convolutional\nnetworks (TCNs) are commonly used for sequence modelling in speech enhancement\ntasks. A feature of TCNs is that they have a receptive field (RF) dependant on\nthe specific model configuration which determines the number of input frames\nthat can be observed to produce an individual output frame. It has been shown\nthat TCNs are capable of performing dereverberation of simulated speech data,\nhowever a thorough analysis, especially with focus on the RF is yet lacking in\nthe literature. This paper analyses dereverberation performance depending on\nthe model size and the RF of TCNs. Experiments using the WHAMR corpus which is\nextended to include room impulse responses (RIRs) with larger T60 values\ndemonstrate that a larger RF can have significant improvement in performance\nwhen training smaller TCN models. It is also demonstrated that TCNs benefit\nfrom a wider RF when dereverberating RIRs with larger RT60 values.",
          "link": "http://arxiv.org/abs/2204.06439",
          "publishedOn": "2022-04-14T00:58:52.092Z",
          "wordCount": null,
          "title": "Receptive Field Analysis of Temporal Convolutional Networks for Monaural Speech Dereverberation. (arXiv:2204.06439v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.07084",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Osa_T/0/1/0/all/0/1\">Takayuki Osa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tangkaratt_V/0/1/0/all/0/1\">Voot Tangkaratt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Reinforcement learning algorithms are typically limited to learning a single\nsolution for a specified task, even though diverse solutions often exist.\nRecent studies showed that learning a set of diverse solutions is beneficial\nbecause diversity enables robust few-shot adaptation. Although existing methods\nlearn diverse solutions by using the mutual information as unsupervised\nrewards, such an approach often suffers from the bias of the gradient estimator\ninduced by value function approximation. In this study, we propose a novel\nmethod that can learn diverse solutions without suffering the bias problem. In\nour method, a policy conditioned on a continuous or discrete latent variable is\ntrained by directly maximizing the variational lower bound of the mutual\ninformation, instead of using the mutual information as unsupervised rewards as\nin previous studies. Through extensive experiments on robot locomotion tasks,\nwe demonstrate that the proposed method successfully learns an infinite set of\ndiverse solutions by learning continuous latent variables, which is more\nchallenging than learning a finite number of solutions. Subsequently, we show\nthat our method enables more effective few-shot adaptation compared with\nexisting methods.",
          "link": "http://arxiv.org/abs/2103.07084",
          "publishedOn": "2022-04-14T00:58:52.091Z",
          "wordCount": null,
          "title": "Discovering Diverse Solutions in Deep Reinforcement Learning by Maximizing State-Action-Based Mutual Information. (arXiv:2103.07084v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06518",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Occhipinti_A/0/1/0/all/0/1\">Annalisa Occhipinti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_L/0/1/0/all/0/1\">Louis Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angione_C/0/1/0/all/0/1\">Claudio Angione</a>",
          "description": "Text-based communication is highly favoured as a communication method,\nespecially in business environments. As a result, it is often abused by sending\nmalicious messages, e.g., spam emails, to deceive users into relaying personal\ninformation, including online accounts credentials or banking details. For this\nreason, many machine learning methods for text classification have been\nproposed and incorporated into the services of most email providers. However,\noptimising text classification algorithms and finding the right tradeoff on\ntheir aggressiveness is still a major research problem.\n\nWe present an updated survey of 12 machine learning text classifiers applied\nto a public spam corpus. A new pipeline is proposed to optimise hyperparameter\nselection and improve the models' performance by applying specific methods\n(based on natural language processing) in the preprocessing stage.\n\nOur study aims to provide a new methodology to investigate and optimise the\neffect of different feature sizes and hyperparameters in machine learning\nclassifiers that are widely used in text classification problems. The\nclassifiers are tested and evaluated on different metrics including F-score\n(accuracy), precision, recall, and run time. By analysing all these aspects, we\nshow how the proposed pipeline can be used to achieve a good accuracy towards\nspam filtering on the Enron dataset, a widely used public email corpus.\nStatistical tests and explainability techniques are applied to provide a robust\nanalysis of the proposed pipeline and interpret the classification outcomes of\nthe 12 machine learning models, also identifying words that drive the\nclassification results. Our analysis shows that it is possible to identify an\neffective machine learning model to classify the Enron dataset with an F-score\nof 94%.",
          "link": "http://arxiv.org/abs/2204.06518",
          "publishedOn": "2022-04-14T00:58:52.090Z",
          "wordCount": null,
          "title": "A pipeline and comparative study of 12 machine learning models for text classification. (arXiv:2204.06518v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.10102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Renjue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Pengfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Cheng-Chao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Youcheng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1\">Bai Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>",
          "description": "To analyse local robustness properties of deep neural networks (DNNs), we\npresent a practical framework from a model learning perspective. Based on\nblack-box model learning with scenario optimisation, we abstract the local\nbehaviour of a DNN via an affine model with the probably approximately correct\n(PAC) guarantee. From the learned model, we can infer the corresponding\nPAC-model robustness property. The innovation of our work is the integration of\nmodel learning into PAC robustness analysis: that is, we construct a PAC\nguarantee on the model level instead of sample distribution, which induces a\nmore faithful and accurate robustness evaluation. This is in contrast to\nexisting statistical methods without model learning. We implement our method in\na prototypical tool named DeepPAC. As a black-box method, DeepPAC is scalable\nand efficient, especially when DNNs have complex structures or high-dimensional\ninputs. We extensively evaluate DeepPAC, with 4 baselines (using formal\nverification, statistical methods, testing and adversarial attack) and 20 DNN\nmodels across 3 datasets, including MNIST, CIFAR-10, and ImageNet. It is shown\nthat DeepPAC outperforms the state-of-the-art statistical method PROVERO, and\nit achieves more practical robustness analysis than the formal verification\ntool ERAN. Also, its results are consistent with existing DNN testing work like\nDeepGini.",
          "link": "http://arxiv.org/abs/2101.10102",
          "publishedOn": "2022-04-14T00:58:52.090Z",
          "wordCount": null,
          "title": "Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning. (arXiv:2101.10102v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.05955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vicente_Sola_A/0/1/0/all/0/1\">Alex Vicente-Sola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manna_D/0/1/0/all/0/1\">Davide L. Manna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirkland_P/0/1/0/all/0/1\">Paul Kirkland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caterina_G/0/1/0/all/0/1\">Gaetano Di Caterina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bihl_T/0/1/0/all/0/1\">Trevor Bihl</a>",
          "description": "Spiking neural networks (SNNs) have become an interesting alternative to\nconventional artificial neural networks (ANN) thanks to their temporal\nprocessing capabilities and energy efficient implementations in neuromorphic\nhardware. However the challenges involved in training SNNs have limited their\nperformance in terms of accuracy and thus their applications. Improving\nlearning algorithms and neural architectures for a more accurate feature\nextraction is therefore one of the current priorities in SNN research. In this\npaper we present a study on the key components of modern spiking architectures.\nWe empirically compare different techniques in image classification datasets\ntaken from the best performing networks. We design a spiking version of the\nsuccessful residual network architecture and provide an in-depth study on the\npossible implementations of spiking residual connections. Our results provide a\nstate of the art guide to SNN design, which allows to make informed choices\nwhen trying to build the optimal visual feature extractor. Finally, our network\noutperforms previous SNN architectures in CIFAR-10 (94.14%) and CIFAR-100\n(74.65%) datasets and matches the state of the art in DVS-CIFAR10 (72.98%),\nwith less parameters than the previous state of the art and without the need\nfor ANN-SNN conversion. Code available at\nhttps://github.com/VicenteAlex/Spiking_ResNet",
          "link": "http://arxiv.org/abs/2111.05955",
          "publishedOn": "2022-04-14T00:58:52.090Z",
          "wordCount": null,
          "title": "Keys to Accurate Feature Extraction Using Residual Spiking Neural Networks. (arXiv:2111.05955v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.10465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_W/0/1/0/all/0/1\">Wai Weng Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Layeghy_S/0/1/0/all/0/1\">Siamak Layeghy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portmann_M/0/1/0/all/0/1\">Marius Portmann</a>",
          "description": "Criminals have become increasingly experienced in using cryptocurrencies,\nsuch as Bitcoin, for money laundering. The use of cryptocurrencies can hide\ncriminal identities and transfer hundreds of millions of dollars of dirty funds\nthrough their criminal digital wallets. However, this is considered a paradox\nbecause cryptocurrencies are gold mines for open-source intelligence, allowing\nlaw enforcement agencies to have more power in conducting forensic analyses.\nThis paper proposed Inspection-L, a graph neural network (GNN) framework based\non self-supervised Deep Graph Infomax (DGI), with supervised learning\nalgorithms, namely Random Forest (RF) to detect illicit transactions for AML.\nTo the best of our knowledge, our proposal is the first of applying\nself-supervised GNNs to the problem of AML in Bitcoin. The proposed method has\nbeen evaluated on the Elliptic dataset and shows that our approach outperforms\nthe baseline in terms of key classification metrics, which demonstrates the\npotential of self-supervised GNN in cryptocurrency illicit transaction\ndetection.",
          "link": "http://arxiv.org/abs/2203.10465",
          "publishedOn": "2022-04-14T00:58:52.090Z",
          "wordCount": null,
          "title": "Inspection-L: A Self-Supervised GNN-Based Money Laundering Detection System for Bitcoin. (arXiv:2203.10465v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06348",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Poelking_C/0/1/0/all/0/1\">Carl Poelking</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chessari_G/0/1/0/all/0/1\">Gianni Chessari</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Murray_C/0/1/0/all/0/1\">Christopher W. Murray</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hall_R/0/1/0/all/0/1\">Richard J. Hall</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Colwell_L/0/1/0/all/0/1\">Lucy Colwell</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Verdonk_M/0/1/0/all/0/1\">Marcel Verdonk</a>",
          "description": "Machine learning (ML) is widely used in drug discovery to train models that\npredict protein-ligand binding. These models are of great value to medicinal\nchemists, in particular if they provide case-specific insight into the physical\ninteractions that drive the binding process. In this study we derive ML models\nfrom over 50 fragment-screening campaigns to introduce two important elements\nthat we believe are absent in most -- if not all -- ML studies of this type\nreported to date: First, alongside the observed hits we use to train our\nmodels, we incorporate true misses and show that these experimentally validated\nnegative data are of significant importance to the quality of the derived\nmodels. Second, we provide a physically interpretable and verifiable\nrepresentation of what the ML model considers important for successful binding.\nThis representation is derived from a straightforward attribution procedure\nthat explains the prediction in terms of the (inter-)action of chemical\nenvironments. Critically, we validate the attribution outcome on a large scale\nagainst prior annotations made independently by expert molecular modellers. We\nfind good agreement between the key molecular substructures proposed by the ML\nmodel and those assigned manually, even when the model's performance in\ndiscriminating hits from misses is far from perfect. By projecting the\nattribution onto predefined interaction prototypes (pharmacophores), we show\nthat ML allows us to formulate simple rules for what drives fragment binding\nagainst a target automatically from screening data.",
          "link": "http://arxiv.org/abs/2204.06348",
          "publishedOn": "2022-04-14T00:58:52.089Z",
          "wordCount": null,
          "title": "Meaningful machine learning models and machine-learned pharmacophores from fragment screening campaigns. (arXiv:2204.06348v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06375",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Blanke_M/0/1/0/all/0/1\">Matthieu Blanke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lelarge_M/0/1/0/all/0/1\">Marc Lelarge</a>",
          "description": "This work addresses the problem of exploration in an unknown environment. For\nlinear dynamical systems, we use an experimental design framework and introduce\nan online greedy policy where the control maximizes the information of the next\nstep. In a setting with a limited number of experimental trials, our algorithm\nhas low complexity and shows experimentally competitive performances compared\nto more elaborate gradient-based methods.",
          "link": "http://arxiv.org/abs/2204.06375",
          "publishedOn": "2022-04-14T00:58:52.089Z",
          "wordCount": null,
          "title": "Online greedy identification of linear dynamical systems. (arXiv:2204.06375v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.05192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goktas_D/0/1/0/all/0/1\">Denizalp Goktas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenwald_A/0/1/0/all/0/1\">Amy Greenwald</a>",
          "description": "Min-max optimization problems (i.e., min-max games) have been attracting a\ngreat deal of attention because of their applicability to a wide range of\nmachine learning problems. Although significant progress has been made\nrecently, the literature to date has focused on games with independent strategy\nsets; little is known about solving games with dependent strategy sets, which\ncan be characterized as min-max Stackelberg games. We introduce two first-order\nmethods that solve a large class of convex-concave min-max Stackelberg games,\nand show that our methods converge in polynomial time. Min-max Stackelberg\ngames were first studied by Wald, under the posthumous name of Wald's maximin\nmodel, a variant of which is the main paradigm used in robust optimization,\nwhich means that our methods can likewise solve many convex robust optimization\nproblems. We observe that the computation of competitive equilibria in Fisher\nmarkets also comprises a min-max Stackelberg game. Further, we demonstrate the\nefficacy and efficiency of our algorithms in practice by computing competitive\nequilibria in Fisher markets with varying utility structures. Our experiments\nsuggest potential ways to extend our theoretical results, by demonstrating how\ndifferent smoothness properties can affect the convergence rate of our\nalgorithms.",
          "link": "http://arxiv.org/abs/2110.05192",
          "publishedOn": "2022-04-14T00:58:52.089Z",
          "wordCount": null,
          "title": "Convex-Concave Min-Max Stackelberg Games. (arXiv:2110.05192v4 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Imbiriba_T/0/1/0/all/0/1\">Tales Imbiriba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demirkaya_A/0/1/0/all/0/1\">Ahmet Demirkaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunik_J/0/1/0/all/0/1\">Jind&#x159;ich Dun&#xed;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Straka_O/0/1/0/all/0/1\">Ond&#x159;ej Straka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogmus_D/0/1/0/all/0/1\">Deniz Erdo&#x11f;mu&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Closas_P/0/1/0/all/0/1\">Pau Closas</a>",
          "description": "In this paper we present a hybrid neural network augmented physics-based\nmodeling (APBM) framework for Bayesian nonlinear latent space estimation. The\nproposed APBM strategy allows for model adaptation when new operation\nconditions come into play or the physics-based model is insufficient (or\nincomplete) to properly describe the latent phenomenon. One advantage of the\nAPBMs and our estimation procedure is the capability of maintaining the\nphysical interpretability of estimated states. Furthermore, we propose a\nconstraint filtering approach to control the neural network contributions to\nthe overall model. We also exploit assumed density filtering techniques and\ncubature integration rules to present a flexible estimation strategy that can\neasily deal with nonlinear models and high-dimensional latent spaces. Finally,\nwe demonstrate the efficacy of our methodology by leveraging a target tracking\nscenario with nonlinear and incomplete measurement and acceleration models,\nrespectively.",
          "link": "http://arxiv.org/abs/2204.06471",
          "publishedOn": "2022-04-14T00:58:52.041Z",
          "wordCount": null,
          "title": "Hybrid Neural Network Augmented Physics-based Models for Nonlinear Filtering. (arXiv:2204.06471v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06274",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ribeiro_A/0/1/0/all/0/1\">Ant&#xf4;nio H. Ribeiro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1\">Thomas B. Sch&#xf6;n</a>",
          "description": "As machine learning models start to be used in critical applications, their\nvulnerabilities and brittleness become a pressing concern. Adversarial attacks\nare a popular framework for studying these vulnerabilities. In this work, we\nstudy the error of linear regression in the face of adversarial attacks. We\nprovide bounds of the error in terms of the traditional risk and the parameter\nnorm and show how these bounds can be leveraged and make it possible to use\nanalysis from non-adversarial setups to study the adversarial risk. The\nusefulness of these results is illustrated by shedding light on whether or not\noverparameterized linear models can be adversarially robust. We show that\nadding features to linear models might be either a source of additional\nrobustness or brittleness. We show that these differences appear due to scaling\nand how the $\\ell_1$ and $\\ell_2$ norms of random projections concentrate. We\nalso show how the reformulation we propose allows for solving adversarial\ntraining as a convex optimization problem. This is then used as a tool to study\nhow adversarial training and other regularization methods might affect the\nrobustness of the estimated models.",
          "link": "http://arxiv.org/abs/2204.06274",
          "publishedOn": "2022-04-14T00:58:52.039Z",
          "wordCount": null,
          "title": "Overparameterized Linear Regression under Adversarial Attacks. (arXiv:2204.06274v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lecerf_U/0/1/0/all/0/1\">Ugo Lecerf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yemdji_Tchassi_C/0/1/0/all/0/1\">Christelle Yemdji-Tchassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michiardi_P/0/1/0/all/0/1\">Pietro Michiardi</a>",
          "description": "When learning to act in a stochastic, partially observable environment, an\nintelligent agent should be prepared to anticipate a change in its belief of\nthe environment state, and be capable of adapting its actions on-the-fly to\nchanging conditions. As humans, we are able to form contingency plans when\nlearning a task with the explicit aim of being able to correct errors in the\ninitial control, and hence prove useful if ever there is a sudden change in our\nperception of the environment which requires immediate corrective action. This\nis especially the case for autonomous vehicles (AVs) navigating real-world\nsituations where safety is paramount, and a strong ability to react to a\nchanging belief about the environment is truly needed.\n\nIn this paper we explore an end-to-end approach, from training to execution,\nfor learning robust contingency plans and combining them with a hierarchical\nplanner to obtain a robust agent policy in an autonomous navigation task where\nother vehicles' behaviours are unknown, and the agent's belief about these\nbehaviours is subject to sudden, last-second change. We show that our approach\nresults in robust, safe behaviour in a partially observable, stochastic\nenvironment, generalizing well over environment dynamics not seen during\ntraining.",
          "link": "http://arxiv.org/abs/2204.06509",
          "publishedOn": "2022-04-14T00:58:52.037Z",
          "wordCount": null,
          "title": "Safer Autonomous Driving in a Stochastic, Partially-Observable Environment by Hierarchical Contingency Planning. (arXiv:2204.06509v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06064",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dreifuerst_R/0/1/0/all/0/1\">Ryan M. Dreifuerst</a>, <a href=\"http://arxiv.org/find/eess/1/au:+jr%2E_R/0/1/0/all/0/1\">Robert W. Heath jr.</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yazdan_A/0/1/0/all/0/1\">Ali Yazdan</a>",
          "description": "Beam codebooks are a new feature of massive multiple-input multiple-output\n(M-MIMO) in 5G new radio (NR). Codebooks comprised of beamforming vectors are\nused to transmit reference signals and obtain limited channel state information\n(CSI) from receivers via the codeword index. This enables large arrays that\ncannot otherwise obtain sufficient CSI. The performance, however, is limited by\nthe codebook design. In this paper, we show that machine learning can be used\nto train site-specific codebooks for initial access. We design a neural network\nbased on an autoencoder architecture that uses a beamspace observation in\ncombination with RF environment characteristics to improve the synchronization\nsignal (SS) burst codebook. We test our algorithm using a flexible dataset of\nchannels generated from QuaDRiGa. The results show that our model outperforms\nthe industry standard (DFT beams) and approaches the optimal performance\n(perfect CSI and singular value decomposition (SVD)-based beamforming), using\nonly a few bits of feedback.",
          "link": "http://arxiv.org/abs/2204.06064",
          "publishedOn": "2022-04-14T00:58:52.035Z",
          "wordCount": null,
          "title": "Massive MIMO Beam Management in Sub-6 GHz 5G NR. (arXiv:2204.06064v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dandi_Y/0/1/0/all/0/1\">Yatin Dandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koloskova_A/0/1/0/all/0/1\">Anastasia Koloskova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1\">Sebastian U. Stich</a>",
          "description": "Decentralized learning provides an effective framework to train machine\nlearning models with data distributed over arbitrary communication graphs.\nHowever, most existing approaches toward decentralized learning disregard the\ninteraction between data heterogeneity and graph topology. In this paper, we\ncharacterize the dependence of convergence on the relationship between the\nmixing weights of the graph and the data heterogeneity across nodes. We propose\na metric that quantifies the ability of a graph to mix the current gradients.\nWe further prove that the metric controls the convergence rate, particularly in\nsettings where the heterogeneity across nodes dominates the stochasticity\nbetween updates for a given node. Motivated by our analysis, we propose an\napproach that periodically and efficiently optimizes the metric using standard\nconvex constrained optimization and sketching techniques. Through comprehensive\nexperiments on standard computer vision and NLP benchmarks, we show that our\napproach leads to improvement in test performance for a wide range of tasks.",
          "link": "http://arxiv.org/abs/2204.06477",
          "publishedOn": "2022-04-14T00:58:52.035Z",
          "wordCount": null,
          "title": "Data-heterogeneity-aware Mixing for Decentralized Learning. (arXiv:2204.06477v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neumayer_S/0/1/0/all/0/1\">Sebastian Neumayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goujon_A/0/1/0/all/0/1\">Alexis Goujon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohra_P/0/1/0/all/0/1\">Pakshal Bohra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unser_M/0/1/0/all/0/1\">Michael Unser</a>",
          "description": "Lipschitz-constrained neural networks have many applications in machine\nlearning. Since designing and training expressive Lipschitz-constrained\nnetworks is very challenging, there is a need for improved methods and a better\ntheoretical understanding. Unfortunately, it turns out that ReLU networks have\nprovable disadvantages in this setting. Hence, we propose to use learnable\nspline activation functions with at least 3 linear regions instead. We prove\nthat this choice is optimal among all component-wise $1$-Lipschitz activation\nfunctions in the sense that no other weight constrained architecture can\napproximate a larger class of functions. Additionally, this choice is at least\nas expressive as the recently introduced non component-wise Groupsort\nactivation function for spectral-norm-constrained weights. Previously published\nnumerical results support our theoretical findings.",
          "link": "http://arxiv.org/abs/2204.06233",
          "publishedOn": "2022-04-14T00:58:52.034Z",
          "wordCount": null,
          "title": "Approximation of Lipschitz Functions using Deep Spline Neural Networks. (arXiv:2204.06233v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yiyou Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1\">Yifei Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaojin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yixuan Li</a>",
          "description": "Out-of-distribution (OOD) detection is a critical task for deploying machine\nlearning models in the open world. Distance-based methods have demonstrated\npromise, where testing samples are detected as OOD if they are relatively far\naway from in-distribution (ID) data. However, prior methods impose a strong\ndistributional assumption of the underlying feature space, which may not always\nhold. In this paper, we explore the efficacy of non-parametric nearest-neighbor\ndistance for OOD detection, which has been largely overlooked in the\nliterature. Unlike prior works, our method does not impose any distributional\nassumption, hence providing stronger flexibility and generality. We demonstrate\nthe effectiveness of nearest-neighbor-based OOD detection on several benchmarks\nand establish superior performance. Under the same model trained on\nImageNet-1k, our method substantially reduces the false positive rate\n(FPR@TPR95) by 24.77% compared to a strong baseline SSD+, which uses a\nparametric approach Mahalanobis distance in detection.",
          "link": "http://arxiv.org/abs/2204.06507",
          "publishedOn": "2022-04-14T00:58:52.034Z",
          "wordCount": null,
          "title": "Out-of-distribution Detection with Deep Nearest Neighbors. (arXiv:2204.06507v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannan_H/0/1/0/all/0/1\">Harish Kannan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cloninger_A/0/1/0/all/0/1\">Alexander Cloninger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saab_R/0/1/0/all/0/1\">Rayan Saab</a>",
          "description": "We propose the use of low bit-depth Sigma-Delta and distributed noise-shaping\nmethods for quantizing the Random Fourier features (RFFs) associated with\nshift-invariant kernels. We prove that our quantized RFFs -- even in the case\nof $1$-bit quantization -- allow a high accuracy approximation of the\nunderlying kernels, and the approximation error decays at least polynomially\nfast as the dimension of the RFFs increases. We also show that the quantized\nRFFs can be further compressed, yielding an excellent trade-off between memory\nuse and accuracy. Namely, the approximation error now decays exponentially as a\nfunction of the bits used. Moreover, we empirically show by testing the\nperformance of our methods on several machine learning tasks that our method\ncompares favorably to other state of the art quantization methods in this\ncontext.",
          "link": "http://arxiv.org/abs/2106.02614",
          "publishedOn": "2022-04-14T00:58:52.034Z",
          "wordCount": null,
          "title": "Sigma-Delta and Distributed Noise-Shaping Quantization Methods for Random Fourier Features. (arXiv:2106.02614v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07284",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuli_S/0/1/0/all/0/1\">Shreshth Tuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casale_G/0/1/0/all/0/1\">Giuliano Casale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jennings_N/0/1/0/all/0/1\">Nicholas R. Jennings</a>",
          "description": "Efficient anomaly detection and diagnosis in multivariate time-series data is\nof great importance for modern industrial applications. However, building a\nsystem that is able to quickly and accurately pinpoint anomalous observations\nis a challenging problem. This is due to the lack of anomaly labels, high data\nvolatility and the demands of ultra-low inference times in modern applications.\nDespite the recent developments of deep learning approaches for anomaly\ndetection, only a few of them can address all of these challenges. In this\npaper, we propose TranAD, a deep transformer network based anomaly detection\nand diagnosis model which uses attention-based sequence encoders to swiftly\nperform inference with the knowledge of the broader temporal trends in the\ndata. TranAD uses focus score-based self-conditioning to enable robust\nmulti-modal feature extraction and adversarial training to gain stability.\nAdditionally, model-agnostic meta learning (MAML) allows us to train the model\nusing limited data. Extensive empirical studies on six publicly available\ndatasets demonstrate that TranAD can outperform state-of-the-art baseline\nmethods in detection and diagnosis performance with data and time-efficient\ntraining. Specifically, TranAD increases F1 scores by up to 17%, reducing\ntraining times by up to 99% compared to the baselines.",
          "link": "http://arxiv.org/abs/2201.07284",
          "publishedOn": "2022-04-14T00:58:52.034Z",
          "wordCount": null,
          "title": "TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate Time Series Data. (arXiv:2201.07284v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.04301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhewei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenwen Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Linyue Zhou</a>",
          "description": "Intrusion detection has been a key topic in the field of cyber security, and\nthe common network threats nowadays have the characteristics of varieties and\nvariation. Considering the serious imbalance of intrusion detection datasets\nwill result in low classification performance on attack behaviors of small\nsample size and difficulty to detect network attacks accurately and\nefficiently, using Adaptive Synthetic Sampling (ADASYN) method to balance\ndatasets was proposed in this paper. In addition, Random Forest algorithm was\nused to train intrusion detection classifiers. Through the comparative\nexperiment of Intrusion detection on CICIDS 2017 dataset, it is found that\nADASYN with Random Forest performs better. Based on the experimental results,\nthe improvement of precision, recall, F1 scores and AUC values after ADASYN is\nthen analyzed. Experiments show that the proposed method can be applied to\nintrusion detection with large data, and can effectively improve the\nclassification accuracy of network attack behaviors. Compared with traditional\nmachine learning models, it has better performance, generalization ability and\nrobustness.",
          "link": "http://arxiv.org/abs/2105.04301",
          "publishedOn": "2022-04-14T00:58:52.033Z",
          "wordCount": null,
          "title": "ADASYN-Random Forest Based Intrusion Detection Model. (arXiv:2105.04301v5 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.06054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Mingfei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devlin_S/0/1/0/all/0/1\">Sam Devlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "Sample efficiency is crucial for imitation learning methods to be applicable\nin real-world applications. Many studies improve sample efficiency by extending\nadversarial imitation to be off-policy regardless of the fact that these\noff-policy extensions could either change the original objective or involve\ncomplicated optimization. We revisit the foundation of adversarial imitation\nand propose an off-policy sample efficient approach that requires no\nadversarial training or min-max optimization. Our formulation capitalizes on\ntwo key insights: (1) the similarity between the Bellman equation and the\nstationary state-action distribution equation allows us to derive a novel\ntemporal difference (TD) learning approach; and (2) the use of a deterministic\npolicy simplifies the TD learning. Combined, these insights yield a practical\nalgorithm, Deterministic and Discriminative Imitation (D2-Imitation), which\noperates by first partitioning samples into two replay buffers and then\nlearning a deterministic policy via off-policy reinforcement learning. Our\nempirical results show that D2-Imitation is effective in achieving good sample\nefficiency, outperforming several off-policy extension approaches of\nadversarial imitation on many control tasks.",
          "link": "http://arxiv.org/abs/2112.06054",
          "publishedOn": "2022-04-14T00:58:52.033Z",
          "wordCount": null,
          "title": "Deterministic and Discriminative Imitation (D2-Imitation): Revisiting Adversarial Imitation for Sample Efficiency. (arXiv:2112.06054v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Visani_G/0/1/0/all/0/1\">Giorgio Visani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graffi_G/0/1/0/all/0/1\">Giacomo Graffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfero_M/0/1/0/all/0/1\">Mattia Alfero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagli_E/0/1/0/all/0/1\">Enrico Bagli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Capuzzo_D/0/1/0/all/0/1\">Davide Capuzzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chesani_F/0/1/0/all/0/1\">Federico Chesani</a>",
          "description": "The switch from a Model-Centric to a Data-Centric mindset is putting emphasis\non data and its quality rather than algorithms, bringing forward new\nchallenges. In particular, the sensitive nature of the information in highly\nregulated scenarios needs to be accounted for. Specific approaches to address\nthe privacy issue have been developed, as Privacy Enhancing Technologies.\nHowever, they frequently cause loss of information, putting forward a crucial\ntrade-off among data quality and privacy. A clever way to bypass such a\nconundrum relies on Synthetic Data: data obtained from a generative process,\nlearning the real data properties. Both Academia and Industry realized the\nimportance of evaluating synthetic data quality: without all-round reliable\nmetrics, the innovative data generation task has no proper objective function\nto maximize. Despite that, the topic remains under-explored. For this reason,\nwe systematically catalog the important traits of synthetic data quality and\nprivacy, and devise a specific methodology to test them. The result is DAISYnt\n(aDoption of Artificial Intelligence SYnthesis): a comprehensive suite of\nadvanced tests, which sets a de facto standard for synthetic data evaluation.\nAs a practical use-case, a variety of generative algorithms have been trained\non real-world Credit Bureau Data. The best model has been assessed, using\nDAISYnt on the different synthetic replicas. Further potential uses, among\nothers, entail auditing and fine-tuning of generative models or ensuring high\nquality of a given synthetic dataset. From a prescriptive viewpoint,\neventually, DAISYnt may pave the way to synthetic data adoption in highly\nregulated domains, ranging from Finance to Healthcare, through Insurance and\nEducation.",
          "link": "http://arxiv.org/abs/2204.06297",
          "publishedOn": "2022-04-14T00:58:52.029Z",
          "wordCount": null,
          "title": "Enabling Synthetic Data adoption in regulated domains. (arXiv:2204.06297v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_H/0/1/0/all/0/1\">Haoyu Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1\">Nianzu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_D/0/1/0/all/0/1\">Daiyue Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jianping Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaokang Yang</a>",
          "description": "User interests are usually dynamic in the real world, which poses both\ntheoretical and practical challenges for learning accurate preferences from\nrich behavior data. Among existing user behavior modeling solutions, attention\nnetworks are widely adopted for its effectiveness and relative simplicity.\nDespite being extensively studied, existing attentions still suffer from two\nlimitations: i) conventional attentions mainly take into account the spatial\ncorrelation between user behaviors, regardless the distance between those\nbehaviors in the continuous time space; and ii) these attentions mostly provide\na dense and undistinguished distribution over all past behaviors then\nattentively encode them into the output latent representations. This is however\nnot suitable in practical scenarios where a user's future actions are relevant\nto a small subset of her/his historical behaviors. In this paper, we propose a\nnovel attention network, named self-modulating attention, that models the\ncomplex and non-linearly evolving dynamic user preferences. We empirically\ndemonstrate the effectiveness of our method on top-N sequential recommendation\ntasks, and the results on three large-scale real-world datasets show that our\nmodel can achieve state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2204.06517",
          "publishedOn": "2022-04-14T00:58:52.023Z",
          "wordCount": null,
          "title": "Learning Self-Modulating Attention in Continuous Time Space with Applications to Sequential Recommendation. (arXiv:2204.06517v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cunha_B/0/1/0/all/0/1\">Barbara Cunha</a> (LTDS), <a href=\"http://arxiv.org/find/cs/1/au:+Droz_C/0/1/0/all/0/1\">Christophe Droz</a> (I4S), <a href=\"http://arxiv.org/find/cs/1/au:+Zine_A/0/1/0/all/0/1\">Abdelmalek Zine</a> (ICJ), <a href=\"http://arxiv.org/find/cs/1/au:+Foulard_S/0/1/0/all/0/1\">St&#xe9;phane Foulard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichchou_M/0/1/0/all/0/1\">Mohamed Ichchou</a> (LTDS)",
          "description": "The use of Machine Learning (ML) has rapidly spread across several fields,\nhaving encountered many applications in Structural Dynamics and Vibroacoustic\n(SD\\&V). The increasing capabilities of ML to unveil insights from data, driven\nby unprecedented data availability, algorithms advances and computational\npower, enhance decision making, uncertainty handling, patterns recognition and\nreal-time assessments. Three main applications in SD\\&V have taken advantage of\nthese benefits. In Structural Health Monitoring, ML detection and prognosis\nlead to safe operation and optimized maintenance schedules. System\nidentification and control design are leveraged by ML techniques in Active\nNoise Control and Active Vibration Control. Finally, the so-called ML-based\nsurrogate models provide fast alternatives to costly simulations, enabling\nrobust and optimized product design. Despite the many works in the area, they\nhave not been reviewed and analyzed. Therefore, to keep track and understand\nthis ongoing integration of fields, this paper presents a survey of ML\napplications in SD\\&V analyses, shedding light on the current state of\nimplementation and emerging opportunities. The main methodologies, advantages,\nlimitations, and recommendations based on scientific knowledge were identified\nfor each of the three applications. Moreover, the paper considers the role of\nDigital Twins and Physics Guided ML to overcome current challenges and power\nfuture research progress. As a result, the survey provides a broad overview of\nthe present landscape of ML applied in SD\\&V and guides the reader to an\nadvanced understanding of progress and prospects in the field.",
          "link": "http://arxiv.org/abs/2204.06362",
          "publishedOn": "2022-04-14T00:58:52.021Z",
          "wordCount": null,
          "title": "A Review of Machine Learning Methods Applied to Structural Dynamics and Vibroacoustic. (arXiv:2204.06362v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06062",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Grigsby_J/0/1/0/all/0/1\">J. Elisenda Grigsby</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lindsey_K/0/1/0/all/0/1\">Kathryn Lindsey</a>, <a href=\"http://arxiv.org/find/math/1/au:+Masden_M/0/1/0/all/0/1\">Marissa Masden</a>",
          "description": "We apply a generalized piecewise-linear (PL) version of Morse theory due to\nGrunert-Kuhnel-Rote to define and study new local and global notions of\ntopological complexity for fully-connected feedforward ReLU neural network\nfunctions, F: R^n -> R. Along the way, we show how to construct, for each such\nF, a canonical polytopal complex K(F) and a deformation retract of the domain\nonto K(F), yielding a convenient compact model for performing calculations. We\nalso give a combinatorial description of local complexity for depth 2 networks,\nand a construction showing that local complexity can be arbitrarily high.",
          "link": "http://arxiv.org/abs/2204.06062",
          "publishedOn": "2022-04-14T00:58:52.020Z",
          "wordCount": null,
          "title": "Local and global topological complexity measures OF ReLU neural network functions. (arXiv:2204.06062v1 [math.AT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.01481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tailor_S/0/1/0/all/0/1\">Shyam A. Tailor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opolka_F/0/1/0/all/0/1\">Felix L. Opolka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1\">Nicholas D. Lane</a>",
          "description": "Common wisdom in the graph neural network (GNN) community dictates that\nanisotropic models -- in which messages sent between nodes are a function of\nboth the source and target node -- are required to achieve state-of-the-art\nperformance. Benchmarks to date have demonstrated that these models perform\nbetter than comparable isotropic models -- where messages are a function of the\nsource node only. In this work we provide empirical evidence challenging this\nnarrative: we propose an isotropic GNN, which we call Efficient Graph\nConvolution (EGC), that consistently outperforms comparable anisotropic models,\nincluding the popular GAT or PNA architectures by using spatially-varying\nadaptive filters. In addition to raising important questions for the GNN\ncommunity, our work has significant real-world implications for efficiency. EGC\nachieves higher model accuracy, with lower memory consumption and latency,\nalong with characteristics suited to accelerator implementation, while being a\ndrop-in replacement for existing architectures. As an isotropic model, it\nrequires memory proportional to the number of vertices in the graph\n($\\mathcal{O}(V)$); in contrast, anisotropic models require memory proportional\nto the number of edges ($\\mathcal{O}(E)$). We demonstrate that EGC outperforms\nexisting approaches across 6 large and diverse benchmark datasets, and conclude\nby discussing questions that our work raise for the community going forward.\nCode and pretrained models for our experiments are provided at\nhttps://github.com/shyam196/egc.",
          "link": "http://arxiv.org/abs/2104.01481",
          "publishedOn": "2022-04-14T00:58:51.988Z",
          "wordCount": null,
          "title": "Do We Need Anisotropic Graph Neural Networks?. (arXiv:2104.01481v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aminpour_M/0/1/0/all/0/1\">Mohammad Aminpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alaie_R/0/1/0/all/0/1\">Reza Alaie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kardani_N/0/1/0/all/0/1\">Navid Kardani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moridpour_S/0/1/0/all/0/1\">Sara Moridpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nazem_M/0/1/0/all/0/1\">Majidreza Nazem</a>",
          "description": "Random field Monte Carlo (MC) reliability analysis is a robust stochastic\nmethod to determine the probability of failure. This method, however, requires\na large number of numerical simulations demanding high computational costs.\nThis paper explores the efficiency of different machine learning (ML)\nalgorithms used as surrogate models trained on a limited number of random field\nslope stability simulations in predicting the results of large datasets. The MC\ndata in this paper require only the examination of failure or non-failure,\ncircumventing the time-consuming calculation of factors of safety. An extensive\ndataset is generated, consisting of 120,000 finite difference MC slope\nstability simulations incorporating different levels of soil heterogeneity and\nanisotropy. The Bagging Ensemble, Random Forest and Support Vector classifiers\nare found to be the superior models for this problem amongst 9 different models\nand ensemble classifiers. Trained only on 0.47% of data (500 samples), the ML\nmodel can classify the entire 120,000 samples with an accuracy of %85 and AUC\nscore of %91. The performance of ML methods in classifying the random field\nslope stability results generally reduces with higher anisotropy and\nheterogeneity of soil. The ML assisted MC reliability analysis proves a robust\nstochastic method where errors in the predicted probability of failure using %5\nof MC data is only %0.46 in average. The approach reduced the computational\ntime from 306 days to less than 6 hours.",
          "link": "http://arxiv.org/abs/2204.06097",
          "publishedOn": "2022-04-14T00:58:51.987Z",
          "wordCount": null,
          "title": "Slope stability predictions on spatially variable random fields using machine learning surrogate models. (arXiv:2204.06097v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.03349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wirth_E/0/1/0/all/0/1\">E. Wirth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pokutta_S/0/1/0/all/0/1\">S. Pokutta</a>",
          "description": "The vanishing ideal of a set of points $X\\subseteq \\mathbb{R}^n$ is the set\nof polynomials that evaluate to $0$ over all points $\\mathbf{x} \\in X$ and\nadmits an efficient representation by a finite set of polynomials called\ngenerators. To accommodate the noise in the data set, we introduce the\nConditional Gradients Approximately Vanishing Ideal algorithm (CGAVI) for the\nconstruction of the set of generators of the approximately vanishing ideal. The\nconstructed set of generators captures polynomial structures in data and gives\nrise to a feature map that can, for example, be used in combination with a\nlinear classifier for supervised learning. In CGAVI, we construct the set of\ngenerators by solving specific instances of (constrained) convex optimization\nproblems with the Pairwise Frank-Wolfe algorithm (PFW). Among other things, the\nconstructed generators inherit the LASSO generalization bound and not only\nvanish on the training but also on out-sample data. Moreover, CGAVI admits a\ncompact representation of the approximately vanishing ideal by constructing few\ngenerators with sparse coefficient vectors.",
          "link": "http://arxiv.org/abs/2202.03349",
          "publishedOn": "2022-04-14T00:58:51.986Z",
          "wordCount": null,
          "title": "Conditional Gradients for the Approximately Vanishing Ideal. (arXiv:2202.03349v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05522",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lin_B/0/1/0/all/0/1\">Baihan Lin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cecchi_G/0/1/0/all/0/1\">Guillermo Cecchi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bouneffouf_D/0/1/0/all/0/1\">Djallel Bouneffouf</a>",
          "description": "The therapeutic working alliance is an important predictor of the outcome of\nthe psychotherapy treatment. In practice, the working alliance is estimated\nfrom a set of scoring questionnaires in an inventory that both the patient and\nthe therapists fill out. In this work, we propose an analytical framework of\ndirectly inferring the therapeutic working alliance from the natural language\nwithin the psychotherapy sessions in a turn-level resolution with deep\nembeddings such as the Doc2Vec and SentenceBERT models. The transcript of each\npsychotherapy session can be transcribed and generated in real-time from the\nsession speech recordings, and these embedded dialogues are compared with the\ndistributed representations of the statements in the working alliance\ninventory. We demonstrate, in a real-world dataset with over 950 sessions of\npsychotherapy treatments in anxiety, depression, schizophrenia and suicidal\npatients, the effectiveness of this method in mapping out trajectories of\npatient-therapist alignment and the interpretability that can offer insights in\nclinical psychiatry. We believe such a framework can be provide timely feedback\nto the therapist regarding the quality of the conversation in interview\nsessions.",
          "link": "http://arxiv.org/abs/2204.05522",
          "publishedOn": "2022-04-14T00:58:51.986Z",
          "wordCount": null,
          "title": "Deep Annotation of Therapeutic Working Alliance in Psychotherapy. (arXiv:2204.05522v1 [q-bio.NC] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Peiyan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1\">Qi Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bingguang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1\">Shiqi Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Rongchan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhi-Ming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Stochastic partial differential equations (SPDEs) are significant tools for\nmodeling dynamics in many areas including atmospheric sciences and physics.\nNeural Operators, generations of neural networks with capability of learning\nmaps between infinite-dimensional spaces, are strong tools for solving\nparametric PDEs. However, they lack the ability to modeling SPDEs which usually\nhave poor regularity due to the driving noise. As the theory of regularity\nstructure has achieved great successes in analyzing SPDEs and provides the\nconcept model feature vectors that well-approximate SPDEs' solutions, we\npropose the Neural Operator with Regularity Structure (NORS) which incorporates\nthe feature vectors for modeling dynamics driven by SPDEs. We conduct\nexperiments on various of SPDEs including the dynamic Phi41 model and the 2d\nstochastic Navier-Stokes equation, and the results demonstrate that the NORS is\nresolution-invariant, efficient, and achieves one order of magnitude lower\nerror with a modest amount of data.",
          "link": "http://arxiv.org/abs/2204.06255",
          "publishedOn": "2022-04-14T00:58:51.985Z",
          "wordCount": null,
          "title": "Neural Operator with Regularity Structure for Modeling Dynamics Driven by SPDEs. (arXiv:2204.06255v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06445",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1\">Haibao Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhai_H/0/1/0/all/0/1\">Hongzhi Zhai</a>",
          "description": "Multi-label learning is often used to mine the correlation between variables\nand multiple labels, and its research focuses on fully extracting the\ninformation between variables and labels. The $\\ell_{2,1}$ regularization is\noften used to get a sparse coefficient matrix, but the problem of\nmulticollinearity among variables cannot be effectively solved. In this paper,\nthe proposed model can choose the most relevant variables by solving a joint\nconstraint optimization problem using the $\\ell_{2,1}$ regularization and\nFrobenius regularization. In manifold regularization, we carry out a random\nwalk strategy based on the joint structure to construct a neighborhood graph,\nwhich is highly robust to outliers. In addition, we give an iterative algorithm\nof the proposed method and proved the convergence of this algorithm. The\nexperiments on the real-world data sets also show that the comprehensive\nperformance of our method is consistently better than the classical method.",
          "link": "http://arxiv.org/abs/2204.06445",
          "publishedOn": "2022-04-14T00:58:51.943Z",
          "wordCount": null,
          "title": "Random Graph Embedding and Joint Sparse Regularization for Multi-label Feature Selection. (arXiv:2204.06445v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06450",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arasteh_S/0/1/0/all/0/1\">Soroosh Tayebi Arasteh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weise_T/0/1/0/all/0/1\">Tobias Weise</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_M/0/1/0/all/0/1\">Maria Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noth_E/0/1/0/all/0/1\">Elmar N&#xf6;th</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Seung Hee Yang</a>",
          "description": "With the advancements in deep learning (DL) and an increasing interest in\ndata-driven speech processing methods, a major challenge for speech data\nscientists in the healthcare domain is the anonymization of pathological\nspeech, which is a required step to be able to make them accessible as a public\ntraining resource. In this paper, we investigate pathological speech data and\ncompare their speaker verifiability with that of healthy individuals. We\nutilize a large pathological speech corpus of more than 2,000 test subjects\nwith various speech and voice disorders from different ages and apply DL-based\nautomatic speaker verification (ASV) techniques. As a result, we obtained a\nmean equal error rate (EER) of 0.86% with a standard deviation of 0.16%, which\nis a factor of three lower than comparable healthy speech databases. We further\nperform detailed analyses of external influencing factors on ASV such as age,\npathology, recording environment, and utterance length, to explore their\nrespective effect. Our findings indicate that speech pathology is a potential\nbiomarker in ASV. This is potentially of high interest for the anonymization of\npathological speech data.",
          "link": "http://arxiv.org/abs/2204.06450",
          "publishedOn": "2022-04-14T00:58:51.943Z",
          "wordCount": null,
          "title": "Is Speech Pathology a Biomarker in Automatic Speaker Verification?. (arXiv:2204.06450v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06407",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_F/0/1/0/all/0/1\">Fu-Chieh Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_Y/0/1/0/all/0/1\">Yu-Wei Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Ya-Wen Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Ssu-Rui Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cioba_A/0/1/0/all/0/1\">Alexandru Cioba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_I/0/1/0/all/0/1\">I-Lun Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_J/0/1/0/all/0/1\">Jhih-Wei Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng-Yuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chien-Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ren-Chu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yao-Wen Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tai-Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tung-Chieh Chen</a>",
          "description": "Recently, successful applications of reinforcement learning to chip placement\nhave emerged. Pretrained models are necessary to improve efficiency and\neffectiveness. Currently, the weights of objective metrics (e.g., wirelength,\ncongestion, and timing) are fixed during pretraining. However, fixed-weighed\nmodels cannot generate the diversity of placements required for engineers to\naccommodate changing requirements as they arise. This paper proposes flexible\nmultiple-objective reinforcement learning (MORL) to support objective functions\nwith inference-time variable weights using just a single pretrained model. Our\nmacro placement results show that MORL can generate the Pareto frontier of\nmultiple objectives effectively.",
          "link": "http://arxiv.org/abs/2204.06407",
          "publishedOn": "2022-04-14T00:58:51.942Z",
          "wordCount": null,
          "title": "Flexible Multiple-Objective Reinforcement Learning for Chip Placement. (arXiv:2204.06407v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.08924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1\">Ian Osband</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zheng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asghari_S/0/1/0/all/0/1\">Seyed Mohammad Asghari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwaracherla_V/0/1/0/all/0/1\">Vikranth Dwaracherla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahimi_M/0/1/0/all/0/1\">Morteza Ibrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Effective decision, exploration, and adaptation often require an agent to\nknow what it knows and, also, what it does not know. This capability relies on\nthe quality of \\textit{joint} predictions of labels assigned to multiple\ninputs. Conventional neural networks lack this capability and, since most\nresearch has focused on marginal predictions, this shortcoming has been largely\noverlooked. By assessing the quality of joint predictions it is possible to\ndetermine whether a neural network effectively distinguishes between epistemic\nuncertainty (that due to lack of knowledge) and aleatoric uncertainty (that due\nto chance). We introduce the \\textit{epistemic neural network} (ENN) as a\ngeneral interface for uncertainty modeling in deep learning. While prior\napproaches to uncertainty modeling can be viewed as ENNs, the new interface\nfacilitates comparison of joint predictions, and the design of novel\narchitectures and algorithms. In particular, we introduce the \\textit{epinet}:\nan architecture that can supplement any existing neural network, including\npretrained models, and trained with modest incremental computation to represent\nuncertainty. With an epinet, conventional neural networks outperform very large\nensembles, consisting of hundreds or more particles, with orders of magnitude\nless computation. We demonstrate this efficacy across synthetic data, ImageNet,\nand sequential decision problems. As part of this effort we open-source\nexperiment code.",
          "link": "http://arxiv.org/abs/2107.08924",
          "publishedOn": "2022-04-14T00:58:51.921Z",
          "wordCount": 676,
          "title": "Epistemic Neural Networks. (arXiv:2107.08924v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zangwei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Pengtai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xuan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_D/0/1/0/all/0/1\">Da Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_C/0/1/0/all/0/1\">Chenguang Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Peng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_L/0/1/0/all/0/1\">Leqi Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Ming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiangzhuo Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1\">Fuzhao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qing_Z/0/1/0/all/0/1\">Ziheng Qing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Youlong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>",
          "description": "The click-through rate (CTR) prediction task is to predict whether a user\nwill click on the recommended item. As mind-boggling amounts of data are\nproduced online daily, accelerating CTR prediction model training is critical\nto ensuring an up-to-date model and reducing the training cost. One approach to\nincrease the training speed is to apply large batch training. However, as shown\nin computer vision and natural language processing tasks, training with a large\nbatch easily suffers from the loss of accuracy. Our experiments show that\nprevious scaling rules fail in the training of CTR prediction neural networks.\nTo tackle this problem, we first theoretically show that different frequencies\nof ids make it challenging to scale hyperparameters when scaling the batch\nsize. To stabilize the training process in a large batch size setting, we\ndevelop the adaptive Column-wise Clipping (CowClip). It enables an easy and\neffective scaling rule for the embeddings, which keeps the learning rate\nunchanged and scales the L2 loss. We conduct extensive experiments with four\nCTR prediction networks on two real-world datasets and successfully scaled 128\ntimes the original batch size without accuracy loss. In particular, for CTR\nprediction model DeepFM training on the Criteo dataset, our optimization\nframework enlarges the batch size from 1K to 128K with over 0.1% AUC\nimprovement and reduces training time from 12 hours to 10 minutes on a single\nV100 GPU. Our code locates at https://github.com/zhengzangw/LargeBatchCTR.",
          "link": "http://arxiv.org/abs/2204.06240",
          "publishedOn": "2022-04-14T00:58:51.901Z",
          "wordCount": null,
          "title": "CowClip: Reducing CTR Prediction Model Training Time from 12 hours to 10 minutes on 1 GPU. (arXiv:2204.06240v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cunegatti_E/0/1/0/all/0/1\">Elia Cunegatti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iacca_G/0/1/0/all/0/1\">Giovanni Iacca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bucur_D/0/1/0/all/0/1\">Doina Bucur</a>",
          "description": "Finding the most influential nodes in a network is a computationally hard\nproblem with several possible applications in various kinds of network-based\nproblems. While several methods have been proposed for tackling the influence\nmaximisation (IM) problem, their runtime typically scales poorly when the\nnetwork size increases. Here, we propose an original method, based on network\ndownscaling, that allows a multi-objective evolutionary algorithm (MOEA) to\nsolve the IM problem on a reduced scale network, while preserving the relevant\nproperties of the original network. The downscaled solution is then upscaled to\nthe original network, using a mechanism based on centrality metrics such as\nPageRank. Our results on eight large networks (including two with $\\sim$50k\nnodes) demonstrate the effectiveness of the proposed method with a more than\n10-fold runtime gain compared to the time needed on the original network, and\nan up to $82\\%$ time reduction compared to CELF.",
          "link": "http://arxiv.org/abs/2204.06250",
          "publishedOn": "2022-04-14T00:58:51.901Z",
          "wordCount": null,
          "title": "Large-scale multi-objective influence maximisation with network downscaling. (arXiv:2204.06250v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06114",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rakka_M/0/1/0/all/0/1\">Mariam Rakka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fouda_M/0/1/0/all/0/1\">Mohammed E. Fouda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanj_R/0/1/0/all/0/1\">Rouwaida Kanj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurdahi_F/0/1/0/all/0/1\">Fadi Kurdahi</a>",
          "description": "Decision trees are considered one of the most powerful tools for data\nclassification. Accelerating the decision tree search is crucial for\non-the-edge applications that have limited power and latency budget. In this\npaper, we propose a Content Addressable Memory (CAM) Compiler for Decision Tree\n(DT) inference acceleration. We propose a novel \"adaptive-precision\" scheme\nthat results in a compact implementation and enables an efficient bijective\nmapping to Ternary Content Addressable Memories while maintaining high\ninference accuracies. In addition, a Resistive-CAM (ReCAM) functional\nsynthesizer is developed for mapping the decision tree to the ReCAM and\nperforming functional simulations for energy, latency, and accuracy\nevaluations. We study the decision tree accuracy under hardware non-idealities\nincluding device defects, manufacturing variability, and input encoding noise.\nWe test our framework on various DT datasets including \\textit{Give Me Some\nCredit}, \\textit{Titanic}, and \\textit{COVID-19}. Our results reveal up to\n{42.4\\%} energy savings and up to 17.8x better energy-delay-area product\ncompared to the state-of-art hardware accelerators, and up to 333 million\ndecisions per sec for the pipelined implementation.",
          "link": "http://arxiv.org/abs/2204.06114",
          "publishedOn": "2022-04-14T00:58:51.900Z",
          "wordCount": null,
          "title": "DT2CAM: A Decision Tree to Content Addressable Memory Framework. (arXiv:2204.06114v1 [cs.AR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.06666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuzhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xi Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Runiu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1\">Shu-Tao Xia</a>",
          "description": "Hypergraph Convolutional Neural Networks (HGCNNs) have demonstrated their\npotential in modeling high-order relations preserved in graph-structured data.\nHowever, most existing convolution filters are localized and determined by the\npre-defined initial hypergraph topology, neglecting to explore implicit and\nlong-range relations in real-world data. In this paper, we propose the first\nlearning-based method tailored for constructing adaptive hypergraph structure,\ntermed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic\nplug-and-play module for improving the representational power of\nHGCNNs.Specifically, HERALD adaptively optimizes the adjacency relationship\nbetween vertices and hyperedges in an end-to-end manner and thus the task-aware\nhypergraph is learned. Furthermore, HERALD employs the self-attention mechanism\nto capture the non-local paired-nodes relation. Extensive experiments on\nvarious popular hypergraph datasets for node classification and graph\nclassification tasks demonstrate that our approach obtains consistent and\nconsiderable performance enhancement, proving its effectiveness and\ngeneralization ability.",
          "link": "http://arxiv.org/abs/2106.06666",
          "publishedOn": "2022-04-14T00:58:51.900Z",
          "wordCount": null,
          "title": "Learnable Hypergraph Laplacian for Hypergraph Learning. (arXiv:2106.06666v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghajanyan_A/0/1/0/all/0/1\">Armen Aghajanyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jessy Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sida Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_F/0/1/0/all/0/1\">Freda Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_R/0/1/0/all/0/1\">Ruiqi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1\">Wen-tau Yih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>",
          "description": "Code is seldom written in a single left-to-right pass and is instead\nrepeatedly edited and refined. We introduce InCoder, a unified generative model\nthat can perform program synthesis (via left-to-right generation) as well as\nediting (via infilling). InCoder is trained to generate code files from a large\ncorpus of permissively licensed code, where regions of code have been randomly\nmasked and moved to the end of each file, allowing code infilling with\nbidirectional context. Our model is the first generative model that is able to\ndirectly perform zero-shot code infilling, which we evaluate on challenging\ntasks such as type inference, comment generation, and variable re-naming. We\nfind that the ability to condition on bidirectional context substantially\nimproves performance on these tasks, while still performing comparably on\nstandard program synthesis benchmarks in comparison to left-to-right only\nmodels pretrained at similar scale. The InCoder models and code are publicly\nreleased. https://sites.google.com/view/incoder-code-models",
          "link": "http://arxiv.org/abs/2204.05999",
          "publishedOn": "2022-04-14T00:58:51.899Z",
          "wordCount": null,
          "title": "InCoder: A Generative Model for Code Infilling and Synthesis. (arXiv:2204.05999v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.11440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muller_D/0/1/0/all/0/1\">Dominik M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_Rey_I/0/1/0/all/0/1\">I&#xf1;aki Soto-Rey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kramer_F/0/1/0/all/0/1\">Frank Kramer</a>",
          "description": "Novel and high-performance medical image classification pipelines are heavily\nutilizing ensemble learning strategies. The idea of ensemble learning is to\nassemble diverse models or multiple predictions and, thus, boost prediction\nperformance. However, it is still an open question to what extent as well as\nwhich ensemble learning strategies are beneficial in deep learning based\nmedical image classification pipelines. In this work, we proposed a\nreproducible medical image classification pipeline for analyzing the\nperformance impact of the following ensemble learning techniques: Augmenting,\nStacking, and Bagging. The pipeline consists of state-of-the-art preprocessing\nand image augmentation methods as well as 9 deep convolution neural network\narchitectures. It was applied on four popular medical imaging datasets with\nvarying complexity. Furthermore, 12 pooling functions for combining multiple\npredictions were analyzed, ranging from simple statistical functions like\nunweighted averaging up to more complex learning-based functions like support\nvector machines. Our results revealed that Stacking achieved the largest\nperformance gain of up to 13% F1-score increase. Augmenting showed consistent\nimprovement capabilities by up to 4% and is also applicable to single model\nbased pipelines. Cross-validation based Bagging demonstrated significant\nperformance gain close to Stacking, which resulted in an F1-score increase up\nto +11%. Furthermore, we demonstrated that simple statistical pooling functions\nare equal or often even better than more complex pooling functions. We\nconcluded that the integration of ensemble learning techniques is a powerful\nmethod for any medical image classification pipeline to improve robustness and\nboost performance.",
          "link": "http://arxiv.org/abs/2201.11440",
          "publishedOn": "2022-04-14T00:58:51.897Z",
          "wordCount": null,
          "title": "An Analysis on Ensemble Learning optimized Medical Image Classification with Deep Convolutional Neural Networks. (arXiv:2201.11440v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1\">Jing Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hung_N/0/1/0/all/0/1\">Nguyen Quoc Viet Hung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongzhi Yin</a>",
          "description": "Next Point-of-Interest (POI) recommendation has become an indispensable\nfunctionality in Location-based Social Networks (LBSNs) due to its\neffectiveness in helping people decide the next POI to visit. However, accurate\nrecommendation requires a vast amount of historical check-in data, thus\nthreatening user privacy as the location-sensitive data needs to be handled by\ncloud servers. Although there have been several on-device frameworks for\nprivacy-preserving POI recommendations, they are still resource-intensive when\nit comes to storage and computation, and show limited robustness to the high\nsparsity of user-POI interactions. On this basis, we propose a novel\ndecentralized collaborative learning framework for POI recommendation (DCLR),\nwhich allows users to train their personalized models locally in a\ncollaborative manner. DCLR significantly reduces the local models' dependence\non the cloud for training, and can be used to expand arbitrary centralized\nrecommendation models. To counteract the sparsity of on-device user data when\nlearning each local model, we design two self-supervision signals to pretrain\nthe POI representations on the server with geographical and categorical\ncorrelations of POIs. To facilitate collaborative learning, we innovatively\npropose to incorporate knowledge from either geographically or semantically\nsimilar users into each local model with attentive aggregation and mutual\ninformation maximization. The collaborative learning process makes use of\ncommunications between devices while requiring only minor engagement from the\ncentral server for identifying user groups, and is compatible with common\nprivacy preservation mechanisms like differential privacy.",
          "link": "http://arxiv.org/abs/2204.06516",
          "publishedOn": "2022-04-14T00:58:51.893Z",
          "wordCount": 668,
          "title": "Decentralized Collaborative Learning Framework for Next POI Recommendation. (arXiv:2204.06516v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06520",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bang Wang</a>",
          "description": "How to effectively sample high-quality negative instances is important for\nwell training a recommendation model. We argue that a high-quality negative\nshould be both \\textit{informativeness} and \\textit{unbiasedness}. Although\nprevious studies have proposed some approaches to address the informativeness\nin negative sampling, few has been done to discriminating false negative from\ntrue negative for unbiased negative sampling, not to mention taking both into\nconsideration. This paper first adopts a parameter learning perspective to\nanalyze negative informativeness and unbiasedness in loss gradient-based model\ntraining. We argue that both negative sampling and collaborative filtering\ninclude an implicit task of negative classification, from which we report an\ninsightful yet beneficial finding about the order relation in predicted\nnegatives' scores. Based on our finding and by regarding negatives as random\nvariables, we next derive the class condition density of true negatives and\nthat of false negatives. We also design a Bayesian classifier for negative\nclassification, from which we define a quantitative unbiasedness measure for\nnegatives. Finally, we propose to use a harmonic mean of informativeness and\nunbiasedness to sample high-quality negatives. Experimental studies validate\nthe superiority of our negative sampling algorithm over the peers in terms of\nbetter sampling quality and better recommendation performance.",
          "link": "http://arxiv.org/abs/2204.06520",
          "publishedOn": "2022-04-14T00:58:51.867Z",
          "wordCount": 624,
          "title": "Negative Sampling for Recommendation. (arXiv:2204.06520v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seongmin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijie J. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_J/0/1/0/all/0/1\">Judy Hoffman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1\">Duen Horng Chau</a>",
          "description": "CNN image classifiers are widely used, thanks to their efficiency and\naccuracy. However, they can suffer from biases that impede their practical\napplications. Most existing bias investigation techniques are either\ninapplicable to general image classification tasks or require significant user\nefforts in perusing all data subgroups to manually specify which data\nattributes to inspect. We present VisCUIT, an interactive visualization system\nthat reveals how and why a CNN classifier is biased. VisCUIT visually\nsummarizes the subgroups on which the classifier underperforms and helps users\ndiscover and characterize the cause of the underperformances by revealing image\nconcepts responsible for activating neurons that contribute to\nmisclassifications. VisCUIT runs in modern browsers and is open-source,\nallowing people to easily access and extend the tool to other model\narchitectures and datasets. VisCUIT is available at the following public demo\nlink: https://poloclub.github.io/VisCUIT. A video demo is available at\nhttps://youtu.be/eNDbSyM4R_4.",
          "link": "http://arxiv.org/abs/2204.05899",
          "publishedOn": "2022-04-14T00:58:51.860Z",
          "wordCount": 611,
          "title": "VisCUIT: Visual Auditor for Bias in CNN Image Classifier. (arXiv:2204.05899v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_W/0/1/0/all/0/1\">Wenqiang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agapitos_A/0/1/0/all/0/1\">Alexandros Agapitos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanwei Liu</a>",
          "description": "Coverage and capacity are the important metrics for performance evaluation in\nwireless networks, while the coverage and capacity have several conflicting\nrelationships, e.g. high transmit power contributes to large coverage but high\ninter-cell interference reduces the capacity performance. Therefore, in order\nto strike a balance between the coverage and capacity, a novel model is\nproposed for the coverage and capacity optimization of simultaneously\ntransmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs)\nassisted networks. To solve the coverage and capacity optimization (CCO)\nproblem, a machine learning-based multi-objective optimization algorithm, i.e.,\nthe multi-objective proximal policy optimization (MO-PPO) algorithm, is\nproposed. In this algorithm, a loss function-based update strategy is the core\npoint, which is able to calculate weights for both loss functions of coverage\nand capacity by a min-norm solver at each update. The numerical results\ndemonstrate that the investigated update strategy outperforms the fixed\nweight-based MO algorithms.",
          "link": "http://arxiv.org/abs/2204.06390",
          "publishedOn": "2022-04-14T00:58:51.850Z",
          "wordCount": 600,
          "title": "Coverage and Capacity Optimization in STAR-RISs Assisted Networks: A Machine Learning Approach. (arXiv:2204.06390v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Josifoski_M/0/1/0/all/0/1\">Martin Josifoski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_N/0/1/0/all/0/1\">Nicola De Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1\">Maxime Peyrard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petroni_F/0/1/0/all/0/1\">Fabio Petroni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>",
          "description": "Structured and grounded representation of text is typically formalized by\nclosed information extraction, the problem of extracting an exhaustive set of\n(subject, relation, object) triplets that are consistent with a predefined set\nof entities and relations from a knowledge base schema. Most existing works are\npipelines prone to error accumulation, and all approaches are only applicable\nto unrealistically small numbers of entities and relations. We introduce GenIE\n(generative information extraction), the first end-to-end autoregressive\nformulation of closed information extraction. GenIE naturally exploits the\nlanguage knowledge from the pre-trained transformer by autoregressively\ngenerating relations and entities in textual form. Thanks to a new bi-level\nconstrained generation strategy, only triplets consistent with the predefined\nknowledge base schema are produced. Our experiments show that GenIE is\nstate-of-the-art on closed information extraction, generalizes from fewer\ntraining data points than baselines, and scales to a previously unmanageable\nnumber of entities and relations. With this work, closed information extraction\nbecomes practical in realistic scenarios, providing new opportunities for\ndownstream tasks. Finally, this work paves the way towards a unified end-to-end\napproach to the core tasks of information extraction. Code, data and models\navailable at https://github.com/epfl-dlab/GenIE.",
          "link": "http://arxiv.org/abs/2112.08340",
          "publishedOn": "2022-04-14T00:58:51.840Z",
          "wordCount": 674,
          "title": "GenIE: Generative Information Extraction. (arXiv:2112.08340v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1810.03730",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walder_C/0/1/0/all/0/1\">Christian Walder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1\">Marian-Andrei Rizoiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lexing Xie</a>",
          "description": "In this paper, we develop an efficient nonparametric Bayesian estimation of\nthe kernel function of Hawkes processes. The non-parametric Bayesian approach\nis important because it provides flexible Hawkes kernels and quantifies their\nuncertainty. Our method is based on the cluster representation of Hawkes\nprocesses. Utilizing the finite support assumption of the Hawkes process, we\nefficiently sample random branching structures and thus, we split the Hawkes\nprocess into clusters of Poisson processes. We derive two algorithms -- a block\nGibbs sampler and a maximum a posteriori estimator based on expectation\nmaximization -- and we show that our methods have a linear time complexity,\nboth theoretically and empirically. On synthetic data, we show our methods to\nbe able to infer flexible Hawkes triggering kernels. On two large-scale Twitter\ndiffusion datasets, we show that our methods outperform the current\nstate-of-the-art in goodness-of-fit and that the time complexity is linear in\nthe size of the dataset. We also observe that on diffusions related to online\nvideos, the learned kernels reflect the perceived longevity for different\ncontent types such as music or pets videos.",
          "link": "http://arxiv.org/abs/1810.03730",
          "publishedOn": "2022-04-14T00:58:51.831Z",
          "wordCount": 671,
          "title": "Efficient Non-parametric Bayesian Hawkes Processes. (arXiv:1810.03730v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Han Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>",
          "description": "Prompt-based learning (i.e., prompting) is an emerging paradigm for\nexploiting knowledge learned by a pretrained language model. In this paper, we\npropose Automatic Multi-Label Prompting (AMuLaP), a simple yet effective method\nto automatically select label mappings for few-shot text classification with\nprompting. Our method exploits one-to-many label mappings and a\nstatistics-based algorithm to select label mappings given a prompt template.\nOur experiments demonstrate that AMuLaP achieves competitive performance on the\nGLUE benchmark without human effort or external resources.",
          "link": "http://arxiv.org/abs/2204.06305",
          "publishedOn": "2022-04-14T00:58:51.800Z",
          "wordCount": 515,
          "title": "Automatic Multi-Label Prompting: Simple and Interpretable Few-Shot Classification. (arXiv:2204.06305v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polk_S/0/1/0/all/0/1\">Sam L. Polk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1\">Kangning Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plemmons_R/0/1/0/all/0/1\">Robert J. Plemmons</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_J/0/1/0/all/0/1\">James M. Murphy</a>",
          "description": "Hyperspectral images encode rich structure that can be exploited for material\ndiscrimination by machine learning algorithms. This article introduces the\nActive Diffusion and VCA-Assisted Image Segmentation (ADVIS) for active\nmaterial discrimination. ADVIS selects high-purity, high-density pixels that\nare far in diffusion distance (a data-dependent metric) from other high-purity,\nhigh-density pixels in the hyperspectral image. The ground truth labels of\nthese pixels are queried and propagated to the rest of the image. The ADVIS\nactive learning algorithm is shown to strongly outperform its fully\nunsupervised clustering algorithm counterpart, suggesting that the\nincorporation of a very small number of carefully-selected ground truth labels\ncan result in substantially superior material discrimination in hyperspectral\nimages.",
          "link": "http://arxiv.org/abs/2204.06298",
          "publishedOn": "2022-04-14T00:58:51.793Z",
          "wordCount": 566,
          "title": "Active Diffusion and VCA-Assisted Image Segmentation of Hyperspectral Images. (arXiv:2204.06298v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suteu_M/0/1/0/all/0/1\">Mihai Suteu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yike Guo</a>",
          "description": "Structured pruning efficiently compresses networks by identifying and\nremoving unimportant neurons. While this can be elegantly achieved by applying\nsparsity-inducing regularisation on BatchNorm parameters, an L1 penalty would\nshrink all scaling factors rather than just those of superfluous neurons. To\ntackle this issue, we introduce a simple BatchNorm variation with bounded\nscaling parameters, based on which we design a novel regularisation term that\nsuppresses only neurons with low importance. Under our method, the weights of\nunnecessary neurons effectively recede, producing a polarised bimodal\ndistribution of importances. We show that neural networks trained this way can\nbe pruned to a larger extent and with less deterioration. We one-shot prune VGG\nand ResNet architectures at different ratios on CIFAR and ImagenNet datasets.\nIn the case of VGG-style networks, our method significantly outperforms\nexisting approaches particularly under a severe pruning regime.",
          "link": "http://arxiv.org/abs/2204.06404",
          "publishedOn": "2022-04-14T00:58:51.785Z",
          "wordCount": 561,
          "title": "Receding Neuron Importances for Structured Pruning. (arXiv:2204.06404v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.15646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Floto_G/0/1/0/all/0/1\">Griffin Floto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kremer_S/0/1/0/all/0/1\">Stefan Kremer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nica_M/0/1/0/all/0/1\">Mihai Nica</a>",
          "description": "An important property for deep neural networks is the ability to perform\nrobust out-of-distribution detection on previously unseen data. This property\nis essential for safety purposes when deploying models for real world\napplications. Recent studies show that probabilistic generative models can\nperform poorly on this task, which is surprising given that they seek to\nestimate the likelihood of training data. To alleviate this issue, we propose\nthe exponentially tilted Gaussian prior distribution for the Variational\nAutoencoder (VAE) which pulls points onto the surface of a hyper-sphere in\nlatent space. This achieves state-of-the art results on the area under the\ncurve-receiver operator characteristics metric using just the log-likelihood\nthat the VAE naturally assigns. Because this prior is a simple modification of\nthe traditional VAE prior, it is faster and easier to implement than\ncompetitive methods.",
          "link": "http://arxiv.org/abs/2111.15646",
          "publishedOn": "2022-04-14T00:58:51.775Z",
          "wordCount": 611,
          "title": "The Exponentially Tilted Gaussian Prior for Variational Autoencoders. (arXiv:2111.15646v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patil_P/0/1/0/all/0/1\">Parth Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranade_A/0/1/0/all/0/1\">Aparna Ranade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabane_M/0/1/0/all/0/1\">Maithili Sabane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litake_O/0/1/0/all/0/1\">Onkar Litake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>",
          "description": "Named Entity Recognition (NER) is a basic NLP task and finds major\napplications in conversational and search systems. It helps us identify key\nentities in a sentence used for the downstream application. NER or similar slot\nfilling systems for popular languages have been heavily used in commercial\napplications. In this work, we focus on Marathi, an Indian language, spoken\nprominently by the people of Maharashtra state. Marathi is a low resource\nlanguage and still lacks useful NER resources. We present L3Cube-MahaNER, the\nfirst major gold standard named entity recognition dataset in Marathi. We also\ndescribe the manual annotation guidelines followed during the process. In the\nend, we benchmark the dataset on different CNN, LSTM, and Transformer based\nmodels like mBERT, XLM-RoBERTa, IndicBERT, MahaBERT, etc. The MahaBERT provides\nthe best performance among all the models. The data and models are available at\nhttps://github.com/l3cube-pune/MarathiNLP .",
          "link": "http://arxiv.org/abs/2204.06029",
          "publishedOn": "2022-04-14T00:58:51.659Z",
          "wordCount": null,
          "title": "L3Cube-MahaNER: A Marathi Named Entity Recognition Dataset and BERT models. (arXiv:2204.06029v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06109",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Baran_S/0/1/0/all/0/1\">Sebastian Baran</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Rola_P/0/1/0/all/0/1\">Przemys&#x142;aw Rola</a>",
          "description": "The insurance industry, with its large datasets, is a natural place to use\nbig data solutions. However it must be stressed, that significant number of\napplications for machine learning in insurance industry, like fraud detection\nor claim prediction, deals with the problem of machine learning on an\nimbalanced data set. This is due to the fact that frauds or claims are rare\nevents when compared with the entire population of drivers. The problem of\nimbalanced learning is often hard to overcome. Therefore, the main goal of this\nwork is to present and apply various methods of dealing with an imbalanced\ndataset in the context of claim occurrence prediction in car insurance. In\naddition, the above techniques are used to compare the results of machine\nlearning algorithms in the context of claim occurrence prediction in car\ninsurance. Our study covers the following techniques: logistic-regression,\ndecision tree, random forest, xgBoost, feed-forward network. The problem is the\nclassification one.",
          "link": "http://arxiv.org/abs/2204.06109",
          "publishedOn": "2022-04-14T00:58:51.659Z",
          "wordCount": null,
          "title": "Prediction of motor insurance claims occurrence as an imbalanced machine learning problem. (arXiv:2204.06109v1 [q-fin.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06214",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mandal_R/0/1/0/all/0/1\">Ranju Mandal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azam_B/0/1/0/all/0/1\">Basim Azam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_B/0/1/0/all/0/1\">Brijesh Verma</a>",
          "description": "Deep learning models have been efficient lately on image parsing tasks.\nHowever, deep learning models are not fully capable of exploiting visual and\ncontextual information simultaneously. The proposed three-layer context-based\ndeep architecture is capable of integrating context explicitly with visual\ninformation. The novel idea here is to have a visual layer to learn visual\ncharacteristics from binary class-based learners, a contextual layer to learn\ncontext, and then an integration layer to learn from both via genetic\nalgorithm-based optimal fusion to produce a final decision. The experimental\noutcomes when evaluated on benchmark datasets are promising. Further analysis\nshows that optimized network weights can improve performance and make stable\npredictions.",
          "link": "http://arxiv.org/abs/2204.06214",
          "publishedOn": "2022-04-14T00:58:51.629Z",
          "wordCount": null,
          "title": "Context-based Deep Learning Architecture with Optimal Integration Layer for Image Parsing. (arXiv:2204.06214v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weyns_D/0/1/0/all/0/1\">Danny Weyns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gheibi_O/0/1/0/all/0/1\">Omid Gheibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quin_F/0/1/0/all/0/1\">Federico Quin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donckt_J/0/1/0/all/0/1\">Jeroen Van Der Donckt</a>",
          "description": "Many software systems today face uncertain operating conditions, such as\nsudden changes in the availability of resources or unexpected user behavior.\nWithout proper mitigation these uncertainties can jeopardize the system goals.\nSelf-adaptation is a common approach to tackle such uncertainties. When the\nsystem goals may be compromised, the self-adaptive system has to select the\nbest adaptation option to reconfigure by analyzing the possible adaptation\noptions, i.e., the adaptation space. Yet, analyzing large adaptation spaces\nusing rigorous methods can be resource- and time-consuming, or even be\ninfeasible. One approach to tackle this problem is by using online machine\nlearning to reduce adaptation spaces. However, existing approaches require\ndomain expertise to perform feature engineering to define the learner, and\nsupport online adaptation space reduction only for specific goals. To tackle\nthese limitations, we present 'Deep Learning for Adaptation Space Reduction\nPlus' -- DLASeR+ in short. DLASeR+ offers an extendable learning framework for\nonline adaptation space reduction that does not require feature engineering,\nwhile supporting three common types of adaptation goals: threshold,\noptimization, and set-point goals. We evaluate DLASeR+ on two instances of an\nInternet-of-Things application with increasing sizes of adaptation spaces for\ndifferent combinations of adaptation goals. We compare DLASeR+ with a baseline\nthat applies exhaustive analysis and two state-of-the-art approaches for\nadaptation space reduction that rely on learning. Results show that DLASeR+ is\neffective with a negligible effect on the realization of the adaptation goals\ncompared to an exhaustive analysis approach, and supports three common types of\nadaptation goals beyond the state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2204.06254",
          "publishedOn": "2022-04-14T00:58:51.629Z",
          "wordCount": null,
          "title": "Deep Learning for Effective and Efficient Reduction of Large Adaptation Spaces in Self-Adaptive Systems. (arXiv:2204.06254v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1\">Dennis Ulmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bassignana_E/0/1/0/all/0/1\">Elisa Bassignana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_Eberstein_M/0/1/0/all/0/1\">Max M&#xfc;ller-Eberstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varab_D/0/1/0/all/0/1\">Daniel Varab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mike Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardmeier_C/0/1/0/all/0/1\">Christian Hardmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1\">Barbara Plank</a>",
          "description": "The field of Deep Learning (DL) has undergone explosive growth during the\nlast decade, with a substantial impact on Natural Language Processing (NLP) as\nwell. Yet, as with other fields employing DL techniques, there has been a lack\nof common experimental standards compared to more established disciplines.\nStarting from fundamental scientific principles, we distill ongoing discussions\non experimental standards in DL into a single, widely-applicable methodology.\nFollowing these best practices is crucial to strengthening experimental\nevidence, improve reproducibility and enable scientific progress. These\nstandards are further collected in a public repository to help them\ntransparently adapt to future needs.",
          "link": "http://arxiv.org/abs/2204.06251",
          "publishedOn": "2022-04-14T00:58:51.628Z",
          "wordCount": null,
          "title": "Experimental Standards for Deep Learning Research: A Natural Language Processing Perspective. (arXiv:2204.06251v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.05097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Do_M/0/1/0/all/0/1\">Manh Tuan Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1\">Noseong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1\">Kijung Shin</a>",
          "description": "Graph neural networks (GNNs) have received massive attention in the field of\nmachine learning on graphs. Inspired by the success of neural networks, a line\nof research has been conducted to train GNNs to deal with various tasks, such\nas node classification, graph classification, and link prediction. In this\nwork, our task of interest is graph classification. Several GNN models have\nbeen proposed and shown great accuracy in this task. However, the question is\nwhether usual training methods fully realize the capacity of the GNN models.\n\nIn this work, we propose a two-stage training framework based on triplet\nloss. In the first stage, GNN is trained to map each graph to a Euclidean-space\nvector so that graphs of the same class are close while those of different\nclasses are mapped far apart. Once graphs are well-separated based on labels, a\nclassifier is trained to distinguish between different classes. This method is\ngeneric in the sense that it is compatible with any GNN model. By adapting five\nGNN models to our method, we demonstrate the consistent improvement in accuracy\nand utilization of each GNN's allocated capacity over the original training\nmethod of each model up to 5.4\\% points in 12 datasets.",
          "link": "http://arxiv.org/abs/2011.05097",
          "publishedOn": "2022-04-11T00:52:29.155Z",
          "wordCount": 684,
          "title": "Two-stage Training of Graph Neural Networks for Graph Classification. (arXiv:2011.05097v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.02445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shevkunov_K/0/1/0/all/0/1\">Kirill Shevkunov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1\">Liudmila Prokhorenkova</a>",
          "description": "Various non-trivial spaces are becoming popular for embedding structured data\nsuch as graphs, texts, or images. Following spherical and hyperbolic spaces,\nmore general product spaces have been proposed. However, searching for the best\nconfiguration of product space is a resource-intensive procedure, which reduces\nthe practical applicability of the idea. We generalize the concept of product\nspace and introduce an overlapping space that does not have the configuration\nsearch problem. The main idea is to allow subsets of coordinates to be shared\nbetween spaces of different types (Euclidean, hyperbolic, spherical). As a\nresult, parameter optimization automatically learns the optimal configuration.\nAdditionally, overlapping spaces allow for more compact representations since\ntheir geometry is more complex. Our experiments confirm that overlapping spaces\noutperform the competitors in graph embedding tasks. Here, we consider both\ndistortion setup, where the aim is to preserve distances, and ranking setup,\nwhere the relative order should be preserved. The proposed method effectively\nsolves the problem and outperforms the competitors in both settings. We also\nperform an empirical analysis in a realistic information retrieval task, where\nwe compare all spaces by incorporating them into DSSM. In this case, the\nproposed overlapping space consistently achieves nearly optimal results without\nany configuration tuning. This allows for reducing training time, which can be\nsignificant in large-scale applications.",
          "link": "http://arxiv.org/abs/2007.02445",
          "publishedOn": "2022-04-11T00:52:29.147Z",
          "wordCount": 697,
          "title": "Overlapping Spaces for Compact Graph Representations. (arXiv:2007.02445v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.06822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1\">Mahdi S. Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jia Shu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_A/0/1/0/all/0/1\">Andre Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jingxuan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuli_M/0/1/0/all/0/1\">Mathieu Tuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1\">Sepehr Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadakia_A/0/1/0/all/0/1\">Arsh Kadakia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1\">Konstantinos N. Plataniotis</a>",
          "description": "Neural Architecture Search (NAS) has shifted network design from using human\nintuition to leveraging search algorithms guided by evaluation metrics. We\nstudy channel size optimization in convolutional neural networks (CNN) and\nidentify the role it plays in model accuracy and complexity. Current channel\nsize selection methods are generally limited by discrete sample spaces while\nsuffering from manual iteration and simple heuristics. To solve this, we\nintroduce an efficient dynamic scaling algorithm -- CONet -- that automatically\noptimizes channel sizes across network layers for a given CNN. Two metrics --\n\"\\textit{Rank}\" and \"\\textit{Rank Average Slope}\" -- are introduced to identify\nthe information accumulated in training. The algorithm dynamically scales\nchannel sizes up or down over a fixed searching phase. We conduct experiments\non CIFAR10/100 and ImageNet datasets and show that CONet can find efficient and\naccurate architectures searched in ResNet, DARTS, and DARTS+ spaces that\noutperform their baseline models.\n\nThis document supersedes previously published paper in ICCV2021-NeurArch\nworkshop. An additional section is included on manual scaling of channel size\nin CNNs to numerically validate of the metrics used in searching optimum\nchannel configurations in CNNs.",
          "link": "http://arxiv.org/abs/2108.06822",
          "publishedOn": "2022-04-11T00:52:29.140Z",
          "wordCount": 677,
          "title": "CONet: Channel Optimization for Convolutional Neural Networks. (arXiv:2108.06822v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.10439",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_A/0/1/0/all/0/1\">Alexander Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_A/0/1/0/all/0/1\">Andrew H. Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bilgic_B/0/1/0/all/0/1\">Berkin Bilgic</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ba_D/0/1/0/all/0/1\">Demba Ba</a>",
          "description": "Sparse Bayesian learning (SBL) is a powerful framework for tackling the\nsparse coding problem while also providing uncertainty quantification. The most\npopular inference algorithms for SBL exhibit prohibitively large computational\ncosts for high-dimensional problems due to the need to maintain a large\ncovariance matrix. To resolve this issue, we introduce a new method for\naccelerating SBL inference -- named covariance-free expectation maximization\n(CoFEM) -- that avoids explicit computation of the covariance matrix. CoFEM\nsolves multiple linear systems to obtain unbiased estimates of the posterior\nstatistics needed by SBL. This is accomplished by exploiting innovations from\nnumerical linear algebra such as preconditioned conjugate gradient and a\nlittle-known diagonal estimation rule. For a large class of compressed sensing\nmatrices, we provide theoretical justifications for why our method scales well\nin high-dimensional settings. Through simulations, we show that CoFEM can be up\nto thousands of times faster than existing baselines without sacrificing coding\naccuracy. Through applications to calcium imaging deconvolution and\nmulti-contrast MRI reconstruction, we show that CoFEM enables SBL to tractably\ntackle high-dimensional sparse coding problems of practical interest.",
          "link": "http://arxiv.org/abs/2105.10439",
          "publishedOn": "2022-04-11T00:52:29.133Z",
          "wordCount": 635,
          "title": "Covariance-Free Sparse Bayesian Learning. (arXiv:2105.10439v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.01808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Isacchini_G/0/1/0/all/0/1\">Giulio Isacchini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spisak_N/0/1/0/all/0/1\">Natanael Spisak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourmohammad_A/0/1/0/all/0/1\">Armita Nourmohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mora_T/0/1/0/all/0/1\">Thierry Mora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walczak_A/0/1/0/all/0/1\">Aleksandra M. Walczak</a>",
          "description": "Simulation-based inference enables learning the parameters of a model even\nwhen its likelihood cannot be computed in practice. One class of methods uses\ndata simulated with different parameters to infer models of the\nlikelihood-to-evidence ratio, or equivalently the posterior function. Here we\nframe the inference task as an estimation of an energy function parametrized\nwith an artificial neural network. We present an intuitive approach where the\noptimal model of the likelihood-to-evidence ratio is found by maximizing the\nlikelihood of simulated data. Within this framework, the connection between the\ntask of simulation-based inference and mutual information maximization is\nclear, and we show how several known methods of posterior estimation relate to\nalternative lower bounds to mutual information. These distinct objective\nfunctions aim at the same optimal energy form and therefore can be directly\nbenchmarked. We compare their accuracy in the inference of model parameters,\nfocusing on four dynamical systems that encompass common challenges in time\nseries analysis: dynamics driven by multiplicative noise, nonlinear\ninteractions, chaotic behavior, and high-dimensional parameter space.",
          "link": "http://arxiv.org/abs/2106.01808",
          "publishedOn": "2022-04-11T00:52:29.125Z",
          "wordCount": 653,
          "title": "MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood Inference from Sampled Trajectories. (arXiv:2106.01808v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sitan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Anru R. Zhang</a>",
          "description": "We consider the problem of learning high dimensional polynomial\ntransformations of Gaussians. Given samples of the form $p(x)$, where $x\\sim\nN(0, \\mathrm{Id}_r)$ is hidden and $p: \\mathbb{R}^r \\to \\mathbb{R}^d$ is a\nfunction where every output coordinate is a low-degree polynomial, the goal is\nto learn the distribution over $p(x)$. This problem is natural in its own\nright, but is also an important special case of learning deep generative\nmodels, namely pushforwards of Gaussians under two-layer neural networks with\npolynomial activations. Understanding the learnability of such generative\nmodels is crucial to understanding why they perform so well in practice.\n\nOur first main result is a polynomial-time algorithm for learning quadratic\ntransformations of Gaussians in a smoothed setting. Our second main result is a\npolynomial-time algorithm for learning constant-degree polynomial\ntransformations of Gaussian in a smoothed setting, when the rank of the\nassociated tensors is small. In fact our results extend to any\nrotation-invariant input distribution, not just Gaussian. These are the first\nend-to-end guarantees for learning a pushforward under a neural network with\nmore than one layer.\n\nAlong the way, we also give the first polynomial-time algorithms with\nprovable guarantees for tensor ring decomposition, a popular generalization of\ntensor decomposition that is used in practice to implicitly store large\ntensors.",
          "link": "http://arxiv.org/abs/2204.04209",
          "publishedOn": "2022-04-11T00:52:29.101Z",
          "wordCount": 641,
          "title": "Learning Polynomial Transformations. (arXiv:2204.04209v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04211",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Turri_V/0/1/0/all/0/1\">Violet Turri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dzombak_R/0/1/0/all/0/1\">Rachel Dzombak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heim_E/0/1/0/all/0/1\">Eric Heim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+VanHoudnos_N/0/1/0/all/0/1\">Nathan VanHoudnos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palat_J/0/1/0/all/0/1\">Jay Palat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Anusha Sinha</a>",
          "description": "Current test and evaluation (T&E) methods for assessing machine learning (ML)\nsystem performance often rely on incomplete metrics. Testing is additionally\noften siloed from the other phases of the ML system lifecycle. Research\ninvestigating cross-domain approaches to ML T&E is needed to drive the state of\nthe art forward and to build an Artificial Intelligence (AI) engineering\ndiscipline. This paper advocates for a robust, integrated approach to testing\nby outlining six key questions for guiding a holistic T&E strategy.",
          "link": "http://arxiv.org/abs/2204.04211",
          "publishedOn": "2022-04-11T00:52:29.094Z",
          "wordCount": 528,
          "title": "Measuring AI Systems Beyond Accuracy. (arXiv:2204.04211v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.06271",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khazraei_A/0/1/0/all/0/1\">Amir Khazraei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hallyburton_S/0/1/0/all/0/1\">Spencer Hallyburton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qitong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajic_M/0/1/0/all/0/1\">Miroslav Pajic</a>",
          "description": "This work focuses on the use of deep learning for vulnerability analysis of\ncyber-physical systems (CPS). Specifically, we consider a control architecture\nwidely used in CPS (e.g., robotics), where the low-level control is based on\ne.g., the extended Kalman filter (EKF) and an anomaly detector. To facilitate\nanalyzing the impact potential sensing attacks could have, our objective is to\ndevelop learning-enabled attack generators capable of designing stealthy\nattacks that maximally degrade system operation. We show how such problem can\nbe cast within a learning-based grey-box framework where parts of the runtime\ninformation are known to the attacker, and introduce two models based on\nfeed-forward neural networks (FNN); both models are trained offline, using a\ncost function that combines the attack effects on the estimation error and the\nresidual signal used for anomaly detection, so that the trained models are\ncapable of recursively generating such effective sensor attacks in real-time.\nThe effectiveness of the proposed methods is illustrated on several case\nstudies.",
          "link": "http://arxiv.org/abs/2103.06271",
          "publishedOn": "2022-04-11T00:52:29.087Z",
          "wordCount": 641,
          "title": "Learning-Based Vulnerability Analysis of Cyber-Physical Systems. (arXiv:2103.06271v3 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04187",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Saar_L/0/1/0/all/0/1\">Logan Saar</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Liang_H/0/1/0/all/0/1\">Haotong Liang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Wang_A/0/1/0/all/0/1\">Alex Wang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+McDannald_A/0/1/0/all/0/1\">Austin McDannald</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Rodriguez_E/0/1/0/all/0/1\">Efrain Rodriguez</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Takeuchi_I/0/1/0/all/0/1\">Ichiro Takeuchi</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kusne_A/0/1/0/all/0/1\">A. Gilad Kusne</a>",
          "description": "The next generation of physical science involves robot scientists -\nautonomous physical science systems capable of experimental design, execution,\nand analysis in a closed loop. Such systems have shown real-world success for\nscientific exploration and discovery, including the first discovery of a\nbest-in-class material. To build and use these systems, the next generation\nworkforce requires expertise in diverse areas including ML, control systems,\nmeasurement science, materials synthesis, decision theory, among others.\nHowever, education is lagging. Educators need a low-cost, easy-to-use platform\nto teach the required skills. Industry can also use such a platform for\ndeveloping and evaluating autonomous physical science methodologies. We present\nthe next generation in science education, a kit for building a low-cost\nautonomous scientist. The kit was used during two courses at the University of\nMaryland to teach undergraduate and graduate students autonomous physical\nscience. We discuss its use in the course and its greater capability to teach\nthe dual tasks of autonomous model exploration, optimization, and\ndetermination, with an example of autonomous experimental \"discovery\" of the\nHenderson-Hasselbalch equation.",
          "link": "http://arxiv.org/abs/2204.04187",
          "publishedOn": "2022-04-11T00:52:29.079Z",
          "wordCount": 625,
          "title": "A Low-Cost Robot Science Kit for Education with Symbolic Regression for Hypothesis Discovery and Validation. (arXiv:2204.04187v1 [cond-mat.mtrl-sci])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.09907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agibetov_A/0/1/0/all/0/1\">Asan Agibetov</a>",
          "description": "Learning good quality neural graph embeddings has long been achieved by\nminimzing the pointwise mutual information (PMI) for co-occuring nodes in\nsimulated random walks. This design choice has been mostly popularized by the\ndirect application of the highly-successful word embedding algorithm word2vec\nto predicting the formation of new links in social, co-citation, and biological\nnetworks. However, such a skeumorphic design of graph embedding methods entails\na truncation of information coming from pairs of nodes with low PMI. To\ncircumvent this issue, we propose an improved approach to learning low-rank\nfactorization embeddings that incorporate information from such unlikely pairs\nof nodes and show that it can improve the link prediction performance of\nbaseline methods from 1.2% to 24.2%. Based on our results and observations we\noutline further steps that could improve the design of next graph embedding\nalgorithms that are based on matrix factorizaion.",
          "link": "http://arxiv.org/abs/2011.09907",
          "publishedOn": "2022-04-11T00:52:29.060Z",
          "wordCount": 626,
          "title": "Neural graph embeddings via matrix factorization for link prediction: smoothing or truncating negatives?. (arXiv:2011.09907v2 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04170",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zaiem_S/0/1/0/all/0/1\">Salah Zaiem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1\">Titouan Parcollet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Essid_S/0/1/0/all/0/1\">Slim Essid</a>",
          "description": "Contrastive learning enables learning useful audio and speech representations\nwithout ground-truth labels by maximizing the similarity between latent\nrepresentations of similar signal segments. In this framework various data\naugmentation techniques are usually exploited to help enforce desired\ninvariances within the learned representations, improving performance on\nvarious audio tasks thanks to more robust embeddings. Now, selecting the most\nrelevant augmentations has proven crucial for better downstream performances.\nThus, this work introduces a conditional independance-based method which allows\nfor automatically selecting a suitable distribution on the choice of\naugmentations and their parametrization from a set of predefined ones, for\ncontrastive self-supervised pre-training. This is performed with respect to a\ndownstream task of interest, hence saving a costly hyper-parameter search.\nExperiments performed on two different downstream tasks validate the proposed\napproach showing better results than experimenting without augmentation or with\nbaseline augmentations. We furthermore conduct a qualitative analysis of the\nautomatically selected augmentations and their variation according to the\nconsidered final downstream dataset.",
          "link": "http://arxiv.org/abs/2204.04170",
          "publishedOn": "2022-04-11T00:52:29.052Z",
          "wordCount": 614,
          "title": "Automatic Data Augmentation Selection and Parametrization in Contrastive Self-Supervised Speech Representation Learning. (arXiv:2204.04170v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.05185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ross_A/0/1/0/all/0/1\">Andrew Slavin Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "In representation learning, there has been recent interest in developing\nalgorithms to disentangle the ground-truth generative factors behind a dataset,\nand metrics to quantify how fully this occurs. However, these algorithms and\nmetrics often assume that both representations and ground-truth factors are\nflat, continuous, and factorized, whereas many real-world generative processes\ninvolve rich hierarchical structure, mixtures of discrete and continuous\nvariables with dependence between them, and even varying intrinsic\ndimensionality. In this work, we develop benchmarks, algorithms, and metrics\nfor learning such hierarchical representations.",
          "link": "http://arxiv.org/abs/2102.05185",
          "publishedOn": "2022-04-11T00:52:29.045Z",
          "wordCount": 569,
          "title": "Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement. (arXiv:2102.05185v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1911.11397",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Duan_J/0/1/0/all/0/1\">Jingliang Duan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengyu Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shengbo Eben Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_Q/0/1/0/all/0/1\">Qi Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_Z/0/1/0/all/0/1\">Zhenzhong Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_B/0/1/0/all/0/1\">Bo Cheng</a>",
          "description": "This paper presents a constrained adaptive dynamic programming (CADP)\nalgorithm to solve general nonlinear nonaffine optimal control problems with\nknown dynamics. Unlike previous ADP algorithms, it can directly deal with\nproblems with state constraints. Firstly, a constrained generalized policy\niteration (CGPI) framework is developed to handle state constraints by\ntransforming the traditional policy improvement process into a constrained\npolicy optimization problem. Next, we propose an actor-critic variant of CGPI,\ncalled CADP, in which both policy and value functions are approximated by\nmulti-layer neural networks to directly map the system states to control inputs\nand value function, respectively. CADP linearizes the constrained optimization\nproblem locally into a quadratically constrained linear programming problem,\nand then obtains the optimal update of the policy network by solving its dual\nproblem. A trust region constraint is added to prevent excessive policy update,\nthus ensuring linearization accuracy. We determine the feasibility of the\npolicy optimization problem by calculating the minimum trust region boundary\nand update the policy using two recovery rules when infeasible. The vehicle\ncontrol problem in the path-tracking task is used to demonstrate the\neffectiveness of this proposed method.",
          "link": "http://arxiv.org/abs/1911.11397",
          "publishedOn": "2022-04-11T00:52:29.037Z",
          "wordCount": 692,
          "title": "Adaptive dynamic programming for nonaffine nonlinear optimal control problem with state constraints. (arXiv:1911.11397v3 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2003.09040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kensen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bieber_D/0/1/0/all/0/1\">David Bieber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rishabh Singh</a>",
          "description": "The success and popularity of deep learning is on the rise, partially due to\npowerful deep learning frameworks such as TensorFlow and PyTorch that make it\neasier to develop deep learning models. However, these libraries also come with\nsteep learning curves, since programming in these frameworks is quite different\nfrom traditional imperative programming with explicit loops and conditionals.\nIn this work, we present a tool called TF-Coder for programming by example in\nTensorFlow. TF-Coder uses a bottom-up weighted enumerative search, with\nvalue-based pruning of equivalent expressions and flexible type- and\nvalue-based filtering to ensure that expressions adhere to various requirements\nimposed by the TensorFlow library. We train models to predict TensorFlow\noperations from features of the input and output tensors and natural language\ndescriptions of tasks, to prioritize relevant operations during search.\nTF-Coder solves 63 of 70 real-world tasks within 5 minutes, sometimes finding\nsimpler solutions in less time compared to experienced human programmers.",
          "link": "http://arxiv.org/abs/2003.09040",
          "publishedOn": "2022-04-11T00:52:29.028Z",
          "wordCount": 664,
          "title": "TF-Coder: Program Synthesis for Tensor Manipulations. (arXiv:2003.09040v4 [cs.PL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04127",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kakoulidis_P/0/1/0/all/0/1\">Panos Kakoulidis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ellinas_N/0/1/0/all/0/1\">Nikolaos Ellinas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vamvoukakis_G/0/1/0/all/0/1\">Georgios Vamvoukakis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Markopoulos_K/0/1/0/all/0/1\">Konstantinos Markopoulos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sung_J/0/1/0/all/0/1\">June Sig Sung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jho_G/0/1/0/all/0/1\">Gunu Jho</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsiakoulis_P/0/1/0/all/0/1\">Pirros Tsiakoulis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chalamandaris_A/0/1/0/all/0/1\">Aimilios Chalamandaris</a>",
          "description": "Existing singing voice synthesis models (SVS) are usually trained on singing\ndata and depend on either error-prone time-alignment and duration features or\nexplicit music score information. In this paper, we propose Karaoker, a\nmultispeaker Tacotron-based model conditioned on voice characteristic features\nthat is trained exclusively on spoken data without requiring time-alignments.\nKaraoker synthesizes singing voice following a multi-dimensional template\nextracted from a source waveform of an unseen speaker/singer. The model is\njointly conditioned with a single deep convolutional encoder on continuous data\nincluding pitch, intensity, harmonicity, formants, cepstral peak prominence and\noctaves. We extend the text-to-speech training objective with feature\nreconstruction, classification and speaker identification tasks that guide the\nmodel to an accurate result. Except for multi-tasking, we also employ a\nWasserstein GAN training scheme as well as new losses on the acoustic model's\noutput to further refine the quality of the model.",
          "link": "http://arxiv.org/abs/2204.04127",
          "publishedOn": "2022-04-11T00:52:29.008Z",
          "wordCount": 598,
          "title": "Karaoker: Alignment-free singing voice synthesis with speech training data. (arXiv:2204.04127v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00464",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_C/0/1/0/all/0/1\">Chris Junchi Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Loizou_N/0/1/0/all/0/1\">Nicolas Loizou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>, <a href=\"http://arxiv.org/find/math/1/au:+Roux_N/0/1/0/all/0/1\">Nicolas Le Roux</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We study the stochastic bilinear minimax optimization problem, presenting an\nanalysis of the same-sample Stochastic ExtraGradient (SEG) method with constant\nstep size, and presenting variations of the method that yield favorable\nconvergence. In sharp contrasts with the basic SEG method whose last iterate\nonly contracts to a fixed neighborhood of the Nash equilibrium, SEG augmented\nwith iteration averaging provably converges to the Nash equilibrium under the\nsame standard settings, and such a rate is further improved by incorporating a\nscheduled restarting procedure. In the interpolation setting where noise\nvanishes at the Nash equilibrium, we achieve an optimal convergence rate up to\ntight constants. We present numerical experiments that validate our theoretical\nfindings and demonstrate the effectiveness of the SEG method when equipped with\niteration averaging and restarting.",
          "link": "http://arxiv.org/abs/2107.00464",
          "publishedOn": "2022-04-11T00:52:28.995Z",
          "wordCount": 647,
          "title": "On the Convergence of Stochastic Extragradient for Bilinear Games using Restarted Iteration Averaging. (arXiv:2107.00464v4 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04054",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Blank_J/0/1/0/all/0/1\">Julian Blank</a>, <a href=\"http://arxiv.org/find/math/1/au:+Deb_K/0/1/0/all/0/1\">Kalyanmoy Deb</a>",
          "description": "Significant effort has been made to solve computationally expensive\noptimization problems in the past two decades, and various optimization methods\nincorporating surrogates into optimization have been proposed. Most research\nfocuses on either exploiting the surrogate by defining a utility optimization\nproblem or customizing an existing optimization method to use one or multiple\napproximation models. However, only a little attention has been paid to generic\nconcepts applicable to different types of algorithms and optimization problems\nsimultaneously. Thus this paper proposes a generalized probabilistic\nsurrogate-assisted framework (GPSAF), applicable to a broad category of\nunconstrained and constrained, single- and multi-objective optimization\nalgorithms. The idea is based on a surrogate assisting an existing optimization\nmethod. The assistance is based on two distinct phases, one facilitating\nexploration and another exploiting the surrogates. The exploration and\nexploitation of surrogates are automatically balanced by performing a\nprobabilistic knockout tournament among different clusters of solutions. A\nstudy of multiple well-known population-based optimization algorithms is\nconducted with and without the proposed surrogate assistance on single- and\nmulti-objective optimization problems with a maximum solution evaluation budget\nof 300 or less. The results indicate the effectiveness of applying GPSAF to an\noptimization algorithm and the competitiveness with other surrogate-assisted\nalgorithms.",
          "link": "http://arxiv.org/abs/2204.04054",
          "publishedOn": "2022-04-11T00:52:28.988Z",
          "wordCount": 645,
          "title": "GPSAF: A Generalized Probabilistic Surrogate-Assisted Framework for Constrained Single- and Multi-objective Optimization. (arXiv:2204.04054v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Araujo_P/0/1/0/all/0/1\">Pedro Henrique Luz de Araujo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1\">Benjamin Roth</a>",
          "description": "Behavioural testing -- verifying system capabilities by validating\nhuman-designed input-output pairs -- is an alternative evaluation method of\nnatural language processing systems proposed to address the shortcomings of the\nstandard approach: computing metrics on held-out data. While behavioural tests\ncapture human prior knowledge and insights, there has been little exploration\non how to leverage them for model training and development. With this in mind,\nwe explore behaviour-aware learning by examining several fine-tuning schemes\nusing HateCheck, a suite of functional tests for hate speech detection systems.\nTo address potential pitfalls of training on data originally intended for\nevaluation, we train and evaluate models on different configurations of\nHateCheck by holding out categories of test cases, which enables us to estimate\nperformance on potentially overlooked system properties. The fine-tuning\nprocedure led to improvements in the classification accuracy of held-out\nfunctionalities and identity groups, suggesting that models can potentially\ngeneralise to overlooked functionalities. However, performance on held-out\nfunctionality classes and i.i.d. hate speech detection data decreased, which\nindicates that generalisation occurs mostly across functionalities from the\nsame class and that the procedure led to overfitting to the HateCheck data\ndistribution.",
          "link": "http://arxiv.org/abs/2204.04042",
          "publishedOn": "2022-04-11T00:52:28.970Z",
          "wordCount": 643,
          "title": "Checking HateCheck: a cross-functional analysis of behaviour-aware learning for hate speech detection. (arXiv:2204.04042v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.00632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pauli_P/0/1/0/all/0/1\">Patricia Pauli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funcke_N/0/1/0/all/0/1\">Niklas Funcke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gramlich_D/0/1/0/all/0/1\">Dennis Gramlich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Msalmi_M/0/1/0/all/0/1\">Mohamed Amine Msalmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allgower_F/0/1/0/all/0/1\">Frank Allg&#xf6;wer</a>",
          "description": "This paper is concerned with the training of neural networks (NNs) under\nsemidefinite constraints, which allows for NN training with robustness and\nstability guarantees. In particular, we set up an efficient and scalable\ntraining scheme for NN training problems of this kind based on interior point\nmethods, while we also exploit the structure of the underlying matrix\nconstraint. We apply our training scheme to several relevant examples that have\nbeen studied in the literature and newly present the application of the method\nto the training of Wasserstein generative adversarial networks (WGANs). In\nnumerical examples, we show the superiority of our method and its applicability\nto WGAN training.",
          "link": "http://arxiv.org/abs/2201.00632",
          "publishedOn": "2022-04-11T00:52:28.958Z",
          "wordCount": null,
          "title": "Neural network training under semidefinite constraints. (arXiv:2201.00632v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.09962",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pegoraro_M/0/1/0/all/0/1\">Marco Pegoraro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uysal_M/0/1/0/all/0/1\">Merih Seran Uysal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgi_D/0/1/0/all/0/1\">David Benedikt Georgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aalst_W/0/1/0/all/0/1\">Wil M.P. van der Aalst</a>",
          "description": "The real-time prediction of business processes using historical event data is\nan important capability of modern business process monitoring systems. Existing\nprocess prediction methods are able to also exploit the data perspective of\nrecorded events, in addition to the control-flow perspective. However, while\nwell-structured numerical or categorical attributes are considered in many\nprediction techniques, almost no technique is able to utilize text documents\nwritten in natural language, which can hold information critical to the\nprediction task. In this paper, we illustrate the design, implementation, and\nevaluation of a novel text-aware process prediction model based on Long\nShort-Term Memory (LSTM) neural networks and natural language models. The\nproposed model can take categorical, numerical and textual attributes in event\ndata into account to predict the activity and timestamp of the next event, the\noutcome, and the cycle time of a running process instance. Experiments show\nthat the text-aware model is able to outperform state-of-the-art process\nprediction methods on simulated and real-world event logs containing textual\ndata.",
          "link": "http://arxiv.org/abs/2104.09962",
          "publishedOn": "2022-04-11T00:52:28.957Z",
          "wordCount": null,
          "title": "Text-Aware Predictive Monitoring of Business Processes. (arXiv:2104.09962v2 [cs.AI] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.02571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ivanov_D/0/1/0/all/0/1\">Dmitry Ivanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiselev_M/0/1/0/all/0/1\">Mikhail Kiselev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larionov_D/0/1/0/all/0/1\">Denis Larionov</a>",
          "description": "This article proposes a sparse computation-based method for optimizing neural\nnetworks for reinforcement learning (RL) tasks. This method combines two ideas:\nneural network pruning and taking into account input data correlations; it\nmakes it possible to update neuron states only when changes in them exceed a\ncertain threshold. It significantly reduces the number of multiplications when\nrunning neural networks. We tested different RL tasks and achieved 20-150x\nreduction in the number of multiplications. There were no substantial\nperformance losses; sometimes the performance even improved.",
          "link": "http://arxiv.org/abs/2201.02571",
          "publishedOn": "2022-04-11T00:52:28.956Z",
          "wordCount": null,
          "title": "Neural Network Optimization for Reinforcement Learning Tasks Using Sparse Computations. (arXiv:2201.02571v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yikai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaoling Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_M/0/1/0/all/0/1\">Mayank Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1\">Dimitris Metaxas</a>",
          "description": "The adversarial risk of a machine learning model has been widely studied.\nMost previous works assume that the data lies in the whole ambient space. We\npropose to take a new angle and take the manifold assumption into\nconsideration. Assuming data lies in a manifold, we investigate two new types\nof adversarial risk, the normal adversarial risk due to perturbation along\nnormal direction, and the in-manifold adversarial risk due to perturbation\nwithin the manifold. We prove that the classic adversarial risk can be bounded\nfrom both sides using the normal and in-manifold adversarial risks. We also\nshow with a surprisingly pessimistic case that the standard adversarial risk\ncan be nonzero even when both normal and in-manifold risks are zero. We\nfinalize the paper with empirical studies supporting our theoretical results.\nOur results suggest the possibility of improving the robustness of a classifier\nby only focusing on the normal adversarial risk.",
          "link": "http://arxiv.org/abs/2203.13277",
          "publishedOn": "2022-04-11T00:52:28.956Z",
          "wordCount": null,
          "title": "A Manifold View of Adversarial Risk. (arXiv:2203.13277v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.00604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rabadan_M/0/1/0/all/0/1\">Miquel Mart&#xed; i Rabad&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bujwid_S/0/1/0/all/0/1\">Sebastian Bujwid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pieropan_A/0/1/0/all/0/1\">Alessandro Pieropan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizpour_H/0/1/0/all/0/1\">Hossein Azizpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maki_A/0/1/0/all/0/1\">Atsuto Maki</a>",
          "description": "Most semi-supervised learning methods over-sample labeled data when\nconstructing training mini-batches. This paper studies whether this common\npractice improves learning and how. We compare it to an alternative setting\nwhere each mini-batch is uniformly sampled from all the training data, labeled\nor not, which greatly reduces direct supervision from true labels in typical\nlow-label regimes. However, this simpler setting can also be seen as more\ngeneral and even necessary in multi-task problems where over-sampling labeled\ndata would become intractable. Our experiments on semi-supervised CIFAR-10\nimage classification using FixMatch show a performance drop when using the\nuniform sampling approach which diminishes when the amount of labeled data or\nthe training time increases. Further, we analyse the training dynamics to\nunderstand how over-sampling of labeled data compares to uniform sampling. Our\nmain finding is that over-sampling is especially beneficial early in training\nbut gets less important in the later stages when more pseudo-labels become\ncorrect. Nevertheless, we also find that keeping some true labels remains\nimportant to avoid the accumulation of confirmation errors from incorrect\npseudo-labels.",
          "link": "http://arxiv.org/abs/2201.00604",
          "publishedOn": "2022-04-11T00:52:28.955Z",
          "wordCount": null,
          "title": "An analysis of over-sampling labeled data in semi-supervised learning with FixMatch. (arXiv:2201.00604v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.14009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sigaud_O/0/1/0/all/0/1\">Olivier Sigaud</a>",
          "description": "Deep neuroevolution and deep Reinforcement Learning have received a lot of\nattention in the last years. Some works have compared them, highlighting theirs\npros and cons, but an emerging trend consists in combining them so as to\nbenefit from the best of both worlds. In this paper, we provide a survey of\nthis emerging trend by organizing the literature into related groups of works\nand casting all the existing combinations in each group into a generic\nframework. We systematically cover all easily available papers irrespective of\ntheir publication status, focusing on the combination mechanisms rather than on\nthe experimental results. In total, we cover 45 algorithms more recent than\n2017. We hope this effort will favor the growth of the domain by facilitating\nthe understanding of the relationships between the methods, leading to deeper\nanalyses, outlining missing useful comparisons and suggesting new combinations\nof mechanisms.",
          "link": "http://arxiv.org/abs/2203.14009",
          "publishedOn": "2022-04-11T00:52:28.954Z",
          "wordCount": null,
          "title": "Combining Evolution and Deep Reinforcement Learning for Policy Search: a Survey. (arXiv:2203.14009v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu-Rong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_S/0/1/0/all/0/1\">Sheng Yen Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shan-Hung Wu</a>",
          "description": "The recent development of Generative adversarial networks (GANs) has driven\nmany computer vision applications. Despite the great synthesis quality,\ntraining GANs often confronts several issues, including non-convergence, mode\ncollapse, and gradient vanishing. There exist several workarounds, for example,\nregularizing Lipschitz continuity and adopting Wasserstein distance. Although\nthese methods can partially solve the problems, we argue that the problems are\nresult from modeling the discriminator with deep neural networks. In this\npaper, we base on newly derived deep neural network theories called Neural\nTangent Kernel (NTK) and propose a new generative algorithm called generative\nadversarial NTK (GA-NTK). The GA-NTK models the discriminator as a Gaussian\nProcess (GP). With the help of the NTK theories, the training dynamics of\nGA-NTK can be described with a closed-form formula. To synthesize data with the\nclosed-form formula, the objectives can be simplified into a single-level\nadversarial optimization problem. We conduct extensive experiments on\nreal-world datasets, and the results show that GA-NTK can generate images\ncomparable to those by GANs but is much easier to train under various\nconditions. We also study the current limitations of GA-NTK and propose some\nworkarounds to make GA-NTK more practical.",
          "link": "http://arxiv.org/abs/2204.04090",
          "publishedOn": "2022-04-11T00:52:28.943Z",
          "wordCount": 613,
          "title": "Generative Adversarial Method Based On Neural Tangent Kernels. (arXiv:2204.04090v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guangyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tatti_N/0/1/0/all/0/1\">Nikolaj Tatti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gionis_A/0/1/0/all/0/1\">Aristides Gionis</a>",
          "description": "Submodular maximization has been the backbone of many important\nmachine-learning problems, and has applications to viral marketing,\ndiversification, sensor placement, and more. However, the study of maximizing\nsubmodular functions has mainly been restricted in the context of selecting a\nset of items. On the other hand, many real-world applications require a\nsolution that is a ranking over a set of items. The problem of ranking in the\ncontext of submodular function maximization has been considered before, but to\na much lesser extent than item-selection formulations. In this paper, we\nexplore a novel formulation for ranking items with submodular valuations and\nbudget constraints. We refer to this problem as max-submodular ranking (MSR).\nIn more detail, given a set of items and a set of non-decreasing submodular\nfunctions, where each function is associated with a budget, we aim to find a\nranking of the set of items that maximizes the sum of values achieved by all\nfunctions under the budget constraints. For the MSR problem with cardinality-\nand knapsack-type budget constraints we propose practical algorithms with\napproximation guarantees. In addition, we perform an empirical evaluation,\nwhich demonstrates the superior performance of the proposed algorithms against\nstrong baselines.",
          "link": "http://arxiv.org/abs/2204.04168",
          "publishedOn": "2022-04-11T00:52:28.935Z",
          "wordCount": 624,
          "title": "Ranking with submodular functions on a budget. (arXiv:2204.04168v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.00246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1\">Hong Jun Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Deep learning has proven effective across a range of data sets. In light of\nthis, a natural inquiry is: \"for what data generating processes can deep\nlearning succeed?\" In this work, we study the sample complexity of learning\nmultilayer data generating processes of a sort for which deep neural networks\nseem to be suited. We develop general and elegant information-theoretic tools\nthat accommodate analysis of any data generating process -- shallow or deep,\nparametric or nonparametric, noiseless or noisy. We then use these tools to\ncharacterize the dependence of sample complexity on the depth of multilayer\nprocesses. Our results indicate roughly linear dependence on depth. This is in\ncontrast to previous results that suggest exponential or high-order polynomial\ndependence.",
          "link": "http://arxiv.org/abs/2203.00246",
          "publishedOn": "2022-04-11T00:52:28.927Z",
          "wordCount": null,
          "title": "Sample Complexity versus Depth: An Information Theoretic Analysis. (arXiv:2203.00246v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05224",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bagdasaryan_E/0/1/0/all/0/1\">Eugene Bagdasaryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmatikov_V/0/1/0/all/0/1\">Vitaly Shmatikov</a>",
          "description": "We investigate a new threat to neural sequence-to-sequence (seq2seq) models:\ntraining-time attacks that cause models to \"spin\" their outputs so as to\nsupport an adversary-chosen sentiment or point of view -- but only when the\ninput contains adversary-chosen trigger words. For example, a spinned\nsummarization model outputs positive summaries of any text that mentions the\nname of some individual or organization.\n\nModel spinning introduces a \"meta-backdoor\" into a model. Whereas\nconventional backdoors cause models to produce incorrect outputs on inputs with\nthe trigger, outputs of spinned models preserve context and maintain standard\naccuracy metrics, yet also satisfy a meta-task chosen by the adversary.\n\nModel spinning enables propaganda-as-a-service, where propaganda is defined\nas biased speech. An adversary can create customized language models that\nproduce desired spins for chosen triggers, then deploy these models to generate\ndisinformation (a platform attack), or else inject them into ML training\npipelines (a supply-chain attack), transferring malicious functionality to\ndownstream models trained by victims.\n\nTo demonstrate the feasibility of model spinning, we develop a new\nbackdooring technique. It stacks an adversarial meta-task onto a seq2seq model,\nbackpropagates the desired meta-task output to points in the word-embedding\nspace we call \"pseudo-words,\" and uses pseudo-words to shift the entire output\ndistribution of the seq2seq model. We evaluate this attack on language\ngeneration, summarization, and translation models with different triggers and\nmeta-tasks such as sentiment, toxicity, and entailment. Spinned models largely\nmaintain their accuracy metrics (ROUGE and BLEU) while shifting their outputs\nto satisfy the adversary's meta-task. We also show that, in the case of a\nsupply-chain attack, the spin functionality transfers to downstream models.",
          "link": "http://arxiv.org/abs/2112.05224",
          "publishedOn": "2022-04-11T00:52:28.924Z",
          "wordCount": null,
          "title": "Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures. (arXiv:2112.05224v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.00734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiqiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1\">Xin Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>",
          "description": "There is a growing interest in applying machine learning techniques for\nhealthcare. Recently, federated machine learning (FL) is gaining popularity\nsince it allows researchers to train powerful models without compromising data\nprivacy and security. However, the performance of existing FL approaches often\ndeteriorates when encountering non-iid situations where there exist\ndistribution gaps among clients, and few previous efforts focus on\npersonalization in healthcare. In this article, we propose AdaFed to tackle\ndomain shifts and obtain personalized models for local clients. AdaFed learns\nthe similarity between clients via the statistics of the batch normalization\nlayers while preserving the specificity of each client with different local\nbatch normalization. Comprehensive experiments on five healthcare benchmarks\ndemonstrate that AdaFed achieves better accuracy compared to state-of-the-art\nmethods (e.g., \\textbf{10}\\%+ accuracy improvement for PAMAP2) with faster\nconvergence speed.",
          "link": "http://arxiv.org/abs/2112.00734",
          "publishedOn": "2022-04-11T00:52:28.917Z",
          "wordCount": null,
          "title": "Federated Learning with Adaptive Batchnorm for Personalized Healthcare. (arXiv:2112.00734v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.09120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_M/0/1/0/all/0/1\">Mohit Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modi_S/0/1/0/all/0/1\">Sahil Modi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_R/0/1/0/all/0/1\">Rishabh Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Saurabh Gupta</a>",
          "description": "Interactive object understanding, or what we can do to objects and how is a\nlong-standing goal of computer vision. In this paper, we tackle this problem\nthrough observation of human hands in in-the-wild egocentric videos. We\ndemonstrate that observation of what human hands interact with and how can\nprovide both the relevant data and the necessary supervision. Attending to\nhands, readily localizes and stabilizes active objects for learning and reveals\nplaces where interactions with objects occur. Analyzing the hands shows what we\ncan do to objects and how. We apply these basic principles on the EPIC-KITCHENS\ndataset, and successfully learn state-sensitive features, and object\naffordances (regions of interaction and afforded grasps), purely by observing\nhands in egocentric videos.",
          "link": "http://arxiv.org/abs/2112.09120",
          "publishedOn": "2022-04-11T00:52:28.917Z",
          "wordCount": null,
          "title": "Human Hands as Probes for Interactive Object Understanding. (arXiv:2112.09120v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11439",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Han_T/0/1/0/all/0/1\">Tianyu Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kather_J/0/1/0/all/0/1\">Jakob Nikolas Kather</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pedersoli_F/0/1/0/all/0/1\">Federico Pedersoli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zimmermann_M/0/1/0/all/0/1\">Markus Zimmermann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Keil_S/0/1/0/all/0/1\">Sebastian Keil</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schulze_Hagen_M/0/1/0/all/0/1\">Maximilian Schulze-Hagen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Terwoelbeck_M/0/1/0/all/0/1\">Marc Terwoelbeck</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Isfort_P/0/1/0/all/0/1\">Peter Isfort</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Haarburger_C/0/1/0/all/0/1\">Christoph Haarburger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiessling_F/0/1/0/all/0/1\">Fabian Kiessling</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schulz_V/0/1/0/all/0/1\">Volkmar Schulz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kuhl_C/0/1/0/all/0/1\">Christiane Kuhl</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nebelung_S/0/1/0/all/0/1\">Sven Nebelung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Truhn_D/0/1/0/all/0/1\">Daniel Truhn</a>",
          "description": "Disease-modifying management aims to prevent deterioration and progression of\nthe disease, not just relieve symptoms. Unfortunately, the development of\nnecessary therapies is often hampered by the failure to recognize the\npresymptomatic disease and limited understanding of disease development. We\npresent a generic solution for this problem by a methodology that allows the\nprediction of progression risk and morphology in individuals using a latent\nextrapolation optimization approach. To this end, we combined a regularized\ngenerative adversarial network (GAN) and a latent nearest neighbor algorithm\nfor joint optimization to generate plausible images of future time points. We\nevaluated our method on osteoarthritis (OA) data from a multi-center\nlongitudinal study (the Osteoarthritis Initiative, OAI). With presymptomatic\nbaseline data, our model is generative and significantly outperforms the\nend-to-end learning model in discriminating the progressive cohort. Two\nexperiments were performed with seven experienced radiologists. When no\nsynthetic follow-up radiographs were provided, our model performed better than\nall seven radiologists. In cases where the synthetic follow-ups generated by\nour model were available, the specificity and sensitivity of all readers in\ndiscriminating progressors increased from $72.3\\%$ to $88.6\\%$ and from\n$42.1\\%$ to $51.6\\%$, respectively. Our results open up a new possibility of\nusing model-based morphology and risk prediction to make predictions about\nfuture disease occurrence, as demonstrated in the example of OA.",
          "link": "http://arxiv.org/abs/2111.11439",
          "publishedOn": "2022-04-11T00:52:28.915Z",
          "wordCount": null,
          "title": "Image prediction of disease progression by style-based manifold extrapolation. (arXiv:2111.11439v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.05267",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yuchen Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hou_N/0/1/0/all/0/1\">Nana Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chng_E/0/1/0/all/0/1\">Eng Siong Chng</a>",
          "description": "Speech enhancement (SE) aims to suppress the additive noise from a noisy\nspeech signal to improve the speech's perceptual quality and intelligibility.\nHowever, the over-suppression phenomenon in the enhanced speech might degrade\nthe performance of downstream automatic speech recognition (ASR) task due to\nthe missing latent information. To alleviate such problem, we propose an\ninteractive feature fusion network (IFF-Net) for noise-robust speech\nrecognition to learn complementary information from the enhanced feature and\noriginal noisy feature. Experimental results show that the proposed method\nachieves absolute word error rate (WER) reduction of 4.1% over the best\nbaseline on RATS Channel-A corpus. Our further analysis indicates that the\nproposed IFF-Net can complement some missing information in the over-suppressed\nenhanced feature.",
          "link": "http://arxiv.org/abs/2110.05267",
          "publishedOn": "2022-04-11T00:52:28.912Z",
          "wordCount": null,
          "title": "Interactive Feature Fusion for End-to-End Noise-Robust Speech Recognition. (arXiv:2110.05267v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.04888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Cameron Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Christopher Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasuda_T/0/1/0/all/0/1\">Taisuke Yasuda</a>",
          "description": "We study active sampling algorithms for linear regression, which aim to query\nonly a few entries of a target vector $b\\in\\mathbb R^n$ and output a near\nminimizer to $\\min_{x\\in\\mathbb R^d} \\|Ax-b\\|$, for a design matrix\n$A\\in\\mathbb R^{n \\times d}$ and loss $\\|\\cdot\\|$.\n\nFor $p$ norm regression for any $0<p<\\infty$, we give an algorithm based on\nLewis weight sampling outputting a $(1+\\epsilon)$-approximate solution using\njust $\\tilde O(d/\\epsilon^2)$ queries to $b$ for $p\\in(0,1)$,\n$\\tilde{O}(d/\\epsilon)$ queries for $1<p<2$, and\n$\\tilde{O}(d^{p/2}/\\epsilon^p)$ queries for $2<p<\\infty$. For $0<p<2$, our\nbounds are optimal up to log factors, settling the query complexity for this\nrange. For $2<p<\\infty$, our dependence on $d$ is optimal, while our dependence\non $\\epsilon$ is off by at most $\\epsilon$, up to log factors. Our result\nresolves an open question of [CD21], who gave near optimal bounds for the $1$\nnorm, but required $d^2/\\epsilon^2$ samples for $\\ell_p$ regression with\n$1<p<2$, and gave no bounds for $2<p<\\infty$ or $0<p<1$.\n\nWe also give the first total sensitivity bound of\n$O(d^{\\max\\{1,p/2\\}}\\log^2n)$ for loss functions of degree $p$ polynomial\ngrowth, improving a result of [TMF20]. By combining this with our techniques\nfor $\\ell_p$ regression, we obtain an active regression algorithm making\n$\\tilde O(d^{1+\\max\\{1,p/2\\}}/\\mathrm{poly}(\\epsilon))$ queries for such loss\nfunctions, including the Tukey and Huber losses, answering another question of\n[CD21]. For the Huber loss, we further improve our bound to $\\tilde\nO(d^{4-2\\sqrt2}/\\mathrm{poly}(\\epsilon))$ samples. Our sensitivity bounds also\nhave many applications, including Orlicz norm subspace embeddings, robust\nsubspace approximation, and dimension reduction for smoothed $p$-norms.\n\nFinally, our active sampling results give the first sublinear time algorithms\nfor Kronecker product regression under every $p$ norm.",
          "link": "http://arxiv.org/abs/2111.04888",
          "publishedOn": "2022-04-11T00:52:28.908Z",
          "wordCount": null,
          "title": "Active Linear Regression for $\\ell_p$ Norms and Beyond. (arXiv:2111.04888v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nayak_G/0/1/0/all/0/1\">Gaurav Kumar Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawal_R/0/1/0/all/0/1\">Ruchit Rawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1\">Anirban Chakraborty</a>",
          "description": "Deep models are highly susceptible to adversarial attacks. Such attacks are\ncarefully crafted imperceptible noises that can fool the network and can cause\nsevere consequences when deployed. To encounter them, the model requires\ntraining data for adversarial training or explicit regularization-based\ntechniques. However, privacy has become an important concern, restricting\naccess to only trained models but not the training data (e.g. biometric data).\nAlso, data curation is expensive and companies may have proprietary rights over\nit. To handle such situations, we propose a completely novel problem of\n'test-time adversarial defense in absence of training data and even their\nstatistics'. We solve it in two stages: a) detection and b) correction of\nadversarial samples. Our adversarial sample detection framework is initially\ntrained on arbitrary data and is subsequently adapted to the unlabelled test\ndata through unsupervised domain adaptation. We further correct the predictions\non detected adversarial samples by transforming them in Fourier domain and\nobtaining their low frequency component at our proposed suitable radius for\nmodel prediction. We demonstrate the efficacy of our proposed technique via\nextensive experiments against several adversarial attacks and for different\nmodel architectures and datasets. For a non-robust Resnet-18 model pre-trained\non CIFAR-10, our detection method correctly identifies 91.42% adversaries.\nAlso, we significantly improve the adversarial accuracy from 0% to 37.37% with\na minimal drop of 0.02% in clean accuracy on state-of-the-art 'Auto Attack'\nwithout having to retrain the model.",
          "link": "http://arxiv.org/abs/2204.01568",
          "publishedOn": "2022-04-11T00:52:28.908Z",
          "wordCount": null,
          "title": "DAD: Data-free Adversarial Defense at Test Time. (arXiv:2204.01568v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sichen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_J/0/1/0/all/0/1\">Jeffrey Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1\">Flora D. Salim</a>",
          "description": "Disentangled representation learning offers useful properties such as\ndimension reduction and interpretability, which are essential to modern deep\nlearning approaches. Although deep learning techniques have been widely applied\nto spatio-temporal data mining, there has been little attention to further\ndisentangle the latent features and understanding their contribution to the\nmodel performance, particularly their mutual information and correlation across\nfeatures. In this study, we adopt two state-of-the-art disentangled\nrepresentation learning methods and apply them to three large-scale public\nspatio-temporal datasets. To evaluate their performance, we propose an internal\nevaluation metric focusing on the degree of correlations among latent variables\nof the learned representations and the prediction performance of the downstream\ntasks. Empirical results show that our modified method can learn disentangled\nrepresentations that achieve the same level of performance as existing\nstate-of-the-art ST deep learning methods in a spatio-temporal sequence\nforecasting problem. Additionally, we find that our methods can be used to\ndiscover real-world spatial-temporal semantics to describe the variables in the\nlearned representation.",
          "link": "http://arxiv.org/abs/2202.04821",
          "publishedOn": "2022-04-11T00:52:28.906Z",
          "wordCount": null,
          "title": "Measuring disentangled generative spatio-temporal representation. (arXiv:2202.04821v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "The noise transition matrix plays a central role in the problem of learning\nfrom noisy labels. Among many other reasons, a significant number of existing\nsolutions rely on access to it. Estimating the transition matrix without using\nground truth labels is a critical and challenging task. When label noise\ntransition depends on each instance, the problem of identifying the\ninstance-dependent noise transition matrix becomes substantially more\nchallenging. Despite recent works proposing solutions for learning from\ninstance-dependent noisy labels, we lack a unified understanding of when such a\nproblem remains identifiable, and therefore learnable. This paper seeks to\nprovide answers to a sequence of related questions: What are the primary\nfactors that contribute to the identifiability of a noise transition matrix?\nCan we explain the observed empirical successes? When a problem is not\nidentifiable, what can we do to make it so? We will relate our theoretical\nfindings to the literature and hope to provide guidelines for developing\neffective solutions for battling instance-dependent label noise.",
          "link": "http://arxiv.org/abs/2202.02016",
          "publishedOn": "2022-04-11T00:52:28.905Z",
          "wordCount": null,
          "title": "Identifiability of Label Noise Transition Matrix. (arXiv:2202.02016v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xing_D/0/1/0/all/0/1\">Dong Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chenguang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Gang Wang</a>",
          "description": "Ride-hailing service is becoming a leading part in urban transportation. To\nimprove the efficiency of ride-hailing service, accurate prediction of\ntransportation demand is a fundamental challenge. In this paper, we tackle this\nproblem from both aspects of network structure and data-set formulation. For\nnetwork design, we propose a spatial-temporal attention multi-graph convolution\nnetwork (STA-MGCN). A spatial-temporal layer in STA-MGCN is developed to\ncapture the temporal correlations by temporal attention mechanism and temporal\ngate convolution, and the spatial correlations by multigraph convolution. A\nfeature cluster layer is introduced to learn latent regional functions and to\nreduce the computation burden. For the data-set formulation, we develop a novel\napproach which considers the transportation feature of periodicity with offset.\nInstead of only using history data during the same time period, the history\norder demand in forward and backward neighboring time periods from yesterday\nand last week are also included. Extensive experiments on the three real-world\ndatasets of New-York, Chicago and Chengdu show that the proposed algorithm\nachieves the state-of-the-art performance for ride-hailing demand prediction.",
          "link": "http://arxiv.org/abs/2203.12505",
          "publishedOn": "2022-04-11T00:52:28.905Z",
          "wordCount": null,
          "title": "A Spatial-Temporal Attention Multi-Graph Convolution Network for Ride-Hailing Demand Prediction Based on Periodicity with Offset. (arXiv:2203.12505v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.13005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Siddharth Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatele_A/0/1/0/all/0/1\">Abhinav Bhatele</a>",
          "description": "In the last few years, the memory requirements to train state-of-the-art\nneural networks have far exceeded the DRAM capacities of modern hardware\naccelerators. This has necessitated the development of efficient algorithms to\ntrain these neural networks in parallel on large-scale GPU-based clusters.\nSince computation is relatively inexpensive on modern GPUs, designing and\nimplementing extremely efficient communication in these parallel training\nalgorithms is critical for extracting the maximum performance. This paper\npresents AxoNN, a parallel deep learning framework that exploits asynchrony and\nmessage-driven execution to schedule neural network operations on each GPU,\nthereby reducing GPU idle time and maximizing hardware efficiency. By using the\nCPU memory as a scratch space for offloading data periodically during training,\nAxoNN is able to reduce GPU memory consumption by four times. This allows us to\nincrease the number of parameters per GPU by four times, thus reducing the\namount of communication and increasing performance by over 13%. When tested\nagainst large transformer models with 12-100 billion parameters on 48-384\nNVIDIA Tesla V100 GPUs, AxoNN achieves a per-GPU throughput of 49.4-54.78% of\ntheoretical peak and reduces the training time by 22-37 days (15-25% speedup)\nas compared to the state-of-the-art.",
          "link": "http://arxiv.org/abs/2110.13005",
          "publishedOn": "2022-04-11T00:52:28.892Z",
          "wordCount": null,
          "title": "AxoNN: An asynchronous, message-driven parallel framework for extreme-scale deep learning. (arXiv:2110.13005v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.11732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1\">Ruoxuan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koenecke_A/0/1/0/all/0/1\">Allison Koenecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Powell_M/0/1/0/all/0/1\">Michael Powell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "Analyzing observational data from multiple sources can be useful for\nincreasing statistical power to detect a treatment effect; however, practical\nconstraints such as privacy considerations may restrict individual-level\ninformation sharing across data sets. This paper develops federated methods\nthat only utilize summary-level information from heterogeneous data sets. Our\nfederated methods provide doubly-robust point estimates of treatment effects as\nwell as variance estimates. We derive the asymptotic distributions of our\nfederated estimators, which are shown to be asymptotically equivalent to the\ncorresponding estimators from the combined, individual-level data. We show that\nto achieve these properties, federated methods should be adjusted based on\nconditions such as whether models are correctly specified and stable across\nheterogeneous data sets.",
          "link": "http://arxiv.org/abs/2107.11732",
          "publishedOn": "2022-04-11T00:52:28.882Z",
          "wordCount": null,
          "title": "Federated Causal Inference in Heterogeneous Observational Data. (arXiv:2107.11732v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.06329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gerhard_Young_G/0/1/0/all/0/1\">Greyson Gerhard-Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anantha_R/0/1/0/all/0/1\">Raviteja Anantha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chappidi_S/0/1/0/all/0/1\">Srinivas Chappidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffmeister_B/0/1/0/all/0/1\">Bj&#xf6;rn Hoffmeister</a>",
          "description": "Recent work building open-domain chatbots has demonstrated that increasing\nmodel size improves performance. On the other hand, latency and connectivity\nconsiderations dictate the move of digital assistants on the device. Giving a\ndigital assistant like Siri, Alexa, or Google Assistant the ability to discuss\njust about anything leads to the need for reducing the chatbot model size such\nthat it fits on the user's device. We demonstrate that low parameter models can\nsimultaneously retain their general knowledge conversational abilities while\nimproving in a specific domain. Additionally, we propose a generic framework\nthat accounts for variety in question types, tracks reference throughout\nmulti-turn conversations, and removes inconsistent and potentially toxic\nresponses. Our framework seamlessly transitions between chatting and performing\ntransactional tasks, which will ultimately make interactions with digital\nassistants more human-like. We evaluate our framework on 1 internal and 4\npublic benchmark datasets using both automatic (Perplexity) and human (SSA -\nSensibleness and Specificity Average) evaluation metrics and establish\ncomparable performance while reducing model parameters by 90%.",
          "link": "http://arxiv.org/abs/2108.06329",
          "publishedOn": "2022-04-11T00:52:28.881Z",
          "wordCount": null,
          "title": "Low-Resource Adaptation of Open-Domain Generative Chatbots. (arXiv:2108.06329v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.04298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sowmen Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md. Saiful Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amin_M/0/1/0/all/0/1\">Md. Ruhul Amin</a>",
          "description": "Forensic analysis of manipulated pixels requires the identification of\nvarious hidden and subtle features from images. Conventional image recognition\nmodels generally fail at this task because they are biased and more attentive\ntoward the dominant local and spatial features. In this paper, we propose a\nnovel Gated Context Attention Network (GCA-Net) that utilizes non-local\nattention in conjunction with a gating mechanism in order to capture the finer\nimage discrepancies and better identify forged regions. The proposed framework\nuses high dimensional embeddings to filter and aggregate the relevant context\nfrom coarse feature maps at various stages of the decoding process. This\nimproves the network's understanding of global differences and reduces\nfalse-positive localizations. Our evaluation on standard image forensic\nbenchmarks shows that GCA-Net can both compete against and improve over\nstate-of-the-art networks by an average of 4.7% AUC. Additional ablation\nstudies also demonstrate the method's robustness against attributions and\nresilience to false-positive predictions.",
          "link": "http://arxiv.org/abs/2112.04298",
          "publishedOn": "2022-04-11T00:52:28.881Z",
          "wordCount": null,
          "title": "GCA-Net : Utilizing Gated Context Attention for Improving Image Forgery Localization and Detection. (arXiv:2112.04298v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.03097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1\">Cuiling Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_Y/0/1/0/all/0/1\">Yidong Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiqiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>",
          "description": "Machine learning systems generally assume that the training and testing\ndistributions are the same. To this end, a key requirement is to develop models\nthat can generalize to unseen distributions. Domain generalization (DG), i.e.,\nout-of-distribution generalization, has attracted increasing interests in\nrecent years. Domain generalization deals with a challenging setting where one\nor several different but related domain(s) are given, and the goal is to learn\na model that can generalize to an unseen test domain. Great progress has been\nmade in the area of domain generalization for years. This paper presents the\nfirst review of recent advances in this area. First, we provide a formal\ndefinition of domain generalization and discuss several related fields. We then\nthoroughly review the theories related to domain generalization and carefully\nanalyze the theory behind generalization. We categorize recent algorithms into\nthree classes: data manipulation, representation learning, and learning\nstrategy, and present several popular algorithms in detail for each category.\nThird, we introduce the commonly used datasets, applications, and our\nopen-sourced codebase for fair evaluation. Finally, we summarize existing\nliterature and present some potential research topics for the future.",
          "link": "http://arxiv.org/abs/2103.03097",
          "publishedOn": "2022-04-11T00:52:28.873Z",
          "wordCount": null,
          "title": "Generalizing to Unseen Domains: A Survey on Domain Generalization. (arXiv:2103.03097v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.09151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiuniu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wenjia Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingzhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1\">Antoni B. Chan</a>",
          "description": "Describing images using natural language is widely known as image captioning,\nwhich has made consistent progress due to the development of computer vision\nand natural language generation techniques. Though conventional captioning\nmodels achieve high accuracy based on popular metrics, i.e., BLEU, CIDEr, and\nSPICE, the ability of captions to distinguish the target image from other\nsimilar images is under-explored. To generate distinctive captions, a few\npioneers employ contrastive learning or re-weighted the ground-truth captions,\nwhich focuses on one single input image. However, the relationships between\nobjects in a similar image group (e.g., items or properties within the same\nalbum or fine-grained events) are neglected. In this paper, we improve the\ndistinctiveness of image captions using a Group-based Distinctive Captioning\nModel (GdisCap), which compares each image with other images in one similar\ngroup and highlights the uniqueness of each image. In particular, we propose a\ngroup-based memory attention (GMA) module, which stores object features that\nare unique among the image group (i.e., with low similarity to objects in other\nimages). These unique object features are highlighted when generating captions,\nresulting in more distinctive captions. Furthermore, the distinctive words in\nthe ground-truth captions are selected to supervise the language decoder and\nGMA. Finally, we propose a new evaluation metric, distinctive word rate\n(DisWordRate) to measure the distinctiveness of captions. Quantitative results\nindicate that the proposed method significantly improves the distinctiveness of\nseveral baseline models, and achieves the state-of-the-art performance on both\naccuracy and distinctiveness. Results of a user study agree with the\nquantitative evaluation and demonstrate the rationality of the new metric\nDisWordRate.",
          "link": "http://arxiv.org/abs/2108.09151",
          "publishedOn": "2022-04-11T00:52:28.873Z",
          "wordCount": null,
          "title": "Group-based Distinctive Image Captioning with Memory Attention. (arXiv:2108.09151v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00594",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zaiem_S/0/1/0/all/0/1\">Salah Zaiem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1\">Titouan Parcollet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Essid_S/0/1/0/all/0/1\">Slim Essid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heba_A/0/1/0/all/0/1\">Abdel Heba</a>",
          "description": "Through solving pretext tasks, self-supervised learning leverages unlabeled\ndata to extract useful latent representations replacing traditional input\nfeatures in the downstream task. In audio/speech signal processing, a wide\nrange of features where engineered through decades of research efforts. As it\nturns out, learning to predict such features (a.k.a pseudo-labels) has proven\nto be a particularly relevant pretext task, leading to useful self-supervised\nrepresentations which prove to be effective for downstream tasks. However,\nmethods and common practices for combining such pretext tasks for better\nperformance on the downstream task have not been explored and understood\nproperly. In fact, the process relies almost exclusively on a computationally\nheavy experimental procedure, which becomes intractable with the increase of\nthe number of pretext tasks. This paper introduces a method to select a group\nof pretext tasks among a set of candidates. The method we propose estimates\ncalibrated weights for the partial losses corresponding to the considered\npretext tasks during the self-supervised training process. The experiments\nconducted on automatic speech recognition, speaker and emotion recognition\nvalidate our approach, as the groups selected and weighted with our method\nperform better than classic baselines, thus facilitating the selection and\ncombination of relevant pseudo-labels for self-supervised representation\nlearning.",
          "link": "http://arxiv.org/abs/2107.00594",
          "publishedOn": "2022-04-11T00:52:28.872Z",
          "wordCount": null,
          "title": "Pretext Tasks selection for multitask self-supervised speech representation learning. (arXiv:2107.00594v4 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07510",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1\">Yang Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Zhangjie Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jinghan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1\">Mingsheng Long</a>",
          "description": "Learning a generalizable deep model from a few examples in a short time\nremains a major challenge of machine learning, which has impeded its wide\ndeployment to many scenarios. Recent advances reveal that a properly\npre-trained model endows an important property: transferability. A higher\ntransferability of the learned representations indicates a better\ngeneralizability across domains of different distributions (domain\ntransferability), or across tasks of different semantics (task\ntransferability). Transferability has become the key to enable data-efficient\ndeep learning, however, existing pre-training methods focus only on domain\ntransferability while meta-training methods only on task transferability. This\nrestricts their data-efficiency in downstream scenarios of diverging domains\nand tasks. A finding of this paper is that even a tight combination of\npre-training and meta-training cannot achieve both kinds of transferability.\nThis motivates the proposed Omni-Training framework towards data-efficient deep\nlearning. Our first contribution is Omni-Net, a tri-flow architecture. Besides\nthe joint representation flow, Omni-Net introduces two new parallel flows for\npre-training and meta-training, respectively responsible for learning\nrepresentations of domain transferability and task transferability. Omni-Net\ncoordinates the parallel flows by routing them via the joint-flow, making each\ngain the other kind of transferability. Our second contribution is Omni-Loss,\nin which a self-distillation regularization is imposed to enable knowledge\ntransfer across the training process. Omni-Training is a general framework that\naccommodates many existing pre-training and meta-training algorithms. A\nthorough evaluation on cross-task and cross-domain datasets in classification,\nregression and reinforcement learning problems shows that Omni-Training\nconsistently outperforms the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2110.07510",
          "publishedOn": "2022-04-11T00:52:28.872Z",
          "wordCount": null,
          "title": "Omni-Training for Data-Efficient Deep Learning. (arXiv:2110.07510v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.09003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1\">Xianyuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiangyu Zhu</a>",
          "description": "We study the problem of safe offline reinforcement learning (RL), the goal is\nto learn a policy that maximizes long-term reward while satisfying safety\nconstraints given only offline data, without further interaction with the\nenvironment. This problem is more appealing for real world RL applications, in\nwhich data collection is costly or dangerous. Enforcing constraint satisfaction\nis non-trivial, especially in offline settings, as there is a potential large\ndiscrepancy between the policy distribution and the data distribution, causing\nerrors in estimating the value of safety constraints. We show that na\\\"ive\napproaches that combine techniques from safe RL and offline RL can only learn\nsub-optimal solutions. We thus develop a simple yet effective algorithm,\nConstraints Penalized Q-Learning (CPQ), to solve the problem. Our method admits\nthe use of data generated by mixed behavior policies. We present a theoretical\nanalysis and demonstrate empirically that our approach can learn robustly\nacross a variety of benchmark control tasks, outperforming several baselines.",
          "link": "http://arxiv.org/abs/2107.09003",
          "publishedOn": "2022-04-11T00:52:28.871Z",
          "wordCount": null,
          "title": "Constraints Penalized Q-learning for Safe Offline Reinforcement Learning. (arXiv:2107.09003v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.08463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cioba_A/0/1/0/all/0/1\">Alexandru Cioba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bromberg_M/0/1/0/all/0/1\">Michael Bromberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niyogi_R/0/1/0/all/0/1\">Ritwik Niyogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1\">Georgios Batzolis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_J/0/1/0/all/0/1\">Jezabel Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernacchia_A/0/1/0/all/0/1\">Alberto Bernacchia</a>",
          "description": "Meta-learning models transfer the knowledge acquired from previous tasks to\nquickly learn new ones. They are trained on benchmarks with a fixed number of\ndata points per task. This number is usually arbitrary and it is unknown how it\naffects performance at testing. Since labelling of data is expensive, finding\nthe optimal allocation of labels across training tasks may reduce costs. Given\na fixed budget of labels, should we use a small number of highly labelled\ntasks, or many tasks with few labels each? Should we allocate more labels to\nsome tasks and less to others? We show that: 1) If tasks are homogeneous, there\nis a uniform optimal allocation, whereby all tasks get the same amount of data;\n2) At fixed budget, there is a trade-off between number of tasks and number of\ndata points per task, with a unique solution for the optimum; 3) When trained\nseparately, harder task should get more data, at the cost of a smaller number\nof tasks; 4) When training on a mixture of easy and hard tasks, more data\nshould be allocated to easy tasks. Interestingly, Neuroscience experiments have\nshown that human visual skills also transfer better from easy tasks. We prove\nthese results mathematically on mixed linear regression, and we show\nempirically that the same results hold for few-shot image classification on\nCIFAR-FS and mini-ImageNet. Our results provide guidance for allocating labels\nacross tasks when collecting data for meta-learning.",
          "link": "http://arxiv.org/abs/2103.08463",
          "publishedOn": "2022-04-11T00:52:28.781Z",
          "wordCount": null,
          "title": "How to distribute data across tasks for meta-learning?. (arXiv:2103.08463v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04017",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Mensa_S/0/1/0/all/0/1\">Stefano Mensa</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sahin_E/0/1/0/all/0/1\">Emre Sahin</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tacchino_F/0/1/0/all/0/1\">Francesco Tacchino</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Barkoutsos_P/0/1/0/all/0/1\">Panagiotis Kl. Barkoutsos</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tavernelli_I/0/1/0/all/0/1\">Ivano Tavernelli</a>",
          "description": "Machine Learning (ML) for Ligand Based Virtual Screening (LB-VS) is an\nimportant in-silico tool for discovering new drugs in a faster and\ncost-effective manner, especially for emerging diseases such as COVID-19. In\nthis paper, we propose a general-purpose framework combining a classical\nSupport Vector Classifier (SVC) algorithm with quantum kernel estimation for\nLB-VS on real-world databases, and we argue in favor of its prospective quantum\nadvantage. Indeed, we heuristically prove that our quantum integrated workflow\ncan, at least in some relevant instances, provide a tangible advantage compared\nto state-of-art classical algorithms operating on the same datasets, showing\nstrong dependence on target and features selection method. Finally, we test our\nalgorithm on IBM Quantum processors using ADRB2 and COVID-19 datasets, showing\nthat hardware simulations provide results in line with the predicted\nperformances and can surpass classical equivalents.",
          "link": "http://arxiv.org/abs/2204.04017",
          "publishedOn": "2022-04-11T00:52:28.779Z",
          "wordCount": null,
          "title": "Quantum Machine Learning Framework for Virtual Screening in Drug Discovery: a Prospective Quantum Advantage. (arXiv:2204.04017v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenqian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shangbin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zilong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1\">Zhenyu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Minnan Luo</a>",
          "description": "Political perspective detection has become an increasingly important task\nthat can help combat echo chambers and political polarization. Previous\napproaches generally focus on leveraging textual content to identify stances,\nwhile they fail to reason with background knowledge or leverage the rich\nsemantic and syntactic textual labels in news articles. In light of these\nlimitations, we propose KCD, a political perspective detection approach to\nenable multi-hop knowledge reasoning and incorporate textual cues as\nparagraph-level labels. Specifically, we firstly generate random walks on\nexternal knowledge graphs and infuse them with news text representations. We\nthen construct a heterogeneous information network to jointly model news\ncontent as well as semantic, syntactic and entity cues in news articles.\nFinally, we adopt relational graph neural networks for graph-level\nrepresentation learning and conduct political perspective detection. Extensive\nexperiments demonstrate that our approach outperforms state-of-the-art methods\non two benchmark datasets. We further examine the effect of knowledge walks and\ntextual cues and how they contribute to our approach's data efficiency.",
          "link": "http://arxiv.org/abs/2204.04046",
          "publishedOn": "2022-04-11T00:52:28.778Z",
          "wordCount": null,
          "title": "KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media. (arXiv:2204.04046v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_D/0/1/0/all/0/1\">Deqing Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xiuju Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiao Feng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wanbing Zhang</a>",
          "description": "Given the trend of digitization and increasing number of maritime transport,\nprediction of vessel berth stay has been triggered for requirements of\noperation research and scheduling optimization problem in the era of maritime\nbig data, which takes a significant part in port efficiency and maritime\nlogistics enhancement. This study proposes a systematic and dynamic approach of\npredicting berth stay for tanker terminals. The approach covers three\ninnovative aspects: 1) Data source employed is multi-faceted, including cargo\noperation data from tanker terminals, time-series data from automatic\nidentification system (AIS), etc. 2) The process of berth stay is decomposed\ninto multiple blocks according to data analysis and information extraction\ninnovatively, and practical operation scenarios are also developed accordingly.\n3) The predictive models of berth stay are developed on the basis of prior data\nanalysis and information extraction under two methods, including regression and\ndecomposed distribution. The models are evaluated under four dynamic scenarios\nwith certain designated cargoes among two different terminals. The evaluation\nresults show that the proposed approach can predict berth stay with the\naccuracy up to 98.81% validated by historical baselines, and also demonstrate\nthe proposed approach has dynamic capability of predicting berth stay among the\nscenarios. The model may be potentially applied for short-term pilot-booking or\nscheduling optimizations within a reasonable time frame for advancement of port\nintelligence and logistics efficiency.",
          "link": "http://arxiv.org/abs/2204.04085",
          "publishedOn": "2022-04-11T00:52:28.778Z",
          "wordCount": null,
          "title": "Predicting Berth Stay for Tanker Terminals: A Systematic and Dynamic Approach. (arXiv:2204.04085v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qilong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_S/0/1/0/all/0/1\">Shibei Xue</a>",
          "description": "Federated learning protects data privacy and security by exchanging models\ninstead of data. However, unbalanced data distributions among participating\nclients compromise the accuracy and convergence speed of federated learning\nalgorithms. To alleviate this problem, unlike previous studies that limit the\ndistance of updates for local models, we propose global-update-guided federated\nlearning (FedGG), which introduces a model-cosine loss into local objective\nfunctions, so that local models can fit local data distributions under the\nguidance of update directions of global models. Furthermore, considering that\nthe update direction of a global model is informative in the early stage of\ntraining, we propose adaptive loss weights based on the update distances of\nlocal models. Numerical simulations show that, compared with other advanced\nalgorithms, FedGG has a significant improvement on model convergence accuracies\nand speeds. Additionally, compared with traditional fixed loss weights,\nadaptive loss weights enable our algorithm to be more stable and easier to\nimplement in practice.",
          "link": "http://arxiv.org/abs/2204.03920",
          "publishedOn": "2022-04-11T00:52:28.774Z",
          "wordCount": null,
          "title": "Global Update Guided Federated Learning. (arXiv:2204.03920v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Portisch_J/0/1/0/all/0/1\">Jan Portisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_G/0/1/0/all/0/1\">Guilherme Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefani_K/0/1/0/all/0/1\">Karolin Stefani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreplin_K/0/1/0/all/0/1\">Katharina Kreplin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hladik_M/0/1/0/all/0/1\">Michael Hladik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1\">Heiko Paulheim</a>",
          "description": "Ontology matching is a core task when creating interoperable and linked open\ndatasets. In this paper, we explore a novel structure-based mapping approach\nwhich is based on knowledge graph embeddings: The ontologies to be matched are\nembedded, and an approach known as absolute orientation is used to align the\ntwo embedding spaces. Next to the approach, the paper presents a first,\npreliminary evaluation using synthetic and real-world datasets. We find in\nexperiments with synthetic data, that the approach works very well on similarly\nstructured graphs; it handles alignment noise better than size and structural\ndifferences in the ontologies.",
          "link": "http://arxiv.org/abs/2204.04040",
          "publishedOn": "2022-04-11T00:52:28.770Z",
          "wordCount": null,
          "title": "Ontology Matching Through Absolute Orientation of Embedding Spaces. (arXiv:2204.04040v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dissen_Y/0/1/0/all/0/1\">Yehoshua Dissen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreuk_F/0/1/0/all/0/1\">Felix Kreuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keshet_J/0/1/0/all/0/1\">Joseph Keshet</a>",
          "description": "Over the last few years, deep learning has grown in popularity for speaker\nverification, identification, and diarization. Inarguably, a significant part\nof this success is due to the demonstrated effectiveness of their speaker\nrepresentations. These, however, are heavily dependent on large amounts of\nannotated data and can be sensitive to new domains. This study proposes an\nentirely unsupervised deep-learning model for speaker diarization.\nSpecifically, the study focuses on generating high-quality neural speaker\nrepresentations without any annotated data, as well as on estimating secondary\nhyperparameters of the model without annotations.\n\nThe speaker embeddings are represented by an encoder trained in a\nself-supervised fashion using pairs of adjacent segments assumed to be of the\nsame speaker. The trained encoder model is then used to self-generate\npseudo-labels to subsequently train a similarity score between different\nsegments of the same call using probabilistic linear discriminant analysis\n(PLDA) and further to learn a clustering stopping threshold. We compared our\nmodel to state-of-the-art unsupervised as well as supervised baselines on the\nCallHome benchmarks. According to empirical results, our approach outperforms\nunsupervised methods when only two speakers are present in the call, and is\nonly slightly worse than recent supervised models.",
          "link": "http://arxiv.org/abs/2204.04166",
          "publishedOn": "2022-04-11T00:52:28.770Z",
          "wordCount": null,
          "title": "Self-supervised Speaker Diarization. (arXiv:2204.04166v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yukai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiaro_R/0/1/0/all/0/1\">Roberta Chiaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macii_E/0/1/0/all/0/1\">Enrico Macii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poncino_M/0/1/0/all/0/1\">Massimo Poncino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagliari_D/0/1/0/all/0/1\">Daniele Jahier Pagliari</a>",
          "description": "Collaborative Inference (CI) optimizes the latency and energy consumption of\ndeep learning inference through the inter-operation of edge and cloud devices.\nAlbeit beneficial for other tasks, CI has never been applied to the sequence-\nto-sequence mapping problem at the heart of Neural Machine Translation (NMT).\nIn this work, we address the specific issues of collaborative NMT, such as\nestimating the latency required to generate the (unknown) output sequence, and\nshow how existing CI methods can be adapted to these applications. Our\nexperiments show that CI can reduce the latency of NMT by up to 44% compared to\na non-collaborative approach.",
          "link": "http://arxiv.org/abs/2204.04043",
          "publishedOn": "2022-04-11T00:52:28.767Z",
          "wordCount": null,
          "title": "C-NMT: A Collaborative Inference Framework for Neural Machine Translation. (arXiv:2204.04043v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04063",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuhao Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Chong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Saizhuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shouling Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuhong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenguang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alex X. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyah_R/0/1/0/all/0/1\">Raheem Beyah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Ting Wang</a>",
          "description": "One intriguing property of adversarial attacks is their \"transferability\" --\nan adversarial example crafted with respect to one deep neural network (DNN)\nmodel is often found effective against other DNNs as well. Intensive research\nhas been conducted on this phenomenon under simplistic controlled conditions.\nYet, thus far, there is still a lack of comprehensive understanding about\ntransferability-based attacks (\"transfer attacks\") in real-world environments.\n\nTo bridge this critical gap, we conduct the first large-scale systematic\nempirical study of transfer attacks against major cloud-based MLaaS platforms,\ntaking the components of a real transfer attack into account. The study leads\nto a number of interesting findings which are inconsistent to the existing\nones, including: (1) Simple surrogates do not necessarily improve real transfer\nattacks. (2) No dominant surrogate architecture is found in real transfer\nattacks. (3) It is the gap between posterior (output of the softmax layer)\nrather than the gap between logit (so-called $\\kappa$ value) that increases\ntransferability. Moreover, by comparing with prior works, we demonstrate that\ntransfer attacks possess many previously unknown properties in real-world\nenvironments, such as (1) Model similarity is not a well-defined concept. (2)\n$L_2$ norm of perturbation can generate high transferability without usage of\ngradient and is a more powerful source than $L_\\infty$ norm. We believe this\nwork sheds light on the vulnerabilities of popular MLaaS platforms and points\nto a few promising research directions.",
          "link": "http://arxiv.org/abs/2204.04063",
          "publishedOn": "2022-04-11T00:52:28.767Z",
          "wordCount": null,
          "title": "Transfer Attacks Revisited: A Large-Scale Empirical Study in Real Computer Vision Settings. (arXiv:2204.04063v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maurya_V/0/1/0/all/0/1\">Vikas Maurya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_R/0/1/0/all/0/1\">Rachit Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Saurabh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1\">Sandeep Kumar Shukla</a>",
          "description": "Due to the importance of Critical Infrastructure (CI) in a nation's economy,\nthey have been lucrative targets for cyber attackers. These critical\ninfrastructures are usually Cyber-Physical Systems (CPS) such as power grids,\nwater, and sewage treatment facilities, oil and gas pipelines, etc. In recent\ntimes, these systems have suffered from cyber attacks numerous times.\nResearchers have been developing cyber security solutions for CIs to avoid\nlasting damages. According to standard frameworks, cyber security based on\nidentification, protection, detection, response, and recovery are at the core\nof these research. Detection of an ongoing attack that escapes standard\nprotection such as firewall, anti-virus, and host/network intrusion detection\nhas gained importance as such attacks eventually affect the physical dynamics\nof the system. Therefore, anomaly detection in physical dynamics proves an\neffective means to implement defense-in-depth. PASAD is one example of anomaly\ndetection in the sensor/actuator data, representing such systems' physical\ndynamics. We present EPASAD, which improves the detection technique used in\nPASAD to detect these micro-stealthy attacks, as our experiments show that\nPASAD's spherical boundary-based detection fails to detect. Our method EPASAD\novercomes this by using Ellipsoid boundaries, thereby tightening the boundaries\nin various dimensions, whereas a spherical boundary treats all dimensions\nequally. We validate EPASAD using the dataset produced by the TE-process\nsimulator and the C-town datasets. The results show that EPASAD improves\nPASAD's average recall by 5.8% and 9.5% for the two datasets, respectively.",
          "link": "http://arxiv.org/abs/2204.04154",
          "publishedOn": "2022-04-11T00:52:28.734Z",
          "wordCount": null,
          "title": "EPASAD: Ellipsoid decision boundary based Process-Aware Stealthy Attack Detector. (arXiv:2204.04154v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_D/0/1/0/all/0/1\">Deqing Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xiuju Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiao Feng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wanbing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1\">Ning Li</a>",
          "description": "In this study, a novel coordinative scheduling optimization approach is\nproposed to enhance port efficiency by reducing weighted average turnaround\ntime. The proposed approach is developed as a heuristic algorithm applied and\ninvestigated through different observation windows with weekly rolling horizon\nparadigm method. The experimental results show that the proposed approach is\neffective and promising on mitigating the turnaround time of vessels. The\nresults demonstrate that largest potential savings of turnaround time (weighted\naverage) are around 17 hours (28%) reduction on baseline of 1-week observation,\n45 hours (37%) reduction on baseline of 2-week observation and 70 hours (40%)\nreduction on baseline of 3-week observation. Even though the experimental\nresults are based on historical datasets, the results potentially present\nsignificant benefits if real-time applications were applied under a quadratic\ncomputational complexity.",
          "link": "http://arxiv.org/abs/2204.03955",
          "publishedOn": "2022-04-11T00:52:28.710Z",
          "wordCount": null,
          "title": "Optimizing Coordinative Schedules for Tanker Terminals: An Intelligent Large Spatial-Temporal Data-Driven Approach -- Part 2. (arXiv:2204.03955v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuejun Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1\">Qiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordy_M/0/1/0/all/0/1\">Maxime Cordy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xiaofei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papadakis_M/0/1/0/all/0/1\">Mike Papadakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Traon_Y/0/1/0/all/0/1\">Yves Le Traon</a>",
          "description": "Various deep neural networks (DNNs) are developed and reported for their\ntremendous success in multiple domains. Given a specific task, developers can\ncollect massive DNNs from public sources for efficient reusing and avoid\nredundant work from scratch. However, testing the performance (e.g., accuracy\nand robustness) of multiple DNNs and giving a reasonable recommendation that\nwhich model should be used is challenging regarding the scarcity of labeled\ndata and demand of domain expertise. Existing testing approaches are mainly\nselection-based where after sampling, a few of the test data are labeled to\ndiscriminate DNNs. Therefore, due to the randomness of sampling, the\nperformance ranking is not deterministic. In this paper, we propose a\nlabeling-free comparison testing approach to overcome the limitations of\nlabeling effort and sampling randomness. The main idea is to learn a Bayesian\nmodel to infer the models' specialty only based on predicted labels. To\nevaluate the effectiveness of our approach, we undertook exhaustive experiments\non 9 benchmark datasets spanning in the domains of image, text, and source\ncode, and 165 DNNs. In addition to accuracy, we consider the robustness against\nsynthetic and natural distribution shifts. The experimental results demonstrate\nthat the performance of existing approaches degrades under distribution shifts.\nOur approach outperforms the baseline methods by up to 0.74 and 0.53 on\nSpearman's correlation and Kendall's $\\tau$, respectively, regardless of the\ndataset and distribution shift. Additionally, we investigated the impact of\nmodel quality (accuracy and robustness) and diversity (standard deviation of\nthe quality) on the testing effectiveness and observe that there is a higher\nchance of a good result when the quality is over 50\\% and the diversity is\nlarger than 18\\%.",
          "link": "http://arxiv.org/abs/2204.03994",
          "publishedOn": "2022-04-11T00:52:28.681Z",
          "wordCount": 711,
          "title": "Labeling-Free Comparison Testing of Deep Learning Models. (arXiv:2204.03994v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Melzi_P/0/1/0/all/0/1\">Pietro Melzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tolosana_R/0/1/0/all/0/1\">Ruben Tolosana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vera_Rodriguez_R/0/1/0/all/0/1\">Ruben Vera-Rodriguez</a>",
          "description": "Electrocardiograms (ECGs) have shown unique patterns to distinguish between\ndifferent subjects and present important advantages compared to other biometric\ntraits, such as difficulty to counterfeit, liveness detection, and ubiquity.\nAlso, with the success of Deep Learning technologies, ECG biometric recognition\nhas received increasing interest in recent years. However, it is not easy to\nevaluate the improvements of novel ECG proposed methods, mainly due to the lack\nof public data and standard experimental protocols. In this study, we perform\nextensive analysis and comparison of different scenarios in ECG biometric\nrecognition. Both verification and identification tasks are investigated, as\nwell as single- and multi-session scenarios. Finally, we also perform single-\nand multi-lead ECG experiments, considering traditional scenarios using\nelectrodes in the chest and limbs and current user-friendly wearable devices.\n\nIn addition, we present ECGXtractor, a robust Deep Learning technology\ntrained with an in-house large-scale database and able to operate successfully\nacross various scenarios and multiple databases. We introduce our proposed\nfeature extractor, trained with multiple sinus-rhythm heartbeats belonging to\n55,967 subjects, and provide a general public benchmark evaluation with\ndetailed experimental protocol. We evaluate the system performance over four\ndifferent databases: i) our in-house database, ii) PTB, iii) ECG-ID, and iv)\nCYBHi. With the widely used PTB database, we achieve Equal Error Rates of 0.14%\nand 2.06% in verification, and accuracies of 100% and 96.46% in identification,\nrespectively in single- and multi-session analysis. We release the source code,\nexperimental protocol details, and pre-trained models in GitHub to advance in\nthe field.",
          "link": "http://arxiv.org/abs/2204.03992",
          "publishedOn": "2022-04-11T00:52:28.658Z",
          "wordCount": 681,
          "title": "ECG Biometric Recognition: Review, System Proposal, and Benchmark Evaluation. (arXiv:2204.03992v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamada_Y/0/1/0/all/0/1\">Yutaro Yamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otani_M/0/1/0/all/0/1\">Mayu Otani</a>",
          "description": "As clean ImageNet accuracy nears its ceiling, the research community is\nincreasingly more concerned about robust accuracy under distributional shifts.\nWhile a variety of methods have been proposed to robustify neural networks,\nthese techniques often target models trained on ImageNet classification. At the\nsame time, it is a common practice to use ImageNet pretrained backbones for\ndownstream tasks such as object detection, semantic segmentation, and image\nclassification from different domains. This raises a question: Can these robust\nimage classifiers transfer robustness to downstream tasks? For object detection\nand semantic segmentation, we find that a vanilla Swin Transformer, a variant\nof Vision Transformer tailored for dense prediction tasks, transfers robustness\nbetter than Convolutional Neural Networks that are trained to be robust to the\ncorrupted version of ImageNet. For CIFAR10 classification, we find that models\nthat are robustified for ImageNet do not retain robustness when fully\nfine-tuned. These findings suggest that current robustification techniques tend\nto emphasize ImageNet evaluations. Moreover, network architecture is a strong\nsource of robustness when we consider transfer learning.",
          "link": "http://arxiv.org/abs/2204.03934",
          "publishedOn": "2022-04-11T00:52:28.647Z",
          "wordCount": 604,
          "title": "Does Robustness on ImageNet Transfer to Downstream Tasks?. (arXiv:2204.03934v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03998",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_N/0/1/0/all/0/1\">Narges Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azmi_R/0/1/0/all/0/1\">Reza Azmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moghadam_S/0/1/0/all/0/1\">Sara Saberi Tehrani Moghadam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zarvani_M/0/1/0/all/0/1\">Maral Zarvani</a>",
          "description": "Fashion is now among the largest industries worldwide, for it represents\nhuman history and helps tell the worlds story. As a result of the Fourth\nIndustrial Revolution, the Internet has become an increasingly important source\nof fashion information. However, with a growing number of web pages and social\ndata, it is nearly impossible for humans to manually catch up with the ongoing\nevolution and the continuously variable content in this domain. The proper\nmanagement and exploitation of big data can pave the way for the substantial\ngrowth of the global economy as well as citizen satisfaction. Therefore,\ncomputer scientists have found it challenging to handle e-commerce fashion\nwebsites by using big data and machine learning technologies. This paper first\nproposes a scalable focused Web Crawler engine based on the distributed\ncomputing platforms to extract and process fashion data on e-commerce websites.\nThe role of the proposed platform is then described in developing a\ndisentangled feature extraction method by employing deep convolutional\ngenerative adversarial networks (DCGANs) for content-based image indexing and\nretrieval. Finally, the state-of-the-art solutions are compared, and the\nresults of the proposed approach are analyzed on a standard dataset. For the\nreal-life implementation of the proposed solution, a Web-based application is\ndeveloped on Apache Storm, Kafka, Solr, and Milvus platforms to create a\nfashion search engine called SnapMode.",
          "link": "http://arxiv.org/abs/2204.03998",
          "publishedOn": "2022-04-11T00:52:28.640Z",
          "wordCount": 689,
          "title": "SnapMode: An Intelligent and Distributed Large-Scale Fashion Image Retrieval Platform Based On Big Data and Deep Generative Adversarial Network Technologies. (arXiv:2204.03998v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_I/0/1/0/all/0/1\">Ijaz Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seokjoo Shin</a>",
          "description": "The traditional communication model based on chain of multiple independent\nprocessing blocks is constraint to efficiency and introduces artificial\nbarriers. Thus, each individually optimized block does not guarantee end-to-end\nperformance of the system. Recently, end-to-end learning of communications\nsystems through machine learning (ML) have been proposed to optimize the system\nmetrics jointly over all components. These methods show performance\nimprovements but has a limitation that it requires a differentiable channel\nmodel. In this study, we have summarized the existing approaches that\nalleviates this problem. We believe that this study will provide better\nunderstanding of the topic and an insight into future research in this field.",
          "link": "http://arxiv.org/abs/2204.03944",
          "publishedOn": "2022-04-11T00:52:28.632Z",
          "wordCount": 547,
          "title": "Channel model for end-to-end learning of communications systems: A survey. (arXiv:2204.03944v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04013",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bulatovic_N/0/1/0/all/0/1\">Nikola Bulatovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djukanovic_S/0/1/0/all/0/1\">Slobodan Djukanovic</a>",
          "description": "The paper addresses acoustic vehicle detection and speed estimation from\nsingle sensor measurements. We predict the vehicle's pass-by instant by\nminimizing clipped vehicle-to-microphone distance, which is predicted from the\nmel-spectrogram of input audio, in a supervised learning approach. In addition,\nmel-spectrogram-based features are used directly for vehicle speed estimation,\nwithout introducing any intermediate features. The results show that the\nproposed features can be used for accurate vehicle detection and speed\nestimation, with an average error of 7.87 km/h. If we formulate speed\nestimation as a classification problem, with a 10 km/h discretization interval,\nthe proposed method attains the average accuracy of 48.7% for correct class\nprediction and 91.0% when an offset of one class is allowed. The proposed\nmethod is evaluated on a dataset of 304 urban-environment on-field recordings\nof ten different vehicles.",
          "link": "http://arxiv.org/abs/2204.04013",
          "publishedOn": "2022-04-11T00:52:28.625Z",
          "wordCount": 588,
          "title": "Mel-spectrogram features for acoustic vehicle detection and speed estimation. (arXiv:2204.04013v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1\">Constantinos Daskalakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golowich_N/0/1/0/all/0/1\">Noah Golowich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqing Zhang</a>",
          "description": "We show that computing approximate stationary Markov coarse correlated\nequilibria (CCE) in general-sum stochastic games is computationally\nintractable, even when there are two players, the game is turn-based, the\ndiscount factor is an absolute constant, and the approximation is an absolute\nconstant. Our intractability results stand in sharp contrast to normal-form\ngames where exact CCEs are efficiently computable. A fortiori, our results\nimply that there are no efficient algorithms for learning stationary Markov CCE\npolicies in multi-agent reinforcement learning (MARL), even when the\ninteraction is two-player and turn-based, and both the discount factor and the\ndesired approximation of the learned policies is an absolute constant. In turn,\nthese results stand in sharp contrast to single-agent reinforcement learning\n(RL) where near-optimal stationary Markov policies can be efficiently learned.\nComplementing our intractability results for stationary Markov CCEs, we provide\na decentralized algorithm (assuming shared randomness among players) for\nlearning a nonstationary Markov CCE policy with polynomial time and sample\ncomplexity in all problem parameters. Previous work for learning Markov CCE\npolicies all required exponential time and sample complexity in the number of\nplayers.",
          "link": "http://arxiv.org/abs/2204.03991",
          "publishedOn": "2022-04-11T00:52:28.606Z",
          "wordCount": 614,
          "title": "The Complexity of Markov Equilibrium in Stochastic Games. (arXiv:2204.03991v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahanor_I/0/1/0/all/0/1\">Izuwa Ahanor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Medal_H/0/1/0/all/0/1\">Hugh Medal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trapp_A/0/1/0/all/0/1\">Andrew C. Trapp</a>",
          "description": "While most methods for solving mixed-integer optimization problems seek a\nsingle optimal solution, finding a diverse set of near-optimal solutions can\noften be more useful. State of the art methods for generating diverse\nnear-optimal solutions usually take a two-phase approach, first finding a set\nof near-optimal solutions and then finding a diverse subset. In contrast, we\npresent a method of finding a set of diverse solutions by emphasizing diversity\nwithin the search for near-optimal solutions. Specifically, within a\nbranch-and-bound framework, we investigate parameterized node selection rules\nthat explicitly consider diversity. Our results indicate that our approach\nsignificantly increases diversity of the final solution set. When compared with\nexisting methods for finding diverse near-optimal sets, our method runs with\nsimilar run-time as regular node selection methods and gives a diversity\nimprovement of up to 140%. In contrast, popular node selection rules such as\nbest-first search gives an improvement of no more than 40%. Further, we find\nthat our method is most effective when diversity is emphasized more in node\nselection when deeper in the tree and when the solution set has grown large\nenough.",
          "link": "http://arxiv.org/abs/2204.03822",
          "publishedOn": "2022-04-11T00:52:28.599Z",
          "wordCount": 637,
          "title": "DiversiTree: Computing Diverse Sets of Near-Optimal Solutions to Mixed-Integer Optimization Problems. (arXiv:2204.03822v1 [cs.DM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_D/0/1/0/all/0/1\">Deqing Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xiuju Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiao Feng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wanbing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1\">Ning Li</a>",
          "description": "In this study, a novel coordinative scheduling optimization approach is\nproposed to enhance port efficiency by reducing average wait time and\nturnaround time. The proposed approach consists of enhanced particle swarm\noptimization (ePSO) as kernel and augmented firefly algorithm (AFA) as global\noptimal search. Two paradigm methods of the proposed approach are investigated,\nwhich are batch method and rolling horizon method. The experimental results\nshow that both paradigm methods of proposed approach can effectively enhance\nport efficiency. The average wait time could be significantly reduced by 86.0%\n- 95.5%, and the average turnaround time could eventually save 38.2% - 42.4%\nwith respect to historical benchmarks. Moreover, the paradigm method of rolling\nhorizon could reduce to 20 mins on running time over 3-month datasets, rather\nthan 4 hrs on batch method at corresponding maximum performance.",
          "link": "http://arxiv.org/abs/2204.03899",
          "publishedOn": "2022-04-11T00:52:28.591Z",
          "wordCount": null,
          "title": "Optimizing Coordinative Schedules for Tanker Terminals: An Intelligent Large Spatial-Temporal Data-Driven Approach -- Part 1. (arXiv:2204.03899v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liew_S/0/1/0/all/0/1\">Seng Pei Liew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_T/0/1/0/all/0/1\">Tsubasa Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takagi_S/0/1/0/all/0/1\">Shun Takagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kato_F/0/1/0/all/0/1\">Fumiyuki Kato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshikawa_M/0/1/0/all/0/1\">Masatoshi Yoshikawa</a>",
          "description": "Recently, it is shown that shuffling can amplify the central differential\nprivacy guarantees of data randomized with local differential privacy. Within\nthis setup, a centralized, trusted shuffler is responsible for shuffling by\nkeeping the identities of data anonymous, which subsequently leads to stronger\nprivacy guarantees for systems. However, introducing a centralized entity to\nthe originally local privacy model loses some appeals of not having any\ncentralized entity as in local differential privacy. Moreover, implementing a\nshuffler in a reliable way is not trivial due to known security issues and/or\nrequirements of advanced hardware or secure computation technology.\n\nMotivated by these practical considerations, we rethink the shuffle model to\nrelax the assumption of requiring a centralized, trusted shuffler. We introduce\nnetwork shuffling, a decentralized mechanism where users exchange data in a\nrandom-walk fashion on a network/graph, as an alternative of achieving privacy\namplification via anonymity. We analyze the threat model under such a setting,\nand propose distributed protocols of network shuffling that is straightforward\nto implement in practice. Furthermore, we show that the privacy amplification\nrate is similar to other privacy amplification techniques such as uniform\nshuffling. To our best knowledge, among the recently studied intermediate trust\nmodels that leverage privacy amplification techniques, our work is the first\nthat is not relying on any centralized entity to achieve privacy amplification.",
          "link": "http://arxiv.org/abs/2204.03919",
          "publishedOn": "2022-04-11T00:52:28.590Z",
          "wordCount": 663,
          "title": "Network Shuffling: Privacy Amplification via Random Walks. (arXiv:2204.03919v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Faundez_Zanuy_M/0/1/0/all/0/1\">Marcos Faundez-Zanuy</a>",
          "description": "This Paper studies different committees of neural networks for biometric\npattern recognition. We use the neural nets as classifiers for identification\nand verification purposes. We show that a committee of nets can improve the\nrecognition rates when compared with a multi-start initialization algo-rithm\nthat just picks up the neural net which offers the best performance. On the\nother hand, we found that there is no strong correlation between\nidentifi-cation and verification applications using the same classifier.",
          "link": "http://arxiv.org/abs/2204.03935",
          "publishedOn": "2022-04-11T00:52:28.583Z",
          "wordCount": 562,
          "title": "Study of a committee of neural networks for biometric hand-geometry recognition. (arXiv:2204.03935v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Subhrajit Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mincu_D/0/1/0/all/0/1\">Diana Mincu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Proleev_L/0/1/0/all/0/1\">Lev Proleev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostamzadeh_N/0/1/0/all/0/1\">Negar Rostamzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghate_C/0/1/0/all/0/1\">Chintan Ghate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harris_N/0/1/0/all/0/1\">Natalie Harris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Christina Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schrouff_J/0/1/0/all/0/1\">Jessica Schrouff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomasev_N/0/1/0/all/0/1\">Nenad Tomasev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartsell_F/0/1/0/all/0/1\">Fletcher Lee Hartsell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_K/0/1/0/all/0/1\">Katherine Heller</a>",
          "description": "Literature on machine learning for multiple sclerosis has primarily focused\non the use of neuroimaging data such as magnetic resonance imaging and clinical\nlaboratory tests for disease identification. However, studies have shown that\nthese modalities are not consistent with disease activity such as symptoms or\ndisease progression. Furthermore, the cost of collecting data from these\nmodalities is high, leading to scarce evaluations. In this work, we used\nmulti-dimensional, affordable, physical and smartphone-based performance\noutcome measures (POM) in conjunction with demographic data to predict multiple\nsclerosis disease progression. We performed a rigorous benchmarking exercise on\ntwo datasets and present results across 13 clinically actionable prediction\nendpoints and 6 machine learning models. To the best of our knowledge, our\nresults are the first to show that it is possible to predict disease\nprogression using POMs and demographic data in the context of both clinical\ntrials and smartphone-base studies by using two datasets. Moreover, we\ninvestigate our models to understand the impact of different POMs and\ndemographics on model performance through feature ablation studies. We also\nshow that model performance is similar across different demographic subgroups\n(based on age and sex). To enable this work, we developed an end-to-end\nreusable pre-processing and machine learning framework which allows quicker\nexperimentation over disparate MS datasets.",
          "link": "http://arxiv.org/abs/2204.03969",
          "publishedOn": "2022-04-11T00:52:28.574Z",
          "wordCount": 656,
          "title": "Disability prediction in multiple sclerosis using performance outcome measures and demographic data. (arXiv:2204.03969v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1\">Md Faisal Mahbub Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_M/0/1/0/all/0/1\">Michael Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossiello_G/0/1/0/all/0/1\">Gaetano Rossiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1\">Alfio Gliozzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1\">Nandana Mihindukulasooriya</a>",
          "description": "In a recent work, we presented a novel state-of-the-art approach to zero-shot\nslot filling that extends dense passage retrieval with hard negatives and\nrobust training procedures for retrieval augmented generation models. In this\npaper, we propose a system based on an enhanced version of this approach where\nwe train task specific models for other knowledge intensive language tasks,\nsuch as open domain question answering (QA), dialogue and fact checking. Our\nsystem achieves results comparable to the best models in the KILT leaderboards.\nMoreover, given a user query, we show how the output from these different\nmodels can be combined to cross-examine each other. Particularly, we show how\naccuracy in dialogue can be improved using the QA model. A short video\ndemonstrating the system is available here -\n\\url{https://ibm.box.com/v/kgi-interactive-demo} .",
          "link": "http://arxiv.org/abs/2204.03985",
          "publishedOn": "2022-04-11T00:52:28.556Z",
          "wordCount": 572,
          "title": "KGI: An Integrated Framework for Knowledge Intensive Language Tasks. (arXiv:2204.03985v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03872",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Seongwook Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jaehyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1\">Heejeong Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sull_S/0/1/0/all/0/1\">Sanghoon Sull</a>",
          "description": "Due to the cost or interference of measurement, we need to control\nmeasurement system. Assuming that each variable can be measured sequentially,\nthere exists optimal policy choosing next measurement for the former\nobservations. Though optimal measurement policy is actually dependent on the\ngoal of measurement, we mainly focus on retrieving complete data, so called as\nimputation. Also, we adapt the imputation method to missingness varying with\nmeasurement policy. However, learning measurement policy and imputation\nrequires complete data which is impossible to be observed, unfortunately. To\ntackle this problem, we propose a data generation method and joint learning\nalgorithm. The main idea is that 1) the data generation method is inherited by\nimputation method, and 2) the adaptation of imputation encourages measurement\npolicy to learn more than individual learning. We implemented some variations\nof proposed algorithm for two different datasets and various missing rates.\nFrom the experimental results, we demonstrate that our algorithm is generally\napplicable and outperforms baseline methods.",
          "link": "http://arxiv.org/abs/2204.03872",
          "publishedOn": "2022-04-11T00:52:28.548Z",
          "wordCount": 595,
          "title": "Controllable Missingness from Uncontrollable Missingness: Joint Learning Measurement Policy and Imputation. (arXiv:2204.03872v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yiqing Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuyin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lequan Yu</a>",
          "description": "Federated learning (FL) is a distributed learning paradigm that enables\nmultiple clients to collaboratively learn a shared global model. Despite the\nrecent progress, it remains challenging to deal with heterogeneous data\nclients, as the discrepant data distributions usually prevent the global model\nfrom delivering good generalization ability on each participating client. In\nthis paper, we propose CD^2-pFed, a novel Cyclic Distillation-guided Channel\nDecoupling framework, to personalize the global model in FL, under various\nsettings of data heterogeneity. Different from previous works which establish\nlayer-wise personalization to overcome the non-IID data across different\nclients, we make the first attempt at channel-wise assignment for model\npersonalization, referred to as channel decoupling. To further facilitate the\ncollaboration between private and shared weights, we propose a novel cyclic\ndistillation scheme to impose a consistent regularization between the local and\nglobal model representations during the federation. Guided by the cyclical\ndistillation, our channel decoupling framework can deliver more accurate and\ngeneralized results for different kinds of heterogeneity, such as feature skew,\nlabel distribution skew, and concept shift. Comprehensive experiments on four\nbenchmarks, including natural image and medical image analysis tasks,\ndemonstrate the consistent effectiveness of our method on both local and\nexternal validations.",
          "link": "http://arxiv.org/abs/2204.03880",
          "publishedOn": "2022-04-11T00:52:28.541Z",
          "wordCount": 640,
          "title": "CD$^2$-pFed: Cyclic Distillation-guided Channel Decoupling for Model Personalization in Federated Learning. (arXiv:2204.03880v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04016",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Weise_T/0/1/0/all/0/1\">Tobias Weise</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klumpp_P/0/1/0/all/0/1\">Philipp Klumpp</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Noeth_E/0/1/0/all/0/1\">Elmar Noeth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heismann_B/0/1/0/all/0/1\">Bjoern Heismann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schuster_M/0/1/0/all/0/1\">Maria Schuster</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_S/0/1/0/all/0/1\">Seung Hee Yang</a>",
          "description": "Speech intelligibility assessment plays an important role in the therapy of\npatients suffering from pathological speech disorders. Automatic and objective\nmeasures are desirable to assist therapists in their traditionally subjective\nand labor-intensive assessments. In this work, we investigate a novel approach\nfor obtaining such a measure using the divergence in disentangled latent speech\nrepresentations of a parallel utterance pair, obtained from a healthy reference\nand a pathological speaker. Experiments on an English database of Cerebral\nPalsy patients, using all available utterances per speaker, show high and\nsignificant correlation values (R = -0.9) with subjective intelligibility\nmeasures, while having only minimal deviation (+-0.01) across four different\nreference speaker pairs. We also demonstrate the robustness of the proposed\nmethod (R = -0.89 deviating +-0.02 over 1000 iterations) by considering a\nsignificantly smaller amount of utterances per speaker. Our results are among\nthe first to show that disentangled speech representations can be used for\nautomatic pathological speech intelligibility assessment, resulting in a\nreference speaker pair invariant method, applicable in scenarios with only few\nutterances available.",
          "link": "http://arxiv.org/abs/2204.04016",
          "publishedOn": "2022-04-11T00:52:28.534Z",
          "wordCount": 633,
          "title": "Disentangled Latent Speech Representation for Automatic Pathological Intelligibility Assessment. (arXiv:2204.04016v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03812",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Cheung_K/0/1/0/all/0/1\">Kingman Cheung</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Chung_Y/0/1/0/all/0/1\">Yi-Lun Chung</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Hsu_S/0/1/0/all/0/1\">Shih-Chieh Hsu</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Nachman_B/0/1/0/all/0/1\">Benjamin Nachman</a>",
          "description": "The modeling of jet substructure significantly differs between Parton Shower\nMonte Carlo (PSMC) programs. Despite this, we observe that machine learning\nclassifiers trained on different PSMCs learn nearly the same function. This\nmeans that when these classifiers are applied to the same PSMC for testing,\nthey result in nearly the same performance. This classifier universality\nindicates that a machine learning model trained on one simulation and tested on\nanother simulation (or data) will likely be optimal. Our observations are based\non detailed studies of shallow and deep neural networks applied to simulated\nLorentz boosted Higgs jet tagging at the LHC.",
          "link": "http://arxiv.org/abs/2204.03812",
          "publishedOn": "2022-04-11T00:52:28.526Z",
          "wordCount": 544,
          "title": "Exploring the Universality of Hadronic Jet Classification. (arXiv:2204.03812v1 [hep-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1\">Stephen Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taehyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hayeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Se-Young Yun</a>",
          "description": "Deep Neural Networks (DNN) have made significant progress in a wide range of\nvisual recognition tasks such as image classification, object detection, and\nsemantic segmentation. The evolution of convolutional architectures has led to\nbetter performance by incurring expensive computational costs. In addition,\nnetwork design has become a difficult task, which is labor-intensive and\nrequires a high level of domain knowledge. To mitigate such issues, there have\nbeen studies for a variety of neural architecture search methods that\nautomatically search for optimal architectures, achieving models with\nimpressive performance that outperform human-designed counterparts. This survey\naims to provide an overview of existing works in this field of research and\nspecifically focus on the supernet optimization that builds a neural network\nthat assembles all the architectures as its sub models by using weight sharing.\nWe aim to accomplish that by categorizing supernet optimization by proposing\nthem as solutions to the common challenges found in the literature: data-side\noptimization, poor rank correlation alleviation, and transferable NAS for a\nnumber of deployment scenarios.",
          "link": "http://arxiv.org/abs/2204.03916",
          "publishedOn": "2022-04-11T00:52:28.509Z",
          "wordCount": 601,
          "title": "SuperNet in Neural Architecture Search: A Taxonomic Survey. (arXiv:2204.03916v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1\">Rajat Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_D/0/1/0/all/0/1\">Debojyoti Dutta</a>",
          "description": "Training action space selection for reinforcement learning (RL) is\nconflict-prone due to complex state-action relationships. To address this\nchallenge, this paper proposes a Shapley-inspired methodology for training\naction space categorization and ranking. To reduce exponential-time shapley\ncomputations, the methodology includes a Monte Carlo simulation to avoid\nunnecessary explorations. The effectiveness of the methodology is illustrated\nusing a cloud infrastructure resource tuning case study. It reduces the search\nspace by 80\\% and categorizes the training action sets into dispensable and\nindispensable groups. Additionally, it ranks different training actions to\nfacilitate high-performance yet cost-efficient RL model design. The proposed\ndata-driven methodology is extensible to different domains, use cases, and\nreinforcement learning algorithms.",
          "link": "http://arxiv.org/abs/2204.03840",
          "publishedOn": "2022-04-11T00:52:28.500Z",
          "wordCount": 535,
          "title": "Data-Driven Evaluation of Training Action Space for Reinforcement Learning. (arXiv:2204.03840v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Copur_O/0/1/0/all/0/1\">Onur Copur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakip_M/0/1/0/all/0/1\">Mert Nak&#x131;p</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scardapane_S/0/1/0/all/0/1\">Simone Scardapane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slowack_J/0/1/0/all/0/1\">J&#xfc;rgen Slowack</a>",
          "description": "Recognition of user interaction, in particular engagement detection, became\nhighly crucial for online working and learning environments, especially during\nthe COVID-19 outbreak. Such recognition and detection systems significantly\nimprove the user experience and efficiency by providing valuable feedback. In\nthis paper, we propose a novel Engagement Detection with Multi-Task Training\n(ED-MTT) system which minimizes mean squared error and triplet loss together to\ndetermine the engagement level of students in an e-learning environment. The\nperformance of this system is evaluated and compared against the\nstate-of-the-art on a publicly available dataset as well as videos collected\nfrom real-life scenarios. The results show that ED-MTT achieves 6% lower MSE\nthan the best state-of-the-art performance with highly acceptable training time\nand lightweight feature extraction.",
          "link": "http://arxiv.org/abs/2204.04020",
          "publishedOn": "2022-04-11T00:52:28.493Z",
          "wordCount": null,
          "title": "Engagement Detection with Multi-Task Training in E-Learning Environments. (arXiv:2204.04020v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anjomshoaa_A/0/1/0/all/0/1\">Amin Anjomshoaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Curry_E/0/1/0/all/0/1\">Edward Curry</a>",
          "description": "The knowledge, embodied in machine learning models for intelligent systems,\nis commonly associated with time-consuming and costly processes such as\nlarge-scale data collection, data labelling, network training, and fine-tuning\nof models. Sharing and reuse of these elaborated models between intelligent\nsystems deployed in a different environment, which is known as transfer\nlearning, would facilitate the adoption of services for the users and\naccelerates the uptake of intelligent systems in environments such as smart\nbuilding and smart city applications. In this context, the communication and\nknowledge exchange between AI-enabled environments depend on a complicated\nnetworks of systems, system of systems, digital assets, and their chain of\ndependencies that hardly follows the centralized schema of traditional\ninformation systems. Rather, it requires an adaptive decentralized system\narchitecture that is empowered by features such as data provenance, workflow\ntransparency, and validation of process participants. In this research, we\npropose a decentralized and adaptive software framework based on blockchain and\nknowledge graph technologies that supports the knowledge exchange and\ninteroperability between IoT-enabled environments, in a transparent and\ntrustworthy way.",
          "link": "http://arxiv.org/abs/2204.03959",
          "publishedOn": "2022-04-11T00:52:28.489Z",
          "wordCount": 601,
          "title": "Blockchain as an Enabler for Transfer Learning in Smart Environments. (arXiv:2204.03959v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1\">Edward Raff</a>",
          "description": "The field of bibliometrics, studying citations and behavior, is critical to\nthe discussion of reproducibility. Citations are one of the primary incentive\nand reward systems for academic work, and so we desire to know if this\nincentive rewards reproducible work. Yet to the best of our knowledge, only one\nwork has attempted to look at this combined space, concluding that\nnon-reproducible work is more highly cited. We show that answering this\nquestion is more challenging than first proposed, and subtle issues can inhibit\na robust conclusion. To make inferences with more robust behavior, we propose a\nhierarchical Bayesian model that incorporates the citation rate over time,\nrather than the total number of citations after a fixed amount of time. In\ndoing so we show that, under current evidence the answer is more likely that\ncertain fields of study such as Medicine and Machine Learning (ML) do correlate\nreproducible works with more citations, but other fields appear to have no\nrelationship. Further, we find that making code available and thoroughly\nreferencing prior works appear to also positively correlate with increased\ncitations. Our code and data can be found at\nhttps://github.com/EdwardRaff/ReproducibleCitations .",
          "link": "http://arxiv.org/abs/2204.03829",
          "publishedOn": "2022-04-11T00:52:28.478Z",
          "wordCount": 631,
          "title": "Does the Market of Citations Reward Reproducible Work?. (arXiv:2204.03829v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03911",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Frezat_H/0/1/0/all/0/1\">Hugo Frezat</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sommer_J/0/1/0/all/0/1\">Julien Le Sommer</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Fablet_R/0/1/0/all/0/1\">Ronan Fablet</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Balarac_G/0/1/0/all/0/1\">Guillaume Balarac</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lguensat_R/0/1/0/all/0/1\">Redouane Lguensat</a>",
          "description": "The use of machine learning to build subgrid parametrizations for climate\nmodels is receiving growing attention. State-of-the-art strategies address the\nproblem as a supervised learning task and optimize algorithms that predict\nsubgrid fluxes based on information from coarse resolution models. In practice,\ntraining data are generated from higher resolution numerical simulations\ntransformed in order to mimic coarse resolution simulations. By essence, these\nstrategies optimize subgrid parametrizations to meet so-called $\\textit{a\npriori}$ criteria. But the actual purpose of a subgrid parametrization is to\nobtain good performance in terms of $\\textit{a posteriori}$ metrics which imply\ncomputing entire model trajectories. In this paper, we focus on the\nrepresentation of energy backscatter in two dimensional quasi-geostrophic\nturbulence and compare parametrizations obtained with different learning\nstrategies at fixed computational complexity. We show that strategies based on\n$\\textit{a priori}$ criteria yield parametrizations that tend to be unstable in\ndirect simulations and describe how subgrid parametrizations can alternatively\nbe trained end-to-end in order to meet $\\textit{a posteriori}$ criteria. We\nillustrate that end-to-end learning strategies yield parametrizations that\noutperform known empirical and data-driven schemes in terms of performance,\nstability and ability to apply to different flow configurations. These results\nsupport the relevance of differentiable programming paradigms for climate\nmodels in the future.",
          "link": "http://arxiv.org/abs/2204.03911",
          "publishedOn": "2022-04-11T00:52:27.840Z",
          "wordCount": 653,
          "title": "A posteriori learning for quasi-geostrophic turbulence parametrization. (arXiv:2204.03911v1 [physics.flu-dyn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1\">Krishna Pillutla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_K/0/1/0/all/0/1\">Kshitiz Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Abdelrahman Mohamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1\">Michael Rabbat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1\">Maziar Sanjabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Lin Xiao</a>",
          "description": "We consider two federated learning algorithms for training partially\npersonalized models, where the shared and personal parameters are updated\neither simultaneously or alternately on the devices. Both algorithms have been\nproposed in the literature, but their convergence properties are not fully\nunderstood, especially for the alternating variant. We provide convergence\nanalyses of both algorithms in the general nonconvex setting with partial\nparticipation and delineate the regime where one dominates the other. Our\nexperiments on real-world image, text, and speech datasets demonstrate that (a)\npartial personalization can obtain most of the benefits of full model\npersonalization with a small fraction of personal parameters, and, (b) the\nalternating update algorithm often outperforms the simultaneous update\nalgorithm.",
          "link": "http://arxiv.org/abs/2204.03809",
          "publishedOn": "2022-04-11T00:52:27.816Z",
          "wordCount": 551,
          "title": "Federated Learning with Partial Model Personalization. (arXiv:2204.03809v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_C/0/1/0/all/0/1\">Congyu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Ning Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xin Geng</a>",
          "description": "Partial label learning (PLL) is a typical weakly supervised learning problem,\nwhere each training example is associated with a set of candidate labels among\nwhich only one is true. Most existing PLL approaches assume that the incorrect\nlabels in each training example are randomly picked as the candidate labels and\nmodel the generation process of the candidate labels in a simple way. However,\nthese approaches usually do not perform as well as expected due to the fact\nthat the generation process of the candidate labels is always\ninstance-dependent. Therefore, it deserves to be modeled in a refined way. In\nthis paper, we consider instance-dependent PLL and assume that the generation\nprocess of the candidate labels could decompose into two sequential parts,\nwhere the correct label emerges first in the mind of the annotator but then the\nincorrect labels related to the feature are also selected with the correct\nlabel as candidate labels due to uncertainty of labeling. Motivated by this\nconsideration, we propose a novel PLL method that performs Maximum A\nPosterior(MAP) based on an explicitly modeled generation process of candidate\nlabels via decomposed probability distribution models. Experiments on benchmark\nand real-world datasets validate the effectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2204.03845",
          "publishedOn": "2022-04-11T00:52:27.805Z",
          "wordCount": 622,
          "title": "Decomposition-based Generation Process for Instance-Dependent Partial Label Learning. (arXiv:2204.03845v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03771",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Min_J/0/1/0/all/0/1\">Joosung Min</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Elliott_L/0/1/0/all/0/1\">Lloyd T. Elliott</a>",
          "description": "$Q$-learning is the most fundamental model-free reinforcement learning\nalgorithm. Deployment of $Q$-learning requires approximation of the\nstate-action value function (also known as the $Q$-function). In this work, we\nprovide online random forests as $Q$-function approximators and propose a novel\nmethod wherein the random forest is grown as learning proceeds (through\nexpanding forests). We demonstrate improved performance of our methods over\nstate-of-the-art Deep $Q$-Networks in two OpenAI gyms (`blackjack' and\n`inverted pendulum') but not in the `lunar lander' gym. We suspect that the\nresilience to overfitting enjoyed by random forests recommends our method for\ncommon tasks that do not require a strong representation of the problem domain.\nWe show that expanding forests (in which the number of trees increases as data\ncomes in) improve performance, suggesting that expanding forests are viable for\nother applications of online random forests beyond the reinforcement learning\nsetting.",
          "link": "http://arxiv.org/abs/2204.03771",
          "publishedOn": "2022-04-11T00:52:27.790Z",
          "wordCount": 563,
          "title": "Q-learning with online random forests. (arXiv:2204.03771v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03761",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Quezada_L/0/1/0/all/0/1\">L.F. Quezada</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sun_G/0/1/0/all/0/1\">Guo-Hua Sun</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Dong_S/0/1/0/all/0/1\">Shi-Hai Dong</a>",
          "description": "In this work we introduce a quantum sorting algorithm with adaptable\nrequirements of memory and circuit depth, and then use it to develop a new\nquantum version of the classical machine learning algorithm known as k-nearest\nneighbors (k-NN). Both the efficiency and performance of this new quantum\nversion of the k-NN algorithm are compared to those of the classical k-NN and\nanother quantum version proposed by Schuld et al. \\cite{Int13}. Results show\nthat the efficiency of both quantum algorithms is similar to each other and\nsuperior to that of the classical algorithm. On the other hand, the performance\nof our proposed quantum k-NN algorithm is superior to the one proposed by\nSchuld et al. and similar to that of the classical k-NN.",
          "link": "http://arxiv.org/abs/2204.03761",
          "publishedOn": "2022-04-11T00:52:27.782Z",
          "wordCount": 570,
          "title": "Quantum version of the k-NN classifier based on a quantum sorting algorithm. (arXiv:2204.03761v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03793",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ding_S/0/1/0/all/0/1\">Shaojin Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rikhye_R/0/1/0/all/0/1\">Rajeev Rikhye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_Q/0/1/0/all/0/1\">Qiao Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yanzhang He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1\">Quan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Narayanan_A/0/1/0/all/0/1\">Arun Narayanan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+OMalley_T/0/1/0/all/0/1\">Tom O&#x27;Malley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McGraw_I/0/1/0/all/0/1\">Ian McGraw</a>",
          "description": "Personalization of on-device speech recognition (ASR) has seen explosive\ngrowth in recent years, largely due to the increasing popularity of personal\nassistant features on mobile devices and smart home speakers. In this work, we\npresent Personal VAD 2.0, a personalized voice activity detector that detects\nthe voice activity of a target speaker, as part of a streaming on-device ASR\nsystem. Although previous proof-of-concept studies have validated the\neffectiveness of Personal VAD, there are still several critical challenges to\naddress before this model can be used in production: first, the quality must be\nsatisfactory in both enrollment and enrollment-less scenarios; second, it\nshould operate in a streaming fashion; and finally, the model size should be\nsmall enough to fit a limited latency and CPU/Memory budget. To meet the\nmulti-faceted requirements, we propose a series of novel designs: 1) advanced\nspeaker embedding modulation methods; 2) a new training paradigm to generalize\nto enrollment-less conditions; 3) architecture and runtime optimizations for\nlatency and resource restrictions. Extensive experiments on a realistic speech\nrecognition system demonstrated the state-of-the-art performance of our\nproposed method.",
          "link": "http://arxiv.org/abs/2204.03793",
          "publishedOn": "2022-04-11T00:52:27.702Z",
          "wordCount": 638,
          "title": "Personal VAD 2.0: Optimizing Personal Voice Activity Detection for On-Device Speech Recognition. (arXiv:2204.03793v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03784",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yasuda_M/0/1/0/all/0/1\">Muneki Yasuda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takahashi_C/0/1/0/all/0/1\">Chako Takahashi</a>",
          "description": "The evaluation of the free energy of a stochastic model is considered to be a\nsignificant issue in various fields of physics and machine learning. However,\nthe exact free energy evaluation is computationally infeasible because it\nincludes an intractable partition function. Annealed importance sampling (AIS)\nis a type of importance sampling based on the Markov chain Monte Carlo method,\nwhich is similar to a simulated annealing, and can effectively approximate the\nfree energy. This study proposes a new AIS-based approach, referred to as\nmarginalized AIS (mAIS). The statistical efficiency of mAIS is investigated in\ndetail based on a theoretical and numerical perspectives. Based on the\ninvestigation, it has been proved that mAIS is more effective than AIS under a\ncertain condition.",
          "link": "http://arxiv.org/abs/2204.03784",
          "publishedOn": "2022-04-11T00:52:27.666Z",
          "wordCount": 564,
          "title": "Free Energy Evaluation Using Marginalized Annealed Importance Sampling. (arXiv:2204.03784v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03804",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bian_W/0/1/0/all/0/1\">Wanyu Bian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingchao Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_X/0/1/0/all/0/1\">Xiaojing Ye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yunmei Chen</a>",
          "description": "Generating multi-contrasts/modal MRI of the same anatomy enriches diagnostic\ninformation but is limited in practice due to excessive data acquisition time.\nIn this paper, we propose a novel deep-learning model for joint reconstruction\nand synthesis of multi-modal MRI using incomplete k-space data of several\nsource modalities as inputs. The output of our model includes reconstructed\nimages of the source modalities and high-quality image synthesized in the\ntarget modality. Our proposed model is formulated as a variational problem that\nleverages several learnable modality-specific feature extractors and a\nmultimodal synthesis module. We propose a learnable optimization algorithm to\nsolve this model, which induces a multi-phase network whose parameters can be\ntrained using multi-modal MRI data. Moreover, a bilevel-optimization framework\nis employed for robust parameter training. We demonstrate the effectiveness of\nour approach using extensive numerical experiments.",
          "link": "http://arxiv.org/abs/2204.03804",
          "publishedOn": "2022-04-11T00:52:27.658Z",
          "wordCount": 591,
          "title": "A Learnable Variational Model for Joint Multimodal MRI Reconstruction and Synthesis. (arXiv:2204.03804v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03719",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aguiar_G/0/1/0/all/0/1\">Gabriel Aguiar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krawczyk_B/0/1/0/all/0/1\">Bartosz Krawczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cano_A/0/1/0/all/0/1\">Alberto Cano</a>",
          "description": "Class imbalance poses new challenges when it comes to classifying data\nstreams. Many algorithms recently proposed in the literature tackle this\nproblem using a variety of data-level, algorithm-level, and ensemble\napproaches. However, there is a lack of standardized and agreed-upon procedures\non how to evaluate these algorithms. This work presents a taxonomy of\nalgorithms for imbalanced data streams and proposes a standardized, exhaustive,\nand informative experimental testbed to evaluate algorithms in a collection of\ndiverse and challenging imbalanced data stream scenarios. The experimental\nstudy evaluates 24 state-of-the-art data streams algorithms on 515 imbalanced\ndata streams that combine static and dynamic class imbalance ratios,\ninstance-level difficulties, concept drift, real-world and semi-synthetic\ndatasets in binary and multi-class scenarios. This leads to the largest\nexperimental study conducted so far in the data stream mining domain. We\ndiscuss the advantages and disadvantages of state-of-the-art classifiers in\neach of these scenarios and we provide general recommendations to end-users for\nselecting the best algorithms for imbalanced data streams. Additionally, we\nformulate open challenges and future directions for this domain. Our\nexperimental testbed is fully reproducible and easy to extend with new methods.\nThis way we propose the first standardized approach to conducting experiments\nin imbalanced data streams that can be used by other researchers to create\ntrustworthy and fair evaluation of newly proposed methods. Our experimental\nframework can be downloaded from\nhttps://github.com/canoalberto/imbalanced-streams.",
          "link": "http://arxiv.org/abs/2204.03719",
          "publishedOn": "2022-04-11T00:52:27.650Z",
          "wordCount": 665,
          "title": "A survey on learning from imbalanced data streams: taxonomy, challenges, empirical study, and reproducible experimental framework. (arXiv:2204.03719v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zehtabi_S/0/1/0/all/0/1\">Shahryar Zehtabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1\">Seyyedali Hosseinalipour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1\">Christopher G. Brinton</a>",
          "description": "A recent emphasis of distributed learning research has been on federated\nlearning (FL), in which model training is conducted by the data-collecting\ndevices. Existing research on FL has mostly focused on a star topology learning\narchitecture with synchronized (time-triggered) model training rounds, where\nthe local models of the devices are periodically aggregated by a centralized\ncoordinating node. However, in many settings, such a coordinating node may not\nexist, motivating efforts to fully decentralize FL. In this work, we propose a\nnovel methodology for distributed model aggregations via asynchronous,\nevent-triggered consensus iterations over the network graph topology. We\nconsider heterogeneous communication event thresholds at each device that weigh\nthe change in local model parameters against the available local resources in\ndeciding the benefit of aggregations at each iteration. Through theoretical\nanalysis, we demonstrate that our methodology achieves asymptotic convergence\nto the globally optimal learning model under standard assumptions in\ndistributed learning and graph consensus literature, and without restrictive\nconnectivity requirements on the underlying topology. Subsequent numerical\nresults demonstrate that our methodology obtains substantial improvements in\ncommunication requirements compared with FL baselines.",
          "link": "http://arxiv.org/abs/2204.03726",
          "publishedOn": "2022-04-11T00:52:27.631Z",
          "wordCount": 606,
          "title": "Decentralized Event-Triggered Federated Learning with Heterogeneous Communication Thresholds. (arXiv:2204.03726v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zahid_M/0/1/0/all/0/1\">Muhammad Uzair Zahid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiranyaz_S/0/1/0/all/0/1\">Serkan Kiranyaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1\">Moncef Gabbouj</a>",
          "description": "Objective: Global (inter-patient) ECG classification for arrhythmia detection\nover Electrocardiogram (ECG) signal is a challenging task for both humans and\nmachines. The main reason is the significant variations of both normal and\narrhythmic ECG patterns among patients. Automating this process with utmost\naccuracy is, therefore, highly desirable due to the advent of wearable ECG\nsensors. However, even with numerous deep learning approaches proposed\nrecently, there is still a notable gap in the performance of global and\npatient-specific ECG classification performances. This study proposes a novel\napproach to narrow this gap and propose a real-time solution with shallow and\ncompact 1D Self-Organized Operational Neural Networks (Self-ONNs). Methods: In\nthis study, we propose a novel approach for inter-patient ECG classification\nusing a compact 1D Self-ONN by exploiting morphological and timing information\nin heart cycles. We used 1D Self-ONN layers to automatically learn\nmorphological representations from ECG data, enabling us to capture the shape\nof the ECG waveform around the R peaks. We further inject temporal features\nbased on RR interval for timing characterization. The classification layers can\nthus benefit from both temporal and learned features for the final arrhythmia\nclassification. Results: Using the MIT-BIH arrhythmia benchmark database, the\nproposed method achieves the highest classification performance ever achieved,\ni.e., 99.21% precision, 99.10% recall, and 99.15% F1-score for normal (N)\nsegments; 82.19% precision, 82.50% recall, and 82.34% F1-score for the\nsupra-ventricular ectopic beat (SVEBs); and finally, 94.41% precision, 96.10%\nrecall, and 95.2% F1-score for the ventricular-ectopic beats (VEBs).",
          "link": "http://arxiv.org/abs/2204.03768",
          "publishedOn": "2022-04-11T00:52:27.624Z",
          "wordCount": 670,
          "title": "Global ECG Classification by Self-Operational Neural Networks with Feature Injection. (arXiv:2204.03768v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03722",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Olague_G/0/1/0/all/0/1\">Gustavo Olague</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menendez_Clavijo_J/0/1/0/all/0/1\">Jose Armando Menendez-Clavijo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olague_M/0/1/0/all/0/1\">Matthieu Olague</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ocampo_A/0/1/0/all/0/1\">Arturo Ocampo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibarra_Vazquez_G/0/1/0/all/0/1\">Gerardo Ibarra-Vazquez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ochoa_R/0/1/0/all/0/1\">Rocio Ochoa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineda_R/0/1/0/all/0/1\">Roberto Pineda</a>",
          "description": "Despite recent improvements in computer vision, artificial visual systems'\ndesign is still daunting since an explanation of visual computing algorithms\nremains elusive. Salient object detection is one problem that is still open due\nto the difficulty of understanding the brain's inner workings. Progress on this\nresearch area follows the traditional path of hand-made designs using\nneuroscience knowledge. In recent years two different approaches based on\ngenetic programming appear to enhance their technique. One follows the idea of\ncombining previous hand-made methods through genetic programming and fuzzy\nlogic. The other approach consists of improving the inner computational\nstructures of basic hand-made models through artificial evolution. This\nresearch work proposes expanding the artificial dorsal stream using a recent\nproposal to solve salient object detection problems. This approach uses the\nbenefits of the two main aspects of this research area: fixation prediction and\ndetection of salient objects. We decided to apply the fusion of visual saliency\nand image segmentation algorithms as a template. The proposed methodology\ndiscovers several critical structures in the template through artificial\nevolution. We present results on a benchmark designed by experts with\noutstanding results in comparison with the state-of-the-art.",
          "link": "http://arxiv.org/abs/2204.03722",
          "publishedOn": "2022-04-11T00:52:27.617Z",
          "wordCount": 650,
          "title": "Automated Design of Salient Object Detection Algorithms with Brain Programming. (arXiv:2204.03722v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03758",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kensen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Joey Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1\">Pengcheng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_C/0/1/0/all/0/1\">Charles Sutton</a>",
          "description": "When writing programs, people have the ability to tackle a new complex task\nby decomposing it into smaller and more familiar subtasks. While it is\ndifficult to measure whether neural program synthesis methods have similar\ncapabilities, what we can measure is whether they compositionally generalize,\nthat is, whether a model that has been trained on the simpler subtasks is\nsubsequently able to solve more complex tasks. In this paper, we focus on\nmeasuring the ability of learned program synthesizers to compositionally\ngeneralize. We first characterize several different axes along which program\nsynthesis methods would be desired to generalize, e.g., length generalization,\nor the ability to combine known subroutines in new ways that do not occur in\nthe training data. Based on this characterization, we introduce a benchmark\nsuite of tasks to assess these abilities based on two popular existing\ndatasets, SCAN and RobustFill. Finally, we make first attempts to improve the\ncompositional generalization ability of Transformer models along these axes\nthrough novel attention mechanisms that draw inspiration from a human-like\ndecomposition strategy. Empirically, we find our modified Transformer models\ngenerally perform better than natural baselines, but the tasks remain\nchallenging.",
          "link": "http://arxiv.org/abs/2204.03758",
          "publishedOn": "2022-04-11T00:52:27.601Z",
          "wordCount": 633,
          "title": "Compositional Generalization and Decomposition in Neural Program Synthesis. (arXiv:2204.03758v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03703",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Guo_Z/0/1/0/all/0/1\">Zhen Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_J/0/1/0/all/0/1\">Jung Ki Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barbastathis_G/0/1/0/all/0/1\">George Barbastathis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Glinsky_M/0/1/0/all/0/1\">Michael E. Glinsky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vaughan_C/0/1/0/all/0/1\">Courtenay T. Vaughan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Larson_K/0/1/0/all/0/1\">Kurt W. Larson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alpert_B/0/1/0/all/0/1\">Bradley K. Alpert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Levine_Z/0/1/0/all/0/1\">Zachary H. Levine</a>",
          "description": "X-ray tomography is capable of imaging the interior of objects in three\ndimensions non-invasively, with applications in biomedical imaging, materials\nscience, electronic inspection, and other fields. The reconstruction process\ncan be an ill-conditioned inverse problem, requiring regularization to obtain\nsatisfactory reconstructions. Recently, deep learning has been adopted for\ntomographic reconstruction. Unlike iterative algorithms which require a\ndistribution that is known a priori, deep reconstruction networks can learn a\nprior distribution through sampling the training distributions. In this work,\nwe develop a Physics-assisted Generative Adversarial Network (PGAN), a two-step\nalgorithm for tomographic reconstruction. In contrast to previous efforts, our\nPGAN utilizes maximum-likelihood estimates derived from the measurements to\nregularize the reconstruction with both known physics and the learned prior.\nSynthetic objects with spatial correlations are integrated circuits (IC) from a\nproposed model CircuitFaker. Compared with maximum-likelihood estimation, PGAN\ncan reduce the photon requirement with limited projection angles to achieve a\ngiven error rate. We further attribute the improvement to the learned prior by\nreconstructing objects created without spatial correlations. The advantages of\nusing a prior from deep learning in X-ray tomography may further enable\nlow-photon nanoscale imaging.",
          "link": "http://arxiv.org/abs/2204.03703",
          "publishedOn": "2022-04-11T00:52:27.584Z",
          "wordCount": 645,
          "title": "Physics-assisted Generative Adversarial Network for X-Ray Tomography. (arXiv:2204.03703v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1\">Siddhartha Datta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kollnig_K/0/1/0/all/0/1\">Konrad Kollnig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shadbolt_N/0/1/0/all/0/1\">Nigel Shadbolt</a>",
          "description": "Digital harms can manifest across any interface. Key problems in addressing\nthese harms include the high individuality of harms and the fast-changing\nnature of digital systems. As a result, we still lack a systematic approach to\nstudy harms and produce interventions for end-users. We put forward\nGreaseVision, a new framework that enables end-users to collaboratively develop\ninterventions against harms in software using a no-code approach and recent\nadvances in few-shot machine learning. The contribution of the framework and\ntool allow individual end-users to study their usage history and create\npersonalized interventions. Our contribution also enables researchers to study\nthe distribution of harms and interventions at scale.",
          "link": "http://arxiv.org/abs/2204.03731",
          "publishedOn": "2022-04-11T00:52:27.576Z",
          "wordCount": 529,
          "title": "GreaseVision: Rewriting the Rules of the Interface. (arXiv:2204.03731v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03737",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xu_X/0/1/0/all/0/1\">Xinjie Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuangzhi Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_D/0/1/0/all/0/1\">Dongwei Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1\">Huaji Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yu_S/0/1/0/all/0/1\">Shanqing Yu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zheng_S/0/1/0/all/0/1\">Shilian Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xuan_Q/0/1/0/all/0/1\">Qi Xuan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoniu Yang</a>",
          "description": "With the rapid development of deep learning, automatic modulation recognition\n(AMR), as an important task in cognitive radio, has gradually transformed from\ntraditional feature extraction and classification to automatic classification\nby deep learning technology. However, deep learning models are data-driven\nmethods, which often require a large amount of data as the training support.\nData augmentation, as the strategy of expanding dataset, can improve the\ngeneralization of the deep learning models and thus improve the accuracy of the\nmodels to a certain extent. In this paper, for AMR of radio signals, we propose\na data augmentation strategy based on mixing signals and consider four specific\nmethods (Random Mixing, Maximum-Similarity-Mixing, $\\theta-$Similarity Mixing\nand n-times Random Mixing) to achieve data augmentation. Experiments show that\nour proposed method can improve the classification accuracy of deep learning\nbased AMR models in the full public dataset RML2016.10a. In particular, for the\ncase of a single signal-to-noise ratio signal set, the classification accuracy\ncan be significantly improved, which verifies the effectiveness of the methods.",
          "link": "http://arxiv.org/abs/2204.03737",
          "publishedOn": "2022-04-11T00:52:27.569Z",
          "wordCount": 612,
          "title": "Mixing Signals: Data Augmentation Approach for Deep Learning Based Modulation Recognition. (arXiv:2204.03737v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ng_P/0/1/0/all/0/1\">Pai Chet Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spachos_P/0/1/0/all/0/1\">Petros Spachos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+She_J/0/1/0/all/0/1\">James She</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1\">Konstantinos N. Plataniotis</a>",
          "description": "This paper presents a nonlinear location estimation to infer the position of\na user holding a smartphone. We consider a large location with $M$ number of\ngrid points, each grid point is labeled with a unique fingerprint consisting of\nthe received signal strength (RSS) values measured from $N$ number of Bluetooth\nLow Energy (BLE) beacons. Given the fingerprint observed by the smartphone, the\nuser's current location can be estimated by finding the top-k similar\nfingerprints from the list of fingerprints registered in the database. Besides\nthe environmental factors, the dynamicity in holding the smartphone is another\nsource to the variation in fingerprint measurements, yet there are not many\nstudies addressing the fingerprint variability due to dynamic smartphone\npositions held by human hands during online detection. To this end, we propose\na nonlinear location estimation using the kernel method. Specifically, our\nproposed method comprises of two steps: 1) a beacon selection strategy to\nselect a subset of beacons that is insensitive to the subtle change of holding\npositions, and 2) a kernel method to compute the similarity between this subset\nof observed signals and all the fingerprints registered in the database. The\nexperimental results based on large-scale data collected in a complex building\nindicate a substantial performance gain of our proposed approach in comparison\nto state-of-the-art methods. The dataset consisting of the signal information\ncollected from the beacons is available online.",
          "link": "http://arxiv.org/abs/2204.03724",
          "publishedOn": "2022-04-11T00:52:27.561Z",
          "wordCount": 672,
          "title": "A Kernel Method to Nonlinear Location Estimation with RSS-based Fingerprint. (arXiv:2204.03724v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_D/0/1/0/all/0/1\">Diego Corr&#xea;a da Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durao_F/0/1/0/all/0/1\">Frederico Ara&#xfa;jo Dur&#xe3;o</a>",
          "description": "Recommender Systems use the user's profile to generate a recommendation list\nwith unknown items to a target user. Although the primary goal of traditional\nrecommendation systems is to deliver the most relevant items, such an effort\nunintentionally can cause collateral effects including low diversity and\nunbalanced genres or categories, benefiting particular groups of categories.\nThis paper proposes an approach to create recommendation lists with a\ncalibrated balance of genres, avoiding disproportion between the user's profile\ninterests and the recommendation list. The calibrated recommendations consider\nconcomitantly the relevance and the divergence between the genres distributions\nextracted from the user's preference and the recommendation list. The main\nclaim is that calibration can contribute positively to generate fairer\nrecommendations. In particular, we propose a new trade-off equation, which\nconsiders the users' bias to provide a recommendation list that seeks for the\nusers' tendencies. Moreover, we propose a conceptual framework and a decision\nprotocol to generate more than one thousand combinations of calibrated systems\nin order to find the best combination. We compare our approach against\nstate-of-the-art approaches using multiple domain datasets, which are analyzed\nby rank and calibration metrics. The results indicate that the trade-off, which\nconsiders the users' bias, produces positive effects on the precision and to\nthe fairness, thus generating recommendation lists that respect the genre\ndistribution and, through the decision protocol, we also found the best system\nfor each dataset.",
          "link": "http://arxiv.org/abs/2204.03706",
          "publishedOn": "2022-04-11T00:52:27.553Z",
          "wordCount": 674,
          "title": "Introducing a Framework and a Decision Protocol to Calibrate Recommender Systems. (arXiv:2204.03706v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">You Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Huiqi Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1\">Angela Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thuerey_N/0/1/0/all/0/1\">Nils Thuerey</a>",
          "description": "We propose a novel approach to generate temporally coherent UV coordinates\nfor loose clothing. Our method is not constrained by human body outlines and\ncan capture loose garments and hair. We implemented a differentiable pipeline\nto learn UV mapping between a sequence of RGB inputs and textures via UV\ncoordinates. Instead of treating the UV coordinates of each frame separately,\nour data generation approach connects all UV coordinates via feature matching\nfor temporal stability. Subsequently, a generative model is trained to balance\nthe spatial quality and temporal stability. It is driven by supervised and\nunsupervised losses in both UV and image spaces. Our experiments show that the\ntrained models output high-quality UV coordinates and generalize to new poses.\nOnce a sequence of UV coordinates has been inferred by our model, it can be\nused to flexibly synthesize new looks and modified visual styles. Compared to\nexisting methods, our approach reduces the computational workload to animate\nnew outfits by several orders of magnitude.",
          "link": "http://arxiv.org/abs/2204.03671",
          "publishedOn": "2022-04-11T00:52:27.536Z",
          "wordCount": 601,
          "title": "TemporalUV: Capturing Loose Clothing with Temporally Coherent UV Coordinates. (arXiv:2204.03671v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nascimento_E/0/1/0/all/0/1\">Erick Giovani Sperandio Nascimento</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Julian Santana Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Figueiredo_I/0/1/0/all/0/1\">Ilan Sousa Figueiredo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guarieiro_L/0/1/0/all/0/1\">Lilian Lefol Nani Guarieiro</a>",
          "description": "Deep learning and big data algorithms have become widely used in industrial\napplications to optimize several tasks in many complex systems. Particularly,\ndeep learning model for diagnosing and prognosing machinery health has\nleveraged predictive maintenance (PdM) to be more accurate and reliable in\ndecision making, in this way avoiding unnecessary interventions, machinery\naccidents, and environment catastrophes. Recently, Transformer Neural Networks\nhave gained notoriety and have been increasingly the favorite choice for\nNatural Language Processing (NLP) tasks. Thus, given their recent major\nachievements in NLP, this paper proposes the development of an automatic fault\nclassifier model for predictive maintenance based on a modified version of the\nTransformer architecture, namely T4PdM, to identify multiple types of faults in\nrotating machinery. Experimental results are developed and presented for the\nMaFaulDa and CWRU databases. T4PdM was able to achieve an overall accuracy of\n99.98% and 98% for both datasets, respectively. In addition, the performance of\nthe proposed model is compared to other previously published works. It has\ndemonstrated the superiority of the model in detecting and classifying faults\nin rotating industrial machinery. Therefore, the proposed Transformer-based\nmodel can improve the performance of machinery fault analysis and diagnostic\nprocesses and leverage companies to a new era of the Industry 4.0. In addition,\nthis methodology can be adapted to any other task of time series\nclassification.",
          "link": "http://arxiv.org/abs/2204.03725",
          "publishedOn": "2022-04-11T00:52:27.528Z",
          "wordCount": 671,
          "title": "T4PdM: a Deep Neural Network based on the Transformer Architecture for Fault Diagnosis of Rotating Machinery. (arXiv:2204.03725v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Genssler_P/0/1/0/all/0/1\">Paul R. Genssler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vas_A/0/1/0/all/0/1\">Austin Vas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amrouch_H/0/1/0/all/0/1\">Hussam Amrouch</a>",
          "description": "Brain-inspired hyperdimensional computing (HDC) is an emerging machine\nlearning (ML) methods. It is based on large vectors of binary or bipolar\nsymbols and a few simple mathematical operations. The promise of HDC is a\nhighly efficient implementation for embedded systems like wearables. While fast\nimplementations have been presented, other constraints have not been considered\nfor edge computing. In this work, we aim at answering how thermal-friendly HDC\nfor edge computing is. Devices like smartwatches, smart glasses, or even mobile\nsystems have a restrictive cooling budget due to their limited volume. Although\nHDC operations are simple, the vectors are large, resulting in a high number of\nCPU operations and thus a heavy load on the entire system potentially causing\ntemperature violations. In this work, the impact of HDC on the chip's\ntemperature is investigated for the first time. We measure the temperature and\npower consumption of a commercial embedded system and compare HDC with\nconventional CNN. We reveal that HDC causes up to 6.8{\\deg}C higher\ntemperatures and leads to up to 47% more CPU throttling. Even when both HDC and\nCNN aim for the same throughput (i.e., perform a similar number of\nclassifications per second), HDC still causes higher on-chip temperatures due\nto the larger power consumption.",
          "link": "http://arxiv.org/abs/2204.03739",
          "publishedOn": "2022-04-11T00:52:27.521Z",
          "wordCount": 645,
          "title": "Brain-Inspired Hyperdimensional Computing: How Thermal-Friendly for Edge Computing?. (arXiv:2204.03739v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lawhon_M/0/1/0/all/0/1\">Matthew Lawhon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1\">Chengzhi Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junfeng Yang</a>",
          "description": "Deep networks achieve state-of-the-art performance on computer vision tasks,\nyet they fail under adversarial attacks that are imperceptible to humans. In\nthis paper, we propose a novel defense that can dynamically adapt the input\nusing the intrinsic structure from multiple self-supervised tasks. By\nsimultaneously using many self-supervised tasks, our defense avoids\nover-fitting the adapted image to one specific self-supervised task and\nrestores more intrinsic structure in the image compared to a single\nself-supervised task approach. Our approach further improves robustness and\nclean accuracy significantly compared to the state-of-the-art single task\nself-supervised defense. Our work is the first to connect multiple\nself-supervised tasks to robustness, and suggests that we can achieve better\nrobustness with more intrinsic signal from visual data.",
          "link": "http://arxiv.org/abs/2204.03714",
          "publishedOn": "2022-04-11T00:52:27.513Z",
          "wordCount": 564,
          "title": "Using Multiple Self-Supervised Tasks Improves Model Robustness. (arXiv:2204.03714v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oviedo_F/0/1/0/all/0/1\">Felipe Oviedo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinnakota_S/0/1/0/all/0/1\">Srinivas Vinnakota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seleznev_E/0/1/0/all/0/1\">Eugene Seleznev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malhotra_H/0/1/0/all/0/1\">Hemant Malhotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaikh_S/0/1/0/all/0/1\">Saqib Shaikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1\">Juan Lavista Ferres</a>",
          "description": "Millions of people around the world have low or no vision. Assistive software\napplications have been developed for a variety of day-to-day tasks, including\noptical character recognition, scene identification, person recognition, and\ncurrency recognition. This last task, the recognition of banknotes from\ndifferent denominations, has been addressed by the use of computer vision\nmodels for image recognition. However, the datasets and models available for\nthis task are limited, both in terms of dataset size and in variety of\ncurrencies covered. In this work, we collect a total of 24,826 images of\nbanknotes in variety of assistive settings, spanning 17 currencies and 112\ndenominations. Using supervised contrastive learning, we develop a machine\nlearning model for universal currency recognition. This model learns compliant\nembeddings of banknote images in a variety of contexts, which can be shared\npublicly (as a compressed vector representation), and can be used to train and\ntest specialized downstream models for any currency, including those not\ncovered by our dataset or for which only a few real images per denomination are\navailable (few-shot learning). We deploy a variation of this model for public\nuse in the last version of the Seeing AI app developed by Microsoft. We share\nour encoder model and the embeddings as an open dataset in our BankNote-Net\nrepository.",
          "link": "http://arxiv.org/abs/2204.03738",
          "publishedOn": "2022-04-11T00:52:27.506Z",
          "wordCount": 657,
          "title": "BankNote-Net: Open dataset for assistive universal currency recognition. (arXiv:2204.03738v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lim_B/0/1/0/all/0/1\">Bryan Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichenbach_A/0/1/0/all/0/1\">Alexander Reichenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cully_A/0/1/0/all/0/1\">Antoine Cully</a>",
          "description": "Quality-Diversity (QD) algorithms can discover large and complex behavioural\nrepertoires consisting of both diverse and high-performing skills. However, the\ngeneration of behavioural repertoires has mainly been limited to simulation\nenvironments instead of real-world learning. This is because existing QD\nalgorithms need large numbers of evaluations as well as episodic resets, which\nrequire manual human supervision and interventions. This paper proposes\nReset-Free Quality-Diversity optimization (RF-QD) as a step towards autonomous\nlearning for robotics in open-ended environments. We build on Dynamics-Aware\nQuality-Diversity (DA-QD) and introduce a behaviour selection policy that\nleverages the diversity of the imagined repertoire and environmental\ninformation to intelligently select of behaviours that can act as automatic\nresets. We demonstrate this through a task of learning to walk within defined\ntraining zones with obstacles. Our experiments show that we can learn full\nrepertoires of legged locomotion controllers autonomously without manual resets\nwith high sample efficiency in spite of harsh safety constraints. Finally,\nusing an ablation of different target objectives, we show that it is important\nfor RF-QD to have diverse types solutions available for the behaviour selection\npolicy over solutions optimised with a specific objective. Videos and code\navailable at https://sites.google.com/view/rf-qd.",
          "link": "http://arxiv.org/abs/2204.03655",
          "publishedOn": "2022-04-11T00:52:27.486Z",
          "wordCount": 635,
          "title": "Learning to Walk Autonomously via Reset-Free Quality-Diversity. (arXiv:2204.03655v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03654",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_F/0/1/0/all/0/1\">Fangyu Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wei_Y/0/1/0/all/0/1\">Yanjie Wei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jin Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xi_W/0/1/0/all/0/1\">Wenhui Xi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_Y/0/1/0/all/0/1\">Yi Pan</a>",
          "description": "The development of noninvasive brain imaging such as resting-state functional\nmagnetic resonance imaging (rs-fMRI) and its combination with AI algorithm\nprovides a promising solution for the early diagnosis of Autism spectrum\ndisorder (ASD). However, the performance of the current ASD classification\nbased on rs-fMRI still needs to be improved. This paper introduces a\nclassification framework to aid ASD diagnosis based on rs-fMRI. In the\nframework, we proposed a novel filter feature selection method based on the\ndifference between step distribution curves (DSDC) to select remarkable\nfunctional connectivities (FCs) and utilized a multilayer perceptron (MLP)\nwhich was pretrained by a simplified Variational Autoencoder (VAE) for\nclassification. We also designed a pipeline consisting of a normalization\nprocedure and a modified hyperbolic tangent (tanh) activation function to\nreplace the original tanh function, further improving the model accuracy. Our\nmodel was evaluated by 10 times 10-fold cross-validation and achieved an\naverage accuracy of 78.12%, outperforming the state-of-the-art methods reported\non the same dataset. Given the importance of sensitivity and specificity in\ndisease diagnosis, two constraints were designed in our model which can improve\nthe model's sensitivity and specificity by up to 9.32% and 10.21%,\nrespectively. The added constraints allow our model to handle different\napplication scenarios and can be used broadly.",
          "link": "http://arxiv.org/abs/2204.03654",
          "publishedOn": "2022-04-11T00:52:27.479Z",
          "wordCount": 682,
          "title": "Identification of Autism spectrum disorder based on a novel feature selection method and Variational Autoencoder. (arXiv:2204.03654v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03657",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Criado_J/0/1/0/all/0/1\">Juan Carlos Criado</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Spannowsky_M/0/1/0/all/0/1\">Michael Spannowsky</a>",
          "description": "We present a general method, called Qade, for solving differential equations\nusing a quantum annealer. The solution is obtained as a linear combination of a\nset of basis functions. On current devices, Qade can solve systems of coupled\npartial differential equations that depend linearly on the solution and its\nderivatives, with non-linear variable coefficients and arbitrary inhomogeneous\nterms. We test the method with several examples and find that state-of-the-art\nquantum annealers can find the solution accurately for problems requiring a\nsmall enough function basis. We provide a Python package implementing the\nmethod at gitlab.com/jccriado/qade.",
          "link": "http://arxiv.org/abs/2204.03657",
          "publishedOn": "2022-04-11T00:52:27.472Z",
          "wordCount": 550,
          "title": "Qade: Solving Differential Equations on Quantum Annealers. (arXiv:2204.03657v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mirzaeian_A/0/1/0/all/0/1\">Ali Mirzaeian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+D_S/0/1/0/all/0/1\">Sai Manoj P D</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latibari_B/0/1/0/all/0/1\">Banafsheh S. Latibari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savidis_I/0/1/0/all/0/1\">Ioannis Savidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Homayoun_H/0/1/0/all/0/1\">Houman Homayoun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasan_A/0/1/0/all/0/1\">Avesta Sasan</a>",
          "description": "This paper presents a novel model training solution, denoted as\nAdaptive-Gravity, for enhancing the robustness of deep neural network\nclassifiers against adversarial examples. We conceptualize the model\nparameters/features associated with each class as a mass characterized by its\ncentroid location and the spread (standard deviation of the distance) of\nfeatures around the centroid. We use the centroid associated with each cluster\nto derive an anti-gravity force that pushes the centroids of different classes\naway from one another during network training. Then we customized an objective\nfunction that aims to concentrate each class's features toward their\ncorresponding new centroid, which has been obtained by anti-gravity force. This\nmethodology results in a larger separation between different masses and reduces\nthe spread of features around each centroid. As a result, the samples are\npushed away from the space that adversarial examples could be mapped to,\neffectively increasing the degree of perturbation needed for making an\nadversarial example. We have implemented this training solution as an iterative\nmethod consisting of four steps at each iteration: 1) centroid extraction, 2)\nanti-gravity force calculation, 3) centroid relocation, and 4) gravity\ntraining. Gravity's efficiency is evaluated by measuring the corresponding\nfooling rates against various attack models, including FGSM, MIM, BIM, and PGD\nusing LeNet and ResNet110 networks, benchmarked against MNIST and CIFAR10\nclassification problems. Test results show that Gravity not only functions as a\npowerful instrument to robustify a model against state-of-the-art adversarial\nattacks but also effectively improves the model training accuracy.",
          "link": "http://arxiv.org/abs/2204.03694",
          "publishedOn": "2022-04-11T00:52:27.460Z",
          "wordCount": 682,
          "title": "Adaptive-Gravity: A Defense Against Adversarial Samples. (arXiv:2204.03694v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yutong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damani_M/0/1/0/all/0/1\">Mehul Damani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pamela Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuhong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sartoretti_G/0/1/0/all/0/1\">Guillaume Sartoretti</a>",
          "description": "Purpose of review: Recent advances in sensing, actuation, and computation\nhave opened the door to multi-robot systems consisting of hundreds/thousands of\nrobots, with promising applications to automated manufacturing, disaster\nrelief, harvesting, last-mile delivery, port/airport operations, or search and\nrescue. The community has leveraged model-free multi-agent reinforcement\nlearning (MARL) to devise efficient, scalable controllers for multi-robot\nsystems (MRS). This review aims to provide an analysis of the state-of-the-art\nin distributed MARL for multi-robot cooperation.\n\nRecent findings: Decentralized MRS face fundamental challenges, such as\nnon-stationarity and partial observability. Building upon the \"centralized\ntraining, decentralized execution\" paradigm, recent MARL approaches include\nindependent learning, centralized critic, value decomposition, and\ncommunication learning approaches. Cooperative behaviors are demonstrated\nthrough AI benchmarks and fundamental real-world robotic capabilities such as\nmulti-robot motion/path planning.\n\nSummary: This survey reports the challenges surrounding decentralized\nmodel-free MARL for multi-robot cooperation and existing classes of approaches.\nWe present benchmarks and robotic applications along with a discussion on\ncurrent open avenues for research.",
          "link": "http://arxiv.org/abs/2204.03516",
          "publishedOn": "2022-04-09T00:48:55.535Z",
          "wordCount": 615,
          "title": "Distributed Reinforcement Learning for Robot Teams: A Review. (arXiv:2204.03516v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yulun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cashman_M/0/1/0/all/0/1\">Mikaela Cashman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choma_N/0/1/0/all/0/1\">Nicholas Choma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prates_E/0/1/0/all/0/1\">&#xc9;rica T. Prates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vergara_V/0/1/0/all/0/1\">Ver&#xf3;nica G. Melesse Vergara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Andrew Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Manesh Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clyde_A/0/1/0/all/0/1\">Austin Clyde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brettin_T/0/1/0/all/0/1\">Thomas S. Brettin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jong_W/0/1/0/all/0/1\">Wibe A. de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1\">Neeraj Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Head_M/0/1/0/all/0/1\">Martha S. Head</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_R/0/1/0/all/0/1\">Rick L. Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nugent_P/0/1/0/all/0/1\">Peter Nugent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobson_D/0/1/0/all/0/1\">Daniel A. Jacobson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_J/0/1/0/all/0/1\">James B. Brown</a>",
          "description": "We developed Distilled Graph Attention Policy Network (DGAPN), a\nreinforcement learning model to generate novel graph-structured chemical\nrepresentations that optimize user-defined objectives by efficiently navigating\na physically constrained domain. The framework is examined on the task of\ngenerating molecules that are designed to bind, noncovalently, to functional\nsites of SARS-CoV-2 proteins. We present a spatial Graph Attention (sGAT)\nmechanism that leverages self-attention over both node and edge attributes as\nwell as encoding the spatial structure -- this capability is of considerable\ninterest in synthetic biology and drug discovery. An attentional policy network\nis introduced to learn the decision rules for a dynamic, fragment-based\nchemical environment, and state-of-the-art policy gradient techniques are\nemployed to train the network with stability. Exploration is driven by the\nstochasticity of the action space design and the innovation reward bonuses\nlearned and proposed by random network distillation. In experiments, our\nframework achieved outstanding results compared to state-of-the-art algorithms,\nwhile reducing the complexity of paths to chemical synthesis.",
          "link": "http://arxiv.org/abs/2106.02190",
          "publishedOn": "2022-04-09T00:48:55.510Z",
          "wordCount": 745,
          "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery. (arXiv:2106.02190v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05845",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Simpson_I/0/1/0/all/0/1\">Ivor J.A. Simpson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McManamon_A/0/1/0/all/0/1\">Ashley McManamon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Orzsik_B/0/1/0/all/0/1\">Bal&#xe1;zs &#xd6;rzsik</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stone_A/0/1/0/all/0/1\">Alan J. Stone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blockley_N/0/1/0/all/0/1\">Nicholas P. Blockley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asllani_I/0/1/0/all/0/1\">Iris Asllani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Colasanti_A/0/1/0/all/0/1\">Alessandro Colasanti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cercignani_M/0/1/0/all/0/1\">Mara Cercignani</a>",
          "description": "Streamlined qBOLD acquisitions enable experimentally straightforward\nobservations of brain oxygen metabolism. $R_2^\\prime$ maps are easily inferred;\nhowever, the Oxygen extraction fraction (OEF) and deoxygenated blood volume\n(DBV) are more ambiguously determined from the data. As such, existing\ninference methods tend to yield very noisy and underestimated OEF maps, while\noverestimating DBV.\n\nThis work describes a novel probabilistic machine learning approach that can\ninfer plausible distributions of OEF and DBV. Initially, we create a model that\nproduces informative voxelwise prior distribution based on synthetic training\ndata. Contrary to prior work, we model the joint distribution of OEF and DBV\nthrough a scaled multivariate logit-Normal distribution, which enables the\nvalues to be constrained within a plausible range. The prior distribution model\nis used to train an efficient amortized variational Bayesian inference model.\nThis model learns to infer OEF and DBV by predicting real image data, with few\ntraining data required, using the signal equations as a forward model.\n\nWe demonstrate that our approach enables the inference of smooth OEF and DBV\nmaps, with a physiologically plausible distribution that can be adapted through\nspecification of an informative prior distribution. Other benefits include\nmodel comparison (via the evidence lower bound) and uncertainty quantification\nfor identifying image artefacts. Results are demonstrated on a small study\ncomparing subjects undergoing hyperventilation and at rest. We illustrate that\nthe proposed approach allows measurement of gray matter differences in OEF and\nDBV and enables voxelwise comparison between conditions, where we observe\nsignificant increases in OEF and $R_2^\\prime$ during hyperventilation.",
          "link": "http://arxiv.org/abs/2203.05845",
          "publishedOn": "2022-04-09T00:48:55.502Z",
          "wordCount": 733,
          "title": "Flexible Amortized Variational Inference in qBOLD MRI. (arXiv:2203.05845v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03132",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1\">Tianyi Lin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zampetakis_M/0/1/0/all/0/1\">Manolis Zampetakis</a>",
          "description": "We consider the problem of computing an equilibrium in a class of nonlinear\ngeneralized Nash equilibrium problems (NGNEPs) in which the strategy sets for\neach player are defined by equality and inequality constraints that may depend\non the choices of rival players. While the asymptotic global convergence and\nlocal convergence rate of solution procedures have been studied in this\nsetting, the analysis of iteration complexity is still in its infancy. Our\ncontribution is to provide two simple first-order algorithmic frameworks based\non the quadratic penalty method and the augmented Lagrangian method,\nrespectively, with an accelerated mirror-prox algorithm as the inner loop. We\nprovide nonasymptotic theoretical guarantees for these algorithms. More\nspecifically, we establish the global convergence rate of our algorithms for\nsolving (strongly) monotone NGNEPs and we provide iteration complexity bounds\nexpressed in terms of the number of gradient evaluations. Experimental results\ndemonstrate the efficiency of our algorithms.",
          "link": "http://arxiv.org/abs/2204.03132",
          "publishedOn": "2022-04-09T00:48:55.494Z",
          "wordCount": 597,
          "title": "First-Order Algorithms for Nonlinear Generalized Nash Equilibrium Problems. (arXiv:2204.03132v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03219",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tseng_W/0/1/0/all/0/1\">Wei-Cheng Tseng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kao_W/0/1/0/all/0/1\">Wei-Tsung Kao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Mean opinion score (MOS) is a typical subjective evaluation metric for speech\nsynthesis systems. Since collecting MOS is time-consuming, it would be\ndesirable if there are accurate MOS prediction models for automatic evaluation.\nIn this work, we propose DDOS, a novel MOS prediction model. DDOS utilizes\ndomain adaptive pre-training to further pre-train self-supervised learning\nmodels on synthetic speech. And a proposed module is added to model the opinion\nscore distribution of each utterance. With the proposed components, DDOS\noutperforms previous works on BVCC dataset. And the zero shot transfer result\non BC2019 dataset is significantly improved. DDOS also wins second place in\nInterspeech 2022 VoiceMOS challenge in terms of system-level score.",
          "link": "http://arxiv.org/abs/2204.03219",
          "publishedOn": "2022-04-09T00:48:55.487Z",
          "wordCount": 580,
          "title": "DDOS: A MOS Prediction Framework utilizing Domain Adaptive Pre-training and Distribution of Opinion Scores. (arXiv:2204.03219v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>",
          "description": "Unsupervised image-to-image translation aims to learn the translation between\ntwo visual domains without paired data. Despite the recent progress in image\ntranslation models, it remains challenging to build mappings between complex\ndomains with drastic visual discrepancies. In this work, we present a novel\nframework, Generative Prior-guided UNsupervised Image-to-image Translation\n(GP-UNIT), to improve the overall quality and applicability of the translation\nalgorithm. Our key insight is to leverage the generative prior from pre-trained\nclass-conditional GANs (e.g., BigGAN) to learn rich content correspondences\nacross various domains. We propose a novel coarse-to-fine scheme: we first\ndistill the generative prior to capture a robust coarse-level content\nrepresentation that can link objects at an abstract semantic level, based on\nwhich fine-level content features are adaptively learned for more accurate\nmulti-level content correspondences. Extensive experiments demonstrate the\nsuperiority of our versatile framework over state-of-the-art methods in robust,\nhigh-quality and diversified translations, even for challenging and distant\ndomains.",
          "link": "http://arxiv.org/abs/2204.03641",
          "publishedOn": "2022-04-09T00:48:55.479Z",
          "wordCount": 603,
          "title": "Unsupervised Image-to-Image Translation with Generative Prior. (arXiv:2204.03641v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maniati_G/0/1/0/all/0/1\">Georgia Maniati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vioni_A/0/1/0/all/0/1\">Alexandra Vioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellinas_N/0/1/0/all/0/1\">Nikolaos Ellinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikitaras_K/0/1/0/all/0/1\">Karolos Nikitaras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klapsas_K/0/1/0/all/0/1\">Konstantinos Klapsas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_J/0/1/0/all/0/1\">June Sig Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jho_G/0/1/0/all/0/1\">Gunu Jho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalamandaris_A/0/1/0/all/0/1\">Aimilios Chalamandaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsiakoulis_P/0/1/0/all/0/1\">Pirros Tsiakoulis</a>",
          "description": "In this work, we present the SOMOS dataset, the first large-scale mean\nopinion scores (MOS) dataset consisting of solely neural text-to-speech (TTS)\nsamples. It can be employed to train automatic MOS prediction systems focused\non the assessment of modern synthesizers, and can stimulate advancements in\nacoustic model evaluation. It consists of 20K synthetic utterances of the LJ\nSpeech voice, a public domain speech dataset which is a common benchmark for\nbuilding neural acoustic models and vocoders. Utterances are generated from 200\nTTS systems including vanilla neural acoustic models as well as models which\nallow prosodic variations. An LPCNet vocoder is used for all systems, so that\nthe samples' variation depends only on the acoustic models. The synthesized\nutterances provide balanced and adequate domain and length coverage. We collect\nMOS naturalness evaluations on 3 English Amazon Mechanical Turk locales and\nshare practices leading to reliable crowdsourced annotations for this task.\nBaseline results of state-of-the-art MOS prediction models on the SOMOS dataset\nare presented, while we show the challenges that such models face when assigned\nto evaluate synthetic utterances.",
          "link": "http://arxiv.org/abs/2204.03040",
          "publishedOn": "2022-04-09T00:48:55.456Z",
          "wordCount": 650,
          "title": "SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis. (arXiv:2204.03040v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03341",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kieu_T/0/1/0/all/0/1\">Tung Kieu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chenjuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jensen_C/0/1/0/all/0/1\">Christian S. Jensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiteng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kai Zheng</a>",
          "description": "Time series data occurs widely, and outlier detection is a fundamental\nproblem in data mining, which has numerous applications. Existing\nautoencoder-based approaches deliver state-of-the-art performance on\nchallenging real-world data but are vulnerable to outliers and exhibit low\nexplainability. To address these two limitations, we propose robust and\nexplainable unsupervised autoencoder frameworks that decompose an input time\nseries into a clean time series and an outlier time series using autoencoders.\nImproved explainability is achieved because clean time series are better\nexplained with easy-to-understand patterns such as trends and periodicities. We\nprovide insight into this by means of a post-hoc explainability analysis and\nempirical studies. In addition, since outliers are separated from clean time\nseries iteratively, our approach offers improved robustness to outliers, which\nin turn improves accuracy. We evaluate our approach on five real-world datasets\nand report improvements over the state-of-the-art approaches in terms of\nrobustness and explainability.\n\nThis is an extended version of \"Robust and Explainable Autoencoders for\nUnsupervised Time Series Outlier Detection\", to appear in IEEE ICDE 2022.",
          "link": "http://arxiv.org/abs/2204.03341",
          "publishedOn": "2022-04-09T00:48:55.449Z",
          "wordCount": 627,
          "title": "Robust and Explainable Autoencoders for Unsupervised Time Series Outlier Detection---Extended Version. (arXiv:2204.03341v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1906.06717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vasic_M/0/1/0/all/0/1\">Marko Vasic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrovic_A/0/1/0/all/0/1\">Andrija Petrovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kaiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolic_M/0/1/0/all/0/1\">Mladen Nikolic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rishabh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurshid_S/0/1/0/all/0/1\">Sarfraz Khurshid</a>",
          "description": "Rapid advancements in deep learning have led to many recent breakthroughs.\nWhile deep learning models achieve superior performance, often statistically\nbetter than humans, their adoption into safety-critical settings, such as\nhealthcare or self-driving cars is hindered by their inability to provide\nsafety guarantees or to expose the inner workings of the model in a human\nunderstandable form. We present Mo\\\"ET, a novel model based on Mixture of\nExperts, consisting of decision tree experts and a generalized linear model\ngating function. Thanks to such gating function the model is more expressive\nthan the standard decision tree. To support non-differentiable decision trees\nas experts, we formulate a novel training procedure. In addition, we introduce\na hard thresholding version, Mo\\\"ETH, in which predictions are made solely by a\nsingle expert chosen via the gating function. Thanks to that property, Mo\\\"ETH\nallows each prediction to be easily decomposed into a set of logical rules in a\nform which can be easily verified. While Mo\\\"ET is a general use model, we\nillustrate its power in the reinforcement learning setting. By training Mo\\\"ET\nmodels using an imitation learning procedure on deep RL agents we outperform\nthe previous state-of-the-art technique based on decision trees while\npreserving the verifiability of the models. Moreover, we show that Mo\\\"ET can\nalso be used in real-world supervised problems on which it outperforms other\nverifiable machine learning models.",
          "link": "http://arxiv.org/abs/1906.06717",
          "publishedOn": "2022-04-09T00:48:55.442Z",
          "wordCount": 750,
          "title": "Mo\\\"ET: Mixture of Expert Trees and its Application to Verifiable Reinforcement Learning. (arXiv:1906.06717v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.06336",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>",
          "description": "The Shapley value (SV) and Least core (LC) are classic methods in cooperative\ngame theory for cost/profit sharing problems. Both methods have recently been\nproposed as a principled solution for data valuation tasks, i.e., quantifying\nthe contribution of individual datum in machine learning. However, both SV and\nLC suffer computational challenges due to the need for retraining models on\ncombinatorially many data subsets. In this work, we propose to boost the\nefficiency in computing Shapley value or Least core by learning to estimate the\nperformance of a learning algorithm on unseen data combinations. Theoretically,\nwe derive bounds relating the error in the predicted learning performance to\nthe approximation error in SV and LC. Empirically, we show that the proposed\nmethod can significantly improve the accuracy of SV and LC estimation.",
          "link": "http://arxiv.org/abs/2107.06336",
          "publishedOn": "2022-04-09T00:48:55.433Z",
          "wordCount": 593,
          "title": "Improving Cooperative Game Theory-based Data Valuation via Data Utility Learning. (arXiv:2107.06336v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1\">Nan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoxiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Supervised federated learning (FL) enables multiple clients to share the\ntrained model without sharing their labeled data. However, potential clients\nmight even be reluctant to label their own data, which could limit the\napplicability of FL in practice. In this paper, we show the possibility of\nunsupervised FL whose model is still a classifier for predicting class labels,\nif the class-prior probabilities are shifted while the class-conditional\ndistributions are shared among the unlabeled data owned by the clients. We\npropose federation of unsupervised learning (FedUL), where the unlabeled data\nare transformed into surrogate labeled data for each of the clients, a modified\nmodel is trained by supervised FL, and the wanted model is recovered from the\nmodified model. FedUL is a very general solution to unsupervised FL: it is\ncompatible with many supervised FL methods, and the recovery of the wanted\nmodel can be theoretically guaranteed as if the data have been labeled.\nExperiments on benchmark and real-world datasets demonstrate the effectiveness\nof FedUL. Code is available at https://github.com/lunanbit/FedUL.",
          "link": "http://arxiv.org/abs/2204.03304",
          "publishedOn": "2022-04-09T00:48:55.414Z",
          "wordCount": 615,
          "title": "Federated Learning from Only Unlabeled Data with Class-Conditional-Sharing Clients. (arXiv:2204.03304v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Junseok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Yunhak Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+In_Y/0/1/0/all/0/1\">Yeonjun In</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Namkyeong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hyun_D/0/1/0/all/0/1\">Dongmin Hyun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chanyoung Park</a>",
          "description": "Despite the success of Graph Neural Networks (GNNs) on various applications,\nGNNs encounter significant performance degradation when the amount of\nsupervision signals, i.e., number of labeled nodes, is limited, which is\nexpected as GNNs are trained solely based on the supervision obtained from the\nlabeled nodes. On the other hand,recent self-supervised learning paradigm aims\nto train GNNs by solving pretext tasks that do not require any labeled nodes,\nand it has shown to even outperform GNNs trained with few labeled nodes.\nHowever, a major drawback of self-supervised methods is that they fall short of\nlearning class discriminative node representations since no labeled information\nis utilized during training. To this end, we propose a novel semi-supervised\nmethod for graphs, GraFN, that leverages few labeled nodes to ensure nodes that\nbelong to the same class to be grouped together, thereby achieving the best of\nboth worlds of semi-supervised and self-supervised methods. Specifically, GraFN\nrandomly samples support nodes from labeled nodes and anchor nodes from the\nentire graph. Then, it minimizes the difference between two predicted class\ndistributions that are non-parametrically assigned by anchor-supports\nsimilarity from two differently augmented graphs. We experimentally show that\nGraFN surpasses both the semi-supervised and self-supervised methods in terms\nof node classification on real-world graphs. The source code for GraFN is\navailable at https://github.com/Junseok0207/GraFN.",
          "link": "http://arxiv.org/abs/2204.01303",
          "publishedOn": "2022-04-09T00:48:55.406Z",
          "wordCount": 690,
          "title": "GraFN: Semi-Supervised Node Classification on Graph with Few Labels via Non-Parametric Distribution Assignment. (arXiv:2204.01303v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Liang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shubin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jianming Deng</a>",
          "description": "Adopting reinforcement learning (RL) for traffic signal control is\nincreasingly popular. Most RL methods use fixed action interval (denoted as\ntduration) and actuate or maintain a phase every tduration, which makes the\nphase duration less dynamic and flexible. In addition, the actuated phase can\nbe arbitrary, affecting the real-world deployment, which requires a fixed\ncyclical phase structure. To address these challenges, we propose a multi-level\ntraffic signal control framework, DynLight, which uses an optimization method\nMax-QueueLength (M-QL) to determine the phase and uses a deep Q-network to\ndetermine the corresponding duration. Based on DynLight, we further propose\nDynLight-C that adopts a well trained deep Q-network of DynLight and replace\nM-QL by a fixed cyclical control policy that actuate a set of phases in fixed\norder to realize cyclical phase structure. Comprehensive experiments on\nmultiple real-world datasets demonstrate that DynLight achives a new\nstate-of-the-art. Furthermore, the deep Q-network of DynLight can learn well on\ndetermining the phase duration and DynLight-C demonstrates high performance for\ndeployment.",
          "link": "http://arxiv.org/abs/2204.03471",
          "publishedOn": "2022-04-09T00:48:55.399Z",
          "wordCount": 615,
          "title": "DynLight: Realize dynamic phase duration with multi-level traffic signal control. (arXiv:2204.03471v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.03398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Narang_A/0/1/0/all/0/1\">Adhyyan Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faulkner_E/0/1/0/all/0/1\">Evan Faulkner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drusvyatskiy_D/0/1/0/all/0/1\">Dmitriy Drusvyatskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazel_M/0/1/0/all/0/1\">Maryam Fazel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratliff_L/0/1/0/all/0/1\">Lillian J. Ratliff</a>",
          "description": "Learning problems commonly exhibit an interesting feedback mechanism wherein\nthe population data reacts to competing decision makers' actions. This paper\nformulates a new game theoretic framework for this phenomenon, called\n\"multi-player performative prediction\". We focus on two distinct solution\nconcepts, namely (i) performatively stable equilibria and (ii) Nash equilibria\nof the game. The latter equilibria are arguably more informative, but can be\nfound efficiently only when the game is monotone. We show that under mild\nassumptions, the performatively stable equilibria can be found efficiently by a\nvariety of algorithms, including repeated retraining and the repeated\n(stochastic) gradient method. We then establish transparent sufficient\nconditions for strong monotonicity of the game and use them to develop\nalgorithms for finding Nash equilibria. We investigate derivative free methods\nand adaptive gradient algorithms wherein each player alternates between\nlearning a parametric description of their distribution and gradient steps on\nthe empirical risk. Synthetic and semi-synthetic numerical experiments\nillustrate the results.",
          "link": "http://arxiv.org/abs/2201.03398",
          "publishedOn": "2022-04-09T00:48:55.388Z",
          "wordCount": null,
          "title": "Multiplayer Performative Prediction: Learning in Decision-Dependent Games. (arXiv:2201.03398v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03248",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sekimoto_K/0/1/0/all/0/1\">Kaiji Sekimoto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yasuda_M/0/1/0/all/0/1\">Muneki Yasuda</a>",
          "description": "Although evaluation of the expectations on the Ising model is essential in\nvarious applications, this is frequently infeasible because of intractable\nmultiple summations (or integrations). Spatial Monte Carlo integration (SMCI)\nis a sampling-based approximation, and can provide high-accuracy estimations\nfor such intractable expectations. To evaluate the expectation of a function of\nvariables in a specific region (called target region), SMCI considers a larger\nregion containing the target region (called sum region). In SMCI, the multiple\nsummation for the variables in the sum region is precisely executed, and that\nin the outer region is evaluated by the sampling approximation such as the\nstandard Monte Carlo integration. It is guaranteed that the accuracy of the\nSMCI estimator is monotonically improved as the size of the sum region\nincreases. However, a haphazard expansion of the sum region could cause a\ncombinatorial explosion. Therefore, we hope to improve the accuracy without\nsuch region expansion. In this study, based on the theory of generalized least\nsquares, a new effective method is proposed by combining multiple SMCI\nestimators. The validity of the proposed method is demonstrated theoretically\nand numerically. The results indicate that the proposed method can be effective\nin the inverse Ising problem (or Boltzmann machine learning).",
          "link": "http://arxiv.org/abs/2204.03248",
          "publishedOn": "2022-04-09T00:48:55.387Z",
          "wordCount": 660,
          "title": "Composite Spatial Monte Carlo Integration Based on Generalized Least Squares. (arXiv:2204.03248v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.06476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akyon_F/0/1/0/all/0/1\">Fatih Cagatay Akyon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavusoglu_D/0/1/0/all/0/1\">Devrim Cavusoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cengiz_C/0/1/0/all/0/1\">Cemil Cengiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altinuc_S/0/1/0/all/0/1\">Sinan Onur Altinuc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Temizel_A/0/1/0/all/0/1\">Alptekin Temizel</a>",
          "description": "While exam-style questions are a fundamental educational tool serving a\nvariety of purposes, manual construction of questions is a complex process that\nrequires training, experience and resources. Automatic question generation (QG)\ntechniques can be utilized to satisfy the need for a continuous supply of new\nquestions by streamlining their generation. However, compared to automatic\nquestion answering (QA), QG is a more challenging task. In this work, we\nfine-tune a multilingual T5 (mT5) transformer in a multi-task setting for QA,\nQG and answer extraction tasks using Turkish QA datasets. To the best of our\nknowledge, this is the first academic work that performs automated text-to-text\nquestion generation from Turkish texts. Experimental evaluations show that the\nproposed multi-task setting achieves state-of-the-art Turkish question\nanswering and question generation performance on TQuADv1, TQuADv2 datasets and\nXQuAD Turkish split. The source code and the pre-trained models are available\nat https://github.com/obss/turkish-question-generation.",
          "link": "http://arxiv.org/abs/2111.06476",
          "publishedOn": "2022-04-09T00:48:55.387Z",
          "wordCount": null,
          "title": "Automated question generation and question answering from Turkish texts. (arXiv:2111.06476v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03193",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiahao Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Shiqi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1\">Guang Lin</a>",
          "description": "A new data-driven method for operator learning of stochastic differential\nequations(SDE) is proposed in this paper. The central goal is to solve forward\nand inverse stochastic problems more effectively using limited data. Deep\noperator network(DeepONet) has been proposed recently for operator learning.\nCompared to other neural networks to learn functions, it aims at the problem of\nlearning nonlinear operators. However, it can be challenging by using the\noriginal model to learn nonlinear operators for high-dimensional stochastic\nproblems. We propose a new multi-resolution autoencoder DeepONet model referred\nto as MultiAuto-DeepONet to deal with this difficulty with the aid of\nconvolutional autoencoder. The encoder part of the network is designed to\nreduce the dimensionality as well as discover the hidden features of\nhigh-dimensional stochastic inputs. The decoder is designed to have a special\nstructure, i.e. in the form of DeepONet. The first DeepONet in decoder is\ndesigned to reconstruct the input function involving randomness while the\nsecond one is used to approximate the solution of desired equations. Those two\nDeepONets has a common branch net and two independent trunk nets. This\narchitecture enables us to deal with multi-resolution inputs naturally. By\nadding $L_1$ regularization to our network, we found the outputs from the\nbranch net and two trunk nets all have sparse structures. This reduces the\nnumber of trainable parameters in the neural network thus making the model more\nefficient. Finally, we conduct several numerical experiments to illustrate the\neffectiveness of our proposed MultiAuto-DeepONet model with uncertainty\nquantification.",
          "link": "http://arxiv.org/abs/2204.03193",
          "publishedOn": "2022-04-09T00:48:55.379Z",
          "wordCount": 705,
          "title": "MultiAuto-DeepONet: A Multi-resolution Autoencoder DeepONet for Nonlinear Dimension Reduction, Uncertainty Quantification and Operator Learning of Forward and Inverse Stochastic Problems. (arXiv:2204.03193v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.01665",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grelier_C/0/1/0/all/0/1\">Cyril Grelier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goudet_O/0/1/0/all/0/1\">Olivier Goudet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jin-Kao Hao</a>",
          "description": "This work presents the first study of using the popular Monte Carlo Tree\nSearch (MCTS) method combined with dedicated heuristics for solving the\nWeighted Vertex Coloring Problem. Starting with the basic MCTS algorithm, we\ngradually introduce a number of algorithmic variants where MCTS is extended by\nvarious simulation strategies including greedy and local search heuristics. We\nconduct experiments on well-known benchmark instances to assess the value of\neach studied combination. We also provide empirical evidence to shed light on\nthe advantages and limits of each strategy.",
          "link": "http://arxiv.org/abs/2202.01665",
          "publishedOn": "2022-04-09T00:48:55.379Z",
          "wordCount": null,
          "title": "On Monte Carlo Tree Search for Weighted Vertex Coloring. (arXiv:2202.01665v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gustineli_M/0/1/0/all/0/1\">Murilo Gustineli</a>",
          "description": "Artificial neural networks (ANN), typically referred to as neural networks,\nare a class of Machine Learning algorithms and have achieved widespread\nsuccess, having been inspired by the biological structure of the human brain.\nNeural networks are inherently powerful due to their ability to learn complex\nfunction approximations from data. This generalization ability has been able to\nimpact multidisciplinary areas involving image recognition, speech recognition,\nnatural language processing, and others. Activation functions are a crucial\nsub-component of neural networks. They define the output of a node in the\nnetwork given a set of inputs. This survey discusses the main concepts of\nactivation functions in neural networks, including; a brief introduction to\ndeep neural networks, a summary of what are activation functions and how they\nare used in neural networks, their most common properties, the different types\nof activation functions, some of the challenges, limitations, and alternative\nsolutions faced by activation functions, concluding with the final remarks.",
          "link": "http://arxiv.org/abs/2204.02921",
          "publishedOn": "2022-04-09T00:48:55.379Z",
          "wordCount": null,
          "title": "A survey on recently proposed activation functions for Deep Learning. (arXiv:2204.02921v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03495",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Gordon_M/0/1/0/all/0/1\">Max Hunter Gordon</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cerezo_M/0/1/0/all/0/1\">M. Cerezo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>",
          "description": "Principal component analysis (PCA) is a dimensionality reduction method in\ndata analysis that involves diagonalizing the covariance matrix of the dataset.\nRecently, quantum algorithms have been formulated for PCA based on\ndiagonalizing a density matrix. These algorithms assume that the covariance\nmatrix can be encoded in a density matrix, but a concrete protocol for this\nencoding has been lacking. Our work aims to address this gap. Assuming\namplitude encoding of the data, with the data given by the ensemble $\\{p_i,|\n\\psi_i \\rangle\\}$, then one can easily prepare the ensemble average density\nmatrix $\\overline{\\rho} = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i |$. We first\nshow that $\\overline{\\rho}$ is precisely the covariance matrix whenever the\ndataset is centered. For quantum datasets, we exploit global phase symmetry to\nargue that there always exists a centered dataset consistent with\n$\\overline{\\rho}$, and hence $\\overline{\\rho}$ can always be interpreted as a\ncovariance matrix. This provides a simple means for preparing the covariance\nmatrix for arbitrary quantum datasets or centered classical datasets. For\nuncentered classical datasets, our method is so-called \"PCA without centering\",\nwhich we interpret as PCA on a symmetrized dataset. We argue that this closely\ncorresponds to standard PCA, and we derive equations and inequalities that\nbound the deviation of the spectrum obtained with our method from that of\nstandard PCA. We numerically illustrate our method for the MNIST handwritten\ndigit dataset. We also argue that PCA on quantum datasets is natural and\nmeaningful, and we numerically implement our method for molecular ground-state\ndatasets.",
          "link": "http://arxiv.org/abs/2204.03495",
          "publishedOn": "2022-04-09T00:48:55.370Z",
          "wordCount": null,
          "title": "Covariance matrix preparation for quantum principal component analysis. (arXiv:2204.03495v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hadi_M/0/1/0/all/0/1\">Mohammad Abdul Hadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yusuf_I/0/1/0/all/0/1\">Imam Nur Bani Yusuf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thung_F/0/1/0/all/0/1\">Ferdian Thung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luong_K/0/1/0/all/0/1\">Kien Gia Luong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lingxiao_J/0/1/0/all/0/1\">Jiang Lingxiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fard_F/0/1/0/all/0/1\">Fatemeh H. Fard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_D/0/1/0/all/0/1\">David Lo</a>",
          "description": "Developers frequently use APIs to implement certain functionalities, such as\nparsing Excel Files, reading and writing text files line by line, etc.\nDevelopers can greatly benefit from automatic API usage sequence generation\nbased on natural language queries for building applications in a faster and\ncleaner manner. Existing approaches utilize information retrieval models to\nsearch for matching API sequences given a query or use RNN-based\nencoder-decoder to generate API sequences. As it stands, the first approach\ntreats queries and API names as bags of words. It lacks deep comprehension of\nthe semantics of the queries. The latter approach adapts a neural language\nmodel to encode a user query into a fixed-length context vector and generate\nAPI sequences from the context vector.\n\nWe want to understand the effectiveness of recent Pre-trained Transformer\nbased Models (PTMs) for the API learning task. These PTMs are trained on large\nnatural language corpora in an unsupervised manner to retain contextual\nknowledge about the language and have found success in solving similar Natural\nLanguage Processing (NLP) problems. However, the applicability of PTMs has not\nyet been explored for the API sequence generation task. We use a dataset that\ncontains 7 million annotations collected from GitHub to evaluate the PTMs\nempirically. This dataset was also used to assess previous approaches. Based on\nour results, PTMs generate more accurate API sequences and outperform other\nrelated methods by around 11%. We have also identified two different\ntokenization approaches that can contribute to a significant boost in PTMs'\nperformance for the API sequence generation task.",
          "link": "http://arxiv.org/abs/2204.03498",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "On the Effectiveness of Pretrained Models for API Learning. (arXiv:2204.03498v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_W/0/1/0/all/0/1\">Wai Weng Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Layeghy_S/0/1/0/all/0/1\">Siamak Layeghy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarhan_M/0/1/0/all/0/1\">Mohanad Sarhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallagher_M/0/1/0/all/0/1\">Marcus Gallagher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portmann_M/0/1/0/all/0/1\">Marius Portmann</a>",
          "description": "This paper presents a new Android malware detection method based on Graph\nNeural Networks (GNNs) with Jumping-Knowledge (JK). Android function call\ngraphs (FCGs) consist of a set of program functions and their inter-procedural\ncalls. Thus, this paper proposes a GNN-based method for Android malware\ndetection by capturing meaningful intra-procedural call path patterns. In\naddition, a Jumping-Knowledge technique is applied to minimize the effect of\nthe over-smoothing problem, which is common in GNNs. The proposed method has\nbeen extensively evaluated using two benchmark datasets. The results\ndemonstrate the superiority of our approach compared to state-of-the-art\napproaches in terms of key classification metrics, which demonstrates the\npotential of GNNs in Android malware detection and classification.",
          "link": "http://arxiv.org/abs/2201.07537",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "Graph Neural Network-based Android Malware Classification with Jumping Knowledge. (arXiv:2201.07537v5 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.12991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shirvanimoghaddam_M/0/1/0/all/0/1\">Mahyar Shirvanimoghaddam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yifeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guha_A/0/1/0/all/0/1\">Aradhika Guha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salari_A/0/1/0/all/0/1\">Ayoob Salari</a>",
          "description": "In this paper, we consider the federated learning (FL) problem in the\npresence of communication errors. We model the link between the devices and the\ncentral node (CN) by a packet erasure channel, where the local parameters from\ndevices are either erased or received correctly by CN with probability $e$ and\n$1-e$, respectively. We provide mathematical proof for the convergence of the\nFL algorithm in the presence of communication errors, where the CN uses past\nlocal updates when the fresh updates are not received from some devices. We\nshow via simulations that by using the past local updates, the FL algorithm can\nconverge in the presence of communication errors. We also show that when the\ndataset is uniformly distributed among devices, the FL algorithm that only uses\nfresh updates and discards missing updates might converge faster than the FL\nalgorithm that uses past local updates.",
          "link": "http://arxiv.org/abs/2201.12991",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "Federated Learning with Erroneous Communication Links. (arXiv:2201.12991v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Washington_P/0/1/0/all/0/1\">Peter Washington</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutlu_C/0/1/0/all/0/1\">Cezmi Mutlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kline_A/0/1/0/all/0/1\">Aaron Kline</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_C/0/1/0/all/0/1\">Cathy Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunlap_K/0/1/0/all/0/1\">Kaitlyn Dunlap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kent_J/0/1/0/all/0/1\">Jack Kent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Husic_A/0/1/0/all/0/1\">Arman Husic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stockham_N/0/1/0/all/0/1\">Nate Stockham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chrisman_B/0/1/0/all/0/1\">Brianna Chrisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paskov_K/0/1/0/all/0/1\">Kelley Paskov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1\">Jae-Yoon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wall_D/0/1/0/all/0/1\">Dennis P. Wall</a>",
          "description": "Some of the most severe bottlenecks preventing widespread development of\nmachine learning models for human behavior include a dearth of labeled training\ndata and difficulty of acquiring high quality labels. Active learning is a\nparadigm for using algorithms to computationally select a useful subset of data\npoints to label using metrics for model uncertainty and data similarity. We\nexplore active learning for naturalistic computer vision emotion data, a\nparticularly heterogeneous and complex data space due to inherently subjective\nlabels. Using frames collected from gameplay acquired from a therapeutic\nsmartphone game for children with autism, we run a simulation of active\nlearning using gameplay prompts as metadata to aid in the active learning\nprocess. We find that active learning using information generated during\ngameplay slightly outperforms random selection of the same number of labeled\nframes. We next investigate a method to conduct active learning with subjective\ndata, such as in affective computing, and where multiple crowdsourced labels\ncan be acquired for each image. Using the Child Affective Facial Expression\n(CAFE) dataset, we simulate an active learning process for crowdsourcing many\nlabels and find that prioritizing frames using the entropy of the crowdsourced\nlabel distribution results in lower categorical cross-entropy loss compared to\nrandom frame selection. Collectively, these results demonstrate pilot\nevaluations of two novel active learning approaches for subjective affective\ndata collected in noisy settings.",
          "link": "http://arxiv.org/abs/2204.01915",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "An Exploration of Active Learning for Affective Digital Phenotyping. (arXiv:2204.01915v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.02700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shia_E/0/1/0/all/0/1\">Ensheng Shia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hongbin Sun</a>",
          "description": "Commit messages concisely describe the content of code diffs (i.e., code\nchanges) and the intent behind them. Recently, many approaches have been\nproposed to generate commit messages automatically. The information\nretrieval-based methods reuse the commit messages of similar code diffs, while\nthe neural-based methods learn the semantic connection between code diffs and\ncommit messages. However, the reused commit messages might not accurately\ndescribe the content/intent of code diffs and neural-based methods tend to\ngenerate high-frequent and repetitive tokens in the corpus. In this paper, we\ncombine the advantages of the two technical routes and propose a novel\nexemplar-based neural commit message generation model, which treats the similar\ncommit message as an exemplar and leverages it to guide the neural network\nmodel to generate an accurate commit message. We perform extensive experiments\nand the results confirm the effectiveness of our model.",
          "link": "http://arxiv.org/abs/2203.02700",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "ECMG: Exemplar-based Commit Message Generation. (arXiv:2203.02700v2 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naser_M/0/1/0/all/0/1\">M.Z. Naser</a>",
          "description": "Much of our experiments are designed to uncover the cause(s) and effect(s)\nbehind a data generating mechanism (i.e., phenomenon) we happen to be\ninterested in. Uncovering such relationships allows us to identify the true\nworking of a phenomenon and, most importantly, articulate a model that may\nenable us to further explore the phenomenon on hand and/or allow us to predict\nit accurately. Fundamentally, such models are likely to be derived via a causal\napproach (as opposed to an observational or empirical mean). In this approach,\ncausal discovery is required to create a causal model, which can then be\napplied to infer the influence of interventions, and answer any hypothetical\nquestions (i.e., in the form of What ifs? Etc.) that we might have. This paper\nbuilds a case for causal discovery and causal inference and contrasts that\nagainst traditional machine learning approaches; all from a civil and\nstructural engineering perspective. More specifically, this paper outlines the\nkey principles of causality and the most commonly used algorithms and packages\nfor causal discovery and causal inference. Finally, this paper also presents a\nseries of examples and case studies of how causal concepts can be adopted for\nour domain.",
          "link": "http://arxiv.org/abs/2204.01543",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "Causality, Causal Discovery, and Causal Inference in Structural Engineering. (arXiv:2204.01543v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daesoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aune_E/0/1/0/all/0/1\">Erlend Aune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langet_N/0/1/0/all/0/1\">Nad&#xe8;ge Langet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eidsvik_J/0/1/0/all/0/1\">Jo Eidsvik</a>",
          "description": "One of the latest self-supervised learning (SSL) methods, VICReg, showed a\ngreat performance both in the linear evaluation and the fine-tuning evaluation.\nHowever, VICReg is proposed in computer vision and it learns by pulling\nrepresentations of random crops of an image while maintaining the\nrepresentation space by the variance and covariance loss. However, VICReg would\nbe ineffective on non-stationary time series where different parts/crops of\ninput should be differently encoded to consider the non-stationarity. Another\nrecent SSL proposal, Temporal Neighborhood Coding (TNC) is effective for\nencoding non-stationary time series. This study shows that a combination of a\nVICReg-style method and TNC is very effective for SSL on non-stationary time\nseries, where a non-stationary seismic signal time series is used as an\nevaluation dataset.",
          "link": "http://arxiv.org/abs/2204.02697",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance Evaluated on Non-stationary Seismic Signal Time Series. (arXiv:2204.02697v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verdecchia_R/0/1/0/all/0/1\">Roberto Verdecchia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_L/0/1/0/all/0/1\">Lu&#xed;s Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sallou_J/0/1/0/all/0/1\">June Sallou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Michelle Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wickenden_J/0/1/0/all/0/1\">James Wickenden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hotellier_E/0/1/0/all/0/1\">Estelle Hotellier</a>",
          "description": "With the growing availability of large-scale datasets, and the popularization\nof affordable storage and computational capabilities, the energy consumed by AI\nis becoming a growing concern. To address this issue, in recent years, studies\nhave focused on demonstrating how AI energy efficiency can be improved by\ntuning the model training strategy. Nevertheless, how modifications applied to\ndatasets can impact the energy consumption of AI is still an open question. To\nfill this gap, in this exploratory study, we evaluate if data-centric\napproaches can be utilized to improve AI energy efficiency. To achieve our\ngoal, we conduct an empirical experiment, executed by considering 6 different\nAI algorithms, a dataset comprising 5,574 data points, and two dataset\nmodifications (number of data points and number of features). Our results show\nevidence that, by exclusively conducting modifications on datasets, energy\nconsumption can be drastically reduced (up to 92.16%), often at the cost of a\nnegligible or even absent accuracy decline. As additional introductory results,\nwe demonstrate how, by exclusively changing the algorithm used, energy savings\nup to two orders of magnitude can be achieved. In conclusion, this exploratory\ninvestigation empirically demonstrates the importance of applying data-centric\ntechniques to improve AI energy efficiency. Our results call for a research\nagenda that focuses on data-centric techniques, to further enable and\ndemocratize Green AI.",
          "link": "http://arxiv.org/abs/2204.02766",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "Data-Centric Green AI: An Exploratory Empirical Study. (arXiv:2204.02766v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.03706",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ramprasad_P/0/1/0/all/0/1\">Pratik Ramprasad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yuantong Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1\">Guang Cheng</a>",
          "description": "The recent emergence of reinforcement learning has created a demand for\nrobust statistical inference methods for the parameter estimates computed using\nthese algorithms. Existing methods for statistical inference in online learning\nare restricted to settings involving independently sampled observations, while\nexisting statistical inference methods in reinforcement learning (RL) are\nlimited to the batch setting. The online bootstrap is a flexible and efficient\napproach for statistical inference in linear stochastic approximation\nalgorithms, but its efficacy in settings involving Markov noise, such as RL,\nhas yet to be explored. In this paper, we study the use of the online bootstrap\nmethod for statistical inference in RL. In particular, we focus on the temporal\ndifference (TD) learning and Gradient TD (GTD) learning algorithms, which are\nthemselves special instances of linear stochastic approximation under Markov\nnoise. The method is shown to be distributionally consistent for statistical\ninference in policy evaluation, and numerical experiments are included to\ndemonstrate the effectiveness of this algorithm at statistical inference tasks\nacross a range of real RL environments.",
          "link": "http://arxiv.org/abs/2108.03706",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Online Bootstrap Inference For Policy Evaluation in Reinforcement Learning. (arXiv:2108.03706v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.00185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Matthew S. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1\">Animesh Garg</a>",
          "description": "Policy gradient methods have been frequently applied to problems in control\nand reinforcement learning with great success, yet existing convergence\nanalysis still relies on non-intuitive, impractical and often opaque\nconditions. In particular, existing rates are achieved in limited settings,\nunder strict regularity conditions. In this work, we establish explicit\nconvergence rates of policy gradient methods, extending the convergence regime\nto weakly smooth policy classes with $L_2$ integrable gradient. We provide\nintuitive examples to illustrate the insight behind these new conditions.\nNotably, our analysis also shows that convergence rates are achievable for both\nthe standard policy gradient and the natural policy gradient algorithms under\nthese assumptions. Lastly we provide performance guarantees for the converged\npolicies.",
          "link": "http://arxiv.org/abs/2111.00185",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Convergence and Optimality of Policy Gradient Methods in Weakly Smooth Settings. (arXiv:2111.00185v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozumnyi_D/0/1/0/all/0/1\">Denys Rozumnyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oswald_M/0/1/0/all/0/1\">Martin R. Oswald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrari_V/0/1/0/all/0/1\">Vittorio Ferrari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>",
          "description": "We propose a method for jointly estimating the 3D motion, 3D shape, and\nappearance of highly motion-blurred objects from a video. To this end, we model\nthe blurred appearance of a fast moving object in a generative fashion by\nparametrizing its 3D position, rotation, velocity, acceleration, bounces,\nshape, and texture over the duration of a predefined time window spanning\nmultiple frames. Using differentiable rendering, we are able to estimate all\nparameters by minimizing the pixel-wise reprojection error to the input video\nvia backpropagating through a rendering pipeline that accounts for motion blur\nby averaging the graphics output over short time intervals. For that purpose,\nwe also estimate the camera exposure gap time within the same optimization. To\naccount for abrupt motion changes like bounces, we model the motion trajectory\nas a piece-wise polynomial, and we are able to estimate the specific time of\nthe bounce at sub-frame accuracy. Experiments on established benchmark datasets\ndemonstrate that our method outperforms previous methods for fast moving object\ndeblurring and 3D reconstruction.",
          "link": "http://arxiv.org/abs/2111.14465",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Motion-from-Blur: 3D Shape and Motion Estimation of Motion-blurred Objects in Videos. (arXiv:2111.14465v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04175",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Elmas_G/0/1/0/all/0/1\">Gokberk Elmas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dar_S/0/1/0/all/0/1\">Salman UH Dar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korkmaz_Y/0/1/0/all/0/1\">Yilmaz Korkmaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ceyani_E/0/1/0/all/0/1\">Emir Ceyani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Susam_B/0/1/0/all/0/1\">Burak Susam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ozbey_M/0/1/0/all/0/1\">Muzaffer &#xd6;zbey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Avestimehr_S/0/1/0/all/0/1\">Salman Avestimehr</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cukur_T/0/1/0/all/0/1\">Tolga &#xc7;ukur</a>",
          "description": "Multi-institutional efforts can facilitate training of deep MRI\nreconstruction models, albeit privacy risks arise during cross-site sharing of\nimaging data. Federated learning (FL) has recently been introduced to address\nprivacy concerns by enabling distributed training without transfer of imaging\ndata. Existing FL methods for MRI reconstruction employ conditional models to\nmap from undersampled to fully-sampled acquisitions via explicit knowledge of\nthe imaging operator. Since conditional models generalize poorly across\ndifferent acceleration rates or sampling densities, imaging operators must be\nfixed between training and testing, and they are typically matched across\nsites. To improve generalization and flexibility in multi-institutional\ncollaborations, here we introduce a novel method for MRI reconstruction based\non Federated learning of Generative IMage Priors (FedGIMP). FedGIMP leverages a\ntwo-stage approach: cross-site learning of a generative MRI prior, and\nsubject-specific injection of the imaging operator. The global MRI prior is\nlearned via an unconditional adversarial model that synthesizes high-quality MR\nimages based on latent variables. Specificity in the prior is preserved via a\nmapper subnetwork that produces site-specific latents. During inference, the\nprior is combined with subject-specific imaging operators to enable\nreconstruction, and further adapted to individual test samples by minimizing\ndata-consistency loss. Comprehensive experiments on multi-institutional\ndatasets clearly demonstrate enhanced generalization performance of FedGIMP\nagainst site-specific and federated methods based on conditional models, as\nwell as traditional reconstruction methods.",
          "link": "http://arxiv.org/abs/2202.04175",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Federated Learning of Generative Image Priors for MRI Reconstruction. (arXiv:2202.04175v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.12800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Solaiyappan_S/0/1/0/all/0/1\">Siddharth Solaiyappan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuxin Wen</a>",
          "description": "Deep generative networks in recent years have reinforced the need for caution\nwhile consuming various modalities of digital information. One avenue of\ndeepfake creation is aligned with injection and removal of tumors from medical\nscans. Failure to detect medical deepfakes can lead to large setbacks on\nhospital resources or even loss of life. This paper attempts to address the\ndetection of such attacks with a structured case study. Specifically, we\nevaluate eight different machine learning algorithms, which including three\nconventional machine learning methods, support vector machine, random forest,\ndecision tree, and five deep learning models, DenseNet121, DenseNet201,\nResNet50, ResNet101, VGG19, on distinguishing between tampered and untampered\nimages.For deep learning models, the five models are used for feature\nextraction, then fine-tune for each pre-trained model is performed. The\nfindings of this work show near perfect accuracy in detecting instances of\ntumor injections and removals.",
          "link": "http://arxiv.org/abs/2109.12800",
          "publishedOn": "2022-04-09T00:48:55.366Z",
          "wordCount": null,
          "title": "Machine Learning based Medical Image Deepfake Detection: A Comparative Study. (arXiv:2109.12800v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castellano_A/0/1/0/all/0/1\">Agustin Castellano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_H/0/1/0/all/0/1\">Hancheng Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bazerque_J/0/1/0/all/0/1\">Juan Bazerque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallada_E/0/1/0/all/0/1\">Enrique Mallada</a>",
          "description": "In this work we address the problem of finding feasible policies for\nConstrained Markov Decision Processes under probability one constraints. We\nargue that stationary policies are not sufficient for solving this problem, and\nthat a rich class of policies can be found by endowing the controller with a\nscalar quantity, so called budget, that tracks how close the agent is to\nviolating the constraint. We show that the minimal budget required to act\nsafely can be obtained as the smallest fixed point of a Bellman-like operator,\nfor which we analyze its convergence properties. We also show how to learn this\nquantity when the true kernel of the Markov decision process is not known,\nwhile providing sample-complexity bounds. The utility of knowing this minimal\nbudget relies in that it can aid in the search of optimal or near-optimal\npolicies by shrinking down the region of the state space the agent must\nnavigate. Simulations illustrate the different nature of probability one\nconstraints against the typically used constraints in expectation.",
          "link": "http://arxiv.org/abs/2112.05198",
          "publishedOn": "2022-04-09T00:48:55.365Z",
          "wordCount": null,
          "title": "Reinforcement Learning with Almost Sure Constraints. (arXiv:2112.05198v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.11200",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Kwak_Y/0/1/0/all/0/1\">Yunseok Kwak</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Yun_W/0/1/0/all/0/1\">Won Joon Yun</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_J/0/1/0/all/0/1\">Jae Pyoung Kim</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cho_H/0/1/0/all/0/1\">Hyunhee Cho</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Choi_M/0/1/0/all/0/1\">Minseok Choi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jung_S/0/1/0/all/0/1\">Soyi Jung</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_J/0/1/0/all/0/1\">Joongheon Kim</a>",
          "description": "Although deep learning (DL) has already become a state-of-the-art technology\nfor various data processing tasks, data security and computational overload\nproblems often arise due to their high data and computational power dependency.\nTo solve this problem, quantum deep learning (QDL) and distributed deep\nlearning (DDL) has emerged to complement existing DL methods. Furthermore, a\nquantum distributed deep learning (QDDL) technique that combines and maximizes\nthese advantages is getting attention. This paper compares several model\nstructures for QDDL and discusses their possibilities and limitations to\nleverage QDDL for some representative application scenarios.",
          "link": "http://arxiv.org/abs/2202.11200",
          "publishedOn": "2022-04-09T00:48:55.365Z",
          "wordCount": null,
          "title": "Quantum Distributed Deep Learning Architectures: Models, Discussions, and Applications. (arXiv:2202.11200v3 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.15783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polk_S/0/1/0/all/0/1\">Sam L. Polk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_J/0/1/0/all/0/1\">James M. Murphy</a>",
          "description": "Clustering algorithms partition a dataset into groups of similar points. The\nprimary contribution of this article is the Multiscale Spatially-Regularized\nDiffusion Learning (M-SRDL) clustering algorithm, which uses\nspatially-regularized diffusion distances to efficiently and accurately learn\nmultiple scales of latent structure in hyperspectral images. The M-SRDL\nclustering algorithm extracts clusterings at many scales from a hyperspectral\nimage and outputs these clusterings' variation of information-barycenter as an\nexemplar for all underlying cluster structure. We show that incorporating\nspatial regularization into a multiscale clustering framework results in\nsmoother and more coherent clusters when applied to hyperspectral data,\nyielding more accurate clustering labels.",
          "link": "http://arxiv.org/abs/2103.15783",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "Multiscale Clustering of Hyperspectral Images Through Spectral-Spatial Diffusion Geometry. (arXiv:2103.15783v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.02375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Miao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1\">Praveer Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1\">Jayashree Kalpathy-Cramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Federated learning is an emerging research paradigm for enabling\ncollaboratively training deep learning models without sharing patient data.\nHowever, the data from different institutions are usually heterogeneous across\ninstitutions, which may reduce the performance of models trained using\nfederated learning. In this study, we propose a novel heterogeneity-aware\nfederated learning method, SplitAVG, to overcome the performance drops from\ndata heterogeneity in federated learning. Unlike previous federated methods\nthat require complex heuristic training or hyper parameter tuning, our SplitAVG\nleverages the simple network split and feature map concatenation strategies to\nencourage the federated model training an unbiased estimator of the target data\ndistribution. We compare SplitAVG with seven state-of-the-art federated\nlearning methods, using centrally hosted training data as the baseline on a\nsuite of both synthetic and real-world federated datasets. We find that the\nperformance of models trained using all the comparison federated learning\nmethods degraded significantly with the increasing degrees of data\nheterogeneity. In contrast, SplitAVG method achieves comparable results to the\nbaseline method under all heterogeneous settings, that it achieves 96.2% of the\naccuracy and 110.4% of the mean absolute error obtained by the baseline in a\ndiabetic retinopathy binary classification dataset and a bone age prediction\ndataset, respectively, on highly heterogeneous data partitions. We conclude\nthat SplitAVG method can effectively overcome the performance drops from\nvariability in data distributions across institutions. Experimental results\nalso show that SplitAVG can be adapted to different base networks and\ngeneralized to various types of medical imaging tasks.",
          "link": "http://arxiv.org/abs/2107.02375",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "SplitAVG: A heterogeneity-aware federated deep learning method for medical imaging. (arXiv:2107.02375v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_T/0/1/0/all/0/1\">Tristan Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1\">Edward J. Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahlou_S/0/1/0/all/0/1\">Salem Lahlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_M/0/1/0/all/0/1\">Mo Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1\">Emmanuel Bengio</a>",
          "description": "Generative Flow Networks (GFlowNets) have been introduced as a method to\nsample a diverse set of candidates in an active learning context, with a\ntraining objective that makes them approximately sample in proportion to a\ngiven reward function. In this paper, we show a number of additional\ntheoretical properties of GFlowNets. They can be used to estimate joint\nprobability distributions and the corresponding marginal distributions where\nsome variables are unspecified and, of particular interest, can represent\ndistributions over composite objects like sets and graphs. GFlowNets amortize\nthe work typically done by computationally expensive MCMC methods in a single\nbut trained generative pass. They could also be used to estimate partition\nfunctions and free energies, conditional probabilities of supersets\n(supergraphs) given a subset (subgraph), as well as marginal distributions over\nall supersets (supergraphs) of a given set (graph). We introduce variations\nenabling the estimation of entropy and mutual information, sampling from a\nPareto frontier, connections to reward-maximizing policies, and extensions to\nstochastic environments, continuous actions and modular energy functions.",
          "link": "http://arxiv.org/abs/2111.09266",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "GFlowNet Foundations. (arXiv:2111.09266v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zechun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1\">Kwang-Ting Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Dong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhiqiang Shen</a>",
          "description": "The nonuniform quantization strategy for compressing neural networks usually\nachieves better performance than its counterpart, i.e., uniform strategy, due\nto its superior representational capacity. However, many nonuniform\nquantization methods overlook the complicated projection process in\nimplementing the nonuniformly quantized weights/activations, which incurs\nnon-negligible time and space overhead in hardware deployment. In this study,\nwe propose Nonuniform-to-Uniform Quantization (N2UQ), a method that can\nmaintain the strong representation ability of nonuniform methods while being\nhardware-friendly and efficient as the uniform quantization for model\ninference. We achieve this through learning the flexible in-equidistant input\nthresholds to better fit the underlying distribution while quantizing these\nreal-valued inputs into equidistant output levels. To train the quantized\nnetwork with learnable input thresholds, we introduce a generalized\nstraight-through estimator (G-STE) for intractable backward derivative\ncalculation w.r.t. threshold parameters. Additionally, we consider entropy\npreserving regularization to further reduce information loss in weight\nquantization. Even under this adverse constraint of imposing uniformly\nquantized weights and activations, our N2UQ outperforms state-of-the-art\nnonuniform quantization methods by 0.5~1.7 on ImageNet, demonstrating the\ncontribution of N2UQ design. Code and models are available at:\nhttps://github.com/liuzechun/Nonuniform-to-Uniform-Quantization.",
          "link": "http://arxiv.org/abs/2111.14826",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via Generalized Straight-Through Estimation. (arXiv:2111.14826v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bowen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wenxin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shinozaki_T/0/1/0/all/0/1\">Takahiro Shinozaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>",
          "description": "The long-tailed class distribution in visual recognition tasks poses great\nchallenges for neural networks on how to handle the biased predictions between\nhead and tail classes, i.e., the model tends to classify tail classes as head\nclasses. While existing research focused on data resampling and loss function\nengineering, in this paper, we take a different perspective: the classification\nmargins. We study the relationship between the margins and logits\n(classification scores) and empirically observe the biased margins and the\nbiased logits are positively correlated. We propose MARC, a simple yet\neffective MARgin Calibration function to dynamically calibrate the biased\nmargins for unbiased logits. We validate MARC through extensive experiments on\ncommon long-tailed benchmarks including CIFAR-LT, ImageNet-LT, Places-LT, and\niNaturalist-LT. Experimental results demonstrate that our MARC achieves\nfavorable results on these benchmarks. In addition, MARC is extremely easy to\nimplement with just three lines of code. We hope this simple method will\nmotivate people to rethink the biased margins and biased logits in long-tailed\nvisual recognition.",
          "link": "http://arxiv.org/abs/2112.07225",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "Margin Calibration for Long-Tailed Visual Recognition. (arXiv:2112.07225v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.06934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akyon_F/0/1/0/all/0/1\">Fatih Cagatay Akyon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altinuc_S/0/1/0/all/0/1\">Sinan Onur Altinuc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Temizel_A/0/1/0/all/0/1\">Alptekin Temizel</a>",
          "description": "Detection of small objects and objects far away in the scene is a major\nchallenge in surveillance applications. Such objects are represented by small\nnumber of pixels in the image and lack sufficient details, making them\ndifficult to detect using conventional detectors. In this work, an open-source\nframework called Slicing Aided Hyper Inference (SAHI) is proposed that provides\na generic slicing aided inference and fine-tuning pipeline for small object\ndetection. The proposed technique is generic in the sense that it can be\napplied on top of any available object detector without any fine-tuning.\nExperimental evaluations, using object detection baselines on the Visdrone and\nxView aerial object detection datasets show that the proposed inference method\ncan increase object detection AP by 6.8%, 5.1% and 5.3% for FCOS, VFNet and\nTOOD detectors, respectively. Moreover, the detection accuracy can be further\nincreased with a slicing aided fine-tuning, resulting in a cumulative increase\nof 12.7%, 13.4% and 14.5% AP in the same order. Proposed technique has been\nintegrated with Detectron2, MMDetection and YOLOv5 models and it is publicly\navailable at https://github.com/obss/sahi.git .",
          "link": "http://arxiv.org/abs/2202.06934",
          "publishedOn": "2022-04-09T00:48:55.363Z",
          "wordCount": null,
          "title": "Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection. (arXiv:2202.06934v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05774",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1\">Yunhan Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Q/0/1/0/all/0/1\">Quanyan Zhu</a>",
          "description": "In this work, we study the deception of a Linear-Quadratic-Gaussian (LQG)\nagent by manipulating the cost signals. We show that a small falsification of\nthe cost parameters will only lead to a bounded change in the optimal policy.\nThe bound is linear on the amount of falsification the attacker can apply to\nthe cost parameters. We propose an attack model where the attacker aims to\nmislead the agent into learning a `nefarious' policy by intentionally\nfalsifying the cost parameters. We formulate the attack's problem as a convex\noptimization problem and develop necessary and sufficient conditions to check\nthe achievability of the attacker's goal.\n\nWe showcase the adversarial manipulation on two types of LQG learners: the\nbatch RL learner and the other is the adaptive dynamic programming (ADP)\nlearner. Our results demonstrate that with only 2.296% of falsification on the\ncost data, the attacker misleads the batch RL into learning the 'nefarious'\npolicy that leads the vehicle to a dangerous position. The attacker can also\ngradually trick the ADP learner into learning the same `nefarious' policy by\nconsistently feeding the learner a falsified cost signal that stays close to\nthe actual cost signal. The paper aims to raise people's awareness of the\nsecurity threats faced by RL-enabled control systems.",
          "link": "http://arxiv.org/abs/2203.05774",
          "publishedOn": "2022-04-09T00:48:55.363Z",
          "wordCount": null,
          "title": "Reinforcement Learning for Linear Quadratic Control is Vulnerable Under Cost Manipulation. (arXiv:2203.05774v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.05113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tseng_W/0/1/0/all/0/1\">Wei-Cheng Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kao_W/0/1/0/all/0/1\">Wei-Tsung Kao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Recently, adapting the idea of self-supervised learning (SSL) on continuous\nspeech has started gaining attention. SSL models pre-trained on a huge amount\nof unlabeled audio can generate general-purpose representations that benefit a\nwide variety of speech processing tasks. Despite their ubiquitous deployment,\nhowever, the potential privacy risks of these models have not been well\ninvestigated. In this paper, we present the first privacy analysis on several\nSSL speech models using Membership Inference Attacks (MIA) under black-box\naccess. The experiment results show that these pre-trained models are\nvulnerable to MIA and prone to membership information leakage with high Area\nUnder the Curve (AUC) in both utterance-level and speaker-level. Furthermore,\nwe also conduct several ablation studies to understand the factors that\ncontribute to the success of MIA.",
          "link": "http://arxiv.org/abs/2111.05113",
          "publishedOn": "2022-04-09T00:48:55.362Z",
          "wordCount": null,
          "title": "Membership Inference Attacks Against Self-supervised Speech Models. (arXiv:2111.05113v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bellinger_C/0/1/0/all/0/1\">Colin Bellinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drozdyuk_A/0/1/0/all/0/1\">Andriy Drozdyuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowley_M/0/1/0/all/0/1\">Mark Crowley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamblyn_I/0/1/0/all/0/1\">Isaac Tamblyn</a>",
          "description": "The use of reinforcement learning (RL) in scientific applications, such as\nmaterials design and automated chemistry, is increasing. A major challenge,\nhowever, lies in fact that measuring the state of the system is often costly\nand time consuming in scientific applications, whereas policy learning with RL\nrequires a measurement after each time step. In this work, we make the\nmeasurement costs explicit in the form of a costed reward and propose a\nframework that enables off-the-shelf deep RL algorithms to learn a policy for\nboth selecting actions and determining whether or not to measure the current\nstate of the system at each time step. In this way, the agents learn to balance\nthe need for information with the cost of information. Our results show that\nwhen trained under this regime, the Dueling DQN and PPO agents can learn\noptimal action policies whilst making up to 50\\% fewer state measurements, and\nrecurrent neural networks can produce a greater than 50\\% reduction in\nmeasurements. We postulate the these reduction can help to lower the barrier to\napplying RL to real-world scientific applications.",
          "link": "http://arxiv.org/abs/2112.07535",
          "publishedOn": "2022-04-09T00:48:55.362Z",
          "wordCount": null,
          "title": "Scientific Discovery and the Cost of Measurement -- Balancing Information and Cost in Reinforcement Learning. (arXiv:2112.07535v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.14417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Donghwan Lee</a>",
          "description": "The goal of this paper is to investigate a control theoretic analysis of\nlinear stochastic iterative algorithm and temporal difference (TD) learning.\nTD-learning is a linear stochastic iterative algorithm to estimate the value\nfunction of a given policy for a Markov decision process, which is one of the\nmost popular and fundamental reinforcement learning algorithms. While there has\nbeen a series of successful works in theoretical analysis of TD-learning, it\nwas not until recently that researchers found some guarantees on its\nstatistical efficiency. In this paper, we propose a control theoretic\nfinite-time analysis TD-learning, which exploits standard notions in linear\nsystem control communities. Therefore, the proposed work provides additional\ninsights on TD-learning and reinforcement learning with simple concepts and\nanalysis tools in control theory.",
          "link": "http://arxiv.org/abs/2112.14417",
          "publishedOn": "2022-04-09T00:48:55.362Z",
          "wordCount": null,
          "title": "Control Theoretic Analysis of Temporal Difference Learning. (arXiv:2112.14417v4 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_C/0/1/0/all/0/1\">Carl Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1\">Aditya Grover</a>",
          "description": "The goal of imitation learning is to mimic expert behavior from\ndemonstrations, without access to an explicit reward signal. A popular class of\napproach infers the (unknown) reward function via inverse reinforcement\nlearning (IRL) followed by maximizing this reward function via reinforcement\nlearning (RL). The policies learned via these approaches are however very\nbrittle in practice and deteriorate quickly even with small test-time\nperturbations due to compounding errors. We propose Imitation with Planning at\nTest-time (IMPLANT), a new meta-algorithm for imitation learning that utilizes\ndecision-time planning to correct for compounding errors of any base imitation\npolicy. In contrast to existing approaches, we retain both the imitation policy\nand the rewards model at decision-time, thereby benefiting from the learning\nsignal of the two components. Empirically, we demonstrate that IMPLANT\nsignificantly outperforms benchmark imitation learning approaches on standard\ncontrol environments and excels at zero-shot generalization when subject to\nchallenging perturbations in test-time dynamics.",
          "link": "http://arxiv.org/abs/2204.03597",
          "publishedOn": "2022-04-09T00:48:55.361Z",
          "wordCount": null,
          "title": "Imitating, Fast and Slow: Robust learning from demonstrations via decision-time planning. (arXiv:2204.03597v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.14836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhun Deng</a>",
          "description": "Representations of the world environment play a crucial role in artificial\nintelligence. It is often inefficient to conduct reasoning and inference\ndirectly in the space of raw sensory representations, such as pixel values of\nimages. Representation learning allows us to automatically discover suitable\nrepresentations from raw sensory data. For example, given raw sensory data, a\ndeep neural network learns nonlinear representations at its hidden layers,\nwhich are subsequently used for classification at its output layer. This\nhappens implicitly during training through minimizing a supervised or\nunsupervised loss. In this paper, we study the dynamics of such implicit\nnonlinear representation learning. We identify a pair of a new assumption and a\nnovel condition, called the common model structure assumption and the\ndata-architecture alignment condition. Under the common model structure\nassumption, the data-architecture alignment condition is shown to be sufficient\nfor the global convergence and necessary for the global optimality. Moreover,\nour theory explains how and when increasing the network size does and does not\nimprove the training behaviors in the practical regime. Our results provide\npractical guidance for designing a model structure: e.g., the common model\nstructure assumption can be used as a justification for using a particular\nmodel structure instead of others. We also derive a new training framework,\nwhich satisfies the data-architecture alignment condition by automatically\nmodifying any given training algorithm. Given a standard training algorithm,\nthe framework running its modified version is empirically shown to maintain\ncompetitive test performances while providing global convergence guarantees for\ndeep residual neural networks with convolutions, skip connections, and batch\nnormalization with datasets, including MNIST, CIFAR-10, CIFAR-100, Semeion,\nKMNIST and SVHN.",
          "link": "http://arxiv.org/abs/2106.14836",
          "publishedOn": "2022-04-09T00:48:55.361Z",
          "wordCount": null,
          "title": "Understanding Dynamics of Nonlinear Representation Learning and Its Application. (arXiv:2106.14836v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Croitoru_F/0/1/0/all/0/1\">Florinel-Alin Croitoru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grigore_D/0/1/0/all/0/1\">Diana-Nicoleta Grigore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>",
          "description": "During the training process, deep neural networks implicitly learn to\nrepresent the input data samples through a hierarchy of features, where the\nsize of the hierarchy is determined by the number of layers. In this paper, we\nfocus on enforcing the discriminative power of the high-level representations,\nthat are typically learned by the deeper layers (closer to the output). To this\nend, we introduce a new loss term inspired by the Gini impurity, which is aimed\nat minimizing the entropy (increasing the discriminative power) of individual\nhigh-level features with respect to the class labels. Although our Gini loss\ninduces highly-discriminative features, it does not ensure that the\ndistribution of the high-level features matches the distribution of the\nclasses. As such, we introduce another loss term to minimize the\nKullback-Leibler divergence between the two distributions. We conduct\nexperiments on two image classification data sets (CIFAR-100 and Caltech 101),\nconsidering multiple neural architectures ranging from convolutional networks\n(ResNet-17, ResNet-18, ResNet-50) to transformers (CvT). Our empirical results\nshow that integrating our novel loss terms into the training objective\nconsistently outperforms the models trained with cross-entropy alone, without\nincreasing the inference time at all.",
          "link": "http://arxiv.org/abs/2202.07073",
          "publishedOn": "2022-04-09T00:48:55.361Z",
          "wordCount": null,
          "title": "Discriminability-enforcing loss to improve representation learning. (arXiv:2202.07073v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krug_A/0/1/0/all/0/1\">Andreas Krug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratul_R/0/1/0/all/0/1\">Raihan Kabir Ratul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stober_S/0/1/0/all/0/1\">Sebastian Stober</a>",
          "description": "Machine Learning with Deep Neural Networks (DNNs) has become a successful\ntool in solving tasks across various fields of application. The success of DNNs\nis strongly connected to their high complexity in terms of the number of\nnetwork layers or of neurons in each layer, which severely complicates to\nunderstand how DNNs solve their learned task. To improve the explainability of\nDNNs, we adapt methods from neuroscience because this field has a rich\nexperience in analyzing complex and opaque systems. In this work, we draw\ninspiration from how neuroscience uses topographic maps to visualize the\nactivity of the brain when it performs certain tasks. Transferring this\napproach to DNNs can help to visualize and understand their internal processes\nmore intuitively, too. However, the inner structures of brains and DNNs differ\nsubstantially. Therefore, to be able to visualize activations of neurons in\nDNNs as topographic maps, we research techniques to layout the neurons in a\ntwo-dimensional space in which neurons of similar activity are in the vicinity\nof each other. In this work, we introduce and compare different methods to\nobtain a topographic layout of the neurons in a network layer. Moreover, we\ndemonstrate how to use the resulting topographic activation maps to identify\nerrors or encoded biases in DNNs or data sets. Our novel visualization\ntechnique improves the transparency of DNN-based algorithmic decision-making\nsystems and is accessible to a broad audience because topographic maps are\nintuitive to interpret without expert-knowledge in Machine Learning.",
          "link": "http://arxiv.org/abs/2204.03528",
          "publishedOn": "2022-04-09T00:48:55.360Z",
          "wordCount": null,
          "title": "Visualizing Deep Neural Networks with Topographic Activation Maps. (arXiv:2204.03528v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.02072",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Kalashev_O/0/1/0/all/0/1\">O. Kalashev</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kharuk_I/0/1/0/all/0/1\">I. Kharuk</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kuznetsov_M/0/1/0/all/0/1\">M. Kuznetsov</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Rubtsov_G/0/1/0/all/0/1\">G. Rubtsov</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sako_T/0/1/0/all/0/1\">T. Sako</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Tsunesada_Y/0/1/0/all/0/1\">Y. Tsunesada</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Zhezher_Y/0/1/0/all/0/1\">Ya. Zhezher</a>",
          "description": "We introduce a novel method for identifying the mass composition of\nultra-high-energy cosmic rays using deep learning. The key idea of the method\nis to use a chain of two neural networks. The first network predicts the type\nof a primary particle for individual events, while the second infers the mass\ncomposition of an ensemble of events. We apply this method to the Monte-Carlo\ndata for the Telescope Array Surface Detectors readings, on which it yields an\nunprecedented low error of 7% for 4-component approximation. We also discuss\nthe problems of applying the developed method to the experimental data, and the\nway they can be resolved.",
          "link": "http://arxiv.org/abs/2112.02072",
          "publishedOn": "2022-04-09T00:48:55.359Z",
          "wordCount": null,
          "title": "Deep learning method for identifying mass composition of ultra-high-energy cosmic rays. (arXiv:2112.02072v2 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yafei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_J/0/1/0/all/0/1\">John Keller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1\">Sebastian Scherer</a>",
          "description": "In traditional robot exploration methods, the robot usually does not have\nprior biases about the environment it is exploring. Thus the robot assigns\nequal importance to the goals which leads to insufficient exploration\nefficiency. Alternative, often a hand-tuned policy is used to tweak the value\nof goals. In this paper, we present a method to learn how \"good\" some states\nare, measured by the state value function, to provide a hint for the robot to\nmake exploration decisions. We propose to learn state value functions from\nprevious offline collected datasets and then transfer and improve the value\nfunction during testing in a new environment. Moreover, the environments\nusually have very few and even no extrinsic reward or feedback for the robot.\nTherefore in this work, we also tackle the problem of sparse extrinsic rewards\nfrom the environments. We design several intrinsic rewards to encourage the\nrobot to obtain more information during exploration. These reward functions\nthen become the building blocks of the state value functions. We test our\nmethod on challenging subterranean and urban environments. To the best of our\nknowledge, this work for the first time demonstrates value function prediction\nwith previous collected datasets to help exploration in challenging\nsubterranean environments.",
          "link": "http://arxiv.org/abs/2204.03140",
          "publishedOn": "2022-04-09T00:48:55.358Z",
          "wordCount": null,
          "title": "Learning and Transferring Value Function for Robot Exploration in Subterranean Environments. (arXiv:2204.03140v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1\">Satwik Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Swaroop Ghosh</a>",
          "description": "In the last few years, quantum computing has experienced a growth spurt. One\nexciting avenue of quantum computing is quantum machine learning (QML) which\ncan exploit the high dimensional Hilbert space to learn richer representations\nfrom limited data and thus can efficiently solve complex learning tasks.\nDespite the increased interest in QML, there have not been many studies that\ndiscuss the security aspects of QML. In this work, we explored the possible\nfuture applications of QML in the hardware security domain. We also expose the\nsecurity vulnerabilities of QML and emerging attack models, and corresponding\ncountermeasures.",
          "link": "http://arxiv.org/abs/2204.03625",
          "publishedOn": "2022-04-09T00:48:55.345Z",
          "wordCount": null,
          "title": "Security Aspects of Quantum Machine Learning: Opportunities, Threats and Defenses. (arXiv:2204.03625v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tzinis_E/0/1/0/all/0/1\">Efthymios Tzinis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wichern_G/0/1/0/all/0/1\">Gordon Wichern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanian_A/0/1/0/all/0/1\">Aswin Subramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smaragdis_P/0/1/0/all/0/1\">Paris Smaragdis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roux_J/0/1/0/all/0/1\">Jonathan Le Roux</a>",
          "description": "We introduce a new paradigm for single-channel target source separation where\nthe sources of interest can be distinguished using non-mutually exclusive\nconcepts (e.g., loudness, gender, language, spatial location, etc). Our\nproposed heterogeneous separation framework can seamlessly leverage datasets\nwith large distribution shifts and learn cross-domain representations under a\nvariety of concepts used as conditioning. Our experiments show that training\nseparation models with heterogeneous conditions facilitates the generalization\nto new concepts with unseen out-of-domain data while also performing\nsubstantially higher than single-domain specialist models. Notably, such\ntraining leads to more robust learning of new harder source separation\ndiscriminative concepts and can yield improvements over permutation invariant\ntraining with oracle source selection. We analyze the intrinsic behavior of\nsource separation training with heterogeneous metadata and propose ways to\nalleviate emerging problems with challenging separation conditions. We release\nthe collection of preparation recipes for all datasets used to further promote\nresearch towards this challenging task.",
          "link": "http://arxiv.org/abs/2204.03594",
          "publishedOn": "2022-04-09T00:48:55.344Z",
          "wordCount": null,
          "title": "Heterogeneous Target Speech Separation. (arXiv:2204.03594v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.06428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ibriga_H/0/1/0/all/0/1\">Hilda S Ibriga</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>",
          "description": "We aim to provably complete a sparse and highly-missing tensor in the\npresence of covariate information along tensor modes. Our motivation comes from\nonline advertising where users click-through-rates (CTR) on ads over various\ndevices form a CTR tensor that has about 96% missing entries and has many zeros\non non-missing entries, which makes the standalone tensor completion method\nunsatisfactory. Beside the CTR tensor, additional ad features or user\ncharacteristics are often available. In this paper, we propose\nCovariate-assisted Sparse Tensor Completion (COSTCO) to incorporate covariate\ninformation for the recovery of the sparse tensor. The key idea is to jointly\nextract latent components from both the tensor and the covariate matrix to\nlearn a synthetic representation. Theoretically, we derive the error bound for\nthe recovered tensor components and explicitly quantify the improvements on\nboth the reveal probability condition and the tensor recovery accuracy due to\ncovariates. Finally, we apply COSTCO to an advertisement dataset consisting of\na CTR tensor and ad covariate matrix, leading to 23% accuracy improvement over\nthe baseline. An important by-product is that ad latent components from COSTCO\nreveal interesting ad clusters, which are useful for better ad targeting.",
          "link": "http://arxiv.org/abs/2103.06428",
          "publishedOn": "2022-04-09T00:48:55.344Z",
          "wordCount": null,
          "title": "Covariate-assisted Sparse Tensor Completion. (arXiv:2103.06428v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yuxin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neiswanger_W/0/1/0/all/0/1\">Willie Neiswanger</a>",
          "description": "With the surge in the number of hyperparameters and training times of modern\nmachine learning models, hyperparameter tuning is becoming increasingly\nexpensive. However, after assessing 40 tuning methods systematically, we find\nthat each faces certain limitations. In particular, methods that speed up\ntuning via knowledge transfer typically require the final performance of\nhyperparameters and do not focus on low-fidelity information. As we demonstrate\nempirically, this common practice is suboptimal and can incur an unnecessary\nuse of resources. It is more cost-efficient to instead leverage low-fidelity\ntuning observations to measure inter-task similarity and transfer knowledge\nfrom existing to new tasks accordingly. However, performing multi-fidelity\ntuning comes with its own challenges in the transfer setting: the noise in\nadditional observations and the need for performance forecasting. Therefore, we\npropose and conduct a thorough analysis of a multi-task multi-fidelity Bayesian\noptimization framework, which leads to the best instantiation--amortized\nauto-tuning (AT2). We further present an offline-computed 27-task\nhyperparameter recommendation (HyperRec) database to serve the community.\nExtensive experiments on HyperRec and other real-world databases illustrate the\neffectiveness of our AT2 method.",
          "link": "http://arxiv.org/abs/2106.09179",
          "publishedOn": "2022-04-09T00:48:55.344Z",
          "wordCount": null,
          "title": "Amortized Auto-Tuning: Cost-Efficient Bayesian Transfer Optimization for Hyperparameter Recommendation. (arXiv:2106.09179v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.02166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1\">Yushuo Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pengyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_Z/0/1/0/all/0/1\">Zhengping Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_K/0/1/0/all/0/1\">Kaigui Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "The convolutional neural network has achieved great success in fulfilling\ncomputer vision tasks despite large computation overhead against efficient\ndeployment. Structured (channel) pruning is usually applied to reduce the model\nredundancy while preserving the network structure, such that the pruned network\ncan be easily deployed in practice. However, existing structured pruning\nmethods require hand-crafted rules which may lead to tremendous pruning space.\nIn this paper, we introduce Differentiable Annealing Indicator Search (DAIS)\nthat leverages the strength of neural architecture search in the channel\npruning and automatically searches for the effective pruned model with given\nconstraints on computation overhead. Specifically, DAIS relaxes the binarized\nchannel indicators to be continuous and then jointly learns both indicators and\nmodel parameters via bi-level optimization. To bridge the non-negligible\ndiscrepancy between the continuous model and the target binarized model, DAIS\nproposes an annealing-based procedure to steer the indicator convergence\ntowards binarized states. Moreover, DAIS designs various regularizations based\non a priori structural knowledge to control the pruning sparsity and to improve\nmodel performance. Experimental results show that DAIS outperforms\nstate-of-the-art pruning methods on CIFAR-10, CIFAR-100, and ImageNet.",
          "link": "http://arxiv.org/abs/2011.02166",
          "publishedOn": "2022-04-09T00:48:55.343Z",
          "wordCount": null,
          "title": "DAIS: Automatic Channel Pruning via Differentiable Annealing Indicator Search. (arXiv:2011.02166v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.08877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parekh_V/0/1/0/all/0/1\">Vivek Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flore_D/0/1/0/all/0/1\">Dominik Flore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schops_S/0/1/0/all/0/1\">Sebastian Sch&#xf6;ps</a>",
          "description": "Conventional magneto-static finite element analysis of electrical machine\ndesign is time-consuming and computationally expensive. Since each machine\ntopology has a distinct set of parameters, design optimization is commonly\nperformed independently. This paper presents a novel method for predicting Key\nPerformance Indicators (KPIs) of differently parameterized electrical machine\ntopologies at the same time by mapping a high dimensional integrated design\nparameters in a lower dimensional latent space using a variational autoencoder.\nAfter training, via a latent space, the decoder and multi-layer neural network\nwill function as meta-models for sampling new designs and predicting associated\nKPIs, respectively. This enables parameter-based concurrent multi-topology\noptimization.",
          "link": "http://arxiv.org/abs/2201.08877",
          "publishedOn": "2022-04-09T00:48:55.343Z",
          "wordCount": null,
          "title": "Variational Autoencoder based Metamodeling for Multi-Objective Topology Optimization of Electrical Machines. (arXiv:2201.08877v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02978",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lemercier_J/0/1/0/all/0/1\">Jean-Marie Lemercier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thiemann_J/0/1/0/all/0/1\">Joachim Thiemann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Koning_R/0/1/0/all/0/1\">Raphael Koning</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gerkmann_T/0/1/0/all/0/1\">Timo Gerkmann</a>",
          "description": "A two-stage online dereverberation algorithm for hearing devices is presented\nin this paper. The approach combines a multi-channel multi-frame linear\nfiltering approach with a single-channel single-frame post-filter. Both\ncomponents rely on power spectral density (PSD) estimates provided by deep\nneural networks (DNNs). This contribution extends our prior work, which shows\nthat directly optimizing for a criterion at the output of the multi-channel\nlinear filtering stage results in a more efficient dereverberation, as compared\nto placing the criterion at the output of the DNN to optimize the PSD\nestimation. In the present work, we show that the dereverberation performance\nof the proposed first stage particularly improves the early-to-mid\nreverberation ratio if trained end-to-end. We thus argue that it can be\ncombined with a post-filtering stage which benefits from the early-to-mid ratio\nimprovement and is consequently able to efficiently suppress the residual late\nreverberation. This proposed two stage procedure is shown to be both very\neffective in terms of dereverberation performance and computational demands.\nFurthermore, the proposed system can be adapted to the needs of different types\nof hearing-device users by controlling the amount of reduction of early\nreflections. The proposed system outperforms the previously proposed end-to-end\nDNN-supported linear filtering algorithm, as well as other traditional\napproaches, based on an evaluation using the noise-free version of the WHAMR!\ndataset.",
          "link": "http://arxiv.org/abs/2204.02978",
          "publishedOn": "2022-04-09T00:48:55.342Z",
          "wordCount": null,
          "title": "End-To-End Optimization of Online Neural Network-supported Two-Stage Dereverberation for Hearing Devices. (arXiv:2204.02978v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01533",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cuesta_Ramirez_J/0/1/0/all/0/1\">Jhouben Cuesta-Ramirez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Riche_R/0/1/0/all/0/1\">Rodolphe Le Riche</a>, <a href=\"http://arxiv.org/find/math/1/au:+Roustant_O/0/1/0/all/0/1\">Olivier Roustant</a>, <a href=\"http://arxiv.org/find/math/1/au:+Perrin_G/0/1/0/all/0/1\">Guillaume Perrin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Durantin_C/0/1/0/all/0/1\">Cedric Durantin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gliere_A/0/1/0/all/0/1\">Alain Gliere</a>",
          "description": "Most real optimization problems are defined over a mixed search space where\nthe variables are both discrete and continuous. In engineering applications,\nthe objective function is typically calculated with a numerically costly\nblack-box simulation.General mixed and costly optimization problems are\ntherefore of a great practical interest, yet their resolution remains in a\nlarge part an open scientific question. In this article, costly mixed problems\nare approached through Gaussian processes where the discrete variables are\nrelaxed into continuous latent variables. The continuous space is more easily\nharvested by classical Bayesian optimization techniques than a mixed space\nwould. Discrete variables are recovered either subsequently to the continuous\noptimization, or simultaneously with an additional continuous-discrete\ncompatibility constraint that is handled with augmented Lagrangians. Several\npossible implementations of such Bayesian mixed optimizers are compared. In\nparticular, the reformulation of the problem with continuous latent variables\nis put in competition with searches working directly in the mixed space. Among\nthe algorithms involving latent variables and an augmented Lagrangian, a\nparticular attention is devoted to the Lagrange multipliers for which a local\nand a global estimation techniques are studied. The comparisons are based on\nthe repeated optimization of three analytical functions and a beam design\nproblem.",
          "link": "http://arxiv.org/abs/2111.01533",
          "publishedOn": "2022-04-09T00:48:55.341Z",
          "wordCount": null,
          "title": "A comparison of mixed-variables Bayesian optimization approaches. (arXiv:2111.01533v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06416",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1\">Qingxu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_T/0/1/0/all/0/1\">Tenghai Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jianqiang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_Z/0/1/0/all/0/1\">Zhiqiang Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shiguang Wu</a>",
          "description": "When dealing with a series of imminent issues, humans can naturally\nconcentrate on a subset of these concerning issues by prioritizing them\naccording to their contributions to motivational indices, e.g., the probability\nof winning a game. This idea of concentration offers insights into\nreinforcement learning of sophisticated Large-scale Multi-Agent Systems (LMAS)\nparticipated by hundreds of agents. In such an LMAS, each agent receives a long\nseries of entity observations at each step, which can overwhelm existing\naggregation networks such as graph attention networks and cause inefficiency.\nIn this paper, we propose a concentration network called ConcNet. First,\nConcNet scores the observed entities considering several motivational indices,\ne.g., expected survival time and state value of the agents, and then ranks,\nprunes, and aggregates the encodings of observed entities to extract features.\nSecond, distinct from the well-known attention mechanism, ConcNet has a unique\nmotivational subnetwork to explicitly consider the motivational indices when\nscoring the observed entities. Furthermore, we present a concentration policy\ngradient architecture that can learn effective policies in LMAS from scratch.\nExtensive experiments demonstrate that the presented architecture has excellent\nscalability and flexibility, and significantly outperforms existing methods on\nLMAS benchmarks.",
          "link": "http://arxiv.org/abs/2203.06416",
          "publishedOn": "2022-04-09T00:48:55.340Z",
          "wordCount": 655,
          "title": "Concentration Network for Reinforcement Learning of Large-Scale Multi-Agent Systems. (arXiv:2203.06416v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.04121",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daunhawer_I/0/1/0/all/0/1\">Imant Daunhawer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutter_T/0/1/0/all/0/1\">Thomas M. Sutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_Cheong_K/0/1/0/all/0/1\">Kieran Chin-Cheong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palumbo_E/0/1/0/all/0/1\">Emanuele Palumbo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "Multimodal variational autoencoders (VAEs) have shown promise as efficient\ngenerative models for weakly-supervised data. Yet, despite their advantage of\nweak supervision, they exhibit a gap in generative quality compared to unimodal\nVAEs, which are completely unsupervised. In an attempt to explain this gap, we\nuncover a fundamental limitation that applies to a large family of\nmixture-based multimodal VAEs. We prove that the sub-sampling of modalities\nenforces an undesirable upper bound on the multimodal ELBO and thereby limits\nthe generative quality of the respective models. Empirically, we showcase the\ngenerative quality gap on both synthetic and real data and present the\ntradeoffs between different variants of multimodal VAEs. We find that none of\nthe existing approaches fulfills all desired criteria of an effective\nmultimodal generative model when applied on more complex datasets than those\nused in previous benchmarks. In summary, we identify, formalize, and validate\nfundamental limitations of VAE-based approaches for modeling weakly-supervised\ndata and discuss implications for real-world applications.",
          "link": "http://arxiv.org/abs/2110.04121",
          "publishedOn": "2022-04-09T00:48:55.331Z",
          "wordCount": null,
          "title": "On the Limitations of Multimodal VAEs. (arXiv:2110.04121v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.09371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1\">Neeraj Varshney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>",
          "description": "It's better to say \"I can't answer\" than to answer incorrectly. This\nselective prediction ability is crucial for NLP systems to be reliably deployed\nin real-world applications. Prior work has shown that existing selective\nprediction techniques fail to perform well, especially in the out-of-domain\nsetting. In this work, we propose a method that improves probability estimates\nof models by calibrating them using prediction confidence and difficulty score\nof instances. Using these two signals, we first annotate held-out instances and\nthen train a calibrator to predict the likelihood of correctness of the model's\nprediction. We instantiate our method with Natural Language Inference (NLI) and\nDuplicate Detection (DD) tasks and evaluate it in both In-Domain (IID) and\nOut-of-Domain (OOD) settings. In (IID, OOD) settings, we show that the\nrepresentations learned by our calibrator result in an improvement of (15.81%,\n5.64%) and (6.19%, 13.9%) over 'MaxProb' -- a selective prediction baseline --\non NLI and DD tasks respectively.",
          "link": "http://arxiv.org/abs/2008.09371",
          "publishedOn": "2022-04-09T00:48:55.329Z",
          "wordCount": null,
          "title": "Towards Improving Selective Prediction Ability of NLP Systems. (arXiv:2008.09371v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abhishek_K/0/1/0/all/0/1\">Kumar Abhishek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_C/0/1/0/all/0/1\">Colin J. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamarneh_G/0/1/0/all/0/1\">Ghassan Hamarneh</a>",
          "description": "Modern deep learning training procedures rely on model regularization\ntechniques such as data augmentation methods, which generate training samples\nthat increase the diversity of data and richness of label information. A\npopular recent method, mixup, uses convex combinations of pairs of original\nsamples to generate new samples. However, as we show in our experiments, mixup\ncan produce undesirable synthetic samples, where the data is sampled off the\nmanifold and can contain incorrect labels. We propose $\\zeta$-mixup, a\ngeneralization of mixup with provably and demonstrably desirable properties\nthat allows convex combinations of $N \\geq 2$ samples, leading to more\nrealistic and diverse outputs that incorporate information from $N$ original\nsamples by using a $p$-series interpolant. We show that, compared to mixup,\n$\\zeta$-mixup better preserves the intrinsic dimensionality of the original\ndatasets, which is a desirable property for training generalizable models.\nFurthermore, we show that our implementation of $\\zeta$-mixup is faster than\nmixup, and extensive evaluation on controlled synthetic and 24 real-world\nnatural and medical image classification datasets shows that $\\zeta$-mixup\noutperforms mixup and traditional data augmentation techniques.",
          "link": "http://arxiv.org/abs/2204.03323",
          "publishedOn": "2022-04-09T00:48:55.328Z",
          "wordCount": null,
          "title": "Multi-Sample $\\zeta$-mixup: Richer, More Realistic Synthetic Samples from a $p$-Series Interpolant. (arXiv:2204.03323v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Svendsen_D/0/1/0/all/0/1\">Daniel Heestermans Svendsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1\">Daniel Hern&#xe1;ndez-Lobato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martino_L/0/1/0/all/0/1\">Luca Martino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laparra_V/0/1/0/all/0/1\">Valero Laparra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreno_A/0/1/0/all/0/1\">Alvaro Moreno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camps_Valls_G/0/1/0/all/0/1\">Gustau Camps-Valls</a>",
          "description": "Earth observation from satellites offers the possibility to monitor our\nplanet with unprecedented accuracy. Radiative transfer models (RTMs) encode the\nenergy transfer through the atmosphere, and are used to model and understand\nthe Earth system, as well as to estimate the parameters that describe the\nstatus of the Earth from satellite observations by inverse modeling. However,\nperforming inference over such simulators is a challenging problem. RTMs are\nnonlinear, non-differentiable and computationally costly codes, which adds a\nhigh level of difficulty in inference. In this paper, we introduce two\ncomputational techniques to infer not only point estimates of biophysical\nparameters but also their joint distribution. One of them is based on a\nvariational autoencoder approach and the second one is based on a Monte Carlo\nExpectation Maximization (MCEM) scheme. We compare and discuss benefits and\ndrawbacks of each approach. We also provide numerical comparisons in synthetic\nsimulations and the real PROSAIL model, a popular RTM that combines land\nvegetation leaf and canopy modeling. We analyze the performance of the two\napproaches for modeling and inferring the distribution of three key biophysical\nparameters for quantifying the terrestrial biosphere.",
          "link": "http://arxiv.org/abs/2204.03346",
          "publishedOn": "2022-04-09T00:48:55.327Z",
          "wordCount": null,
          "title": "Inference over radiative transfer models using variational and expectation maximization methods. (arXiv:2204.03346v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leslie_D/0/1/0/all/0/1\">David Leslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briggs_M/0/1/0/all/0/1\">Morgan Briggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perini_A/0/1/0/all/0/1\">Antonella Perini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayadeva_S/0/1/0/all/0/1\">Smera Jayadeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rincon_C/0/1/0/all/0/1\">Cami Rinc&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raval_N/0/1/0/all/0/1\">Noopur Raval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birhane_A/0/1/0/all/0/1\">Abeba Birhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Powell_R/0/1/0/all/0/1\">Rosamund Powell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katell_M/0/1/0/all/0/1\">Michael Katell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aitken_M/0/1/0/all/0/1\">Mhairi Aitken</a>",
          "description": "The idea of \"data justice\" is of recent academic vintage. It has arisen over\nthe past decade in Anglo-European research institutions as an attempt to bring\ntogether a critique of the power dynamics that underlie accelerating trends of\ndatafication with a normative commitment to the principles of social justice-a\ncommitment to the achievement of a society that is equitable, fair, and capable\nof confronting the root causes of injustice.However, despite the seeming\nnovelty of such a data justice pedigree, this joining up of the critique of the\npower imbalances that have shaped the digital and \"big data\" revolutions with a\ncommitment to social equity and constructive societal transformation has a\ndeeper historical, and more geographically diverse, provenance. As the stories\nof the data justice initiatives, activism, and advocacy contained in this\nvolume well evidence, practices of data justice across the globe have, in fact,\nlargely preceded the elaboration and crystallisation of the idea of data\njustice in contemporary academic discourse. In telling these data justice\nstories, we hope to provide the reader with two interdependent tools of data\njustice thinking: First, we aim to provide the reader with the critical\nleverage needed to discern those distortions and malformations of data justice\nthat manifest in subtle and explicit forms of power, domination, and coercion.\nSecond, we aim to provide the reader with access to the historically effective\nforms of normativity and ethical insight that have been marshalled by data\njustice activists and advocates as tools of societal transformation-so that\nthese forms of normativity and insight can be drawn on, in turn, as\nconstructive resources to spur future transformative data justice practices.",
          "link": "http://arxiv.org/abs/2204.03100",
          "publishedOn": "2022-04-09T00:48:55.326Z",
          "wordCount": null,
          "title": "Data Justice Stories: A Repository of Case Studies. (arXiv:2204.03100v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03379",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ben_Simon_T/0/1/0/all/0/1\">Talia Ben-Simon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kreuk_F/0/1/0/all/0/1\">Felix Kreuk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Awwad_F/0/1/0/all/0/1\">Faten Awwad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cohen_J/0/1/0/all/0/1\">Jacob T. Cohen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Keshet_J/0/1/0/all/0/1\">Joseph Keshet</a>",
          "description": "Learning a new language involves constantly comparing speech productions with\nreference productions from the environment. Early in speech acquisition,\nchildren make articulatory adjustments to match their caregivers' speech.\nGrownup learners of a language tweak their speech to match the tutor reference.\nThis paper proposes a method to synthetically generate correct pronunciation\nfeedback given incorrect production. Furthermore, our aim is to generate the\ncorrected production while maintaining the speaker's original voice.\n\nThe system prompts the user to pronounce a phrase. The speech is recorded,\nand the samples associated with the inaccurate phoneme are masked with zeros.\nThis waveform serves as an input to a speech generator, implemented as a deep\nlearning inpainting system with a U-net architecture, and trained to output a\nreconstructed speech. The training set is composed of unimpaired proper speech\nexamples, and the generator is trained to reconstruct the original proper\nspeech. We evaluated the performance of our system on phoneme replacement of\nminimal pair words of English as well as on children with pronunciation\ndisorders. Results suggest that human listeners slightly prefer our generated\nspeech over a smoothed replacement of the inaccurate phoneme with a production\nof a different speaker.",
          "link": "http://arxiv.org/abs/2204.03379",
          "publishedOn": "2022-04-09T00:48:55.326Z",
          "wordCount": null,
          "title": "Correcting Misproducted Speech using Spectrogram Inpainting. (arXiv:2204.03379v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenge Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodrati_S/0/1/0/all/0/1\">Soroush Ghodrati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yazdanbakhsh_A/0/1/0/all/0/1\">Amir Yazdanbakhsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmaeilzadeh_H/0/1/0/all/0/1\">Hadi Esmaeilzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Mingu Kang</a>",
          "description": "Self-attention is a key enabler of state-of-art accuracy for various\ntransformer-based Natural Language Processing models. This attention mechanism\ncalculates a correlation score for each word with respect to the other words in\na sentence. Commonly, only a small subset of words highly correlates with the\nword under attention, which is only determined at runtime. As such, a\nsignificant amount of computation is inconsequential due to low attention\nscores and can potentially be pruned. The main challenge is finding the\nthreshold for the scores below which subsequent computation will be\ninconsequential. Although such a threshold is discrete, this paper formulates\nits search through a soft differentiable regularizer integrated into the loss\nfunction of the training. This formulation piggy backs on the back-propagation\ntraining to analytically co-optimize the threshold and the weights\nsimultaneously, striking a formally optimal balance between accuracy and\ncomputation pruning. To best utilize this mathematical innovation, we devise a\nbit-serial architecture, dubbed LeOPArd, for transformer language models with\nbit-level early termination microarchitectural mechanism. We evaluate our\ndesign across 43 back-end tasks for MemN2N, BERT, ALBERT, GPT-2, and Vision\ntransformer models. Post-layout results show that, on average, LeOPArd yields\n1.9x and 3.9x speedup and energy reduction, respectively, while keeping the\naverage accuracy virtually intact (<0.2% degradation)",
          "link": "http://arxiv.org/abs/2204.03227",
          "publishedOn": "2022-04-09T00:48:55.325Z",
          "wordCount": null,
          "title": "Accelerating Attention through Gradient-Based Learned Runtime Pruning. (arXiv:2204.03227v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jiyoung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jungin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_D/0/1/0/all/0/1\">Dongbo Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kwanghoon Sohn</a>",
          "description": "The rise of deep neural networks has led to several breakthroughs for\nsemantic segmentation. In spite of this, a model trained on source domain often\nfails to work properly in new challenging domains, that is directly concerned\nwith the generalization capability of the model. In this paper, we present a\nnovel memory-guided domain generalization method for semantic segmentation\nbased on meta-learning framework. Especially, our method abstracts the\nconceptual knowledge of semantic classes into categorical memory which is\nconstant beyond the domains. Upon the meta-learning concept, we repeatedly\ntrain memory-guided networks and simulate virtual test to 1) learn how to\nmemorize a domain-agnostic and distinct information of classes and 2) offer an\nexternally settled memory as a class-guidance to reduce the ambiguity of\nrepresentation in the test data of arbitrary unseen domain. To this end, we\nalso propose memory divergence and feature cohesion losses, which encourage to\nlearn memory reading and update processes for category-aware domain\ngeneralization. Extensive experiments for semantic segmentation demonstrate the\nsuperior generalization capability of our method over state-of-the-art works on\nvarious benchmarks.",
          "link": "http://arxiv.org/abs/2204.03609",
          "publishedOn": "2022-04-09T00:48:55.321Z",
          "wordCount": null,
          "title": "Pin the Memory: Learning to Generalize Semantic Segmentation. (arXiv:2204.03609v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tz-Ying Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_G/0/1/0/all/0/1\">Gurumurthy Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhizhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1\">Avinash Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_N/0/1/0/all/0/1\">Nuno Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhotika_R/0/1/0/all/0/1\">Rahul Bhotika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Class-incremental learning (CIL) has been widely studied under the setting of\nstarting from a small number of classes (base classes). Instead, we explore an\nunderstudied real-world setting of CIL that starts with a strong model\npre-trained on a large number of base classes. We hypothesize that a strong\nbase model can provide a good representation for novel classes and incremental\nlearning can be done with small adaptations. We propose a 2-stage training\nscheme, i) feature augmentation -- cloning part of the backbone and fine-tuning\nit on the novel data, and ii) fusion -- combining the base and novel\nclassifiers into a unified classifier. Experiments show that the proposed\nmethod significantly outperforms state-of-the-art CIL methods on the\nlarge-scale ImageNet dataset (e.g. +10% overall accuracy than the best). We\nalso propose and analyze understudied practical CIL scenarios, such as\nbase-novel overlap with distribution shift. Our proposed method is robust and\ngeneralizes to all analyzed CIL settings.",
          "link": "http://arxiv.org/abs/2204.03634",
          "publishedOn": "2022-04-09T00:48:55.317Z",
          "wordCount": null,
          "title": "Class-Incremental Learning with Strong Pre-trained Models. (arXiv:2204.03634v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.11048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhihua Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qianwen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1\">Yao Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengfei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>",
          "description": "Graph Neural Networks (GNNs) aim to extend deep learning techniques to graph\ndata and have achieved significant progress in graph analysis tasks (e.g., node\nclassification) in recent years. However, similar to other deep neural networks\nlike Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs),\nGNNs behave like a black box with their details hidden from model developers\nand users. It is therefore difficult to diagnose possible errors of GNNs.\nDespite many visual analytics studies being done on CNNs and RNNs, little\nresearch has addressed the challenges for GNNs. This paper fills the research\ngap with an interactive visual analysis tool, GNNLens, to assist model\ndevelopers and users in understanding and analyzing GNNs. Specifically,\nParallel Sets View and Projection View enable users to quickly identify and\nvalidate error patterns in the set of wrong predictions; Graph View and Feature\nMatrix View offer a detailed analysis of individual nodes to assist users in\nforming hypotheses about the error patterns. Since GNNs jointly model the graph\nstructure and the node features, we reveal the relative influences of the two\ntypes of information by comparing the predictions of three models: GNN,\nMulti-Layer Perceptron (MLP), and GNN Without Using Features (GNNWUF). Two case\nstudies and interviews with domain experts demonstrate the effectiveness of\nGNNLens in facilitating the understanding of GNN models and their errors.",
          "link": "http://arxiv.org/abs/2011.11048",
          "publishedOn": "2022-04-09T00:48:55.317Z",
          "wordCount": null,
          "title": "GNNLens: A Visual Analytics Approach for Prediction Error Diagnosis of Graph Neural Networks. (arXiv:2011.11048v6 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.05454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhenzhen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yuanlong Yu</a>",
          "description": "Feature selection is an important data preprocessing in data mining and\nmachine learning which can be used to reduce the feature dimension without\ndeteriorating model's performance. Since obtaining annotated data is laborious\nor even infeasible in many cases, unsupervised feature selection is more\npractical in reality. Though lots of methods for unsupervised feature selection\nhave been proposed, these methods select features independently, thus it is no\nguarantee that the group of selected features is optimal. What's more, the\nnumber of selected features must be tuned carefully to obtain a satisfactory\nresult. To tackle these problems, we propose a joint adaptive graph and\nstructured sparsity regularization unsupervised feature selection (JASFS)\nmethod in this paper, in which a $l_{2,0}$-norm regularization term with\nrespect to transformation matrix is imposed in the manifold learning for\nfeature selection, and a graph regularization term is incorporated into the\nlearning model to learn the local geometric structure of data adaptively. An\nefficient and simple iterative algorithm is designed to solve the proposed\noptimization problem with the analysis of computational complexity. After\noptimized, a subset of optimal features will be selected in group, and the\nnumber of selected features will be determined automatically. Experimental\nresults on eight benchmarks demonstrate the effectiveness and efficiency of the\nproposed method compared with several state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2010.05454",
          "publishedOn": "2022-04-09T00:48:55.315Z",
          "wordCount": null,
          "title": "Joint Adaptive Graph and Structured Sparsity Regularization for Unsupervised Feature Selection. (arXiv:2010.05454v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.01747",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Narain_S/0/1/0/all/0/1\">Sanjai Narain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mak_E/0/1/0/all/0/1\">Emily Mak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chee_D/0/1/0/all/0/1\">Dana Chee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Englot_B/0/1/0/all/0/1\">Brendan Englot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pochiraju_K/0/1/0/all/0/1\">Kishore Pochiraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1\">Niraj K. Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_K/0/1/0/all/0/1\">Karthik Narayan</a>",
          "description": "System design tools are often only available as input-output blackboxes: for\na given design as input they compute an output representing system behavior.\nBlackboxes are intended to be run in the forward direction. This paper presents\na new method of solving the inverse design problem namely, given requirements\nor constraints on output, find an input that also optimizes an objective\nfunction. This problem is challenging for several reasons. First, blackboxes\nare not designed to be run in reverse. Second, inputs and outputs can be\ndiscrete and continuous. Third, finding designs concurrently satisfying a set\nof requirements is hard because designs satisfying individual requirements may\nconflict with each other. Fourth, blackbox evaluations can be expensive.\nFinally, blackboxes can sometimes fail to produce an output. This paper\npresents CNMA, a new method of solving the inverse problem that overcomes these\nchallenges. CNMA tries to sample only the part of the design space relevant to\nsolving the problem, leveraging the power of neural networks, Mixed Integer\nLinear Programs, and a new learning-from-failure feedback loop. The paper also\npresents a parallel version of CNMA that improves the efficiency and quality of\nsolutions over the sequential version, and tries to steer it away from local\noptima. CNMA's performance is evaluated against conventional optimization\nmethods for seven nonlinear design problems of 8 (two problems), 10, 15, 36 and\n60 real-valued dimensions and one with 186 binary dimensions. Conventional\nmethods evaluated are off-the-shelf implementations of Bayesian Optimization\nwith Gaussian Processes, Nelder Mead and Random Search. The first two do not\nsolve problems that are high-dimensional, have discrete and continuous\nvariables or whose blackboxes can fail to return values. CNMA solves all\nproblems, and surpasses the performance of conventional methods by up to 87%.",
          "link": "http://arxiv.org/abs/2104.01747",
          "publishedOn": "2022-04-09T00:48:55.314Z",
          "wordCount": null,
          "title": "Fast Design Space Exploration of Nonlinear Systems: Part I. (arXiv:2104.01747v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03145",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saragadam_V/0/1/0/all/0/1\">Vishwanath Saragadam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Veeraraghavan_A/0/1/0/all/0/1\">Ashok Veeraraghavan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>",
          "description": "DeepTensor is a computationally efficient framework for low-rank\ndecomposition of matrices and tensors using deep generative networks. We\ndecompose a tensor as the product of low-rank tensor factors (e.g., a matrix as\nthe outer product of two vectors), where each low-rank tensor is generated by a\ndeep network (DN) that is trained in a self-supervised manner to minimize the\nmean-squared approximation error. Our key observation is that the implicit\nregularization inherent in DNs enables them to capture nonlinear signal\nstructures (e.g., manifolds) that are out of the reach of classical linear\nmethods like the singular value decomposition (SVD) and principal component\nanalysis (PCA). Furthermore, in contrast to the SVD and PCA, whose performance\ndeteriorates when the tensor's entries deviate from additive white Gaussian\nnoise, we demonstrate that the performance of DeepTensor is robust to a wide\nrange of distributions. We validate that DeepTensor is a robust and\ncomputationally efficient drop-in replacement for the SVD, PCA, nonnegative\nmatrix factorization (NMF), and similar decompositions by exploring a range of\nreal-world applications, including hyperspectral image denoising, 3D MRI\ntomography, and image classification. In particular, DeepTensor offers a 6dB\nsignal-to-noise ratio improvement over standard denoising methods for signals\ncorrupted by Poisson noise and learns to decompose 3D tensors 60 times faster\nthan a single DN equipped with 3D convolutions.",
          "link": "http://arxiv.org/abs/2204.03145",
          "publishedOn": "2022-04-09T00:48:55.313Z",
          "wordCount": null,
          "title": "DeepTensor: Low-Rank Tensor Decomposition with Deep Network Priors. (arXiv:2204.03145v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03305",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zezario_R/0/1/0/all/0/1\">Ryandhimas E. Zezario</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fuh_C/0/1/0/all/0/1\">Chiou-Shann Fuh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Improving the user's hearing ability to understand speech in noisy\nenvironments is critical to the development of hearing aid (HA) devices. For\nthis, it is important to derive a metric that can fairly predict speech\nintelligibility for HA users. A straightforward approach is to conduct a\nsubjective listening test and use the test results as an evaluation metric.\nHowever, conducting large-scale listening tests is time-consuming and\nexpensive. Therefore, several evaluation metrics were derived as surrogates for\nsubjective listening test results. In this study, we propose a multi-branched\nspeech intelligibility prediction model (MBI-Net), for predicting the\nsubjective intelligibility scores of HA users. MBI-Net consists of two branches\nof models, with each branch consisting of a hearing loss model, a cross-domain\nfeature extraction module, and a speech intelligibility prediction model, to\nprocess speech signals from one channel. The outputs of the two branches are\nfused through a linear layer to obtain predicted speech intelligibility scores.\nExperimental results confirm the effectiveness of MBI-Net, which produces\nhigher prediction scores than the baseline system in Track 1 and Track 2 on the\nClarity Prediction Challenge 2022 dataset.",
          "link": "http://arxiv.org/abs/2204.03305",
          "publishedOn": "2022-04-09T00:48:55.313Z",
          "wordCount": null,
          "title": "MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility Prediction Model for Hearing Aids. (arXiv:2204.03305v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.05861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hadi_M/0/1/0/all/0/1\">Mohammad Abdul Hadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fard_F/0/1/0/all/0/1\">Fatemeh H. Fard</a>",
          "description": "Context: Mobile app reviews written by users on app stores or social media\nare significant resources for app developers.Analyzing app reviews have proved\nto be useful for many areas of software engineering (e.g., requirement\nengineering, testing). Automatic classification of app reviews requires\nextensive efforts to manually curate a labeled dataset. When the classification\npurpose changes (e.g. identifying bugs versus usability issues or sentiment),\nnew datasets should be labeled, which prevents the extensibility of the\ndeveloped models for new desired classes/tasks in practice. Recent pre-trained\nneural language models (PTM) are trained on large corpora in an unsupervised\nmanner and have found success in solving similar Natural Language Processing\nproblems. However, the applicability of PTMs is not explored for app review\nclassification Objective: We investigate the benefits of PTMs for app review\nclassification compared to the existing models, as well as the transferability\nof PTMs in multiple settings. Method: We empirically study the accuracy and\ntime efficiency of PTMs compared to prior approaches using six datasets from\nliterature. In addition, we investigate the performance of the PTMs trained on\napp reviews (i.e. domain-specific PTMs) . We set up different studies to\nevaluate PTMs in multiple settings: binary vs. multi-class classification,\nzero-shot classification (when new labels are introduced to the model),\nmulti-task setting, and classification of reviews from different resources. The\ndatasets are manually labeled app review datasets from Google Play Store, Apple\nApp Store, and Twitter data. In all cases, Micro and Macro Precision, Recall,\nand F1-scores will be used and we will report the time required for training\nand prediction with the models.",
          "link": "http://arxiv.org/abs/2104.05861",
          "publishedOn": "2022-04-09T00:48:55.313Z",
          "wordCount": null,
          "title": "Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews. (arXiv:2104.05861v3 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2004.10888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shangtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "We present a mean-variance policy iteration (MVPI) framework for risk-averse\ncontrol in a discounted infinite horizon MDP optimizing the variance of a\nper-step reward random variable. MVPI enjoys great flexibility in that any\npolicy evaluation method and risk-neutral control method can be dropped in for\nrisk-averse control off the shelf, in both on- and off-policy settings. This\nflexibility reduces the gap between risk-neutral control and risk-averse\ncontrol and is achieved by working on a novel augmented MDP directly. We\npropose risk-averse TD3 as an example instantiating MVPI, which outperforms\nvanilla TD3 and many previous risk-averse control methods in challenging Mujoco\nrobot simulation tasks under a risk-aware performance metric. This risk-averse\nTD3 is the first to introduce deterministic policies and off-policy learning\ninto risk-averse reinforcement learning, both of which are key to the\nperformance boost we show in Mujoco domains.",
          "link": "http://arxiv.org/abs/2004.10888",
          "publishedOn": "2022-04-09T00:48:55.312Z",
          "wordCount": null,
          "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning. (arXiv:2004.10888v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.09745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1\">Sivakanth Gopi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulhane_P/0/1/0/all/0/1\">Pankaj Gulhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1\">Janardhan Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Judy Hanwen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yekhanin_S/0/1/0/all/0/1\">Sergey Yekhanin</a>",
          "description": "We study the basic operation of set union in the global model of differential\nprivacy. In this problem, we are given a universe $U$ of items, possibly of\ninfinite size, and a database $D$ of users. Each user $i$ contributes a subset\n$W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially\nprivate algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the\nsize of $S$ is as large as possible. The problem arises in countless real world\napplications; it is particularly ubiquitous in natural language processing\n(NLP) applications as vocabulary extraction. For example, discovering words,\nsentences, $n$-grams etc., from private text data belonging to users is an\ninstance of the set union problem.\n\nKnown algorithms for this problem proceed by collecting a subset of items\nfrom each user, taking the union of such subsets, and disclosing the items\nwhose noisy counts fall above a certain threshold. Crucially, in the above\nprocess, the contribution of each individual user is always independent of the\nitems held by other users, resulting in a wasteful aggregation process, where\nsome item counts happen to be way above the threshold. We deviate from the\nabove paradigm by allowing users to contribute their items in a\n$\\textit{dependent fashion}$, guided by a $\\textit{policy}$. In this new\nsetting ensuring privacy is significantly delicate. We prove that any policy\nwhich has certain $\\textit{contractive}$ properties would result in a\ndifferentially private algorithm. We design two new algorithms, one using\nLaplace noise and other Gaussian noise, as specific instances of policies\nsatisfying the contractive properties. Our experiments show that the new\nalgorithms significantly outperform previously known mechanisms for the\nproblem.",
          "link": "http://arxiv.org/abs/2002.09745",
          "publishedOn": "2022-04-09T00:48:55.311Z",
          "wordCount": null,
          "title": "Differentially Private Set Union. (arXiv:2002.09745v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jelcicova_Z/0/1/0/all/0/1\">Zuzana Jel&#x10d;icov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verhelst_M/0/1/0/all/0/1\">Marian Verhelst</a>",
          "description": "Multi-head self-attention forms the core of Transformer networks. However,\ntheir quadratically growing complexity with respect to the input sequence\nlength impedes their deployment on resource-constrained edge devices. We\naddress this challenge by proposing a dynamic pruning method, which exploits\nthe temporal stability of data across tokens to reduce inference cost. The\nthreshold-based method only retains significant differences between the\nsubsequent tokens, effectively reducing the number of multiply-accumulates, as\nwell as the internal tensor data sizes. The approach is evaluated on the Google\nSpeech Commands Dataset for keyword spotting, and the performance is compared\nagainst the baseline Keyword Transformer. Our experiments show that we can\nreduce ~80% of operations while maintaining the original 98.4% accuracy.\nMoreover, a reduction of ~87-94% operations can be achieved when only degrading\nthe accuracy by 1-4%, speeding up the multi-head self-attention inference by a\nfactor of ~7.5-16.",
          "link": "http://arxiv.org/abs/2204.03479",
          "publishedOn": "2022-04-09T00:48:55.309Z",
          "wordCount": null,
          "title": "Delta Keyword Transformer: Bringing Transformers to the Edge through Dynamically Pruned Multi-Head Self-Attention. (arXiv:2204.03479v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.08850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zimmermann_R/0/1/0/all/0/1\">Roland S. Zimmermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_S/0/1/0/all/0/1\">Steffen Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1\">Matthias Bethge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>",
          "description": "Contrastive learning has recently seen tremendous success in self-supervised\nlearning. So far, however, it is largely unclear why the learned\nrepresentations generalize so effectively to a large variety of downstream\ntasks. We here prove that feedforward models trained with objectives belonging\nto the commonly used InfoNCE family learn to implicitly invert the underlying\ngenerative model of the observed data. While the proofs make certain\nstatistical assumptions about the generative model, we observe empirically that\nour findings hold even if these assumptions are severely violated. Our theory\nhighlights a fundamental connection between contrastive learning, generative\nmodeling, and nonlinear independent component analysis, thereby furthering our\nunderstanding of the learned representations as well as providing a theoretical\nfoundation to derive more effective contrastive losses.",
          "link": "http://arxiv.org/abs/2102.08850",
          "publishedOn": "2022-04-09T00:48:55.309Z",
          "wordCount": null,
          "title": "Contrastive Learning Inverts the Data Generating Process. (arXiv:2102.08850v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.00135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_G/0/1/0/all/0/1\">Guanghui Lan</a>",
          "description": "We present new policy mirror descent (PMD) methods for solving reinforcement\nlearning (RL) problems with either strongly convex or general convex\nregularizers. By exploring the structural properties of these overall highly\nnonconvex problems we show that the PMD methods exhibit fast linear rate of\nconvergence to the global optimality. We develop stochastic counterparts of\nthese methods, and establish an ${\\cal O}(1/\\epsilon)$ (resp., ${\\cal\nO}(1/\\epsilon^2)$) sampling complexity for solving these RL problems with\nstrongly (resp., general) convex regularizers using different sampling schemes,\nwhere $\\epsilon$ denote the target accuracy. We further show that the\ncomplexity for computing the gradients of these regularizers, if necessary, can\nbe bounded by ${\\cal O}\\{(\\log_\\gamma \\epsilon) [(1-\\gamma)L/\\mu]^{1/2}\\log\n(1/\\epsilon)\\}$ (resp., ${\\cal O} \\{(\\log_\\gamma \\epsilon )\n(L/\\epsilon)^{1/2}\\}$)for problems with strongly (resp., general) convex\nregularizers. Here $\\gamma$ denotes the discounting factor. To the best of our\nknowledge, these complexity bounds, along with our algorithmic developments,\nappear to be new in both optimization and RL literature. The introduction of\nthese convex regularizers also greatly expands the flexibility and\napplicability of RL models.",
          "link": "http://arxiv.org/abs/2102.00135",
          "publishedOn": "2022-04-09T00:48:55.308Z",
          "wordCount": null,
          "title": "Policy Mirror Descent for Reinforcement Learning: Linear Convergence, New Sampling Complexity, and Generalized Problem Classes. (arXiv:2102.00135v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03503",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haller_S/0/1/0/all/0/1\">Stefan Haller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aldea_A/0/1/0/all/0/1\">Adina Aldea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seifert_C/0/1/0/all/0/1\">Christin Seifert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strisciuglio_N/0/1/0/all/0/1\">Nicola Strisciuglio</a>",
          "description": "Automated short answer grading (ASAG) has gained attention in education as a\nmeans to scale educational tasks to the growing number of students. Recent\nprogress in Natural Language Processing and Machine Learning has largely\ninfluenced the field of ASAG, of which we survey the recent research\nadvancements. We complement previous surveys by providing a comprehensive\nanalysis of recently published methods that deploy deep learning approaches. In\nparticular, we focus our analysis on the transition from hand engineered\nfeatures to representation learning approaches, which learn representative\nfeatures for the task at hand automatically from large corpora of data. We\nstructure our analysis of deep learning methods along three categories: word\nembeddings, sequential models, and attention-based methods. Deep learning\nimpacted ASAG differently than other fields of NLP, as we noticed that the\nlearned representations alone do not contribute to achieve the best results,\nbut they rather show to work in a complementary way with hand-engineered\nfeatures. The best performance are indeed achieved by methods that combine the\ncarefully hand-engineered features with the power of the semantic descriptions\nprovided by the latest models, like transformers architectures. We identify\nchallenges and provide an outlook on research direction that can be addressed\nin the future",
          "link": "http://arxiv.org/abs/2204.03503",
          "publishedOn": "2022-04-09T00:48:55.306Z",
          "wordCount": null,
          "title": "Survey on Automated Short Answer Grading with Deep Learning: from Word Embeddings to Transformers. (arXiv:2204.03503v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.03081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadeghi_D/0/1/0/all/0/1\">Delaram Sadeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeibi_A/0/1/0/all/0/1\">Afshin Shoeibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_N/0/1/0/all/0/1\">Navid Ghassemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moridian_P/0/1/0/all/0/1\">Parisa Moridian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadem_A/0/1/0/all/0/1\">Ali Khadem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1\">Roohallah Alizadehsani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teshnehlab_M/0/1/0/all/0/1\">Mohammad Teshnehlab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorriz_J/0/1/0/all/0/1\">J. Manuel Gorriz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khozeimeh_F/0/1/0/all/0/1\">Fahime Khozeimeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu-Dong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1\">Saeid Nahavandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_U/0/1/0/all/0/1\">U Rajendra Acharya</a>",
          "description": "Schizophrenia (SZ) is a mental disorder that typically emerges in late\nadolescence or early adulthood. It reduces the life expectancy of patients by\n15 years. Abnormal behavior, perception of emotions, social relationships, and\nreality perception are among its most significant symptoms. Past studies have\nrevealed the temporal and anterior lobes of hippocampus regions of brain get\naffected by SZ. Also, increased volume of cerebrospinal fluid (CSF) and\ndecreased volume of white and gray matter can be observed due to this disease.\nThe magnetic resonance imaging (MRI) is the popular neuroimaging technique used\nto explore structural/functional brain abnormalities in SZ disorder owing to\nits high spatial resolution. Various artificial intelligence (AI) techniques\nhave been employed with advanced image/signal processing methods to obtain\naccurate diagnosis of SZ. This paper presents a comprehensive overview of\nstudies conducted on automated diagnosis of SZ using MRI modalities. Main\nfindings, various challenges, and future works in developing the automated SZ\ndetection are described in this paper.",
          "link": "http://arxiv.org/abs/2103.03081",
          "publishedOn": "2022-04-09T00:48:55.306Z",
          "wordCount": null,
          "title": "An Overview on Artificial Intelligence Techniques for Diagnosis of Schizophrenia Based on Magnetic Resonance Imaging Modalities: Methods, Challenges, and Future Works. (arXiv:2103.03081v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengchuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Bin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Ce Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "Visual recognition is recently learned via either supervised learning on\nhuman-annotated image-label data or language-image contrastive learning with\nwebly-crawled image-text pairs. While supervised learning may result in a more\ndiscriminative representation, language-image pretraining shows unprecedented\nzero-shot recognition capability, largely due to the different properties of\ndata sources and learning objectives. In this work, we introduce a new\nformulation by combining the two data sources into a common image-text-label\nspace. In this space, we propose a new learning paradigm, called Unified\nContrastive Learning (UniCL) with a single learning objective to seamlessly\nprompt the synergy of two data types. Extensive experiments show that our UniCL\nis an effective way of learning semantically rich yet discriminative\nrepresentations, universally for image recognition in zero-shot, linear-probe,\nfully finetuning and transfer learning scenarios. Particularly, it attains\ngains up to 9.2% and 14.5% in average on zero-shot recognition benchmarks over\nthe language-image contrastive learning and supervised learning methods,\nrespectively. In linear probe setting, it also boosts the performance over the\ntwo methods by 7.3% and 3.4%, respectively. Our study also indicates that UniCL\nstand-alone is a good learner on pure image-label data, rivaling the supervised\nlearning methods across three image classification datasets and two types of\nvision backbones, ResNet and Swin Transformer. Code is available at\nhttps://github.com/microsoft/UniCL.",
          "link": "http://arxiv.org/abs/2204.03610",
          "publishedOn": "2022-04-09T00:48:55.305Z",
          "wordCount": null,
          "title": "Unified Contrastive Learning in Image-Text-Label Space. (arXiv:2204.03610v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03572",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rocha_K/0/1/0/all/0/1\">Karoline da Rocha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bermudez_J/0/1/0/all/0/1\">Jos&#xe9; C. M. Bermudez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rivero_E/0/1/0/all/0/1\">Elena R. C. Rivero</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Costa_M/0/1/0/all/0/1\">M&#xe1;rcio H. Costa</a>",
          "description": "The Epithelial Dysplasia (ED) is a tissue alteration commonly present in\nlesions preceding oral cancer, being its presence one of the most important\nfactors in the progression toward carcinoma. This study proposes a method to\ndesign a low computational cost classification system to support the detection\nof dysplastic epithelia, contributing to reduce the variability of pathologist\nassessments. We employ a multilayer artificial neural network (MLP-ANN) and\ndefining the regions of the epithelium to be assessed based on the knowledge of\nthe pathologist. The performance of the proposed solution was statistically\nevaluated. The implemented MLP-ANN presented an average accuracy of 87%, with a\nvariability much inferior to that obtained from three trained evaluators.\nMoreover, the proposed solution led to results which are very close to those\nobtained using a convolutional neural network (CNN) implemented by transfer\nlearning, with 100 times less computational complexity. In conclusion, our\nresults show that a simple neural network structure can lead to a performance\nequivalent to that of much more complex structures, which are routinely used in\nthe literature.",
          "link": "http://arxiv.org/abs/2204.03572",
          "publishedOn": "2022-04-09T00:48:55.304Z",
          "wordCount": null,
          "title": "A Pathology-Based Machine Learning Method to Assist in Epithelial Dysplasia Diagnosis. (arXiv:2204.03572v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yeh_R/0/1/0/all/0/1\">Raymond A. Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yuan-Ting Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasegawa_Johnson_M/0/1/0/all/0/1\">Mark Hasegawa-Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1\">Alexander G. Schwing</a>",
          "description": "Designing equivariance as an inductive bias into deep-nets has been a\nprominent approach to build effective models, e.g., a convolutional neural\nnetwork incorporates translation equivariance. However, incorporating these\ninductive biases requires knowledge about the equivariance properties of the\ndata, which may not be available, e.g., when encountering a new domain. To\naddress this, we study how to discover interpretable equivariances from data.\nSpecifically, we formulate this discovery process as an optimization problem\nover a model's parameter-sharing schemes. We propose to use the partition\ndistance to empirically quantify the accuracy of the recovered equivariance.\nAlso, we theoretically analyze the method for Gaussian data and provide a bound\non the mean squared gap between the studied discovery scheme and the oracle\nscheme. Empirically, we show that the approach recovers known equivariances,\nsuch as permutations and shifts, on sum of numbers and spatially-invariant\ndata.",
          "link": "http://arxiv.org/abs/2204.03640",
          "publishedOn": "2022-04-09T00:48:55.304Z",
          "wordCount": null,
          "title": "Equivariance Discovery by Learned Parameter-Sharing. (arXiv:2204.03640v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.02601",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lock_E/0/1/0/all/0/1\">Eric F. Lock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_J/0/1/0/all/0/1\">Jun Young Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hoadley_K/0/1/0/all/0/1\">Katherine A. Hoadley</a>",
          "description": "Several modern applications require the integration of multiple large data\nmatrices that have shared rows and/or columns. For example, cancer studies that\nintegrate multiple omics platforms across multiple types of cancer, pan-omics\npan-cancer analysis, have extended our knowledge of molecular heterogenity\nbeyond what was observed in single tumor and single platform studies. However,\nthese studies have been limited by available statistical methodology. We\npropose a flexible approach to the simultaneous factorization and decomposition\nof variation across such bidimensionally linked matrices, BIDIFAC+. This\ndecomposes variation into a series of low-rank components that may be shared\nacross any number of row sets (e.g., omics platforms) or column sets (e.g.,\ncancer types). This builds on a growing literature for the factorization and\ndecomposition of linked matrices, which has primarily focused on multiple\nmatrices that are linked in one dimension (rows or columns) only. Our objective\nfunction extends nuclear norm penalization, is motivated by random matrix\ntheory, gives an identifiable decomposition under relatively mild conditions,\nand can be shown to give the mode of a Bayesian posterior distribution. We\napply BIDIFAC+ to pan-omics pan-cancer data from TCGA, identifying shared and\nspecific modes of variability across 4 different omics platforms and 29\ndifferent cancer types.",
          "link": "http://arxiv.org/abs/2002.02601",
          "publishedOn": "2022-04-09T00:48:55.304Z",
          "wordCount": null,
          "title": "Bidimensional linked matrix factorization for pan-omics pan-cancer analysis. (arXiv:2002.02601v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1\">Shounak Datta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mullick_S/0/1/0/all/0/1\">Sankha Subhra Mullick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Swagatam Das</a>",
          "description": "Few-shot learning aims to transfer the knowledge acquired from training on a\ndiverse set of tasks, from a given task distribution, to generalize to unseen\ntasks, from the same distribution, with a limited amount of labeled data. The\nunderlying requirement for effective few-shot generalization is to learn a good\nrepresentation of the task manifold. One way to encourage this is to preserve\nlocal neighborhoods in the feature space learned by the few-shot learner. To\nthis end, we introduce the notion of interval bounds from the provably robust\ntraining literature to few-shot learning. The interval bounds are used to\ncharacterize neighborhoods around the training tasks. These neighborhoods can\nthen be preserved by minimizing the distance between a task and its respective\nbounds. We further introduce a novel strategy to artificially form new tasks\nfor training by interpolating between the available tasks and their respective\ninterval bounds, to aid in cases with a scarcity of tasks. We apply our\nframework to both model-agnostic meta-learning as well as prototype-based\nmetric-learning paradigms. The efficacy of our proposed approach is evident\nfrom the improved performance on several datasets from diverse domains in\ncomparison to a sizable number of recent competitors.",
          "link": "http://arxiv.org/abs/2204.03511",
          "publishedOn": "2022-04-09T00:48:55.303Z",
          "wordCount": null,
          "title": "Interval Bound Propagation--aided Few-shot Learning. (arXiv:2204.03511v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03573",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tiwari_S/0/1/0/all/0/1\">Sadhana Tiwari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>",
          "description": "Stress, anxiety, and nervousness are all high-risk health states in everyday\nlife. Previously, stress levels were determined by speaking with people and\ngaining insight into what they had experienced recently or in the past.\nTypically, stress is caused by an incidence that occurred a long time ago, but\nsometimes it is triggered by unknown factors. This is a challenging and complex\ntask, but recent research advances have provided numerous opportunities to\nautomate it. The fundamental features of most of these techniques are electro\ndermal activity (EDA) and heart rate values (HRV). We utilized an accelerometer\nto measure body motions to solve this challenge. The proposed novel method\nemploys a test that measures a subject's electrocardiogram (ECG), galvanic skin\nvalues (GSV), HRV values, and body movements in order to provide a low-cost and\ntime-saving solution for detecting stress lifestyle disease in modern times\nusing cyber physical systems. This study provides a new hybrid model for\nlifestyle disease classification that decreases execution time while picking\nthe best collection of characteristics and increases classification accuracy.\nThe developed approach is capable of dealing with the class imbalance problem\nby using WESAD (wearable stress and affect dataset) dataset. The new model uses\nthe Grid search (GS) method to select an optimized set of hyper parameters, and\nit uses a combination of the Correlation coefficient based Recursive feature\nelimination (CoC-RFE) method for optimal feature selection and gradient\nboosting as an estimator to classify the dataset, which achieves high accuracy\nand helps to provide smart, accurate, and high-quality healthcare systems. To\ndemonstrate the validity and utility of the proposed methodology, its\nperformance is compared to those of other well-established machine learning\nmodels.",
          "link": "http://arxiv.org/abs/2204.03573",
          "publishedOn": "2022-04-09T00:48:55.303Z",
          "wordCount": null,
          "title": "An optimized hybrid solution for IoT based lifestyle disease classification using stress data. (arXiv:2204.03573v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.07401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bai Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qiaomin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modiano_E/0/1/0/all/0/1\">Eytan Modiano</a>",
          "description": "With the rapid advance of information technology, network systems have become\nincreasingly complex and hence the underlying system dynamics are often unknown\nor difficult to characterize. Finding a good network control policy is of\nsignificant importance to achieve desirable network performance (e.g., high\nthroughput or low delay). In this work, we consider using model-based\nreinforcement learning (RL) to learn the optimal control policy for queueing\nnetworks so that the average job delay (or equivalently the average queue\nbacklog) is minimized. Traditional approaches in RL, however, cannot handle the\nunbounded state spaces of the network control problem. To overcome this\ndifficulty, we propose a new algorithm, called Reinforcement Learning for\nQueueing Networks (RL-QN), which applies model-based RL methods over a finite\nsubset of the state space, while applying a known stabilizing policy for the\nrest of the states. We establish that the average queue backlog under RL-QN\nwith an appropriately constructed subset can be arbitrarily close to the\noptimal result. We evaluate RL-QN in dynamic server allocation, routing and\nswitching problems. Simulation results show that RL-QN minimizes the average\nqueue backlog effectively.",
          "link": "http://arxiv.org/abs/2011.07401",
          "publishedOn": "2022-04-09T00:48:55.303Z",
          "wordCount": null,
          "title": "RL-QN: A Reinforcement Learning Framework for Optimal Control of Queueing Systems. (arXiv:2011.07401v2 [cs.PF] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abaho_M/0/1/0/all/0/1\">M. Abaho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollegala_D/0/1/0/all/0/1\">D. Bollegala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williamson_P/0/1/0/all/0/1\">P. Williamson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodd_S/0/1/0/all/0/1\">S. Dodd</a>",
          "description": "Probing Pre-trained Language Models (PLMs) using prompts has indirectly\nimplied that language models (LMs) can be treated as knowledge bases. To this\nend, this phenomena has been effective especially when these LMs are fine-tuned\ntowards not just data of a specific domain, but also to the style or linguistic\npattern of the prompts themselves. We observe that, satisfying a particular\nlinguistic pattern in prompts is an unsustainable constraint that unnecessarily\nlengthens the probing task, especially because, they are often manually\ndesigned and the range of possible prompt template patterns can vary depending\non the prompting objective and domain. We therefore explore an idea of using a\nposition-attention mechanism to capture positional information of each word in\na prompt relative to the mask to be filled, hence avoiding the need to\nre-construct prompts when the prompts linguistic pattern changes. Using our\napproach, we demonstrate the ability of eliciting answers to rare prompt\ntemplates (in a case study on health outcome generation) such as Postfix and\nMixed patterns whose missing information is respectively at the start and in\nmultiple random places of the prompt. More so, using various biomedical PLMs,\nour approach consistently outperforms a baseline in which the default mask\nlanguage model (MLM) representation is used to predict masked tokens.",
          "link": "http://arxiv.org/abs/2204.03489",
          "publishedOn": "2022-04-09T00:48:55.302Z",
          "wordCount": null,
          "title": "Position-based Prompting for Health Outcome Generation. (arXiv:2204.03489v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Songlin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "Second-order semantic parsing with end-to-end mean-field inference has been\nshown good performance. In this work we aim to improve this method by modeling\nlabel correlations between adjacent arcs. However, direct modeling leads to\nmemory explosion because second-order score tensors have sizes of $O(n^3L^2)$\n($n$ is the sentence length and $L$ is the number of labels), which is not\naffordable. To tackle this computational challenge, we leverage tensor\ndecomposition techniques, and interestingly, we show that the large\nsecond-order score tensors have no need to be materialized during mean-field\ninference, thereby reducing the computational complexity from cubic to\nquadratic. We conduct experiments on SemEval 2015 Task 18 English datasets,\nshowing the effectiveness of modeling label correlations. Our code is publicly\navailable at https://github.com/sustcsonglin/mean-field-dep-parsing.",
          "link": "http://arxiv.org/abs/2204.03619",
          "publishedOn": "2022-04-09T00:48:55.302Z",
          "wordCount": null,
          "title": "Modeling Label Correlations for Second-Order Semantic Dependency Parsing with Mean-Field Inference. (arXiv:2204.03619v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tingting Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Siyao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jie Liu</a>",
          "description": "As an emerging technology, federated learning (FL) involves training machine\nlearning models over distributed edge devices, which attracts sustained\nattention and has been extensively studied. However, the heterogeneity of\nclient data severely degrades the performance of FL compared with that in\ncentralized training. It causes the locally trained models of clients to move\nin different directions. On the one hand, it slows down or even stalls the\nglobal updates, leading to inefficient communication. On the other hand, it\nenlarges the distances between local models, resulting in an aggregated global\nmodel with poor performance. Fortunately, these shortcomings can be mitigated\nby reducing the angle between the directions that local models move in. Based\non this fact, we propose FedCos, which reduces the directional inconsistency of\nlocal models by introducing a cosine-similarity penalty. It promotes the local\nmodel iterations towards an auxiliary global direction. Moreover, our approach\nis auto-adapt to various non-IID settings without an elaborate selection of\nhyperparameters. The experimental results show that FedCos outperforms the\nwell-known baselines and can enhance them under a variety of FL scenes,\nincluding varying degrees of data heterogeneity, different number of\nparticipants, and cross-silo and cross-device settings. Besides, FedCos\nimproves communication efficiency by 2 to 5 times. With the help of FedCos,\nmultiple FL methods require significantly fewer communication rounds than\nbefore to obtain a model with comparable performance.",
          "link": "http://arxiv.org/abs/2204.03174",
          "publishedOn": "2022-04-09T00:48:55.301Z",
          "wordCount": null,
          "title": "FedCos: A Scene-adaptive Federated Optimization Enhancement for Performance Improvement. (arXiv:2204.03174v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.08676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Yixin Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "We introduce distributed NLI, a new NLU task with a goal to predict the\ndistribution of human judgements for natural language inference. We show that\nby applying additional distribution estimation methods, namely, Monte Carlo\n(MC) Dropout, Deep Ensemble, Re-Calibration, and Distribution Distillation,\nmodels can capture human judgement distribution more effectively than the\nsoftmax baseline. We show that MC Dropout is able to achieve decent performance\nwithout any distribution annotations while Re-Calibration can give further\nimprovements with extra distribution annotations, suggesting the value of\nmultiple annotations for one example in modeling the distribution of human\njudgements. Despite these improvements, the best results are still far below\nthe estimated human upper-bound, indicating that predicting the distribution of\nhuman judgements is still an open, challenging problem with a large room for\nimprovements. We showcase the common errors for MC Dropout and Re-Calibration.\nFinally, we give guidelines on the usage of these methods with different levels\nof data availability and encourage future work on modeling the human opinion\ndistribution for language reasoning. Our code and data are publicly available\nat https://github.com/easonnie/ChaosNLI",
          "link": "http://arxiv.org/abs/2104.08676",
          "publishedOn": "2022-04-09T00:48:55.301Z",
          "wordCount": null,
          "title": "Distributed NLI: Learning to Predict Human Opinion Distributions for Language Reasoning. (arXiv:2104.08676v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barkhof_C/0/1/0/all/0/1\">Claartje Barkhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1\">Wilker Aziz</a>",
          "description": "We propose a framework for the statistical evaluation of variational\nauto-encoders (VAEs) and test two instances of this framework in the context of\nmodelling images of handwritten digits and a corpus of English text. Our take\non evaluation is based on the idea of statistical model criticism, popular in\nBayesian data analysis, whereby a statistical model is evaluated in terms of\nits ability to reproduce statistics of an unknown data generating process from\nwhich we can obtain samples. A VAE learns not one, but two joint distributions\nover a shared sample space, each exploiting a choice of factorisation that\nmakes sampling tractable in one of two directions (latent-to-data,\ndata-to-latent). We evaluate samples from these distributions, assessing their\n(marginal) fit to the observed data and our choice of prior, and we also\nevaluate samples through a pipeline that connects the two distributions\nstarting from a data sample, assessing whether together they exploit and reveal\nlatent factors of variation that are useful to a practitioner. We show that\nthis methodology offers possibilities for model selection qualitatively beyond\nintrinsic evaluation metrics and at a finer granularity than commonly used\nstatistics can offer.",
          "link": "http://arxiv.org/abs/2204.03030",
          "publishedOn": "2022-04-09T00:48:55.300Z",
          "wordCount": null,
          "title": "Statistical Model Criticism of Variational Auto-Encoders. (arXiv:2204.03030v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bazzan_A/0/1/0/all/0/1\">Ana L. C. Bazzan</a>",
          "description": "As the demand for mobility in our society seems to increase, the various\nissues centered on urban mobility are among those that worry most city\ninhabitants in this planet. For instance, how to go from A to B in an efficient\n(but also less stressful) way? These questions and concerns have not changed\neven during the covid-19 pandemic; on the contrary, as the current stand,\npeople who are avoiding public transportation are only contributing to an\nincrease in the vehicular traffic. The are of intelligent transportation\nsystems (ITS) aims at investigating how to employ information and communication\ntechnologies to problems related to transportation. This may mean monitoring\nand managing the infrastructure (e.g., traffic roads, traffic signals, etc.).\nHowever, currently, ITS is also targeting the management of demand. In this\npanorama, artificial intelligence plays an important role, especially with the\nadvances in machine learning that translates in the use of computational\nvision, connected and autonomous vehicles, agent-based simulation, among\nothers. In the present work, a survey of several works developed by our group\nare discussed in a holistic perspective, i.e., they cover not only the supply\nside (as commonly found in ITS works), but also the demand side, and, in an\nnovel perspective, the integration of both.",
          "link": "http://arxiv.org/abs/2204.03570",
          "publishedOn": "2022-04-09T00:48:55.300Z",
          "wordCount": null,
          "title": "Improving Urban Mobility: using artificial intelligence and new technologies to connect supply and demand. (arXiv:2204.03570v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shaowu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunton_S/0/1/0/all/0/1\">Steven L. Brunton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1\">J. Nathan Kutz</a>",
          "description": "High-dimensional spatio-temporal dynamics can often be encoded in a\nlow-dimensional subspace. Engineering applications for modeling,\ncharacterization, design, and control of such large-scale systems often rely on\ndimensionality reduction to make solutions computationally tractable in\nreal-time. Common existing paradigms for dimensionality reduction include\nlinear methods, such as the singular value decomposition (SVD), and nonlinear\nmethods, such as variants of convolutional autoencoders (CAE). However, these\nencoding techniques lack the ability to efficiently represent the complexity\nassociated with spatio-temporal data, which often requires variable geometry,\nnon-uniform grid resolution, adaptive meshing, and/or parametric\ndependencies.To resolve these practical engineering challenges, we propose a\ngeneral framework called Neural Implicit Flow (NIF) that enables a\nmesh-agnostic, low-rank representation of large-scale, parametric,\nspatial-temporal data. NIF consists of two modified multilayer perceptrons\n(MLPs): (i) ShapeNet, which isolates and represents the spatial complexity, and\n(ii) ParameterNet, which accounts for any other input complexity, including\nparametric dependencies, time, and sensor measurements. We demonstrate the\nutility of NIF for parametric surrogate modeling, enabling the interpretable\nrepresentation and compression of complex spatio-temporal dynamics, efficient\nmany-spatial-query tasks, and improved generalization performance for sparse\nreconstruction.",
          "link": "http://arxiv.org/abs/2204.03216",
          "publishedOn": "2022-04-09T00:48:55.299Z",
          "wordCount": null,
          "title": "Neural Implicit Flow: a mesh-agnostic dimensionality reduction paradigm of spatio-temporal data. (arXiv:2204.03216v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1\">Tal Ridnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawen_H/0/1/0/all/0/1\">Hussam Lawen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1\">Emanuel Ben-Baruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1\">Asaf Noy</a>",
          "description": "ImageNet serves as the primary dataset for evaluating the quality of\ncomputer-vision models. The common practice today is training each architecture\nwith a tailor-made scheme, designed and tuned by an expert. In this paper, we\npresent a unified scheme for training any backbone on ImageNet. The scheme,\nnamed USI (Unified Scheme for ImageNet), is based on knowledge distillation and\nmodern tricks. It requires no adjustments or hyper-parameters tuning between\ndifferent models, and is efficient in terms of training times. We test USI on a\nwide variety of architectures, including CNNs, Transformers, Mobile-oriented\nand MLP-only. On all models tested, USI outperforms previous state-of-the-art\nresults. Hence, we are able to transform training on ImageNet from an\nexpert-oriented task to an automatic seamless routine. Since USI accepts any\nbackbone and trains it to top results, it also enables to perform methodical\ncomparisons, and identify the most efficient backbones along the speed-accuracy\nPareto curve. Implementation is available\nat:https://github.com/Alibaba-MIIL/Solving_ImageNet",
          "link": "http://arxiv.org/abs/2204.03475",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results. (arXiv:2204.03475v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chau_R/0/1/0/all/0/1\">Rodrigo Chau</a>",
          "description": "We investigate the \"Visual Pushing for Grasping\" (VPG) system by Zeng et al.\nand the \"Hourglass\" system by Ewerton et al., an evolution of the former. The\nfocus of our work is the investigation of the capabilities of both systems to\nlearn long-term rewards and policies. Zeng et al. original task only needs a\nlimited amount of foresight. Ewerton et al. attain their best performance using\nan agent which only takes the most immediate action under consideration. We are\ninterested in the ability of their models and training algorithms to accurately\npredict long-term Q-Values. To evaluate this ability, we design a new bin\nsorting task and reward function. Our task requires agents to accurately\nestimate future rewards and therefore use high discount factors in their\nQ-Value calculation. We investigate the behaviour of an adaptation of the VPG\ntraining algorithm on our task. We show that this adaptation can not accurately\npredict the required long-term action sequences. In addition to the limitations\nidentified by Ewerton et al., it suffers from the known Deep Q-Learning problem\nof overestimated Q-Values. In an effort to solve our task, we turn to the\nHourglass models and combine them with the Double Q-Learning approach. We show\nthat this approach enables the models to accurately predict long-term action\nsequences when trained with large discount factors. Our results show that the\nDouble Q-Learning technique is essential for training with very high discount\nfactors, as the models Q-Value predictions diverge otherwise. We also\nexperiment with different approaches for discount factor scheduling, loss\ncalculation and exploration procedures. Our results show that the latter\nfactors do not visibly influence the model's performance for our task.",
          "link": "http://arxiv.org/abs/2204.03487",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Optimizing the Long-Term Behaviour of Deep Reinforcement Learning for Pushing and Grasping. (arXiv:2204.03487v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03574",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nayak_N/0/1/0/all/0/1\">Nihal V. Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peilin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1\">Stephen H. Bach</a>",
          "description": "We introduce compositional soft prompting (CSP), a parameter-efficient\nlearning technique to improve the zero-shot compositionality of large-scale\npretrained vision-language models (VLMs) without the overhead of fine-tuning\nthe entire model. VLMs can represent arbitrary classes as natural language\nprompts in their flexible text encoders but they underperform state-of-the-art\nmethods on compositional zero-shot benchmark tasks. To improve VLMs, we propose\na novel form of soft prompting. We treat the attributes and objects that are\ncomposed to define classes as learnable tokens of vocabulary and tune them on\nmultiple prompt compositions. During inference, we recompose the learned\nattribute-object vocabulary in new combinations and show that CSP outperforms\nthe original VLM on benchmark datasets by an average of 14.7 percentage points\nof accuracy. CSP also achieves new state-of-the-art accuracies on two out of\nthree benchmark datasets, while only fine-tuning a small number of parameters.\nFurther, we show that CSP improves generalization to higher-order\nattribute-attribute-object compositions and combinations of pretrained\nattributes and fine-tuned objects.",
          "link": "http://arxiv.org/abs/2204.03574",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Learning to Compose Soft Prompts for Compositional Zero-Shot Learning. (arXiv:2204.03574v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03583",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ribas_C/0/1/0/all/0/1\">Celso H. H. Ribas</a> (1,2), <a href=\"http://arxiv.org/find/cs/1/au:+Bermudez_J/0/1/0/all/0/1\">Jos&#xe9; C. M. Bermudez</a> (1) ((1) Digital Signal Processing Research Laboratory, Federal University of Santa Catarina, Santa Catarina, Brazil, (2) Superintendence of Inspection, National Telecommunications Agency, Amazonas, Brazil)",
          "description": "Access to data and data processing, including the use of machine learning\ntechniques, has become significantly easier and cheaper in recent years.\nNevertheless, solutions that can be widely adopted by regulators for market\nmonitoring and inspection targeting in a data-driven way have not been\nfrequently discussed by the scientific community. This article discusses the\nneed and the difficulties for the development of such solutions, presents an\neffective method to address regulation planning, and illustrates its use to\naccount for the most important and common subject for the majority of\nregulators: the consumer. This article hopes to contribute to increase the\nawareness of the regulatory community to the need for data processing methods\nthat are objective, impartial, transparent, explainable, simple to implement\nand with low computational cost, aiming to the implementation of risk-based\nregulation in the world.",
          "link": "http://arxiv.org/abs/2204.03583",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Risk-based regulation for all: The need and a method for a wide adoption solution for data-driven inspection targeting. (arXiv:2204.03583v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huertas_Tato_J/0/1/0/all/0/1\">Javier Huertas-Tato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_A/0/1/0/all/0/1\">Alejandro Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_D/0/1/0/all/0/1\">David Camacho</a>",
          "description": "The appearance of complex attention-based language models such as BERT,\nRoberta or GPT-3 has allowed to address highly complex tasks in a plethora of\nscenarios. However, when applied to specific domains, these models encounter\nconsiderable difficulties. This is the case of Social Networks such as Twitter,\nan ever-changing stream of information written with informal and complex\nlanguage, where each message requires careful evaluation to be understood even\nby humans given the important role that context plays. Addressing tasks in this\ndomain through Natural Language Processing involves severe challenges. When\npowerful state-of-the-art multilingual language models are applied to this\nscenario, language specific nuances use to get lost in translation. To face\nthese challenges we present \\textbf{BERTuit}, the larger transformer proposed\nso far for Spanish language, pre-trained on a massive dataset of 230M Spanish\ntweets using RoBERTa optimization. Our motivation is to provide a powerful\nresource to better understand Spanish Twitter and to be used on applications\nfocused on this social network, with special emphasis on solutions devoted to\ntackle the spreading of misinformation in this platform. BERTuit is evaluated\non several tasks and compared against M-BERT, XLM-RoBERTa and XLM-T, very\ncompetitive multilingual transformers. The utility of our approach is shown\nwith applications, in this case: a zero-shot methodology to visualize groups of\nhoaxes and profiling authors spreading disinformation.\n\nMisinformation spreads wildly on platforms such as Twitter in languages other\nthan English, meaning performance of transformers may suffer when transferred\noutside English speaking communities.",
          "link": "http://arxiv.org/abs/2204.03465",
          "publishedOn": "2022-04-09T00:48:55.297Z",
          "wordCount": null,
          "title": "BERTuit: Understanding Spanish language in Twitter through a native transformer. (arXiv:2204.03465v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zeyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>",
          "description": "Various neural network models have been proposed to tackle combinatorial\noptimization problems such as the travelling salesman problem (TSP). Existing\nlearning-based TSP methods adopt a simple setting that the training and testing\ndata are independent and identically distributed. However, the existing\nliterature fails to solve TSP instances when training and testing data have\ndifferent distributions. Concretely, we find that different training and\ntesting distribution will result in more difficult TSP instances, i.e., the\nsolution obtained by the model has a large gap from the optimal solution. To\ntackle this problem, in this work, we study learning-based TSP methods when\ntraining and testing data have different distributions using adaptive-hardness,\ni.e., how difficult a TSP instance can be for a solver. This problem is\nchallenging because it is non-trivial to (1) define hardness measurement\nquantitatively; (2) efficiently and continuously generate sufficiently hard TSP\ninstances upon model training; (3) fully utilize instances with different\nlevels of hardness to learn a more powerful TSP solver. To solve these\nchallenges, we first propose a principled hardness measurement to quantify the\nhardness of TSP instances. Then, we propose a hardness-adaptive generator to\ngenerate instances with different hardness. We further propose a curriculum\nlearner fully utilizing these instances to train the TSP solver. Experiments\nshow that our hardness-adaptive generator can generate instances ten times\nharder than the existing methods, and our proposed method achieves significant\nimprovement over state-of-the-art models in terms of the optimality gap.",
          "link": "http://arxiv.org/abs/2204.03236",
          "publishedOn": "2022-04-09T00:48:55.295Z",
          "wordCount": null,
          "title": "Learning to Solve Travelling Salesman Problem with Hardness-adaptive Curriculum. (arXiv:2204.03236v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulynych_B/0/1/0/all/0/1\">Bogdan Kulynych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yao-Yuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1\">Jaros&#x142;aw B&#x142;asiok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1\">Preetum Nakkiran</a>",
          "description": "We investigate and leverage a connection between Differential Privacy (DP)\nand the recently proposed notion of Distributional Generalization (DG).\nApplying this connection, we introduce new conceptual tools for designing\ndeep-learning methods that bypass \"pathologies\" of standard stochastic gradient\ndescent (SGD). First, we prove that differentially private methods satisfy a\n\"What You See Is What You Get (WYSIWYG)\" generalization guarantee: whatever a\nmodel does on its train data is almost exactly what it will do at test time.\nThis guarantee is formally captured by distributional generalization. WYSIWYG\nenables principled algorithm design in deep learning by reducing\n$\\textit{generalization}$ concerns to $\\textit{optimization}$ ones: in order to\nmitigate unwanted behavior at test time, it is provably sufficient to mitigate\nthis behavior on the train data. This is notably false for standard (non-DP)\nmethods, hence this observation has applications even when privacy is not\nrequired. For example, importance sampling is known to fail for standard SGD,\nbut we show that it has exactly the intended effect for DP-trained models.\nThus, with DP-SGD, unlike with SGD, we can influence test-time behavior by\nmaking principled train-time interventions. We use these insights to construct\nsimple algorithms which match or outperform SOTA in several distributional\nrobustness applications, and to significantly improve the privacy vs. disparate\nimpact trade-off of DP-SGD. Finally, we also improve on known theoretical\nbounds relating differential privacy, stability, and distributional\ngeneralization.",
          "link": "http://arxiv.org/abs/2204.03230",
          "publishedOn": "2022-04-09T00:48:55.291Z",
          "wordCount": null,
          "title": "What You See is What You Get: Distributional Generalization for Algorithm Design in Deep Learning. (arXiv:2204.03230v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Sibo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianhua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasiou_C/0/1/0/all/0/1\">Charitos Anastasiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angeli_P/0/1/0/all/0/1\">Panagiota Angeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matar_O/0/1/0/all/0/1\">Omar K. Matar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yi-Ke Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pain_C/0/1/0/all/0/1\">Christopher C. Pain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcucci_R/0/1/0/all/0/1\">Rossella Arcucci</a>",
          "description": "Reduced-order modelling and low-dimensional surrogate models generated using\nmachine learning algorithms have been widely applied in high-dimensional\ndynamical systems to improve the algorithmic efficiency. In this paper, we\ndevelop a system which combines reduced-order surrogate models with a novel\ndata assimilation (DA) technique used to incorporate real-time observations\nfrom different physical spaces. We make use of local smooth surrogate functions\nwhich link the space of encoded system variables and the one of current\nobservations to perform variational DA with a low computational cost. The new\nsystem, named Generalised Latent Assimilation can benefit both the efficiency\nprovided by the reduced-order modelling and the accuracy of data assimilation.\nA theoretical analysis of the difference between surrogate and original\nassimilation cost function is also provided in this paper where an upper bound,\ndepending on the size of the local training set, is given. The new approach is\ntested on a high-dimensional CFD application of a two-phase liquid flow with\nnon-linear observation operators that current Latent Assimilation methods can\nnot handle. Numerical results demonstrate that the proposed assimilation\napproach can significantly improve the reconstruction and prediction accuracy\nof the deep learning surrogate model which is nearly 1000 times faster than the\nCFD simulation.",
          "link": "http://arxiv.org/abs/2204.03497",
          "publishedOn": "2022-04-09T00:48:55.291Z",
          "wordCount": null,
          "title": "Generalised Latent Assimilation in Heterogeneous Reduced Spaces with Machine Learning Surrogate Models. (arXiv:2204.03497v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minkyu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Hyun-Soo Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jinho Kim</a>",
          "description": "Graph neural networks are powerful methods to handle graph-structured data.\nHowever, existing graph neural networks only learn higher-order feature\ninteractions implicitly. Thus, they cannot capture information that occurred in\nlow-order feature interactions. To overcome this problem, we propose Explicit\nFeature Interaction-aware Graph Neural Network (EFI-GNN), which explicitly\nlearns arbitrary-order feature interactions. EFI-GNN can jointly learn with any\nother graph neural network. We demonstrate that the joint learning method\nalways enhances performance on the various node classification tasks.\nFurthermore, since EFI-GNN is inherently a linear model, we can interpret the\nprediction result of EFI-GNN. With the computation rule, we can obtain an\nany-order feature's effect on the decision. By that, we visualize the effects\nof the first-order and second-order features as a form of a heatmap.",
          "link": "http://arxiv.org/abs/2204.03225",
          "publishedOn": "2022-04-09T00:48:55.282Z",
          "wordCount": null,
          "title": "Explicit Feature Interaction-aware Graph Neural Networks. (arXiv:2204.03225v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03439",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Gebhard_T/0/1/0/all/0/1\">Timothy D. Gebhard</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Bonse_M/0/1/0/all/0/1\">Markus J. Bonse</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Quanz_S/0/1/0/all/0/1\">Sascha P. Quanz</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "High-contrast imaging of exoplanets hinges on powerful post-processing\nmethods to denoise the data and separate the signal of a companion from its\nhost star, which is typically orders of magnitude brighter. Existing\npost-processing algorithms do not use all prior domain knowledge that is\navailable about the problem. We propose a new method that builds on our\nunderstanding of the systematic noise and the causal structure of the\ndata-generating process. Our algorithm is based on a modified version of\nhalf-sibling regression (HSR), a flexible denoising framework that combines\nideas from the fields of machine learning and causality. We adapt the method to\naddress the specific requirements of high-contrast exoplanet imaging data\nobtained in pupil tracking mode. The key idea is to estimate the systematic\nnoise in a pixel by regressing the time series of this pixel onto a set of\ncausally independent, signal-free predictor pixels. We use regularized linear\nmodels in this work; however, other (non-linear) models are also possible. In a\nsecond step, we demonstrate how the HSR framework allows us to incorporate\nobserving conditions such as wind speed or air temperature as additional\npredictors. When we apply our method to four data sets from the VLT/NACO\ninstrument, our algorithm provides a better false-positive fraction than\nPCA-based PSF subtraction, a popular baseline method in the field.\nAdditionally, we find that the HSR-based method provides direct and accurate\nestimates for the contrast of the exoplanets without the need to insert\nartificial companions for calibration in the data sets. Finally, we present\nfirst evidence that using the observing conditions as additional predictors can\nimprove the results. Our HSR-based method provides an alternative, flexible and\npromising approach to the challenge of modeling and subtracting the stellar PSF\nand systematic noise in exoplanet imaging data.",
          "link": "http://arxiv.org/abs/2204.03439",
          "publishedOn": "2022-04-09T00:48:55.280Z",
          "wordCount": null,
          "title": "Half-sibling regression meets exoplanet imaging: PSF modeling and subtraction using a flexible, domain knowledge-driven, causal framework. (arXiv:2204.03439v1 [astro-ph.IM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vamsi Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_L/0/1/0/all/0/1\">Likith Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shivam Kumar Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dadi_K/0/1/0/all/0/1\">Kamalakar Dadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yarra_C/0/1/0/all/0/1\">Chiranjeevi Yarra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raju_B/0/1/0/all/0/1\">Bapi S. Raju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajendran_S/0/1/0/all/0/1\">Srijithesh Rajendran</a>",
          "description": "Modeling effective representations using multiple views that positively\ninfluence each other is challenging, and the existing methods perform poorly on\nElectroencephalogram (EEG) signals for sleep-staging tasks. In this paper, we\npropose a novel multi-view self-supervised method (mulEEG) for unsupervised EEG\nrepresentation learning. Our method attempts to effectively utilize the\ncomplementary information available in multiple views to learn better\nrepresentations. We introduce diverse loss that further encourages\ncomplementary information across multiple views. Our method with no access to\nlabels beats the supervised training while outperforming multi-view baseline\nmethods on transfer learning experiments carried out on sleep-staging tasks. We\nposit that our method was able to learn better representations by using\ncomplementary multi-views.",
          "link": "http://arxiv.org/abs/2204.03272",
          "publishedOn": "2022-04-09T00:48:55.279Z",
          "wordCount": null,
          "title": "mulEEG: A Multi-View Representation Learning on EEG Signals. (arXiv:2204.03272v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vital_F/0/1/0/all/0/1\">F&#xe1;bio Vital</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasco_M/0/1/0/all/0/1\">Miguel Vasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sardinha_A/0/1/0/all/0/1\">Alberto Sardinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melo_F/0/1/0/all/0/1\">Francisco Melo</a>",
          "description": "We present Perceive-Represent-Generate (PRG), a novel three-stage framework\nthat maps perceptual information of different modalities (e.g., visual or\nsound), corresponding to a sequence of instructions, to an adequate sequence of\nmovements to be executed by a robot. In the first stage, we perceive and\npre-process the given inputs, isolating individual commands from the complete\ninstruction provided by a human user. In the second stage we encode the\nindividual commands into a multimodal latent space, employing a deep generative\nmodel. Finally, in the third stage we convert the multimodal latent values into\nindividual trajectories and combine them into a single dynamic movement\nprimitive, allowing its execution in a robotic platform. We evaluate our\npipeline in the context of a novel robotic handwriting task, where the robot\nreceives as input a word through different perceptual modalities (e.g., image,\nsound), and generates the corresponding motion trajectory to write it, creating\ncoherent and readable handwritten words.",
          "link": "http://arxiv.org/abs/2204.03051",
          "publishedOn": "2022-04-09T00:48:55.278Z",
          "wordCount": null,
          "title": "Perceive, Represent, Generate: Translating Multimodal Information to Robotic Motion Trajectories. (arXiv:2204.03051v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_P/0/1/0/all/0/1\">Priya Sundaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antonova_R/0/1/0/all/0/1\">Rika Antonova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1\">Jeannette Bohg</a>",
          "description": "Research in manipulation of deformable objects is typically conducted on a\nlimited range of scenarios, because handling each scenario on hardware takes\nsignificant effort. Realistic simulators with support for various types of\ndeformations and interactions have the potential to speed up experimentation\nwith novel tasks and algorithms. However, for highly deformable objects it is\nchallenging to align the output of a simulator with the behavior of real\nobjects. Manual tuning is not intuitive, hence automated methods are needed. We\nview this alignment problem as a joint perception-inference challenge and\ndemonstrate how to use recent neural network architectures to successfully\nperform simulation parameter inference from real point clouds. We analyze the\nperformance of various architectures, comparing their data and training\nrequirements. Furthermore, we propose to leverage differentiable point cloud\nsampling and differentiable simulation to significantly reduce the time to\nachieve the alignment. We employ an efficient way to propagate gradients from\npoint clouds to simulated meshes and further through to the physical simulation\nparameters, such as mass and stiffness. Experiments with highly deformable\nobjects show that our method can achieve comparable or better alignment with\nreal object behavior, while reducing the time needed to achieve this by more\nthan an order of magnitude. Videos and supplementary material are available at\nhttps://tinyurl.com/diffcloud.",
          "link": "http://arxiv.org/abs/2204.03139",
          "publishedOn": "2022-04-09T00:48:55.278Z",
          "wordCount": null,
          "title": "DiffCloud: Real-to-Sim from Point Clouds with Differentiable Simulation and Rendering of Deformable Objects. (arXiv:2204.03139v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simsek_M/0/1/0/all/0/1\">Murat Simsek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantarci_B/0/1/0/all/0/1\">Burak Kantarci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouftah_H/0/1/0/all/0/1\">Hussein T. Mouftah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djukic_P/0/1/0/all/0/1\">Petar Djukic</a>",
          "description": "Despite its technological benefits, Internet of Things (IoT) has cyber\nweaknesses due to the vulnerabilities in the wireless medium. Machine learning\n(ML)-based methods are widely used against cyber threats in IoT networks with\npromising performance. Advanced persistent threat (APT) is prominent for\ncybercriminals to compromise networks, and it is crucial to long-term and\nharmful characteristics. However, it is difficult to apply ML-based approaches\nto identify APT attacks to obtain a promising detection performance due to an\nextremely small percentage among normal traffic. There are limited surveys to\nfully investigate APT attacks in IoT networks due to the lack of public\ndatasets with all types of APT attacks. It is worth to bridge the\nstate-of-the-art in network attack detection with APT attack detection in a\ncomprehensive review article. This survey article reviews the security\nchallenges in IoT networks and presents the well-known attacks, APT attacks,\nand threat models in IoT systems. Meanwhile, signature-based, anomaly-based,\nand hybrid intrusion detection systems are summarized for IoT networks. The\narticle highlights statistical insights regarding frequently applied ML-based\nmethods against network intrusion alongside the number of attacks types\ndetected. Finally, open issues and challenges for common network intrusion and\nAPT attacks are presented for future research.",
          "link": "http://arxiv.org/abs/2204.03433",
          "publishedOn": "2022-04-09T00:48:55.278Z",
          "wordCount": null,
          "title": "Machine Learning-Enabled IoT Security: Open Issues and Challenges Under Advanced Persistent Threats. (arXiv:2204.03433v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03456",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brinkmeyer_L/0/1/0/all/0/1\">Lukas Brinkmeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drumond_R/0/1/0/all/0/1\">Rafael Rego Drumond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burchert_J/0/1/0/all/0/1\">Johannes Burchert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1\">Lars Schmidt-Thieme</a>",
          "description": "Learning complex time series forecasting models usually requires a large\namount of data, as each model is trained from scratch for each task/data set.\nLeveraging learning experience with similar datasets is a well-established\ntechnique for classification problems called few-shot classification. However,\nexisting approaches cannot be applied to time-series forecasting because i)\nmultivariate time-series datasets have different channels and ii) forecasting\nis principally different from classification. In this paper we formalize the\nproblem of few-shot forecasting of time-series with heterogeneous channels for\nthe first time. Extending recent work on heterogeneous attributes in vector\ndata, we develop a model composed of permutation-invariant deep set-blocks\nwhich incorporate a temporal embedding. We assemble the first meta-dataset of\n40 multivariate time-series datasets and show through experiments that our\nmodel provides a good generalization, outperforming baselines carried over from\nsimpler scenarios that either fail to learn across tasks or miss temporal\ninformation.",
          "link": "http://arxiv.org/abs/2204.03456",
          "publishedOn": "2022-04-09T00:48:55.276Z",
          "wordCount": null,
          "title": "Few-Shot Forecasting of Time-Series with Heterogeneous Channels. (arXiv:2204.03456v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ott_F/0/1/0/all/0/1\">Felix Ott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1\">David R&#xfc;gamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heublein_L/0/1/0/all/0/1\">Lucas Heublein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutschler_C/0/1/0/all/0/1\">Christopher Mutschler</a>",
          "description": "The performance of a machine learning model degrades when it is applied to\ndata from a similar but different domain than the data it has initially been\ntrained on. To mitigate this domain shift problem, domain adaptation (DA)\ntechniques search for an optimal transformation that converts the (current)\ninput data from a source domain to a target domain to learn a domain-invariant\nrepresentations that reduces domain discrepancy.\n\nThis paper proposes a novel supervised domain adaptation based on two steps.\nFirst, we search for an optimal class-dependent transformation from the source\nto the target domain from a few samples. We consider optimal transport methods\nsuch as the earth mover distance with Laplacian regularization, Sinkhorn\ntransport and correlation alignment. Second, we use embedding similarity\ntechniques to select the corresponding transformation at inference. We use\ncorrelation metrics and maximum mean discrepancy with higher-order moment\nmatching techniques. We conduct an extensive evaluation on time-series datasets\nwith domain shift including simulated and various online handwriting datasets\nto demonstrate the performance.",
          "link": "http://arxiv.org/abs/2204.03342",
          "publishedOn": "2022-04-09T00:48:55.275Z",
          "wordCount": null,
          "title": "Domain Adaptation for Time-Series Classification to Mitigate Covariate Shift. (arXiv:2204.03342v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daghero_F/0/1/0/all/0/1\">Francesco Daghero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burrello_A/0/1/0/all/0/1\">Alessio Burrello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagliari_D/0/1/0/all/0/1\">Daniele Jahier Pagliari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macii_E/0/1/0/all/0/1\">Enrico Macii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poncino_M/0/1/0/all/0/1\">Massimo Poncino</a>",
          "description": "Energy-efficient machine learning models that can run directly on edge\ndevices are of great interest in IoT applications, as they can reduce network\npressure and response latency, and improve privacy. An effective way to obtain\nenergy-efficiency with small accuracy drops is to sequentially execute a set of\nincreasingly complex models, early-stopping the procedure for \"easy\" inputs\nthat can be confidently classified by the smallest models. As a stopping\ncriterion, current methods employ a single threshold on the output\nprobabilities produced by each model. In this work, we show that such a\ncriterion is sub-optimal for datasets that include classes of different\ncomplexity, and we demonstrate a more general approach based on per-classes\nthresholds. With experiments on a low-power end-node, we show that our method\ncan significantly reduce the energy consumption compared to the\nsingle-threshold approach.",
          "link": "http://arxiv.org/abs/2204.03431",
          "publishedOn": "2022-04-09T00:48:55.274Z",
          "wordCount": null,
          "title": "Energy-Efficient Adaptive Machine Learning on IoT End-Nodes With Class-Dependent Confidence. (arXiv:2204.03431v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balagansky_N/0/1/0/all/0/1\">Nikita Balagansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavrilov_D/0/1/0/all/0/1\">Daniil Gavrilov</a>",
          "description": "Currently, pre-trained models can be considered the default choice for a wide\nrange of NLP tasks. Despite their SoTA results, there is practical evidence\nthat these models may require a different number of computing layers for\ndifferent input sequences, since evaluating all layers leads to overconfidence\non wrong predictions (namely overthinking). This problem can potentially be\nsolved by implementing adaptive computation time approaches, which were first\ndesigned to improve inference speed. Recently proposed PonderNet may be a\npromising solution for performing an early exit by treating the exit layers\nindex as a latent variable. However, the originally proposed exit criterion,\nrelying on sampling from trained posterior distribution on the probability of\nexiting from i-th layer, introduces major variance in model outputs,\nsignificantly reducing the resulting models performance. In this paper, we\npropose Ponder ALBERT (PALBERT): an improvement to PonderNet with a novel\ndeterministic Q-exit criterion and a revisited model architecture. We compared\nPALBERT with recent methods for performing an early exit. We observed that the\nproposed changes can be considered significant improvements on the original\nPonderNet architecture and outperform PABEE on a wide range of GLUE tasks. In\naddition, we also performed an in-depth ablation study of the proposed\narchitecture to further understand Lambda layers and their performance.",
          "link": "http://arxiv.org/abs/2204.03276",
          "publishedOn": "2022-04-09T00:48:55.273Z",
          "wordCount": null,
          "title": "PALBERT: Teaching ALBERT to Ponder. (arXiv:2204.03276v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hedegaard_L/0/1/0/all/0/1\">Lukas Hedegaard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "We present Continual Inference, a Python library for implementing Continual\nInference Networks (CINs) in PyTorch, a class of Neural Networks designed\nspecifically for efficient inference in both online and batch processing\nscenarios. We offer a comprehensive introduction and guide to CINs and their\nimplementation in practice, and provide best-practices and code examples for\ncomposing complex modules for modern Deep Learning. Continual Inference is\nreadily downloadable via the Python Package Index and at\n\\url{www.github.com/lukashedegaard/continual-inference}.",
          "link": "http://arxiv.org/abs/2204.03418",
          "publishedOn": "2022-04-09T00:48:55.272Z",
          "wordCount": null,
          "title": "Continual Inference: A Library for Efficient Online Inference with Deep Neural Networks in PyTorch. (arXiv:2204.03418v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ranjbar_N/0/1/0/all/0/1\">Niloofar Ranjbar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safabakhsh_R/0/1/0/all/0/1\">Reza Safabakhsh</a>",
          "description": "Nowadays, deep neural networks are being used in many domains because of\ntheir high accuracy results. However, they are considered as \"black box\", means\nthat they are not explainable for humans. On the other hand, in some tasks such\nas medical, economic, and self-driving cars, users want the model to be\ninterpretable to decide if they can trust these results or not. In this work,\nwe present a modified version of an autoencoder-based approach for local\ninterpretability called ALIME. The ALIME itself is inspired by a famous method\ncalled Local Interpretable Model-agnostic Explanations (LIME). LIME generates a\nsingle instance level explanation by generating new data around the instance\nand training a local linear interpretable model. ALIME uses an autoencoder to\nweigh the new data around the sample. Nevertheless, the ALIME uses a linear\nmodel as the interpretable model to be trained locally, just like the LIME.\nThis work proposes a new approach, which uses a decision tree instead of the\nlinear model, as the interpretable model. We evaluate the proposed model in\ncase of stability, local fidelity, and interpretability on different datasets.\nCompared to ALIME, the experiments show significant results on stability and\nlocal fidelity and improved results on interpretability.",
          "link": "http://arxiv.org/abs/2204.03321",
          "publishedOn": "2022-04-09T00:48:55.271Z",
          "wordCount": null,
          "title": "Using Decision Tree as Local Interpretable Model in Autoencoder-based LIME. (arXiv:2204.03321v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venezian_E/0/1/0/all/0/1\">Elad Venezian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_Y/0/1/0/all/0/1\">Yoav Katz</a>",
          "description": "Pretrained models are the standard starting point for training. This approach\nconsistently outperforms the use of a random initialization. However,\npretraining is a costly endeavour that few can undertake.\n\nIn this paper, we create better base models at hardly any cost, by fusing\nmultiple existing fine tuned models into one. Specifically, we fuse by\naveraging the weights of these models. We show that the fused model results\nsurpass the pretrained model ones. We also show that fusing is often better\nthan intertraining.\n\nWe find that fusing is less dependent on the target task. Furthermore, weight\ndecay nullifies intertraining effects but not those of fusing.",
          "link": "http://arxiv.org/abs/2204.03044",
          "publishedOn": "2022-04-09T00:48:55.270Z",
          "wordCount": null,
          "title": "Fusing finetuned models for better pretraining. (arXiv:2204.03044v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Chenyan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1\">Payal Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwary_S/0/1/0/all/0/1\">Saurabh Tiwary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1\">Paul Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xia Song</a>",
          "description": "We present a new framework AMOS that pretrains text encoders with an\nAdversarial learning curriculum via a Mixture Of Signals from multiple\nauxiliary generators. Following ELECTRA-style pretraining, the main encoder is\ntrained as a discriminator to detect replaced tokens generated by auxiliary\nmasked language models (MLMs). Different from ELECTRA which trains one MLM as\nthe generator, we jointly train multiple MLMs of different sizes to provide\ntraining signals at various levels of difficulty. To push the discriminator to\nlearn better with challenging replaced tokens, we learn mixture weights over\nthe auxiliary MLMs' outputs to maximize the discriminator loss by\nbackpropagating the gradient from the discriminator via Gumbel-Softmax. For\nbetter pretraining efficiency, we propose a way to assemble multiple MLMs into\none unified auxiliary model. AMOS outperforms ELECTRA and recent\nstate-of-the-art pretrained models by about 1 point on the GLUE benchmark for\nBERT base-sized models.",
          "link": "http://arxiv.org/abs/2204.03243",
          "publishedOn": "2022-04-09T00:48:55.270Z",
          "wordCount": null,
          "title": "Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators. (arXiv:2204.03243v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_J/0/1/0/all/0/1\">Jeffrey Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_R/0/1/0/all/0/1\">Rajat Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tumma_N/0/1/0/all/0/1\">Neehal Tumma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhishek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "Topic models are some of the most popular ways to represent textual data in\nan interpret-able manner. Recently, advances in deep generative models,\nspecifically auto-encoding variational Bayes (AEVB), have led to the\nintroduction of unsupervised neural topic models, which leverage deep\ngenerative models as opposed to traditional statistics-based topic models. We\nextend upon these neural topic models by introducing the Label-Indexed Neural\nTopic Model (LI-NTM), which is, to the extent of our knowledge, the first\neffective upstream semi-supervised neural topic model. We find that LI-NTM\noutperforms existing neural topic models in document reconstruction benchmarks,\nwith the most notable results in low labeled data regimes and for data-sets\nwith informative labels; furthermore, our jointly learned classifier\noutperforms baseline classifiers in ablation studies.",
          "link": "http://arxiv.org/abs/2204.03208",
          "publishedOn": "2022-04-09T00:48:55.269Z",
          "wordCount": null,
          "title": "A Joint Learning Approach for Semi-supervised Neural Topic Modeling. (arXiv:2204.03208v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adibi_A/0/1/0/all/0/1\">Arman Adibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_A/0/1/0/all/0/1\">Aritra Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>",
          "description": "Recent years have witnessed a growing interest in the topic of min-max\noptimization, owing to its relevance in the context of generative adversarial\nnetworks (GANs), robust control and optimization, and reinforcement learning.\nMotivated by this line of work, we consider a multi-agent min-max learning\nproblem, and focus on the emerging challenge of contending with worst-case\nByzantine adversarial agents in such a setup. By drawing on recent results from\nrobust statistics, we design a robust distributed variant of the extra-gradient\nalgorithm - a popular algorithmic approach for min-max optimization. Our main\ncontribution is to provide a crisp analysis of the proposed robust\nextra-gradient algorithm for smooth convex-concave and smooth strongly\nconvex-strongly concave functions. Specifically, we establish statistical rates\nof convergence to approximate saddle points. Our rates are near-optimal, and\nreveal both the effect of adversarial corruption and the benefit of\ncollaboration among the non-faulty agents. Notably, this is the first paper to\nprovide formal theoretical guarantees for large-scale distributed min-max\nlearning in the presence of adversarial agents.",
          "link": "http://arxiv.org/abs/2204.03187",
          "publishedOn": "2022-04-09T00:48:55.268Z",
          "wordCount": null,
          "title": "Distributed Statistical Min-Max Learning in the Presence of Byzantine Agents. (arXiv:2204.03187v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03214",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thapa_C/0/1/0/all/0/1\">Chandra Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1\">Seung Ick Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1\">Muhammad Ejaz Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camtepe_S/0/1/0/all/0/1\">Seyit Camtepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pieprzyk_J/0/1/0/all/0/1\">Josef Pieprzyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nepal_S/0/1/0/all/0/1\">Surya Nepal</a>",
          "description": "The large transformer-based language models demonstrate excellent performance\nin natural language processing. By considering the closeness of natural\nlanguages to the high-level programming language such as C/C++, this work\nstudies how good are the large transformer-based language models detecting\nsoftware vulnerabilities. Our results demonstrate the well performance of these\nmodels on software vulnerability detection. The answer enables extending\ntransformer-based language models to vulnerability detection and leveraging\nsuperior performance beyond the natural language processing domain. Besides, we\nperform the model's security check using Microsoft's Counterfit, a command-line\ntool to assess the model's security. Our results find that these models are\nvulnerable to adversarial examples. In this regard, we present a simple\ncountermeasure and its result. Experimenting with large models is always a\nchallenge due to the requirement of computing resources and platforms/libraries\n& dependencies. Based on the experiences and difficulties we faced during this\nwork, we present our recommendation while choosing the platforms to run these\nlarge models. Moreover, the popular platforms are surveyed thoroughly in this\npaper.",
          "link": "http://arxiv.org/abs/2204.03214",
          "publishedOn": "2022-04-09T00:48:55.266Z",
          "wordCount": null,
          "title": "Transformer-Based Language Models for Software Vulnerability Detection: Performance, Model's Security and Platforms. (arXiv:2204.03214v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Emerson_H/0/1/0/all/0/1\">Harry Emerson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guy_M/0/1/0/all/0/1\">Matt Guy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McConville_R/0/1/0/all/0/1\">Ryan McConville</a>",
          "description": "Hybrid closed loop systems represent the future of care for people with type\n1 diabetes (T1D). These devices usually utilise simple control algorithms to\nselect the optimal insulin dose for maintaining blood glucose levels within a\nhealthy range. Online reinforcement learning (RL) has been utilised as a method\nfor further enhancing glucose control in these devices. Previous approaches\nhave been shown to reduce patient risk and improve time spent in the target\nrange when compared to classical control algorithms, but are prone to\ninstability in the learning process, often resulting in the selection of unsafe\nactions. This work presents an evaluation of offline RL as a means for\ndeveloping clinically effective dosing policies without the need for patient\ninteraction. This paper examines the utility of BCQ, CQL and TD3-BC in managing\nthe blood glucose of nine virtual patients within the UVA/Padova glucose\ndynamics simulator. When trained on less than a tenth of the data required by\nonline RL approaches, this work shows that offline RL can significantly\nincrease time in the healthy blood glucose range when compared to the strongest\nstate-of-art baseline. This is achieved without any associated increase in low\nblood glucose events. Offline RL is also shown to be able to correct for common\nand challenging scenarios such as incorrect bolus dosing, irregular meal\ntimings and sub-optimal training data.",
          "link": "http://arxiv.org/abs/2204.03376",
          "publishedOn": "2022-04-09T00:48:55.265Z",
          "wordCount": null,
          "title": "Offline Reinforcement Learning for Safer Blood Glucose Control in People with Type 1 Diabetes. (arXiv:2204.03376v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thomas_J/0/1/0/all/0/1\">Josephine M. Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moallemy_Oureh_A/0/1/0/all/0/1\">Alice Moallemy-Oureh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beddar_Wiesing_S/0/1/0/all/0/1\">Silvia Beddar-Wiesing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holzhuter_C/0/1/0/all/0/1\">Clara Holzh&#xfc;ter</a>",
          "description": "Graphs are ubiquitous in nature and can therefore serve as models for many\npractical but also theoretical problems. Based on this, the young research\nfield of Graph Neural Networks (GNNs) has emerged. Despite the youth of the\nfield and the speed in which new models are developed, many good surveys have\nbeen published in the last years. Nevertheless, an overview on which graph\ntypes can be modeled by GNNs is missing. In this survey, we give a detailed\noverview of already existing GNNs and, unlike previous surveys, categorize them\naccording to their ability to handle different graph types. We consider GNNs\noperating on static as well as on dynamic graphs of different structural\nconstitutions, with or without node or edge attributes. Moreover in the dynamic\ncase, we separate the models in discrete-time and continuous-time dynamic\ngraphs based on their architecture. According to our findings, there are still\ngraph types, that are not covered by existing GNN models. Specifically, models\nconcerning heterogeneity in attributes are missing and the deletion of nodes\nand edges is only covered rarely.",
          "link": "http://arxiv.org/abs/2204.03080",
          "publishedOn": "2022-04-09T00:48:55.264Z",
          "wordCount": null,
          "title": "Graph Neural Networks Designed for Different Graph Types: A Survey. (arXiv:2204.03080v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weikai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1\">Meng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Songcan Chen</a>",
          "description": "Unsupervised Source (data) Free domain adaptation (USFDA) aims to transfer\nknowledge from a well-trained source model to a related but unlabeled target\ndomain. In such a scenario, all conventional adaptation methods that require\nsource data fail. To combat this challenge, existing USFDAs turn to transfer\nknowledge by aligning the target feature to the latent distribution hidden in\nthe source model. However, such information is naturally limited. Thus, the\nalignment in such a scenario is not only difficult but also insufficient, which\ndegrades the target generalization performance. To relieve this dilemma in\ncurrent USFDAs, we are motivated to explore a new perspective to boost their\nperformance. For this purpose and gaining necessary insight, we look back upon\nthe origin of the domain adaptation and first theoretically derive a new-brand\ntarget generalization error bound based on the model smoothness. Then,\nfollowing the theoretical insight, a general and model-smoothness-guided\nJacobian norm (JN) regularizer is designed and imposed on the target domain to\nmitigate this dilemma. Extensive experiments are conducted to validate its\neffectiveness. In its implementation, just with a few lines of codes added to\nthe existing USFDAs, we achieve superior results on various benchmark datasets.",
          "link": "http://arxiv.org/abs/2204.03467",
          "publishedOn": "2022-04-09T00:48:55.263Z",
          "wordCount": null,
          "title": "Jacobian Norm for Unsupervised Source-Free Domain Adaptation. (arXiv:2204.03467v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangjoon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "The widespread application of artificial intelligence in health research is\ncurrently hampered by limitations in data availability. Distributed learning\nmethods such as federated learning (FL) and shared learning (SL) are introduced\nto solve this problem as well as data management and ownership issues with\ntheir different strengths and weaknesses. The recent proposal of federated\nsplit task-agnostic (FeSTA) learning tries to reconcile the distinct merits of\nFL and SL by enabling the multi-task collaboration between participants through\nVision Transformer (ViT) architecture, but they suffer from higher\ncommunication overhead. To address this, here we present a multi-task\ndistributed learning using ViT with random patch permutation. Instead of using\na CNN based head as in FeSTA, p-FeSTA adopts a randomly permuting simple patch\nembedder, improving the multi-task learning performance without sacrificing\nprivacy. Experimental results confirm that the proposed method significantly\nenhances the benefit of multi-task collaboration, communication efficiency, and\nprivacy preservation, shedding light on practical multi-task distributed\nlearning in the field of medical imaging.",
          "link": "http://arxiv.org/abs/2204.03500",
          "publishedOn": "2022-04-09T00:48:55.247Z",
          "wordCount": null,
          "title": "Multi-Task Distributed Learning using Vision Transformer with Random Patch Permutation. (arXiv:2204.03500v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kommrusch_S/0/1/0/all/0/1\">Steve Kommrusch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monperrus_M/0/1/0/all/0/1\">Martin Monperrus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouchet_L/0/1/0/all/0/1\">Louis-No&#xeb;l Pouchet</a>",
          "description": "We target the problem of automatically synthesizing proofs of semantic\nequivalence between two programs made of sequences of statements. We represent\nprograms using abstract syntax trees (AST), where a given set of\nsemantics-preserving rewrite rules can be applied on a specific AST pattern to\ngenerate a transformed and semantically equivalent program. In our system, two\nprograms are equivalent if there exists a sequence of application of these\nrewrite rules that leads to rewriting one program into the other. We propose a\nneural network architecture based on a transformer model to generate proofs of\nequivalence between program pairs. The system outputs a sequence of rewrites,\nand the validity of the sequence is simply checked by verifying it can be\napplied. If no valid sequence is produced by the neural network, the system\nreports the programs as non-equivalent, ensuring by design no programs may be\nincorrectly reported as equivalent. Our system is fully implemented for a given\ngrammar. To efficiently train the system to generate such sequences, we develop\nan original incremental training technique, named self-supervised sample\nselection. We extensively study the effectiveness of this novel training\napproach on proofs of increasing complexity and length. Our system, S4Eq,\nachieves 97% proof success on a curated dataset of 10,000 pairs of equivalent\nprograms.",
          "link": "http://arxiv.org/abs/2109.10476",
          "publishedOn": "2022-04-09T00:48:55.246Z",
          "wordCount": null,
          "title": "Self-Supervised Learning to Prove Equivalence Between Programs via Semantics-Preserving Rewrite Rules. (arXiv:2109.10476v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03564",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khalid_U/0/1/0/all/0/1\">Umar Khalid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karim_N/0/1/0/all/0/1\">Nazmul Karim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rahnavard_N/0/1/0/all/0/1\">Nazanin Rahnavard</a>",
          "description": "Deep neural networks (DNNs) designed for computer vision and natural language\nprocessing tasks cannot be directly applied to the radio frequency (RF)\ndatasets. To address this challenge, we propose to convert the raw RF data to\ndata types that are suitable for off-the-shelf DNNs by introducing a\nconvolutional transform technique. In addition, we propose a simple 5-layer\nconvolutional neural network architecture (CONV-5) that can operate with raw RF\nI/Q data without any transformation. Further, we put forward an RF dataset,\nreferred to as RF1024, to facilitate future RF research. RF1024 consists of 8\ndifferent RF modulation classes with each class having 1000/200 training/test\nsamples. Each sample of the RF1024 dataset contains 1024 complex I/Q values.\nLastly, the experiments are performed on the RadioML2016 and RF1024 datasets to\ndemonstrate the improved classification performance.",
          "link": "http://arxiv.org/abs/2204.03564",
          "publishedOn": "2022-04-09T00:48:55.190Z",
          "wordCount": null,
          "title": "RF Signal Transformation and Classification using Deep Neural Networks. (arXiv:2204.03564v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiqin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1\">Kangxue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1\">Sanja Fidler</a>",
          "description": "In this paper, we address the problem of texture representation for 3D shapes\nfor the challenging and underexplored tasks of texture transfer and synthesis.\nPrevious works either apply spherical texture maps which may lead to large\ndistortions, or use continuous texture fields that yield smooth outputs lacking\ndetails. We argue that the traditional way of representing textures with images\nand linking them to a 3D mesh via UV mapping is more desirable, since\nsynthesizing 2D images is a well-studied problem. We propose AUV-Net which\nlearns to embed 3D surfaces into a 2D aligned UV space, by mapping the\ncorresponding semantic parts of different 3D shapes to the same location in the\nUV space. As a result, textures are aligned across objects, and can thus be\neasily synthesized by generative models of images. Texture alignment is learned\nin an unsupervised manner by a simple yet effective texture alignment module,\ntaking inspiration from traditional works on linear subspace learning. The\nlearned UV mapping and aligned texture representations enable a variety of\napplications including texture transfer, texture synthesis, and textured single\nview 3D reconstruction. We conduct experiments on multiple datasets to\ndemonstrate the effectiveness of our method. Project page:\nhttps://nv-tlabs.github.io/AUV-NET.",
          "link": "http://arxiv.org/abs/2204.03105",
          "publishedOn": "2022-04-09T00:48:55.189Z",
          "wordCount": null,
          "title": "AUV-Net: Learning Aligned UV Maps for Texture Transfer and Synthesis. (arXiv:2204.03105v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yonghai Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yichuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freris_N/0/1/0/all/0/1\">Nikolaos M. Freris</a>",
          "description": "Federated Learning (FL) is an emerging framework for distributed processing\nof large data volumes by edge devices subject to limited communication\nbandwidths, heterogeneity in data distributions and computational resources, as\nwell as privacy considerations. In this paper, we introduce a new FL protocol\ntermed FedADMM based on primal-dual optimization. The proposed method leverages\ndual variables to tackle statistical heterogeneity, and accommodates system\nheterogeneity by tolerating variable amount of work performed by clients.\nFedADMM maintains identical communication costs per round as FedAvg/Prox, and\ngeneralizes them via the augmented Lagrangian. A convergence proof is\nestablished for nonconvex objectives, under no restrictions in terms of data\ndissimilarity or number of participants per round of the algorithm. We\ndemonstrate the merits through extensive experiments on real datasets, under\nboth IID and non-IID data distributions across clients. FedADMM consistently\noutperforms all baseline methods in terms of communication efficiency, with the\nnumber of rounds needed to reach a prescribed accuracy reduced by up to 87%.\nThe algorithm effectively adapts to heterogeneous data distributions through\nthe use of dual variables, without the need for hyperparameter tuning, and its\nadvantages are more pronounced in large-scale systems.",
          "link": "http://arxiv.org/abs/2204.03529",
          "publishedOn": "2022-04-09T00:48:55.189Z",
          "wordCount": null,
          "title": "FedADMM: A Robust Federated Deep Learning Framework with Adaptivity to System Heterogeneity. (arXiv:2204.03529v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03310",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zezario_R/0/1/0/all/0/1\">Ryandhimas E. Zezario</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_S/0/1/0/all/0/1\">Szu-wei Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fuh_C/0/1/0/all/0/1\">Chiou-Shann Fuh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Recently, deep learning (DL)-based non-intrusive speech assessment models\nhave attracted great attention. Many studies report that these DL-based models\nyield satisfactory assessment performance and good flexibility, but their\nperformance in unseen environments remains a challenge. Furthermore, compared\nto quality scores, fewer studies elaborate deep learning models to estimate\nintelligibility scores. This study proposes a multi-task speech intelligibility\nprediction model, called MTI-Net, for simultaneously predicting human and\nmachine intelligibility measures. Specifically, given a speech utterance,\nMTI-Net is designed to predict subjective listening test results and word error\nrate (WER) scores. We also investigate several methods that can improve the\nprediction performance of MTI-Net. First, we compare different features\n(including low-level features and embeddings from self-supervised learning\n(SSL) models) and prediction targets of MTI-Net. Second, we explore the effect\nof transfer learning and multi-tasking learning on training MTI-Net. Finally,\nwe examine the potential advantages of fine-tuning SSL embeddings. Experimental\nresults demonstrate the effectiveness of using cross-domain features,\nmulti-task learning, and fine-tuning SSL embeddings. Furthermore, it is\nconfirmed that the intelligibility and WER scores predicted by MTI-Net are\nhighly correlated with the ground-truth scores.",
          "link": "http://arxiv.org/abs/2204.03310",
          "publishedOn": "2022-04-09T00:48:55.188Z",
          "wordCount": null,
          "title": "MTI-Net: A Multi-Target Speech Intelligibility Prediction Model. (arXiv:2204.03310v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Minghui Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangnan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_K/0/1/0/all/0/1\">Keping Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leung_V/0/1/0/all/0/1\">Victor C.M.Leung</a>",
          "description": "Due to the rapid growth of data transmissions in internet of vehicles (IoV),\nfinding schemes that can effectively alleviate access congestion has become an\nimportant issue. Recently, many traffic control schemes have been studied.\nNevertheless, the dynamics of traffic and the heterogeneous requirements of\ndifferent IoV applications are not considered in most existing studies, which\nis significant for the random access resource allocation. In this paper, we\nconsider a hybrid traffic control scheme and use proximal policy optimization\n(PPO) method to tackle it. Firstly, IoV devices are divided into various\nclasses based on delay characteristics. The target of maximizing the successful\ntransmission of packets with the success rate constraint is established. Then,\nthe optimization objective is transformed into a markov decision process (MDP)\nmodel. Finally, the access class barring (ACB) factors are obtained based on\nthe PPO method to maximize the number of successful access devices. The\nperformance of the proposal algorithm in respect of successful events and delay\ncompared to existing schemes is verified by simulations.",
          "link": "http://arxiv.org/abs/2204.03504",
          "publishedOn": "2022-04-09T00:48:55.108Z",
          "wordCount": null,
          "title": "AI-aided Traffic Control Scheme for M2M Communications in the Internet of Vehicles. (arXiv:2204.03504v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03326",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joshi_P/0/1/0/all/0/1\">Praveen Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afli_H/0/1/0/all/0/1\">Haithem Afli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasanuzzaman_M/0/1/0/all/0/1\">Mohammed Hasanuzzaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapa_C/0/1/0/all/0/1\">Chandra Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scully_T/0/1/0/all/0/1\">Ted Scully</a>",
          "description": "Deep Learning-based models have been widely investigated, and they have\ndemonstrated significant performance on non-trivial tasks such as speech\nrecognition, image processing, and natural language understanding. However,\nthis is at the cost of substantial data requirements. Considering the\nwidespread proliferation of edge devices (e.g. Internet of Things devices) over\nthe last decade, Deep Learning in the edge paradigm, such as device-cloud\nintegrated platforms, is required to leverage its superior performance.\nMoreover, it is suitable from the data requirements perspective in the edge\nparadigm because the proliferation of edge devices has resulted in an explosion\nin the volume of generated and collected data. However, there are difficulties\ndue to other requirements such as high computation, high latency, and high\nbandwidth caused by Deep Learning applications in real-world scenarios. In this\nregard, this survey paper investigates Deep Learning at the edge, its\narchitecture, enabling technologies, and model adaption techniques, where edge\nservers and edge devices participate in deep learning training and inference.\nFor simplicity, we call this paradigm the All-in EDGE paradigm. Besides, this\npaper presents the key performance metrics for Deep Learning at the All-in EDGE\nparadigm to evaluate various deep learning techniques and choose a suitable\ndesign. Moreover, various open challenges arising from the deployment of Deep\nLearning at the All-in EDGE paradigm are identified and discussed.",
          "link": "http://arxiv.org/abs/2204.03326",
          "publishedOn": "2022-04-09T00:48:55.107Z",
          "wordCount": null,
          "title": "Enabling Deep Learning for All-in EDGE paradigm. (arXiv:2204.03326v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kopacz_A/0/1/0/all/0/1\">Anik&#xf3; Kopacz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mester_A/0/1/0/all/0/1\">&#xc1;gnes Mester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolumban_S/0/1/0/all/0/1\">S&#xe1;ndor Kolumb&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehel_C/0/1/0/all/0/1\">Csat&#xf3; Lehel</a>",
          "description": "We propose a train rescheduling algorithm which applies a standardized\nfeature selection based on pairwise conflicts in order to serve as input for\nthe reinforcement learning framework. We implement an analytical method which\nidentifies and optimally solves every conflict arising between two trains, then\nwe design a corresponding observation space which features the most relevant\ninformation considering these conflicts. The data obtained this way then\ntranslates to actions in the context of the reinforcement learning framework.\nWe test our preliminary model using the evaluation metrics of the Flatland\nChallenge. The empirical results indicate that the suggested feature space\nprovides meaningful observations, from which a sensible scheduling policy can\nbe learned.",
          "link": "http://arxiv.org/abs/2204.03061",
          "publishedOn": "2022-04-09T00:48:55.105Z",
          "wordCount": null,
          "title": "Standardized feature extraction from pairwise conflicts applied to the train rescheduling problem. (arXiv:2204.03061v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Wen Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qingna Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1\">Chunfeng Cui</a>",
          "description": "Adversarial perturbations have drawn great attentions in various deep neural\nnetworks. Most of them are computed by iterations and cannot be interpreted\nvery well. In contrast, little attentions are paid to basic machine learning\nmodels such as support vector machines. In this paper, we investigate the\noptimization models and the interpretations for three types of adversarial\nperturbations against support vector machines, including sample-adversarial\nperturbations (sAP), class-universal adversarial perturbations (cuAP) as well\nas universal adversarial perturbations (uAP). For linear binary/multi\nclassification support vector machines (SVMs), we derive the explicit solutions\nfor sAP, cuAP and uAP (binary case), and approximate solution for uAP of\nmulti-classification. We also obtain the upper bound of fooling rate for uAP.\nSuch results not only increase the interpretability of the three adversarial\nperturbations, but also provide great convenience in computation since\niterative process can be avoided. Numerical results show that our method is\nfast and effective in calculating three types of adversarial perturbations.",
          "link": "http://arxiv.org/abs/2204.03154",
          "publishedOn": "2022-04-09T00:48:55.105Z",
          "wordCount": null,
          "title": "Optimization Models and Interpretations for Three Types of Adversarial Perturbations against Support Vector Machines. (arXiv:2204.03154v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ermolov_A/0/1/0/all/0/1\">Aleksandr Ermolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sangineto_E/0/1/0/all/0/1\">Enver Sangineto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1\">Nicu Sebe</a>",
          "description": "Environments in Reinforcement Learning are usually only partially observable.\nTo address this problem, a possible solution is to provide the agent with\ninformation about the past. However, providing complete observations of\nnumerous steps can be excessive. Inspired by human memory, we propose to\nrepresent history with only important changes in the environment and, in our\napproach, to obtain automatically this representation using self-supervision.\nOur method (TempAl) aligns temporally-close frames, revealing a general, slowly\nvarying state of the environment. This procedure is based on contrastive loss,\nwhich pulls embeddings of nearby observations to each other while pushing away\nother samples from the batch. It can be interpreted as a metric that captures\nthe temporal relations of observations. We propose to combine both common\ninstantaneous and our history representation and we evaluate TempAl on all\navailable Atari games from the Arcade Learning Environment. TempAl surpasses\nthe instantaneous-only baseline in 35 environments out of 49. The source code\nof the method and of all the experiments is available at\nhttps://github.com/htdt/tempal.",
          "link": "http://arxiv.org/abs/2204.03525",
          "publishedOn": "2022-04-09T00:48:55.105Z",
          "wordCount": null,
          "title": "Temporal Alignment for History Representation in Reinforcement Learning. (arXiv:2204.03525v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zongmin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yitian Xu</a>",
          "description": "Direct multi-task twin support vector machine (DMTSVM) explores the shared\ninformation between multiple correlated tasks, then it produces better\ngeneralization performance. However, it contains matrix inversion operation\nwhen solving the dual problems, so it costs much running time. Moreover, kernel\ntrick cannot be directly utilized in the nonlinear case. To effectively avoid\nabove problems, a novel multi-task nonparallel support vector machine (MTNPSVM)\nincluding linear and nonlinear cases is proposed in this paper. By introducing\nepsilon-insensitive loss instead of square loss in DMTSVM, MTNPSVM effectively\navoids matrix inversion operation and takes full advantage of the kernel trick.\nTheoretical implication of the model is further discussed. To further improve\nthe computational efficiency, the alternating direction method of multipliers\n(ADMM) is employed when solving the dual problem. The computational complexity\nand convergence of the algorithm are provided. In addition, the property and\nsensitivity of the parameter in model are further explored. The experimental\nresults on fifteen benchmark datasets and twelve image datasets demonstrate the\nvalidity of MTNPSVM in comparison with the state-of-the-art algorithms.\nFinally, it is applied to real Chinese Wine dataset, and also verifies its\neffectiveness.",
          "link": "http://arxiv.org/abs/2204.02972",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "Multi-task nonparallel support vector machine for classification. (arXiv:2204.02972v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yi Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagduyu_Y/0/1/0/all/0/1\">Yalin E. Sagduyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erpek_T/0/1/0/all/0/1\">Tugba Erpek</a>",
          "description": "NextG networks are intended to provide the flexibility of sharing the\nspectrum with incumbent users and support various spectrum monitoring tasks\nsuch as anomaly detection, fault diagnostics, user equipment identification,\nand authentication. A network of wireless sensors is needed to monitor the\nspectrum for signal transmissions of interest over a large deployment area.\nEach sensor receives signals under a specific channel condition depending on\nits location and trains an individual model of a deep neural network (DNN)\naccordingly to classify signals. To improve the accuracy, individual sensors\nmay exchange sensing data or sensor results with each other or with a fusion\ncenter (such as in cooperative spectrum sensing). In this paper, distributed\nfederated learning over a multi-hop wireless network is considered to\ncollectively train a DNN for signal identification. In distributed federated\nlearning, each sensor broadcasts its trained model to its neighbors, collects\nthe DNN models from its neighbors, and aggregates them to initialize its own\nmodel for the next round of training. Without exchanging any spectrum data,\nthis process is repeated over time such that a common DNN is built across the\nnetwork while preserving the privacy associated with signals collected at\ndifferent locations. Signal classification accuracy and convergence time are\nevaluated for different network topologies (including line, star, ring, grid,\nand random networks) and packet loss events. Then, the reduction of\ncommunication overhead and energy consumption is considered with random\nparticipation of sensors in model updates. The results show the feasibility of\nextending cooperative spectrum sensing over a general multi-hop wireless\nnetwork through federated learning and indicate its robustness to wireless\nnetwork effects, thereby sustaining high accuracy with low communication\noverhead and energy consumption.",
          "link": "http://arxiv.org/abs/2204.03027",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "Federated Learning for Distributed Spectrum Sensing in NextG Communication Networks. (arXiv:2204.03027v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1\">Maria-Florina Balcan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seiler_C/0/1/0/all/0/1\">Christopher Seiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1\">Dravyansh Sharma</a>",
          "description": "Data-driven algorithm configuration is a promising, learning-based approach\nfor beyond worst-case analysis of algorithms with tunable parameters. An\nimportant open problem is the design of efficient data-driven algorithms for\nalgorithm families with more than one parameter. In this work we provide\nalgorithms for efficient (output-polynomial) multidimensional parameter tuning,\ni.e. for families with a small constant number of parameters, for three very\ndifferent combinatorial problems -- linkage-based clustering, dynamic\nprogramming for sequence alignment, and auction design for two-part tariff\nschemes. We extend the single-parameter clustering algorithm of Balcan et al.\n2020 arXiv:1907.00533 to multiple parameters and to the sequence alignment\nproblem by proposing an execution graph which compactly represents all the\nstates the algorithm could attain for all possible parameter values. A key\nproblem-specific challenge is to efficiently compute how the partition of the\nparameter space (into regions with unique algorithmic states) changes with a\nsingle algorithmic step. We give algorithms which improve on the runtime of\npreviously best known results for linkage-based clustering, sequence alignment\nand two-part tariff pricing.",
          "link": "http://arxiv.org/abs/2204.03569",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "Faster algorithms for learning to link, align sequences, and price two-part tariffs. (arXiv:2204.03569v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1\">Leon Bottou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>",
          "description": "Regularization is a fundamental technique to prevent over-fitting and to\nimprove generalization performances by constraining a model's complexity.\nCurrent Deep Networks heavily rely on regularizers such as Data-Augmentation\n(DA) or weight-decay, and employ structural risk minimization, i.e.\ncross-validation, to select the optimal regularization hyper-parameters. In\nthis study, we demonstrate that techniques such as DA or weight decay produce a\nmodel with a reduced complexity that is unfair across classes. The optimal\namount of DA or weight decay found from cross-validation leads to disastrous\nmodel performances on some classes e.g. on Imagenet with a resnet50, the \"barn\nspider\" classification test accuracy falls from $68\\%$ to $46\\%$ only by\nintroducing random crop DA during training. Even more surprising, such\nperformance drop also appears when introducing uninformative regularization\ntechniques such as weight decay. Those results demonstrate that our search for\never increasing generalization performance -- averaged over all classes and\nsamples -- has left us with models and regularizers that silently sacrifice\nperformances on some classes. This scenario can become dangerous when deploying\na model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on\nINaturalist sees its performances fall from $70\\%$ to $30\\%$ on class \\#8889\nwhen introducing random crop DA during the Imagenet pre-training phase. Those\nresults demonstrate that designing novel regularizers without class-dependent\nbias remains an open research question.",
          "link": "http://arxiv.org/abs/2204.03632",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "The Effects of Regularization and Data Augmentation are Class Dependent. (arXiv:2204.03632v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Shashank Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaonkar_R/0/1/0/all/0/1\">Radhika Gaonkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chongyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1\">Soroush Vosoughi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>",
          "description": "Pre-trained language models (LMs) have been shown to memorize a substantial\namount of knowledge from the pre-training corpora; however, they are still\nlimited in recalling factually correct knowledge given a certain context.\nHence, they tend to suffer from counterfactual or hallucinatory generation when\nused in knowledge-intensive natural language generation (NLG) tasks. Recent\nremedies to this problem focus on modifying either the pre-training or task\nfine-tuning objectives to incorporate knowledge, which normally require\nadditional costly training or architecture modification of LMs for practical\napplications. We present Knowledge Infused Decoding (KID) -- a novel decoding\nalgorithm for generative LMs, which dynamically infuses external knowledge into\neach step of the LM decoding. Specifically, we maintain a local knowledge\nmemory based on the current context, interacting with a dynamically created\nexternal knowledge trie, and continuously update the local memory as a\nknowledge-aware constraint to guide decoding via reinforcement learning. On six\ndiverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART)\narmed with KID outperform many task-optimized state-of-the-art models, and show\nparticularly strong performance in few-shot scenarios over seven related\nknowledge-infusion techniques. Human evaluation confirms KID's ability to\ngenerate more relevant and factual language for the input context when compared\nwith multiple baselines. Finally, KID also alleviates exposure bias and\nprovides stable generation quality when generating longer sequences. Code for\nKID is available at https://github.com/microsoft/KID.",
          "link": "http://arxiv.org/abs/2204.03084",
          "publishedOn": "2022-04-09T00:48:55.103Z",
          "wordCount": null,
          "title": "Knowledge Infused Decoding. (arXiv:2204.03084v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Ming Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamura_T/0/1/0/all/0/1\">Toshiyo Tamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ono_N/0/1/0/all/0/1\">Naoaki Ono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altaf_Ul_Amin_M/0/1/0/all/0/1\">MD Altaf-Ul-Amin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanaya_S/0/1/0/all/0/1\">Shigehiko Kanaya</a>",
          "description": "Considering the natural frequency characteristics in sleep medicine, this\npaper first proposes a time-frequency framework for the representation learning\nof the electroencephalogram (EEG) following the definition of the American\nAcademy of Sleep Medicine. To meet the temporal-random and transient nature of\nthe defining characteristics of sleep stages, we further design a\ncontext-sensitive flexible pipeline that automatically adapts to the attributes\nof data itself. That is, the input EEG spectrogram is partitioned into a\nsequence of patches in the time and frequency axes, and then input to a\ndelicate deep learning network for further representation learning to extract\nthe stage-dependent features, which are used in the classification step\nfinally. The proposed pipeline is validated against a large database, i.e., the\nSleep Heart Health Study (SHHS), and the results demonstrate that the\ncompetitive performance for the wake, N2, and N3 stages outperforms the\nstate-of-art works, with the F1 scores being 0.93, 0.88, and 0.87,\nrespectively, and the proposed method has a high inter-rater reliability of\n0.80 kappa. Importantly, we visualize the stage scoring process of the model\ndecision with the Layer-wise Relevance Propagation (LRP) method, which shows\nthat the proposed pipeline is more sensitive and perceivable in the\ndecision-making process than the baseline pipelines. Therefore, the pipeline\ntogether with the LRP method can provide better model interpretability, which\nis important for clinical support.",
          "link": "http://arxiv.org/abs/2204.03173",
          "publishedOn": "2022-04-09T00:48:55.103Z",
          "wordCount": null,
          "title": "Enhancement on Model Interpretability and Sleep Stage Scoring Performance with A Novel Pipeline Based on Deep Neural Network. (arXiv:2204.03173v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1\">Jonathan Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salimans_T/0/1/0/all/0/1\">Tim Salimans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gritsenko_A/0/1/0/all/0/1\">Alexey Gritsenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1\">William Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1\">Mohammad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1\">David J. Fleet</a>",
          "description": "Generating temporally coherent high fidelity video is an important milestone\nin generative modeling research. We make progress towards this milestone by\nproposing a diffusion model for video generation that shows very promising\ninitial results. Our model is a natural extension of the standard image\ndiffusion architecture, and it enables jointly training from image and video\ndata, which we find to reduce the variance of minibatch gradients and speed up\noptimization. To generate long and higher resolution videos we introduce a new\nconditional sampling technique for spatial and temporal video extension that\nperforms better than previously proposed methods. We present the first results\non a large text-conditioned video generation task, as well as state-of-the-art\nresults on an established unconditional video generation benchmark.\nSupplementary material is available at https://video-diffusion.github.io/",
          "link": "http://arxiv.org/abs/2204.03458",
          "publishedOn": "2022-04-09T00:48:55.102Z",
          "wordCount": null,
          "title": "Video Diffusion Models. (arXiv:2204.03458v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yanyong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1\">Kejun Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiuwen Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianrui Li</a>",
          "description": "Multi-view unsupervised feature selection has been proven to be efficient in\nreducing the dimensionality of multi-view unlabeled data with high dimensions.\nThe previous methods assume all of the views are complete. However, in real\napplications, the multi-view data are often incomplete, i.e., some views of\ninstances are missing, which will result in the failure of these methods.\nBesides, while the data arrive in form of streams, these existing methods will\nsuffer the issues of high storage cost and expensive computation time. To\naddress these issues, we propose an Incremental Incomplete Multi-view\nUnsupervised Feature Selection method (I$^2$MUFS) on incomplete multi-view\nstreaming data. By jointly considering the consistent and complementary\ninformation across different views, I$^2$MUFS embeds the unsupervised feature\nselection into an extended weighted non-negative matrix factorization model,\nwhich can learn a consensus clustering indicator matrix and fuse different\nlatent feature matrices with adaptive view weights. Furthermore, we introduce\nthe incremental leaning mechanisms to develop an alternative iterative\nalgorithm, where the feature selection matrix is incrementally updated, rather\nthan recomputing on the entire updated data from scratch. A series of\nexperiments are conducted to verify the effectiveness of the proposed method by\ncomparing with several state-of-the-art methods. The experimental results\ndemonstrate the effectiveness and efficiency of the proposed method in terms of\nthe clustering metrics and the computational cost.",
          "link": "http://arxiv.org/abs/2204.02973",
          "publishedOn": "2022-04-09T00:48:55.002Z",
          "wordCount": null,
          "title": "Incremental Unsupervised Feature Selection for Dynamic Incomplete Multi-view Data. (arXiv:2204.02973v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_E/0/1/0/all/0/1\">Ensheng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gub_W/0/1/0/all/0/1\">Wenchao Gub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hongbin Sun</a>",
          "description": "Code search aims to retrieve the most semantically relevant code snippet for\na given natural language query. Recently, large-scale code pre-trained models\nsuch as CodeBERT and GraphCodeBERT learn generic representations of source code\nand have achieved substantial improvement on code search task. However, the\nhigh-quality sequence-level representations of code snippets have not been\nsufficiently explored. In this paper, we propose a new approach with multimodal\ncontrastive learning and soft data augmentation for code search. Multimodal\ncontrastive learning is used to pull together the representations of code-query\npairs and push apart the unpaired code snippets and queries. Moreover, data\naugmentation is critical in contrastive learning for learning high-quality\nrepresentations. However, only semantic-preserving augmentations for source\ncode are considered in existing work. In this work, we propose to do soft data\naugmentation by dynamically masking and replacing some tokens in code sequences\nto generate code snippets that are similar but not necessarily\nsemantic-preserving as positive samples for paired queries. We conduct\nextensive experiments to evaluate the effectiveness of our approach on a\nlarge-scale dataset with six programming languages. The experimental results\nshow that our approach significantly outperforms the state-of-the-art methods.\nWe also adapt our techniques to several pre-trained models such as RoBERTa and\nCodeBERT, and significantly boost their performance on the code search task.",
          "link": "http://arxiv.org/abs/2204.03293",
          "publishedOn": "2022-04-09T00:48:55.002Z",
          "wordCount": null,
          "title": "Enhancing Semantic Code Search with Multimodal Contrastive Learning and Soft Data Augmentation. (arXiv:2204.03293v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klapsas_K/0/1/0/all/0/1\">Konstantinos Klapsas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellinas_N/0/1/0/all/0/1\">Nikolaos Ellinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikitaras_K/0/1/0/all/0/1\">Karolos Nikitaras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vamvoukakis_G/0/1/0/all/0/1\">Georgios Vamvoukakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakoulidis_P/0/1/0/all/0/1\">Panos Kakoulidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markopoulos_K/0/1/0/all/0/1\">Konstantinos Markopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raptis_S/0/1/0/all/0/1\">Spyros Raptis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_J/0/1/0/all/0/1\">June Sig Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jho_G/0/1/0/all/0/1\">Gunu Jho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalamandaris_A/0/1/0/all/0/1\">Aimilios Chalamandaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsiakoulis_P/0/1/0/all/0/1\">Pirros Tsiakoulis</a>",
          "description": "Voice cloning is a difficult task which requires robust and informative\nfeatures incorporated in a high quality TTS system in order to effectively copy\nan unseen speaker's voice. In our work, we utilize features learned in a\nself-supervised framework via the Bootstrap Your Own Latent (BYOL) method,\nwhich is shown to produce high quality speech representations when specific\naudio augmentations are applied to the vanilla algorithm. We further extend the\naugmentations in the training procedure to aid the resulting features to\ncapture the speaker identity and to make them robust to noise and acoustic\nconditions. The learned features are used as pre-trained utterance-level\nembeddings and as inputs to a Non-Attentive Tacotron based architecture, aiming\nto achieve multispeaker speech synthesis without utilizing additional speaker\nfeatures. This method enables us to train our model in an unlabeled\nmultispeaker dataset as well as use unseen speaker embeddings to copy a\nspeaker's voice. Subjective and objective evaluations are used to validate the\nproposed model, as well as the robustness to the acoustic conditions of the\ntarget utterance.",
          "link": "http://arxiv.org/abs/2204.03421",
          "publishedOn": "2022-04-09T00:48:55.002Z",
          "wordCount": null,
          "title": "Self supervised learning for robust voice cloning. (arXiv:2204.03421v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03565",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhu_L/0/1/0/all/0/1\">Lingwei Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Odani_K/0/1/0/all/0/1\">Koki Odani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Ziwei Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_G/0/1/0/all/0/1\">Guang Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kan_Y/0/1/0/all/0/1\">Yirong Kan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_R/0/1/0/all/0/1\">Renyuan Zhang</a>",
          "description": "Recently there has seen promising results on automatic stage scoring by\nextracting spatio-temporal features from electroencephalogram (EEG). Such\nmethods entail laborious manual feature engineering and domain knowledge. In\nthis study, we propose an adaptive scheme to probabilistically encode, filter\nand accumulate the input signals and weight the resultant features by the\nhalf-Gaussian probabilities of signal intensities. The adaptive representations\nare subsequently fed into a transformer model to automatically mine the\nrelevance between features and corresponding stages. Extensive experiments on\nthe largest public dataset against state-of-the-art methods validate the\neffectiveness of our proposed method and reveal promising future directions.",
          "link": "http://arxiv.org/abs/2204.03565",
          "publishedOn": "2022-04-09T00:48:55.001Z",
          "wordCount": null,
          "title": "Adaptive Spike-Like Representation of EEG Signals for Sleep Stages Scoring. (arXiv:2204.03565v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03125",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Niu_K/0/1/0/all/0/1\">Kaicheng Niu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_M/0/1/0/all/0/1\">Mi Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abdallah_C/0/1/0/all/0/1\">Chaouki T. Abdallah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hayajneh_M/0/1/0/all/0/1\">Mohammad Hayajneh</a>",
          "description": "Recurrent neural networks (RNNs) have many advantages over more traditional\nsystem identification techniques. They may be applied to linear and nonlinear\nsystems, and they require fewer modeling assumptions. However, these neural\nnetwork models may also need larger amounts of data to learn and generalize.\nFurthermore, neural networks training is a time-consuming process. Hence,\nbuilding upon long-short term memory neural networks (LSTM), this paper\nproposes using two types of deep transfer learning, namely parameter\nfine-tuning and freezing, to reduce the data and computation requirements for\nsystem identification. We apply these techniques to identify two dynamical\nsystems, namely a second-order linear system and a Wiener-Hammerstein nonlinear\nsystem. Results show that compared with direct learning, our method accelerates\nlearning by 10% to 50%, which also saves data and computing resources.",
          "link": "http://arxiv.org/abs/2204.03125",
          "publishedOn": "2022-04-09T00:48:54.812Z",
          "wordCount": null,
          "title": "Deep transfer learning for system identification using long short-term memory neural networks. (arXiv:2204.03125v1 [eess.SY])",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "stat.ML updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/stat.ML",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2110.05165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ludtke_S/0/1/0/all/0/1\">Stefan L&#xfc;dtke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartelt_C/0/1/0/all/0/1\">Christian Bartelt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stuckenschmidt_H/0/1/0/all/0/1\">Heiner Stuckenschmidt</a>",
          "description": "Sum-Product Networks (SPNs) are expressive probabilistic models that provide\nexact, tractable inference. They achieve this efficiency by making use of local\nindependence. On the other hand, mixtures of exchangeable variable models\n(MEVMs) are a class of tractable probabilistic models that make use of\nexchangeability of discrete random variables to render inference tractable.\nExchangeability, which arises naturally in relational domains, has not been\nconsidered for efficient representation and inference in SPNs yet. The\ncontribution of this paper is a novel probabilistic model which we call\nExchangeability-Aware Sum-Product Networks (XSPNs). It contains both SPNs and\nMEVMs as special cases, and combines the ability of SPNs to efficiently learn\ndeep probabilistic models with the ability of MEVMs to efficiently handle\nexchangeable random variables. We introduce a structure learning algorithm for\nXSPNs and empirically show that they can be more accurate than conventional\nSPNs when the data contains repeated, interchangeable parts.",
          "link": "http://arxiv.org/abs/2110.05165",
          "publishedOn": "2022-04-30T01:01:32.531Z",
          "wordCount": 608,
          "title": "Exchangeability-Aware Sum-Product Networks. (arXiv:2110.05165v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.07564",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pronzato_L/0/1/0/all/0/1\">Luc Pronzato</a>",
          "description": "We analyse the performance of several iterative algorithms for the\nquantisation of a probability measure $\\mu$, based on the minimisation of a\nMaximum Mean Discrepancy (MMD). Our analysis includes kernel herding, greedy\nMMD minimisation and Sequential Bayesian Quadrature (SBQ). We show that the\nfinite-sample-size approximation error, measured by the MMD, decreases as $1/n$\nfor SBQ and also for kernel herding and greedy MMD minimisation when using a\nsuitable step-size sequence. The upper bound on the approximation error is\nslightly better for SBQ, but the other methods are significantly faster, with a\ncomputational cost that increases only linearly with the number of points\nselected. This is illustrated by two numerical examples, with the target\nmeasure $\\mu$ being uniform (a space-filling design application) and with $\\mu$\na Gaussian mixture. They suggest that the bounds derived in the paper are\noverly pessimistic, in particular for SBQ. The sources of this pessimism are\nidentified but seem difficult to counter.",
          "link": "http://arxiv.org/abs/2101.07564",
          "publishedOn": "2022-04-30T01:01:32.509Z",
          "wordCount": 625,
          "title": "Performance analysis of greedy algorithms for minimising a Maximum Mean Discrepancy. (arXiv:2101.07564v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suk_J/0/1/0/all/0/1\">Joe Suk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>",
          "description": "In bandit with distribution shifts, one aims to automatically adapt to\nunknown changes in reward distribution, and restart exploration when necessary.\nWhile this problem has been studied for many years, a recent breakthrough of\nAuer et al. (2018, 2019) provides the first adaptive procedure to guarantee an\noptimal (dynamic) regret $\\sqrt{LT}$, for $T$ rounds, and an unknown number $L$\nof changes. However, while this rate is tight in the worst case, it remained\nopen whether faster rates are possible, without prior knowledge, if few changes\nin distribution are actually severe.\n\nTo resolve this question, we propose a new notion of significant shift, which\nonly counts very severe changes that clearly necessitate a restart: roughly,\nthese are changes involving not only best arm switches, but also involving\nlarge aggregate differences in reward overtime. Thus, our resulting procedure\nadaptively achieves rates always faster (sometimes significantly) than\n$O(\\sqrt{ST})$, where $S\\ll L$ only counts best arm switches, while at the same\ntime, always faster than the optimal $O(V^{\\frac{1}{3}}T^{\\frac{2}{3}})$ when\nexpressed in terms of total variation $V$ (which aggregates differences\novertime). Our results are expressed in enough generality to also capture\nnon-stochastic adversarial settings.",
          "link": "http://arxiv.org/abs/2112.13838",
          "publishedOn": "2022-04-30T01:01:32.501Z",
          "wordCount": 672,
          "title": "Tracking Most Significant Arm Switches in Bandits. (arXiv:2112.13838v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.12657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiavazzi_D/0/1/0/all/0/1\">Daniele E. Schiavazzi</a>",
          "description": "Fast inference of numerical model parameters from data is an important\nprerequisite to generate predictive models for a wide range of applications.\nUse of sampling-based approaches such as Markov chain Monte Carlo may become\nintractable when each likelihood evaluation is computationally expensive. New\napproaches combining variational inference with normalizing flow are\ncharacterized by a computational cost that grows only linearly with the\ndimensionality of the latent variable space, and rely on gradient-based\noptimization instead of sampling, providing a more efficient approach for\nBayesian inference about the model parameters. Moreover, the cost of frequently\nevaluating an expensive likelihood can be mitigated by replacing the true model\nwith an offline trained surrogate model, such as neural networks. However, this\napproach might generate significant bias when the surrogate is insufficiently\naccurate around the posterior modes. To reduce the computational cost without\nsacrificing inferential accuracy, we propose Normalizing Flow with Adaptive\nSurrogate (NoFAS), an optimization strategy that alternatively updates the\nnormalizing flow parameters and surrogate model parameters. We also propose an\nefficient sample weighting scheme for surrogate model training that preserves\nglobal accuracy while effectively capturing high posterior density regions. We\ndemonstrate the inferential and computational superiority of NoFAS against\nvarious benchmarks, including cases where the underlying model lacks\nidentifiability. The source code and numerical experiments used for this study\nare available at https://github.com/cedricwangyu/NoFAS.",
          "link": "http://arxiv.org/abs/2108.12657",
          "publishedOn": "2022-04-30T01:01:32.487Z",
          "wordCount": 694,
          "title": "Variational Inference with NoFAS: Normalizing Flow with Adaptive Surrogate for Computationally Expensive Models. (arXiv:2108.12657v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.10613",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Terenin_A/0/1/0/all/0/1\">Alexander Terenin</a>",
          "description": "Bayesian learning using Gaussian processes provides a foundational framework\nfor making decisions in a manner that balances what is known with what could be\nlearned by gathering data. In this dissertation, we develop techniques for\nbroadening the applicability of Gaussian processes. This is done in two ways.\nFirstly, we develop pathwise conditioning techniques for Gaussian processes,\nwhich allow one to express posterior random functions as prior random functions\nplus a dependent update term. We introduce a wide class of efficient\napproximations built from this viewpoint, which can be randomly sampled once in\nadvance, and evaluated at arbitrary locations without any subsequent\nstochasticity. This key property improves efficiency and makes it simpler to\ndeploy Gaussian process models in decision-making settings. Secondly, we\ndevelop a collection of Gaussian process models over non-Euclidean spaces,\nincluding Riemannian manifolds and graphs. We derive fully constructive\nexpressions for the covariance kernels of scalar-valued Gaussian processes on\nRiemannian manifolds and graphs. Building on these ideas, we describe a\nformalism for defining vector-valued Gaussian processes on Riemannian\nmanifolds. The introduced techniques allow all of these models to be trained\nusing standard computational methods. In total, these contributions make\nGaussian processes easier to work with and allow them to be used within a wider\nclass of domains in an effective and principled manner. This, in turn, makes it\npossible to potentially apply Gaussian processes to novel decision-making\nsettings.",
          "link": "http://arxiv.org/abs/2202.10613",
          "publishedOn": "2022-04-30T01:01:32.480Z",
          "wordCount": 692,
          "title": "Gaussian Processes and Statistical Decision-making in Non-Euclidean Spaces. (arXiv:2202.10613v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12275",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ashman_M/0/1/0/all/0/1\">Matthew Ashman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bui_T/0/1/0/all/0/1\">Thang D. Bui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_C/0/1/0/all/0/1\">Cuong V. Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Markou_S/0/1/0/all/0/1\">Stratis Markou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Swaroop_S/0/1/0/all/0/1\">Siddharth Swaroop</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>",
          "description": "The proliferation of computing devices has brought about an opportunity to\ndeploy machine learning models on new problem domains using previously\ninaccessible data. Traditional algorithms for training such models often\nrequire data to be stored on a single machine with compute performed by a\nsingle node, making them unsuitable for decentralised training on multiple\ndevices. This deficiency has motivated the development of federated learning\nalgorithms, which allow multiple data owners to train collaboratively and use a\nshared model whilst keeping local data private. However, many of these\nalgorithms focus on obtaining point estimates of model parameters, rather than\nprobabilistic estimates capable of capturing model uncertainty, which is\nessential in many applications. Variational inference (VI) has become the\nmethod of choice for fitting many modern probabilistic models. In this paper we\nintroduce partitioned variational inference (PVI), a general framework for\nperforming VI in the federated setting. We develop new supporting theory for\nPVI, demonstrating a number of properties that make it an attractive choice for\npractitioners; use PVI to unify a wealth of fragmented, yet related literature;\nand provide empirical results that showcase the effectiveness of PVI in a\nvariety of federated settings.",
          "link": "http://arxiv.org/abs/2202.12275",
          "publishedOn": "2022-04-30T01:01:32.468Z",
          "wordCount": 682,
          "title": "Partitioned Variational Inference: A Framework for Probabilistic Federated Learning. (arXiv:2202.12275v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.08696",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Wirnsberger_P/0/1/0/all/0/1\">Peter Wirnsberger</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Papamakarios_G/0/1/0/all/0/1\">George Papamakarios</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ibarz_B/0/1/0/all/0/1\">Borja Ibarz</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Racaniere_S/0/1/0/all/0/1\">S&#xe9;bastien Racani&#xe8;re</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ballard_A/0/1/0/all/0/1\">Andrew J. Ballard</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pritzel_A/0/1/0/all/0/1\">Alexander Pritzel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Blundell_C/0/1/0/all/0/1\">Charles Blundell</a>",
          "description": "We present a machine-learning approach, based on normalizing flows, for\nmodelling atomic solids. Our model transforms an analytically tractable base\ndistribution into the target solid without requiring ground-truth samples for\ntraining. We report Helmholtz free energy estimates for cubic and hexagonal ice\nmodelled as monatomic water as well as for a truncated and shifted\nLennard-Jones system, and find them to be in excellent agreement with\nliterature values and with estimates from established baseline methods. We\nfurther investigate structural properties and show that the model samples are\nnearly indistinguishable from the ones obtained with molecular dynamics. Our\nresults thus demonstrate that normalizing flows can provide high-quality\nsamples and free energy estimates without the need for multi-staging.",
          "link": "http://arxiv.org/abs/2111.08696",
          "publishedOn": "2022-04-30T01:01:32.447Z",
          "wordCount": 591,
          "title": "Normalizing flows for atomic solids. (arXiv:2111.08696v2 [physics.comp-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.04266",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Wein_S/0/1/0/all/0/1\">Simon Wein</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Schuller_A/0/1/0/all/0/1\">Alina Sch&#xfc;ller</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tome_A/0/1/0/all/0/1\">Ana Maria Tom&#xe9;</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Malloni_W/0/1/0/all/0/1\">Wilhelm M. Malloni</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Greenlee_M/0/1/0/all/0/1\">Mark W. Greenlee</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lang_E/0/1/0/all/0/1\">Elmar W. Lang</a>",
          "description": "Comprehending the interplay between spatial and temporal characteristics of\nneural dynamics can contribute to our understanding of information processing\nin the human brain. Graph neural networks (GNNs) provide a new possibility to\ninterpret graph structured signals like those observed in complex brain\nnetworks. In our study we compare different spatio-temporal GNN architectures\nand study their ability to model neural activity distributions obtained in\nfunctional MRI (fMRI) studies. We evaluate the performance of the GNN models on\na variety of scenarios in MRI studies and also compare it to a VAR model, which\nis currently often used for directed functional connectivity analysis. We show\nthat by learning localized functional interactions on the anatomical substrate,\nGNN based approaches are able to robustly scale to large network studies, even\nwhen available data are scarce. By including anatomical connectivity as the\nphysical substrate for information propagation, such GNNs also provide a\nmulti-modal perspective on directed connectivity analysis, offering a novel\npossibility to investigate the spatio-temporal dynamics in brain networks.",
          "link": "http://arxiv.org/abs/2112.04266",
          "publishedOn": "2022-04-30T01:01:32.438Z",
          "wordCount": 646,
          "title": "Forecasting Brain Activity Based on Models of Spatio-Temporal Brain Dynamics: A Comparison of Graph Neural Network Architectures. (arXiv:2112.04266v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.01052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Angelopoulos_A/0/1/0/all/0/1\">Anastasios N. Angelopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bates_S/0/1/0/all/0/1\">Stephen Bates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candes_E/0/1/0/all/0/1\">Emmanuel J. Cand&#xe8;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_L/0/1/0/all/0/1\">Lihua Lei</a>",
          "description": "We introduce a framework for calibrating machine learning models so that\ntheir predictions satisfy explicit, finite-sample statistical guarantees. Our\ncalibration algorithm works with any underlying model and (unknown)\ndata-generating distribution and does not require model refitting. The\nframework addresses, among other examples, false discovery rate control in\nmulti-label classification, intersection-over-union control in instance\nsegmentation, and the simultaneous control of the type-1 error of outlier\ndetection and confidence set coverage in classification or regression. Our main\ninsight is to reframe the risk-control problem as multiple hypothesis testing,\nenabling techniques and mathematical arguments different from those in the\nprevious literature. We use our framework to provide new calibration methods\nfor several core machine learning tasks with detailed worked examples in\ncomputer vision and tabular medical data.",
          "link": "http://arxiv.org/abs/2110.01052",
          "publishedOn": "2022-04-30T01:01:32.423Z",
          "wordCount": 639,
          "title": "Learn then Test: Calibrating Predictive Algorithms to Achieve Risk Control. (arXiv:2110.01052v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.03278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Minh N. H. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1\">Shashi Raj Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1\">Tri Nguyen Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huh_E/0/1/0/all/0/1\">Eui-Nam Huh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_N/0/1/0/all/0/1\">Nguyen H. Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1\">Walid Saad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1\">Choong Seon Hong</a>",
          "description": "Emerging cross-device artificial intelligence (AI) applications require a\ntransition from conventional centralized learning systems towards large-scale\ndistributed AI systems that can collaboratively perform complex learning tasks.\nIn this regard, democratized learning (Dem-AI) lays out a holistic philosophy\nwith underlying principles for building large-scale distributed and\ndemocratized machine learning systems. The outlined principles are meant to\nstudy a generalization in distributed learning systems that goes beyond\nexisting mechanisms such as federated learning. Moreover, such learning systems\nrely on hierarchical self-organization of well-connected distributed learning\nagents who have limited and highly personalized data and can evolve and\nregulate themselves based on the underlying duality of specialized and\ngeneralized processes. Inspired by Dem-AI philosophy, a novel distributed\nlearning approach is proposed in this paper. The approach consists of a\nself-organizing hierarchical structuring mechanism based on agglomerative\nclustering, hierarchical generalization, and corresponding learning mechanism.\nSubsequently, hierarchical generalized learning problems in recursive forms are\nformulated and shown to be approximately solved using the solutions of\ndistributed personalized learning problems and hierarchical update mechanisms.\nTo that end, a distributed learning algorithm, namely DemLearn is proposed.\nExtensive experiments on benchmark MNIST, Fashion-MNIST, FE-MNIST, and CIFAR-10\ndatasets show that the proposed algorithms demonstrate better results in the\ngeneralization performance of learning models in agents compared to the\nconventional FL algorithms. The detailed analysis provides useful observations\nto further handle both the generalization and specialization performance of the\nlearning models in Dem-AI systems.",
          "link": "http://arxiv.org/abs/2007.03278",
          "publishedOn": "2022-04-30T01:01:32.294Z",
          "wordCount": 728,
          "title": "Self-organizing Democratized Learning: Towards Large-scale Distributed Learning Systems. (arXiv:2007.03278v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.05465",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qiu_H/0/1/0/all/0/1\">Hongxiang Qiu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Luedtke_A/0/1/0/all/0/1\">Alex Luedtke</a>",
          "description": "Bayes estimators are well known to provide a means to incorporate prior\nknowledge that can be expressed in terms of a single prior distribution.\nHowever, when this knowledge is too vague to express with a single prior, an\nalternative approach is needed. Gamma-minimax estimators provide such an\napproach. These estimators minimize the worst-case Bayes risk over a set\n$\\Gamma$ of prior distributions that are compatible with the available\nknowledge. Traditionally, Gamma-minimaxity is defined for parametric models. In\nthis work, we define Gamma-minimax estimators for general models and propose\nadversarial meta-learning algorithms to compute them when the set of prior\ndistributions is constrained by generalized moments. Accompanying convergence\nguarantees are also provided. We also introduce a neural network class that\nprovides a rich, but finite-dimensional, class of estimators from which a\nGamma-minimax estimator can be selected. We illustrate our method in two\nsettings, namely entropy estimation and a prediction problem that arises in\nbiodiversity studies.",
          "link": "http://arxiv.org/abs/2012.05465",
          "publishedOn": "2022-04-30T01:01:32.251Z",
          "wordCount": 607,
          "title": "Adversarial Meta-Learning of Gamma-Minimax Estimators That Leverage Prior Knowledge. (arXiv:2012.05465v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13599",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cocola_J/0/1/0/all/0/1\">Jorio Cocola</a>",
          "description": "We study compressive sensing with a deep generative network prior. Initial\ntheoretical guarantees for efficient recovery from compressed linear\nmeasurements have been developed for signals in the range of a ReLU network\nwith Gaussian weights and logarithmic expansivity: that is when each layer is\nlarger than the previous one by a logarithmic factor. It was later shown that\nconstant expansivity is sufficient for recovery. It has remained open whether\nthe expansivity can be relaxed allowing for networks with contractive layers,\nas often the case of real generators. In this work we answer this question,\nproving that a signal in the range of a Gaussian generative network can be\nrecovered from a few linear measurements provided that the width of the layers\nis proportional to the input layer size (up to log factors). This condition\nallows the generative network to have contractive layers. Our result is based\non showing that Gaussian matrices satisfy a matrix concentration inequality,\nwhich we term Range Restricted Weight Distribution Condition (R2WDC), and\nweakens the Weight Distribution Condition (WDC) upon which previous theoretical\nguarantees were based on. The WDC has also been used to analyze other signal\nrecovery problems with generative network priors. By replacing the WDC with the\nR2WDC, we are able to extend previous results for signal recovery with\nexpansive generative network priors to non-expansive ones. We discuss these\nextensions for phase retrieval, denoising, and spiked matrix recovery.",
          "link": "http://arxiv.org/abs/2204.13599",
          "publishedOn": "2022-04-30T01:01:32.231Z",
          "wordCount": 671,
          "title": "Signal Recovery with Non-Expansive Generative Network Priors. (arXiv:2204.13599v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.16223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leplat_V/0/1/0/all/0/1\">Valentin Leplat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gillis_N/0/1/0/all/0/1\">Nicolas Gillis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Idier_J/0/1/0/all/0/1\">J&#xe9;r&#xf4;me Idier</a>",
          "description": "Nonnegative matrix factorization (NMF) is the problem of approximating an\ninput nonnegative matrix, $V$, as the product of two smaller nonnegative\nmatrices, $W$ and $H$. In this paper, we introduce a general framework to\ndesign multiplicative updates (MU) for NMF based on $\\beta$-divergences\n($\\beta$-NMF) with disjoint equality constraints, and with penalty terms in the\nobjective function. By disjoint, we mean that each variable appears in at most\none equality constraint. Our MU satisfy the set of constraints after each\nupdate of the variables during the optimization process, while guaranteeing\nthat the objective function decreases monotonically. We showcase this framework\non three NMF models, and show that it competes favorably the state of the art:\n(1)~$\\beta$-NMF with sum-to-one constraints on the columns of $H$, (2)\nminimum-volume $\\beta$-NMF with sum-to-one constraints on the columns of $W$,\nand (3) sparse $\\beta$-NMF with $\\ell_2$-norm constraints on the columns of\n$W$.",
          "link": "http://arxiv.org/abs/2010.16223",
          "publishedOn": "2022-04-30T01:01:32.184Z",
          "wordCount": 690,
          "title": "Multiplicative Updates for NMF with $\\beta$-Divergences under Disjoint Equality Constraints. (arXiv:2010.16223v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Donati_N/0/1/0/all/0/1\">Nicolas Donati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corman_E/0/1/0/all/0/1\">Etienne Corman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ovsjanikov_M/0/1/0/all/0/1\">Maks Ovsjanikov</a>",
          "description": "State-of-the-art fully intrinsic networks for non-rigid shape matching often\nstruggle to disambiguate the symmetries of the shapes leading to unstable\ncorrespondence predictions. Meanwhile, recent advances in the functional map\nframework allow to enforce orientation preservation using a functional\nrepresentation for tangent vector field transfer, through so-called complex\nfunctional maps. Using this representation, we propose a new deep learning\napproach to learn orientation-aware features in a fully unsupervised setting.\nOur architecture is built on top of DiffusionNet, making it robust to\ndiscretization changes. Additionally, we introduce a vector field-based loss,\nwhich promotes orientation preservation without using (often unstable)\nextrinsic descriptors.",
          "link": "http://arxiv.org/abs/2204.13453",
          "publishedOn": "2022-04-30T01:01:32.082Z",
          "wordCount": 589,
          "title": "Deep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching. (arXiv:2204.13453v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hetzel_L/0/1/0/all/0/1\">Leon Hetzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohm_S/0/1/0/all/0/1\">Simon B&#xf6;hm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kilbertus_N/0/1/0/all/0/1\">Niki Kilbertus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lotfollahi_M/0/1/0/all/0/1\">Mohammad Lotfollahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theis_F/0/1/0/all/0/1\">Fabian Theis</a>",
          "description": "Single-cell transcriptomics enabled the study of cellular heterogeneity in\nresponse to perturbations at the resolution of individual cells. However,\nscaling high-throughput screens (HTSs) to measure cellular responses for many\ndrugs remains a challenge due to technical limitations and, more importantly,\nthe cost of such multiplexed experiments. Thus, transferring information from\nroutinely performed bulk RNA-seq HTS is required to enrich single-cell data\nmeaningfully. We introduce a new encoder-decoder architecture to study the\nperturbational effects of unseen drugs. We combine the model with a transfer\nlearning scheme and demonstrate how training on existing bulk RNA-seq HTS\ndatasets can improve generalisation performance. Better generalisation reduces\nthe need for extensive and costly screens at single-cell resolution. We\nenvision that our proposed method will facilitate more efficient experiment\ndesigns through its ability to generate in-silico hypotheses, ultimately\naccelerating targeted drug discovery.",
          "link": "http://arxiv.org/abs/2204.13545",
          "publishedOn": "2022-04-30T01:01:32.057Z",
          "wordCount": 597,
          "title": "Predicting single-cell perturbation responses for unseen drugs. (arXiv:2204.13545v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jitkrittum_W/0/1/0/all/0/1\">Wittawat Jitkrittum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1\">Aditya Krishna Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawat_A/0/1/0/all/0/1\">Ankit Singh Rawat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>",
          "description": "Long-tail learning is the problem of learning under skewed label\ndistributions, which pose a challenge for standard learners. Several recent\napproaches for the problem have proposed enforcing a suitable margin in logit\nspace. Such techniques are intuitive analogues of the guiding principle behind\nSVMs, and are equally applicable to linear models and neural models. However,\nwhen applied to neural models, such techniques do not explicitly control the\ngeometry of the learned embeddings. This can be potentially sub-optimal, since\nembeddings for tail classes may be diffuse, resulting in poor generalization\nfor these classes. We present Embedding and Logit Margins (ELM), a unified\napproach to enforce margins in logit space, and regularize the distribution of\nembeddings. This connects losses for long-tail learning to proposals in the\nliterature on metric embedding, and contrastive learning. We theoretically show\nthat minimising the proposed ELM objective helps reduce the generalisation gap.\nThe ELM method is shown to perform well empirically, and results in tighter\ntail class embeddings.",
          "link": "http://arxiv.org/abs/2204.13208",
          "publishedOn": "2022-04-30T01:01:32.049Z",
          "wordCount": 602,
          "title": "ELM: Embedding and Logit Margins for Long-Tail Learning. (arXiv:2204.13208v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1905.10395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1\">Yunfei Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wenbo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalus_F/0/1/0/all/0/1\">Francois Chalus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanska_A/0/1/0/all/0/1\">Anna Choromanska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldfarb_D/0/1/0/all/0/1\">Donald Goldfarb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "We consider distributed optimization under communication constraints for\ntraining deep learning models. We propose a new algorithm, whose parameter\nupdates rely on two forces: a regular gradient step, and a corrective direction\ndictated by the currently best-performing worker (leader). Our method differs\nfrom the parameter-averaging scheme EASGD in a number of ways: (i) our\nobjective formulation does not change the location of stationary points\ncompared to the original optimization problem; (ii) we avoid convergence\ndecelerations caused by pulling local workers descending to different local\nminima to each other (i.e. to the average of their parameters); (iii) our\nupdate by design breaks the curse of symmetry (the phenomenon of being trapped\nin poorly generalizing sub-optimal solutions in symmetric non-convex\nlandscapes); and (iv) our approach is more communication efficient since it\nbroadcasts only parameters of the leader rather than all workers. We provide\ntheoretical analysis of the batch version of the proposed algorithm, which we\ncall Leader Gradient Descent (LGD), and its stochastic variant (LSGD). Finally,\nwe implement an asynchronous version of our algorithm and extend it to the\nmulti-leader setting, where we form groups of workers, each represented by its\nown local leader (the best performer in a group), and update each worker with a\ncorrective direction comprised of two attractive forces: one to the local, and\none to the global leader (the best performer among all workers). The\nmulti-leader setting is well-aligned with current hardware architecture, where\nlocal workers forming a group lie within a single computational node and\ndifferent groups correspond to different nodes. For training convolutional\nneural networks, we empirically demonstrate that our approach compares\nfavorably to state-of-the-art baselines. This work is a gentle extension of\n[2].",
          "link": "http://arxiv.org/abs/1905.10395",
          "publishedOn": "2022-04-30T01:01:32.042Z",
          "wordCount": 809,
          "title": "Leader Stochastic Gradient Descent for Distributed Training of Deep Learning Models: Extension. (arXiv:1905.10395v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.12581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1\">Yunfei Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanska_A/0/1/0/all/0/1\">Anna Choromanska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1\">Murray Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Songtao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1\">Parikshit Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horesh_L/0/1/0/all/0/1\">Lior Horesh</a>",
          "description": "This paper studies a new design of the optimization algorithm for training\ndeep learning models with a fixed architecture of the classification network in\na continual learning framework. The training data is non-stationary and the\nnon-stationarity is imposed by a sequence of distinct tasks. We first analyze a\ndeep model trained on only one learning task in isolation and identify a region\nin network parameter space, where the model performance is close to the\nrecovered optimum. We provide empirical evidence that this region resembles a\ncone that expands along the convergence direction. We study the principal\ndirections of the trajectory of the optimizer after convergence and show that\ntraveling along a few top principal directions can quickly bring the parameters\noutside the cone but this is not the case for the remaining directions. We\nargue that catastrophic forgetting in a continual learning setting can be\nalleviated when the parameters are constrained to stay within the intersection\nof the plausible cones of individual tasks that were so far encountered during\ntraining. Based on this observation we present our direction-constrained\noptimization (DCO) method, where for each task we introduce a linear\nautoencoder to approximate its corresponding top forbidden principal\ndirections. They are then incorporated into the loss function in the form of a\nregularization term for the purpose of learning the coming tasks without\nforgetting. Furthermore, in order to control the memory growth as the number of\ntasks increases, we propose a memory-efficient version of our algorithm called\ncompressed DCO (DCO-COMP) that allocates a memory of fixed size for storing all\nautoencoders. We empirically demonstrate that our algorithm performs favorably\ncompared to other state-of-art regularization-based continual learning methods.",
          "link": "http://arxiv.org/abs/2011.12581",
          "publishedOn": "2022-04-30T01:01:32.033Z",
          "wordCount": 741,
          "title": "Overcoming Catastrophic Forgetting via Direction-Constrained Optimization. (arXiv:2011.12581v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13166",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chugh_T/0/1/0/all/0/1\">Tinkle Chugh</a>",
          "description": "Many real-world multi-objective optimisation problems rely on computationally\nexpensive function evaluations. Multi-objective Bayesian optimisation (BO) can\nbe used to alleviate the computation time to find an approximated set of Pareto\noptimal solutions. In many real-world problems, a decision-maker has some\npreferences on the objective functions. One approach to incorporate the\npreferences in multi-objective BO is to use a scalarising function and build a\nsingle surrogate model (mono-surrogate approach) on it. This approach has two\nmajor limitations. Firstly, the fitness landscape of the scalarising function\nand the objective functions may not be similar. Secondly, the approach assumes\nthat the scalarising function distribution is Gaussian, and thus a closed-form\nexpression of an acquisition function e.g., expected improvement can be used.\nWe overcome these limitations by building independent surrogate models\n(multi-surrogate approach) on each objective function and show that the\ndistribution of the scalarising function is not Gaussian. We approximate the\ndistribution using Generalised value distribution. We present an a-priori\nmulti-surrogate approach to incorporate the desirable objective function values\n(or reference point) as the preferences of a decision-maker in multi-objective\nBO. The results and comparison with the existing mono-surrogate approach on\nbenchmark and real-world optimisation problems show the potential of the\nproposed approach.",
          "link": "http://arxiv.org/abs/2204.13166",
          "publishedOn": "2022-04-30T01:01:32.007Z",
          "wordCount": 655,
          "title": "R-MBO: A Multi-surrogate Approach for Preference Incorporation in Multi-objective Bayesian Optimisation. (arXiv:2204.13166v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+De_S/0/1/0/all/0/1\">Soham De</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berrada_L/0/1/0/all/0/1\">Leonard Berrada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayes_J/0/1/0/all/0/1\">Jamie Hayes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1\">Samuel L. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balle_B/0/1/0/all/0/1\">Borja Balle</a>",
          "description": "Differential Privacy (DP) provides a formal privacy guarantee preventing\nadversaries with access to a machine learning model from extracting information\nabout individual training points. Differentially Private Stochastic Gradient\nDescent (DP-SGD), the most popular DP training method, realizes this protection\nby injecting noise during training. However previous works have found that\nDP-SGD often leads to a significant degradation in performance on standard\nimage classification benchmarks. Furthermore, some authors have postulated that\nDP-SGD inherently performs poorly on large models, since the norm of the noise\nrequired to preserve privacy is proportional to the model dimension. In\ncontrast, we demonstrate that DP-SGD on over-parameterized models can perform\nsignificantly better than previously thought. Combining careful hyper-parameter\ntuning with simple techniques to ensure signal propagation and improve the\nconvergence rate, we obtain a new SOTA on CIFAR-10 of 81.4% under (8,\n10^{-5})-DP using a 40-layer Wide-ResNet, improving over the previous SOTA of\n71.7%. When fine-tuning a pre-trained 200-layer Normalizer-Free ResNet, we\nachieve a remarkable 77.1% top-1 accuracy on ImageNet under (1, 8*10^{-7})-DP,\nand achieve 81.1% under (8, 8*10^{-7})-DP. This markedly exceeds the previous\nSOTA of 47.9% under a larger privacy budget of (10, 10^{-6})-DP. We believe our\nresults are a significant step towards closing the accuracy gap between private\nand non-private image classification.",
          "link": "http://arxiv.org/abs/2204.13650",
          "publishedOn": "2022-04-30T01:01:31.998Z",
          "wordCount": 659,
          "title": "Unlocking High-Accuracy Differentially Private Image Classification through Scale. (arXiv:2204.13650v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scheiermann_J/0/1/0/all/0/1\">Johannes Scheiermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konen_W/0/1/0/all/0/1\">Wolfgang Konen</a>",
          "description": "Recently, the seminal algorithms AlphaGo and AlphaZero have started a new era\nin game learning and deep reinforcement learning. While the achievements of\nAlphaGo and AlphaZero - playing Go and other complex games at super human level\n- are truly impressive, these architectures have the drawback that they are\nvery complex and require high computational resources. Many researchers are\nlooking for methods that are similar to AlphaZero, but have lower computational\ndemands and are thus more easily reproducible. In this paper, we pick an\nimportant element of AlphaZero - the Monte Carlo Tree Search (MCTS) planning\nstage - and combine it with reinforcement learning (RL) agents. We wrap MCTS\nfor the first time around RL n-tuple networks to create versatile agents that\nkeep at the same time the computational demands low. We apply this new\narchitecture to several complex games (Othello, ConnectFour, Rubik's Cube) and\nshow the advantages achieved with this AlphaZero-inspired MCTS wrapper. In\nparticular, we present results that this AlphaZero-inspired agent is the first\none trained on standard hardware (no GPU or TPU) to beat the very strong\nOthello program Edax up to and including level 7 (where most other algorithms\ncould only defeat Edax up to level 2).",
          "link": "http://arxiv.org/abs/2204.13307",
          "publishedOn": "2022-04-30T01:01:31.991Z",
          "wordCount": 646,
          "title": "AlphaZero-Inspired General Board Game Learning and Playing. (arXiv:2204.13307v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haug_J/0/1/0/all/0/1\">Johannes Haug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tramountani_E/0/1/0/all/0/1\">Effi Tramountani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1\">Gjergji Kasneci</a>",
          "description": "Due to the unspecified and dynamic nature of data streams, online machine\nlearning requires powerful and flexible solutions. However, evaluating online\nmachine learning methods under realistic conditions is difficult. Existing work\ntherefore often draws on different heuristics and simulations that do not\nnecessarily produce meaningful and reliable results. Indeed, in the absence of\ncommon evaluation standards, it often remains unclear how online learning\nmethods will perform in practice or in comparison to similar work. In this\npaper, we propose a comprehensive set of properties for high-quality machine\nlearning in evolving data streams. In particular, we discuss sensible\nperformance measures and evaluation strategies for online predictive modelling,\nonline feature selection and concept drift detection. As one of the first\nworks, we also look at the interpretability of online learning methods. The\nproposed evaluation standards are provided in a new Python framework called\nfloat. Float is completely modular and allows the simultaneous integration of\ncommon libraries, such as scikit-multiflow or river, with custom code. Float is\nopen-sourced and can be accessed at https://github.com/haugjo/float. In this\nsense, we hope that our work will contribute to more standardized, reliable and\nrealistic testing and comparison of online machine learning methods.",
          "link": "http://arxiv.org/abs/2204.13625",
          "publishedOn": "2022-04-30T01:01:31.984Z",
          "wordCount": 636,
          "title": "Standardized Evaluation of Machine Learning Methods for Evolving Data Streams. (arXiv:2204.13625v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.06236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pejo_B/0/1/0/all/0/1\">Bal&#xe1;zs Pej&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Totth_A/0/1/0/all/0/1\">Andr&#xe1;s T&#xf3;tth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biczok_G/0/1/0/all/0/1\">Gergely Bicz&#xf3;k</a>",
          "description": "Federated learning algorithms are developed both for efficiency reasons and\nto ensure the privacy and confidentiality of personal and business data,\nrespectively. Despite no data being shared explicitly, recent studies showed\nthat the mechanism could still leak sensitive information. Hence, secure\naggregation is utilized in many real-world scenarios to prevent attribution to\nspecific participants. In this paper, we focus on the quality of individual\ntraining datasets and show that such quality information could be inferred and\nattributed to specific participants even when secure aggregation is applied.\nSpecifically, through a series of image recognition experiments, we infer the\nrelative quality ordering of participants. Moreover, we apply the inferred\nquality information to detect misbehaviours, to stabilize training performance,\nand to measure the individual contributions of participants.",
          "link": "http://arxiv.org/abs/2007.06236",
          "publishedOn": "2022-04-30T01:01:31.966Z",
          "wordCount": 598,
          "title": "Quality Inference in Federated Learning with Secure Aggregation. (arXiv:2007.06236v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horvath_S/0/1/0/all/0/1\">Samuel Horv&#xe1;th</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1\">Maziar Sanjabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Lin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1\">Michael Rabbat</a>",
          "description": "The practice of applying several local updates before aggregation across\nclients has been empirically shown to be a successful approach to overcoming\nthe communication bottleneck in Federated Learning (FL). In this work, we\npropose a general recipe, FedShuffle, that better utilizes the local updates in\nFL, especially in the heterogeneous regime. Unlike many prior works, FedShuffle\ndoes not assume any uniformity in the number of updates per device. Our\nFedShuffle recipe comprises four simple-yet-powerful ingredients: 1) local\nshuffling of the data, 2) adjustment of the local learning rates, 3) update\nweighting, and 4) momentum variance reduction (Cutkosky and Orabona, 2019). We\npresent a comprehensive theoretical analysis of FedShuffle and show that both\ntheoretically and empirically, our approach does not suffer from the objective\nfunction mismatch that is present in FL methods which assume homogeneous\nupdates in heterogeneous FL setups, e.g., FedAvg (McMahan et al., 2017). In\naddition, by combining the ingredients above, FedShuffle improves upon FedNova\n(Wang et al., 2020), which was previously proposed to solve this mismatch. We\nalso show that FedShuffle with momentum variance reduction can improve upon\nnon-local methods under a Hessian similarity assumption. Finally, through\nexperiments on synthetic and real-world datasets, we illustrate how each of the\nfour ingredients used in FedShuffle helps improve the use of local updates in\nFL.",
          "link": "http://arxiv.org/abs/2204.13169",
          "publishedOn": "2022-04-30T01:01:31.956Z",
          "wordCount": 685,
          "title": "FedShuffle: Recipes for Better Use of Local Work in Federated Learning. (arXiv:2204.13169v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.03350",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Munkhdalai_L/0/1/0/all/0/1\">Lkhagvadorj Munkhdalai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Munkhdalai_T/0/1/0/all/0/1\">Tsendsuren Munkhdalai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ryu_K/0/1/0/all/0/1\">Keun Ho Ryu</a>",
          "description": "Machine learning models with both good predictability and high\ninterpretability are crucial for decision support systems. Linear regression is\none of the most interpretable prediction models. However, the linearity in a\nsimple linear regression worsens its predictability. In this work, we introduce\na locally adaptive interpretable regression (LoAIR). In LoAIR, a metamodel\nparameterized by neural networks predicts percentile of a Gaussian distribution\nfor the regression coefficients for a rapid adaptation. Our experimental\nresults on public benchmark datasets show that our model not only achieves\ncomparable or better predictive performance than the other state-of-the-art\nbaselines but also discovers some interesting relationships between input and\ntarget variables such as a parabolic relationship between CO2 emissions and\nGross National Product (GNP). Therefore, LoAIR is a step towards bridging the\ngap between econometrics, statistics, and machine learning by improving the\npredictive ability of linear regression without depreciating its\ninterpretability.",
          "link": "http://arxiv.org/abs/2005.03350",
          "publishedOn": "2022-04-30T01:01:31.950Z",
          "wordCount": 611,
          "title": "A Locally Adaptive Interpretable Regression. (arXiv:2005.03350v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beck_E/0/1/0/all/0/1\">Edgar Beck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bockelmann_C/0/1/0/all/0/1\">Carsten Bockelmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dekorsy_A/0/1/0/all/0/1\">Armin Dekorsy</a>",
          "description": "Motivated by recent success of machine learning tools at the PHY layer and\ndriven by high bandwidth demands of the next wireless communication standard\n6G, the old idea of semantic communication by Weaver from 1949 has received\nconsiderable attention. It breaks with the classic design paradigm according to\nShannon by aiming to transmit the meaning of a message rather than its exact\ncopy and thus potentially allows for savings in bandwidth.\n\nIn this work, inspired by Weaver, we propose an information-theoretic\nframework where the semantic context is explicitly introduced into\nprobabilistic models. In particular, for bandwidth efficient transmission, we\ndefine semantic communication system design as an Information Bottleneck\noptimization problem and consider important implementation aspects. Further, we\nuncover the restrictions of the classic 5G communication system design w.r.t.\nsemantic context. Notably, based on the example of distributed image\nclassification, we reveal the huge potential of a semantic communication system\ndesign. Numerical results show a tremendous saving in bandwidth of 20 dB with\nour proposed approach ISCNet compared to a classic PHY layer design.",
          "link": "http://arxiv.org/abs/2204.13366",
          "publishedOn": "2022-04-30T01:01:31.942Z",
          "wordCount": 625,
          "title": "Semantic Communication: An Information Bottleneck View. (arXiv:2204.13366v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13182",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hatipoglu_G/0/1/0/all/0/1\">G&#xfc;ray Hatipo&#x11f;lu</a>",
          "description": "Identification of the current and expected future pollution sources to rivers\nis crucial for sound environmental management. For this purpose numerous\napproaches were proposed that can be clustered under physical based models,\nstable isotope analysis and mixing methods, mass balance methods, time series\nanalysis, land cover analysis, and spatial statistics. Another extremely common\nmethod is Principal Component Analysis, as well as its modifications, such as\nAbsolute Principal Component Score. they have been applied to the source\nidentification problems for nitrogen entry to rivers. This manuscript is\nchecking whether PCA can really be a powerful method to uncover nitrogen\npollution sources considering its theoretical background and assumptions.\nMoreover, slightly similar techniques, Independent Component Analysis and\nFactor Analysis will also be considered.",
          "link": "http://arxiv.org/abs/2204.13182",
          "publishedOn": "2022-04-30T01:01:31.928Z",
          "wordCount": 568,
          "title": "On the Use of Dimension Reduction or Signal Separation Methods for Nitrogen River Pollution Source Identification. (arXiv:2204.13182v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13290",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gordon_Rodriguez_E/0/1/0/all/0/1\">Elliott Gordon-Rodriguez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Loaiza_Ganem_G/0/1/0/all/0/1\">Gabriel Loaiza-Ganem</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Potapczynski_A/0/1/0/all/0/1\">Andres Potapczynski</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cunningham_J/0/1/0/all/0/1\">John P. Cunningham</a>",
          "description": "Probability distributions supported on the simplex enjoy a wide range of\napplications across statistics and machine learning. Recently, a novel family\nof such distributions has been discovered: the continuous categorical. This\nfamily enjoys remarkable mathematical simplicity; its density function\nresembles that of the Dirichlet distribution, but with a normalizing constant\nthat can be written in closed form using elementary functions only. In spite of\nthis mathematical simplicity, our understanding of the normalizing constant\nremains far from complete. In this work, we characterize the numerical behavior\nof the normalizing constant and we present theoretical and methodological\nadvances that can, in turn, help to enable broader applications of the\ncontinuous categorical distribution. Our code is available at\nhttps://github.com/cunningham-lab/cb_and_cc/.",
          "link": "http://arxiv.org/abs/2204.13290",
          "publishedOn": "2022-04-30T01:01:31.905Z",
          "wordCount": 556,
          "title": "On the Normalizing Constant of the Continuous Categorical Distribution. (arXiv:2204.13290v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13231",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Goldman_D/0/1/0/all/0/1\">Dorian Goldman</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>",
          "description": "In this paper we extend the work of Owen (2007) by deriving a second order\nexpansion for the slope parameter in logistic regression, when the size of the\nmajority class is unbounded and the minority class is finite. More precisely,\nwe demonstrate that the second order term converges to a normal distribution\nand explicitly compute its variance, which surprisingly once again depends only\non the mean of the minority class points and not their arrangement under mild\nregularity assumptions. In the case that the majority class is normally\ndistributed, we illustrate that the variance of the the limiting slope depends\nexponentially on the z-score of the average of the minority class's points with\nrespect to the majority class's distribution. We confirm our results by Monte\nCarlo simulations.",
          "link": "http://arxiv.org/abs/2204.13231",
          "publishedOn": "2022-04-30T01:01:31.874Z",
          "wordCount": 558,
          "title": "Asymptotic Inference for Infinitely Imbalanced Logistic Regression. (arXiv:2204.13231v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.12399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nayman_N/0/1/0/all/0/1\">Niv Nayman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aflalo_Y/0/1/0/all/0/1\">Yonathan Aflalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1\">Asaf Noy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1\">Rong Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zelnik_Manor_L/0/1/0/all/0/1\">Lihi Zelnik-Manor</a>",
          "description": "Practical use of neural networks often involves requirements on latency,\nenergy and memory among others. A popular approach to find networks under such\nrequirements is through constrained Neural Architecture Search (NAS). However,\nprevious methods use complicated predictors for the accuracy of the network.\nThose predictors are hard to interpret and sensitive to many hyperparameters to\nbe tuned, hence, the resulting accuracy of the generated models is often\nharmed. In this work we resolve this by introducing Bilinear Interpretable\nNeural Architecture Search (BINAS), that is based on an accurate and simple\nbilinear formulation of both an accuracy estimator and the expected resource\nrequirement, together with a scalable search method with theoretical\nguarantees. The simplicity of our proposed estimator together with the\nintuitive way it is constructed bring interpretability through many insights\nabout the contribution of different design choices. For example, we find that\nin the examined search space, adding depth and width is more effective at\ndeeper stages of the network and at the beginning of each resolution stage. Our\nexperiments show that BINAS generates comparable to or better architectures\nthan other state-of-the-art NAS methods within a reduced marginal search cost,\nwhile strictly satisfying the resource constraints.",
          "link": "http://arxiv.org/abs/2110.12399",
          "publishedOn": "2022-04-28T01:16:10.089Z",
          "wordCount": 708,
          "title": "BINAS: Bilinear Interpretable Neural Architecture Search. (arXiv:2110.12399v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.00555",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Khouja_R/0/1/0/all/0/1\">Rima Khouja</a> (AROMATH), <a href=\"http://arxiv.org/find/math/1/au:+Mattei_P/0/1/0/all/0/1\">Pierre-Alexandre Mattei</a> (MAASAI), <a href=\"http://arxiv.org/find/math/1/au:+Mourrain_B/0/1/0/all/0/1\">Bernard Mourrain</a> (AROMATH)",
          "description": "In data processing and machine learning, an important challenge is to recover\nand exploit models that can represent accurately the data. We consider the\nproblem of recovering Gaussian mixture models from datasets. We investigate\nsymmetric tensor decomposition methods for tackling this problem, where the\ntensor is built from empirical moments of the data distribution. We consider\nidentifiable tensors, which have a unique decomposition, showing that moment\ntensors built from spherical Gaussian mixtures have this property. We prove\nthat symmetric tensors with interpolation degree strictly less than half their\norder are identifiable and we present an algorithm, based on simple linear\nalgebra operations, to compute their decomposition. Illustrative\nexperimentations show the impact of the tensor decomposition method for\nrecovering Gaussian mixtures, in comparison with other state-of-the-art\napproaches.",
          "link": "http://arxiv.org/abs/2106.00555",
          "publishedOn": "2022-04-28T01:16:10.083Z",
          "wordCount": 605,
          "title": "Tensor decomposition for learning Gaussian mixtures from moments. (arXiv:2106.00555v2 [math.AG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12526",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Hassan_S/0/1/0/all/0/1\">Syeda Sakira Hassan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mangayil_R/0/1/0/all/0/1\">Rahul Mangayil</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Aho_T/0/1/0/all/0/1\">Tommi Aho</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yli_Harja_O/0/1/0/all/0/1\">Olli Yli-Harja</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Karp_M/0/1/0/all/0/1\">Matti Karp</a>",
          "description": "In this paper, we utilize a machine learning approach to identify the\nsignificant pathways for c-di-GMP signaling proteins. The dataset involves gene\ncounts from 12 pathways and 5 essential c-di-GMP binding domains for 1024\nbacterial genomes. Two novel approaches, Least absolute shrinkage and selection\noperator (Lasso) and Random forests, have been applied for analyzing and\nmodeling the dataset. Both approaches show that bacterial chemotaxis is the\nmost essential pathway for c-di-GMP encoding domains. Though popular for\nfeature selection, the strong regularization of Lasso method fails to associate\nany pathway to MshE domain. Results from the analysis may help to understand\nand emphasize the supporting pathways involved in bacterial cellulose\nproduction. These findings demonstrate the need for a chassis to restrict the\nbehavior or functionality by deactivating the selective pathways in cellulose\nproduction.",
          "link": "http://arxiv.org/abs/2204.12526",
          "publishedOn": "2022-04-28T01:16:10.066Z",
          "wordCount": 600,
          "title": "Identification of feasible pathway information for c-di-GMP binding proteins in cellulose production. (arXiv:2204.12526v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01409",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rosato_C/0/1/0/all/0/1\">Conor Rosato</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beraud_V/0/1/0/all/0/1\">Vincent Beraud</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Horridge_P/0/1/0/all/0/1\">Paul Horridge</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1\">Thomas B. Sch&#xf6;n</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maskell_S/0/1/0/all/0/1\">Simon Maskell</a>",
          "description": "It has been widely documented that the sampling and resampling steps in\nparticle filters cannot be differentiated. The {\\itshape reparameterisation\ntrick} was introduced to allow the sampling step to be reformulated into a\ndifferentiable function. We extend the {\\itshape reparameterisation trick} to\ninclude the stochastic input to resampling therefore limiting the\ndiscontinuities in the gradient calculation after this step. Knowing the\ngradients of the prior and likelihood allows us to run particle Markov Chain\nMonte Carlo (p-MCMC) and use the No-U-Turn Sampler (NUTS) as the proposal when\nestimating parameters.\n\nWe compare the Metropolis-adjusted Langevin algorithm (MALA), Hamiltonian\nMonte Carlo with different number of steps and NUTS. We consider two\nstate-space models and show that NUTS improves the mixing of the Markov chain\nand can produce more accurate results in less computational time.",
          "link": "http://arxiv.org/abs/2111.01409",
          "publishedOn": "2022-04-28T01:16:10.061Z",
          "wordCount": 605,
          "title": "Efficient Learning of the Parameters of Non-Linear Models using Differentiable Resampling in Particle Filters. (arXiv:2111.01409v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12404",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bull_L/0/1/0/all/0/1\">L.A. Bull</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dhada_M/0/1/0/all/0/1\">M. Dhada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steinert_O/0/1/0/all/0/1\">O. Steinert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lindgren_T/0/1/0/all/0/1\">T. Lindgren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Parlikad_A/0/1/0/all/0/1\">A.K. Parlikad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duncan_A/0/1/0/all/0/1\">A.B. Duncan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">M. Girolami</a>",
          "description": "We propose a population-level analysis to address issues of data sparsity\nwhen building predictive models of engineering infrastructure. By sharing\ninformation between similar assets, hierarchical Bayesian modelling is used to\nimprove the survival analysis of a truck fleet (hazard curves) and power\nprediction in a wind farm (power curves). In each example, a set of correlated\nfunctions are learnt over the asset fleet, in a combined inference, to learn a\npopulation model. Parameter estimation is improved when sub-fleets of assets\nare allowed to share correlated information at different levels in the\nhierarchy. In turn, groups with incomplete data automatically borrow\nstatistical strength from those that are data-rich. The correlations can be\ninspected to inform which assets share information for which effect (i.e.\nparameter).",
          "link": "http://arxiv.org/abs/2204.12404",
          "publishedOn": "2022-04-28T01:16:10.055Z",
          "wordCount": 578,
          "title": "Knowledge Transfer in Engineering Fleets: Hierarchical Bayesian Modelling for Multi-Task Learning. (arXiv:2204.12404v1 [stat.ML] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.09457",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Tanner_J/0/1/0/all/0/1\">Jared Tanner</a>, <a href=\"http://arxiv.org/find/math/1/au:+Vary_S/0/1/0/all/0/1\">Simon Vary</a>",
          "description": "Expressing a matrix as the sum of a low-rank matrix plus a sparse matrix is a\nflexible model capturing global and local features in data popularized as\nRobust PCA (Candes et al., 2011; Chandrasekaran et al., 2009). Compressed\nsensing, matrix completion, and their variants (Eldar and Kutyniok, 2012;\nFoucart and Rauhut, 2013) have established that data satisfying low complexity\nmodels can be efficiently measured and recovered from a number of measurements\nproportional to the model complexity rather than the ambient dimension. This\nmanuscript develops similar guarantees showing that $m\\times n$ matrices that\ncan be expressed as the sum of a rank-$r$ matrix and a $s$-sparse matrix can be\nrecovered by computationally tractable methods from\n$\\mathcal{O}(r(m+n-r)+s)\\log(mn/s)$ linear measurements. More specifically, we\nestablish that the low-rank plus sparse matrix set is closed provided the\nincoherence of the low-rank component is upper bounded as\n$\\mu<\\sqrt{mn}/(r\\sqrt{s})$, and subsequently, the restricted isometry\nconstants for the aforementioned matrices remain bounded independent of problem\nsize provided $p/mn$, $s/p$, and $r(m+n-r)/p$ remain fixed. Additionally, we\nshow that semidefinite programming and two hard threshold gradient descent\nalgorithms, NIHT and NAHT, converge to the measured matrix provided the\nmeasurement operator's RIC's are sufficiently small. These results also\nprovably solve convex and non-convex formulation of Robust PCA with the\nasymptotically optimal fraction of corruptions $\\alpha=\\mathcal{O}\\left(1/(\\mu\nr) \\right)$, where $s = \\alpha^2 mn$, and improve the previously best known\nguarantees by not requiring that the fraction of corruptions is spread in every\ncolumn and row by being upper bounded by $\\alpha$. Numerical experiments\nillustrating these results are shown for synthetic problems,\ndynamic-foreground/static-background separation, and multispectral imaging.",
          "link": "http://arxiv.org/abs/2007.09457",
          "publishedOn": "2022-04-28T01:16:10.049Z",
          "wordCount": 729,
          "title": "Compressed sensing of low-rank plus sparse matrices. (arXiv:2007.09457v2 [math.NA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.02508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chung-Yi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kostina_V/0/1/0/all/0/1\">Victoria Kostina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassibi_B/0/1/0/all/0/1\">Babak Hassibi</a>",
          "description": "Consider the following distributed optimization scenario. A worker has access\nto training data that it uses to compute the gradients while a server decides\nwhen to stop iterative computation based on its target accuracy or delay\nconstraints. The server receives all its information about the problem instance\nfrom the worker via a rate-limited noiseless communication channel. We\nintroduce the principle we call Differential Quantization (DQ) that prescribes\ncompensating the past quantization errors to direct the descent trajectory of a\nquantized algorithm towards that of its unquantized counterpart. Assuming that\nthe objective function is smooth and strongly convex, we prove that\nDifferentially Quantized Gradient Descent (DQ-GD) attains a linear contraction\nfactor of $\\max\\{\\sigma_{\\mathrm{GD}}, \\rho_n 2^{-R}\\}$, where\n$\\sigma_{\\mathrm{GD}}$ is the contraction factor of unquantized gradient\ndescent (GD), $\\rho_n \\geq 1$ is the covering efficiency of the quantizer, and\n$R$ is the bitrate per problem dimension $n$. Thus at any $R\\geq\\log_2 \\rho_n\n/\\sigma_{\\mathrm{GD}}$ bits, the contraction factor of DQ-GD is the same as\nthat of unquantized GD, i.e., there is no loss due to quantization. We show\nthat no algorithm within a certain class can converge faster than\n$\\max\\{\\sigma_{\\mathrm{GD}}, 2^{-R}\\}$. Since quantizers exist with $\\rho_n \\to\n1$ as $n \\to \\infty$ (Rogers, 1963), this means that DQ-GD is asymptotically\noptimal. The principle of differential quantization continues to apply to\ngradient methods with momentum such as Nesterov's accelerated gradient descent,\nand Polyak's heavy ball method. For these algorithms as well, if the rate is\nabove a certain threshold, there is no loss in contraction factor obtained by\nthe differentially quantized algorithm compared to its unquantized counterpart.\nExperimental results on least-squares problems validate our theoretical\nanalysis.",
          "link": "http://arxiv.org/abs/2002.02508",
          "publishedOn": "2022-04-28T01:16:10.043Z",
          "wordCount": 759,
          "title": "Differentially Quantized Gradient Methods. (arXiv:2002.02508v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Liang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yibo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofei He</a>",
          "description": "Class imbalance distribution widely exists in real-world engineering.\nHowever, the mainstream optimization algorithms that seek to minimize error\nwill trap the deep learning model in sub-optimums when facing extreme class\nimbalance. It seriously harms the classification precision, especially on the\nminor classes. The essential reason is that the gradients of the classifier\nweights are imbalanced among the components from different classes. In this\npaper, we propose Attraction-Repulsion-Balanced Loss (ARB-Loss) to balance the\ndifferent components of the gradients. We perform experiments on the\nlarge-scale classification and segmentation datasets and our ARB-Loss can\nachieve state-of-the-art performance via only one-stage training instead of\n2-stage learning like nowadays SOTA works.",
          "link": "http://arxiv.org/abs/2204.08735",
          "publishedOn": "2022-04-28T01:16:10.017Z",
          "wordCount": 565,
          "title": "Neural Collapse Inspired Attraction-Repulsion-Balanced Loss for Imbalanced Learning. (arXiv:2204.08735v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trillos_N/0/1/0/all/0/1\">Nicolas Garcia Trillos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_M/0/1/0/all/0/1\">Matt Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jakwang Kim</a>",
          "description": "We study a family of adversarial multiclass classification problems and\nprovide equivalent reformulations in terms of: 1) a family of generalized\nbarycenter problems introduced in the paper and 2) a family of multimarginal\noptimal transport problems where the number of marginals is equal to the number\nof classes in the original classification problem. These new theoretical\nresults reveal a rich geometric structure of adversarial learning problems in\nmulticlass classification and extend recent results restricted to the binary\nclassification setting. A direct computational implication of our results is\nthat by solving either the barycenter problem and its dual, or the MOT problem\nand its dual, we can recover the optimal robust classification rule and the\noptimal adversarial strategy for the original adversarial problem. Examples\nwith synthetic and real data illustrate our results.",
          "link": "http://arxiv.org/abs/2204.12676",
          "publishedOn": "2022-04-28T01:16:09.862Z",
          "wordCount": null,
          "title": "The Multimarginal Optimal Transport Formulation of Adversarial Multiclass Classification. (arXiv:2204.12676v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12536",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Evangelou_N/0/1/0/all/0/1\">Nikolaos Evangelou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dietrich_F/0/1/0/all/0/1\">Felix Dietrich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chiavazzo_E/0/1/0/all/0/1\">Eliodoro Chiavazzo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lehmberg_D/0/1/0/all/0/1\">Daniel Lehmberg</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meila_M/0/1/0/all/0/1\">Marina Meila</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kevrekidis_I/0/1/0/all/0/1\">Ioannis G. Kevrekidis</a>",
          "description": "We introduce a data-driven approach to building reduced dynamical models\nthrough manifold learning; the reduced latent space is discovered using\nDiffusion Maps (a manifold learning technique) on time series data. A second\nround of Diffusion Maps on those latent coordinates allows the approximation of\nthe reduced dynamical models. This second round enables mapping the latent\nspace coordinates back to the full ambient space (what is called lifting); it\nalso enables the approximation of full state functions of interest in terms of\nthe reduced coordinates. In our work, we develop and test three different\nreduced numerical simulation methodologies, either through pre-tabulation in\nthe latent space and integration on the fly or by going back and forth between\nthe ambient space and the latent space. The data-driven latent space simulation\nresults, based on the three different approaches, are validated through (a) the\nlatent space observation of the full simulation through the Nystr\\\"om Extension\nformula, or through (b) lifting the reduced trajectory back to the full ambient\nspace, via Latent Harmonics. Latent space modeling often involves additional\nregularization to favor certain properties of the space over others, and the\nmapping back to the ambient space is then constructed mostly independently from\nthese properties; here, we use the same data-driven approach to construct the\nlatent space and then map back to the ambient space.",
          "link": "http://arxiv.org/abs/2204.12536",
          "publishedOn": "2022-04-28T01:16:09.796Z",
          "wordCount": null,
          "title": "Double Diffusion Maps and their Latent Harmonics for Scientific Computations in Latent Space. (arXiv:2204.12536v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1\">Zongqi Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaoming Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jialin Zhang</a>",
          "description": "We study the adversarial bandit problem with composite anonymous delayed\nfeedback. In this setting, losses of an action are split into $d$ components,\nspreading over consecutive rounds after the action is chosen. And in each\nround, the algorithm observes the aggregation of losses that come from the\nlatest $d$ rounds. Previous works focus on oblivious adversarial setting, while\nwe investigate the harder non-oblivious setting. We show non-oblivious setting\nincurs $\\Omega(T)$ pseudo regret even when the loss sequence is bounded memory.\nHowever, we propose a wrapper algorithm which enjoys $o(T)$ policy regret on\nmany adversarial bandit problems with the assumption that the loss sequence is\nbounded memory. Especially, for $K$-armed bandit and bandit convex\noptimization, we have $\\mathcal{O}(T^{2/3})$ policy regret bound. We also prove\na matching lower bound for $K$-armed bandit. Our lower bound works even when\nthe loss sequence is oblivious but the delay is non-oblivious. It answers the\nopen problem proposed in \\cite{wang2021adaptive}, showing that non-oblivious\ndelay is enough to incur $\\tilde{\\Omega}(T^{2/3})$ regret.",
          "link": "http://arxiv.org/abs/2204.12764",
          "publishedOn": "2022-04-28T01:16:09.765Z",
          "wordCount": null,
          "title": "Bounded Memory Adversarial Bandits with Composite Anonymous Delayed Feedback. (arXiv:2204.12764v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12868",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_A/0/1/0/all/0/1\">Alice J. Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hu_L/0/1/0/all/0/1\">Linwei Hu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1\">Jie Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nair_V/0/1/0/all/0/1\">Vijayan Nair</a>",
          "description": "This paper compares the performances of three supervised machine learning\nalgorithms in terms of predictive ability and model interpretation on\nstructured or tabular data. The algorithms considered were scikit-learn\nimplementations of extreme gradient boosting machines (XGB) and random forests\n(RFs), and feedforward neural networks (FFNNs) from TensorFlow. The paper is\norganized in a findings-based manner, with each section providing general\nconclusions supported by empirical results from simulation studies that cover a\nwide range of model complexity and correlation structures among predictors. We\nconsidered both continuous and binary responses of different sample sizes.\n\nOverall, XGB and FFNNs were competitive, with FFNNs showing better\nperformance in smooth models and tree-based boosting algorithms performing\nbetter in non-smooth models. This conclusion held generally for predictive\nperformance, identification of important variables, and determining correct\ninput-output relationships as measured by partial dependence plots (PDPs).\nFFNNs generally had less over-fitting, as measured by the difference in\nperformance between training and testing datasets. However, the difference with\nXGB was often small. RFs did not perform well in general, confirming the\nfindings in the literature. All models exhibited different degrees of bias seen\nin PDPs, but the bias was especially problematic for RFs. The extent of the\nbiases varied with correlation among predictors, response type, and data set\nsample size. In general, tree-based models tended to over-regularize the fitted\nmodel in the tails of predictor distributions. Finally, as to be expected,\nperformances were better for continuous responses compared to binary data and\nwith larger samples.",
          "link": "http://arxiv.org/abs/2204.12868",
          "publishedOn": "2022-04-28T01:16:09.757Z",
          "wordCount": null,
          "title": "Performance and Interpretability Comparisons of Supervised Machine Learning Algorithms: An Empirical Study. (arXiv:2204.12868v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumagai_A/0/1/0/all/0/1\">Atsutoshi Kumagai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chijiwa_D/0/1/0/all/0/1\">Daiki Chijiwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>",
          "description": "Transfer learning is crucial in training deep neural networks on new target\ntasks. Current transfer learning methods generally assume at least one of (i)\nsource and target task label spaces must overlap, (ii) source datasets are\navailable, and (iii) target network architectures are consistent with source\nones. However, these all assumptions are difficult to hold in practical\nsettings because the target task rarely has the same labels as the source task,\nthe source dataset access is restricted due to licensing and storage costs, and\nthe target architecture is often specialized to each task. To transfer source\nknowledge without these assumptions, we propose a transfer learning method that\nuses deep generative models and is composed of the following two stages: pseudo\npre-training (PP) and pseudo semi-supervised learning (P-SSL). PP trains a\ntarget architecture with a synthesized dataset by using conditional source\ngenerative models. P-SSL applies SSL algorithms to labeled target data and\nunlabeled pseudo samples, which are generated by cascading the source\nclassifier and generative models to condition them with target samples. Our\nexperimental results indicate that our method can outperform baselines of\nscratch training and knowledge distillation.",
          "link": "http://arxiv.org/abs/2204.12833",
          "publishedOn": "2022-04-28T01:16:09.756Z",
          "wordCount": null,
          "title": "Transfer Learning with Pre-trained Conditional Generative Models. (arXiv:2204.12833v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karmakar_S/0/1/0/all/0/1\">Sayar Karmakar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Anirbit Mukherjee</a>",
          "description": "A particular direction of recent advance about stochastic deep-learning\nalgorithms has been about uncovering a rather mysterious heavy-tailed nature of\nthe stationary distribution of these algorithms, even when the data\ndistribution is not so. Moreover, the heavy-tail index is known to show\ninteresting dependence on the input dimension of the net, the mini-batch size\nand the step size of the algorithm. In this short note, we undertake an\nexperimental study of this index for S.G.D. while training a $\\relu$ gate (in\nthe realizable and in the binary classification setup) and for a variant of\nS.G.D. that was proven in Karmakar and Mukherjee (2022) for ReLU realizable\ndata. From our experiments we conjecture that these two algorithms have similar\nheavy-tail behaviour on any data where the latter can be proven to converge.\nSecondly, we demonstrate that the heavy-tail index of the late time iterates in\nthis model scenario has strikingly different properties than either what has\nbeen proven for linear hypothesis classes or what has been previously\ndemonstrated for large nets.",
          "link": "http://arxiv.org/abs/2204.12554",
          "publishedOn": "2022-04-28T01:16:09.668Z",
          "wordCount": null,
          "title": "An Empirical Study of the Occurrence of Heavy-Tails in Training a ReLU Gate. (arXiv:2204.12554v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13089",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Das_N/0/1/0/all/0/1\">Niladri Das</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duersch_J/0/1/0/all/0/1\">Jed A. Duersch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Catanach_T/0/1/0/all/0/1\">Thomas A. Catanach</a>",
          "description": "In this paper, we address the problem of convergence of sequential\nvariational inference filter (VIF) through the application of a robust\nvariational objective and Hinf-norm based correction for a linear Gaussian\nsystem. As the dimension of state or parameter space grows, performing the full\nKalman update with the dense covariance matrix for a large scale system\nrequires increased storage and computational complexity, making it impractical.\nThe VIF approach, based on mean-field Gaussian variational inference, reduces\nthis burden through the variational approximation to the covariance usually in\nthe form of a diagonal covariance approximation. The challenge is to retain\nconvergence and correct for biases introduced by the sequential VIF steps. We\ndesire a framework that improves feasibility while still maintaining reasonable\nproximity to the optimal Kalman filter as data is assimilated. To accomplish\nthis goal, a Hinf-norm based optimization perturbs the VIF covariance matrix to\nimprove robustness. This yields a novel VIF- Hinf recursion that employs\nconsecutive variational inference and Hinf based optimization steps. We explore\nthe development of this method and investigate a numerical example to\nillustrate the effectiveness of the proposed filter.",
          "link": "http://arxiv.org/abs/2204.13089",
          "publishedOn": "2022-04-28T01:16:08.986Z",
          "wordCount": 627,
          "title": "Variational Kalman Filtering with Hinf-Based Correction for Robust Bayesian Learning in High Dimensions. (arXiv:2204.13089v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1903.03104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hotaling_A/0/1/0/all/0/1\">Abigail Hotaling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagrow_J/0/1/0/all/0/1\">James Bagrow</a>",
          "description": "Allocation strategies improve the efficiency of crowdsourcing by decreasing\nthe work needed to complete individual tasks accurately. However, these\nalgorithms introduce bias by preferentially allocating workers onto easy tasks,\nleading to sets of completed tasks that are no longer representative of all\ntasks. This bias challenges inference of problem-wide properties such as\ntypical task difficulty or crowd properties such as worker completion times,\nimportant information that goes beyond the crowd responses themselves. Here we\nstudy inference about problem properties when using an allocation algorithm to\nimprove crowd efficiency. We introduce Decision-Explicit Probability Sampling\n(DEPS), a novel method to perform inference of problem properties while\naccounting for the potential bias introduced by an allocation strategy.\nExperiments on real and synthetic crowdsourcing data show that DEPS outperforms\nbaseline inference methods while still leveraging the efficiency gains of the\nallocation method. The ability to perform accurate inference of general\nproperties when using non-representative data allows crowdsourcers to extract\nmore knowledge out of a given crowdsourced dataset.",
          "link": "http://arxiv.org/abs/1903.03104",
          "publishedOn": "2022-04-28T01:16:08.981Z",
          "wordCount": 661,
          "title": "Accurate inference of crowdsourcing properties when using efficient allocation strategies. (arXiv:1903.03104v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.13087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_C/0/1/0/all/0/1\">Chirag Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "We study the problem of making calibrated probabilistic forecasts for a\nbinary sequence generated by an adversarial nature. Following the seminal paper\nof Foster and Vohra (1998), nature is often modeled as an adaptive adversary\nwho sees all activity of the forecaster except the randomization that the\nforecaster may deploy. A number of papers have proposed randomized forecasting\nstrategies that achieve an $\\epsilon$-calibration error rate of\n$O(1/\\sqrt{T})$, which we prove is tight in general. On the other hand, it is\nwell known that it is not possible to be calibrated without randomization, or\nif nature also sees the forecaster's randomization; in both cases the\ncalibration error could be $\\Omega(1)$. Inspired by the equally seminal works\non the \"power of two choices\" and imprecise probability theory, we study a\nsmall variant of the standard online calibration problem. The adversary gives\nthe forecaster the option of making two nearby probabilistic forecasts, or\nequivalently an interval forecast of small width, and the endpoint closest to\nthe revealed outcome is used to judge calibration. This power of two choices,\nor imprecise forecast, accords the forecaster with significant power -- we show\nthat a faster $\\epsilon$-calibration rate of $O(1/T)$ can be achieved even\nwithout deploying any randomization.",
          "link": "http://arxiv.org/abs/2204.13087",
          "publishedOn": "2022-04-28T01:16:08.957Z",
          "wordCount": 656,
          "title": "Faster online calibration without randomization: interval forecasts and the power of two choices. (arXiv:2204.13087v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12965",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kuntz_J/0/1/0/all/0/1\">Juan Kuntz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Johansen_A/0/1/0/all/0/1\">Adam M. Johansen</a>",
          "description": "Building on (Neal and Hinton, 1998), where the problem tackled by EM is\nrecast as the optimization of a free energy functional on an\ninfinite-dimensional space, we obtain three practical particle-based\nalternatives to EM applicable to broad classes of models. All three are derived\nthrough straightforward discretizations of gradient flows associated with the\nfunctional. The novel algorithms scale well to high-dimensional settings and\noutperform existing state-of-the-art methods in numerical experiments.",
          "link": "http://arxiv.org/abs/2204.12965",
          "publishedOn": "2022-04-28T01:16:08.951Z",
          "wordCount": 499,
          "title": "Scalable particle-based alternatives to EM. (arXiv:2204.12965v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12169",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rikhye_R/0/1/0/all/0/1\">Rajeev Rikhye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1\">Quan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_Q/0/1/0/all/0/1\">Qiao Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yanzhang He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McGraw_I/0/1/0/all/0/1\">Ian McGraw</a>",
          "description": "VoiceFilter-Lite is a speaker-conditioned voice separation model that plays a\ncrucial role in improving speech recognition and speaker verification by\nsuppressing overlapping speech from non-target speakers. However, one\nlimitation of VoiceFilter-Lite, and other speaker-conditioned speech models in\ngeneral, is that these models are usually limited to a single target speaker.\nThis is undesirable as most smart home devices now support multiple enrolled\nusers. In order to extend the benefits of personalization to multiple users, we\npreviously developed an attention-based speaker selection mechanism and applied\nit to VoiceFilter-Lite. However, the original multi-user VoiceFilter-Lite model\nsuffers from significant performance degradation compared with single-user\nmodels. In this paper, we devised a series of experiments to improve the\nmulti-user VoiceFilter-Lite model. By incorporating a dual learning rate\nschedule and by using feature-wise linear modulation (FiLM) to condition the\nmodel with the attended speaker embedding, we successfully closed the\nperformance gap between multi-user and single-user VoiceFilter-Lite models on\nsingle-speaker evaluations. At the same time, the new model can also be easily\nextended to support any number of users, and significantly outperforms our\npreviously published model on multi-speaker evaluations.",
          "link": "http://arxiv.org/abs/2202.12169",
          "publishedOn": "2022-04-28T01:16:08.940Z",
          "wordCount": 651,
          "title": "Closing the Gap between Single-User and Multi-User VoiceFilter-Lite. (arXiv:2202.12169v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.02588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Wayne Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Da_D/0/1/0/all/0/1\">Daicong Da</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuge_M/0/1/0/all/0/1\">Mark Fuge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rai_R/0/1/0/all/0/1\">Rahul Rai</a>",
          "description": "Variable-density cellular structures can overcome connectivity and\nmanufacturability issues of topologically optimized structures, particularly\nthose represented as discrete density maps. However, the optimization of such\ncellular structures is challenging due to the multiscale design problem. Past\nwork addressing this problem generally either only optimizes the volume\nfraction of single-type unit cells but ignores the effects of unit cell\ngeometry on properties, or considers the geometry-property relation but builds\nthis relation via heuristics. In contrast, we propose a simple yet more\nprincipled way to accurately model the property to geometry mapping using a\nconditional deep generative model, named Inverse Homogenization Generative\nAdversarial Network (IH-GAN). It learns the conditional distribution of unit\ncell geometries given properties and can realize the one-to-many mapping from\nproperties to geometries. We further reduce the complexity of IH-GAN by using\nthe implicit function parameterization to represent unit cell geometries.\nResults show that our method can 1) generate various unit cells that satisfy\ngiven material properties with high accuracy ($R^2$-scores between target\nproperties and properties of generated unit cells $>98\\%$) and 2) improve the\noptimized structural performance over the conventional variable-density\nsingle-type structure. In the minimum compliance example, our IH-GAN generated\nstructure achieves a $79.7\\%$ reduction in concentrated stress and an extra\n$3.03\\%$ reduction in displacement. In the target deformation examples, our\nIH-GAN generated structure reduces the target matching error by $86.4\\%$ and\n$79.6\\%$ for two test cases, respectively. We also demonstrated that the\nconnectivity issue for multi-type unit cells can be solved by transition layer\nblending.",
          "link": "http://arxiv.org/abs/2103.02588",
          "publishedOn": "2022-04-28T01:16:08.912Z",
          "wordCount": 756,
          "title": "IH-GAN: A Conditional Generative Model for Implicit Surface-Based Inverse Design of Cellular Structures. (arXiv:2103.02588v4 [cs.CE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12914",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Li_L/0/1/0/all/0/1\">Linwei Li</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Matt_P/0/1/0/all/0/1\">Paul-Amaury Matt</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Heumann_C/0/1/0/all/0/1\">Christian Heumann</a>",
          "description": "The article is concerned with the problem of multi-step financial time series\nforecasting of Foreign Exchange (FX) rates. To address this problem, we\nintroduce a parameter-free regression network termed RegPred Net. The exchange\nrate to forecast is treated as a stochastic process. It is assumed to follow a\ngeneralization of Brownian motion and the mean-reverting process referred to as\nthe generalized Ornstein-Uhlenbeck (OU) process, with time-dependent\ncoefficients. Using past observed values of the input time series, these\ncoefficients can be regressed online by the cells of the first half of the\nnetwork (Reg). The regressed coefficients depend only on - but are very\nsensitive to - a small number of hyperparameters required to be set by a global\noptimization procedure for which, Bayesian optimization is an adequate\nheuristic. Thanks to its multi-layered architecture, the second half of the\nregression network (Pred) can project time-dependent values for the OU process\ncoefficients and generate realistic trajectories of the time series.\nPredictions can be easily derived in the form of expected values estimated by\naveraging values obtained by Monte Carlo simulation. The forecasting accuracy\non a 100 days horizon is evaluated for several of the most important FX rates\nsuch as EUR/USD, EUR/CNY, and EUR/GBP. Our experimental results show that the\nRegPred Net significantly outperforms ARMA, ARIMA, LSTMs, and Autoencoder-LSTM\nmodels in this task.",
          "link": "http://arxiv.org/abs/2204.12914",
          "publishedOn": "2022-04-28T01:16:08.769Z",
          "wordCount": 660,
          "title": "Forecasting Foreign Exchange Rates With Parameter-Free Regression Networks Tuned By Bayesian Optimization. (arXiv:2204.12914v1 [q-fin.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12939",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Berman_D/0/1/0/all/0/1\">David S. Berman</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Heckman_J/0/1/0/all/0/1\">Jonathan J. Heckman</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Klinger_M/0/1/0/all/0/1\">Marc Klinger</a>",
          "description": "Statistical Inference is the process of determining a probability\ndistribution over the space of parameters of a model given a data set. As more\ndata becomes available this probability distribution becomes updated via the\napplication of Bayes' theorem. We present a treatment of this Bayesian updating\nprocess as a continuous dynamical system. Statistical inference is then\ngoverned by a first order differential equation describing a trajectory or flow\nin the information geometry determined by a parametric family of models. We\nsolve this equation for some simple models and show that when the\nCram\\'{e}r-Rao bound is saturated the learning rate is governed by a simple\n$1/T$ power-law, with $T$ a time-like variable denoting the quantity of data.\nThe presence of hidden variables can be incorporated in this setting, leading\nto an additional driving term in the resulting flow equation. We illustrate\nthis with both analytic and numerical examples based on Gaussians and Gaussian\nRandom Processes and inference of the coupling constant in the 1D Ising model.\nFinally we compare the qualitative behaviour exhibited by Bayesian flows to the\ntraining of various neural networks on benchmarked data sets such as MNIST and\nCIFAR10 and show how that for networks exhibiting small final losses the simple\npower-law is also satisfied.",
          "link": "http://arxiv.org/abs/2204.12939",
          "publishedOn": "2022-04-28T01:16:08.763Z",
          "wordCount": 658,
          "title": "On the Dynamics of Inference and Learning. (arXiv:2204.12939v1 [cond-mat.dis-nn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.12993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Richens_J/0/1/0/all/0/1\">Jonathan G. Richens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beard_R/0/1/0/all/0/1\">Rory Beard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thompson_D/0/1/0/all/0/1\">Daniel H. Thompson</a>",
          "description": "To act safely and ethically in the real world, agents must be able to reason\nabout harm and avoid harmful actions. In this paper we develop the first\nstatistical definition of harm and a framework for factoring harm into\nalgorithmic decisions. We argue that harm is fundamentally a counterfactual\nquantity, and show that standard machine learning algorithms are guaranteed to\npursue harmful policies in certain environments. To resolve this, we derive a\nfamily of counterfactual objective functions that robustly mitigate for harm.\nWe demonstrate our approach with a statistical model for identifying optimal\ndrug doses. While identifying optimal doses using the causal treatment effect\nresults in harmful treatment decisions, our counterfactual algorithm identifies\ndoses that are far less harmful without sacrificing efficacy. Our results show\nthat counterfactual reasoning is a key ingredient for safe and ethical AI.",
          "link": "http://arxiv.org/abs/2204.12993",
          "publishedOn": "2022-04-28T01:16:08.731Z",
          "wordCount": 576,
          "title": "First do no harm: counterfactual objective functions for safe & ethical AI. (arXiv:2204.12993v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>",
          "description": "We study the theory of neural network (NN) from the lens of classical\nnonparametric regression problems with a focus on NN's ability to adaptively\nestimate functions with heterogeneous smoothness -- a property of functions in\nBesov or Bounded Variation (BV) classes. Existing work on this problem requires\ntuning the NN architecture based on the function spaces and sample sizes. We\nconsider a \"Parallel NN\" variant of deep ReLU networks and show that the\nstandard weight decay is equivalent to promoting the $\\ell_p$-sparsity\n($0<p<1$) of the coefficient vector of an end-to-end learned function bases,\ni.e., a dictionary. Using this equivalence, we further establish that by tuning\nonly the weight decay, such Parallel NN achieves an estimation error\narbitrarily close to the minimax rates for both the Besov and BV classes.\nNotably, it gets exponentially closer to minimax optimal as the NN gets deeper.\nOur research sheds new lights on why depth matters and how NNs are more\npowerful than kernel methods.",
          "link": "http://arxiv.org/abs/2204.09664",
          "publishedOn": "2022-04-23T00:53:50.168Z",
          "wordCount": 610,
          "title": "Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?. (arXiv:2204.09664v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bennett_M/0/1/0/all/0/1\">Michele Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balusu_J/0/1/0/all/0/1\">Jaya Balusu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayes_K/0/1/0/all/0/1\">Karin Hayes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleczyk_E/0/1/0/all/0/1\">Ewa J. Kleczyk</a>",
          "description": "The COVID-19 pandemic has dramatically changed how healthcare is delivered to\npatients, how patients interact with healthcare providers, and how healthcare\ninformation is disseminated to both healthcare providers and patients.\nAnalytical models that were trained and tested pre-pandemic may no longer be\nperforming up to expectations, providing unreliable and irrelevant learning\n(ML) models given that ML depends on the basic principle that what happened in\nthe past are likely to repeat in the future. ML faced to two important\ndegradation principles, concept drift, when the underlying properties and\ncharacteristics of the variables change and data drift, when the data\ndistributions, probabilities, co-variates, and other variable relationships\nchange, both of which are prime culprits of model failure. Therefore, detecting\nand diagnosing drift in existing models is something that has become an\nimperative. And perhaps even more important is a shift in our mindset towards a\nconscious recognition that drift is inevitable, and model building must\nincorporate intentional resilience, the ability to offset and recover quickly\nfrom failure, and proactive robustness, avoiding failure by developing models\nthat are less vulnerable to drift and disruption.",
          "link": "http://arxiv.org/abs/2204.10227",
          "publishedOn": "2022-04-23T00:53:50.137Z",
          "wordCount": 694,
          "title": "The Silent Problem -- Machine Learning Model Failure -- How to Diagnose and Fix Ailing Machine Learning Models. (arXiv:2204.10227v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.10754",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Dolera_E/0/1/0/all/0/1\">Emanuele Dolera</a>, <a href=\"http://arxiv.org/find/math/1/au:+Favaro_S/0/1/0/all/0/1\">Stefano Favaro</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mainini_E/0/1/0/all/0/1\">Edoardo Mainini</a>",
          "description": "In this paper, we develop a novel approach to posterior contractions rates\n(PCRs), for both finite-dimensional (parametric) and infinite-dimensional\n(nonparametric) Bayesian models. Critical to our approach is the combination of\nan assumption of local Lipschitz-continuity for the posterior distribution with\na dynamic formulation of the Wasserstein distance, here referred to as\nWasserstein dynamics, which allows to set forth a connection between the\nproblem of establishing PCRs and some classical problems in mathematical\nanalysis, probability theory and mathematical statistics: the Laplace method\nfor approximating integrals, Sanov's large deviation principles in the\nWasserstein distance, rates of convergence of the mean Glivenko-Cantelli\ntheorem, and estimates of weighted Poincar\\'e-Wirtinger constants. Under\ndominated Bayesian models, we present two main results: i) a theorem on PCRs\nfor the regular infinite-dimensional exponential family of statistical models;\nii) a theorem on PCRs for a general dominated statistical model. Some\napplications of our results are presented for the regular parametric model, the\nmultinomial model, the finite-dimensional and the infinite-dimensional\nlogistic-Gaussian model and the infinite-dimensional linear regression. In\ngeneral, our results lead to optimal PCRs in finite dimension, whereas in\ninfinite dimension it is shown how the prior distribution may affect PCRs. With\nregards to infinite-dimensional Bayesian models for density estimation, our\napproach to PCRs is the first to consider strong norm distances on parameter\nspaces of functions, such as Sobolev-like norms, as most of the approaches in\nthe classical (frequentist) and Bayesian literature deal with spaces of density\nfunctions endowed with $\\mathrm{L}^p$ norms or the Hellinger distance.",
          "link": "http://arxiv.org/abs/2203.10754",
          "publishedOn": "2022-04-23T00:53:50.120Z",
          "wordCount": 706,
          "title": "Strong posterior contraction rates via Wasserstein dynamics. (arXiv:2203.10754v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.07295",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saito_Y/0/1/0/all/0/1\">Yuta Saito</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nomura_M/0/1/0/all/0/1\">Masahiro Nomura</a>",
          "description": "We study offline recommender learning from explicit rating feedback in the\npresence of selection bias. A current promising solution for the bias is the\ninverse propensity score (IPS) estimation. However, the performance of existing\npropensity-based methods can suffer significantly from the propensity\nestimation bias. In fact, most of the previous IPS-based methods require some\namount of missing-completely-at-random (MCAR) data to accurately estimate the\npropensity. This leads to a critical self-contradiction; IPS is ineffective\nwithout MCAR data, even though it originally aims to learn recommenders from\nonly missing-not-at-random feedback. To resolve this propensity contradiction,\nwe derive a propensity-independent generalization error bound and propose a\nnovel algorithm to minimize the theoretical bound via adversarial learning. Our\ntheory and algorithm do not require a propensity estimation procedure, thereby\nleading to a well-performing rating predictor without the true propensity\ninformation. Extensive experiments demonstrate that the proposed approach is\nsuperior to a range of existing methods both in rating prediction and ranking\nmetrics in practical settings without MCAR data.",
          "link": "http://arxiv.org/abs/1910.07295",
          "publishedOn": "2022-04-23T00:53:50.104Z",
          "wordCount": 656,
          "title": "Towards Resolving Propensity Contradiction in Offline Recommender Learning. (arXiv:1910.07295v6 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09790",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Galaz_Garcia_F/0/1/0/all/0/1\">Fernando Galaz-Garcia</a>, <a href=\"http://arxiv.org/find/math/1/au:+Papamichalis_M/0/1/0/all/0/1\">Marios Papamichalis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Turnbull_K/0/1/0/all/0/1\">Kathryn Turnbull</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lunagomez_S/0/1/0/all/0/1\">Simon Lunagomez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Airoldi_E/0/1/0/all/0/1\">Edoardo Airoldi</a>",
          "description": "We provide a general framework for constructing probability distributions on\nRiemannian manifolds, taking advantage of area-preserving maps and isometries.\nControl over distributions' properties, such as parameters, symmetry and\nmodality yield a family of flexible distributions that are straightforward to\nsample from, suitable for use within Monte Carlo algorithms and latent variable\nmodels, such as autoencoders. As an illustration, we empirically validate our\napproach by utilizing our proposed distributions within a variational\nautoencoder and a latent space network model. Finally, we take advantage of the\ngeneralized description of this framework to posit questions for future work.",
          "link": "http://arxiv.org/abs/2204.09790",
          "publishedOn": "2022-04-23T00:53:50.095Z",
          "wordCount": 555,
          "title": "Wrapped Distributions on homogeneous Riemannian manifolds. (arXiv:2204.09790v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1\">Qi Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>",
          "description": "Despite the success of reinforcement learning (RL) for Markov decision\nprocesses (MDPs) with function approximation, most RL algorithms easily fail if\nthe agent only has partial observations of the state. Such a setting is often\nmodeled as a partially observable Markov decision process (POMDP). Existing\nsample-efficient algorithms for POMDPs are restricted to the tabular setting\nwhere the state and observation spaces are finite. In this paper, we make the\nfirst attempt at tackling the tension between function approximation and\npartial observability. In specific, we focus on a class of undercomplete POMDPs\nwith linear function approximations, which allows the state and observation\nspaces to be infinite. For such POMDPs, we show that the optimal policy and\nvalue function can be characterized by a sequence of finite-memory Bellman\noperators. We propose an RL algorithm that constructs optimistic estimators of\nthese operators via reproducing kernel Hilbert space (RKHS) embedding.\nMoreover, we theoretically prove that the proposed algorithm finds an\n$\\varepsilon$-optimal policy with $\\tilde O (1/\\varepsilon^2)$ episodes of\nexploration. Also, this sample complexity only depends on the intrinsic\ndimension of the POMDP polynomially and is independent of the size of the state\nand observation spaces. To our best knowledge, we develop the first provably\nsample-efficient algorithm for POMDPs with function approximation.",
          "link": "http://arxiv.org/abs/2204.09787",
          "publishedOn": "2022-04-23T00:53:49.554Z",
          "wordCount": null,
          "title": "Sample-Efficient Reinforcement Learning for POMDPs with Linear Function Approximations. (arXiv:2204.09787v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.00953",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Shen_Y/0/1/0/all/0/1\">Yinan Shen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1\">Jingyang Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Cai_J/0/1/0/all/0/1\">Jian-Feng Cai</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xia_D/0/1/0/all/0/1\">Dong Xia</a>",
          "description": "Low-rank matrix estimation under heavy-tailed noise is challenging, both\ncomputationally and statistically. Convex approaches have been proven\nstatistically optimal but suffer from high computational costs, especially\nsince robust loss functions are usually non-smooth. More recently,\ncomputationally fast non-convex approaches via sub-gradient descent are\nproposed, which, unfortunately, fail to deliver a statistically consistent\nestimator even under sub-Gaussian noise. In this paper, we introduce a novel\nRiemannian sub-gradient (RsGrad) algorithm which is not only computationally\nefficient with linear convergence but also is statistically optimal, be the\nnoise Gaussian or heavy-tailed. Convergence theory is established for a general\nframework and specific applications to absolute loss, Huber loss, and quantile\nloss are investigated. Compared with existing non-convex methods, ours reveals\na surprising phenomenon of dual-phase convergence. In phase one, RsGrad behaves\nas in a typical non-smooth optimization that requires gradually decaying\nstepsizes. However, phase one only delivers a statistically sub-optimal\nestimator which is already observed in the existing literature. Interestingly,\nduring phase two, RsGrad converges linearly as if minimizing a smooth and\nstrongly convex objective function and thus a constant stepsize suffices.\nUnderlying the phase-two convergence is the smoothing effect of random noise to\nthe non-smooth robust losses in an area close but not too close to the truth.\nLastly, RsGrad is applicable for low-rank tensor estimation under heavy-tailed\nnoise where a statistically optimal rate is attainable with the same phenomenon\nof dual-phase convergence, and a novel shrinkage-based second-order moment\nmethod is guaranteed to deliver a warm initialization. Numerical simulations\nconfirm our theoretical discovery and showcase the superiority of RsGrad over\nprior methods.",
          "link": "http://arxiv.org/abs/2203.00953",
          "publishedOn": "2022-04-23T00:53:49.542Z",
          "wordCount": null,
          "title": "Computationally Efficient and Statistically Optimal Robust Low-rank Matrix and Tensor Estimation. (arXiv:2203.00953v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sang Michael Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Pretrained language models have achieved state-of-the-art performance when\nadapted to a downstream NLP task. However, theoretical analysis of these models\nis scarce and challenging since the pretraining and downstream tasks can be\nvery different. We propose an analysis framework that links the pretraining and\ndownstream tasks with an underlying latent variable generative model of text --\nthe downstream classifier must recover a function of the posterior distribution\nover the latent variables. We analyze head tuning (learning a classifier on top\nof the frozen pretrained model) and prompt tuning in this setting. The\ngenerative model in our analysis is either a Hidden Markov Model (HMM) or an\nHMM augmented with a latent memory component, motivated by long-term\ndependencies in natural language. We show that 1) under certain non-degeneracy\nconditions on the HMM, simple classification heads can solve the downstream\ntask, 2) prompt tuning obtains downstream guarantees with weaker non-degeneracy\nconditions, and 3) our recovery guarantees for the memory-augmented HMM are\nstronger than for the vanilla HMM because task-relevant information is easier\nto recover from the long-term memory. Experiments on synthetically generated\ndata from HMMs back our theoretical findings.",
          "link": "http://arxiv.org/abs/2106.09226",
          "publishedOn": "2022-04-23T00:53:49.532Z",
          "wordCount": null,
          "title": "Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning. (arXiv:2106.09226v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.10510",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ovsianas_A/0/1/0/all/0/1\">Andrius Ovsianas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fernandes_D/0/1/0/all/0/1\">David Fernandes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">Mark Girolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lawrence_N/0/1/0/all/0/1\">Neil D. Lawrence</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nusken_N/0/1/0/all/0/1\">Nikolas N&#xfc;sken</a>",
          "description": "In this work we explore a new framework for approximate Bayesian inference in\nlarge datasets based on stochastic control (i.e. Schr\\\"odinger bridges). We\nadvocate stochastic control as a finite time and low variance alternative to\npopular steady-state methods such as stochastic gradient Langevin dynamics\n(SGLD). Furthermore, we discuss and adapt the existing theoretical guarantees\nof this framework and establish connections to already existing VI routines in\nSDE-based models.",
          "link": "http://arxiv.org/abs/2111.10510",
          "publishedOn": "2022-04-23T00:53:49.517Z",
          "wordCount": null,
          "title": "Bayesian Learning via Neural Schr\\\"odinger-F\\\"ollmer Flows. (arXiv:2111.10510v8 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lingxiao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Wei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1\">Leman Akoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>",
          "description": "Message Passing Neural Networks (MPNNs) are a common type of Graph Neural\nNetwork (GNN), in which each node's representation is computed recursively by\naggregating representations (messages) from its immediate neighbors akin to a\nstar-shaped pattern. MPNNs are appealing for being efficient and scalable,\nhow-ever their expressiveness is upper-bounded by the 1st-order\nWeisfeiler-Lehman isomorphism test (1-WL). In response, prior works propose\nhighly expressive models at the cost of scalability and sometimes\ngeneralization performance. Our work stands between these two regimes: we\nintroduce a general framework to uplift any MPNN to be more expressive, with\nlimited scalability overhead and greatly improved practical performance. We\nachieve this by extending local aggregation in MPNNs from star patterns to\ngeneral subgraph patterns (e.g.,k-egonets):in our framework, each node\nrepresentation is computed as the encoding of a surrounding induced subgraph\nrather than encoding of immediate neighbors only (i.e. a star). We choose the\nsubgraph encoder to be a GNN (mainly MPNNs, considering scalability) to design\na general framework that serves as a wrapper to up-lift any GNN. We call our\nproposed method GNN-AK(GNN As Kernel), as the framework resembles a\nconvolutional neural network by replacing the kernel with GNNs. Theoretically,\nwe show that our framework is strictly more powerful than 1&2-WL, and is not\nless powerful than 3-WL. We also design subgraph sampling strategies which\ngreatly reduce memory footprint and improve speed while maintaining\nperformance. Our method sets new state-of-the-art performance by large margins\nfor several well-known graph ML tasks; specifically, 0.08 MAE on ZINC,74.79%\nand 86.887% accuracy on CIFAR10 and PATTERN respectively.",
          "link": "http://arxiv.org/abs/2110.03753",
          "publishedOn": "2022-04-23T00:53:49.513Z",
          "wordCount": null,
          "title": "From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness. (arXiv:2110.03753v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1807.06919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Resnick_C/0/1/0/all/0/1\">Cinjon Resnick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1\">Roberta Raileanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1\">Sanyam Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peysakhovich_A/0/1/0/all/0/1\">Alexander Peysakhovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>",
          "description": "Model-free reinforcement learning (RL) requires a large number of trials to\nlearn a good policy, especially in environments with sparse rewards. We explore\na method to improve the sample efficiency when we have access to\ndemonstrations. Our approach, Backplay, uses a single demonstration to\nconstruct a curriculum for a given task. Rather than starting each training\nepisode in the environment's fixed initial state, we start the agent near the\nend of the demonstration and move the starting point backwards during the\ncourse of training until we reach the initial state. Our contributions are that\nwe analytically characterize the types of environments where Backplay can\nimprove training speed, demonstrate the effectiveness of Backplay both in large\ngrid worlds and a complex four player zero-sum game (Pommerman), and show that\nBackplay compares favorably to other competitive methods known to improve\nsample efficiency. This includes reward shaping, behavioral cloning, and\nreverse curriculum generation.",
          "link": "http://arxiv.org/abs/1807.06919",
          "publishedOn": "2022-04-23T00:53:49.511Z",
          "wordCount": null,
          "title": "Backplay: \"Man muss immer umkehren\". (arXiv:1807.06919v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.09139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pilault_J/0/1/0/all/0/1\">Jonathan Pilault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhattami_A/0/1/0/all/0/1\">Amine Elhattami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "Multi-Task Learning (MTL) networks have emerged as a promising method for\ntransferring learned knowledge across different tasks. However, MTL must deal\nwith challenges such as: overfitting to low resource tasks, catastrophic\nforgetting, and negative task transfer, or learning interference. Often, in\nNatural Language Processing (NLP), a separate model per task is needed to\nobtain the best performance. However, many fine-tuning approaches are both\nparameter inefficient, i.e., potentially involving one new model per task, and\nhighly susceptible to losing knowledge acquired during pretraining. We propose\na novel Transformer architecture consisting of a new conditional attention\nmechanism as well as a set of task-conditioned modules that facilitate weight\nsharing. Through this construction (a hypernetwork adapter), we achieve more\nefficient parameter sharing and mitigate forgetting by keeping half of the\nweights of a pretrained model fixed. We also use a new multi-task data sampling\nstrategy to mitigate the negative effects of data imbalance across tasks. Using\nthis approach, we are able to surpass single task fine-tuning methods while\nbeing parameter and data efficient (using around 66% of the data for weight\nupdates). Compared to other BERT Large methods on GLUE, our 8-task model\nsurpasses other Adapter methods by 2.8% and our 24-task model outperforms by\n0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger\nvariant of our single multi-task model approach performs competitively across\n26 NLP tasks and yields state-of-the-art results on a number of test and\ndevelopment sets. Our code is publicly available at\nhttps://github.com/CAMTL/CA-MTL.",
          "link": "http://arxiv.org/abs/2009.09139",
          "publishedOn": "2022-04-23T00:53:49.505Z",
          "wordCount": null,
          "title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data. (arXiv:2009.09139v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.03622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1\">Kendrick Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yining Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Self-training algorithms, which train a model to fit pseudolabels predicted\nby another previously-learned model, have been very successful for learning\nwith unlabeled data using neural networks. However, the current theoretical\nunderstanding of self-training only applies to linear models. This work\nprovides a unified theoretical analysis of self-training with deep networks for\nsemi-supervised learning, unsupervised domain adaptation, and unsupervised\nlearning. At the core of our analysis is a simple but realistic \"expansion\"\nassumption, which states that a low probability subset of the data must expand\nto a neighborhood with large probability relative to the subset. We also assume\nthat neighborhoods of examples in different classes have minimal overlap. We\nprove that under these assumptions, the minimizers of population objectives\nbased on self-training and input-consistency regularization will achieve high\naccuracy with respect to ground-truth labels. By using off-the-shelf\ngeneralization bounds, we immediately convert this result to sample complexity\nguarantees for neural nets that are polynomial in the margin and Lipschitzness.\nOur results help explain the empirical successes of recently proposed\nself-training algorithms which use input consistency regularization.",
          "link": "http://arxiv.org/abs/2010.03622",
          "publishedOn": "2022-04-23T00:53:49.492Z",
          "wordCount": null,
          "title": "Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. (arXiv:2010.03622v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10177",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Morel_R/0/1/0/all/0/1\">Rudy Morel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rochette_G/0/1/0/all/0/1\">Gaspar Rochette</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Leonarduzzi_R/0/1/0/all/0/1\">Roberto Leonarduzzi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bouchaud_J/0/1/0/all/0/1\">Jean-Philippe Bouchaud</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mallat_S/0/1/0/all/0/1\">St&#xe9;phane Mallat</a>",
          "description": "We introduce a scattering covariance matrix which provides non-Gaussian\nmodels of time-series having stationary increments. A complex wavelet transform\ncomputes signal variations at each scale. Dependencies across scales are\ncaptured by the joint covariance across time and scales of complex wavelet\ncoefficients and their modulus. This covariance is nearly diagonalized by a\nsecond wavelet transform, which defines the scattering covariance. We show that\nthis set of moments characterizes a wide range of non-Gaussian properties of\nmulti-scale processes. This is analyzed for a variety of processes, including\nfractional Brownian motions, Poisson, multifractal random walks and Hawkes\nprocesses. We prove that self-similar processes have a scattering covariance\nmatrix which is scale invariant. This property can be estimated numerically and\ndefines a class of wide-sense self-similar processes. We build maximum entropy\nmodels conditioned by scattering covariance coefficients, and generate new\ntime-series with a microcanonical sampling algorithm. Applications are shown\nfor highly non-Gaussian financial and turbulence time-series.",
          "link": "http://arxiv.org/abs/2204.10177",
          "publishedOn": "2022-04-23T00:53:49.487Z",
          "wordCount": null,
          "title": "Scale Dependencies and Self-Similarity Through Wavelet Scattering Covariance. (arXiv:2204.10177v1 [physics.data-an])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10031",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Deville_Y/0/1/0/all/0/1\">Yannick Deville</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Deville_A/0/1/0/all/0/1\">Alain Deville</a>",
          "description": "Two types of states are widely used in quantum mechanics, namely\n(deterministic-coefficient) pure states and statistical mixtures. A density\noperator can be associated with each of them. We here address a third type of\nstates, that we previously introduced in a more restricted framework. These\nstates generalize pure ones by replacing each of their deterministic ket\ncoefficients by a random variable. We therefore call them Random-Coefficient\nPure States, or RCPS. We analyze their properties and their relationships with\nboth types of usual states. We show that RCPS contain much richer information\nthan the density operator and mean of observables that we associate with them.\nThis occurs because the latter operator only exploits the second-order\nstatistics of the random state coefficients, whereas their higher-order\nstatistics contain additional information. That information can be accessed in\npractice with the multiple-preparation procedure that we propose for RCPS, by\nusing second-order and higher-order statistics of associated random\nprobabilities of measurement outcomes. Exploiting these higher-order statistics\nopens the way to a very general approach for performing advanced quantum\ninformation processing tasks. We illustrate the relevance of this approach with\na generic example, dealing with the estimation of parameters of a quantum\nprocess and thus related to quantum process tomography. This parameter\nestimation is performed in the non-blind (i.e. supervised) or blind (i.e.\nunsupervised) mode. We show that this problem cannot be solved by using only\nthe density operator \\rho of an RCPS and the associated mean value Tr(\\rho A)\nof the operator A that corresponds to the considered physical quantity. We\nsucceed in solving this problem by exploiting a fourth-order statistical\nparameter of state coefficients, in addition to second-order statistics.\nNumerical tests validate this result.",
          "link": "http://arxiv.org/abs/2204.10031",
          "publishedOn": "2022-04-23T00:53:49.467Z",
          "wordCount": null,
          "title": "Beyond the density operator and Tr(\\rho A): Exploiting the higher-order statistics of random-coefficient pure states for quantum information processing. (arXiv:2204.10031v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_A/0/1/0/all/0/1\">Anjul Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_P/0/1/0/all/0/1\">Pushkar Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Swasti Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_K/0/1/0/all/0/1\">Klaus Mueller</a>",
          "description": "Infographics are an aesthetic visual representation of information following\nspecific design principles of human perception. Designing infographics can be a\ntedious process for non-experts and time-consuming, even for professional\ndesigners. With the help of designers, we propose a semi-automated infographic\nframework for general structured and flow-based infographic design generation.\nFor novice designers, our framework automatically creates and ranks infographic\ndesigns for a user-provided text with no requirement for design input. However,\nexpert designers can still provide custom design inputs to customize the\ninfographics. We will also contribute an individual visual group (VG) designs\ndataset (in SVG), along with a 1k complete infographic image dataset with\nsegmented VGs in this work. Evaluation results confirm that by using our\nframework, designers from all expertise levels can generate generic infographic\ndesigns faster than existing methods while maintaining the same quality as\nhand-designed infographics templates.",
          "link": "http://arxiv.org/abs/2204.09904",
          "publishedOn": "2022-04-23T00:53:49.465Z",
          "wordCount": null,
          "title": "Infographics Wizard: Flexible Infographics Authoring and Design Exploration. (arXiv:2204.09904v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tibo_A/0/1/0/all/0/1\">Alessandro Tibo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_T/0/1/0/all/0/1\">Thomas Dyhre Nielsen</a>",
          "description": "Gaussian processes (GPs) are powerful but computationally expensive machine\nlearning models, requiring an estimate of the kernel covariance matrix for\nevery prediction. In large and complex domains, such as graphs, sets, or\nimages, the choice of suitable kernel can also be non-trivial to determine,\nproviding an additional obstacle to the learning task. Over the last decade,\nthese challenges have resulted in significant advances being made in terms of\nscalability and expressivity, exemplified by, e.g., the use of inducing points\nand neural network kernel approximations. In this paper, we propose inducing\nGaussian process networks (IGN), a simple framework for simultaneously learning\nthe feature space as well as the inducing points. The inducing points, in\nparticular, are learned directly in the feature space, enabling a seamless\nrepresentation of complex structured domains while also facilitating scalable\ngradient-based learning methods. We consider both regression and (binary)\nclassification tasks and report on experimental results for real-world data\nsets showing that IGNs provide significant advances over state-of-the-art\nmethods. We also demonstrate how IGNs can be used to effectively model complex\ndomains using neural network architectures.",
          "link": "http://arxiv.org/abs/2204.09889",
          "publishedOn": "2022-04-23T00:53:49.400Z",
          "wordCount": null,
          "title": "Inducing Gaussian Process Networks. (arXiv:2204.09889v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10140",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+He_Y/0/1/0/all/0/1\">Yang-Hui He</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lee_K/0/1/0/all/0/1\">Kyu-Hwan Lee</a>, <a href=\"http://arxiv.org/find/math/1/au:+Oliver_T/0/1/0/all/0/1\">Thomas Oliver</a>, <a href=\"http://arxiv.org/find/math/1/au:+Pozdnyakov_A/0/1/0/all/0/1\">Alexey Pozdnyakov</a>",
          "description": "We investigate the average value of the $p$th Dirichlet coefficients of\nelliptic curves for a prime p in a fixed conductor range with given rank.\nPlotting this average yields a striking oscillating pattern, the details of\nwhich vary with the rank. Based on this observation, we perform various\ndata-scientific experiments with the goal of classifying elliptic curves\naccording to their ranks.",
          "link": "http://arxiv.org/abs/2204.10140",
          "publishedOn": "2022-04-23T00:53:49.385Z",
          "wordCount": null,
          "title": "Murmurations of elliptic curves. (arXiv:2204.10140v1 [math.NT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Magron_P/0/1/0/all/0/1\">Paul Magron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fevotte_C/0/1/0/all/0/1\">C&#xe9;dric F&#xe9;votte</a>",
          "description": "This paper tackles the problem of decomposing binary data using matrix\nfactorization. We consider the family of mean-parametrized Bernoulli models, a\nclass of generative models that are well suited for modeling binary data and\nenables interpretability of the factors. We factorize the Bernoulli parameter\nand consider an additional Beta prior on one of the factors to further improve\nthe model's expressive power. While similar models have been proposed in the\nliterature, they only exploit the Beta prior as a proxy to ensure a valid\nBernoulli parameter in a Bayesian setting; in practice it reduces to a uniform\nor uninformative prior. Besides, estimation in these models has focused on\ncostly Bayesian inference. In this paper, we propose a simple yet very\nefficient majorization-minimization algorithm for maximum a posteriori\nestimation. Our approach leverages the Beta prior whose parameters can be tuned\nto improve performance in matrix completion tasks. Experiments conducted on\nthree public binary datasets show that our approach offers an excellent\ntrade-off between prediction performance, computational complexity, and\ninterpretability.",
          "link": "http://arxiv.org/abs/2204.09741",
          "publishedOn": "2022-04-23T00:53:49.349Z",
          "wordCount": null,
          "title": "A majorization-minimization algorithm for nonnegative binary matrix factorization. (arXiv:2204.09741v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.10461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clarke_R/0/1/0/all/0/1\">Ross M. Clarke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oldewage_E/0/1/0/all/0/1\">Elre T. Oldewage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1\">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>",
          "description": "Machine learning training methods depend plentifully and intricately on\nhyperparameters, motivating automated strategies for their optimisation. Many\nexisting algorithms restart training for each new hyperparameter choice, at\nconsiderable computational cost. Some hypergradient-based one-pass methods\nexist, but these either cannot be applied to arbitrary optimiser\nhyperparameters (such as learning rates and momenta) or take several times\nlonger to train than their base models. We extend these existing methods to\ndevelop an approximate hypergradient-based hyperparameter optimiser which is\napplicable to any continuous hyperparameter appearing in a differentiable model\nweight update, yet requires only one training episode, with no restarts. We\nalso provide a motivating argument for convergence to the true hypergradient,\nand perform tractable gradient-based optimisation of independent learning rates\nfor each model parameter. Our method performs competitively from varied random\nhyperparameter initialisations on several UCI datasets and Fashion-MNIST (using\na one-layer MLP), Penn Treebank (using an LSTM) and CIFAR-10 (using a\nResNet-18), in time only 2-3x greater than vanilla training.",
          "link": "http://arxiv.org/abs/2110.10461",
          "publishedOn": "2022-04-23T00:53:49.212Z",
          "wordCount": 655,
          "title": "Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation. (arXiv:2110.10461v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.06662",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_P/0/1/0/all/0/1\">Pengzhou Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fukumizu_K/0/1/0/all/0/1\">Kenji Fukumizu</a>",
          "description": "NOTE: This preprint has a flawed theoretical formulation. Please avoid it and\nrefer to the ICLR22 publication https://openreview.net/forum?id=q7n2RngwOM.\nAlso, arXiv:2109.15062 contains some new ideas on unobserved Confounding.\n\nAs an important problem of causal inference, we discuss the identification\nand estimation of treatment effects under unobserved confounding. Representing\nthe confounder as a latent variable, we propose Intact-VAE, a new variant of\nvariational autoencoder (VAE), motivated by the prognostic score that is\nsufficient for identifying treatment effects. We theoretically show that, under\ncertain settings, treatment effects are identified by our model, and further,\nbased on the identifiability of our model (i.e., determinacy of\nrepresentation), our VAE is a consistent estimator with representation balanced\nfor treatment groups. Experiments on (semi-)synthetic datasets show\nstate-of-the-art performance under diverse settings.",
          "link": "http://arxiv.org/abs/2101.06662",
          "publishedOn": "2022-04-23T00:53:49.152Z",
          "wordCount": 606,
          "title": "Intact-VAE: Estimating Treatment Effects under Unobserved Confounding. (arXiv:2101.06662v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10228",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sadjadi_S/0/1/0/all/0/1\">Seyed Omid Sadjadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greenberg_C/0/1/0/all/0/1\">Craig Greenberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singer_E/0/1/0/all/0/1\">Elliot Singer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mason_L/0/1/0/all/0/1\">Lisa Mason</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Reynolds_D/0/1/0/all/0/1\">Douglas Reynolds</a>",
          "description": "The US National Institute of Standards and Technology (NIST) has been\nconducting a second iteration of the CTS challenge since August 2020. The\ncurrent iteration of the CTS Challenge is a leaderboard-style speaker\nrecognition evaluation using telephony data extracted from the unexposed\nportions of the Call My Net 2 (CMN2) and Multi-Language Speech (MLS) corpora\ncollected by the LDC. The CTS Challenge is currently organized in a similar\nmanner to the SRE19 CTS Challenge, offering only an open training condition\nusing two evaluation subsets, namely Progress and Test. Unlike in the SRE19\nChallenge, no training or development set was initially released, and NIST has\npublicly released the leaderboards on both subsets for the CTS Challenge. Which\nsubset (i.e., Progress or Test) a trial belongs to is unknown to challenge\nparticipants, and each system submission needs to contain outputs for all of\nthe trials. The CTS Challenge has also served, and will continue to do so, as a\nprerequisite for entrance to the regular SREs (such as SRE21). Since August\n2020, a total of 53 organizations (forming 33 teams) from academia and industry\nhave participated in the CTS Challenge and submitted more than 4400 valid\nsystem outputs. This paper presents an overview of the evaluation and several\nanalyses of system performance for some primary conditions in the CTS\nChallenge. The CTS Challenge results thus far indicate remarkable improvements\nin performance due to 1) speaker embeddings extracted using large-scale and\ncomplex neural network architectures such as ResNets along with angular margin\nlosses for speaker embedding extraction, 2) extensive data augmentation, 3) the\nuse of large amounts of in-house proprietary data from a large number of\nlabeled speakers, 4) long-duration fine-tuning.",
          "link": "http://arxiv.org/abs/2204.10228",
          "publishedOn": "2022-04-23T00:53:49.144Z",
          "wordCount": 729,
          "title": "The NIST CTS Speaker Recognition Challenge. (arXiv:2204.10228v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jesson_A/0/1/0/all/0/1\">Andrew Jesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Douglas_A/0/1/0/all/0/1\">Alyson Douglas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manshausen_P/0/1/0/all/0/1\">Peter Manshausen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinshausen_N/0/1/0/all/0/1\">Nicolai Meinshausen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stier_P/0/1/0/all/0/1\">Philip Stier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalit_U/0/1/0/all/0/1\">Uri Shalit</a>",
          "description": "Estimating the effects of continuous-valued interventions from observational\ndata is critically important in fields such as climate science, healthcare, and\neconomics. Recent work focuses on designing neural-network architectures and\nregularization functions to allow for scalable estimation of average and\nindividual-level dose response curves from high-dimensional, large-sample data.\nSuch methodologies assume ignorability (all confounding variables are observed)\nand positivity (all levels of treatment can be observed for every unit\ndescribed by a given covariate value), which are especially challenged in the\ncontinuous treatment regime. Developing scalable sensitivity and uncertainty\nanalyses that allow us to understand the ignorance induced in our estimates\nwhen these assumptions are relaxed receives less attention. Here, we develop a\ncontinuous treatment-effect marginal sensitivity model (CMSM) and derive bounds\nthat agree with both the observed data and a researcher-defined level of hidden\nconfounding. We introduce a scalable algorithm to derive the bounds and\nuncertainty-aware deep models to efficiently estimate these bounds for\nhigh-dimensional, large-sample observational data. We validate our methods\nusing both synthetic and real-world experiments. For the latter, we work in\nconcert with climate scientists interested in evaluating the climatological\nimpacts of human emissions on cloud properties using satellite observations\nfrom the past 15 years: a finite-data problem known to be complicated by the\npresence of a multitude of unobserved confounders.",
          "link": "http://arxiv.org/abs/2204.10022",
          "publishedOn": "2022-04-23T00:53:49.105Z",
          "wordCount": 668,
          "title": "Scalable Sensitivity and Uncertainty Analysis for Causal-Effect Estimates of Continuous-Valued Interventions. (arXiv:2204.10022v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1905.09449",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanwei Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Donghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1\">Zuyuan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xinwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jinshan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>",
          "description": "The great success of deep neural networks is built upon their\nover-parameterization, which smooths the optimization landscape without\ndegrading the generalization ability. Despite the benefits of\nover-parameterization, a huge amount of parameters makes deep networks\ncumbersome in daily life applications. Though techniques such as pruning and\ndistillation are developed, they are expensive in fully training a dense\nnetwork as backward selection methods, and there is still a void on\nsystematically exploring forward selection methods for learning structural\nsparsity in deep networks. To fill in this gap, this paper proposes a new\napproach based on differential inclusions of inverse scale spaces, which\ngenerate a family of models from simple to complex ones along the dynamics via\ncoupling a pair of parameters, such that over-parameterized deep models and\ntheir structural sparsity can be explored simultaneously. This kind of\ndifferential inclusion scheme has a simple discretization, dubbed Deep\nstructure splitting Linearized Bregman Iteration (DessiLBI), whose global\nconvergence in learning deep networks could be established under the\nKurdyka-Lojasiewicz framework. Experimental evidence shows that our method\nachieves comparable and even better performance than the competitive optimizers\nin exploring the sparse structure of several widely used backbones on the\nbenchmark datasets. Remarkably, with early stopping, our method unveils\n`winning tickets' in early epochs: the effective sparse network structures with\ncomparable test accuracy to fully trained over-parameterized models, that are\nfurther transferable to similar alternative tasks. Furthermore, our method is\nable to grow networks efficiently with adaptive filter configurations,\ndemonstrating a good performance with much less computational cost. Codes and\nmodels can be downloaded at {https://github.com/DessiLBI2020/DessiLBI}.",
          "link": "http://arxiv.org/abs/1905.09449",
          "publishedOn": "2022-04-23T00:53:49.098Z",
          "wordCount": 811,
          "title": "Exploring Structural Sparsity of Deep Networks via Inverse Scale Spaces. (arXiv:1905.09449v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10268",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1\">Matthias C. Caro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1\">Hsin-Yuan Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ezzell_N/0/1/0/all/0/1\">Nicholas Ezzell</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gibbs_J/0/1/0/all/0/1\">Joe Gibbs</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sornborger_A/0/1/0/all/0/1\">Andrew T. Sornborger</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Holmes_Z/0/1/0/all/0/1\">Zo&#xeb; Holmes</a>",
          "description": "Generalization bounds are a critical tool to assess the training data\nrequirements of Quantum Machine Learning (QML). Recent work has established\nguarantees for in-distribution generalization of quantum neural networks\n(QNNs), where training and testing data are assumed to be drawn from the same\ndata distribution. However, there are currently no results on\nout-of-distribution generalization in QML, where we require a trained model to\nperform well even on data drawn from a distribution different from the training\ndistribution. In this work, we prove out-of-distribution generalization for the\ntask of learning an unknown unitary using a QNN and for a broad class of\ntraining and testing distributions. In particular, we show that one can learn\nthe action of a unitary on entangled states using only product state training\ndata. We numerically illustrate this by showing that the evolution of a\nHeisenberg spin chain can be learned using only product training states. Since\nproduct states can be prepared using only single-qubit gates, this advances the\nprospects of learning quantum dynamics using near term quantum computers and\nquantum experiments, and further opens up new methods for both the classical\nand quantum compilation of quantum circuits.",
          "link": "http://arxiv.org/abs/2204.10268",
          "publishedOn": "2022-04-23T00:53:49.091Z",
          "wordCount": 656,
          "title": "Out-of-distribution generalization for learning quantum dynamics. (arXiv:2204.10268v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1\">Sebastian Farquhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carey_R/0/1/0/all/0/1\">Ryan Carey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Everitt_T/0/1/0/all/0/1\">Tom Everitt</a>",
          "description": "We present a general framework for training safe agents whose naive\nincentives are unsafe. As an example, manipulative or deceptive behaviour can\nimprove rewards but should be avoided. Most approaches fail here: agents\nmaximize expected return by any means necessary. We formally describe settings\nwith 'delicate' parts of the state which should not be used as a means to an\nend. We then train agents to maximize the causal effect of actions on the\nexpected return which is not mediated by the delicate parts of state, using\nCausal Influence Diagram analysis. The resulting agents have no incentive to\ncontrol the delicate state. We further show how our framework unifies and\ngeneralizes existing proposals.",
          "link": "http://arxiv.org/abs/2204.10018",
          "publishedOn": "2022-04-23T00:53:49.042Z",
          "wordCount": 550,
          "title": "Path-Specific Objectives for Safer Agent Incentives. (arXiv:2204.10018v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09938",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Janssen_J/0/1/0/all/0/1\">Joseph Janssen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Guan_V/0/1/0/all/0/1\">Vincent Guan</a>",
          "description": "Scientists frequently prioritize learning from data rather than training the\nbest possible model; however, research in machine learning often prioritizes\nthe latter. The development of marginal feature importance methods, such as\nmarginal contribution feature importance, attempts to break this trend by\nproviding a useful framework for explaining relationships in data in an\ninterpretable fashion. In this work, we generalize the framework of marginal\ncontribution feature importance to improve performance with regards to\ndetecting correlated interactions and reducing runtime. To do so, we consider\n\"information subsets\" of the set of features $F$ and show that our importance\nmetric can be computed directly after applying fair representation learning\nmethods from the AI fairness literature. The methods of optimal transport and\nlinear regression are considered and explored experimentally for removing all\nthe information of our feature of interest $f$ from the feature set $F$. Given\nthese implementations, we show on real and simulated data that ultra marginal\nfeature importance performs at least as well as marginal contribution feature\nimportance, with substantially faster computation time and better performance\nin the presence of correlated interactions and unrelated features.",
          "link": "http://arxiv.org/abs/2204.09938",
          "publishedOn": "2022-04-23T00:53:49.007Z",
          "wordCount": 616,
          "title": "Ultra Marginal Feature Importance. (arXiv:2204.09938v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1\">Chirag Nagpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potosnak_W/0/1/0/all/0/1\">Willa Potosnak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1\">Artur Dubrawski</a>",
          "description": "Applications of machine learning in healthcare often require working with\ntime-to-event prediction tasks including prognostication of an adverse event,\nre-hospitalization or death. Such outcomes are typically subject to censoring\ndue to loss of follow up. Standard machine learning methods cannot be applied\nin a straightforward manner to datasets with censored outcomes. In this paper,\nwe present auton-survival, an open-source repository of tools to streamline\nworking with censored time-to-event or survival data. auton-survival includes\ntools for survival regression, adjustment in the presence of domain shift,\ncounterfactual estimation, phenotyping for risk stratification, evaluation, as\nwell as estimation of treatment effects. Through real world case studies\nemploying a large subset of the SEER oncology incidence data, we demonstrate\nthe ability of auton-survival to rapidly support data scientists in answering\ncomplex health and epidemiological questions.",
          "link": "http://arxiv.org/abs/2204.07276",
          "publishedOn": "2022-04-18T00:59:13.761Z",
          "wordCount": null,
          "title": "auton-survival: an Open-Source Package for Regression, Counterfactual Estimation, Evaluation and Phenotyping with Censored Time-to-Event Data. (arXiv:2204.07276v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07172",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Loaiza_Ganem_G/0/1/0/all/0/1\">Gabriel Loaiza-Ganem</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ross_B/0/1/0/all/0/1\">Brendan Leigh Ross</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cresswell_J/0/1/0/all/0/1\">Jesse C. Cresswell</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Caterini_A/0/1/0/all/0/1\">Anthony L. Caterini</a>",
          "description": "Likelihood-based, or explicit, deep generative models use neural networks to\nconstruct flexible high-dimensional densities. This formulation directly\ncontradicts the manifold hypothesis, which states that observed data lies on a\nlow-dimensional manifold embedded in high-dimensional ambient space. In this\npaper we investigate the pathologies of maximum-likelihood training in the\npresence of this dimensionality mismatch. We formally prove that degenerate\noptima are achieved wherein the manifold itself is learned but not the\ndistribution on it, a phenomenon we call manifold overfitting. We propose a\nclass of two-step procedures consisting of a dimensionality reduction step\nfollowed by maximum-likelihood density estimation, and prove that they recover\nthe data-generating distribution in the nonparametric regime, thus avoiding\nmanifold overfitting. We also show that these procedures enable density\nestimation on the manifolds learned by implicit models, such as generative\nadversarial networks, hence addressing a major shortcoming of these models.\nSeveral recently proposed methods are instances of our two-step procedures; we\nthus unify, extend, and theoretically justify a large class of models.",
          "link": "http://arxiv.org/abs/2204.07172",
          "publishedOn": "2022-04-18T00:59:13.754Z",
          "wordCount": null,
          "title": "Diagnosing and Fixing Manifold Overfitting in Deep Generative Models. (arXiv:2204.07172v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03310",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nystrom_K/0/1/0/all/0/1\">Kaj Nystr&#xf6;m</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vestberg_M/0/1/0/all/0/1\">Matias Vestberg</a>",
          "description": "The Monge-Amp\\`ere equation is a fully nonlinear partial differential\nequation (PDE) of fundamental importance in analysis, geometry and in the\napplied sciences. In this paper we solve the Dirichlet problem associated with\nthe Monge-Amp\\`ere equation using neural networks and we show that an ansatz\nusing deep input convex neural networks can be used to find the unique convex\nsolution. As part of our analysis we study the effect of singularities,\ndiscontinuities and noise in the source function, we consider nontrivial\ndomains, and we investigate how the method performs in higher dimensions. We\nalso compare this method to an alternative approach in which standard\nfeed-forward networks are used together with a loss function which penalizes\nlack of convexity.",
          "link": "http://arxiv.org/abs/2110.03310",
          "publishedOn": "2022-04-18T00:59:13.749Z",
          "wordCount": null,
          "title": "Solving the Dirichlet problem for the Monge-Amp\\`ere equation using neural networks. (arXiv:2110.03310v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.05624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nath_U/0/1/0/all/0/1\">Utkarsh Nath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kushagra_S/0/1/0/all/0/1\">Shrinu Kushagra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yingzhen Yang</a>",
          "description": "Compressing deep neural networks while maintaining accuracy is important when\nwe want to deploy large, powerful models in production and/or edge devices. One\ncommon technique used to achieve this goal is knowledge distillation.\nTypically, the output of a static pre-defined teacher (a large base network) is\nused as soft labels to train and transfer information to a student (or smaller)\nnetwork. In this paper, we introduce Adjoined Networks, or AN, a learning\nparadigm that trains both the original base network and the smaller compressed\nnetwork together. In our training approach, the parameters of the smaller\nnetwork are shared across both the base and the compressed networks. Using our\ntraining paradigm, we can simultaneously compress (the student network) and\nregularize (the teacher network) any architecture. In this paper, we focus on\npopular CNN-based architectures used for computer vision tasks. We conduct an\nextensive experimental evaluation of our training paradigm on various\nlarge-scale datasets. Using ResNet-50 as the base network, AN achieves 71.8%\ntop-1 accuracy with only 1.8M parameters and 1.6 GFLOPs on the ImageNet\ndata-set. We further propose Differentiable Adjoined Networks (DAN), a training\nparadigm that augments AN by using neural architecture search to jointly learn\nboth the width and the weights for each layer of the smaller network. DAN\nachieves ResNet-50 level accuracy on ImageNet with $3.8\\times$ fewer parameters\nand $2.2\\times$ fewer FLOPs.",
          "link": "http://arxiv.org/abs/2006.05624",
          "publishedOn": "2022-04-18T00:59:13.748Z",
          "wordCount": null,
          "title": "Adjoined Networks: A Training Paradigm with Applications to Network Compression. (arXiv:2006.05624v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.13579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ruo Yu Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francois_Lavet_V/0/1/0/all/0/1\">Vincent Fran&#xe7;ois-Lavet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>",
          "description": "We present a new approach for efficient exploration which leverages a\nlow-dimensional encoding of the environment learned with a combination of\nmodel-based and model-free objectives. Our approach uses intrinsic rewards that\nare based on the distance of nearest neighbors in the low dimensional\nrepresentational space to gauge novelty. We then leverage these intrinsic\nrewards for sample-efficient exploration with planning routines in\nrepresentational space for hard exploration tasks with sparse rewards. One key\nelement of our approach is the use of information theoretic principles to shape\nour representations in a way so that our novelty reward goes beyond pixel\nsimilarity. We test our approach on a number of maze tasks, as well as a\ncontrol problem and show that our exploration approach is more sample-efficient\ncompared to strong baselines.",
          "link": "http://arxiv.org/abs/2009.13579",
          "publishedOn": "2022-04-18T00:59:13.716Z",
          "wordCount": null,
          "title": "Novelty Search in Representational Space for Sample Efficient Exploration. (arXiv:2009.13579v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1\">Paras Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruocheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candan_K/0/1/0/all/0/1\">K. Sel&#xe7;uk Candan</a>",
          "description": "Recommender systems aim to recommend new items to users by learning user and\nitem representations. In practice, these representations are highly entangled\nas they consist of information about multiple factors, including user's\ninterests, item attributes along with confounding factors such as user\nconformity, and item popularity. Considering these entangled representations\nfor inferring user preference may lead to biased recommendations (e.g., when\nthe recommender model recommends popular items even if they do not align with\nthe user's interests).\n\nRecent research proposes to debias by modeling a recommender system from a\ncausal perspective. The exposure and the ratings are analogous to the treatment\nand the outcome in the causal inference framework, respectively. The critical\nchallenge in this setting is accounting for the hidden confounders. These\nconfounders are unobserved, making it hard to measure them. On the other hand,\nsince these confounders affect both the exposure and the ratings, it is\nessential to account for them in generating debiased recommendations. To better\napproximate hidden confounders, we propose to leverage network information\n(i.e., user-social and user-item networks), which are shown to influence how\nusers discover and interact with an item. Aside from the user conformity,\naspects of confounding such as item popularity present in the network\ninformation is also captured in our method with the aid of \\textit{causal\ndisentanglement} which unravels the learned representations into independent\nfactors that are responsible for (a) modeling the exposure of an item to the\nuser, (b) predicting the ratings, and (c) controlling the hidden confounders.\nExperiments on real-world datasets validate the effectiveness of the proposed\nmodel for debiasing recommender systems.",
          "link": "http://arxiv.org/abs/2204.07221",
          "publishedOn": "2022-04-18T00:59:13.643Z",
          "wordCount": null,
          "title": "Causal Disentanglement with Network Information for Debiased Recommendations. (arXiv:2204.07221v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07526",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Dudeja_R/0/1/0/all/0/1\">Rishabh Dudeja</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hsu_D/0/1/0/all/0/1\">Daniel Hsu</a>",
          "description": "Tensor PCA is a stylized statistical inference problem introduced by\nMontanari and Richard to study the computational difficulty of estimating an\nunknown parameter from higher-order moment tensors. Unlike its matrix\ncounterpart, Tensor PCA exhibits a statistical-computational gap, i.e., a\nsample size regime where the problem is information-theoretically solvable but\nconjectured to be computationally hard. This paper derives computational lower\nbounds on the run-time of memory bounded algorithms for Tensor PCA using\ncommunication complexity. These lower bounds specify a trade-off among the\nnumber of passes through the data sample, the sample size, and the memory\nrequired by any algorithm that successfully solves Tensor PCA. While the lower\nbounds do not rule out polynomial-time algorithms, they do imply that many\ncommonly-used algorithms, such as gradient descent and power method, must have\na higher iteration count when the sample size is not large enough. Similar\nlower bounds are obtained for Non-Gaussian Component Analysis, a family of\nstatistical estimation problems in which low-order moment tensors carry no\ninformation about the unknown parameter. Finally, stronger lower bounds are\nobtained for an asymmetric variant of Tensor PCA and related statistical\nestimation problems. These results explain why many estimators for these\nproblems use a memory state that is significantly larger than the effective\ndimensionality of the parameter of interest.",
          "link": "http://arxiv.org/abs/2204.07526",
          "publishedOn": "2022-04-18T00:59:13.634Z",
          "wordCount": null,
          "title": "Statistical-Computational Trade-offs in Tensor PCA and Related Problems via Communication Complexity. (arXiv:2204.07526v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.05527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dongjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seungjae Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kyungwoo Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wanmo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_I/0/1/0/all/0/1\">Il-Chul Moon</a>",
          "description": "Recent advances in diffusion models bring the state-of-the art performance on\nimage generation tasks. However, empirical results on previous research in\ndiffusion models imply that there is an inverse correlation on performances for\ndensity estimation and sample generation. This paper analyzes that the inverse\ncorrelation arises because density estimation is mostly contributed from small\ndiffusion time, whereas sample generation mainly depends on large diffusion\ntime. However, training score network on both small and large diffusion time is\ndemanding because of the loss imbalance issue. To successfully train the score\nnetwork on both small and large diffusion time, this paper introduces a\ntraining technique, Soft Truncation, that softens the truncation time for every\nmini-batch update, which is universally applicable to any types of diffusion\nmodels. It turns out that Soft Truncation is equivalent to a diffusion model\nwith a general weight, and we prove the variational bound of the general\nweighted diffusion model. In view of this variational bound, Soft Truncation\nbecomes a natural way to train the score network. In experiments, Soft\nTruncation achieves the state-of-the-art performance on CIFAR-10, CelebA,\nCelebA-HQ $256\\times 256$, and STL-10 datasets.",
          "link": "http://arxiv.org/abs/2106.05527",
          "publishedOn": "2022-04-18T00:59:12.624Z",
          "wordCount": 695,
          "title": "Soft Truncation: A Universal Training Technique of Score-based Diffusion Model for High Precision Score Estimation. (arXiv:2106.05527v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.08966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sigrist_F/0/1/0/all/0/1\">Fabio Sigrist</a>",
          "description": "Latent Gaussian models and boosting are widely used techniques in statistics\nand machine learning. Tree-boosting shows excellent prediction accuracy on many\ndata sets, but potential drawbacks are that it assumes conditional independence\nof samples, produces discontinuous predictions for, e.g., spatial data, and it\ncan have difficulty with high-cardinality categorical variables. Latent\nGaussian models, such as Gaussian process and grouped random effects models,\nare flexible prior models which explicitly model dependence among samples and\nwhich allow for efficient learning of predictor functions and for making\nprobabilistic predictions. However, existing latent Gaussian models usually\nassume either a zero or a linear prior mean function which can be an\nunrealistic assumption. This article introduces a novel approach that combines\nboosting and latent Gaussian models to remedy the above-mentioned drawbacks and\nto leverage the advantages of both techniques. We obtain increased prediction\naccuracy compared to existing approaches in both simulated and real-world data\nexperiments.",
          "link": "http://arxiv.org/abs/2105.08966",
          "publishedOn": "2022-04-18T00:59:12.591Z",
          "wordCount": 628,
          "title": "Latent Gaussian Model Boosting. (arXiv:2105.08966v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.10545",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vaiciukynas_E/0/1/0/all/0/1\">Evaldas Vaiciukynas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Danenas_P/0/1/0/all/0/1\">Paulius Danenas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kontrimas_V/0/1/0/all/0/1\">Vilius Kontrimas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Butleris_R/0/1/0/all/0/1\">Rimantas Butleris</a>",
          "description": "Amounts of historical data collected increase and business intelligence\napplicability with automatic forecasting of time series are in high demand.\nWhile no single time series modeling method is universal to all types of\ndynamics, forecasting using an ensemble of several methods is often seen as a\ncompromise. Instead of fixing ensemble diversity and size, we propose to\npredict these aspects adaptively using meta-learning. Meta-learning here\nconsiders two separate random forest regression models, built on 390\ntime-series features, to rank 22 univariate forecasting methods and recommend\nensemble size. The forecasting ensemble is consequently formed from methods\nranked as the best, and forecasts are pooled using either simple or weighted\naverage (with a weight corresponding to reciprocal rank). The proposed approach\nwas tested on 12561 micro-economic time-series (expanded to 38633 for various\nforecasting horizons) of M4 competition where meta-learning outperformed Theta\nand Comb benchmarks by relative forecasting errors for all data types and\nhorizons. Best overall results were achieved by weighted pooling with a\nsymmetric mean absolute percentage error of 9.21% versus 11.05% obtained using\nthe Theta method.",
          "link": "http://arxiv.org/abs/2011.10545",
          "publishedOn": "2022-04-18T00:59:12.570Z",
          "wordCount": 669,
          "title": "Two-Step Meta-Learning for Time-Series Forecasting Ensemble. (arXiv:2011.10545v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1911.12426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sandler_A/0/1/0/all/0/1\">Adam Sandler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1\">Diego Klabjan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yuan Luo</a>",
          "description": "We develop methods for reducing the dimensionality of large data sets, common\nin biomedical applications. Learning about patients using genetic data often\nincludes more features than observations, which makes direct supervised\nlearning difficult. One method of reducing the feature space is to use latent\nDirichlet allocation to group genetic variants in an unsupervised manner.\nLatent Dirichlet allocation describes a patient as a mixture of topics\ncorresponding to genetic variants. This can be generalized as a Bayesian tensor\ndecomposition to account for multiple feature variables. Our most significant\ncontributions are with hierarchical topic modeling. We design distinct methods\nof incorporating hierarchical topic modeling, based on nested Chinese\nrestaurant processes and Pachinko Allocation Machine, into Bayesian tensor\ndecomposition. We apply these models to examine patients with one of four\ncommon types of cancer (breast, lung, prostate, and colorectal) and siblings\nwith and without autism spectrum disorder. We linked the genes with their\nbiological pathways and combine this information into a tensor of patients,\ncounts of their genetic variants, and the genes' membership in pathways. We\nfind that our trained models outperform baseline models, with respect to\ncoherence, by up to 40%.",
          "link": "http://arxiv.org/abs/1911.12426",
          "publishedOn": "2022-04-18T00:59:12.561Z",
          "wordCount": 669,
          "title": "Conditional Hierarchical Bayesian Tucker Decomposition for Genetic Data Analysis. (arXiv:1911.12426v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.00036",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lakshminarayanan_B/0/1/0/all/0/1\">Braghadeesh Lakshminarayanan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rojas_C/0/1/0/all/0/1\">Cristian R. Rojas</a>",
          "description": "One of the most important problems in system identification and statistics is\nhow to estimate the unknown parameters of a given model. Optimization methods\nand specialized procedures, such as Empirical Minimization (EM) can be used in\ncase the likelihood function can be computed. For situations where one can only\nsimulate from a parametric model, but the likelihood is difficult or impossible\nto evaluate, a technique known as the Two-Stage (TS) Approach can be applied to\nobtain reliable parametric estimates. Unfortunately, there is currently a lack\nof theoretical justification for TS. In this paper, we propose a statistical\ndecision-theoretical derivation of TS, which leads to Bayesian and Minimax\nestimators. We also show how to apply the TS approach on models for independent\nand identically distributed samples, by computing quantiles of the data as a\nfirst step, and using a linear function as the second stage. The proposed\nmethod is illustrated via numerical simulations.",
          "link": "http://arxiv.org/abs/2204.00036",
          "publishedOn": "2022-04-18T00:59:12.537Z",
          "wordCount": 621,
          "title": "A Statistical Decision-Theoretical Perspective on the Two-Stage Approach to Parameter Estimation. (arXiv:2204.00036v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1607.01624",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Naik_C/0/1/0/all/0/1\">Cian Naik</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Caron_F/0/1/0/all/0/1\">Francois Caron</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rousseau_J/0/1/0/all/0/1\">Judith Rousseau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Palla_K/0/1/0/all/0/1\">Konstantina Palla</a>",
          "description": "In this paper we propose a Bayesian nonparametric approach to modelling\nsparse time-varying networks. A positive parameter is associated to each node\nof a network, which models the sociability of that node. Sociabilities are\nassumed to evolve over time, and are modelled via a dynamic point process\nmodel. The model is able to capture long term evolution of the sociabilities.\nMoreover, it yields sparse graphs, where the number of edges grows\nsubquadratically with the number of nodes. The evolution of the sociabilities\nis described by a tractable time-varying generalised gamma process. We provide\nsome theoretical insights into the model and apply it to three datasets: a\nsimulated network, a network of hyperlinks between communities on Reddit, and a\nnetwork of co-occurences of words in Reuters news articles after the September\n11th attacks.",
          "link": "http://arxiv.org/abs/1607.01624",
          "publishedOn": "2022-04-18T00:59:12.529Z",
          "wordCount": 585,
          "title": "Bayesian Nonparametrics for Sparse Dynamic Networks. (arXiv:1607.01624v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.08604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Galvez_B/0/1/0/all/0/1\">Borja Rodr&#xed;guez-G&#xe1;lvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granqvist_F/0/1/0/all/0/1\">Filip Granqvist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalen_R/0/1/0/all/0/1\">Rogier van Dalen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seigel_M/0/1/0/all/0/1\">Matt Seigel</a>",
          "description": "Federated learning with differential privacy, or private federated learning,\nprovides a strategy to train machine learning models while respecting users'\nprivacy. However, differential privacy can disproportionately degrade the\nperformance of the models on under-represented groups, as these parts of the\ndistribution are difficult to learn in the presence of noise. Existing\napproaches for enforcing fairness in machine learning models have considered\nthe centralized setting, in which the algorithm has access to the users' data.\nThis paper introduces an algorithm to enforce group fairness in private\nfederated learning, where users' data does not leave their devices. First, the\npaper extends the modified method of differential multipliers to empirical risk\nminimization with fairness constraints, thus providing an algorithm to enforce\nfairness in the central setting. Then, this algorithm is extended to the\nprivate federated learning setting. The proposed algorithm, \\texttt{FPFL}, is\ntested on a federated version of the Adult dataset and an \"unfair\" version of\nthe FEMNIST dataset. The experiments on these datasets show how private\nfederated learning accentuates unfairness in the trained models, and how FPFL\nis able to mitigate such unfairness.",
          "link": "http://arxiv.org/abs/2109.08604",
          "publishedOn": "2022-04-18T00:59:12.521Z",
          "wordCount": 677,
          "title": "Enforcing fairness in private federated learning via the modified method of differential multipliers. (arXiv:2109.08604v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07293",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Deng_W/0/1/0/all/0/1\">Wenying Deng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Coker_B/0/1/0/all/0/1\">Beau Coker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jeremiah Zhe Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Coull_B/0/1/0/all/0/1\">Brent A. Coull</a>",
          "description": "We develop a simple and unified framework for nonlinear variable selection\nthat incorporates model uncertainty and is compatible with a wide range of\nmachine learning models (e.g., tree ensembles, kernel methods and neural\nnetwork). In particular, for a learned nonlinear model $f(\\mathbf{x})$, we\nconsider quantifying the importance of an input variable $\\mathbf{x}^j$ using\nthe integrated gradient measure $\\psi_j = \\Vert \\frac{\\partial}{\\partial\n\\mathbf{x}^j} f(\\mathbf{x})\\Vert^2_2$. We then (1) provide a principled\napproach for quantifying variable selection uncertainty by deriving its\nposterior distribution, and (2) show that the approach is generalizable even to\nnon-differentiable models such as tree ensembles. Rigorous Bayesian\nnonparametric theorems are derived to guarantee the posterior consistency and\nasymptotic uncertainty of the proposed approach. Extensive simulation confirms\nthat the proposed algorithm outperforms existing classic and recent variable\nselection methods.",
          "link": "http://arxiv.org/abs/2204.07293",
          "publishedOn": "2022-04-18T00:59:12.513Z",
          "wordCount": 580,
          "title": "Towards a Unified Framework for Uncertainty-aware Nonlinear Variable Selection with Theoretical Guarantees. (arXiv:2204.07293v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1909.04746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khaled_A/0/1/0/all/0/1\">Ahmed Khaled</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>",
          "description": "We provide a new analysis of local SGD, removing unnecessary assumptions and\nelaborating on the difference between two data regimes: identical and\nheterogeneous. In both cases, we improve the existing theory and provide values\nof the optimal stepsize and optimal number of local iterations. Our bounds are\nbased on a new notion of variance that is specific to local SGD methods with\ndifferent data. The tightness of our results is guaranteed by recovering known\nstatements when we plug $H=1$, where $H$ is the number of local steps. The\nempirical evidence further validates the severe impact of data heterogeneity on\nthe performance of local SGD.",
          "link": "http://arxiv.org/abs/1909.04746",
          "publishedOn": "2022-04-18T00:59:12.496Z",
          "wordCount": 618,
          "title": "Tighter Theory for Local SGD on Identical and Heterogeneous Data. (arXiv:1909.04746v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Melnychuk_V/0/1/0/all/0/1\">Valentyn Melnychuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frauen_D/0/1/0/all/0/1\">Dennis Frauen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>",
          "description": "Estimating counterfactual outcomes over time from observational data is\nrelevant for many applications (e.g., personalized medicine). Yet,\nstate-of-the-art methods build upon simple long short-term memory (LSTM)\nnetworks, thus rendering inferences for complex, long-range dependencies\nchallenging. In this paper, we develop a novel Causal Transformer for\nestimating counterfactual outcomes over time. Our model is specifically\ndesigned to capture complex, long-range dependencies among time-varying\nconfounders. For this, we combine three transformer subnetworks with separate\ninputs for time-varying covariates, previous treatments, and previous outcomes\ninto a joint network with in-between cross-attentions. We further develop a\ncustom, end-to-end training procedure for our Causal Transformer. Specifically,\nwe propose a novel counterfactual domain confusion loss to address confounding\nbias: it aims to learn adversarial balanced representations, so that they are\npredictive of the next outcome but non-predictive of the current treatment\nassignment. We evaluate our Causal Transformer based on synthetic and\nreal-world datasets, where it achieves superior performance over current\nbaselines. To the best of our knowledge, this is the first work proposing\ntransformer-based architecture for estimating counterfactual outcomes from\nlongitudinal data.",
          "link": "http://arxiv.org/abs/2204.07258",
          "publishedOn": "2022-04-18T00:59:12.488Z",
          "wordCount": 608,
          "title": "Causal Transformer for Estimating Counterfactual Outcomes. (arXiv:2204.07258v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.14790",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+King_B/0/1/0/all/0/1\">Brian King</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kowal_D/0/1/0/all/0/1\">Daniel R. Kowal</a>",
          "description": "Dynamic Linear Models (DLMs) are commonly employed for time series analysis\ndue to their versatile structure, simple recursive updating, ability to handle\nmissing data, and probabilistic forecasting. However, the options for count\ntime series are limited: Gaussian DLMs require continuous data, while\nPoisson-based alternatives often lack sufficient modeling flexibility. We\nintroduce a novel semiparametric methodology for count time series by warping a\nGaussian DLM. The warping function has two components: a (nonparametric)\ntransformation operator that provides distributional flexibility and a rounding\noperator that ensures the correct support for the discrete data-generating\nprocess. We develop conjugate inference for the warped DLM, which enables\nanalytic and recursive updates for the state space filtering and smoothing\ndistributions. We leverage these results to produce customized and efficient\nalgorithms for inference and forecasting, including Monte Carlo simulation for\noffline analysis and an optimal particle filter for online inference. This\nframework unifies and extends a variety of discrete time series models and is\nvalid for natural counts, rounded values, and multivariate observations.\nSimulation studies illustrate the excellent forecasting capabilities of the\nwarped DLM. The proposed approach is applied to a multivariate time series of\ndaily overdose counts and demonstrates both modeling and computational\nsuccesses.",
          "link": "http://arxiv.org/abs/2110.14790",
          "publishedOn": "2022-04-18T00:59:12.480Z",
          "wordCount": 656,
          "title": "Warped Dynamic Linear Models for Time Series of Counts. (arXiv:2110.14790v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teshima_T/0/1/0/all/0/1\">Takeshi Teshima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tojo_K/0/1/0/all/0/1\">Koichi Tojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oono_K/0/1/0/all/0/1\">Kenta Oono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Invertible neural networks (INNs) are neural network architectures with\ninvertibility by design. Thanks to their invertibility and the tractability of\nJacobian, INNs have various machine learning applications such as probabilistic\nmodeling, generative modeling, and representation learning. However, their\nattractive properties often come at the cost of restricting the layer designs,\nwhich poses a question on their representation power: can we use these models\nto approximate sufficiently diverse functions? To answer this question, we have\ndeveloped a general theoretical framework to investigate the representation\npower of INNs, building on a structure theorem of differential geometry. The\nframework simplifies the approximation problem of diffeomorphisms, which\nenables us to show the universal approximation properties of INNs. We apply the\nframework to two representative classes of INNs, namely Coupling-Flow-based\nINNs (CF-INNs) and Neural Ordinary Differential Equations (NODEs), and\nelucidate their high representation power despite the restrictions on their\narchitectures.",
          "link": "http://arxiv.org/abs/2204.07415",
          "publishedOn": "2022-04-18T00:59:12.472Z",
          "wordCount": 638,
          "title": "Universal approximation property of invertible neural networks. (arXiv:2204.07415v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hahn_Klimroth_M/0/1/0/all/0/1\">Max Hahn-Klimroth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaaser_D/0/1/0/all/0/1\">Dominik Kaaser</a>",
          "description": "In the pooled data problem we are given a set of $n$ agents, each of which\nholds a hidden state bit, either $0$ or $1$. A querying procedure returns for a\nquery set the sum of the states of the queried agents. The goal is to\nreconstruct the states using as few queries as possible. In this paper we\nconsider two noise models for the pooled data problem. In the noisy channel\nmodel, the result for each agent flips with a certain probability. In the noisy\nquery model, each query result is subject to random Gaussian noise. Our results\nare twofold. First, we present and analyze for both error models a simple and\nefficient distributed algorithm that reconstructs the initial states in a\ngreedy fashion. Our novel analysis pins down the range of error probabilities\nand distributions for which our algorithm reconstructs the exact initial states\nwith high probability. Secondly, we present simulation results of our algorithm\nand compare its performance with approximate message passing (AMP) algorithms\nthat are conjectured to be optimal in a number of related problems.",
          "link": "http://arxiv.org/abs/2204.07491",
          "publishedOn": "2022-04-18T00:59:12.452Z",
          "wordCount": 635,
          "title": "Distributed Reconstruction of Noisy Pooled Data. (arXiv:2204.07491v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07136",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pozdnyakov_S/0/1/0/all/0/1\">Sergey N. Pozdnyakov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ceriotti_M/0/1/0/all/0/1\">Michele Ceriotti</a>",
          "description": "Graph neural networks (GNN) are very popular methods in machine learning and\nhave been applied very successfully to the prediction of the properties of\nmolecules and materials. First-order GNNs are well known to be incomplete,\ni.e., there exist graphs that are distinct but appear identical when seen\nthrough the lens of the GNN. More complicated schemes have thus been designed\nto increase their resolving power. Applications to molecules (and more\ngenerally, point clouds), however, add a geometric dimension to the problem.\nThe most straightforward and prevalent approach to construct graph\nrepresentation for molecules regards atoms as vertices in a graph and draws a\nbond between each pair of atoms within a chosen cutoff. Bonds can be decorated\nwith the distance between atoms, and the resulting \"distance graph NNs\" (dGNN)\nhave empirically demonstrated excellent resolving power and are widely used in\nchemical ML, with all known indistinguishable graphs being resolved in the\nfully-connected limit. Here we show that even for the restricted case of\nfully-connected graphs induced by 3D atom clouds dGNNs are not complete. We\nconstruct pairs of distinct point clouds that generate graphs that, for any\ncutoff radius, are equivalent based on a first-order Weisfeiler-Lehman test.\nThis class of degenerate structures includes chemically-plausible\nconfigurations, setting an ultimate limit to the expressive power of some of\nthe well-established GNN architectures for atomistic machine learning. Models\nthat explicitly use angular or directional information in the description of\natomic environments can resolve these degeneracies.",
          "link": "http://arxiv.org/abs/2201.07136",
          "publishedOn": "2022-04-16T00:51:43.716Z",
          "wordCount": null,
          "title": "Incompleteness of graph convolutional neural networks for points clouds in three dimensions. (arXiv:2201.07136v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ley_D/0/1/0/all/0/1\">Dan Ley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Saumitra Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1\">Daniele Magazzeni</a>",
          "description": "Counterfactual explanations have been widely studied in explainability, with\na range of application dependent methods emerging in fairness, recourse and\nmodel understanding. However, the major shortcoming associated with these\nmethods is their inability to provide explanations beyond the local or\ninstance-level. While some works touch upon the notion of a global explanation,\ntypically suggesting to aggregate masses of local explanations in the hope of\nascertaining global properties, few provide frameworks that are either reliable\nor computationally tractable. Meanwhile, practitioners are requesting more\nefficient and interactive explainability tools. We take this opportunity to\ninvestigate existing global methods, with a focus on implementing and improving\nActionable Recourse Summaries (AReS), the only known global counterfactual\nexplanation framework for recourse.",
          "link": "http://arxiv.org/abs/2204.06917",
          "publishedOn": "2022-04-16T00:51:43.712Z",
          "wordCount": null,
          "title": "Global Counterfactual Explanations: Investigations, Implementations and Improvements. (arXiv:2204.06917v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05933",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Freguglia_V/0/1/0/all/0/1\">Victor Freguglia</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Garcia_N/0/1/0/all/0/1\">Nancy Lopes Garcia</a>",
          "description": "We consider the problem of estimating the interacting neighborhood of a\nMarkov Random Field model with finite support and homogeneous pairwise\ninteractions based on relative positions of a two-dimensional lattice. Using a\nBayesian framework, we propose a Reversible Jump Monte Carlo Markov Chain\nalgorithm that jumps across subsets of a maximal range neighborhood, allowing\nus to perform model selection based on a marginal pseudoposterior distribution\nof models.",
          "link": "http://arxiv.org/abs/2204.05933",
          "publishedOn": "2022-04-16T00:51:43.711Z",
          "wordCount": null,
          "title": "Sparse Interaction Neighborhood Selection for Markov Random Fields via Reversible Jump and Pseudoposteriors. (arXiv:2204.05933v2 [stat.CO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04219",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ren_T/0/1/0/all/0/1\">Tongzheng Ren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhuo_J/0/1/0/all/0/1\">Jiacheng Zhuo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sanghavi_S/0/1/0/all/0/1\">Sujay Sanghavi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>",
          "description": "It is known that when the statistical models are singular, i.e., the Fisher\ninformation matrix at the true parameter is degenerate, the fixed step-size\ngradient descent algorithm takes polynomial number of steps in terms of the\nsample size $n$ to converge to a final statistical radius around the true\nparameter, which can be unsatisfactory for the application. To further improve\nthat computational complexity, we consider the utilization of the second-order\ninformation in the design of optimization algorithms. Specifically, we study\nthe normalized gradient descent (NormGD) algorithm for solving parameter\nestimation in parametric statistical models, which is a variant of gradient\ndescent algorithm whose step size is scaled by the maximum eigenvalue of the\nHessian matrix of the empirical loss function of statistical models. When the\npopulation loss function, i.e., the limit of the empirical loss function when\n$n$ goes to infinity, is homogeneous in all directions, we demonstrate that the\nNormGD iterates reach a final statistical radius around the true parameter\nafter a logarithmic number of iterations in terms of $n$. Therefore, for fixed\ndimension $d$, the NormGD algorithm achieves the optimal overall computational\ncomplexity $\\mathcal{O}(n)$ to reach the final statistical radius. This\ncomputational complexity is cheaper than that of the fixed step-size gradient\ndescent algorithm, which is of the order $\\mathcal{O}(n^{\\tau})$ for some $\\tau\n> 1$, to reach the same statistical radius. We illustrate our general theory\nunder two statistical models: generalized linear models and mixture models, and\nexperimental results support our prediction with general theory.",
          "link": "http://arxiv.org/abs/2202.04219",
          "publishedOn": "2022-04-16T00:51:43.709Z",
          "wordCount": null,
          "title": "Improving Computational Complexity in Statistical Models with Second-Order Information. (arXiv:2202.04219v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jenul_A/0/1/0/all/0/1\">Anna Jenul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schrunner_S/0/1/0/all/0/1\">Stefan Schrunner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_B/0/1/0/all/0/1\">Bao Ngoc Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helin_R/0/1/0/all/0/1\">Runar Helin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Futsaether_C/0/1/0/all/0/1\">Cecilia Marie Futs&#xe6;ther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liland_K/0/1/0/all/0/1\">Kristian Hovde Liland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomic_O/0/1/0/all/0/1\">Oliver Tomic</a>",
          "description": "In artificial neural networks, understanding the contributions of input\nfeatures on the prediction fosters model explainability and delivers relevant\ninformation about the dataset. While typical setups for feature importance\nranking assess input features individually, in this study, we go one step\nfurther and rank the importance of groups of features, denoted as\nfeature-blocks. A feature-block can contain features of a specific type or\nfeatures derived from a particular source, which are presented to the neural\nnetwork in separate input branches (multiblock ANNs). This work presents three\nmethods pursuing distinct strategies to rank features in multiblock ANNs by\ntheir importance: (1) a composite strategy building on individual feature\nimportance rankings, (2) a knock-in, and (3) a knock-out strategy. While the\ncomposite strategy builds on state-of-the-art feature importance rankings,\nknock-in and knock-out strategies evaluate the block as a whole via a mutual\ninformation criterion. Our experiments consist of a simulation study validating\nall three approaches, followed by a case study on two distinct real-world\ndatasets to compare the strategies. We conclude that each strategy has its\nmerits for specific application scenarios.",
          "link": "http://arxiv.org/abs/2109.10279",
          "publishedOn": "2022-04-16T00:51:43.700Z",
          "wordCount": null,
          "title": "Ranking Feature-Block Importance in Artificial Multiblock Neural Networks. (arXiv:2109.10279v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junxiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_D/0/1/0/all/0/1\">Debabrota Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trummer_I/0/1/0/all/0/1\">Immanuel Trummer</a>",
          "description": "In black-box optimization problems, we aim to maximize an unknown objective\nfunction, where the function is only accessible through feedbacks of an\nevaluation or simulation oracle. In real-life, the feedbacks of such oracles\nare often noisy and available after some unknown delay that may depend on the\ncomputation time of the oracle. Additionally, if the exact evaluations are\nexpensive but coarse approximations are available at a lower cost, the\nfeedbacks can have multi-fidelity. In order to address this problem, we propose\na generic extension of hierarchical optimistic tree search (HOO), called\nProCrastinated Tree Search (PCTS), that flexibly accommodates a delay and\nnoise-tolerant bandit algorithm. We provide a generic proof technique to\nquantify regret of PCTS under delayed, noisy, and multi-fidelity feedbacks.\nSpecifically, we derive regret bounds of PCTS enabled with delayed-UCB1 (DUCB1)\nand delayed-UCB-V (DUCBV) algorithms. Given a horizon $T$, PCTS retains the\nregret bound of non-delayed HOO for expected delay of $O(\\log T)$ and worsens\nby $O(T^{\\frac{1-\\alpha}{d+2}})$ for expected delays of $O(T^{1-\\alpha})$ for\n$\\alpha \\in (0,1]$. We experimentally validate on multiple synthetic functions\nand hyperparameter tuning problems that PCTS outperforms the state-of-the-art\nblack-box optimization methods for feedbacks with different noise levels,\ndelays, and fidelity.",
          "link": "http://arxiv.org/abs/2110.07232",
          "publishedOn": "2022-04-16T00:51:42.726Z",
          "wordCount": null,
          "title": "Procrastinated Tree Search: Black-box Optimization with Delayed, Noisy, and Multi-Fidelity Feedback. (arXiv:2110.07232v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1\">Haewon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>",
          "description": "We investigate the fairness concerns of training a machine learning model\nusing data with missing values. Even though there are a number of fairness\nintervention methods in the literature, most of them require a complete\ntraining set as input. In practice, data can have missing values, and data\nmissing patterns can depend on group attributes (e.g. gender or race). Simply\napplying off-the-shelf fair learning algorithms to an imputed dataset may lead\nto an unfair model. In this paper, we first theoretically analyze different\nsources of discrimination risks when training with an imputed dataset. Then, we\npropose an integrated approach based on decision trees that does not require a\nseparate process of imputation and learning. Instead, we train a tree with\nmissing incorporated as attribute (MIA), which does not require explicit\nimputation, and we optimize a fairness-regularized objective function. We\ndemonstrate that our approach outperforms existing fairness intervention\nmethods applied to an imputed dataset, through several experiments on\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2109.10431",
          "publishedOn": "2022-04-16T00:51:42.676Z",
          "wordCount": null,
          "title": "Fairness without Imputation: A Decision Tree Approach for Fair Prediction with Missing Values. (arXiv:2109.10431v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.13001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1\">MohammadJavad Azizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_T/0/1/0/all/0/1\">Thang Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1\">Yasin Abbasi-Yadkori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andr&#xe1;s Gy&#xf6;rgy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vernade_C/0/1/0/all/0/1\">Claire Vernade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>",
          "description": "We study a sequential decision problem where the learner faces a sequence of\n$K$-armed stochastic bandit tasks. The tasks may be designed by an adversary,\nbut the adversary is constrained to choose the optimal arm of each task in a\nsmaller (but unknown) subset of $M$ arms. The task boundaries might be known\n(the bandit meta-learning setting), or unknown (the non-stationary bandit\nsetting), and the number of tasks $N$ as well as the total number of rounds $T$\nare known ($N$ could be unknown in the meta-learning setting). We design an\nalgorithm based on a reduction to bandit submodular maximization, and show that\nits regret in both settings is smaller than the simple baseline of\n$\\tilde{O}(\\sqrt{KNT})$ that can be obtained by using standard algorithms\ndesigned for non-stationary bandit problems. For the bandit meta-learning\nproblem with fixed task length $\\tau$, we show that the regret of the algorithm\nis bounded as $\\tilde{O}(N\\sqrt{M \\tau}+N^{2/3})$. Under additional assumptions\non the identifiability of the optimal arms in each task, we show a bandit\nmeta-learning algorithm with an improved $\\tilde{O}(N\\sqrt{M \\tau}+N^{1/2})$\nregret.",
          "link": "http://arxiv.org/abs/2202.13001",
          "publishedOn": "2022-04-16T00:51:42.512Z",
          "wordCount": null,
          "title": "Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms. (arXiv:2202.13001v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gokcesu_K/0/1/0/all/0/1\">Kaan Gokcesu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokcesu_H/0/1/0/all/0/1\">Hakan Gokcesu</a>",
          "description": "We study the problem of expert advice under partial bandit feedback setting\nand create a sequential minimax optimal algorithm. Our algorithm works with a\nmore general partial monitoring setting, where, in contrast to the classical\nbandit feedback, the losses can be revealed in an adversarial manner. Our\nalgorithm adopts a universal prediction perspective, whose performance is\nanalyzed with regret against a general expert selection sequence. The regret we\nstudy is against a general competition class that covers many settings (such as\nthe switching or contextual experts settings) and the expert selection\nsequences in the competition class are determined by the application at hand.\nOur regret bounds are second order bounds in terms of the sum of squared losses\nand the normalized regret of our algorithm is invariant under arbitrary affine\ntransforms of the loss sequence. Our algorithm is truly online and does not use\nany preliminary information about the loss sequences.",
          "link": "http://arxiv.org/abs/2204.06660",
          "publishedOn": "2022-04-16T00:51:42.461Z",
          "wordCount": 620,
          "title": "Second Order Regret Bounds Against Generalized Expert Sequences under Partial Bandit Feedback. (arXiv:2204.06660v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.04788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_H/0/1/0/all/0/1\">Hsiang Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1\">Mario Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>",
          "description": "Disparate treatment occurs when a machine learning model yields different\ndecisions for individuals based on a sensitive attribute (e.g., age, sex). In\ndomains where prediction accuracy is paramount, it could potentially be\nacceptable to fit a model which exhibits disparate treatment. To evaluate the\neffect of disparate treatment, we compare the performance of split classifiers\n(i.e., classifiers trained and deployed separately on each group) with\ngroup-blind classifiers (i.e., classifiers which do not use a sensitive\nattribute). We introduce the benefit-of-splitting for quantifying the\nperformance improvement by splitting classifiers. Computing the\nbenefit-of-splitting directly from its definition could be intractable since it\ninvolves solving optimization problems over an infinite-dimensional functional\nspace. Under different performance measures, we (i) prove an equivalent\nexpression for the benefit-of-splitting which can be efficiently computed by\nsolving small-scale convex programs; (ii) provide sharp upper and lower bounds\nfor the benefit-of-splitting which reveal precise conditions where a\ngroup-blind classifier will always suffer from a non-trivial performance gap\nfrom the split classifiers. In the finite sample regime, splitting is not\nnecessarily beneficial and we provide data-dependent bounds to understand this\neffect. Finally, we validate our theoretical results through numerical\nexperiments on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2002.04788",
          "publishedOn": "2022-04-16T00:51:42.364Z",
          "wordCount": 705,
          "title": "To Split or Not to Split: The Impact of Disparate Treatment in Classification. (arXiv:2002.04788v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruoning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1\">Kangning Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_R/0/1/0/all/0/1\">Raymond H. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plemmons_R/0/1/0/all/0/1\">Robert J. Plemmons</a>",
          "description": "In this work, a novel algorithm called SVM with Shape-adaptive Reconstruction\nand Smoothed Total Variation (SaR-SVM-STV) is introduced to classify\nhyperspectral images, which makes full use of spatial and spectral information.\nThe Shape-adaptive Reconstruction (SaR) is introduced to preprocess each pixel\nbased on the Pearson Correlation between pixels in its shape-adaptive (SA)\nregion. Support Vector Machines (SVMs) are trained to estimate the pixel-wise\nprobability maps of each class. Then the Smoothed Total Variation (STV) model\nis applied to denoise and generate the final classification map. Experiments\nshow that SaR-SVM-STV outperforms the SVM-STV method with a few training\nlabels, demonstrating the significance of reconstructing hyperspectral images\nbefore classification.",
          "link": "http://arxiv.org/abs/2203.15619",
          "publishedOn": "2022-04-16T00:51:38.063Z",
          "wordCount": 600,
          "title": "Classification of Hyperspectral Images Using SVM with Shape-adaptive Reconstruction and Smoothed Total Variation. (arXiv:2203.15619v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1903.09668",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yuexi Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Polson_N/0/1/0/all/0/1\">Nicholas G. Polson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolov_V/0/1/0/all/0/1\">Vadim O. Sokolov</a>",
          "description": "Deep Learning (DL) methods have emerged as one of the most powerful tools for\nfunctional approximation and prediction. While the representation properties of\nDL have been well studied, uncertainty quantification remains challenging and\nlargely unexplored. Data augmentation techniques are a natural approach to\nprovide uncertainty quantification and to incorporate stochastic Monte Carlo\nsearch into stochastic gradient descent (SGD) methods. The purpose of our paper\nis to show that training DL architectures with data augmentation leads to\nefficiency gains. We use the theory of scale mixtures of normals to derive data\naugmentation strategies for deep learning. This allows variants of the\nexpectation-maximization and MCMC algorithms to be brought to bear on these\nhigh dimensional nonlinear deep learning models. To demonstrate our\nmethodology, we develop data augmentation algorithms for a variety of commonly\nused activation functions: logit, ReLU, leaky ReLU and SVM. Our methodology is\ncompared to traditional stochastic gradient descent with back-propagation. Our\noptimization procedure leads to a version of iteratively re-weighted least\nsquares and can be implemented at scale with accelerated linear algebra methods\nproviding substantial improvement in speed. We illustrate our methodology on a\nnumber of standard datasets. Finally, we conclude with directions for future\nresearch.",
          "link": "http://arxiv.org/abs/1903.09668",
          "publishedOn": "2022-04-16T00:51:38.054Z",
          "wordCount": 660,
          "title": "Data Augmentation for Bayesian Deep Learning. (arXiv:1903.09668v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06990",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Bellec_P/0/1/0/all/0/1\">Pierre C Bellec</a>",
          "description": "We consider observations $(X,y)$ from single index models with unknown link\nfunction, Gaussian covariates and a regularized M-estimator $\\hat\\beta$\nconstructed from convex loss function and regularizer. In the regime where\nsample size $n$ and dimension $p$ are both increasing such that $p/n$ has a\nfinite limit, the behavior of the empirical distribution of $\\hat\\beta$ and the\npredicted values $X\\hat\\beta$ has been previously characterized in a number of\nmodels: The empirical distributions are known to converge to proximal operators\nof the loss and penalty in a related Gaussian sequence model, which captures\nthe interplay between ratio $p/n$, loss, regularization and the data generating\nprocess. This connection between$(\\hat\\beta,X\\hat\\beta)$ and the corresponding\nproximal operators require solving fixed-point equations that typically involve\nunobservable quantities such as the prior distribution on the index or the link\nfunction.\n\nThis paper develops a different theory to describe the empirical distribution\nof $\\hat\\beta$ and $X\\hat\\beta$: Approximations of $(\\hat\\beta,X\\hat\\beta)$ in\nterms of proximal operators are provided that only involve observable\nadjustments. These proposed observable adjustments are data-driven, e.g., do\nnot require prior knowledge of the index or the link function. These new\nadjustments yield confidence intervals for individual components of the index,\nas well as estimators of the correlation of $\\hat\\beta$ with the index. The\ninterplay between loss, regularization and the model is thus captured in a\ndata-driven manner, without solving the fixed-point equations studied in\nprevious works. The results apply to both strongly convex regularizers and\nunregularized M-estimation. Simulations are provided for the square and\nlogistic loss in single index models including logistic regression and 1-bit\ncompressed sensing with 20\\% corrupted bits.",
          "link": "http://arxiv.org/abs/2204.06990",
          "publishedOn": "2022-04-16T00:51:38.046Z",
          "wordCount": 698,
          "title": "Observable adjustments in single-index models for regularized M-estimators. (arXiv:2204.06990v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06935",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1\">Zhijun Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schaeffer_H/0/1/0/all/0/1\">Hayden Schaeffer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ward_R/0/1/0/all/0/1\">Rachel Ward</a>",
          "description": "The spectra of random feature matrices provide essential information on the\nconditioning of the linear system used in random feature regression problems\nand are thus connected to the consistency and generalization of random feature\nmodels. Random feature matrices are asymmetric rectangular nonlinear matrices\ndepending on two input variables, the data and the weights, which can make\ntheir characterization challenging. We consider two settings for the two input\nvariables, either both are random variables or one is a random variable and the\nother is well-separated, i.e. there is a minimum distance between points. With\nconditions on the dimension, the complexity ratio, and the sampling variance,\nwe show that the singular values of these matrices concentrate near their full\nexpectation and near one with high-probability. In particular, since the\ndimension depends only on the logarithm of the number of random weights or the\nnumber of data points, our complexity bounds can be achieved even in moderate\ndimensions for many practical setting. The theoretical results are verified\nwith numerical experiments.",
          "link": "http://arxiv.org/abs/2204.06935",
          "publishedOn": "2022-04-16T00:51:38.038Z",
          "wordCount": 609,
          "title": "Concentration of Random Feature Matrices in High-Dimensions. (arXiv:2204.06935v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06997",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bruinsma_W/0/1/0/all/0/1\">Wessel P. Bruinsma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tegner_M/0/1/0/all/0/1\">Martin Tegn&#xe9;r</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>",
          "description": "The Gaussian Process Convolution Model (GPCM; Tobar et al., 2015a) is a model\nfor signals with complex spectral structure. A significant limitation of the\nGPCM is that it assumes a rapidly decaying spectrum: it can only model smooth\nsignals. Moreover, inference in the GPCM currently requires (1) a mean-field\nassumption, resulting in poorly calibrated uncertainties, and (2) a tedious\nvariational optimisation of large covariance matrices. We redesign the GPCM\nmodel to induce a richer distribution over the spectrum with relaxed\nassumptions about smoothness: the Causal Gaussian Process Convolution Model\n(CGPCM) introduces a causality assumption into the GPCM, and the Rough Gaussian\nProcess Convolution Model (RGPCM) can be interpreted as a Bayesian\nnonparametric generalisation of the fractional Ornstein-Uhlenbeck process. We\nalso propose a more effective variational inference scheme, going beyond the\nmean-field assumption: we design a Gibbs sampler which directly samples from\nthe optimal variational solution, circumventing any variational optimisation\nentirely. The proposed variations of the GPCM are validated in experiments on\nsynthetic and real-world data, showing promising results.",
          "link": "http://arxiv.org/abs/2203.06997",
          "publishedOn": "2022-04-16T00:51:38.017Z",
          "wordCount": 641,
          "title": "Modelling Non-Smooth Signals with Complex Spectral Structure. (arXiv:2203.06997v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamm_K/0/1/0/all/0/1\">Keaton Hamm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henscheid_N/0/1/0/all/0/1\">Nick Henscheid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">Shujie Kang</a>",
          "description": "In this paper, we propose Wasserstein Isometric Mapping (Wassmap), a\nparameter-free nonlinear dimensionality reduction technique that provides\nsolutions to some drawbacks in existing global nonlinear dimensionality\nreduction algorithms in imaging applications. Wassmap represents images via\nprobability measures in Wasserstein space, then uses pairwise quadratic\nWasserstein distances between the associated measures to produce a\nlow-dimensional, approximately isometric embedding. We show that the algorithm\nis able to exactly recover parameters of some image manifolds including those\ngenerated by translations or dilations of a fixed generating measure.\nAdditionally, we show that a discrete version of the algorithm retrieves\nparameters from manifolds generated from discrete measures by providing a\ntheoretical bridge to transfer recovery results from functional data to\ndiscrete data. Testing of the proposed algorithms on various image data\nmanifolds show that Wassmap yields good embeddings compared with other global\ntechniques.",
          "link": "http://arxiv.org/abs/2204.06645",
          "publishedOn": "2022-04-16T00:51:38.009Z",
          "wordCount": 585,
          "title": "Wassmap: Wasserstein Isometric Mapping for Image Manifold Learning. (arXiv:2204.06645v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.06246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cen_S/0/1/0/all/0/1\">Sarah H. Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>",
          "description": "Making an informed decision -- for example, when choosing a career or housing\n-- requires knowledge about the available options. Such knowledge is generally\nacquired through costly trial and error, but this learning process can be\ndisrupted by competition. In this work, we study how competition affects the\nlong-term outcomes of individuals as they learn. We build on a line of work\nthat models this setting as a two-sided matching market with bandit learners. A\nrecent result in this area states that it is impossible to simultaneously\nguarantee two natural desiderata: stability and low optimal regret for all\nagents. Resource-allocating platforms can point to this result as a\njustification for assigning good long-term outcomes to some agents and poor\nones to others. We show that this impossibility need not hold true. In\nparticular, by modeling two additional components of competition -- namely,\ncosts and transfers -- we prove that it is possible to simultaneously guarantee\nfour desiderata: stability, low optimal regret, fairness in the distribution of\nregret, and high social welfare.",
          "link": "http://arxiv.org/abs/2102.06246",
          "publishedOn": "2022-04-16T00:51:38.001Z",
          "wordCount": 663,
          "title": "Regret, stability & fairness in matching markets with bandit learners. (arXiv:2102.06246v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06664",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Niss_L/0/1/0/all/0/1\">Laura Niss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yuekai Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1\">Ambuj Tewari</a>",
          "description": "Sampling biases in training data are a major source of algorithmic biases in\nmachine learning systems. Although there are many methods that attempt to\nmitigate such algorithmic biases during training, the most direct and obvious\nway is simply collecting more representative training data. In this paper, we\nconsider the task of assembling a training dataset in which minority groups are\nadequately represented from a given set of data sources. In essence, this is an\nadaptive sampling problem to determine if a given point lies in the convex hull\nof the means from a set of unknown distributions. We present adaptive sampling\nmethods to determine, with high confidence, whether it is possible to assemble\na representative dataset from the given data sources. We also demonstrate the\nefficacy of our policies in simulations in the Bernoulli and a multinomial\nsetting.",
          "link": "http://arxiv.org/abs/2204.06664",
          "publishedOn": "2022-04-16T00:51:37.994Z",
          "wordCount": 575,
          "title": "Achieving Representative Data via Convex Hull Feasibility Sampling Algorithms. (arXiv:2204.06664v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.08928",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_K/0/1/0/all/0/1\">Kan Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_X/0/1/0/all/0/1\">Xuanyi Zhao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bastani_H/0/1/0/all/0/1\">Hamsa Bastani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Unstructured text provides decision-makers with a rich data source in many\ndomains, ranging from product reviews in retailing to nursing notes in\nhealthcare. To leverage this information, words are typically translated into\nword embeddings -- vectors that encode the semantic relationships between words\n-- through unsupervised learning algorithms such as matrix factorization.\nHowever, learning word embeddings from new domains with limited training data\ncan be challenging, because the meaning/usage may be different in the new\ndomain, e.g., the word \"positive\" typically has positive sentiment, but often\nhas negative sentiment in medical notes since it may imply that a patient is\ntested positive for a disease. Intuitively, we expect that only a small number\nof domain-specific words may have new meanings/usages. We propose an intuitive\ntwo-stage estimator that exploits this structure via a group-sparse penalty to\nefficiently transfer learn domain-specific word embeddings by combining\nlarge-scale text corpora (such as Wikipedia) with limited domain-specific text\ndata. We bound the generalization error of our estimator, proving that it can\nachieve the same accuracy (compared to not transfer learning) with\nsubstantially less domain-specific data when only a small number of embeddings\nare altered between domains. Our results provide the first bounds on\ngroup-sparse matrix factorization, which may be of independent interest. We\nempirically evaluate the effectiveness of our approach compared to\nstate-of-the-art fine-tuning heuristics from natural language processing.",
          "link": "http://arxiv.org/abs/2104.08928",
          "publishedOn": "2022-04-16T00:51:37.986Z",
          "wordCount": 685,
          "title": "Group-Sparse Matrix Factorization for Transfer Learning of Word Embeddings. (arXiv:2104.08928v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yun Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yufei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Ting Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1\">Michael Backes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stringhini_G/0/1/0/all/0/1\">Gianluca Stringhini</a>",
          "description": "Previous security research efforts orbiting around graphs have been\nexclusively focusing on either (de-)anonymizing the graphs or understanding the\nsecurity and privacy issues of graph neural networks. Little attention has been\npaid to understand the privacy risks of integrating the output from graph\nembedding models (e.g., node embeddings) with complex downstream machine\nlearning pipelines. In this paper, we fill this gap and propose a novel\nmodel-agnostic graph recovery attack that exploits the implicit graph\nstructural information preserved in the embeddings of graph nodes. We show that\nan adversary can recover edges with decent accuracy by only gaining access to\nthe node embedding matrix of the original graph without interactions with the\nnode embedding models. We demonstrate the effectiveness and applicability of\nour graph recovery attack through extensive experiments.",
          "link": "http://arxiv.org/abs/2204.06963",
          "publishedOn": "2022-04-16T00:51:37.963Z",
          "wordCount": 594,
          "title": "Finding MNEMON: Reviving Memories of Node Embeddings. (arXiv:2204.06963v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caillon_A/0/1/0/all/0/1\">Antoine Caillon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esling_P/0/1/0/all/0/1\">Philippe Esling</a>",
          "description": "Deep learning models are mostly used in an offline inference fashion.\nHowever, this strongly limits the use of these models inside audio generation\nsetups, as most creative workflows are based on real-time digital signal\nprocessing. Although approaches based on recurrent networks can be naturally\nadapted to this buffer-based computation, the use of convolutions still poses\nsome serious challenges. To tackle this issue, the use of causal streaming\nconvolutions have been proposed. However, this requires specific complexified\ntraining and can impact the resulting audio quality.\n\nIn this paper, we introduce a new method allowing to produce non-causal\nstreaming models. This allows to make any convolutional model compatible with\nreal-time buffer-based processing. As our method is based on a post-training\nreconfiguration of the model, we show that it is able to transform models\ntrained without causal constraints into a streaming model. We show how our\nmethod can be adapted to fit complex architectures with parallel branches. To\nevaluate our method, we apply it on the recent RAVE model, which provides\nhigh-quality real-time audio synthesis. We test our approach on multiple music\nand speech datasets and show that it is faster than overlap-add methods, while\nhaving no impact on the generation quality. Finally, we introduce two\nopen-source implementation of our work as Max/MSP and PureData externals, and\nas a VST audio plugin. This allows to endow traditional digital audio\nworkstation with real-time neural audio synthesis on a laptop CPU.",
          "link": "http://arxiv.org/abs/2204.07064",
          "publishedOn": "2022-04-16T00:51:37.955Z",
          "wordCount": 676,
          "title": "Streamable Neural Audio Synthesis With Non-Causal Convolutions. (arXiv:2204.07064v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.05842",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dwivedi_R/0/1/0/all/0/1\">Raaz Dwivedi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "We introduce kernel thinning, a new procedure for compressing a distribution\n$\\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given\na suitable reproducing kernel $\\mathbf{k}$ and $\\mathcal{O}(n^2)$ time, kernel\nthinning compresses an $n$-point approximation to $\\mathbb{P}$ into a\n$\\sqrt{n}$-point approximation with comparable worst-case integration error\nacross the associated reproducing kernel Hilbert space. With high probability,\nthe maximum discrepancy in integration error is\n$\\mathcal{O}_d(n^{-1/2}\\sqrt{\\log n})$ for compactly supported $\\mathbb{P}$ and\n$\\mathcal{O}_d(n^{-\\frac{1}{2}} (\\log n)^{(d+1)/2}\\sqrt{\\log\\log n})$ for\nsub-exponential $\\mathbb{P}$ on $\\mathbb{R}^d$. In contrast, an equal-sized\ni.i.d. sample from $\\mathbb{P}$ suffers $\\Omega(n^{-1/4})$ integration error.\nOur sub-exponential guarantees resemble the classical quasi-Monte Carlo error\nrates for uniform $\\mathbb{P}$ on $[0,1]^d$ but apply to general distributions\non $\\mathbb{R}^d$ and a wide range of common kernels. We use our results to\nderive explicit non-asymptotic maximum mean discrepancy bounds for Gaussian,\nMat\\'ern, and B-spline kernels and present two vignettes illustrating the\npractical benefits of kernel thinning over i.i.d. sampling and standard Markov\nchain Monte Carlo thinning, in dimensions $d=2$ through $100$.",
          "link": "http://arxiv.org/abs/2105.05842",
          "publishedOn": "2022-04-16T00:51:37.947Z",
          "wordCount": 674,
          "title": "Kernel Thinning. (arXiv:2105.05842v7 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gorinova_M/0/1/0/all/0/1\">Maria I. Gorinova</a>",
          "description": "Probabilistic programming is a growing area that strives to make statistical\nanalysis more accessible, by separating probabilistic modelling from\nprobabilistic inference. In practice this decoupling is difficult. No single\ninference algorithm can be used as a probabilistic programming back-end that is\nsimultaneously reliable, efficient, black-box, and general. Probabilistic\nprogramming languages often choose a single algorithm to apply to a given\nproblem, thus inheriting its limitations. While substantial work has been done\nboth to formalise probabilistic programming and to improve efficiency of\ninference, there has been little work that makes use of the available program\nstructure, by formally analysing it, to better utilise the underlying inference\nalgorithm.\n\nThis dissertation presents three novel techniques (both static and dynamic),\nwhich aim to improve probabilistic programming using program analysis. The\ntechniques analyse a probabilistic program and adapt it to make inference more\nefficient, sometimes in a way that would have been tedious or impossible to do\nby hand.",
          "link": "http://arxiv.org/abs/2204.06868",
          "publishedOn": "2022-04-16T00:51:37.939Z",
          "wordCount": 588,
          "title": "Program Analysis of Probabilistic Programs. (arXiv:2204.06868v1 [cs.PL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.13669",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Herrera_C/0/1/0/all/0/1\">Calypso Herrera</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krach_F/0/1/0/all/0/1\">Florian Krach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ruyssen_P/0/1/0/all/0/1\">Pierre Ruyssen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teichmann_J/0/1/0/all/0/1\">Josef Teichmann</a>",
          "description": "This paper presents new machine learning approaches to approximate the\nsolutions of optimal stopping problems. The key idea of these methods is to use\nneural networks, where the parameters of the hidden layers are generated\nrandomly and only the last layer is trained, in order to approximate the\ncontinuation value. Our approaches are applicable to high dimensional problems\nwhere the existing approaches become increasingly impractical. In addition,\nsince our approaches can be optimized using simple linear regression, they are\neasy to implement and theoretical guarantees are provided. Our randomized\nreinforcement learning approach and randomized recurrent neural network\napproach outperform the state-of-the-art and other relevant machine learning\napproaches in Markovian and non-Markovian examples, respectively. In\nparticular, we test our approaches on Black-Scholes, Heston, rough Heston and\nfractional Brownian motion. Moreover, we show that they can also be used to\nefficiently compute Greeks of American options.",
          "link": "http://arxiv.org/abs/2104.13669",
          "publishedOn": "2022-04-16T00:51:37.915Z",
          "wordCount": 607,
          "title": "Optimal Stopping via Randomized Neural Networks. (arXiv:2104.13669v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.11234",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Diethe_T/0/1/0/all/0/1\">Tom Diethe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Flach_P/0/1/0/all/0/1\">Peter Flach</a>",
          "description": "The use of episodic memory in continual learning has demonstrated\neffectiveness for alleviating catastrophic forgetting. In recent studies,\ngradient-based approaches have been developed to make more efficient use of\ncompact episodic memory. Such approaches refine the gradients resulting from\nnew samples by those from memorized samples, aiming to reduce the diversity of\ngradients from different tasks. In this paper, we clarify the relation between\ndiversity of gradients and discriminativeness of representations, showing\nshared as well as conflicting interests between Deep Metric Learning and\ncontinual learning, thus demonstrating pros and cons of learning discriminative\nrepresentations in continual learning. Based on these findings, we propose a\nsimple method -- Semi-Discriminative Representation Loss (SDRL) -- for\ncontinual learning. In comparison with state-of-the-art methods, SDRL shows\nbetter performance with low computational cost on multiple benchmark tasks in\nthe setting of online continual learning.",
          "link": "http://arxiv.org/abs/2006.11234",
          "publishedOn": "2022-04-16T00:51:37.905Z",
          "wordCount": 607,
          "title": "Semi-Discriminative Representation Loss for Online Continual Learning. (arXiv:2006.11234v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.04109",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nabi_R/0/1/0/all/0/1\">Razieh Nabi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Malinsky_D/0/1/0/all/0/1\">Daniel Malinsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shpitser_I/0/1/0/all/0/1\">Ilya Shpitser</a>",
          "description": "Recently there has been sustained interest in modifying prediction algorithms\nto satisfy fairness constraints. These constraints are typically complex\nnonlinear functionals of the observed data distribution. Focusing on the\npath-specific causal constraints proposed by Nabi and Shpitser (2018), we\nintroduce new theoretical results and optimization techniques to make model\ntraining easier and more accurate. Specifically, we show how to reparameterize\nthe observed data likelihood such that fairness constraints correspond directly\nto parameters that appear in the likelihood, transforming a complex constrained\noptimization objective into a simple optimization problem with box constraints.\nWe also exploit methods from empirical likelihood theory in statistics to\nimprove predictive performance by constraining baseline covariates, without\nrequiring parametric models. We combine the merits of both proposals to\noptimize a hybrid reparameterized likelihood. The techniques presented here\nshould be applicable more broadly to fair prediction proposals that impose\nconstraints on predictive models.",
          "link": "http://arxiv.org/abs/1910.04109",
          "publishedOn": "2022-04-16T00:51:37.897Z",
          "wordCount": 621,
          "title": "Optimal Training of Fair Predictive Models. (arXiv:1910.04109v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07124",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Blumlein_T/0/1/0/all/0/1\">Theresa Bl&#xfc;mlein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Persson_J/0/1/0/all/0/1\">Joel Persson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>",
          "description": "Dynamic treatment regimes (DTRs) are used in medicine to tailor sequential\ntreatment decisions to patients by considering patient heterogeneity. Common\nmethods for learning optimal DTRs, however, have shortcomings: they are\ntypically based on outcome prediction and not treatment effect estimation, or\nthey use linear models that are restrictive for patient data from modern\nelectronic health records. To address these shortcomings, we develop two novel\nmethods for learning optimal DTRs that effectively handle complex patient data.\nWe call our methods DTR-CT and DTR-CF. Our methods are based on a data-driven\nestimation of heterogeneous treatment effects using causal tree methods,\nspecifically causal trees and causal forests, that learn non-linear\nrelationships, control for time-varying confounding, are doubly robust, and\nexplainable. To the best of our knowledge, our paper is the first that adapts\ncausal tree methods for learning optimal DTRs. We evaluate our proposed methods\nusing synthetic data and then apply them to real-world data from intensive care\nunits. Our methods outperform state-of-the-art baselines in terms of cumulative\nregret and percentage of optimal decisions by a considerable margin. Our work\nimproves treatment recommendations from electronic health record and is thus of\ndirect relevance for personalized medicine.",
          "link": "http://arxiv.org/abs/2204.07124",
          "publishedOn": "2022-04-16T00:51:37.887Z",
          "wordCount": 644,
          "title": "Learning Optimal Dynamic Treatment Regimes Using Causal Tree Methods in Medicine. (arXiv:2204.07124v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Butler_A/0/1/0/all/0/1\">Andrew Butler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_R/0/1/0/all/0/1\">Roy H. Kwon</a>",
          "description": "Many problems in engineering and statistics involve both predictive\nforecasting and decision-based optimization. Traditionally, predictive models\nare optimized independently from the final decision-based optimization problem.\nIn contrast, a `smart, predict then optimize' (SPO) framework optimizes\nprediction models to explicitly minimize the final downstream decision loss. In\nthis paper we present dboost, a gradient boosting algorithm for training\nprediction model ensembles to minimize decision regret. The dboost framework\nsupports any convex optimization program that can be cast as convex quadratic\ncone program and gradient boosting is performed by implicit differentiation of\na custom fixed-point mapping. To our knowledge, the dboost framework is the\nfirst general purpose implementation of gradient boosting to predict and\noptimize problems. Experimental results comparing with state-of-the-art SPO\nmethods show that dboost can further reduce out-of-sample decision regret.",
          "link": "http://arxiv.org/abs/2204.06895",
          "publishedOn": "2022-04-16T00:51:37.876Z",
          "wordCount": 573,
          "title": "Gradient boosting for convex cone predict and optimize problems. (arXiv:2204.06895v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.01799",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Menictas_M/0/1/0/all/0/1\">Marianne Menictas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Credico_G/0/1/0/all/0/1\">Gioia Di Credico</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wand_M/0/1/0/all/0/1\">Matt P. Wand</a>",
          "description": "We derive streamlined mean field variational Bayes algorithms for fitting\nlinear mixed models with crossed random effects. In the most general situation,\nwhere the dimensions of the crossed groups are arbitrarily large, streamlining\nis hindered by lack of sparseness in the underlying least squares system.\nBecause of this fact we also consider a hierarchy of relaxations of the mean\nfield product restriction. The least stringent product restriction delivers a\nhigh degree of inferential accuracy. However, this accuracy must be mitigated\nagainst its higher storage and computing demands. Faster sparse storage and\ncomputing alternatives are also provided, but come with the price of diminished\ninferential accuracy. This article provides full algorithmic details of three\nvariational inference strategies, presents detailed empirical results on their\npros and cons and, thus, guides the users on their choice of variational\ninference approach depending on the problem size and computing resources.",
          "link": "http://arxiv.org/abs/1910.01799",
          "publishedOn": "2022-04-16T00:51:37.851Z",
          "wordCount": 611,
          "title": "Streamlined Variational Inference for Linear Mixed Models with Crossed Random Effects. (arXiv:1910.01799v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06900",
          "author": "<a href=\"http://arxiv.org/find/nucl-ex/1/au:+Graczykowski_L/0/1/0/all/0/1\">&#x141;ukasz Kamil Graczykowski</a>, <a href=\"http://arxiv.org/find/nucl-ex/1/au:+Jakubowska_M/0/1/0/all/0/1\">Monika Jakubowska</a>, <a href=\"http://arxiv.org/find/nucl-ex/1/au:+Deja_K/0/1/0/all/0/1\">Kamil Rafa&#x142; Deja</a>, <a href=\"http://arxiv.org/find/nucl-ex/1/au:+Kabus_M/0/1/0/all/0/1\">Maja Kabus</a> (for the ALICE Collaboration)",
          "description": "Particle identification (PID) is one of the main strengths of the ALICE\nexperiment at the LHC. It is a crucial ingredient for detailed studies of the\nstrongly interacting matter formed in ultrarelativistic heavy-ion collisions.\nALICE provides PID information via various experimental techniques, allowing\nfor the identification of particles over a broad momentum range (from around\n100 MeV/$c$ to around 50 GeV/$c$). The main challenge is how to combine the\ninformation from various detectors effectively. Therefore, PID represents a\nmodel classification problem, which can be addressed using Machine Learning\n(ML) solutions. Moreover, the complexity of the detector and richness of the\ndetection techniques make PID an interesting area of research also for the\ncomputer science community. In this work, we show the current status of the ML\napproach to PID in ALICE. We discuss the preliminary work with the Random\nForest approach for the LHC Run 2 and a more advanced solution based on Domain\nAdaptation Neural Networks, including a proposal for its future implementation\nwithin the ALICE computing software for the upcoming LHC Run 3.",
          "link": "http://arxiv.org/abs/2204.06900",
          "publishedOn": "2022-04-16T00:51:37.843Z",
          "wordCount": 650,
          "title": "Using Machine Learning for Particle Identification in ALICE. (arXiv:2204.06900v1 [nucl-ex])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Visani_G/0/1/0/all/0/1\">Giorgio Visani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graffi_G/0/1/0/all/0/1\">Giacomo Graffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfero_M/0/1/0/all/0/1\">Mattia Alfero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagli_E/0/1/0/all/0/1\">Enrico Bagli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Capuzzo_D/0/1/0/all/0/1\">Davide Capuzzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chesani_F/0/1/0/all/0/1\">Federico Chesani</a>",
          "description": "The switch from a Model-Centric to a Data-Centric mindset is putting emphasis\non data and its quality rather than algorithms, bringing forward new\nchallenges. In particular, the sensitive nature of the information in highly\nregulated scenarios needs to be accounted for. Specific approaches to address\nthe privacy issue have been developed, as Privacy Enhancing Technologies.\nHowever, they frequently cause loss of information, putting forward a crucial\ntrade-off among data quality and privacy. A clever way to bypass such a\nconundrum relies on Synthetic Data: data obtained from a generative process,\nlearning the real data properties. Both Academia and Industry realized the\nimportance of evaluating synthetic data quality: without all-round reliable\nmetrics, the innovative data generation task has no proper objective function\nto maximize. Despite that, the topic remains under-explored. For this reason,\nwe systematically catalog the important traits of synthetic data quality and\nprivacy, and devise a specific methodology to test them. The result is DAISYnt\n(aDoption of Artificial Intelligence SYnthesis): a comprehensive suite of\nadvanced tests, which sets a de facto standard for synthetic data evaluation.\nAs a practical use-case, a variety of generative algorithms have been trained\non real-world Credit Bureau Data. The best model has been assessed, using\nDAISYnt on the different synthetic replicas. Further potential uses, among\nothers, entail auditing and fine-tuning of generative models or ensuring high\nquality of a given synthetic dataset. From a prescriptive viewpoint,\neventually, DAISYnt may pave the way to synthetic data adoption in highly\nregulated domains, ranging from Finance to Healthcare, through Insurance and\nEducation.",
          "link": "http://arxiv.org/abs/2204.06297",
          "publishedOn": "2022-04-14T00:58:51.989Z",
          "wordCount": null,
          "title": "Enabling Synthetic Data adoption in regulated domains. (arXiv:2204.06297v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dandi_Y/0/1/0/all/0/1\">Yatin Dandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koloskova_A/0/1/0/all/0/1\">Anastasia Koloskova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1\">Sebastian U. Stich</a>",
          "description": "Decentralized learning provides an effective framework to train machine\nlearning models with data distributed over arbitrary communication graphs.\nHowever, most existing approaches toward decentralized learning disregard the\ninteraction between data heterogeneity and graph topology. In this paper, we\ncharacterize the dependence of convergence on the relationship between the\nmixing weights of the graph and the data heterogeneity across nodes. We propose\na metric that quantifies the ability of a graph to mix the current gradients.\nWe further prove that the metric controls the convergence rate, particularly in\nsettings where the heterogeneity across nodes dominates the stochasticity\nbetween updates for a given node. Motivated by our analysis, we propose an\napproach that periodically and efficiently optimizes the metric using standard\nconvex constrained optimization and sketching techniques. Through comprehensive\nexperiments on standard computer vision and NLP benchmarks, we show that our\napproach leads to improvement in test performance for a wide range of tasks.",
          "link": "http://arxiv.org/abs/2204.06477",
          "publishedOn": "2022-04-14T00:58:51.989Z",
          "wordCount": null,
          "title": "Data-heterogeneity-aware Mixing for Decentralized Learning. (arXiv:2204.06477v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06544",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Papacharalampous_G/0/1/0/all/0/1\">Georgia Papacharalampous</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tyralis_H/0/1/0/all/0/1\">Hristos Tyralis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Markonis_Y/0/1/0/all/0/1\">Yannis Markonis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maca_P/0/1/0/all/0/1\">Petr Maca</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanel_M/0/1/0/all/0/1\">Martin Hanel</a>",
          "description": "Detailed feature investigations and comparisons across climates, continents\nand time series types can progress our understanding and modelling ability of\nthe Earth's hydroclimate and its dynamics. As a step towards these important\ndirections, we here propose and extensively apply a multifaceted and\nengineering-friendly methodological framework for the thorough characterization\nof seasonal hydroclimatic dependence, variability and change at the global\nscale. We apply this framework using over 13 000 quarterly temperature,\nprecipitation and river flow time series. In these time series, the seasonal\nhydroclimatic behaviour is represented by 3-month means of earth-observed\nvariables. In our analyses, we also adopt the well-established Koppen-Geiger\nclimate classification system and define continental-scale regions with large\nor medium density of observational stations. In this context, we provide in\nparallel seasonal hydroclimatic feature summaries and comparisons in terms of\nautocorrelation, seasonality, temporal variation, entropy, long-range\ndependence and trends. We find notable differences to characterize the\nmagnitudes of most of these features across the various Koppen-Geiger climate\nclasses, as well as between several continental-scale geographical regions. We,\ntherefore, deem that the consideration of the comparative summaries could be\nmore beneficial in water resources engineering contexts than the also provided\nglobal summaries. Lastly, we apply explainable machine learning to compare the\ninvestigated features with respect to how informative they are in explaining\nand predicting either the main Koppen-Geiger climate or the continental-scale\nregion, with the entropy, long-range dependence and trend features being\n(roughly) found to be less informative than the remaining ones at the seasonal\ntime scale.",
          "link": "http://arxiv.org/abs/2204.06544",
          "publishedOn": "2022-04-14T00:58:51.989Z",
          "wordCount": null,
          "title": "Features of the Earth's seasonal hydroclimate: Characterizations and comparisons across the Koppen-Geiger climates and across continents. (arXiv:2204.06544v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07365",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Siviero_E/0/1/0/all/0/1\">Emilia Siviero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chautru_E/0/1/0/all/0/1\">Emilie Chautru</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Clemencon_S/0/1/0/all/0/1\">Stephan Cl&#xe9;men&#xe7;on</a>",
          "description": "In the Big Data era, with the ubiquity of geolocation sensors in particular,\nmassive datasets exhibiting a possibly complex spatial dependence structure are\nbecoming increasingly available. In this context, the standard probabilistic\ntheory of statistical learning does not apply directly and guarantees of the\ngeneralization capacity of predictive rules learned from such data are left to\nestablish. We analyze here the simple Kriging task, the flagship problem in\nGeostatistics: the values of a square integrable random field $X=\\{X_s\\}_{s\\in\nS}$, $S\\subset \\mathbb{R}^2$, with unknown covariance structure are to be\npredicted with minimum quadratic risk, based upon observing a single\nrealization of the spatial process at a finite number of locations $s_1,\\;\n\\ldots,\\; s_n$ in $S$. Despite the connection of this minimization problem with\nkernel ridge regression, establishing the generalization capacity of empirical\nrisk minimizers is far from straightforward, due to the non i.i.d. nature of\nthe spatial data $X_{s_1},\\; \\ldots,\\; X_{s_n}$ involved. In this article,\nnonasymptotic bounds of order $O_{\\mathbb{P}}(1/n)$ are proved for the excess\nrisk of a plug-in predictive rule mimicking the true minimizer in the case of\nisotropic stationary Gaussian processes observed at locations forming a regular\ngrid. These theoretical results, as well as the role played by the technical\nconditions required to establish them, are illustrated by various numerical\nexperiments and hopefully pave the way for further developments in statistical\nlearning based on spatial data.",
          "link": "http://arxiv.org/abs/2202.07365",
          "publishedOn": "2022-04-14T00:58:51.989Z",
          "wordCount": null,
          "title": "A Statistical Learning View of Simple Kriging. (arXiv:2202.07365v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.10102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Renjue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Pengfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Cheng-Chao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Youcheng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1\">Bai Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>",
          "description": "To analyse local robustness properties of deep neural networks (DNNs), we\npresent a practical framework from a model learning perspective. Based on\nblack-box model learning with scenario optimisation, we abstract the local\nbehaviour of a DNN via an affine model with the probably approximately correct\n(PAC) guarantee. From the learned model, we can infer the corresponding\nPAC-model robustness property. The innovation of our work is the integration of\nmodel learning into PAC robustness analysis: that is, we construct a PAC\nguarantee on the model level instead of sample distribution, which induces a\nmore faithful and accurate robustness evaluation. This is in contrast to\nexisting statistical methods without model learning. We implement our method in\na prototypical tool named DeepPAC. As a black-box method, DeepPAC is scalable\nand efficient, especially when DNNs have complex structures or high-dimensional\ninputs. We extensively evaluate DeepPAC, with 4 baselines (using formal\nverification, statistical methods, testing and adversarial attack) and 20 DNN\nmodels across 3 datasets, including MNIST, CIFAR-10, and ImageNet. It is shown\nthat DeepPAC outperforms the state-of-the-art statistical method PROVERO, and\nit achieves more practical robustness analysis than the formal verification\ntool ERAN. Also, its results are consistent with existing DNN testing work like\nDeepGini.",
          "link": "http://arxiv.org/abs/2101.10102",
          "publishedOn": "2022-04-14T00:58:51.988Z",
          "wordCount": null,
          "title": "Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning. (arXiv:2101.10102v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06375",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Blanke_M/0/1/0/all/0/1\">Matthieu Blanke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lelarge_M/0/1/0/all/0/1\">Marc Lelarge</a>",
          "description": "This work addresses the problem of exploration in an unknown environment. For\nlinear dynamical systems, we use an experimental design framework and introduce\nan online greedy policy where the control maximizes the information of the next\nstep. In a setting with a limited number of experimental trials, our algorithm\nhas low complexity and shows experimentally competitive performances compared\nto more elaborate gradient-based methods.",
          "link": "http://arxiv.org/abs/2204.06375",
          "publishedOn": "2022-04-14T00:58:51.987Z",
          "wordCount": null,
          "title": "Online greedy identification of linear dynamical systems. (arXiv:2204.06375v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06274",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ribeiro_A/0/1/0/all/0/1\">Ant&#xf4;nio H. Ribeiro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1\">Thomas B. Sch&#xf6;n</a>",
          "description": "As machine learning models start to be used in critical applications, their\nvulnerabilities and brittleness become a pressing concern. Adversarial attacks\nare a popular framework for studying these vulnerabilities. In this work, we\nstudy the error of linear regression in the face of adversarial attacks. We\nprovide bounds of the error in terms of the traditional risk and the parameter\nnorm and show how these bounds can be leveraged and make it possible to use\nanalysis from non-adversarial setups to study the adversarial risk. The\nusefulness of these results is illustrated by shedding light on whether or not\noverparameterized linear models can be adversarially robust. We show that\nadding features to linear models might be either a source of additional\nrobustness or brittleness. We show that these differences appear due to scaling\nand how the $\\ell_1$ and $\\ell_2$ norms of random projections concentrate. We\nalso show how the reformulation we propose allows for solving adversarial\ntraining as a convex optimization problem. This is then used as a tool to study\nhow adversarial training and other regularization methods might affect the\nrobustness of the estimated models.",
          "link": "http://arxiv.org/abs/2204.06274",
          "publishedOn": "2022-04-14T00:58:51.986Z",
          "wordCount": null,
          "title": "Overparameterized Linear Regression under Adversarial Attacks. (arXiv:2204.06274v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.15646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Floto_G/0/1/0/all/0/1\">Griffin Floto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kremer_S/0/1/0/all/0/1\">Stefan Kremer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nica_M/0/1/0/all/0/1\">Mihai Nica</a>",
          "description": "An important property for deep neural networks is the ability to perform\nrobust out-of-distribution detection on previously unseen data. This property\nis essential for safety purposes when deploying models for real world\napplications. Recent studies show that probabilistic generative models can\nperform poorly on this task, which is surprising given that they seek to\nestimate the likelihood of training data. To alleviate this issue, we propose\nthe exponentially tilted Gaussian prior distribution for the Variational\nAutoencoder (VAE) which pulls points onto the surface of a hyper-sphere in\nlatent space. This achieves state-of-the art results on the area under the\ncurve-receiver operator characteristics metric using just the log-likelihood\nthat the VAE naturally assigns. Because this prior is a simple modification of\nthe traditional VAE prior, it is faster and easier to implement than\ncompetitive methods.",
          "link": "http://arxiv.org/abs/2111.15646",
          "publishedOn": "2022-04-14T00:58:51.943Z",
          "wordCount": null,
          "title": "The Exponentially Tilted Gaussian Prior for Variational Autoencoders. (arXiv:2111.15646v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06043",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Burkner_P/0/1/0/all/0/1\">Paul-Christian B&#xfc;rkner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kroker_I/0/1/0/all/0/1\">Ilja Kr&#xf6;ker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oladyshkin_S/0/1/0/all/0/1\">Sergey Oladyshkin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nowak_W/0/1/0/all/0/1\">Wolfgang Nowak</a>",
          "description": "Polynomial chaos expansion (PCE) is a versatile tool widely used in\nuncertainty quantification and machine learning, but its successful application\ndepends strongly on the accuracy and reliability of the resulting PCE-based\nresponse surface. High accuracy typically requires high polynomial degrees,\ndemanding many training points especially in high-dimensional problems through\nthe curse of dimensionality. So-called sparse PCE concepts work with a much\nsmaller selection of basis polynomials compared to conventional PCE approaches\nand can overcome the curse of dimensionality very efficiently, but have to pay\nspecific attention to their strategies of choosing training points.\nFurthermore, the approximation error resembles an uncertainty that most\nexisting PCE-based methods do not estimate. In this study, we develop and\nevaluate a fully Bayesian approach to establish the PCE representation via\njoint shrinkage priors and Markov chain Monte Carlo. The suggested Bayesian PCE\nmodel directly aims to solve the two challenges named above: achieving a sparse\nPCE representation and estimating uncertainty of the PCE itself. The embedded\nBayesian regularizing via the joint shrinkage prior allows using higher\npolynomial degrees for given training points due to its ability to handle\nunderdetermined situations, where the number of considered PCE coefficients\ncould be much larger than the number of available training points. We also\nexplore multiple variable selection methods to construct sparse PCE expansions\nbased on the established Bayesian representations, while globally selecting the\nmost meaningful orthonormal polynomials given the available training data. We\ndemonstrate the advantages of our Bayesian PCE and the corresponding\nsparsity-inducing methods on several benchmarks.",
          "link": "http://arxiv.org/abs/2204.06043",
          "publishedOn": "2022-04-14T00:58:51.901Z",
          "wordCount": null,
          "title": "The sparse Polynomial Chaos expansion: a fully Bayesian approach with joint priors on the coefficients and global selection of terms. (arXiv:2204.06043v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06150",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Horowitz_H/0/1/0/all/0/1\">Haim Horowitz</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Rao_P/0/1/0/all/0/1\">Pooja Rao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Radha_S/0/1/0/all/0/1\">Santosh Kumar Radha</a>",
          "description": "Synthetic data generation has proven to be a promising solution for\naddressing data availability issues in various domains. Even more challenging\nis the generation of synthetic time series data, where one has to preserve\ntemporal dynamics, i.e., the generated time series must respect the original\nrelationships between variables across time. Recently proposed techniques such\nas generative adversarial networks (GANs) and quantum-GANs lack the ability to\nattend to the time series specific temporal correlations adequately. We propose\nusing the inherent nature of quantum computers to simulate quantum dynamics as\na technique to encode such features. We start by assuming that a given time\nseries can be generated by a quantum process, after which we proceed to learn\nthat quantum process using quantum machine learning. We then use the learned\nmodel to generate out-of-sample time series and show that it captures unique\nand complex features of the learned time series. We also study the class of\ntime series that can be modeled using this technique. Finally, we\nexperimentally demonstrate the proposed algorithm on an 11-qubit trapped-ion\nquantum machine.",
          "link": "http://arxiv.org/abs/2204.06150",
          "publishedOn": "2022-04-14T00:58:51.901Z",
          "wordCount": null,
          "title": "A quantum generative model for multi-dimensional time series using Hamiltonian learning. (arXiv:2204.06150v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06264",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Levy_T/0/1/0/all/0/1\">Tomer Levy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Abramovich_F/0/1/0/all/0/1\">Felix Abramovich</a>",
          "description": "We consider high-dimensional multiclass classification by sparse multinomial\nlogistic regression. Unlike binary classification, in the multiclass setup one\ncan think about an entire spectrum of possible notions of sparsity associated\nwith different structural assumptions on the regression coefficients matrix. We\npropose a computationally feasible feature selection procedure based on\npenalized maximum likelihood with convex penalties capturing a specific type of\nsparsity at hand. In particular, we consider global sparsity, double row-wise\nsparsity, and low-rank sparsity, and show that with the properly chosen tuning\nparameters the derived plug-in classifiers attain the minimax generalization\nerror bounds (in terms of misclassification excess risk) within the\ncorresponding classes of multiclass sparse linear classifiers. The developed\napproach is general and can be adapted to other types of sparsity as well.",
          "link": "http://arxiv.org/abs/2204.06264",
          "publishedOn": "2022-04-14T00:58:51.900Z",
          "wordCount": null,
          "title": "Generalization Error Bounds for Multiclass Sparse Linear Classifiers. (arXiv:2204.06264v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.08924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1\">Ian Osband</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zheng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asghari_S/0/1/0/all/0/1\">Seyed Mohammad Asghari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwaracherla_V/0/1/0/all/0/1\">Vikranth Dwaracherla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahimi_M/0/1/0/all/0/1\">Morteza Ibrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Effective decision, exploration, and adaptation often require an agent to\nknow what it knows and, also, what it does not know. This capability relies on\nthe quality of \\textit{joint} predictions of labels assigned to multiple\ninputs. Conventional neural networks lack this capability and, since most\nresearch has focused on marginal predictions, this shortcoming has been largely\noverlooked. By assessing the quality of joint predictions it is possible to\ndetermine whether a neural network effectively distinguishes between epistemic\nuncertainty (that due to lack of knowledge) and aleatoric uncertainty (that due\nto chance). We introduce the \\textit{epistemic neural network} (ENN) as a\ngeneral interface for uncertainty modeling in deep learning. While prior\napproaches to uncertainty modeling can be viewed as ENNs, the new interface\nfacilitates comparison of joint predictions, and the design of novel\narchitectures and algorithms. In particular, we introduce the \\textit{epinet}:\nan architecture that can supplement any existing neural network, including\npretrained models, and trained with modest incremental computation to represent\nuncertainty. With an epinet, conventional neural networks outperform very large\nensembles, consisting of hundreds or more particles, with orders of magnitude\nless computation. We demonstrate this efficacy across synthetic data, ImageNet,\nand sequential decision problems. As part of this effort we open-source\nexperiment code.",
          "link": "http://arxiv.org/abs/2107.08924",
          "publishedOn": "2022-04-14T00:58:51.900Z",
          "wordCount": null,
          "title": "Epistemic Neural Networks. (arXiv:2107.08924v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11507",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yuexi Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaji_T/0/1/0/all/0/1\">Tetsuya Kaji</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rockova_V/0/1/0/all/0/1\">Veronika Ro&#x10d;kov&#xe1;</a>",
          "description": "Approximate Bayesian Computation (ABC) enables statistical inference in\nsimulator-based models whose likelihoods are difficult to calculate but easy to\nsimulate from. ABC constructs a kernel-type approximation to the posterior\ndistribution through an accept/reject mechanism which compares summary\nstatistics of real and simulated data. To obviate the need for summary\nstatistics, we directly compare empirical distributions with a Kullback-Leibler\n(KL) divergence estimator obtained via contrastive learning. In particular, we\nblend flexible machine learning classifiers within ABC to automate fake/real\ndata comparisons. We consider the traditional accept/reject kernel as well as\nan exponential weighting scheme which does not require the ABC acceptance\nthreshold. Our theoretical results show that the rate at which our ABC\nposterior distributions concentrate around the true parameter depends on the\nestimation error of the classifier. We derive limiting posterior shape results\nand find that, with a properly scaled exponential kernel, asymptotic normality\nholds. We demonstrate the usefulness of our approach on simulated examples as\nwell as real data in the context of stock volatility estimation.",
          "link": "http://arxiv.org/abs/2111.11507",
          "publishedOn": "2022-04-14T00:58:51.900Z",
          "wordCount": null,
          "title": "Approximate Bayesian Computation via Classification. (arXiv:2111.11507v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06445",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1\">Haibao Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhai_H/0/1/0/all/0/1\">Hongzhi Zhai</a>",
          "description": "Multi-label learning is often used to mine the correlation between variables\nand multiple labels, and its research focuses on fully extracting the\ninformation between variables and labels. The $\\ell_{2,1}$ regularization is\noften used to get a sparse coefficient matrix, but the problem of\nmulticollinearity among variables cannot be effectively solved. In this paper,\nthe proposed model can choose the most relevant variables by solving a joint\nconstraint optimization problem using the $\\ell_{2,1}$ regularization and\nFrobenius regularization. In manifold regularization, we carry out a random\nwalk strategy based on the joint structure to construct a neighborhood graph,\nwhich is highly robust to outliers. In addition, we give an iterative algorithm\nof the proposed method and proved the convergence of this algorithm. The\nexperiments on the real-world data sets also show that the comprehensive\nperformance of our method is consistently better than the classical method.",
          "link": "http://arxiv.org/abs/2204.06445",
          "publishedOn": "2022-04-14T00:58:51.899Z",
          "wordCount": null,
          "title": "Random Graph Embedding and Joint Sparse Regularization for Multi-label Feature Selection. (arXiv:2204.06445v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.07084",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Osa_T/0/1/0/all/0/1\">Takayuki Osa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tangkaratt_V/0/1/0/all/0/1\">Voot Tangkaratt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Reinforcement learning algorithms are typically limited to learning a single\nsolution for a specified task, even though diverse solutions often exist.\nRecent studies showed that learning a set of diverse solutions is beneficial\nbecause diversity enables robust few-shot adaptation. Although existing methods\nlearn diverse solutions by using the mutual information as unsupervised\nrewards, such an approach often suffers from the bias of the gradient estimator\ninduced by value function approximation. In this study, we propose a novel\nmethod that can learn diverse solutions without suffering the bias problem. In\nour method, a policy conditioned on a continuous or discrete latent variable is\ntrained by directly maximizing the variational lower bound of the mutual\ninformation, instead of using the mutual information as unsupervised rewards as\nin previous studies. Through extensive experiments on robot locomotion tasks,\nwe demonstrate that the proposed method successfully learns an infinite set of\ndiverse solutions by learning continuous latent variables, which is more\nchallenging than learning a finite number of solutions. Subsequently, we show\nthat our method enables more effective few-shot adaptation compared with\nexisting methods.",
          "link": "http://arxiv.org/abs/2103.07084",
          "publishedOn": "2022-04-14T00:58:51.899Z",
          "wordCount": null,
          "title": "Discovering Diverse Solutions in Deep Reinforcement Learning by Maximizing State-Action-Based Mutual Information. (arXiv:2103.07084v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06270",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Sahlstrom_T/0/1/0/all/0/1\">Teemu Sahlstr&#xf6;m</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tarvainen_T/0/1/0/all/0/1\">Tanja Tarvainen</a>",
          "description": "There has been an increasing interest in utilizing machine learning methods\nin inverse problems and imaging. Most of the work has, however, concentrated on\nimage reconstruction problems, and the number of studies regarding the full\nsolution of the inverse problem is limited. In this work, we study a machine\nlearning based approach for the Bayesian inverse problem of photoacoustic\ntomography. We develop an approach for estimating the posterior distribution in\nphotoacoustic tomography using an approach based on the variational\nautoencoder. The approach is evaluated with numerical simulations and compared\nto the solution of the inverse problem using a Bayesian approach.",
          "link": "http://arxiv.org/abs/2204.06270",
          "publishedOn": "2022-04-14T00:58:51.898Z",
          "wordCount": null,
          "title": "Utilizing variational autoencoders in the Bayesian inverse problem of photoacoustic tomography. (arXiv:2204.06270v1 [physics.comp-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.06476",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Waudby_Smith_I/0/1/0/all/0/1\">Ian Waudby-Smith</a>, <a href=\"http://arxiv.org/find/math/1/au:+Arbour_D/0/1/0/all/0/1\">David Arbour</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sinha_R/0/1/0/all/0/1\">Ritwik Sinha</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kennedy_E/0/1/0/all/0/1\">Edward H. Kennedy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "This work introduces time-uniform analogues of confidence intervals based on\nthe central limit theorem (CLT). Our methods take the form of confidence\nsequences (CS) -- sequences of confidence intervals that are uniformly valid\nover time. CSs provide valid inference at arbitrary stopping times, incurring\nno penalties for \"peeking\" at the data, unlike classical confidence intervals\nwhich require the sample size to be fixed in advance. Existing CSs in the\nliterature are nonasymptotic, requiring strong assumptions on the data, while\nthe classical (fixed-time) CLT is ubiquitous due to the weak assumptions it\nimposes. Our work bridges the gap by introducing time-uniform CSs that only\nrequire CLT-like assumptions. While the CLT approximates the distribution of a\nsample average by that of a Gaussian at a fixed sample size, we use strong\ninvariance principles like the seminal work of Koml\\'os, Major, and Tusn\\'ady\nto uniformly approximate the entire sample average process by an implicit\nBrownian motion. Applying Robbins' normal mixture martingale method to this\nBrownian motion then yields closed-form time-uniform boundaries. We combine\nthese boundaries with doubly robust estimators to derive nonparametric CSs for\nthe average treatment effect (and other causal estimands). These allow\nrandomized experiments and observational studies to be continuously monitored\nand adaptively stopped, all while controlling the type-I error.",
          "link": "http://arxiv.org/abs/2103.06476",
          "publishedOn": "2022-04-14T00:58:51.898Z",
          "wordCount": null,
          "title": "Time-uniform central limit theory with applications to anytime-valid causal inference. (arXiv:2103.06476v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannan_H/0/1/0/all/0/1\">Harish Kannan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cloninger_A/0/1/0/all/0/1\">Alexander Cloninger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saab_R/0/1/0/all/0/1\">Rayan Saab</a>",
          "description": "We propose the use of low bit-depth Sigma-Delta and distributed noise-shaping\nmethods for quantizing the Random Fourier features (RFFs) associated with\nshift-invariant kernels. We prove that our quantized RFFs -- even in the case\nof $1$-bit quantization -- allow a high accuracy approximation of the\nunderlying kernels, and the approximation error decays at least polynomially\nfast as the dimension of the RFFs increases. We also show that the quantized\nRFFs can be further compressed, yielding an excellent trade-off between memory\nuse and accuracy. Namely, the approximation error now decays exponentially as a\nfunction of the bits used. Moreover, we empirically show by testing the\nperformance of our methods on several machine learning tasks that our method\ncompares favorably to other state of the art quantization methods in this\ncontext.",
          "link": "http://arxiv.org/abs/2106.02614",
          "publishedOn": "2022-04-14T00:58:51.898Z",
          "wordCount": null,
          "title": "Sigma-Delta and Distributed Noise-Shaping Quantization Methods for Random Fourier Features. (arXiv:2106.02614v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1902.07190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perea_J/0/1/0/all/0/1\">Jose A. Perea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munch_E/0/1/0/all/0/1\">Elizabeth Munch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasawneh_F/0/1/0/all/0/1\">Firas A. Khasawneh</a>",
          "description": "The persistence diagram is an increasingly useful tool from Topological Data\nAnalysis, but its use alongside typical machine learning techniques requires\nmathematical finesse. The most success to date has come from methods that map\npersistence diagrams into vector spaces, in a way which maximizes the structure\npreserved. This process is commonly referred to as featurization. In this\npaper, we describe a mathematical framework for featurization called\n\\emph{template functions}, and we show that it addresses the problem of\napproximating continuous functions on compact subsets of the space of\npersistence diagrams. Specifically, we begin by characterizing relative\ncompactness with respect to the bottleneck distance, and then provide explicit\ntheoretical methods for constructing compact-open dense subsets of continuous\nfunctions on persistence diagrams. These dense subsets -- obtained via template\nfunctions -- are leveraged for supervised learning tasks with persistence\ndiagrams. Specifically, we test the method for classification and regression\nalgorithms on several examples including shape data and dynamical systems.",
          "link": "http://arxiv.org/abs/1902.07190",
          "publishedOn": "2022-04-14T00:58:51.897Z",
          "wordCount": null,
          "title": "Approximating Continuous Functions on Persistence Diagrams Using Template Functions. (arXiv:1902.07190v3 [cs.CG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.05848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changjun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaomo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xudong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuhua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaofang Wang</a>",
          "description": "The demand of probabilistic time series forecasting has been recently raised\nin various dynamic system scenarios, for example, system identification and\nprognostic and health management of machines. To this end, we combine the\nadvances in both deep generative models and state space model (SSM) to come up\nwith a novel, data-driven deep probabilistic sequence model. Specifically, we\nfollow the popular encoder-decoder generative structure to build the recurrent\nneural networks (RNN) assisted variational sequence model on an augmented\nrecurrent input space, which could induce rich stochastic sequence dependency.\nBesides, in order to alleviate the inconsistency issue of the posterior between\ntraining and predicting as well as improving the mining of dynamic patterns, we\n(i) propose using a lagged hybrid output as input for the posterior at next\ntime step, which brings training and predicting into alignment; and (ii)\nfurther devise a generalized auto-regressive strategy that encodes all the\nhistorical dependencies for the posterior. Thereafter, we first investigate the\nmethodological characteristics of the proposed deep probabilistic sequence\nmodel on toy cases, and then comprehensively demonstrate the superiority of our\nmodel against existing deep probabilistic SSM models through extensive\nnumerical experiments on eight system identification benchmarks from various\ndynamic systems. Finally, we apply our sequence model to a real-world\ncentrifugal compressor forecasting problem, and again verify its outstanding\nperformance by quantifying the time series predictive distribution.",
          "link": "http://arxiv.org/abs/2106.05848",
          "publishedOn": "2022-04-14T00:58:51.897Z",
          "wordCount": null,
          "title": "Deep Probabilistic Time Series Forecasting using Augmented Recurrent Input for Dynamic Systems. (arXiv:2106.05848v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1810.03730",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walder_C/0/1/0/all/0/1\">Christian Walder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1\">Marian-Andrei Rizoiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lexing Xie</a>",
          "description": "In this paper, we develop an efficient nonparametric Bayesian estimation of\nthe kernel function of Hawkes processes. The non-parametric Bayesian approach\nis important because it provides flexible Hawkes kernels and quantifies their\nuncertainty. Our method is based on the cluster representation of Hawkes\nprocesses. Utilizing the finite support assumption of the Hawkes process, we\nefficiently sample random branching structures and thus, we split the Hawkes\nprocess into clusters of Poisson processes. We derive two algorithms -- a block\nGibbs sampler and a maximum a posteriori estimator based on expectation\nmaximization -- and we show that our methods have a linear time complexity,\nboth theoretically and empirically. On synthetic data, we show our methods to\nbe able to infer flexible Hawkes triggering kernels. On two large-scale Twitter\ndiffusion datasets, we show that our methods outperform the current\nstate-of-the-art in goodness-of-fit and that the time complexity is linear in\nthe size of the dataset. We also observe that on diffusions related to online\nvideos, the learned kernels reflect the perceived longevity for different\ncontent types such as music or pets videos.",
          "link": "http://arxiv.org/abs/1810.03730",
          "publishedOn": "2022-04-14T00:58:51.823Z",
          "wordCount": null,
          "title": "Efficient Non-parametric Bayesian Hawkes Processes. (arXiv:1810.03730v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06242",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qoku_A/0/1/0/all/0/1\">Arber Qoku</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Buettner_F/0/1/0/all/0/1\">Florian Buettner</a>",
          "description": "Many real-world systems are described not only by data from a single source\nbut via multiple data views. For example, in genomic medicine, a patient can be\ndescribed by data from different molecular layers. This raises the need for\nmulti-view models that are able to disentangle variation within and across data\nviews in an interpretable manner. Latent variable models with structured\nsparsity are a commonly used tool to address this modeling task but\ninterpretability is cumbersome since it requires a direct inspection and\ninterpretation of each factor via a specialized domain expert. Here, we propose\nMuVI, a novel approach for domain-informed multi-view latent variable models,\nfacilitating the analysis of multi-view data in an inherently explainable\nmanner. We demonstrate that our model (i) is able to integrate noisy domain\nexpertise in form of feature sets, (ii) is robust to noise in the encoded\ndomain knowledge, (iii) results in identifiable factors and (iv) is able to\ninfer interpretable and biologically meaningful axes of variation in a\nreal-world multi-view dataset of cancer patients.",
          "link": "http://arxiv.org/abs/2204.06242",
          "publishedOn": "2022-04-14T00:58:51.777Z",
          "wordCount": null,
          "title": "Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity. (arXiv:2204.06242v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06540",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Papacharalampous_G/0/1/0/all/0/1\">Georgia Papacharalampous</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tyralis_H/0/1/0/all/0/1\">Hristos Tyralis</a>",
          "description": "Regression-based frameworks for streamflow regionalization are built around\ncatchment attributes that traditionally originate from catchment hydrology,\nflood frequency analysis and their interplay. In this work, we deviated from\nthis traditional path by formulating and extensively investigating the first\nregression-based streamflow regionalization frameworks that largely emerge from\ngeneral-purpose time series features for data science and, more precisely, from\na large variety of such features. We focused on 28 features that included\n(partial) autocorrelation, entropy, temporal variation, seasonality, trend,\nlumpiness, stability, nonlinearity, linearity, spikiness, curvature and others.\nWe estimated these features for daily temperature, precipitation and streamflow\ntime series from 511 catchments, and then merged them within regionalization\ncontexts with traditional topographic, land cover, soil and geologic\nattributes. Precipitation and temperature features (e.g., the spectral entropy,\nseasonality strength and lag-1 autocorrelation of the precipitation time\nseries, and the stability and trend strength of the temperature time series)\nwere found to be useful predictors of many streamflow features. The same\napplies to traditional attributes, such as the catchment mean elevation.\nRelationships between predictor and dependent variables were also revealed,\nwhile the spectral entropy, the seasonality strength and several\nautocorrelation features of the streamflow time series were found to be more\nregionalizable than others.",
          "link": "http://arxiv.org/abs/2204.06540",
          "publishedOn": "2022-04-14T00:58:51.589Z",
          "wordCount": null,
          "title": "Time series features for supporting hydrometeorological explorations and predictions in ungauged locations using large datasets. (arXiv:2204.06540v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06108",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Richardson_N/0/1/0/all/0/1\">Nicholas Richardson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schaeffer_H/0/1/0/all/0/1\">Hayden Schaeffer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tran_G/0/1/0/all/0/1\">Giang Tran</a>",
          "description": "Signal decomposition and multiscale signal analysis provide many useful tools\nfor time-frequency analysis. We proposed a random feature method for analyzing\ntime-series data by constructing a sparse approximation to the spectrogram. The\nrandomization is both in the time window locations and the frequency sampling,\nwhich lowers the overall sampling and computational cost. The sparsification of\nthe spectrogram leads to a sharp separation between time-frequency clusters\nwhich makes it easier to identify intrinsic modes, and thus leads to a new\ndata-driven mode decomposition. The applications include signal representation,\noutlier removal, and mode decomposition. On the benchmark tests, we show that\nour approach outperforms other state-of-the-art decomposition methods.",
          "link": "http://arxiv.org/abs/2204.06108",
          "publishedOn": "2022-04-14T00:58:51.579Z",
          "wordCount": null,
          "title": "SRMD: Sparse Random Mode Decomposition. (arXiv:2204.06108v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Josifoski_M/0/1/0/all/0/1\">Martin Josifoski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_N/0/1/0/all/0/1\">Nicola De Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1\">Maxime Peyrard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petroni_F/0/1/0/all/0/1\">Fabio Petroni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>",
          "description": "Structured and grounded representation of text is typically formalized by\nclosed information extraction, the problem of extracting an exhaustive set of\n(subject, relation, object) triplets that are consistent with a predefined set\nof entities and relations from a knowledge base schema. Most existing works are\npipelines prone to error accumulation, and all approaches are only applicable\nto unrealistically small numbers of entities and relations. We introduce GenIE\n(generative information extraction), the first end-to-end autoregressive\nformulation of closed information extraction. GenIE naturally exploits the\nlanguage knowledge from the pre-trained transformer by autoregressively\ngenerating relations and entities in textual form. Thanks to a new bi-level\nconstrained generation strategy, only triplets consistent with the predefined\nknowledge base schema are produced. Our experiments show that GenIE is\nstate-of-the-art on closed information extraction, generalizes from fewer\ntraining data points than baselines, and scales to a previously unmanageable\nnumber of entities and relations. With this work, closed information extraction\nbecomes practical in realistic scenarios, providing new opportunities for\ndownstream tasks. Finally, this work paves the way towards a unified end-to-end\napproach to the core tasks of information extraction. Code, data and models\navailable at https://github.com/epfl-dlab/GenIE.",
          "link": "http://arxiv.org/abs/2112.08340",
          "publishedOn": "2022-04-14T00:58:51.579Z",
          "wordCount": null,
          "title": "GenIE: Generative Information Extraction. (arXiv:2112.08340v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12363",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saad_F/0/1/0/all/0/1\">Feras A. Saad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cusumano_Towner_M/0/1/0/all/0/1\">Marco Cusumano-Towner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mansinghka_V/0/1/0/all/0/1\">Vikash K. Mansinghka</a>",
          "description": "Estimating information-theoretic quantities such as entropy and mutual\ninformation is central to many problems in statistics and machine learning, but\nchallenging in high dimensions. This paper presents estimators of entropy via\ninference (EEVI), which deliver upper and lower bounds on many information\nquantities for arbitrary variables in a probabilistic generative model. These\nestimators use importance sampling with proposal distribution families that\ninclude amortized variational inference and sequential Monte Carlo, which can\nbe tailored to the target model and used to squeeze true information values\nwith high accuracy. We present several theoretical properties of EEVI and\ndemonstrate scalability and efficacy on two problems from the medical domain:\n(i) in an expert system for diagnosing liver disorders, we rank medical tests\naccording to how informative they are about latent diseases, given a pattern of\nobserved symptoms and patient attributes; and (ii) in a differential equation\nmodel of carbohydrate metabolism, we find optimal times to take blood glucose\nmeasurements that maximize information about a diabetic patient's insulin\nsensitivity, given their meal and medication schedule.",
          "link": "http://arxiv.org/abs/2202.12363",
          "publishedOn": "2022-04-14T00:58:51.503Z",
          "wordCount": null,
          "title": "Estimators of Entropy and Information via Inference in Probabilistic Models. (arXiv:2202.12363v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.01808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Isacchini_G/0/1/0/all/0/1\">Giulio Isacchini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spisak_N/0/1/0/all/0/1\">Natanael Spisak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourmohammad_A/0/1/0/all/0/1\">Armita Nourmohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mora_T/0/1/0/all/0/1\">Thierry Mora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walczak_A/0/1/0/all/0/1\">Aleksandra M. Walczak</a>",
          "description": "Simulation-based inference enables learning the parameters of a model even\nwhen its likelihood cannot be computed in practice. One class of methods uses\ndata simulated with different parameters to infer models of the\nlikelihood-to-evidence ratio, or equivalently the posterior function. Here we\nframe the inference task as an estimation of an energy function parametrized\nwith an artificial neural network. We present an intuitive approach where the\noptimal model of the likelihood-to-evidence ratio is found by maximizing the\nlikelihood of simulated data. Within this framework, the connection between the\ntask of simulation-based inference and mutual information maximization is\nclear, and we show how several known methods of posterior estimation relate to\nalternative lower bounds to mutual information. These distinct objective\nfunctions aim at the same optimal energy form and therefore can be directly\nbenchmarked. We compare their accuracy in the inference of model parameters,\nfocusing on four dynamical systems that encompass common challenges in time\nseries analysis: dynamics driven by multiplicative noise, nonlinear\ninteractions, chaotic behavior, and high-dimensional parameter space.",
          "link": "http://arxiv.org/abs/2106.01808",
          "publishedOn": "2022-04-11T00:52:26.948Z",
          "wordCount": 653,
          "title": "MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood Inference from Sampled Trajectories. (arXiv:2106.01808v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.02445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shevkunov_K/0/1/0/all/0/1\">Kirill Shevkunov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1\">Liudmila Prokhorenkova</a>",
          "description": "Various non-trivial spaces are becoming popular for embedding structured data\nsuch as graphs, texts, or images. Following spherical and hyperbolic spaces,\nmore general product spaces have been proposed. However, searching for the best\nconfiguration of product space is a resource-intensive procedure, which reduces\nthe practical applicability of the idea. We generalize the concept of product\nspace and introduce an overlapping space that does not have the configuration\nsearch problem. The main idea is to allow subsets of coordinates to be shared\nbetween spaces of different types (Euclidean, hyperbolic, spherical). As a\nresult, parameter optimization automatically learns the optimal configuration.\nAdditionally, overlapping spaces allow for more compact representations since\ntheir geometry is more complex. Our experiments confirm that overlapping spaces\noutperform the competitors in graph embedding tasks. Here, we consider both\ndistortion setup, where the aim is to preserve distances, and ranking setup,\nwhere the relative order should be preserved. The proposed method effectively\nsolves the problem and outperforms the competitors in both settings. We also\nperform an empirical analysis in a realistic information retrieval task, where\nwe compare all spaces by incorporating them into DSSM. In this case, the\nproposed overlapping space consistently achieves nearly optimal results without\nany configuration tuning. This allows for reducing training time, which can be\nsignificant in large-scale applications.",
          "link": "http://arxiv.org/abs/2007.02445",
          "publishedOn": "2022-04-11T00:52:26.939Z",
          "wordCount": 697,
          "title": "Overlapping Spaces for Compact Graph Representations. (arXiv:2007.02445v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "The noise transition matrix plays a central role in the problem of learning\nfrom noisy labels. Among many other reasons, a significant number of existing\nsolutions rely on access to it. Estimating the transition matrix without using\nground truth labels is a critical and challenging task. When label noise\ntransition depends on each instance, the problem of identifying the\ninstance-dependent noise transition matrix becomes substantially more\nchallenging. Despite recent works proposing solutions for learning from\ninstance-dependent noisy labels, we lack a unified understanding of when such a\nproblem remains identifiable, and therefore learnable. This paper seeks to\nprovide answers to a sequence of related questions: What are the primary\nfactors that contribute to the identifiability of a noise transition matrix?\nCan we explain the observed empirical successes? When a problem is not\nidentifiable, what can we do to make it so? We will relate our theoretical\nfindings to the literature and hope to provide guidelines for developing\neffective solutions for battling instance-dependent label noise.",
          "link": "http://arxiv.org/abs/2202.02016",
          "publishedOn": "2022-04-11T00:52:26.931Z",
          "wordCount": 621,
          "title": "Identifiability of Label Noise Transition Matrix. (arXiv:2202.02016v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.04888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Cameron Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Christopher Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasuda_T/0/1/0/all/0/1\">Taisuke Yasuda</a>",
          "description": "We study active sampling algorithms for linear regression, which aim to query\nonly a few entries of a target vector $b\\in\\mathbb R^n$ and output a near\nminimizer to $\\min_{x\\in\\mathbb R^d} \\|Ax-b\\|$, for a design matrix\n$A\\in\\mathbb R^{n \\times d}$ and loss $\\|\\cdot\\|$.\n\nFor $p$ norm regression for any $0<p<\\infty$, we give an algorithm based on\nLewis weight sampling outputting a $(1+\\epsilon)$-approximate solution using\njust $\\tilde O(d/\\epsilon^2)$ queries to $b$ for $p\\in(0,1)$,\n$\\tilde{O}(d/\\epsilon)$ queries for $1<p<2$, and\n$\\tilde{O}(d^{p/2}/\\epsilon^p)$ queries for $2<p<\\infty$. For $0<p<2$, our\nbounds are optimal up to log factors, settling the query complexity for this\nrange. For $2<p<\\infty$, our dependence on $d$ is optimal, while our dependence\non $\\epsilon$ is off by at most $\\epsilon$, up to log factors. Our result\nresolves an open question of [CD21], who gave near optimal bounds for the $1$\nnorm, but required $d^2/\\epsilon^2$ samples for $\\ell_p$ regression with\n$1<p<2$, and gave no bounds for $2<p<\\infty$ or $0<p<1$.\n\nWe also give the first total sensitivity bound of\n$O(d^{\\max\\{1,p/2\\}}\\log^2n)$ for loss functions of degree $p$ polynomial\ngrowth, improving a result of [TMF20]. By combining this with our techniques\nfor $\\ell_p$ regression, we obtain an active regression algorithm making\n$\\tilde O(d^{1+\\max\\{1,p/2\\}}/\\mathrm{poly}(\\epsilon))$ queries for such loss\nfunctions, including the Tukey and Huber losses, answering another question of\n[CD21]. For the Huber loss, we further improve our bound to $\\tilde\nO(d^{4-2\\sqrt2}/\\mathrm{poly}(\\epsilon))$ samples. Our sensitivity bounds also\nhave many applications, including Orlicz norm subspace embeddings, robust\nsubspace approximation, and dimension reduction for smoothed $p$-norms.\n\nFinally, our active sampling results give the first sublinear time algorithms\nfor Kronecker product regression under every $p$ norm.",
          "link": "http://arxiv.org/abs/2111.04888",
          "publishedOn": "2022-04-11T00:52:26.924Z",
          "wordCount": 761,
          "title": "Active Linear Regression for $\\ell_p$ Norms and Beyond. (arXiv:2111.04888v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00464",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_C/0/1/0/all/0/1\">Chris Junchi Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Loizou_N/0/1/0/all/0/1\">Nicolas Loizou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>, <a href=\"http://arxiv.org/find/math/1/au:+Roux_N/0/1/0/all/0/1\">Nicolas Le Roux</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We study the stochastic bilinear minimax optimization problem, presenting an\nanalysis of the same-sample Stochastic ExtraGradient (SEG) method with constant\nstep size, and presenting variations of the method that yield favorable\nconvergence. In sharp contrasts with the basic SEG method whose last iterate\nonly contracts to a fixed neighborhood of the Nash equilibrium, SEG augmented\nwith iteration averaging provably converges to the Nash equilibrium under the\nsame standard settings, and such a rate is further improved by incorporating a\nscheduled restarting procedure. In the interpolation setting where noise\nvanishes at the Nash equilibrium, we achieve an optimal convergence rate up to\ntight constants. We present numerical experiments that validate our theoretical\nfindings and demonstrate the effectiveness of the SEG method when equipped with\niteration averaging and restarting.",
          "link": "http://arxiv.org/abs/2107.00464",
          "publishedOn": "2022-04-11T00:52:26.916Z",
          "wordCount": 647,
          "title": "On the Convergence of Stochastic Extragradient for Bilinear Games using Restarted Iteration Averaging. (arXiv:2107.00464v4 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.10439",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_A/0/1/0/all/0/1\">Alexander Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_A/0/1/0/all/0/1\">Andrew H. Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bilgic_B/0/1/0/all/0/1\">Berkin Bilgic</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ba_D/0/1/0/all/0/1\">Demba Ba</a>",
          "description": "Sparse Bayesian learning (SBL) is a powerful framework for tackling the\nsparse coding problem while also providing uncertainty quantification. The most\npopular inference algorithms for SBL exhibit prohibitively large computational\ncosts for high-dimensional problems due to the need to maintain a large\ncovariance matrix. To resolve this issue, we introduce a new method for\naccelerating SBL inference -- named covariance-free expectation maximization\n(CoFEM) -- that avoids explicit computation of the covariance matrix. CoFEM\nsolves multiple linear systems to obtain unbiased estimates of the posterior\nstatistics needed by SBL. This is accomplished by exploiting innovations from\nnumerical linear algebra such as preconditioned conjugate gradient and a\nlittle-known diagonal estimation rule. For a large class of compressed sensing\nmatrices, we provide theoretical justifications for why our method scales well\nin high-dimensional settings. Through simulations, we show that CoFEM can be up\nto thousands of times faster than existing baselines without sacrificing coding\naccuracy. Through applications to calcium imaging deconvolution and\nmulti-contrast MRI reconstruction, we show that CoFEM enables SBL to tractably\ntackle high-dimensional sparse coding problems of practical interest.",
          "link": "http://arxiv.org/abs/2105.10439",
          "publishedOn": "2022-04-11T00:52:26.898Z",
          "wordCount": 635,
          "title": "Covariance-Free Sparse Bayesian Learning. (arXiv:2105.10439v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03771",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Min_J/0/1/0/all/0/1\">Joosung Min</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Elliott_L/0/1/0/all/0/1\">Lloyd T. Elliott</a>",
          "description": "$Q$-learning is the most fundamental model-free reinforcement learning\nalgorithm. Deployment of $Q$-learning requires approximation of the\nstate-action value function (also known as the $Q$-function). In this work, we\nprovide online random forests as $Q$-function approximators and propose a novel\nmethod wherein the random forest is grown as learning proceeds (through\nexpanding forests). We demonstrate improved performance of our methods over\nstate-of-the-art Deep $Q$-Networks in two OpenAI gyms (`blackjack' and\n`inverted pendulum') but not in the `lunar lander' gym. We suspect that the\nresilience to overfitting enjoyed by random forests recommends our method for\ncommon tasks that do not require a strong representation of the problem domain.\nWe show that expanding forests (in which the number of trees increases as data\ncomes in) improve performance, suggesting that expanding forests are viable for\nother applications of online random forests beyond the reinforcement learning\nsetting.",
          "link": "http://arxiv.org/abs/2204.03771",
          "publishedOn": "2022-04-11T00:52:26.891Z",
          "wordCount": 563,
          "title": "Q-learning with online random forests. (arXiv:2204.03771v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00594",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zaiem_S/0/1/0/all/0/1\">Salah Zaiem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1\">Titouan Parcollet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Essid_S/0/1/0/all/0/1\">Slim Essid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heba_A/0/1/0/all/0/1\">Abdel Heba</a>",
          "description": "Through solving pretext tasks, self-supervised learning leverages unlabeled\ndata to extract useful latent representations replacing traditional input\nfeatures in the downstream task. In audio/speech signal processing, a wide\nrange of features where engineered through decades of research efforts. As it\nturns out, learning to predict such features (a.k.a pseudo-labels) has proven\nto be a particularly relevant pretext task, leading to useful self-supervised\nrepresentations which prove to be effective for downstream tasks. However,\nmethods and common practices for combining such pretext tasks for better\nperformance on the downstream task have not been explored and understood\nproperly. In fact, the process relies almost exclusively on a computationally\nheavy experimental procedure, which becomes intractable with the increase of\nthe number of pretext tasks. This paper introduces a method to select a group\nof pretext tasks among a set of candidates. The method we propose estimates\ncalibrated weights for the partial losses corresponding to the considered\npretext tasks during the self-supervised training process. The experiments\nconducted on automatic speech recognition, speaker and emotion recognition\nvalidate our approach, as the groups selected and weighted with our method\nperform better than classic baselines, thus facilitating the selection and\ncombination of relevant pseudo-labels for self-supervised representation\nlearning.",
          "link": "http://arxiv.org/abs/2107.00594",
          "publishedOn": "2022-04-11T00:52:26.883Z",
          "wordCount": 690,
          "title": "Pretext Tasks selection for multitask self-supervised speech representation learning. (arXiv:2107.00594v4 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sitan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Anru R. Zhang</a>",
          "description": "We consider the problem of learning high dimensional polynomial\ntransformations of Gaussians. Given samples of the form $p(x)$, where $x\\sim\nN(0, \\mathrm{Id}_r)$ is hidden and $p: \\mathbb{R}^r \\to \\mathbb{R}^d$ is a\nfunction where every output coordinate is a low-degree polynomial, the goal is\nto learn the distribution over $p(x)$. This problem is natural in its own\nright, but is also an important special case of learning deep generative\nmodels, namely pushforwards of Gaussians under two-layer neural networks with\npolynomial activations. Understanding the learnability of such generative\nmodels is crucial to understanding why they perform so well in practice.\n\nOur first main result is a polynomial-time algorithm for learning quadratic\ntransformations of Gaussians in a smoothed setting. Our second main result is a\npolynomial-time algorithm for learning constant-degree polynomial\ntransformations of Gaussian in a smoothed setting, when the rank of the\nassociated tensors is small. In fact our results extend to any\nrotation-invariant input distribution, not just Gaussian. These are the first\nend-to-end guarantees for learning a pushforward under a neural network with\nmore than one layer.\n\nAlong the way, we also give the first polynomial-time algorithms with\nprovable guarantees for tensor ring decomposition, a popular generalization of\ntensor decomposition that is used in practice to implicitly store large\ntensors.",
          "link": "http://arxiv.org/abs/2204.04209",
          "publishedOn": "2022-04-11T00:52:26.875Z",
          "wordCount": 641,
          "title": "Learning Polynomial Transformations. (arXiv:2204.04209v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.05097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Do_M/0/1/0/all/0/1\">Manh Tuan Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1\">Noseong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1\">Kijung Shin</a>",
          "description": "Graph neural networks (GNNs) have received massive attention in the field of\nmachine learning on graphs. Inspired by the success of neural networks, a line\nof research has been conducted to train GNNs to deal with various tasks, such\nas node classification, graph classification, and link prediction. In this\nwork, our task of interest is graph classification. Several GNN models have\nbeen proposed and shown great accuracy in this task. However, the question is\nwhether usual training methods fully realize the capacity of the GNN models.\n\nIn this work, we propose a two-stage training framework based on triplet\nloss. In the first stage, GNN is trained to map each graph to a Euclidean-space\nvector so that graphs of the same class are close while those of different\nclasses are mapped far apart. Once graphs are well-separated based on labels, a\nclassifier is trained to distinguish between different classes. This method is\ngeneric in the sense that it is compatible with any GNN model. By adapting five\nGNN models to our method, we demonstrate the consistent improvement in accuracy\nand utilization of each GNN's allocated capacity over the original training\nmethod of each model up to 5.4\\% points in 12 datasets.",
          "link": "http://arxiv.org/abs/2011.05097",
          "publishedOn": "2022-04-11T00:52:26.867Z",
          "wordCount": 684,
          "title": "Two-stage Training of Graph Neural Networks for Graph Classification. (arXiv:2011.05097v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.00246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1\">Hong Jun Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Deep learning has proven effective across a range of data sets. In light of\nthis, a natural inquiry is: \"for what data generating processes can deep\nlearning succeed?\" In this work, we study the sample complexity of learning\nmultilayer data generating processes of a sort for which deep neural networks\nseem to be suited. We develop general and elegant information-theoretic tools\nthat accommodate analysis of any data generating process -- shallow or deep,\nparametric or nonparametric, noiseless or noisy. We then use these tools to\ncharacterize the dependence of sample complexity on the depth of multilayer\nprocesses. Our results indicate roughly linear dependence on depth. This is in\ncontrast to previous results that suggest exponential or high-order polynomial\ndependence.",
          "link": "http://arxiv.org/abs/2203.00246",
          "publishedOn": "2022-04-11T00:52:26.848Z",
          "wordCount": 585,
          "title": "Sample Complexity versus Depth: An Information Theoretic Analysis. (arXiv:2203.00246v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2003.09040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kensen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bieber_D/0/1/0/all/0/1\">David Bieber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rishabh Singh</a>",
          "description": "The success and popularity of deep learning is on the rise, partially due to\npowerful deep learning frameworks such as TensorFlow and PyTorch that make it\neasier to develop deep learning models. However, these libraries also come with\nsteep learning curves, since programming in these frameworks is quite different\nfrom traditional imperative programming with explicit loops and conditionals.\nIn this work, we present a tool called TF-Coder for programming by example in\nTensorFlow. TF-Coder uses a bottom-up weighted enumerative search, with\nvalue-based pruning of equivalent expressions and flexible type- and\nvalue-based filtering to ensure that expressions adhere to various requirements\nimposed by the TensorFlow library. We train models to predict TensorFlow\noperations from features of the input and output tensors and natural language\ndescriptions of tasks, to prioritize relevant operations during search.\nTF-Coder solves 63 of 70 real-world tasks within 5 minutes, sometimes finding\nsimpler solutions in less time compared to experienced human programmers.",
          "link": "http://arxiv.org/abs/2003.09040",
          "publishedOn": "2022-04-11T00:52:26.839Z",
          "wordCount": 664,
          "title": "TF-Coder: Program Synthesis for Tensor Manipulations. (arXiv:2003.09040v4 [cs.PL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.00632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pauli_P/0/1/0/all/0/1\">Patricia Pauli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funcke_N/0/1/0/all/0/1\">Niklas Funcke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gramlich_D/0/1/0/all/0/1\">Dennis Gramlich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Msalmi_M/0/1/0/all/0/1\">Mohamed Amine Msalmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allgower_F/0/1/0/all/0/1\">Frank Allg&#xf6;wer</a>",
          "description": "This paper is concerned with the training of neural networks (NNs) under\nsemidefinite constraints, which allows for NN training with robustness and\nstability guarantees. In particular, we set up an efficient and scalable\ntraining scheme for NN training problems of this kind based on interior point\nmethods, while we also exploit the structure of the underlying matrix\nconstraint. We apply our training scheme to several relevant examples that have\nbeen studied in the literature and newly present the application of the method\nto the training of Wasserstein generative adversarial networks (WGANs). In\nnumerical examples, we show the superiority of our method and its applicability\nto WGAN training.",
          "link": "http://arxiv.org/abs/2201.00632",
          "publishedOn": "2022-04-11T00:52:26.832Z",
          "wordCount": 583,
          "title": "Neural network training under semidefinite constraints. (arXiv:2201.00632v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.06170",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lin_Q/0/1/0/all/0/1\">Qiaohui Lin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lunde_R/0/1/0/all/0/1\">Robert Lunde</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sarkar_P/0/1/0/all/0/1\">Purnamrita Sarkar</a>",
          "description": "We propose a new class of multiplier bootstraps for count functionals,\nranging from a fast, approximate linear bootstrap tailored to sparse, massive\ngraphs to a quadratic bootstrap procedure that offers refined accuracy for\nsmaller, denser graphs. For the fast, approximate linear bootstrap, we show\nthat $\\sqrt{n}$-consistent inference of the count functional is attainable in\ncertain computational regimes that depend on the sparsity level of the graph.\nFurthermore, even in more challenging regimes, we prove that our bootstrap\nprocedure offers valid coverage and vanishing confidence intervals. For the\nquadratic bootstrap, we establish an Edgeworth expansion and show that this\nprocedure offers higher-order accuracy under appropriate sparsity conditions.\nWe complement our theoretical results with a simulation study and real data\nanalysis and verify that our procedure offers state-of-the-art performance for\nseveral functionals.",
          "link": "http://arxiv.org/abs/2009.06170",
          "publishedOn": "2022-04-11T00:52:26.823Z",
          "wordCount": 616,
          "title": "Trading off Accuracy for Speedup: Multiplier Bootstraps for Subgraph Counts. (arXiv:2009.06170v5 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03784",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yasuda_M/0/1/0/all/0/1\">Muneki Yasuda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takahashi_C/0/1/0/all/0/1\">Chako Takahashi</a>",
          "description": "The evaluation of the free energy of a stochastic model is considered to be a\nsignificant issue in various fields of physics and machine learning. However,\nthe exact free energy evaluation is computationally infeasible because it\nincludes an intractable partition function. Annealed importance sampling (AIS)\nis a type of importance sampling based on the Markov chain Monte Carlo method,\nwhich is similar to a simulated annealing, and can effectively approximate the\nfree energy. This study proposes a new AIS-based approach, referred to as\nmarginalized AIS (mAIS). The statistical efficiency of mAIS is investigated in\ndetail based on a theoretical and numerical perspectives. Based on the\ninvestigation, it has been proved that mAIS is more effective than AIS under a\ncertain condition.",
          "link": "http://arxiv.org/abs/2204.03784",
          "publishedOn": "2022-04-11T00:52:26.805Z",
          "wordCount": 564,
          "title": "Free Energy Evaluation Using Marginalized Annealed Importance Sampling. (arXiv:2204.03784v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.02455",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xing_L/0/1/0/all/0/1\">Li Xing</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Joun_S/0/1/0/all/0/1\">Songwan Joun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackay_K/0/1/0/all/0/1\">Kurt Mackay</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lesperance_M/0/1/0/all/0/1\">Mary Lesperance</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xuekui Zhang</a>",
          "description": "Background: Selecting feature genes to predict phenotypes is one of the\ntypical tasks in analyzing genomics data. Though many general-purpose\nalgorithms were developed for prediction, dealing with highly correlated genes\nin the prediction model is still not well addressed. High correlation among\ngenes introduces technical problems, such as multi-collinearity issues, leading\nto unreliable prediction models. Furthermore, when a causal gene (whose\nvariants have an actual biological effect on a phenotype) is highly correlated\nwith other genes, most algorithms select the feature gene from the correlated\ngroup in a purely data-driven manner. Since the correlation structure among\ngenes could change substantially when condition changes, the prediction model\nbased on not correctly selected feature genes is unreliable. Therefore, we aim\nto keep the causal biological signal in the prediction process and build a more\nrobust prediction model.\n\nMethod: We propose a grouping algorithm, which treats highly correlated genes\nas a group and uses their common pattern to represent the group's biological\nsignal in feature selection. Our novel grouping algorithm can be integrated\ninto existing prediction algorithms to enhance their prediction performance.\nOur proposed grouping method has two advantages. First, using the gene group's\ncommon patterns makes the prediction more robust and reliable under condition\nchange. Second, it reports whole correlated gene groups as discovered\nbiomarkers for prediction tasks, allowing researchers to conduct follow-up\nstudies to identify causal genes within the identified groups.\n\nResult: Using real benchmark scRNA-seq datasets with simulated cell\nphenotypes, we demonstrate our novel method significantly outperforms standard\nmodels in both (1) prediction of cell phenotypes and (2) feature gene\nselection.",
          "link": "http://arxiv.org/abs/2007.02455",
          "publishedOn": "2022-04-11T00:52:26.796Z",
          "wordCount": 741,
          "title": "Handling highly correlated genes in prediction analysis of genomic studies. (arXiv:2007.02455v4 [stat.AP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04099",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Araya_E/0/1/0/all/0/1\">Ernesto Araya</a>, <a href=\"http://arxiv.org/find/math/1/au:+Braun_G/0/1/0/all/0/1\">Guillaume Braun</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tyagi_H/0/1/0/all/0/1\">Hemant Tyagi</a>",
          "description": "In the graph matching problem we observe two graphs $G,H$ and the goal is to\nfind an assignment (or matching) between their vertices such that some measure\nof edge agreement is maximized. We assume in this work that the observed pair\n$G,H$ has been drawn from the correlated Wigner model -- a popular model for\ncorrelated weighted graphs -- where the entries of the adjacency matrices of\n$G$ and $H$ are independent Gaussians and each edge of $G$ is correlated with\none edge of $H$ (determined by the unknown matching) with the edge correlation\ndescribed by a parameter $\\sigma\\in [0,1)$. In this paper, we analyse the\nperformance of the projected power method (PPM) as a seeded graph matching\nalgorithm where we are given an initial partially correct matching (called the\nseed) as side information. We prove that if the seed is close enough to the\nground-truth matching, then with high probability, PPM iteratively improves the\nseed and recovers the ground-truth matching (either partially or exactly) in\n$\\mathcal{O}(\\log n)$ iterations. Our results prove that PPM works even in\nregimes of constant $\\sigma$, thus extending the analysis in (Mao et al.,2021)\nfor the sparse Erd\\\"os-Renyi model to the (dense) Wigner model. As a byproduct\nof our analysis, we see that the PPM framework generalizes some of the\nstate-of-art algorithms for seeded graph matching. We support and complement\nour theoretical findings with numerical experiments on synthetic data.",
          "link": "http://arxiv.org/abs/2204.04099",
          "publishedOn": "2022-04-11T00:52:26.788Z",
          "wordCount": 672,
          "title": "Seeded graph matching for the correlated Wigner model via the projected power method. (arXiv:2204.04099v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.06428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ibriga_H/0/1/0/all/0/1\">Hilda S Ibriga</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>",
          "description": "We aim to provably complete a sparse and highly-missing tensor in the\npresence of covariate information along tensor modes. Our motivation comes from\nonline advertising where users click-through-rates (CTR) on ads over various\ndevices form a CTR tensor that has about 96% missing entries and has many zeros\non non-missing entries, which makes the standalone tensor completion method\nunsatisfactory. Beside the CTR tensor, additional ad features or user\ncharacteristics are often available. In this paper, we propose\nCovariate-assisted Sparse Tensor Completion (COSTCO) to incorporate covariate\ninformation for the recovery of the sparse tensor. The key idea is to jointly\nextract latent components from both the tensor and the covariate matrix to\nlearn a synthetic representation. Theoretically, we derive the error bound for\nthe recovered tensor components and explicitly quantify the improvements on\nboth the reveal probability condition and the tensor recovery accuracy due to\ncovariates. Finally, we apply COSTCO to an advertisement dataset consisting of\na CTR tensor and ad covariate matrix, leading to 23% accuracy improvement over\nthe baseline. An important by-product is that ad latent components from COSTCO\nreveal interesting ad clusters, which are useful for better ad targeting.",
          "link": "http://arxiv.org/abs/2103.06428",
          "publishedOn": "2022-04-09T00:48:55.162Z",
          "wordCount": 664,
          "title": "Covariate-assisted Sparse Tensor Completion. (arXiv:2103.06428v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03495",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Gordon_M/0/1/0/all/0/1\">Max Hunter Gordon</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cerezo_M/0/1/0/all/0/1\">M. Cerezo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>",
          "description": "Principal component analysis (PCA) is a dimensionality reduction method in\ndata analysis that involves diagonalizing the covariance matrix of the dataset.\nRecently, quantum algorithms have been formulated for PCA based on\ndiagonalizing a density matrix. These algorithms assume that the covariance\nmatrix can be encoded in a density matrix, but a concrete protocol for this\nencoding has been lacking. Our work aims to address this gap. Assuming\namplitude encoding of the data, with the data given by the ensemble $\\{p_i,|\n\\psi_i \\rangle\\}$, then one can easily prepare the ensemble average density\nmatrix $\\overline{\\rho} = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i |$. We first\nshow that $\\overline{\\rho}$ is precisely the covariance matrix whenever the\ndataset is centered. For quantum datasets, we exploit global phase symmetry to\nargue that there always exists a centered dataset consistent with\n$\\overline{\\rho}$, and hence $\\overline{\\rho}$ can always be interpreted as a\ncovariance matrix. This provides a simple means for preparing the covariance\nmatrix for arbitrary quantum datasets or centered classical datasets. For\nuncentered classical datasets, our method is so-called \"PCA without centering\",\nwhich we interpret as PCA on a symmetrized dataset. We argue that this closely\ncorresponds to standard PCA, and we derive equations and inequalities that\nbound the deviation of the spectrum obtained with our method from that of\nstandard PCA. We numerically illustrate our method for the MNIST handwritten\ndigit dataset. We also argue that PCA on quantum datasets is natural and\nmeaningful, and we numerically implement our method for molecular ground-state\ndatasets.",
          "link": "http://arxiv.org/abs/2204.03495",
          "publishedOn": "2022-04-09T00:48:55.140Z",
          "wordCount": 702,
          "title": "Covariance matrix preparation for quantum principal component analysis. (arXiv:2204.03495v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.07896",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Esteban_Perez_A/0/1/0/all/0/1\">Adri&#xe1;n Esteban-P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Morales_J/0/1/0/all/0/1\">Juan M. Morales</a>",
          "description": "In this paper, we develop a distributionally robust chance-constrained\nformulation of the Optimal Power Flow problem (OPF) whereby the system operator\ncan leverage contextual information. For this purpose, we exploit an ambiguity\nset based on probability trimmings and optimal transport through which the\ndispatch solution is protected against the incomplete knowledge of the\nrelationship between the OPF uncertainties and the context that is conveyed by\na sample of their joint probability distribution. We provide a tractable\nreformulation of the proposed distributionally robust chance-constrained OPF\nproblem under the popular conditional-value-at-risk approximation. By way of\nnumerical experiments run on a modified IEEE-118 bus network with wind\nuncertainty, we show how the power system can substantially benefit from taking\ninto account the well-known statistical dependence between the point forecast\nof wind power outputs and its associated prediction error. Furthermore, the\nexperiments conducted also reveal that the distributional robustness conferred\non the OPF solution by our probability-trimmings-based approach is superior to\nthat bestowed by alternative approaches in terms of expected cost and system\nreliability.",
          "link": "http://arxiv.org/abs/2109.07896",
          "publishedOn": "2022-04-09T00:48:55.132Z",
          "wordCount": 629,
          "title": "Distributionally Robust Optimal Power Flow with Contextual Information. (arXiv:2109.07896v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01533",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cuesta_Ramirez_J/0/1/0/all/0/1\">Jhouben Cuesta-Ramirez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Riche_R/0/1/0/all/0/1\">Rodolphe Le Riche</a>, <a href=\"http://arxiv.org/find/math/1/au:+Roustant_O/0/1/0/all/0/1\">Olivier Roustant</a>, <a href=\"http://arxiv.org/find/math/1/au:+Perrin_G/0/1/0/all/0/1\">Guillaume Perrin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Durantin_C/0/1/0/all/0/1\">Cedric Durantin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gliere_A/0/1/0/all/0/1\">Alain Gliere</a>",
          "description": "Most real optimization problems are defined over a mixed search space where\nthe variables are both discrete and continuous. In engineering applications,\nthe objective function is typically calculated with a numerically costly\nblack-box simulation.General mixed and costly optimization problems are\ntherefore of a great practical interest, yet their resolution remains in a\nlarge part an open scientific question. In this article, costly mixed problems\nare approached through Gaussian processes where the discrete variables are\nrelaxed into continuous latent variables. The continuous space is more easily\nharvested by classical Bayesian optimization techniques than a mixed space\nwould. Discrete variables are recovered either subsequently to the continuous\noptimization, or simultaneously with an additional continuous-discrete\ncompatibility constraint that is handled with augmented Lagrangians. Several\npossible implementations of such Bayesian mixed optimizers are compared. In\nparticular, the reformulation of the problem with continuous latent variables\nis put in competition with searches working directly in the mixed space. Among\nthe algorithms involving latent variables and an augmented Lagrangian, a\nparticular attention is devoted to the Lagrange multipliers for which a local\nand a global estimation techniques are studied. The comparisons are based on\nthe repeated optimization of three analytical functions and a beam design\nproblem.",
          "link": "http://arxiv.org/abs/2111.01533",
          "publishedOn": "2022-04-09T00:48:55.116Z",
          "wordCount": 683,
          "title": "A comparison of mixed-variables Bayesian optimization approaches. (arXiv:2111.01533v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1906.06717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vasic_M/0/1/0/all/0/1\">Marko Vasic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrovic_A/0/1/0/all/0/1\">Andrija Petrovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kaiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolic_M/0/1/0/all/0/1\">Mladen Nikolic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rishabh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurshid_S/0/1/0/all/0/1\">Sarfraz Khurshid</a>",
          "description": "Rapid advancements in deep learning have led to many recent breakthroughs.\nWhile deep learning models achieve superior performance, often statistically\nbetter than humans, their adoption into safety-critical settings, such as\nhealthcare or self-driving cars is hindered by their inability to provide\nsafety guarantees or to expose the inner workings of the model in a human\nunderstandable form. We present Mo\\\"ET, a novel model based on Mixture of\nExperts, consisting of decision tree experts and a generalized linear model\ngating function. Thanks to such gating function the model is more expressive\nthan the standard decision tree. To support non-differentiable decision trees\nas experts, we formulate a novel training procedure. In addition, we introduce\na hard thresholding version, Mo\\\"ETH, in which predictions are made solely by a\nsingle expert chosen via the gating function. Thanks to that property, Mo\\\"ETH\nallows each prediction to be easily decomposed into a set of logical rules in a\nform which can be easily verified. While Mo\\\"ET is a general use model, we\nillustrate its power in the reinforcement learning setting. By training Mo\\\"ET\nmodels using an imitation learning procedure on deep RL agents we outperform\nthe previous state-of-the-art technique based on decision trees while\npreserving the verifiability of the models. Moreover, we show that Mo\\\"ET can\nalso be used in real-world supervised problems on which it outperforms other\nverifiable machine learning models.",
          "link": "http://arxiv.org/abs/1906.06717",
          "publishedOn": "2022-04-09T00:48:55.098Z",
          "wordCount": 750,
          "title": "Mo\\\"ET: Mixture of Expert Trees and its Application to Verifiable Reinforcement Learning. (arXiv:1906.06717v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yuxin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neiswanger_W/0/1/0/all/0/1\">Willie Neiswanger</a>",
          "description": "With the surge in the number of hyperparameters and training times of modern\nmachine learning models, hyperparameter tuning is becoming increasingly\nexpensive. However, after assessing 40 tuning methods systematically, we find\nthat each faces certain limitations. In particular, methods that speed up\ntuning via knowledge transfer typically require the final performance of\nhyperparameters and do not focus on low-fidelity information. As we demonstrate\nempirically, this common practice is suboptimal and can incur an unnecessary\nuse of resources. It is more cost-efficient to instead leverage low-fidelity\ntuning observations to measure inter-task similarity and transfer knowledge\nfrom existing to new tasks accordingly. However, performing multi-fidelity\ntuning comes with its own challenges in the transfer setting: the noise in\nadditional observations and the need for performance forecasting. Therefore, we\npropose and conduct a thorough analysis of a multi-task multi-fidelity Bayesian\noptimization framework, which leads to the best instantiation--amortized\nauto-tuning (AT2). We further present an offline-computed 27-task\nhyperparameter recommendation (HyperRec) database to serve the community.\nExtensive experiments on HyperRec and other real-world databases illustrate the\neffectiveness of our AT2 method.",
          "link": "http://arxiv.org/abs/2106.09179",
          "publishedOn": "2022-04-09T00:48:55.076Z",
          "wordCount": 647,
          "title": "Amortized Auto-Tuning: Cost-Efficient Bayesian Transfer Optimization for Hyperparameter Recommendation. (arXiv:2106.09179v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_J/0/1/0/all/0/1\">Jeffrey Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_R/0/1/0/all/0/1\">Rajat Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tumma_N/0/1/0/all/0/1\">Neehal Tumma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhishek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "Topic models are some of the most popular ways to represent textual data in\nan interpret-able manner. Recently, advances in deep generative models,\nspecifically auto-encoding variational Bayes (AEVB), have led to the\nintroduction of unsupervised neural topic models, which leverage deep\ngenerative models as opposed to traditional statistics-based topic models. We\nextend upon these neural topic models by introducing the Label-Indexed Neural\nTopic Model (LI-NTM), which is, to the extent of our knowledge, the first\neffective upstream semi-supervised neural topic model. We find that LI-NTM\noutperforms existing neural topic models in document reconstruction benchmarks,\nwith the most notable results in low labeled data regimes and for data-sets\nwith informative labels; furthermore, our jointly learned classifier\noutperforms baseline classifiers in ablation studies.",
          "link": "http://arxiv.org/abs/2204.03208",
          "publishedOn": "2022-04-09T00:48:55.069Z",
          "wordCount": 586,
          "title": "A Joint Learning Approach for Semi-supervised Neural Topic Modeling. (arXiv:2204.03208v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.09745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1\">Sivakanth Gopi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulhane_P/0/1/0/all/0/1\">Pankaj Gulhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1\">Janardhan Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Judy Hanwen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yekhanin_S/0/1/0/all/0/1\">Sergey Yekhanin</a>",
          "description": "We study the basic operation of set union in the global model of differential\nprivacy. In this problem, we are given a universe $U$ of items, possibly of\ninfinite size, and a database $D$ of users. Each user $i$ contributes a subset\n$W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially\nprivate algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the\nsize of $S$ is as large as possible. The problem arises in countless real world\napplications; it is particularly ubiquitous in natural language processing\n(NLP) applications as vocabulary extraction. For example, discovering words,\nsentences, $n$-grams etc., from private text data belonging to users is an\ninstance of the set union problem.\n\nKnown algorithms for this problem proceed by collecting a subset of items\nfrom each user, taking the union of such subsets, and disclosing the items\nwhose noisy counts fall above a certain threshold. Crucially, in the above\nprocess, the contribution of each individual user is always independent of the\nitems held by other users, resulting in a wasteful aggregation process, where\nsome item counts happen to be way above the threshold. We deviate from the\nabove paradigm by allowing users to contribute their items in a\n$\\textit{dependent fashion}$, guided by a $\\textit{policy}$. In this new\nsetting ensuring privacy is significantly delicate. We prove that any policy\nwhich has certain $\\textit{contractive}$ properties would result in a\ndifferentially private algorithm. We design two new algorithms, one using\nLaplace noise and other Gaussian noise, as specific instances of policies\nsatisfying the contractive properties. Our experiments show that the new\nalgorithms significantly outperform previously known mechanisms for the\nproblem.",
          "link": "http://arxiv.org/abs/2002.09745",
          "publishedOn": "2022-04-09T00:48:55.060Z",
          "wordCount": 754,
          "title": "Differentially Private Set Union. (arXiv:2002.09745v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krug_A/0/1/0/all/0/1\">Andreas Krug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratul_R/0/1/0/all/0/1\">Raihan Kabir Ratul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stober_S/0/1/0/all/0/1\">Sebastian Stober</a>",
          "description": "Machine Learning with Deep Neural Networks (DNNs) has become a successful\ntool in solving tasks across various fields of application. The success of DNNs\nis strongly connected to their high complexity in terms of the number of\nnetwork layers or of neurons in each layer, which severely complicates to\nunderstand how DNNs solve their learned task. To improve the explainability of\nDNNs, we adapt methods from neuroscience because this field has a rich\nexperience in analyzing complex and opaque systems. In this work, we draw\ninspiration from how neuroscience uses topographic maps to visualize the\nactivity of the brain when it performs certain tasks. Transferring this\napproach to DNNs can help to visualize and understand their internal processes\nmore intuitively, too. However, the inner structures of brains and DNNs differ\nsubstantially. Therefore, to be able to visualize activations of neurons in\nDNNs as topographic maps, we research techniques to layout the neurons in a\ntwo-dimensional space in which neurons of similar activity are in the vicinity\nof each other. In this work, we introduce and compare different methods to\nobtain a topographic layout of the neurons in a network layer. Moreover, we\ndemonstrate how to use the resulting topographic activation maps to identify\nerrors or encoded biases in DNNs or data sets. Our novel visualization\ntechnique improves the transparency of DNN-based algorithmic decision-making\nsystems and is accessible to a broad audience because topographic maps are\nintuitive to interpret without expert-knowledge in Machine Learning.",
          "link": "http://arxiv.org/abs/2204.03528",
          "publishedOn": "2022-04-09T00:48:55.052Z",
          "wordCount": null,
          "title": "Visualizing Deep Neural Networks with Topographic Activation Maps. (arXiv:2204.03528v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1\">Leon Bottou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>",
          "description": "Regularization is a fundamental technique to prevent over-fitting and to\nimprove generalization performances by constraining a model's complexity.\nCurrent Deep Networks heavily rely on regularizers such as Data-Augmentation\n(DA) or weight-decay, and employ structural risk minimization, i.e.\ncross-validation, to select the optimal regularization hyper-parameters. In\nthis study, we demonstrate that techniques such as DA or weight decay produce a\nmodel with a reduced complexity that is unfair across classes. The optimal\namount of DA or weight decay found from cross-validation leads to disastrous\nmodel performances on some classes e.g. on Imagenet with a resnet50, the \"barn\nspider\" classification test accuracy falls from $68\\%$ to $46\\%$ only by\nintroducing random crop DA during training. Even more surprising, such\nperformance drop also appears when introducing uninformative regularization\ntechniques such as weight decay. Those results demonstrate that our search for\never increasing generalization performance -- averaged over all classes and\nsamples -- has left us with models and regularizers that silently sacrifice\nperformances on some classes. This scenario can become dangerous when deploying\na model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on\nINaturalist sees its performances fall from $70\\%$ to $30\\%$ on class \\#8889\nwhen introducing random crop DA during the Imagenet pre-training phase. Those\nresults demonstrate that designing novel regularizers without class-dependent\nbias remains an open research question.",
          "link": "http://arxiv.org/abs/2204.03632",
          "publishedOn": "2022-04-09T00:48:55.052Z",
          "wordCount": null,
          "title": "The Effects of Regularization and Data Augmentation are Class Dependent. (arXiv:2204.03632v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03406",
          "author": "<a href=\"http://arxiv.org/find/hep-th/1/au:+Loukas_O/0/1/0/all/0/1\">Orestis Loukas</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Chung_H/0/1/0/all/0/1\">Ho Ryun Chung</a>",
          "description": "The estimation of categorical distributions under marginal constraints\nsummarizing some sample from a population in the most-generalizable way is key\nfor many machine-learning and data-driven approaches. We provide a\nparameter-agnostic theoretical framework that enables this task ensuring (i)\nthat a categorical distribution of Maximum Entropy under marginal constraints\nalways exists and (ii) that it is unique. The procedure of iterative\nproportional fitting (IPF) naturally estimates that distribution from any\nconsistent set of marginal constraints directly in the space of probabilities,\nthus deductively identifying a least-biased characterization of the population.\nThe theoretical framework together with IPF leads to a holistic workflow that\nenables modeling any class of categorical distributions solely using the\nphenomenological information provided.",
          "link": "http://arxiv.org/abs/2204.03406",
          "publishedOn": "2022-04-09T00:48:55.049Z",
          "wordCount": 565,
          "title": "Categorical Distributions of Maximum Entropy under Marginal Constraints. (arXiv:2204.03406v1 [hep-th])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_T/0/1/0/all/0/1\">Tristan Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1\">Edward J. Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahlou_S/0/1/0/all/0/1\">Salem Lahlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_M/0/1/0/all/0/1\">Mo Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1\">Emmanuel Bengio</a>",
          "description": "Generative Flow Networks (GFlowNets) have been introduced as a method to\nsample a diverse set of candidates in an active learning context, with a\ntraining objective that makes them approximately sample in proportion to a\ngiven reward function. In this paper, we show a number of additional\ntheoretical properties of GFlowNets. They can be used to estimate joint\nprobability distributions and the corresponding marginal distributions where\nsome variables are unspecified and, of particular interest, can represent\ndistributions over composite objects like sets and graphs. GFlowNets amortize\nthe work typically done by computationally expensive MCMC methods in a single\nbut trained generative pass. They could also be used to estimate partition\nfunctions and free energies, conditional probabilities of supersets\n(supergraphs) given a subset (subgraph), as well as marginal distributions over\nall supersets (supergraphs) of a given set (graph). We introduce variations\nenabling the estimation of entropy and mutual information, sampling from a\nPareto frontier, connections to reward-maximizing policies, and extensions to\nstochastic environments, continuous actions and modular energy functions.",
          "link": "http://arxiv.org/abs/2111.09266",
          "publishedOn": "2022-04-09T00:48:55.042Z",
          "wordCount": 632,
          "title": "GFlowNet Foundations. (arXiv:2111.09266v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05845",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Simpson_I/0/1/0/all/0/1\">Ivor J.A. Simpson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McManamon_A/0/1/0/all/0/1\">Ashley McManamon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Orzsik_B/0/1/0/all/0/1\">Bal&#xe1;zs &#xd6;rzsik</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stone_A/0/1/0/all/0/1\">Alan J. Stone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blockley_N/0/1/0/all/0/1\">Nicholas P. Blockley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asllani_I/0/1/0/all/0/1\">Iris Asllani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Colasanti_A/0/1/0/all/0/1\">Alessandro Colasanti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cercignani_M/0/1/0/all/0/1\">Mara Cercignani</a>",
          "description": "Streamlined qBOLD acquisitions enable experimentally straightforward\nobservations of brain oxygen metabolism. $R_2^\\prime$ maps are easily inferred;\nhowever, the Oxygen extraction fraction (OEF) and deoxygenated blood volume\n(DBV) are more ambiguously determined from the data. As such, existing\ninference methods tend to yield very noisy and underestimated OEF maps, while\noverestimating DBV.\n\nThis work describes a novel probabilistic machine learning approach that can\ninfer plausible distributions of OEF and DBV. Initially, we create a model that\nproduces informative voxelwise prior distribution based on synthetic training\ndata. Contrary to prior work, we model the joint distribution of OEF and DBV\nthrough a scaled multivariate logit-Normal distribution, which enables the\nvalues to be constrained within a plausible range. The prior distribution model\nis used to train an efficient amortized variational Bayesian inference model.\nThis model learns to infer OEF and DBV by predicting real image data, with few\ntraining data required, using the signal equations as a forward model.\n\nWe demonstrate that our approach enables the inference of smooth OEF and DBV\nmaps, with a physiologically plausible distribution that can be adapted through\nspecification of an informative prior distribution. Other benefits include\nmodel comparison (via the evidence lower bound) and uncertainty quantification\nfor identifying image artefacts. Results are demonstrated on a small study\ncomparing subjects undergoing hyperventilation and at rest. We illustrate that\nthe proposed approach allows measurement of gray matter differences in OEF and\nDBV and enables voxelwise comparison between conditions, where we observe\nsignificant increases in OEF and $R_2^\\prime$ during hyperventilation.",
          "link": "http://arxiv.org/abs/2203.05845",
          "publishedOn": "2022-04-09T00:48:55.020Z",
          "wordCount": 733,
          "title": "Flexible Amortized Variational Inference in qBOLD MRI. (arXiv:2203.05845v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.15783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polk_S/0/1/0/all/0/1\">Sam L. Polk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_J/0/1/0/all/0/1\">James M. Murphy</a>",
          "description": "Clustering algorithms partition a dataset into groups of similar points. The\nprimary contribution of this article is the Multiscale Spatially-Regularized\nDiffusion Learning (M-SRDL) clustering algorithm, which uses\nspatially-regularized diffusion distances to efficiently and accurately learn\nmultiple scales of latent structure in hyperspectral images. The M-SRDL\nclustering algorithm extracts clusterings at many scales from a hyperspectral\nimage and outputs these clusterings' variation of information-barycenter as an\nexemplar for all underlying cluster structure. We show that incorporating\nspatial regularization into a multiscale clustering framework results in\nsmoother and more coherent clusters when applied to hyperspectral data,\nyielding more accurate clustering labels.",
          "link": "http://arxiv.org/abs/2103.15783",
          "publishedOn": "2022-04-09T00:48:55.011Z",
          "wordCount": 581,
          "title": "Multiscale Clustering of Hyperspectral Images Through Spectral-Spatial Diffusion Geometry. (arXiv:2103.15783v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03562",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cheng_K/0/1/0/all/0/1\">Kai Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zimmermann_R/0/1/0/all/0/1\">Ralf Zimmermann</a>",
          "description": "Gradient-enhanced Kriging (GE-Kriging) is a well-established surrogate\nmodelling technique for approximating expensive computational models. However,\nit tends to get impractical for high-dimensional problems due to the large\ninherent correlation matrix and the associated high-dimensional hyper-parameter\ntuning problem. To address these issues, we propose a new method in this paper,\ncalled sliced GE-Kriging (SGE-Kriging) for reducing both the size of the\ncorrelation matrix and the number of hyper-parameters. Firstly, we perform a\nderivative-based global sensitivity analysis to detect the relative importance\nof each input variable with respect to model response. Then, we propose to\nsplit the training sample set into multiple slices, and invoke Bayes' theorem\nto approximate the full likelihood function via a sliced likelihood function,\nin which multiple small correlation matrices are utilized to describe the\ncorrelation of the sample set. Additionally, we replace the original\nhigh-dimensional hyper-parameter tuning problem with a low-dimensional\ncounterpart by learning the relationship between the hyper-parameters and the\nglobal sensitivity indices. Finally, we validate SGE-Kriging by means of\nnumerical experiments with several benchmarks problems. The results show that\nthe SGE-Kriging model features an accuracy and robustness that is comparable to\nthe standard one but comes at much less training costs. The benefits are most\nevident in high-dimensional problems.",
          "link": "http://arxiv.org/abs/2204.03562",
          "publishedOn": "2022-04-09T00:48:54.964Z",
          "wordCount": null,
          "title": "Sliced gradient-enhanced Kriging for high-dimensional function approximation. (arXiv:2204.03562v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.11079",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Leiner_J/0/1/0/all/0/1\">James Leiner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duan_B/0/1/0/all/0/1\">Boyan Duan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wasserman_L/0/1/0/all/0/1\">Larry Wasserman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "Suppose we observe a random vector $X$ from some distribution $P$ in a known\nfamily with unknown parameters. We ask the following question: when is it\npossible to split $X$ into two parts $f(X)$ and $g(X)$ such that neither part\nis sufficient to reconstruct $X$ by itself, but both together can recover $X$\nfully, and the joint distribution of $(f(X),g(X))$ is tractable? As one\nexample, if $X=(X_1,\\dots,X_n)$ and $P$ is a product distribution, then for any\n$m<n$, we can split the sample to define $f(X)=(X_1,\\dots,X_m)$ and\n$g(X)=(X_{m+1},\\dots,X_n)$. Rasines and Young (2021) offers an alternative\nroute of accomplishing this task through randomization of $X$ with additive\nGaussian noise which enables post-selection inference in finite samples for\nGaussian distributed data and asymptotically for non-Gaussian additive models.\nIn this paper, we offer a more general methodology for achieving such a split\nin finite samples by borrowing ideas from Bayesian inference to yield a\n(frequentist) solution that can be viewed as a continuous analog of data\nsplitting. We call our method data blurring, as an alternative to data\nsplitting, data carving and p-value masking. We exemplify the method on a few\nprototypical applications, such as post-selection inference for trend filtering\nand other regression problems.",
          "link": "http://arxiv.org/abs/2112.11079",
          "publishedOn": "2022-04-09T00:48:54.964Z",
          "wordCount": null,
          "title": "Data blurring: sample splitting a single sample. (arXiv:2112.11079v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.03706",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ramprasad_P/0/1/0/all/0/1\">Pratik Ramprasad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yuantong Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1\">Guang Cheng</a>",
          "description": "The recent emergence of reinforcement learning has created a demand for\nrobust statistical inference methods for the parameter estimates computed using\nthese algorithms. Existing methods for statistical inference in online learning\nare restricted to settings involving independently sampled observations, while\nexisting statistical inference methods in reinforcement learning (RL) are\nlimited to the batch setting. The online bootstrap is a flexible and efficient\napproach for statistical inference in linear stochastic approximation\nalgorithms, but its efficacy in settings involving Markov noise, such as RL,\nhas yet to be explored. In this paper, we study the use of the online bootstrap\nmethod for statistical inference in RL. In particular, we focus on the temporal\ndifference (TD) learning and Gradient TD (GTD) learning algorithms, which are\nthemselves special instances of linear stochastic approximation under Markov\nnoise. The method is shown to be distributionally consistent for statistical\ninference in policy evaluation, and numerical experiments are included to\ndemonstrate the effectiveness of this algorithm at statistical inference tasks\nacross a range of real RL environments.",
          "link": "http://arxiv.org/abs/2108.03706",
          "publishedOn": "2022-04-09T00:48:54.961Z",
          "wordCount": 673,
          "title": "Online Bootstrap Inference For Policy Evaluation in Reinforcement Learning. (arXiv:2108.03706v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.14836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhun Deng</a>",
          "description": "Representations of the world environment play a crucial role in artificial\nintelligence. It is often inefficient to conduct reasoning and inference\ndirectly in the space of raw sensory representations, such as pixel values of\nimages. Representation learning allows us to automatically discover suitable\nrepresentations from raw sensory data. For example, given raw sensory data, a\ndeep neural network learns nonlinear representations at its hidden layers,\nwhich are subsequently used for classification at its output layer. This\nhappens implicitly during training through minimizing a supervised or\nunsupervised loss. In this paper, we study the dynamics of such implicit\nnonlinear representation learning. We identify a pair of a new assumption and a\nnovel condition, called the common model structure assumption and the\ndata-architecture alignment condition. Under the common model structure\nassumption, the data-architecture alignment condition is shown to be sufficient\nfor the global convergence and necessary for the global optimality. Moreover,\nour theory explains how and when increasing the network size does and does not\nimprove the training behaviors in the practical regime. Our results provide\npractical guidance for designing a model structure: e.g., the common model\nstructure assumption can be used as a justification for using a particular\nmodel structure instead of others. We also derive a new training framework,\nwhich satisfies the data-architecture alignment condition by automatically\nmodifying any given training algorithm. Given a standard training algorithm,\nthe framework running its modified version is empirically shown to maintain\ncompetitive test performances while providing global convergence guarantees for\ndeep residual neural networks with convolutions, skip connections, and batch\nnormalization with datasets, including MNIST, CIFAR-10, CIFAR-100, Semeion,\nKMNIST and SVHN.",
          "link": "http://arxiv.org/abs/2106.14836",
          "publishedOn": "2022-04-09T00:48:54.953Z",
          "wordCount": 777,
          "title": "Understanding Dynamics of Nonlinear Representation Learning and Its Application. (arXiv:2106.14836v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daesoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aune_E/0/1/0/all/0/1\">Erlend Aune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langet_N/0/1/0/all/0/1\">Nad&#xe8;ge Langet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eidsvik_J/0/1/0/all/0/1\">Jo Eidsvik</a>",
          "description": "One of the latest self-supervised learning (SSL) methods, VICReg, showed a\ngreat performance both in the linear evaluation and the fine-tuning evaluation.\nHowever, VICReg is proposed in computer vision and it learns by pulling\nrepresentations of random crops of an image while maintaining the\nrepresentation space by the variance and covariance loss. However, VICReg would\nbe ineffective on non-stationary time series where different parts/crops of\ninput should be differently encoded to consider the non-stationarity. Another\nrecent SSL proposal, Temporal Neighborhood Coding (TNC) is effective for\nencoding non-stationary time series. This study shows that a combination of a\nVICReg-style method and TNC is very effective for SSL on non-stationary time\nseries, where a non-stationary seismic signal time series is used as an\nevaluation dataset.",
          "link": "http://arxiv.org/abs/2204.02697",
          "publishedOn": "2022-04-09T00:48:54.916Z",
          "wordCount": 592,
          "title": "VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance Evaluated on Non-stationary Seismic Signal Time Series. (arXiv:2204.02697v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.02601",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lock_E/0/1/0/all/0/1\">Eric F. Lock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_J/0/1/0/all/0/1\">Jun Young Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hoadley_K/0/1/0/all/0/1\">Katherine A. Hoadley</a>",
          "description": "Several modern applications require the integration of multiple large data\nmatrices that have shared rows and/or columns. For example, cancer studies that\nintegrate multiple omics platforms across multiple types of cancer, pan-omics\npan-cancer analysis, have extended our knowledge of molecular heterogenity\nbeyond what was observed in single tumor and single platform studies. However,\nthese studies have been limited by available statistical methodology. We\npropose a flexible approach to the simultaneous factorization and decomposition\nof variation across such bidimensionally linked matrices, BIDIFAC+. This\ndecomposes variation into a series of low-rank components that may be shared\nacross any number of row sets (e.g., omics platforms) or column sets (e.g.,\ncancer types). This builds on a growing literature for the factorization and\ndecomposition of linked matrices, which has primarily focused on multiple\nmatrices that are linked in one dimension (rows or columns) only. Our objective\nfunction extends nuclear norm penalization, is motivated by random matrix\ntheory, gives an identifiable decomposition under relatively mild conditions,\nand can be shown to give the mode of a Bayesian posterior distribution. We\napply BIDIFAC+ to pan-omics pan-cancer data from TCGA, identifying shared and\nspecific modes of variability across 4 different omics platforms and 29\ndifferent cancer types.",
          "link": "http://arxiv.org/abs/2002.02601",
          "publishedOn": "2022-04-09T00:48:54.898Z",
          "wordCount": 683,
          "title": "Bidimensional linked matrix factorization for pan-omics pan-cancer analysis. (arXiv:2002.02601v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2004.10888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shangtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "We present a mean-variance policy iteration (MVPI) framework for risk-averse\ncontrol in a discounted infinite horizon MDP optimizing the variance of a\nper-step reward random variable. MVPI enjoys great flexibility in that any\npolicy evaluation method and risk-neutral control method can be dropped in for\nrisk-averse control off the shelf, in both on- and off-policy settings. This\nflexibility reduces the gap between risk-neutral control and risk-averse\ncontrol and is achieved by working on a novel augmented MDP directly. We\npropose risk-averse TD3 as an example instantiating MVPI, which outperforms\nvanilla TD3 and many previous risk-averse control methods in challenging Mujoco\nrobot simulation tasks under a risk-aware performance metric. This risk-averse\nTD3 is the first to introduce deterministic policies and off-policy learning\ninto risk-averse reinforcement learning, both of which are key to the\nperformance boost we show in Mujoco domains.",
          "link": "http://arxiv.org/abs/2004.10888",
          "publishedOn": "2022-04-09T00:48:54.883Z",
          "wordCount": 644,
          "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning. (arXiv:2004.10888v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03145",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saragadam_V/0/1/0/all/0/1\">Vishwanath Saragadam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Veeraraghavan_A/0/1/0/all/0/1\">Ashok Veeraraghavan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>",
          "description": "DeepTensor is a computationally efficient framework for low-rank\ndecomposition of matrices and tensors using deep generative networks. We\ndecompose a tensor as the product of low-rank tensor factors (e.g., a matrix as\nthe outer product of two vectors), where each low-rank tensor is generated by a\ndeep network (DN) that is trained in a self-supervised manner to minimize the\nmean-squared approximation error. Our key observation is that the implicit\nregularization inherent in DNs enables them to capture nonlinear signal\nstructures (e.g., manifolds) that are out of the reach of classical linear\nmethods like the singular value decomposition (SVD) and principal component\nanalysis (PCA). Furthermore, in contrast to the SVD and PCA, whose performance\ndeteriorates when the tensor's entries deviate from additive white Gaussian\nnoise, we demonstrate that the performance of DeepTensor is robust to a wide\nrange of distributions. We validate that DeepTensor is a robust and\ncomputationally efficient drop-in replacement for the SVD, PCA, nonnegative\nmatrix factorization (NMF), and similar decompositions by exploring a range of\nreal-world applications, including hyperspectral image denoising, 3D MRI\ntomography, and image classification. In particular, DeepTensor offers a 6dB\nsignal-to-noise ratio improvement over standard denoising methods for signals\ncorrupted by Poisson noise and learns to decompose 3D tensors 60 times faster\nthan a single DN equipped with 3D convolutions.",
          "link": "http://arxiv.org/abs/2204.03145",
          "publishedOn": "2022-04-09T00:48:53.175Z",
          "wordCount": 659,
          "title": "DeepTensor: Low-Rank Tensor Decomposition with Deep Network Priors. (arXiv:2204.03145v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03193",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiahao Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Shiqi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1\">Guang Lin</a>",
          "description": "A new data-driven method for operator learning of stochastic differential\nequations(SDE) is proposed in this paper. The central goal is to solve forward\nand inverse stochastic problems more effectively using limited data. Deep\noperator network(DeepONet) has been proposed recently for operator learning.\nCompared to other neural networks to learn functions, it aims at the problem of\nlearning nonlinear operators. However, it can be challenging by using the\noriginal model to learn nonlinear operators for high-dimensional stochastic\nproblems. We propose a new multi-resolution autoencoder DeepONet model referred\nto as MultiAuto-DeepONet to deal with this difficulty with the aid of\nconvolutional autoencoder. The encoder part of the network is designed to\nreduce the dimensionality as well as discover the hidden features of\nhigh-dimensional stochastic inputs. The decoder is designed to have a special\nstructure, i.e. in the form of DeepONet. The first DeepONet in decoder is\ndesigned to reconstruct the input function involving randomness while the\nsecond one is used to approximate the solution of desired equations. Those two\nDeepONets has a common branch net and two independent trunk nets. This\narchitecture enables us to deal with multi-resolution inputs naturally. By\nadding $L_1$ regularization to our network, we found the outputs from the\nbranch net and two trunk nets all have sparse structures. This reduces the\nnumber of trainable parameters in the neural network thus making the model more\nefficient. Finally, we conduct several numerical experiments to illustrate the\neffectiveness of our proposed MultiAuto-DeepONet model with uncertainty\nquantification.",
          "link": "http://arxiv.org/abs/2204.03193",
          "publishedOn": "2022-04-09T00:48:53.167Z",
          "wordCount": 705,
          "title": "MultiAuto-DeepONet: A Multi-resolution Autoencoder DeepONet for Nonlinear Dimension Reduction, Uncertainty Quantification and Operator Learning of Forward and Inverse Stochastic Problems. (arXiv:2204.03193v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03123",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+John_M/0/1/0/all/0/1\">Majnu John</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vettam_S/0/1/0/all/0/1\">Sujit Vettam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yihren Wu</a>",
          "description": "Nonconvex penalties are utilized for regularization in high-dimensional\nstatistical learning algorithms primarily because they yield unbiased or nearly\nunbiased estimators for the parameters in the model. Nonconvex penalties\nexisting in the literature such as SCAD, MCP, Laplace and arctan have a\nsingularity at origin which makes them useful also for variable selection.\nHowever, in several high-dimensional frameworks such as deep learning, variable\nselection is less of a concern. In this paper, we present a nonconvex penalty\nwhich is smooth at origin. The paper includes asymptotic results for ordinary\nleast squares estimators regularized with the new penalty function, showing\nasymptotic bias that vanishes exponentially fast. We also conducted an\nempirical study employing deep neural network architecture on three datasets\nand convolutional neural network on four datasets. The empirical study showed\nbetter performance for the new regularization approach in five out of the seven\ndatasets.",
          "link": "http://arxiv.org/abs/2204.03123",
          "publishedOn": "2022-04-09T00:48:53.143Z",
          "wordCount": 594,
          "title": "A novel nonconvex, smooth-at-origin penalty for statistical learning. (arXiv:2204.03123v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barkhof_C/0/1/0/all/0/1\">Claartje Barkhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1\">Wilker Aziz</a>",
          "description": "We propose a framework for the statistical evaluation of variational\nauto-encoders (VAEs) and test two instances of this framework in the context of\nmodelling images of handwritten digits and a corpus of English text. Our take\non evaluation is based on the idea of statistical model criticism, popular in\nBayesian data analysis, whereby a statistical model is evaluated in terms of\nits ability to reproduce statistics of an unknown data generating process from\nwhich we can obtain samples. A VAE learns not one, but two joint distributions\nover a shared sample space, each exploiting a choice of factorisation that\nmakes sampling tractable in one of two directions (latent-to-data,\ndata-to-latent). We evaluate samples from these distributions, assessing their\n(marginal) fit to the observed data and our choice of prior, and we also\nevaluate samples through a pipeline that connects the two distributions\nstarting from a data sample, assessing whether together they exploit and reveal\nlatent factors of variation that are useful to a practitioner. We show that\nthis methodology offers possibilities for model selection qualitatively beyond\nintrinsic evaluation metrics and at a finer granularity than commonly used\nstatistics can offer.",
          "link": "http://arxiv.org/abs/2204.03030",
          "publishedOn": "2022-04-09T00:48:53.135Z",
          "wordCount": 625,
          "title": "Statistical Model Criticism of Variational Auto-Encoders. (arXiv:2204.03030v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulynych_B/0/1/0/all/0/1\">Bogdan Kulynych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yao-Yuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1\">Jaros&#x142;aw B&#x142;asiok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1\">Preetum Nakkiran</a>",
          "description": "We investigate and leverage a connection between Differential Privacy (DP)\nand the recently proposed notion of Distributional Generalization (DG).\nApplying this connection, we introduce new conceptual tools for designing\ndeep-learning methods that bypass \"pathologies\" of standard stochastic gradient\ndescent (SGD). First, we prove that differentially private methods satisfy a\n\"What You See Is What You Get (WYSIWYG)\" generalization guarantee: whatever a\nmodel does on its train data is almost exactly what it will do at test time.\nThis guarantee is formally captured by distributional generalization. WYSIWYG\nenables principled algorithm design in deep learning by reducing\n$\\textit{generalization}$ concerns to $\\textit{optimization}$ ones: in order to\nmitigate unwanted behavior at test time, it is provably sufficient to mitigate\nthis behavior on the train data. This is notably false for standard (non-DP)\nmethods, hence this observation has applications even when privacy is not\nrequired. For example, importance sampling is known to fail for standard SGD,\nbut we show that it has exactly the intended effect for DP-trained models.\nThus, with DP-SGD, unlike with SGD, we can influence test-time behavior by\nmaking principled train-time interventions. We use these insights to construct\nsimple algorithms which match or outperform SOTA in several distributional\nrobustness applications, and to significantly improve the privacy vs. disparate\nimpact trade-off of DP-SGD. Finally, we also improve on known theoretical\nbounds relating differential privacy, stability, and distributional\ngeneralization.",
          "link": "http://arxiv.org/abs/2204.03230",
          "publishedOn": "2022-04-09T00:48:53.125Z",
          "wordCount": 701,
          "title": "What You See is What You Get: Distributional Generalization for Algorithm Design in Deep Learning. (arXiv:2204.03230v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03248",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sekimoto_K/0/1/0/all/0/1\">Kaiji Sekimoto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yasuda_M/0/1/0/all/0/1\">Muneki Yasuda</a>",
          "description": "Although evaluation of the expectations on the Ising model is essential in\nvarious applications, this is frequently infeasible because of intractable\nmultiple summations (or integrations). Spatial Monte Carlo integration (SMCI)\nis a sampling-based approximation, and can provide high-accuracy estimations\nfor such intractable expectations. To evaluate the expectation of a function of\nvariables in a specific region (called target region), SMCI considers a larger\nregion containing the target region (called sum region). In SMCI, the multiple\nsummation for the variables in the sum region is precisely executed, and that\nin the outer region is evaluated by the sampling approximation such as the\nstandard Monte Carlo integration. It is guaranteed that the accuracy of the\nSMCI estimator is monotonically improved as the size of the sum region\nincreases. However, a haphazard expansion of the sum region could cause a\ncombinatorial explosion. Therefore, we hope to improve the accuracy without\nsuch region expansion. In this study, based on the theory of generalized least\nsquares, a new effective method is proposed by combining multiple SMCI\nestimators. The validity of the proposed method is demonstrated theoretically\nand numerically. The results indicate that the proposed method can be effective\nin the inverse Ising problem (or Boltzmann machine learning).",
          "link": "http://arxiv.org/abs/2204.03248",
          "publishedOn": "2022-04-09T00:48:49.945Z",
          "wordCount": 660,
          "title": "Composite Spatial Monte Carlo Integration Based on Generalized Least Squares. (arXiv:2204.03248v1 [stat.CO])",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Machine Learning",
      "feedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
      "siteUrl": "https://www.reddit.com/r/MachineLearning/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uh2rhp/d_how_to_do_unsupervised_anomaly_detection_in_a/",
          "author": null,
          "description": "I have terabytes of tabular and image data. I want to determine what data points are novel/anomalous. I have a couple anchor data points for entities that are known and features about said entities.\n Effectively I want to find things that are novel relative to my anchors without any labels for if something is actually interesting and not noise to train on.\n Here's an analogy:\n  \nI have driving footage of a reference driver who is \"perfectly\" driving. I also have all of the sensor data: accelerometers, where the human is looking, etc.\n I simulate 1000s of self-driving cars that are running their own agent models. I get data on all of these as well.\n I deploy an agent to the real world that is expected to do better/comparable to the reference driver while having different model parameters. I don't know how this driving agent will do in the real world. I want to choose agent instantiations that are different from the rest in some regard (anomaly)\n I'm constrained by how many deployments I can make. It's expensive and dangerous.\n  \n​\n An issue I face with this is that there are dozens of models that will give me anomalous points, but sometimes they don't overlap at all. There's no consistency. Ideally I want to find data points that are novel in feature space (far away?), but expected to be functional... on non-labeled data.\n So yea... after writing this it kind of sounds like just a screwed situation, but maybe someone here has an idea/experience of how to build a system that can enable this kind of parameter selection engine (suggesting novel parameters that are functional without any labeled data).\n    submitted by    /u/memproc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uh2rhp/d_how_to_do_unsupervised_anomaly_detection_in_a/",
          "publishedOn": "2022-05-02T23:31:31.000Z",
          "wordCount": 376,
          "title": "[D] How to do unsupervised anomaly detection in a principled way?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uh1wf9/p_transfer_learning_with_bert_number_of_examples/",
          "author": null,
          "description": "I'm looking to make a review classifier (3 classification). It sounds like transfer learning is standard these days. But how many examples would generally be needed to make an improvement on the out of the box result? Would 1,000 be sufficient or realistically would it make to be in the 10's of thousands. Or is it a \"how long is a piece of string question\" edit: sorry wrong tag\n    submitted by    /u/mldude8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uh1wf9/p_transfer_learning_with_bert_number_of_examples/",
          "publishedOn": "2022-05-02T22:48:23.000Z",
          "wordCount": 226,
          "title": "[P] Transfer Learning with BERT, number of examples.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugui1v/d_present_ml_classification_model_results_for_non/",
          "author": null,
          "description": "I wanna include Machine Learning classification (str target) results into a web platform, what informations that I can show and will be meaningful , I can already think of (Predicted value, Accuracy, Probability) what else I can include, graphics or anything useful to present my results for non technical people (clients)?\n    submitted by    /u/According-Promise-23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugui1v/d_present_ml_classification_model_results_for_non/",
          "publishedOn": "2022-05-02T17:11:23.000Z",
          "wordCount": 204,
          "title": "[D] Present ML classification model results for non technical",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugrucs/d_how_do_some_people_publish_so_much_in_this_field/",
          "author": null,
          "description": "I'm not talking about PIs necessarily, but sometimes I search up other grad students in my department or people who email me and some of them have 10+ first author papers a year? I don't really understand how this is possible; I don't think I'm the best implementer out there but it would take me at least 2-3 months to read the literature, come up with a new research question, run experiments, iterate and write up. I mostly work with just me and my advisor though, maybe that's the difference?\n If you're one of these people, are you just hyper-productive? Already supervising students? Or collaborating with a ton of people and not doing a high proportion of work on any project?\n    submitted by    /u/IPvIV  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugrucs/d_how_do_some_people_publish_so_much_in_this_field/",
          "publishedOn": "2022-05-02T15:12:56.000Z",
          "wordCount": 1487,
          "title": "[D] How do some people publish so much in this field?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugrr21/p_pretraining_dense_retrievers_with_masked/",
          "author": null,
          "description": "Hi, I made a video explaining REALM. It is a pretraining method for dense retrievers. It uses a language model along with a retriever for pretraining. \n Given a random masked sentence like \"Each angle in an equilateral triangle is [MASK]\", the retriever gets top passages that might contain information about equilateral triangles. The passages are then passed to a language model to predict the value for each \"[MASK]\" token. Using this MLM objective, as model performance improves so does the quality of retrieval. A simple and effective idea for pretraining.\n This is the final video of our series on Open-domain question answering using dense retrievers. I will appreciate any feedback. Thanks for the support till now.\n https://www.youtube.com/watch?v=aQcoI1t6HOs\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugrr21/p_pretraining_dense_retrievers_with_masked/",
          "publishedOn": "2022-05-02T15:08:35.000Z",
          "wordCount": 215,
          "title": "[P] Pretraining dense retrievers with masked language model objective(REALM)",
          "imageUrl": "https://external-preview.redd.it/hmmZjMCwzPDE4nJ-IB3DabniaOls3JuP4HfAsCeNlJY.jpg?auto=webp&s=09eab6b0a51db8a5c9e060456f9ec6455f37cc8b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugp6b6/d_where_did_mtnlg_go_wrong_with_their_scaling/",
          "author": null,
          "description": "The MT-NLG model was 530B parameters compared to PaLM's 540B. They seem to have done things correctly from what I skimmed, However their model is neither that impressive on benchmarks, nor does it demonstrate any special capabilities.\n So what was the reason MT-NLG didn't work as well as expected? Is it possible it has abilities to explain jokes (on par PaLM) but they were undiscovered by the authors? Or are there any gaping flaws in how they scale the different hyperameters (heads, layers, dims etc.)?\n Perhaps such an analysis has already been done, but I would love to see what you guys think about why it underperformed... In such an unknown area as this, it seems that unless one scales models with multiple attempts it's hard to accurately judge when we would have reached the point where scaling laws fall off.\n    submitted by    /u/Competitive-Rub-1958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugp6b6/d_where_did_mtnlg_go_wrong_with_their_scaling/",
          "publishedOn": "2022-05-02T13:03:46.000Z",
          "wordCount": 347,
          "title": "[D] Where did MT-NLG go wrong with their scaling experiments, comparing its capabilities to PaLM?",
          "imageUrl": "https://external-preview.redd.it/PXcjoooiia3R7XYDppXw0Spu8Lb-_NYQ-hHC5_SJGZ4.jpg?auto=webp&s=eab286636b3305312472ec3a9120a72ac0bef157"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugo8ri/r_how_to_access_cvpr_21_workshop_extended/",
          "author": null,
          "description": "Hi everyone, I intend to submit a short paper to a 2022 CVPR workshop. I wanted to get inspiration from other CVPR short abstracts to see how they are written, their structure and so on. However, I'm really struggling a lot to find a place on the internet where I can download workshop extended abstracts from.\n Does anyone know where one can download the 2021 CVPR workshop short papers?\n    submitted by    /u/BigDataOverflow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugo8ri/r_how_to_access_cvpr_21_workshop_extended/",
          "publishedOn": "2022-05-02T12:11:56.000Z",
          "wordCount": 169,
          "title": "[R] How to access CVPR 21 workshop extended abstracts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugkws7/d_train_model_to_predict_continuous_variable/",
          "author": null,
          "description": "I have thousands of images of structures that I am trying to use to train a NN to predict their parameters. The inputs are the 2D images of the structure, and the output is the 1 parameter I am trying to predict (I have 2 parameters I am trying to predict but one is fine too). \n I have tried using the dimensions of the structure to predict the parameters but the error was too high.\n What do you recommend I do for this? \n Links are appreciated\n    submitted by    /u/ftority  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugkws7/d_train_model_to_predict_continuous_variable/",
          "publishedOn": "2022-05-02T08:25:39.000Z",
          "wordCount": 338,
          "title": "[D] Train model to predict continuous variable ranging from 0 to 1 using images as input.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugkeut/d_how_do_you_test_unit_integration_your_machine/",
          "author": null,
          "description": "First things first, do you test them at all? Practices can differ across companies..\n Secondly, I believe that testing process can differ based on the model use case (CV, NLP..) but is there any unified set of recommendations, good practices?\n  \nCan general approaches regarding unit and integration testing practices be applied to ML models/pipelines?\n What is your approach to this? If you feel like writing maybe you could write in comments: \n Area of ML that you are talking about: traditional ml algorithms, CV models, NLP models\n What are you testing? \n Is it the validity of the forward pass? (example: unit testing the shapes)\n Is it the validity of the training loop? (somehow)\n Are you testing if your model's performance is above some threshold? (example: accuracy, F1, bleu, maybe execution time?)\n Are you testing if your model is making correct predictions on some crucial cases\n Are you testing important metrics related to your dataset? (example: if it's properly standardized)\n \n \n  \nSome of this things can be tested pretty easily and don't require automated tests, but it is nice to have them. Do you have some other ways to do sanity checks?\n Please feel free to add other aspects of ML models/pipelines which are worth testing. Looking forward to your insights!\n    submitted by    /u/Icy_Fisherman7187  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugkeut/d_how_do_you_test_unit_integration_your_machine/",
          "publishedOn": "2022-05-02T07:48:04.000Z",
          "wordCount": 646,
          "title": "[D] How do you test (unit, integration) your Machine Learning models/pipelines?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugios2/d_what_programsoftware_can_make_animations_like/",
          "author": null,
          "description": "Hi, looking for advice for software/programs that can make animations like this one - thanks!\n https://upload.wikimedia.org/wikipedia/commons/transcoded/9/92/Infinitely_wide_neural_network.webm/Infinitely_wide_neural_network.webm.360p.vp9.webm\n    submitted by    /u/unital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugios2/d_what_programsoftware_can_make_animations_like/",
          "publishedOn": "2022-05-02T05:45:41.000Z",
          "wordCount": 126,
          "title": "[D] What program/software can make animations like this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugii9h/r_a_very_preliminary_analysis_of_dalle_2/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugii9h/r_a_very_preliminary_analysis_of_dalle_2/",
          "publishedOn": "2022-05-02T05:33:28.000Z",
          "wordCount": 413,
          "title": "[R] A very preliminary analysis of DALL-E 2",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugg2bz/p_the_easiest_way_to_process_and_tag_video_data/",
          "author": null,
          "description": "submitted by    /u/happybirthday290  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugg2bz/p_the_easiest_way_to_process_and_tag_video_data/",
          "publishedOn": "2022-05-02T02:59:17.000Z",
          "wordCount": 970,
          "title": "[P] The easiest way to process and tag video data",
          "imageUrl": "https://external-preview.redd.it/f0dNPu-fVdCAkoqQqsBJCdS0SkAnHV97eACL4oD-2mw.png?format=pjpg&auto=webp&s=1152c9a1acb55f0912fb90c16ecc847372e7bf36"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugfotg/d_how_to_effectively_sample_from_high_dimensional/",
          "author": null,
          "description": "So I have been working on generating data and creating a neural network to predict deformation in meshes, given some mesh parameters like thickness, elasticity, point of force, etc.\n What I know for sure is these parameters that I am creating a dataset for are/will be in a range and some meshes will have the same deformation for some combined different values of these parameters.\n What I have tried is uniformly sample from each of these parameters but this seems very data inefficient because there might be some blind spots in the combined sampling, say deformation for a particular combination of parameters can be different and unseen.\n My questing is how do you efficiently sample from a large multi-dimensional space, is there a better training method that would somehow inform another network to sample efficiently?\n ​\n I will be happy to explain more if this is somehow unclear.\n    submitted by    /u/bitemenow999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugfotg/d_how_to_effectively_sample_from_high_dimensional/",
          "publishedOn": "2022-05-02T02:37:58.000Z",
          "wordCount": 273,
          "title": "[D] How to effectively sample from high dimensional space and create data-efficient training.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugd0x4/d_multiple_pdf_files_similarity/",
          "author": null,
          "description": "Hi Everyone,\n I am developing one application in that I have multiple pdf files which user will upload then application will group those PDFs according to their similarity%(% entered by user) if user enters 80% it means documents with atleast 80% similarity will group in batch 1 and so on (similar pdf files will group into one batches i e. Batch 1, batch 2....). PDFs documents can be text or image or collection of both.\n I am using .Net Core and Angular. I tried Kmean algo but results are different everytime as an Algo is picking random files for centroids. How can i implement this?\n    submitted by    /u/ConsciousSlice4329  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugd0x4/d_multiple_pdf_files_similarity/",
          "publishedOn": "2022-05-02T00:08:41.000Z",
          "wordCount": 192,
          "title": "[D] Multiple PDF Files Similarity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ugbjv8/d_how_would_you_update_a_super_harsh_guide_to/",
          "author": null,
          "description": "Hey,\n So, I still see A Super Harsh Guide to Machine Learning get mentioned when people give advice for those new to the field.\n  \nFirst, read fucking Hastie, Tibshirani, and whoever. Chapters 1-4 and 7-8. If you don't understand it, keep reading it until you do.\n You can read the rest of the book if you want. You probably should, but I'll assume you know all of it.\n Take Andrew Ng's Coursera. Do all the exercises in python and R. Make sure you get the same answers with all of them.\n Now forget all of that and read the deep learning book. Put tensorflow and pytorch on a Linux box and run examples until you get it. Do stuff with CNNs and RNNs and just feed forward NNs.\n Once you do all of that, go on arXiv and read the most recent useful papers. The literature changes every few months, so keep up.\n There. Now you can probably be hired most places. If you need resume filler, so some Kaggle competitions. If you have debugging questions, use StackOverflow. If you have math questions, read more. If you have life questions, I have no idea.\n  \nHowever, the post is 5 years old and honestly seems out of date (with the Andrew Ng coursera stuff for ex).\n How would you update it?\n    submitted by    /u/Soft-Ear-6905  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ugbjv8/d_how_would_you_update_a_super_harsh_guide_to/",
          "publishedOn": "2022-05-01T22:52:08.000Z",
          "wordCount": 683,
          "title": "[D] How would you update \"A Super Harsh Guide to Machine Learning\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ug1mo6/pn_using_python_in_html_new_project_by_anaconda/",
          "author": null,
          "description": "Peter Wong, the co-founder and CEO of Anaconda, shared at PyCon US a new open source project called PyScript. The project's goal is to enable using Python in HTML files! This is a game-changer for Python dev in general and ML practitioners in particular. It unlocks a world of opportunities and sharability.\n Peter had a live coding session (respect!) and showed some of PyScript's capabilities. He started with a basic \"hello world\" example, or better yet \"hello PyCon\", and very quickly moved to show more advanced applications running on the browser, written in Python and wrapped in HTML!\n The first app was a super Mario game where he controlled the player with hand gestures using computer vision packages written in Python.\n The second one was an interactive dashboard of taxi travels in Manha…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ug1mo6/pn_using_python_in_html_new_project_by_anaconda/",
          "publishedOn": "2022-05-01T14:57:44.000Z",
          "wordCount": 642,
          "title": "[P][N] Using Python in HTML - New project by Anaconda",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ufzysu/d_meaningful_discussions/",
          "author": null,
          "description": "One of the reasons I left academia was the sense that I rarely actually had any meaningful discussions about research that interested me. I published, gave talks, went to conferences, went to workshops, tried to engage smart, important people... It was pretty common to get, \"interesting work\", \"nice jobs\", \"have you thought about using it for this problem...\" or to get superficial citations. But it was extremely rare to find someone who actually would think together about a topic, to care enough to constructively criticize, to delve into the details together, to share in the question and research.\n My question is for those that have found it at different times, what was the context? What did you do to find it? What did you do with it? Did you figure out how to nurture it? Is it easier online?\n    submitted by    /u/ChinCoin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ufzysu/d_meaningful_discussions/",
          "publishedOn": "2022-05-01T13:31:13.000Z",
          "wordCount": 42,
          "title": "[D] Meaningful discussions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ufvfdl/p_music2viz_conditioning_latent_diffusion_models/",
          "author": null,
          "description": "submitted by    /u/DoeL  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ufvfdl/p_music2viz_conditioning_latent_diffusion_models/",
          "publishedOn": "2022-05-01T08:25:37.000Z",
          "wordCount": 361,
          "title": "[P] music2viz: Conditioning Latent Diffusion Models on Audio Windows (proof of concept)",
          "imageUrl": "https://external-preview.redd.it/pWkkFNOeCYMQbeTlq6zeBuH9DrdkiikEDJvpW6hiUOw.jpg?auto=webp&s=670985f03b1610588bcede6c9fa02c14c20f3389"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ufspfj/rp_selfdistilled_stylegan_towards_generation_from/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ufspfj/rp_selfdistilled_stylegan_towards_generation_from/",
          "publishedOn": "2022-05-01T05:14:41.000Z",
          "wordCount": 251,
          "title": "[R][P] Self-Distilled StyleGAN: Towards Generation from Internet Photos + Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/7SD70t2jD_A8ptCAv2J85ncJVS8kZaecAQh_mPoNfVY.png?format=pjpg&auto=webp&s=7c9c88d27894161ae984b115aa5b26dadf4fa2df"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ufo3vr/p_how_forte_transforms_the_building_of_ml/",
          "author": null,
          "description": "submitted by    /u/julie_ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ufo3vr/p_how_forte_transforms_the_building_of_ml/",
          "publishedOn": "2022-05-01T00:37:07.000Z",
          "wordCount": 147,
          "title": "[P] How Forte Transforms the Building of ML Solutions with PyTorch into Assembly Lines",
          "imageUrl": "https://external-preview.redd.it/0pVkDc8cjnn1m848A5Ke7gndpZYChUUHOaBpbiII47E.jpg?auto=webp&s=81a18fbebeb23038c86cf7e437f326c7406661d7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ufiz5e/d_paper_explained_saycan_do_as_i_can_not_as_i_say/",
          "author": null,
          "description": "https://youtu.be/Ru23eWAQ6_E\n Large Language Models are excellent at generating plausible plans in response to real-world problems, but without interacting with the environment, they have no abilities to estimate which of these plans are feasible or appropriate. SayCan combines the semantic capabilities of language models with a bank of low-level skills, which are available to the agent as individual policies to execute. SayCan automatically finds the best policy to execute by considering a trade-off between the policy's ability to progress towards the goal, given by the language model, and the policy's probability of executing successfully, given by the respective value function. The result is a system that can generate and execute long-horizon action sequences in the real world to fulfil complex tasks.\n ​\n OUTLINE:\n 0:00 - Introduction & Overview\n 3:20 - Sponsor: Zeta Alpha\n 5:00 - Using language models for action planning\n 8:00 - Combining LLMs with learned atomic skills\n 16:50 - The full SayCan system\n 20:30 - Experimental setup and data collection\n 21:25 - Some weaknesses & strengths of the system\n 27:00 - Experimental results\n ​\n Paper: https://arxiv.org/abs/2204.01691\n Website: https://say-can.github.io/\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ufiz5e/d_paper_explained_saycan_do_as_i_can_not_as_i_say/",
          "publishedOn": "2022-04-30T20:08:58.000Z",
          "wordCount": 312,
          "title": "[D] Paper Explained - SayCan: Do As I Can, Not As I Say: Grounding Language in Robotic Affordances (Video)",
          "imageUrl": "https://external-preview.redd.it/JYRdXHKy9hHO5dzzXL6chYGvAmYopSqTnK7_Ovk5yxw.jpg?auto=webp&s=8da6c3e160847f82d55fd8ee7bf8ed107a00615a"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ufghef/d_deep_learning_in_neuroimaging/",
          "author": null,
          "description": "Check out the new Gradient article Deep Learning in Neuroimaging! \n  \nThis article provides an informal introduction to unique aspects of neuroimaging data and how we can leverage these aspects with deep learning algorithms. Specifically, this overview will first explain some common neuroimaging modalities more in-depth and then discuss applications of deep learning in conjunction with some of the unique characteristics of neuroimaging data. These unique characteristics tie into a broader movement in deep learning, namely that data understanding should be a goal in itself to maximize the impact of applied deep learning.\n  \nThe author is Eloy Geenjaar, a Ph.D. student at Georgia Tech who studies the functional dynamics of the brain using deep learning.\n    submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ufghef/d_deep_learning_in_neuroimaging/",
          "publishedOn": "2022-04-30T18:02:47.000Z",
          "wordCount": 201,
          "title": "[D] Deep Learning in Neuroimaging",
          "imageUrl": "https://external-preview.redd.it/3_LngMpfRlnNlqck_BmtS45_uFUAbO3WIRFy9af3rr8.jpg?auto=webp&s=f9fe7e6e99f7a285d8599d2ee92358f70fa2d7d3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ufei8t/research_hospitals_around_the_world_are_using_ai/",
          "author": null,
          "description": "submitted by    /u/MidnightMaverick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ufei8t/research_hospitals_around_the_world_are_using_ai/",
          "publishedOn": "2022-04-30T16:23:12.000Z",
          "wordCount": 705,
          "title": "[Research] Hospitals around the world are using AI algorithms to help predict length of stay to target care to the neediest patients and cut costs. A new systematic review published in PLOS Digital Health finds that they are institution & institution-data dependent: not generalizable to scale up",
          "imageUrl": "https://external-preview.redd.it/SljSvwAdTAX8HEBeH1fAg8fi-axly3JFESraQfWAdHA.jpg?auto=webp&s=81316bd05a1c02715e6a8154c44e536e1d4a04cc"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uf8mpz/r_a_technique_for_determining_relevance_scores_of/",
          "author": null,
          "description": "Process models generated through process mining depict the as-is state of a process. Through annotations with metrics such as the frequency or duration of activities, these models provide generic information to the process analyst. To improve business processes with respect to performance measures, process analysts require further guidance from the process model. In this study, we design Graph Relevance Miner (GRM), a technique based on graph neural networks, to determine the relevance scores for process activities with respect to performance measures. Annotating process models with such relevance scores facilitates a problem-focused analysis of the business process, placing these problems at the centre of the analysis. We quantitatively evaluate the predictive quality of our technique using four datasets from different domains, to demonstrate the faithfulness of the relevance scores. Furthermore, we present the results of a case study, which highlight the utility of the technique for organisations. Our work has important implications both for research and business applications, because process model-based analyses feature shortcomings that need to be urgently addressed to realise successful process mining at an enterprise level.\n https://www.researchgate.net/publication/349252283_A_technique_for_determining_relevance_scores_of_process_activities_using_graph-based_neural_networks\n https://www.sciencedirect.com/science/article/pii/S016792362100021X\n    submitted by    /u/Positive_Ad_1090  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uf8mpz/r_a_technique_for_determining_relevance_scores_of/",
          "publishedOn": "2022-04-30T10:46:51.000Z",
          "wordCount": 294,
          "title": "[R] A technique for determining relevance scores of process activities using graph-based neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uf71xy/d_paper_explained_palm_pathways_language_model/",
          "author": null,
          "description": "https://youtu.be/yi-A0kWXEO4\n This video explains and summarizes the 87 pages long PaLM: Pathways Language Models paper from Google AI’s Pathways. Yes, it is that 540 billion dense parameter model which can explain jokes and is sensitive to chain of thought reasoning.\n Paper link: https://arxiv.org/abs/2204.02311 \n PaLM blog post: https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\n ​\n Outline:\n 00:00 DALL-E 2 or PaLM?\n 01:14 Weights&Biases (Sponsor)\n 02:25 A brief history of boring large language models\n 03:43 What is PaLM?\n 05:11 Training PaLM on all TPUs\n 08:11 PaLM training data\n 08:49 What it can do\n 10:31 Few-shot learning explained\n 13:20 Explaining jokes and Outlook\n    submitted by    /u/AICoffeeBreak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uf71xy/d_paper_explained_palm_pathways_language_model/",
          "publishedOn": "2022-04-30T08:43:08.000Z",
          "wordCount": 202,
          "title": "[D] Paper Explained – PaLM Pathways Language Model explained | 540 Billion parameters can explain jokes!?",
          "imageUrl": "https://external-preview.redd.it/OSQDKD33PRN9tlLx_J5sneumyI2rgh-B5dyWa9b1FwQ.jpg?auto=webp&s=09f22cfa1d27153599a12797a08d7cb6736f2cc6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uf6t5a/n_a_brief_history_of_deepfakes/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uf6t5a/n_a_brief_history_of_deepfakes/",
          "publishedOn": "2022-04-30T08:22:21.000Z",
          "wordCount": 109,
          "title": "[N]: A brief history of deepfakes",
          "imageUrl": "https://external-preview.redd.it/YSDWQDpqz8bwWsnNMHTmmNyWDoN1p5UaUMaQ8yHo5Zs.jpg?auto=webp&s=a520a9f6d7f1d2ca77149d33cae80519ccac0139"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uf5k10/research_sources_for_transliteration_in_nlp/",
          "author": null,
          "description": "Looking for any sources you have found relevant or useful in regards to transliteration and machine translation in NLP. I am working on a subfield survey that requires ~30 sources so I am open to any!\n My specific interest is the transliteration of Arabic-based languages but this is not exclusively what will be covered.\n Thank you for your time and help\n    submitted by    /u/changethediaper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uf5k10/research_sources_for_transliteration_in_nlp/",
          "publishedOn": "2022-04-30T06:44:11.000Z",
          "wordCount": 156,
          "title": "[Research] Sources for Transliteration in NLP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uf552a/p_arcane_style_transfer_gradio_web_demo/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uf552a/p_arcane_style_transfer_gradio_web_demo/",
          "publishedOn": "2022-04-30T06:13:08.000Z",
          "wordCount": 469,
          "title": "[P] Arcane Style Transfer + Gradio Web Demo",
          "imageUrl": "https://preview.redd.it/jcw9homiylw81.png?auto=webp&s=a22675e48cc97ab76532eaf3f494f3fb5187e04e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uf4fcr/d_how_much_of_an_effort_is_adopting_ai_solution/",
          "author": null,
          "description": "While searching some information about automated machine learning (AutoML), I found in one article the next statement: \n \"For 58% of businesses it takes two years to get to the piloting stage. Furthermore, these big investments in data and AI projects are successful only 15% of the time.\"\n I was surprised out that only 15% of AI solution can be adopted... It is weird to see such a small precentage when a lot of companies are searching for DS and AI position for further analysis and getting as many as possible insight from the user/clients... Is that true? How's your situation?\n    submitted by    /u/wtfimdoingwithmylife  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uf4fcr/d_how_much_of_an_effort_is_adopting_ai_solution/",
          "publishedOn": "2022-04-30T05:23:45.000Z",
          "wordCount": 1234,
          "title": "[D] How much of an effort is adopting AI solution? (for the business)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uevhi8/d_usage_optimized_aws_gpus_5763_off_ondemand/",
          "author": null,
          "description": "www.usage.ai\n ​\n Usage AI bundles 3-year no-upfront RIs on AWS with guaranteed buyback -- so users get all the savings of 3-year RIs with none of the commitment. I helped engineer the product. Here to answer any questions!\n    submitted by    /u/usage-team  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uevhi8/d_usage_optimized_aws_gpus_5763_off_ondemand/",
          "publishedOn": "2022-04-29T21:01:05.000Z",
          "wordCount": 127,
          "title": "[D] Usage Optimized AWS GPUs, 57-63% off On-Demand Prices",
          "imageUrl": "https://external-preview.redd.it/1q91kcXx0zSJPpK_XzTILrP_ZDpW1sf5V9-r8ZFoTd4.jpg?auto=webp&s=0232e0342dc4b3174da06a45c93ad5f59643d9e4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ueur29/p_blog_post_learning_jax_by_learning_to_learn/",
          "author": null,
          "description": "I recently published a new blog post, which goes over how meta-learned optimizers work and how to implement them in JAX. JAX's composable function transforms make implementing meta-learning algorithms very straightforward. If you're interested in JAX or meta learning give it a read!\n Blog post: https://teddykoker.com/2022/04/learning-to-learn-jax/\n Code: https://github.com/teddykoker/learning-to-learn-jax\n Original Paper (NeurIPS '16): https://arxiv.org/abs/1606.04474\n    submitted by    /u/tomkoker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ueur29/p_blog_post_learning_jax_by_learning_to_learn/",
          "publishedOn": "2022-04-29T20:26:07.000Z",
          "wordCount": 167,
          "title": "[P] Blog post: Learning JAX by Learning to Learn",
          "imageUrl": "https://external-preview.redd.it/NU5c2u13A5-C4nwHN_Fne23YnW0eSrq-EroxvJKaDSg.jpg?auto=webp&s=5b10ea95707da5c77eb6c49abd372355abca8ab7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uepago/p_introducing_flowmeter_for_network_packet/",
          "author": null,
          "description": "We’ve released a new open source project - https://github.com/deepfence/FlowMeter - to analyze and classify packet captures using ML techniques. \n FlowMeter is an experimental project; we’re using it to evaluate how effectively we can train an ML model to discriminate between different types of traffic flows, e.g. normal and anomalous. You can use sample data from various sources (see the README), or gather packet captures using PacketStreamer https://github.com/deepfence/PacketStreamer or other pcap tools.\n More information in the README, here: https://github.com/deepfence/FlowMeter and this blogpost: https://medium.com/@siddharthsatpathy.ss/introducing-flowmeter-97e0507862b6\n Hope some people find it useful; we’d welcome any feedback, thank you.\n    submitted by    /u/sidd_ss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uepago/p_introducing_flowmeter_for_network_packet/",
          "publishedOn": "2022-04-29T16:07:40.000Z",
          "wordCount": 191,
          "title": "[P] Introducing FlowMeter for network packet analysis",
          "imageUrl": "https://external-preview.redd.it/hMRmaTL6DrpArwTLSVLHQyY2o2e9fVJcTPz6QZHGG1s.jpg?auto=webp&s=dd5f91f06e750c7715004cd670c892bc8867a1dc"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ueod3x/p_opensource_python_library_for_making_machine/",
          "author": null,
          "description": "https://gradio.app/ is for demoing machine learning models\n https://reddit.com/link/ueod3x/video/75e1ozmjihw81/player\n Prerequisite: Python 3.7+ and that's it!\n Quick Start\n To get Gradio running with a simple \"Hello, World\" example, follow these three steps:\n  \nInstall Gradio from pip.\n  \n​\n pip install gradio \n  \nRun the code below as a Python script or in a Python notebook (or in a colab notebook).\n  \n​\n import gradio as gr def greet(name): return \"Hello \" + name + \"!!\" demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\") if __name__ == \"__main__\": demo.launch() \n  \nThe interface below will appear automatically within the Python notebook, or pop in a browser on http://localhost:7860 if running from a script.\n  \nsee more in the getting started guide: https://gradio.app/getting_started/\n    submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ueod3x/p_opensource_python_library_for_making_machine/",
          "publishedOn": "2022-04-29T15:25:24.000Z",
          "wordCount": 490,
          "title": "[P] open-source python library for making machine learning demos that runs in the browser or inside a jupyter notebook/google colab, package is available on PyPI",
          "imageUrl": "https://external-preview.redd.it/_jq3RHJF4dWo0ICB0aESwOXlW3jCTwldBtbIIuFynSw.jpg?auto=webp&s=8bf1e5972aabb7d81fcda17ccbee87891e8cf6ae"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uemwxw/p_hot_reloading_for_pandas/",
          "author": null,
          "description": "Hi guys I thought you might find my project useful. It's called Reloadium and saves a lot of time during python development, especially in data science and machine learning field.\n More details here: https://github.com/reloadware/reloadium\n Hot Reloading dataframes\n Modifying and fixing code during debugging\n What do you guys think about it?\n    submitted by    /u/kwazar90  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uemwxw/p_hot_reloading_for_pandas/",
          "publishedOn": "2022-04-29T14:16:51.000Z",
          "wordCount": 295,
          "title": "[P] Hot Reloading for Pandas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uellgx/d_shap_method_to_get_feature_importance_is/",
          "author": null,
          "description": "The SHAP method assumes linear relationship between the feature effects (see definition \"Additive feature attribution methods\" in the paper). But is this assumption realistic?\n    submitted by    /u/savoga  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uellgx/d_shap_method_to_get_feature_importance_is/",
          "publishedOn": "2022-04-29T13:10:33.000Z",
          "wordCount": 410,
          "title": "[D] SHAP method to get feature importance: is linearity realistic?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uelb5r/d_need_to_find_a_good_selfhosted_medical_image/",
          "author": null,
          "description": "Hi.\n I'm trying to come up with a solution for a medical image annotation system for our laboratory. We need it to be self-hosted (in order to only work in the uni's internal network), and open source (since the funds are limited). So far I've only found out about https://lab.vindr.ai/dashboard/projects but the documentation is really bad and I could not launch it using docker compose.\n I've also found MONAILabel(https://github.com/Project-MONAI/MONAILabel), but it apparently requires GPU which makes it really expensive. I'd rather find a cpu based solution because our task is not that complex. We only get some Dicom files (each have studies in them), and want to label them.\n    submitted by    /u/feryet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uelb5r/d_need_to_find_a_good_selfhosted_medical_image/",
          "publishedOn": "2022-04-29T12:55:21.000Z",
          "wordCount": 417,
          "title": "[D] Need to find a good self-hosted medical image annotation tool.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uek252/machine_learning_in_fantasy_premier_league_d/",
          "author": null,
          "description": "https://medium.com/@subin.sen7/our-client-is-the-worlds-best-fpl-player-this-is-not-clickbait-51481fae76c9\n Is it possible to use models to beat the market in Fantasy Football?\n    submitted by    /u/AI_FPL  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uek252/machine_learning_in_fantasy_premier_league_d/",
          "publishedOn": "2022-04-29T11:45:22.000Z",
          "wordCount": 105,
          "title": "Machine Learning in Fantasy Premier League? [D]",
          "imageUrl": "https://external-preview.redd.it/enpNzajWS27FWnQUCbVKw4WBEQaKB_HriVo70C_M9VA.jpg?auto=webp&s=0e7cca3c2815679fe6e31efa36a0a8b04c817839"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uejmts/p_xgboost_sklearn_and_others_running_over/",
          "author": null,
          "description": "Hello everyone! Following this post numpy in fhe we are releasing a new lib that allows popular machine learning frameworks to run over encrypted data: https://github.com/zama-ai/concrete-ml\n Currently this supports xgboost and many sklearn models. We also support pytorch to some extent.\n We are trying to closely follow sklearn API (when relevant) to make the use easy to machine learning practitioners.\n Happy to hear any feedback on this !\n    submitted by    /u/strojax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uejmts/p_xgboost_sklearn_and_others_running_over/",
          "publishedOn": "2022-04-29T11:19:15.000Z",
          "wordCount": 417,
          "title": "[P] XGboost, sklearn and others running over encrypted data",
          "imageUrl": "https://external-preview.redd.it/0jPVa-YX3cMiXsnd8pYzE5l0xTdGNHr17zoYi7kAU6I.jpg?auto=webp&s=70ae7b188277db71efacf81fafe144549f513458"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ueh2n3/d_is_tensorflowjs_still_much_slower_than/",
          "author": null,
          "description": "Last time I used Tensorflow was 3 years ago and it was a resource hog as well as very slow.\n I intend to get back into machine learning and wondering if I should give Tensorflow.js a go again using the Nodejs backend since this will be an electron app. Or should I just go straight for Tensorflow.\n Ideally I will need about 15 fps while taking up minimal resources\n    submitted by    /u/manrayboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ueh2n3/d_is_tensorflowjs_still_much_slower_than/",
          "publishedOn": "2022-04-29T08:09:11.000Z",
          "wordCount": 208,
          "title": "[D] Is Tensorflow.js still much slower than Tensorflow",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uefz2l/d_collaborationfirst_machine_learning_platform/",
          "author": null,
          "description": "Hey r/MachineLearning,\n I'm Derrick from Layer (layer.ai) - the collaboration-first machine learning platform that enables you to build, train, track, and share your ML projects simply with a few lines of code.\n We are soft-launching today! I’ve been working on Layer for the past 2 years with an awesome team around the world. We really poured our hearts and minds into Layer and hope you will like it. Your feedback would be very appreciated!\n Layer Demo\n To get started, you can simply run our Quickstart Example!\n How is Layer different from other tools?\n  \nAlthough there are plenty of ML and DS tooling products, we believe that there is still a large gap around collaboration. Many data science projects are hosted on GitHub, which, in our experience, does not provide sufficient depth and abs…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uefz2l/d_collaborationfirst_machine_learning_platform/",
          "publishedOn": "2022-04-29T06:47:32.000Z",
          "wordCount": 1053,
          "title": "[D] Collaboration-first machine learning platform that enables you to build, train, track, and share your ML projects simply with a few lines of code",
          "imageUrl": "https://external-preview.redd.it/OubaRzJP4HG9cTtZ4rl78KwTiCb4kqMagYFREoJcAe0.jpg?auto=webp&s=bfa96e508b3895c4f9042183b949d1c31eac2ac9"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ue68z4/d_any_independent_researchers_ever_get/",
          "author": null,
          "description": "For personal context: I worked over time during my bachelors and took grad classes/started research, but financial situation took a hit for the worse and we'll let's say I don't have enough money for a Masters/continue my studies. I'm job hunting now but in a chicken/egg problem most of these jobs want at the very least research (which I know how to conduct) for which they have the resources for. Either way I have a couple research topics I want to explore, but limited resources and want to be realistic here.\n main question: do you know of anyone who has done it as a non-grad/non-institutional way without the help of established figures in the field. I only know of those that have done it in the way I describe above (either under an established researcher's team, a university, or a company)?\n Add-on: would appreciate any personal experiences as well, and if anyone has experience with conferences/how long it takes, etc. My research experience has been largely under NDAs so I haven't experienced formal publishing yet (but want to!)\n    submitted by    /u/robml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ue68z4/d_any_independent_researchers_ever_get/",
          "publishedOn": "2022-04-28T21:50:26.000Z",
          "wordCount": 469,
          "title": "[D] Any independent researchers ever get published/into conferences?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ue5qk5/d_feature_embeddings_extraction_for_image/",
          "author": null,
          "description": "Is there any rule of thumb to decide from which layer extract feature embeddings for classification tasks based on knn? Does it depend by the architecture ?(conv net , vs vit models, ecc) Should I extract before or after activation function?\n Edit: Which model do you suggest to start from ? Actually i'm using a resnet50 trained with DINO\n    submitted by    /u/Rich_Freedom98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ue5qk5/d_feature_embeddings_extraction_for_image/",
          "publishedOn": "2022-04-28T21:27:13.000Z",
          "wordCount": 172,
          "title": "[D] feature embeddings extraction for image classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ue4uhf/p_terraform_provider_iterative_tpi_plugin_for/",
          "author": null,
          "description": "Terraform Provider Iterative (TPI) address the specific needs of machine learning teams - it is an open-source tool extending the functionality of Terraform, the world's most widely used multi-cloud provisioning product. The tool enables full lifecycle management of computing resources and is designed specifically for machine learning pipelines: Terraform plugin for machine learning workloads: spot instance recovery & auto-termination | AWS, GCP, Azure, Kubernetes\n The tool aims to bridge the gap between devops and data science teams and build on top of Terraform, a tool universally familiar to devops teams, but extend it to suit machine learning needs. It provides to following advantages for your ML workflow:\n  \nLower cost: use your preferred cloud provider's existing pricing, including on-demand per-second billing and bulk discounts.\n Auto-recovery: spot/preemptible instances are cheap but unreliable. TPI reliably and automatically respawns such interrupted instances, caching & restoring the working directory in the cloud even when you are offline.\n Custom spec: full control over hardware & software requirements via a single config file.\n  \n   submitted by    /u/cmstrump  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ue4uhf/p_terraform_provider_iterative_tpi_plugin_for/",
          "publishedOn": "2022-04-28T20:48:15.000Z",
          "wordCount": 299,
          "title": "[P] Terraform Provider Iterative (TPI) - plugin for ML/AI workloads to spot instance recovery & auto-termination on AWS, GCP, Azure, Kubernetes",
          "imageUrl": "https://external-preview.redd.it/-XxBSq8jUyFCgZp7IOZGfLvGhWFiMYpRGwAe-o_FnXU.jpg?auto=webp&s=0010d34c869946a94ed40e6b057e7c7e18f61da6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ue2ptk/r_flamingo_a_visual_language_model_for_fewshot/",
          "author": null,
          "description": "Paper (pdf). A link to the paper is also in this blog post.\n Abstract:\n  \nBuilding models that can be rapidly adapted to numerous tasks using only a handful of annotated examples is an open challenge for multimodal machine learning research. We introduce Flamingo, a family of Visual Language Models (VLM) with this ability. Flamingo models include key architectural innovations to: (i) bridge powerful pretrained vision-only and language-only models, (ii) handle sequences of arbitrarily interleaved visual and textual data, and (iii) seamlessly ingest images or videos as inputs. Thanks to their flexibility, Flamingo models can be trained on large-scale multimodal web corpora containing arbitrarily interleaved text and images, which is key to endow them with in-context few-shot learning capabilities. We perform a thorough evaluation of the proposed Flamingo models, exploring and measuring their ability to rapidly adapt to a variety of image and video understanding benchmarks. These include open-ended tasks such as visual question-answering, where the model is prompted with a question which it has to answer, captioning tasks, which evaluate the ability to describe a scene or an event, and close-ended tasks such as multiple choice visual question-answering. For tasks lying anywhere on this spectrum, we demonstrate that a single Flamingo model can achieve a new state of the art for few-shot learning, simply by prompting the model with task-specific examples. On many of these benchmarks, Flamingo actually surpasses the performance of models that are fine-tuned on thousands of times more task-specific data.\n  \n   submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ue2ptk/r_flamingo_a_visual_language_model_for_fewshot/",
          "publishedOn": "2022-04-28T19:12:19.000Z",
          "wordCount": 368,
          "title": "[R] Flamingo: a Visual Language Model for Few-Shot Learning (from DeepMind)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ue2pac/d_selforganizing_maps_and_principal_component/",
          "author": null,
          "description": "Hello all, I am doing my PhD on numerical modelling of solar radiation and I am researching SOMs as a possible tool. I have this problem where I can't decide on a network size, so I have been trying to develop some means to compare SOM neurons from different sized networks. I have read that the 2-d SOM array tends to spam the 2 highest variance principal components. So would it be adecuate to tag my SOM nodes with the first two proyections of PCA? So that I can compare results from different experiments.\n    submitted by    /u/juliancanellas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ue2pac/d_selforganizing_maps_and_principal_component/",
          "publishedOn": "2022-04-28T19:11:39.000Z",
          "wordCount": 189,
          "title": "[D] Self-Organizing Maps and Principal Component Analysis.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ue1wuu/discussion_same_mae_result/",
          "author": null,
          "description": "Hello guys, I'm wondering if you can help: we use machine learning models to identify trading opportunities using historical trading data of price and market indicators.\n The data we use is fine: abundant, accurate and (manually) proven to work over several non-sequential months in the past.\n The problem is that we keep on getting the exact same MAE result.\n Any suggestions on solving this issue would be immensely appreciated.\n    submitted by    /u/AFAC1410  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ue1wuu/discussion_same_mae_result/",
          "publishedOn": "2022-04-28T18:36:41.000Z",
          "wordCount": 267,
          "title": "\"[Discussion]\", Same MAE Result",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ue1wda/p_new_blog_post_how_to_automatically_find_label/",
          "author": null,
          "description": "Hi folks, our blog post on how to automatically find label errors in audio datasets has just gone live. We cover the steps to:\n  \n⛏️ Perform feature extraction (aka embeddings) on the Spoken Digit dataset with a pre-trained PyTorch model.\n 🔢 Use cross-validation to generate out-of-sample predicted probabilities for every example in the dataset.\n 🏷️ Run one line of cleanlab code on these predicted probabilities to identify which audio clips may be mislabeled.\n  \n📰 Blog Post + Google Colab: https://cleanlab.ai/blog/label-errors-audio-datasets/\n https://preview.redd.it/vpzhwg6jebw81.png?width=1260&format=png&auto=webp&s=3fa79d8a097ae5936e5e6a51e87508adf6190835\n    submitted by    /u/weijinglok  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ue1wda/p_new_blog_post_how_to_automatically_find_label/",
          "publishedOn": "2022-04-28T18:36:05.000Z",
          "wordCount": 192,
          "title": "[P] New blog post: how to automatically find label errors in your audio datasets!",
          "imageUrl": "https://external-preview.redd.it/nlSZWIluTA6ZDe83fPm_5Tc_-4lIemU0LMmRfPSmJyA.jpg?auto=webp&s=011b088a27521f2df7eeabf7c121cc2db0a66ab8"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ue0pcc/shazam_app_for_your_brain_r/",
          "author": null,
          "description": "https://arxiv.org/abs/2202.03265?context=eess\n Computer vision approach to processing naturalistic brain responses to music. Models achieved state of the art and they used publicly available datasets. With 1 sec of brain signal they can classify the name of the song you're listening to and how much you enjoyed it ~89%. \n Imagine this but on your airpods, seems wild.\n    submitted by    /u/blackliquerish  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ue0pcc/shazam_app_for_your_brain_r/",
          "publishedOn": "2022-04-28T17:43:24.000Z",
          "wordCount": 145,
          "title": "Shazam App for your brain? [R]",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udzloe/d_what_roles_were_you_able_to_receive_as_a_phd/",
          "author": null,
          "description": "It’s looking more and more like I won’t be able to get any top tier publications in my PhD (NeurIPS, ICLR, etc.). I’ve tried, but various factors have limited the experience. I’m curious what people were able to do in this circumstance. I’ll have 3-5 publications in mid-tier venues, plus many years of experience as a software engineer and machine learning engineer (in non-tech companies). People in my program have gone on to work at Amazon, and a few Google, but these were all applied scientist and engineering roles. Does anyone go on to work as a research scientist? National labs seem like a good bet, I’m curious what others have done.\n    submitted by    /u/walterkronkite33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udzloe/d_what_roles_were_you_able_to_receive_as_a_phd/",
          "publishedOn": "2022-04-28T16:54:59.000Z",
          "wordCount": 1393,
          "title": "[D] What roles were you able to receive as a PhD with no top tier research?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udzc5g/d_have_we_stopped_researching_agents/",
          "author": null,
          "description": "It seems to me that the ML research community has stopped talking about agents? As in, machines that act in complex environments by themselves?\n Ever since GPT-3 came out, bascially every single paper has been related to NLP or Transformers in general.\n It seems a natural next step would be to try to get agents we could tell what to do and how to do it in natural language, no? \n Yet that has not been the focus at all.\n The last time we had wide spread focus on planning and acting was the Starcraft challenge, but that was \"solved\" so quickly nothing much came of it.\n Research I know about: - Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents - Tesla in general I guess, with their cars and maybe robots\n Is it just me or is there just no interest in researching more capable agents right now?\n    submitted by    /u/ReasonablyBadass  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udzc5g/d_have_we_stopped_researching_agents/",
          "publishedOn": "2022-04-28T16:43:30.000Z",
          "wordCount": 630,
          "title": "[D] Have we stopped researching agents?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udua96/d_advertisement_allocation_models_being_used/",
          "author": null,
          "description": "There are a bunch of papers on different advertisement allocation techniques (placing ads to valid ad spots) and in algorithms in grad school I learned MaxFlow/MinCut, but I'm wondering what is actually being used in production systems? Linear models, genetic algorithms, reinforcement learning, some neural network?\n I know that very little of this is published/talked about due to being proprietary. However, I'm wondering because so much gets published, but the more advanced algorithms tend to be complex and not necessarily possible to be deployed in production systems (what I suspect)?\n    submitted by    /u/Flipper3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udua96/d_advertisement_allocation_models_being_used/",
          "publishedOn": "2022-04-28T12:52:31.000Z",
          "wordCount": 632,
          "title": "[D] Advertisement Allocation models being used?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uds4d8/d_ml_model_dev_pipelines/",
          "author": null,
          "description": "Hi Folks!\n It'd really help if you can participate in this poll and share about your ML/DL model workflow before moving it to production. \n Out of these steps, which one is your most preferred way of integrating ML into your app or business (not specific to any domain):\n View Poll\n    submitted by    /u/fgp121  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uds4d8/d_ml_model_dev_pipelines/",
          "publishedOn": "2022-04-28T10:44:49.000Z",
          "wordCount": 337,
          "title": "[D] ML model dev pipelines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udro6m/r_rl_papers_relating_to_green_vehicle_routing/",
          "author": null,
          "description": "My current work requires me to work with GVRP. The specific problem is for an EV (agent) to find the optimal route to deliver items based on charge consumption and not discharging. I'm currently modelling it as a graph datastructure although it could be different.\n Are there any papers (both RL and exact method based) for state of the art that I can look into regarding this. I'm also interested in earlier papers that can help me build understanding, and I can increase complexity slowly.\n Thanks for the help!\n    submitted by    /u/evilBotman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udro6m/r_rl_papers_relating_to_green_vehicle_routing/",
          "publishedOn": "2022-04-28T10:13:37.000Z",
          "wordCount": 227,
          "title": "[R] RL papers relating to Green Vehicle Routing Problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udpvl8/d_what_is_the_recommended_way_to_estimate_norm/",
          "author": null,
          "description": "I have read several blogs in which they specified that you should clip your gradients to the largest value that doesn't cause exploding gradients. But that also means that you could get a situation that you don't need to do gradient clipping at all. \n Could that hurt convergence speed in some way? Is there any guideline for how to pick this hyperparameter based on learning rate, batch size, model size, input size (seq len, img size) etc.?\n Or is this project/use case dependent and it represents \"just another hyperparameter\"?\n    submitted by    /u/Icy_Fisherman7187  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udpvl8/d_what_is_the_recommended_way_to_estimate_norm/",
          "publishedOn": "2022-04-28T07:57:57.000Z",
          "wordCount": 238,
          "title": "[D] What is the recommended way to estimate norm for gradient clipping?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udowdg/p_huspacy_industrialstrength_hungarian_nlp/",
          "author": null,
          "description": "I'd like to show off a Hungarian NLP pipeline which we've been heavily improving over the past year. https://github.com/huspacy/huspacy\n While processing Hungarian texts might not be interesting for the most of you, I believe this project can be a good learning resource, as our models utilize the latest NLP technologies from Explosion and are fully reproducible:\n  \nWe've created a transformers-based model on top of a language specific BERT model\n Multi-task and transfer-learning is heavily used across the models.\n Incorporated edit-tree lemmatization and biaffine parsing from spacy-experimental\n We provide word embeddings using the (fastText-like) floret tool\n  \n   submitted by    /u/oroszgy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udowdg/p_huspacy_industrialstrength_hungarian_nlp/",
          "publishedOn": "2022-04-28T06:48:04.000Z",
          "wordCount": 185,
          "title": "[P] HuSpaCy: Industrial-strength Hungarian NLP",
          "imageUrl": "https://external-preview.redd.it/29Ua3fFKf_d8Suh0HTMsiuIiHC460BBA04-YIwEjBnY.jpg?auto=webp&s=942267117f3998b8a3a24af8cbda146fd9e4e462"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udnkue/d_how_do_you_decide_the_ranges_for/",
          "author": null,
          "description": "I'm trying to tune the parameters of two models - a random forest classifier, and a gradient boosting classifier. When using a grid search or a random search (I might also play around with the genetic algorithm), what are appropriate ranges to use / how can I come to know them? I obviously can't just specify a very arbitrary range because that might decrease the effectiveness of the random search, and make the grid search too long.\n Do they depend on the number of features in the dataset or other characteristics (e.g. our dataset is quite imbalanced and we're using SMOTE resampling)? I'm just trying to tune n_estimators and max_depth, but RandomForestClassifier also has many other parameters, do I just experiment with all of them, or are there any known parameters that don't do anything useful unless I'm trying for an extra 0.1% of accuracy or recall?\n Basically the same questions as above for the GradientBoostingClassifier. Letting go of specific models for a second, I'd appreciate generic pointers on how to deliberately tune hyperparameters or specify ranges instead of just arbitrarily specifying sth and hoping it works. Thanks!\n    submitted by    /u/stuffingmybrain  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udnkue/d_how_do_you_decide_the_ranges_for/",
          "publishedOn": "2022-04-28T05:19:23.000Z",
          "wordCount": 723,
          "title": "[D] How do you decide the ranges for hyperparameters when doing a grid search or a random search?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udml1k/how_to_do_meaningful_work_as_an_independent/",
          "author": null,
          "description": "With big players like OpenAI and Google building these massive models, how does independent researchers without access to such scale and compute do meaningful work? Came across tweets from researchers, especially ones working on generative models saying they feel their work looks irrelevant after seeing results from DALL-E 2. It feels like just a couple of years ago if you had a decent GPU setup, you could pretty much do world class research. Doesn't look like it anymore. Is there, if any, research directions that makes it a level playing field where compute and scale is not necessarily the solution, or are we all doomed to be prompt engineers for GPT models?\n    submitted by    /u/HairyIndianDude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udml1k/how_to_do_meaningful_work_as_an_independent/",
          "publishedOn": "2022-04-28T04:19:52.000Z",
          "wordCount": 1259,
          "title": "How to do meaningful work as an independent researcher? [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udh3l4/p_autoencoder_image_dimension_error/",
          "author": null,
          "description": "Hello,\n I have a problem regarding my auto-encoder model. I built it so it can be able to give a MSE error abnormally high when presented an image too different from what it knows.\n I have this little function at the end of my program to predict whether or not the image presented is an anomaly : `\n def check_anomaly(img_path): density_threshold = 2500 #Set this value based on the above exercise reconstruction_error_threshold = 0.004 # Set this value based on the above exercise img = Image.open(img_path) img = np.array(img.resize((128,128), Image.ANTIALIAS)) plt.imshow(img) img = img / 255. img = img[np.newaxis, :,:,:] encoded_img = encoder_model.predict([[img]]) encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] density = kde.score_samples(encoded_img)[0] reconstruc…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udh3l4/p_autoencoder_image_dimension_error/",
          "publishedOn": "2022-04-27T23:35:00.000Z",
          "wordCount": 398,
          "title": "[P] Auto-encoder image dimension error",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udgyy4/whats_the_actual_difference_in_simple_terms/",
          "author": null,
          "description": "I've also noticed Cloudera and DataRobot seem to follow user pricing where DataBricks follows the standard hourly machine rate.\n    submitted by    /u/SmarterChild8675309  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udgyy4/whats_the_actual_difference_in_simple_terms/",
          "publishedOn": "2022-04-27T23:28:25.000Z",
          "wordCount": 141,
          "title": "What's the actual difference in simple terms between Cloudera Data Science Workbench, DataRobot, and DataBricks? [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udgtn8/project_multibounding_box_identification/",
          "author": null,
          "description": "I have a data set of satellite images of aircraft. For the labels of these images I have the bounding boxes for all aircraft in that image. \n I looking for some advice on where to get started for this. I need to estimate all bounding boxes for these aircraft, any suggestions?\n    submitted by    /u/The_Dov  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udgtn8/project_multibounding_box_identification/",
          "publishedOn": "2022-04-27T23:20:52.000Z",
          "wordCount": 136,
          "title": "[Project] Multi-Bounding box identification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udfnow/d_nlp_anyone_familiar_with_taxonomy_extraction/",
          "author": null,
          "description": "Hi all, does anyone have experience with automatic taxonomy/ontology extraction from unlabelled corpus, especially how to evaluate the extracted structures without gold standards? most published papers would invite students/researchers to conduct manual reviews, thus making it very difficult to compare the results. thanks in advance.\n    submitted by    /u/CestLucas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udfnow/d_nlp_anyone_familiar_with_taxonomy_extraction/",
          "publishedOn": "2022-04-27T22:25:45.000Z",
          "wordCount": 146,
          "title": "[D] NLP: anyone familiar with taxonomy extraction and evaluation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/udfe70/d_precisionrecall_curve_with_best_f1_score_of_056/",
          "author": null,
          "description": "I am evaluating the performance of a model. I get different Precison-Recall curves for different configurations and the best F1 score (0.56) corresponds to the red point.\n Would you consider this performance acceptable? I know there is a lot of room for improvement but is it okay or is it extremely poor performance? \n https://preview.redd.it/k5qihccdb5w81.png?width=784&format=png&auto=webp&s=a0f3408f2ff671ee491faa50752b6c8e0cf17e4c\n Also, if I understood it correctly, each point of the Precision-Recall curve has its own F1 Score, right? \n Thank you!\n    submitted by    /u/SeaResponsibility176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/udfe70/d_precisionrecall_curve_with_best_f1_score_of_056/",
          "publishedOn": "2022-04-27T22:13:30.000Z",
          "wordCount": 251,
          "title": "[D] Precision-Recall curve with best F1 Score of 0.56",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uddtfk/p_surgeonpytorch_a_small_library_to_inspect/",
          "author": null,
          "description": "I've made surgeon https://github.com/archinetai/surgeon-pytorch, a small library to inspect the intermediate output layers of pyTorch models without changing the original implementation. \n This can be very useful if you are using pre-trained models (e.g. from Huggingface or torch.hub) and want to get embeddings, attention matrices, or simply debug the model without adding additional code – which is often hard to do without changing the implementation. \n I hope this can be helpful to anyone!\n    submitted by    /u/Aglitter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uddtfk/p_surgeonpytorch_a_small_library_to_inspect/",
          "publishedOn": "2022-04-27T21:02:14.000Z",
          "wordCount": 318,
          "title": "[P] surgeon-pytorch – a small library to inspect intermediate layers of pyTorch models",
          "imageUrl": "https://external-preview.redd.it/GfNtmlOALy2qPJTqc8lzA4kMijLNMdDehBmOSdm1Yfs.jpg?auto=webp&s=520434ad32e7b9ccc91085e3e6b5a2b14d4eafdd"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ud7fpj/d_thoughts_on_the_ai4_conference/",
          "author": null,
          "description": "Lately, I have been receiving many messages from the organizers of this conference that they have some free passes to pass on to attend it: https://ai4.io/usa/\n While the speaker line-up from the industry appears impressive, I have not heard of this conference before. Any thoughts on how legit/good this conference is?\n    submitted by    /u/roalddahl14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ud7fpj/d_thoughts_on_the_ai4_conference/",
          "publishedOn": "2022-04-27T16:21:16.000Z",
          "wordCount": 191,
          "title": "[D] Thoughts on the AI4 conference?",
          "imageUrl": "https://external-preview.redd.it/vyJJT50EGwHVImil3h_asT64ZX5iOhxVNuYdSZJ3zOE.jpg?auto=webp&s=de0ff8a39e1e60f514ee5dfda6cb778f9a7fe504"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ud6d5k/d_has_anyone_attempted_to_recreate_the_work/",
          "author": null,
          "description": "The D3VO paper from the Tech. University of Munich looks quite promising, however that Uni does not seem very keen on publishing code along with their papers.\n  \nHas already tried to reproduce their work?\n What kind of results did you see in your version?\n What hardware did you run it on?\n How difficult was it reproduce their models in pytorch?\n  \n   submitted by    /u/autojazari  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ud6d5k/d_has_anyone_attempted_to_recreate_the_work/",
          "publishedOn": "2022-04-27T15:34:55.000Z",
          "wordCount": 284,
          "title": "[D] Has anyone attempted to recreate the work describe in the Deep Depth, Deep Pose and Deep Uncertainty for Monocular Visual Odometry Paper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ud5lwj/d_are_gflow_nets_considered_diffusion_models/",
          "author": null,
          "description": "I stumbled upon GFlow Net and in my opinion, it looks very similar to diffusion models. There is a touch of RL in GFlow Net but the main idea is very similar to diffusion models. is that right? or am I missing something?\n    submitted by    /u/dimem16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ud5lwj/d_are_gflow_nets_considered_diffusion_models/",
          "publishedOn": "2022-04-27T15:01:15.000Z",
          "wordCount": 141,
          "title": "[D] - Are GFlow Nets considered diffusion models?",
          "imageUrl": "https://external-preview.redd.it/xt4KuiGWfCTbR-L_p15LcUpfjzRbwzvENIX7r-10sys.jpg?auto=webp&s=6a80c1b9d996d296de86e49265660525db7221eb"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ud52m3/d_how_is_it_checked_if_models_do_not_just/",
          "author": null,
          "description": "Hello everyone,\n this post is about generative models! (i.e. Score-based-generative models, GANs, etc.)\n on leaderboards like this https://paperswithcode.com/sota/image-generation-on-cifar-10\n How do they check if the models do not just memorize the training examples? The FID score would be optimal in case you would just generate training examples again.\n Best\n    submitted by    /u/future_gcp_poweruser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ud52m3/d_how_is_it_checked_if_models_do_not_just/",
          "publishedOn": "2022-04-27T14:37:11.000Z",
          "wordCount": 1461,
          "title": "[D] How is it checked if models do not just memorize their training examples?",
          "imageUrl": "https://external-preview.redd.it/BRYZbV7wdpRHf9T9M4rLc9TUkuvAr9ASmT5B1SEG1VU.jpg?auto=webp&s=423224b23ce955449a3bcd518cff1558c693e1b3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ud48ty/d_iclr_2022_blog_post_track/",
          "author": null,
          "description": "It seems like the list of accepted blog posts has been published for the ICLR 2022 blog post track (https://iclr-blog-track.github.io/). They also invited Karpathy to publish his most recent blog post on the history and future of convnets.\n What do you think about the blog posts? Any blog posts that you particularly like or that are definitely worth reading? Any blog posts that actually have interesting contributions and/or that you plan to cite?\n But maybe more importantly: how do you think this will evolve? They seem to have decided to organise the blog post track again for next year's ICLR already. Do you think these kind of publications could have an impact on how we do science or is this rather a nice extra on top of scientific work?\n There has only been one post in this subreddit on one of the accepted blog posts (since the announcement). I think there are some nice blog posts in there, so I expected to find some discussions here, but it seems like it is either ignored or not worth discussing. Therefore, I thought it would be interesting to (try to) start a discussion. \n TL;DR: what do you think of the ICLR blog post track and/or the accepted blog posts?\n    submitted by    /u/mr_tsjolder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ud48ty/d_iclr_2022_blog_post_track/",
          "publishedOn": "2022-04-27T13:59:49.000Z",
          "wordCount": 336,
          "title": "[D] ICLR 2022 blog post track",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ud3w4n/d_mlops_tools_for_automatic_fine_tuning_of/",
          "author": null,
          "description": "I'm working on a ML model for data extraction out of documents. The model is trained and deployed into production. For fine tuning the model and improving performance I added the possibility for users to correct the extracted data. A concrete example would be: the model labels a word in the document as \"company_name\" the user corrects it to \"street_name\". This correction is then used to fine tune the model.\n Currently the fine tuning is done manually. That is, if the number of corrections exceeds some threshold I take them and start a new training and evaluate the new model before putting it into production. My question would be: is there an MLOps tool that automates this process? Or should I write one myself? I am aware of the tool seldon core that offers A/B testing for comparing the old model with the new one and putting it into production. But unfortunately it does not offer automatic fine tuning. Or that's what I understood from their website.\n    submitted by    /u/alzoubi36  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ud3w4n/d_mlops_tools_for_automatic_fine_tuning_of/",
          "publishedOn": "2022-04-27T13:42:54.000Z",
          "wordCount": 288,
          "title": "[D] MLOps tools for automatic fine tuning of deployed machine learning models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ud3ezk/p_create_interactive_slides_for_machine_learning/",
          "author": null,
          "description": "Would you like to create an interactive presentation for your ML model directly from Jupyter Notebook? \n I'm working on an open-source project for converting notebooks into interactive documents. Recently, I've added the option to turn notebooks into interactive slides. You can showcase your Machine Learning model as an interactive presentation. During the presentation, the user can change values and recompute the slide! I've created a demo presentation where I use Random Forest to predict Iris species. \n The screenshot recording of the presentation: https://github.com/pplonski/ml-model-slides/raw/main/media/slides-from-ml-model.gif\n The presentation is available online (deployed at Heroku) https://ml-model-presentation.herokuapp.com/ What is more, the presentation code is on GitHub https://github.com/pplonski/ml-model-slides (yes, code is presentation! bye-bye PPT) In case anyone is interested, the framework is called Mercury.\n    submitted by    /u/pp314159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ud3ezk/p_create_interactive_slides_for_machine_learning/",
          "publishedOn": "2022-04-27T13:19:50.000Z",
          "wordCount": 318,
          "title": "[P] Create interactive slides for Machine Learning models from Jupyter Notebook",
          "imageUrl": "https://external-preview.redd.it/V3kxj-Tj1O2A4thUpYW86xhAai8d6iEcasXT4-PgdgE.gif?format=png8&s=75c41c4f6dd8a6aac542fcebe4c90ddfb0821140"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ud20gg/d_feature_engineering_automation/",
          "author": null,
          "description": "Hello, I’m working as a Data Scientist currently and I realized that most of my time is spent on feature engineering.\n My general practice is that I create aggregations of data (via sql because of the amount of data that needs to be processed) like sum, mean, avg, std, median, q25, q75. I need to do it on a few dozen features. Also I am calculating these aggregations on different time windows: previous week, previous month, previous 3 month. \n At the end I end up with hundreds of features and I need to select the ones that make any sense, contain relevant information. Currently I am applying pandas profiling, or sweetviz on this huge dataset and trying to analyze it by eyeballing the results. \n My main challenge is that this process is highly repetitive and manual. I am wondering if there is any tool out there that could help me automate this process and make some parts reusable? I like having a UI especially for visualizing the data.\n Am I doing something wrong or is there a tool that I’m clearly not aware of?\n    submitted by    /u/sgergely  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ud20gg/d_feature_engineering_automation/",
          "publishedOn": "2022-04-27T12:07:11.000Z",
          "wordCount": 1128,
          "title": "[D] Feature engineering automation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ud1sel/d_how_to_storesurface_predictions_along_with/",
          "author": null,
          "description": "Hi, I am faced with something that I thought was simpe but I have been thinking about it so much that I now very confused. Any suggestions are helpful ! \n Let's assume the scenario that you have a database of cars. For each car you have a brand, model, colour etc. \n You have an api for this db which you can call, with a car id, and surface the car data. People rely on this api for fast and up to date car information. You have 1 million cars in the db.\n Assume now there is a requirement to predict a yes/no if the car has a black front bumper (completely made up requirement). This has to be surfaced to the api users along with the car data. You have built a classifier for this, and it takes some time to surface a prediction, e.g. 2 mins. You select what you think is the best operating point for your classifier.\n When a new car gets added into the db you can now run your predictor and you get back a probability and depending on the operating point a yes/no.\n What is the best approach here now ? \n Do you store the result of this prediction in the database (probability, model_version and boolean result) alongside the rest of the car data ? Less flexible as if you decide to tweak the operating point you will need to recalculate the new boolean values for all cars - but you have consistency wrt to what you have in the db and what you return to your users. If there is a mistake you can readily fix it by altering the boolean field.\n Do you just store the probabilities and decide on the yes/no using the model_version & operating point only when you surface the data to the end user ? More flexible if you decide to tweak the opearting point of the classifier.\n or would you have a completely different approach ? \n Would you change anything, if for some cars you have the ground truth data of they have a black bumper or not in the db already ?\n Thanks for reading !\n    submitted by    /u/42isthenumber_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ud1sel/d_how_to_storesurface_predictions_along_with/",
          "publishedOn": "2022-04-27T11:55:24.000Z",
          "wordCount": 516,
          "title": "[D] How to store/surface predictions along with immutable data in a database api?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucqchp/d_transformermodelsfromscratch/",
          "author": null,
          "description": "I recently started learning machine learning, and I have implemented several transformer models for different tasks from scratch in PyTorch in my Github repository:\n Transformer-Models-from-Scratch\n The notebooks are self-contained. And I also included a note I wrote on transformers. Hope it's helpful for anyone learning the transformer model! \n Let me know if you have any comments!\n    submitted by    /u/hbchen-one  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucqchp/d_transformermodelsfromscratch/",
          "publishedOn": "2022-04-26T23:59:24.000Z",
          "wordCount": 133,
          "title": "[D] Transformer-Models-from-Scratch",
          "imageUrl": "https://external-preview.redd.it/mVIdBNpG3jWYMEilXrtFZglBCNuGivr9GoRJvWtHt1c.jpg?auto=webp&s=72da3e32ec1cd5d2bc5296062e4effdfe2d0e8ad"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucpr0b/p_curated_list_of_company_blogs_about_mlops_infra/",
          "author": null,
          "description": "Hi all. I am starting a github repo to compile a list of company blogs about their MLops/ infra. Please feel free to contribute if you are interested:\n https://github.com/enochkan/awesome-ml-stack\n    submitted by    /u/kanxx030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucpr0b/p_curated_list_of_company_blogs_about_mlops_infra/",
          "publishedOn": "2022-04-26T23:28:22.000Z",
          "wordCount": 119,
          "title": "[P] Curated List of Company Blogs about MLops/ Infra",
          "imageUrl": "https://external-preview.redd.it/hKwf3qA8BVcG-qnNglYtmlkwBC7PQkhvtCLYN_kKB88.jpg?auto=webp&s=200b73335f2d39b38cf64480b91bdd2ba22b9a98"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucpg0u/p_tortoise_a_true_zeroshot_multivoice_tts_engine/",
          "author": null,
          "description": "I'd like to show off a TTS system I have been working on for the past year. I've open-sourced all the code and the trained model weights: https://github.com/neonbjb/tortoise-tts\n This was born out of a desire to reproduce the original DALLE with speech. It is \"zero-shot\" because you feed the text and examples of a voice to mimic as prompts to an autoregressive LLM. I think the results are fantastic. Here are some samples: https://nonint.com/static/tortoise_v2_examples.html\n Here is a colab in which you can try out the whole system: https://colab.research.google.com/drive/1wVVqUPqwiDBUVeWWOUNglpGhU3hg_cbR\n    submitted by    /u/neonbjb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucpg0u/p_tortoise_a_true_zeroshot_multivoice_tts_engine/",
          "publishedOn": "2022-04-26T23:12:55.000Z",
          "wordCount": 196,
          "title": "[P] TorToiSe - a true zero-shot multi-voice TTS engine",
          "imageUrl": "https://external-preview.redd.it/AeQKcn6PghyvS_ZKnwlmyjml7ptJJko8g7FDAxkLwp8.jpg?auto=webp&s=3da0e2b7b575adcfcd1926fdb0f76b208be2c196"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucogqc/p_baseten_build_mlpowered_applications/",
          "author": null,
          "description": "Hey, we've been building Baseten to be able quickly deploy models, backends and frontends. I'd love to get your feedback.\n    submitted by    /u/Available-Cookie2754  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucogqc/p_baseten_build_mlpowered_applications/",
          "publishedOn": "2022-04-26T22:25:44.000Z",
          "wordCount": 112,
          "title": "[P] Baseten – Build ML-powered applications",
          "imageUrl": "https://external-preview.redd.it/5w3DHNleW9WJu_lbJK1ezN22t2DPGcgIKWcgn1X2_ZQ.jpg?auto=webp&s=80463aa9f2258850a86ed5c03b1a21716c5acdcf"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uch3rs/n_upcoming_talk_on_data_centric_approach_to_ai/",
          "author": null,
          "description": "Hey folks, \n There’s an upcoming free talk on May 13. This is what I know: \n Vijay K, Head of Engineering at Scale.ai, and Mike Wu, Stanford PhD in Machine Learning are going to be talking about strategies for taking a data centric approach to AI, and Vijay’s lessons from doing this at Apple, YouTube, and Scale AI. There’s a a renewed focus on the data layer as a foundation for successful ML projects, and Vijay participated in this transformation firsthand. \n You’ll be able to hear his reflections and learnings, should be super useful! \n Sign-up link is here, see you there.\n    submitted by    /u/sb2nov  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uch3rs/n_upcoming_talk_on_data_centric_approach_to_ai/",
          "publishedOn": "2022-04-26T16:53:41.000Z",
          "wordCount": 218,
          "title": "[N] Upcoming talk on Data centric approach to AI from experience at Youtube, ScaleAI and Apple",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucgxyh/news_adept_ai_labs_launches/",
          "author": null,
          "description": "This seems like a pretty powerhouse team\n adept.ai/post/introducing-adept\n    submitted by    /u/mrpogiface  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucgxyh/news_adept_ai_labs_launches/",
          "publishedOn": "2022-04-26T16:46:06.000Z",
          "wordCount": 119,
          "title": "[News] Adept AI Labs Launches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucgppf/d_is_it_possible_to_train_a_very_large_6b_model/",
          "author": null,
          "description": "Hi, I was wondering how long it would take or if it would be possible for a model with 6 billion neurons to become able to predict that for 6 7 8 the next number should be 9, given only a single training example 1 2 3. Let's say we use an architecture like the ones used in GPT.\n Essentially, I am trying to make sense of something here: is the human design component in DL the weak link in the AGI chain? Much like we could not achieve a true AI by manually coding each rule with if's and else, perhaps we cannot achieve true intelligence by manually designing the networks.\n Can we grow a model organically so it immediately gets this right from a single training example, and continue using the same network to keep on learning from rich input and making new observations. For guidance, the network can use what it already knows, learning outward. A pre-programmed inherent ability to find motifs, for example with STUMPY and Time Series Analysis, allows it to make relationship observations, and is how the agent immediately guesses that a numeric pattern increments by 1 from a single training example.\n Putting this into DL, perhaps we can achieve something less organic but still good using a model-agnostic architecture with multi-resolution 'tiles' of neurons. Some property of the information would theoretically allow deciding if the tile should be upgraded to a higher resolution (more neurons), and a side buffer keeps track of the connections between these tiles and tries to move the topology forward, adding some small clusters, removing others, attempting to connect them, etc.\n    submitted by    /u/o_snake-monster_o_o_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucgppf/d_is_it_possible_to_train_a_very_large_6b_model/",
          "publishedOn": "2022-04-26T16:35:51.000Z",
          "wordCount": 473,
          "title": "[D] Is it possible to train a very large 6B model learn from a single training input 1 2 3 to infer 6 7 8 (9) ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucflc2/d_understanding_the_use_of_ema_in_diffusion_models/",
          "author": null,
          "description": "Reading the original diffusion models paper and the improved diffusion model by openAI, I noticed they are using EMA (exponential moving average) to update the parameters of the models.\n so I started looking at the code openAI published for their version of the diffusion models, and when looking at the code, I see that the model during the training process has its params stored in a variable called \"master_params\" and then they create a deep copy of the params and call them ema_params.\n when looking at the \"optimize_normal\" method, I see that they update the model params using AdamW and gradient descent, and then after that, they update the ema param variable using the EMA equation, so that means the actual model params do a full gradient descent step to the reach minimum of the loss function, and then they do a pseudo step from the original parameters before the optimizer and making them closer to the params after the optimizer.\n but then looking at the rest of the code, all I see is that they just save a checkpoint of the ema params to the disk but never update the model params using them or anything.\n so my question is, what is the EMA for if it is not used during training and the model is fully updated using \"classical\" machine learning optimization with gradient descent?\n only at inference time do they load the EMA params to generate images, instead of the regular params that were updated using the AdamW?\n    submitted by    /u/eyalmazuz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucflc2/d_understanding_the_use_of_ema_in_diffusion_models/",
          "publishedOn": "2022-04-26T15:46:50.000Z",
          "wordCount": 625,
          "title": "[D] Understanding the use of EMA in Diffusion models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucfdci/p_benchmarking_and_profiling_hugging_face/",
          "author": null,
          "description": "We've recently added Hugging Face support to https://github.com/graphsignal/graphsignal profiler, which I'd like to share in case someone finds it useful in their efforts to optimize speed and compute. More details, code and screenshots in the blog post https://graphsignal.com/blog/benchmarking-and-profiling-hugging-face-training-with-graphsignal/.\n    submitted by    /u/l0g1cs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucfdci/p_benchmarking_and_profiling_hugging_face/",
          "publishedOn": "2022-04-26T15:36:54.000Z",
          "wordCount": 129,
          "title": "[P] Benchmarking and profiling Hugging Face training with Graphsignal",
          "imageUrl": "https://external-preview.redd.it/-u0wOVQUUMl8TOmPJcPOkR_XG5uoPJV1_q2gXjFYYeY.jpg?auto=webp&s=65096b979e08ee2b3eaf745cdffa7eaebe5ade07"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucdp5t/n_mitmeta_ai_released_their_new_sota_unsupervised/",
          "author": null,
          "description": "Researchers from MIT/Meta recently released a new framework for unsupervised sentence embedding. \n The performance seems to be better than SimCSE, the previous SOTA, by 2.3 absolute points on downstream tasks. \n The pretrained models are available on Huggingface. GitHub: https://github.com/voidism/DiffCSE arXiv: https://arxiv.org/abs/2204.10298\n    submitted by    /u/virtualenv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucdp5t/n_mitmeta_ai_released_their_new_sota_unsupervised/",
          "publishedOn": "2022-04-26T14:22:21.000Z",
          "wordCount": 272,
          "title": "[N] MIT/Meta AI released their new SOTA unsupervised sentence embedding model \"DiffCSE\"",
          "imageUrl": "https://external-preview.redd.it/vX7tDFL9qixiu9dNrnwvfUpbaiMPsGjzx5smzOuszYQ.jpg?auto=webp&s=7923ce416fbaf89f77a040d3491e8ee73c47fc02"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucczb6/d_what_do_you_think_of_the_double_standard_where/",
          "author": null,
          "description": "Some useful optional considerations:\n  \nAssume copies of the original copyrighted work are owned lawfully.\n Assume the AI maintains a single active copy to avoid group performance.\n The implications this has on banning possibly uploading your own consciousness to save your life on copyright grounds.\n  \nThis “stealing” concept people jump to seems to bring up some interesting logical contradictions. What do you think?\n    submitted by    /u/sext-scientist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucczb6/d_what_do_you_think_of_the_double_standard_where/",
          "publishedOn": "2022-04-26T13:48:23.000Z",
          "wordCount": 677,
          "title": "[D] What do you think of the double standard where an AI learning from copyrighted material is “stealing”, but when a human does it that’s just education?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ucawrm/news_new_jupyter_notebook_competition/",
          "author": null,
          "description": "Are you passionate about coding, data science or Earth observation? \n https://preview.redd.it/wfwk9ifo4vv81.png?width=1920&format=png&auto=webp&s=5f11885bd8efe88986c181b565cc160534634f0b\n We're looking for bright-minded people from around the world to showcase their skills and develop new Jupyter Notebooks using Copernicus data! \n Sound interesting? Find out more here: https://www.eumetsat.int/science-blog/new-jupyter-notebook-competition\n    submitted by    /u/EUMETSAT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ucawrm/news_new_jupyter_notebook_competition/",
          "publishedOn": "2022-04-26T12:00:18.000Z",
          "wordCount": 128,
          "title": "[News] New Jupyter Notebook competition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uca7eh/p_kprototypes_and_evaluating_model_performance/",
          "author": null,
          "description": "I have reached a blocking point in a current project. We are using K-Prototypes to segment two populations (one with 100k elements and the other with 1M). In order to evaluate the clustering, during our K-Means stage we used silhouettes which are already implemented in sklearn.\n For the second stage, this became a problem. Either it was a time issue or a memory issue. So, for the 100k dataset, finding the silhouette profile took around 50 hours using a custom distance metric function. \n While this is feasible in the project's scope, for the 1M dataset the computation time would be highly impractical.\n As such, at the moment, we are stuck without a proper evaluation metric for our model. Sure, we can run Davies-Bouldin or other similar metrics, but the silhouette profile gave us much more detailed information.\n We are also moving the project to databricks. At first, the pyspark clustering evaluator had me hopeful, but it has very limited options regarding distance metrics.\n This is also an issue because the model is to be deployed in production and should have some metric informing when it needs to be retrained. While this point is still fluid, this is the preferred course of action.\n Has anyone faced similar issues using K-Prototypes? Or just silhouette profiles with custom distance metrics?\n    submitted by    /u/CaptMartelo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uca7eh/p_kprototypes_and_evaluating_model_performance/",
          "publishedOn": "2022-04-26T11:19:58.000Z",
          "wordCount": 309,
          "title": "[P] K-Prototypes and evaluating model performance and drift",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uc9z2y/p_we_cleaned_up_pascal_and_improved_map_by_13/",
          "author": null,
          "description": "How important is clean data for how your AI models perform? \n According to our experiments - very important. Using state-of-the-art confidence learning to clean up PASCAL, two people improved our primary model metric by 13% in a week.\n To learn more about our results and what we did check out our article: https://hasty.ai/content-hub/articles/cleaning-pascal-improving-map-by-13?utm_source=mk832ksa\n Disclaimer: We used our own platform to clean up the data and the article, therefore, contains self-promotion. However, the article mainly focuses on the results we achieved.\n    submitted by    /u/treebeard_hasty_ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uc9z2y/p_we_cleaned_up_pascal_and_improved_map_by_13/",
          "publishedOn": "2022-04-26T11:05:22.000Z",
          "wordCount": 1027,
          "title": "[P] We cleaned up Pascal and improved mAP by 13%",
          "imageUrl": "https://external-preview.redd.it/dfYDNyZOC1W28l68kB1PLrv040yL98-QC9JpJTPlnZE.jpg?auto=webp&s=672211afb999e10a83a307f9d524679bd25f48a6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uc0orl/rp_using_language_models_for_molecule_captioning/",
          "author": null,
          "description": "Hi. We recently did some work on using language models for molecule captioning and text-based molecule generation. You can think of it as doing translation between molecules and natural language.\n Would love to know if you have any feedback 🤗. Arxiv: https://arxiv.org/abs/2204.11817\n    submitted by    /u/SimilarShape9122  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uc0orl/rp_using_language_models_for_molecule_captioning/",
          "publishedOn": "2022-04-26T01:12:23.000Z",
          "wordCount": 320,
          "title": "[R][P] Using language models for molecule captioning and text-based molecule generation",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubzot6/d_making_texttoimage_even_better_glide_towards/",
          "author": null,
          "description": "“Diffusion models beat GANs”. While true, the statement comes with several ifs and buts, not to say that the math behind diffusion models is not for the faint of heart. Alas, GLIDE, an OpenAI paper from last December took a big step towards making it true in every sense. Specifically, it introduced a new guidance method for diffusion models that produces higher quality images than even DALL-E, which uses expensive CLIP reranking. And if that wasn’t impressive enough, GLIDE models can be fine-tuned for various downstream tasks such a inpainting and and text-based editing.\n As for the details, let’s dive in, shall we?\n Full summary: https://t.me/casual_gan/289\n Blog post: https://www.casualganpapers.com/faster-diffusion-models-text-to-image-classifier-free-guidance/GLIDE-explained.html\n GLIDE\n arxiv / code\n Join the discord community and follow on Twitter for weekly AI paper summaries!\n    submitted by    /u/KirillTheMunchKing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubzot6/d_making_texttoimage_even_better_glide_towards/",
          "publishedOn": "2022-04-26T00:21:27.000Z",
          "wordCount": 285,
          "title": "[D] Making text-to-image even better - GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models, a 5-minute paper summary by Casual GAN Papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubymfu/d_hypothetically_whats_the_value_in_being_able_to/",
          "author": null,
          "description": "I'm not going to make this vague. Specifically I'm seeing a lot of comments related to Elon Musk saying he's going to remove bots from Twitter. There's a lot of speculation on how this could be done with comments suggesting a captcha-based system for every post/reply (or maybe every action?). More specifically people seem fixated on captcha systems that can't be botted. (Ignore for a moment the accessibility issues and audio fallbacks that might be required).\n I'm aware that Tesla transitioned to using more massive synthetic datasets for training, so this might be somewhat outdated. That said they do have a lot of data collection of new real world data from their sensors. This has me curious on the estimated value of large-scale captcha systems directly tied with a company that might need large-scale labeling services.\n I'm sure researchers here have run numbers on labeling services and how to best to utilize them. (Goes without saying the prices vary quite a bit and cover a wide range of tasks from simple bounding boxes to relatively expensive polygons for semantic labeling. For example just as a reference: https://cloud.google.com/ai-platform/data-labeling/pricing ). Most services don't list prices for like 500 million tasks which makes sense given that's a lot.\n A captcha system would have independent users redoing tasks multiple times to find baselines, but in general it would average to find a ground truth label. This redundant work isn't wasted in this sense as it can find say difficult scenarios and refine labels.\n I could naively say 500 million / (10 USD/1000 tasks) = 5 million USD a day not counting server costs and development. Not super scientific though and it seems high. (I have doubts on if gathering 500 million samples of value a day to even get labeled is realistic).\n I digress, what would you say is the hypothetical value of such a system using short captcha tasks?\n    submitted by    /u/Sirisian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubymfu/d_hypothetically_whats_the_value_in_being_able_to/",
          "publishedOn": "2022-04-25T23:28:52.000Z",
          "wordCount": 604,
          "title": "[D] Hypothetically, what's the value in being able to label ~500 million images a day?",
          "imageUrl": "https://external-preview.redd.it/9LgEYrUEvxXu01uRFdtgCCuou8dOpEa-ra9F8oTXfkI.jpg?auto=webp&s=ce706d27c0d1a861292851279769281e25f0fcca"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubx9pv/n_modular_reasoning_knowledge_language_mrkl/",
          "author": null,
          "description": "AI21 Labs’ Modular Reasoning, Knowledge and Language (MRKL, pronounced “miracle”) system – and Jurassic-X includes one or more language models, and augment them with external knowledge sources as well as symbolic reasoning experts that can handle tasks that lie beyond the reach of neural models. There are 55 different task-specific modules that MRKL currently supports. If the router is unsure which module is best, it calls on Jurassic-1. Jurassic also helps compose the contextual language around MRKL’s response. This allows MRKL to give factual answers with up-to-date information instead of being limited to its training data alone, and gives it the ability to carry out a much wider range of NLP tasks as compared to other LLM's like Google's PaLM or OpenAI's GPT-3\n AI21 blog and whitepaper here\n Video here\n    submitted by    /u/SlightSituation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubx9pv/n_modular_reasoning_knowledge_language_mrkl/",
          "publishedOn": "2022-04-25T22:24:52.000Z",
          "wordCount": 241,
          "title": "[N] Modular Reasoning, Knowledge, & Language (MRKL) Hybrid System For More 'General' NLP",
          "imageUrl": "https://external-preview.redd.it/fDd9c-UIVZ46vmnLwHbEqeWsEnXeKYrd897aC379tvE.jpg?auto=webp&s=6fec3c59b829bf9de2ed47821f860f1f109f0682"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubvrld/d_opinions_on_nvidia_tao_toolkit/",
          "author": null,
          "description": "I'm working on an Edge ML product where we train models in the cloud and then run them on a device using tensorRT. We're considering switching to using the Nvidia TAO Toolkit for training. If you've used TAO, do you like it? Is it limiting? Our alternative is training in pytorch and then converting to ONNX and then tensorRT separately. Thanks!\n    submitted by    /u/linguistBot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubvrld/d_opinions_on_nvidia_tao_toolkit/",
          "publishedOn": "2022-04-25T21:17:17.000Z",
          "wordCount": 153,
          "title": "[D] Opinions on NVIDIA TAO Toolkit?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubtfh3/rp_an_arxivsanitylike_view_of_iclr_2022_papers/",
          "author": null,
          "description": "submitted by    /u/tanelai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubtfh3/rp_an_arxivsanitylike_view_of_iclr_2022_papers/",
          "publishedOn": "2022-04-25T19:36:54.000Z",
          "wordCount": 233,
          "title": "[R][P] An arxiv-sanity-like view of ICLR 2022 papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubsx32/d_paper_explained_accel_evolving_curricula_with/",
          "author": null,
          "description": "https://youtu.be/povBDxUn1VQ\n Automatic curriculum generation is one of the most promising avenues for Reinforcement Learning today. Multiple approaches have been proposed, each with their own set of advantages and drawbacks. This paper presents ACCEL, which takes the next step into the direction of constructing curricula for multi-capable agents. ACCEL combines the adversarial adaptiveness of regret-based sampling methods with the capabilities of level-editing, usually found in Evolutionary Methods.\n ​\n OUTLINE:\n 0:00 - Intro & Demonstration\n 3:50 - Paper overview\n 5:20 - The ACCEL algorithm\n 15:25 - Looking at the pseudocode\n 23:10 - Approximating regret\n 33:45 - Experimental results\n 40:00 - Discussion & Comments\n ​\n Website: https://accelagent.github.io\n Paper: https://arxiv.org/abs/2203.01302\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubsx32/d_paper_explained_accel_evolving_curricula_with/",
          "publishedOn": "2022-04-25T19:14:37.000Z",
          "wordCount": 222,
          "title": "[D] Paper Explained - ACCEL: Evolving Curricula with Regret-Based Environment Design (Video Walkthrough)",
          "imageUrl": "https://external-preview.redd.it/G56_EvZ7Bhe2e66UjiT-qdu0Jeri0z_iHA80wmvdCYQ.jpg?auto=webp&s=0968009e53ace29cd095f9976c472e91969e68ef"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubscue/d_parameter_efficiency_without_computational/",
          "author": null,
          "description": "Hello hivemind.\n Context\n I am working on streamlined design strategies for (manual) neural architecture design. I recently came across a simple, receptive field-based strategy that allows me to reliably improve the architectures of some SOTA models like EfficientNet by up +1.5% top1-accuracy.That being said, there seems to be a trade-off between performance and number of computations I put into the same number of parameters.Basically, the more computationally expensive the architectural change is, the better the performance turns out to be. The number of parameters does not change in the process. The model becomes therefore more parameter efficient but computationally less efficient, which you could consider a somewhat Pyrrhic victory.\n Now to my question:\n Is there use for parameter efficiency in models when it does not also coincide with computational efficiency? Is there any literature on the topic you can recommend?\n    submitted by    /u/KrakenInAJar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubscue/d_parameter_efficiency_without_computational/",
          "publishedOn": "2022-04-25T18:50:36.000Z",
          "wordCount": 316,
          "title": "[D] Parameter Efficiency without Computational Efficiency",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uboxle/d_calculating_feature_importance_which/",
          "author": null,
          "description": "So far I've only seen feature importance calculated on one model/ training set at a time, However, with cross validation there are many models built on different training sets, how do you calculate feature importance in this case? Just do it on one model? Or calculate feature importance for each model and somehow aggregate it (e.g., by averaging)?\n    submitted by    /u/Comprehensive-Egg707  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uboxle/d_calculating_feature_importance_which/",
          "publishedOn": "2022-04-25T16:19:23.000Z",
          "wordCount": 584,
          "title": "[D] Calculating feature importance: which model/training set to use in the case of cross validation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubosur/r_recent_trends_in_diffusionbased_textconditional/",
          "author": null,
          "description": "Hello, I wrote the blog post about text-conditional image generation using diffusion models (including DALLE-2). Let me know what you think!\n ​\n https://sangyun884.github.io/recent-trends-in-diffusion-based-text-conditional/\n    submitted by    /u/Impressive-Mirror430  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubosur/r_recent_trends_in_diffusionbased_textconditional/",
          "publishedOn": "2022-04-25T16:13:41.000Z",
          "wordCount": 124,
          "title": "[R] Recent Trends In Diffusion-Based Text-Conditional Image Synthesis",
          "imageUrl": "https://external-preview.redd.it/5ZUYF2qZ9oW9_6AoGMSy5GlDG-C9Kx1PyG4ZynT6IYk.jpg?auto=webp&s=7ff2c46197313b35e184786cb58a402c8dca10d9"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubme2a/np_use_github_actions_for_ml_with_dagshub_connect/",
          "author": null,
          "description": "Hey r/MachineLearning, Nir from DagsHub here, and I'm thrilled to share a project we're launching today that will hopefully unlock GitHub Actions for ML.\n GitHub Actions solved a DevOps burden many of us felt by providing an easy-to-configure CI/CD tool to build, test, and deploy pipelines. However, when it comes to ML pipelines, and working with data, models, and experimentation in mind, the workflow is not as well defined and can get tricky to implement.\n DagsHub is kind of like GitHub for machine learning, which extends what GitHub did for code management to track data, models, experiments, and data pipelines. We do this by integrating awesome open source tools like DVC, MLflow, Label Studio, and more. One of our most requested features was a deeper integration with GitHub that will let…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubme2a/np_use_github_actions_for_ml_with_dagshub_connect/",
          "publishedOn": "2022-04-25T14:26:04.000Z",
          "wordCount": 447,
          "title": "[N][P] Use GitHub Actions for ML with DagsHub Connect",
          "imageUrl": "https://external-preview.redd.it/miy8ZOmxsxxt3oLG2rZXO4I2lnPwkZE6fO_Smw31Cjg.jpg?auto=webp&s=eb1f6c559705b0d00873abe5ddc6e1ca5cc53a2a"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ublzwx/r_iclr_2022_blog_post_the_37_implementation/",
          "author": null,
          "description": "Hi folks, our ICLR 2022 Blog post on \"The 37 Implementation Details of Proximal Policy Optimization\" is live 😀 Our post makes it easier to understand the nitty-gritty PPO's implementations with \n 1) 🎥 video tutorials 2) 📜 detailed references and explanations 3) ⌨️ really simple code\n Here are the links:\n  \nOfficial URL: https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/\n Twitter thread: https://twitter.com/vwxyzjn/status/1518589115163369472\n OpenReview link:https://openreview.net/forum?id=Hl6jCqIp2j\n GitHub repo: https://github.com/vwxyzjn/ppo-implementation-details\n YouTube tutorial on PPO: https://www.youtube.com/playlist?list=PLD80i8An1OEHhcxclwq8jOMam0m0M9dQ_\n  \nI am the main author & feel free to ask me anything here.\n    submitted by    /u/vwxyzjn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ublzwx/r_iclr_2022_blog_post_the_37_implementation/",
          "publishedOn": "2022-04-25T14:07:45.000Z",
          "wordCount": 254,
          "title": "[R] ICLR 2022 Blog Post: The 37 Implementation Details of Proximal Policy Optimization",
          "imageUrl": "https://external-preview.redd.it/Nrk17IHZ48Q-TVSgonwE3nu9Cz6NRLHt5HfNaznMF6Q.jpg?auto=webp&s=cb9777201c9daf7f84d7dc9dd71dddbbdad5ae57"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubkw3n/n_learn_how_the_opensource_ecosystem_can_be_used/",
          "author": null,
          "description": "Hey,\n 🤗 Hugging Face is offering a workshop (June 6) for instructors of machine learning and data science who would like to learn how the open-source ecosystem can be used in their classes.\n After this workshop, you will know how to:\n 🧑‍💻 Teach Transformers models & famous ML libraries\n 🤖 Onboard students to the Hub to build/host projects\n 💾 Publish models/datasets in a few lines of code\n During the workshop, you will be invited to join the following page for a better understanding of our open-source solutions: https://huggingface.co/teach\n For more details about the workshop content, visit: https://hf.co/teaching\n Feel free to register here:)\n    submitted by    /u/VioletteLep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubkw3n/n_learn_how_the_opensource_ecosystem_can_be_used/",
          "publishedOn": "2022-04-25T13:14:21.000Z",
          "wordCount": 250,
          "title": "[N] Learn how the open-source ecosystem can be used in your machine learning and data science classes.",
          "imageUrl": "https://external-preview.redd.it/8BbLqQCd8ZIKmiy4RdrDTl6eDcHui3Li5BwxoC-WsKs.jpg?auto=webp&s=b7e701b010346785e9be5e312743f16aa1bd5f1a"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubj79m/d_does_anyone_know_a_large_varied_image_dataset/",
          "author": null,
          "description": "It could be pictures of anything, except of humans. But it would be better if it were not focused on a single topic like dog images.\n    submitted by    /u/TheManveru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubj79m/d_does_anyone_know_a_large_varied_image_dataset/",
          "publishedOn": "2022-04-25T11:44:33.000Z",
          "wordCount": 338,
          "title": "[D] Does anyone know a large varied image dataset that do NOT contain humans?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubg40r/r_a_new_dataset_and_a_library_that_you_can_use/",
          "author": null,
          "description": "TL;DR: Download dataset of labelled Web pages, WebTraversalLibrary for scripting web interactions\n Hi everyone! Our group at Klarna has been putting in a ton of work into deep learning for the Web over the past few years and we've made a couple of useful resources available for the research community. You might find them interesting if you're looking for new ideas for spare-time or even post-grad research projects.\n  \nWe've open-sourced a dataset of about 50k labeled product web pages from roughly 8000 distinct e-commerce merchants, available as MHTML and WebTraversalLibrary clones (see next point :) ), along with the corresponding screenshots. Not all of the MHTMLs render correctly, but the ones that do also have screenshots in a corresponding dataset for CV applications. You can find doc…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubg40r/r_a_new_dataset_and_a_library_that_you_can_use/",
          "publishedOn": "2022-04-25T08:19:07.000Z",
          "wordCount": 484,
          "title": "[R] A new dataset and a library that you can use for ML and RL over the Web",
          "imageUrl": "https://external-preview.redd.it/nEWdNw6tOLTkbPlkuR_d4dfrSEppmrXzgjja-SbvAsw.jpg?auto=webp&s=53f01522597457284b505a5aec6d564996e35806"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ubduwi/d_is_anyone_working_on_opensourcing_dalle_2/",
          "author": null,
          "description": "Just like Eleuther did with GPT3?\n    submitted by    /u/invertedpassion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ubduwi/d_is_anyone_working_on_opensourcing_dalle_2/",
          "publishedOn": "2022-04-25T05:40:47.000Z",
          "wordCount": 459,
          "title": "[D] Is anyone working on open-sourcing Dall-E 2?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ub8oxx/p_demo_of_googles_new_phorum_image3d_figure/",
          "author": null,
          "description": "submitted by    /u/NichodonARG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ub8oxx/p_demo_of_googles_new_phorum_image3d_figure/",
          "publishedOn": "2022-04-25T00:44:20.000Z",
          "wordCount": 102,
          "title": "[P] Demo of Google's new PHORUM Image➠3D Figure Project",
          "imageUrl": "https://external-preview.redd.it/xarSgeckhCFOVGDdVFJVuHrLVrL_PaQb4b_arEQvVU8.jpg?auto=webp&s=e47a1e07736d71010cd2d4284cef42806dfc4c3d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ub64n5/d_legality_of_hosting_imagenet/",
          "author": null,
          "description": "Despite it's immense popularity in academia, it's surprisingly difficult to download the ImageNet Object Localization dataset. As far as I can tell this is due to legal issues -- no single entity owns the copyright to the images, so no entity can host the whole dataset.\n The result is that if you want to use ImageNet you're forced to either manually scrape a million URLs (requiring both cpu time, your time, and imposing costs on a million unsuspecting websites), know somebody who has already done that, or fetch it from a legally questionable source.\n So I have a couple questions:\n  \nIs the owner of the ImageNet dataset on Kaggle performing a selfless public service, thanklessly accepting legal liability to make ImageNet more accessible? Or is she protected (e.g. by fair use)? Is she required to accept DMCA requests?\n If I'd like to share ImageNet (I've recently downloaded it and processed it to be ~10 GB, which seems like a helpful thing to share), is there any legally safe path for me to do this?\n  \n   submitted by    /u/you-get-an-upvote  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ub64n5/d_legality_of_hosting_imagenet/",
          "publishedOn": "2022-04-24T22:31:17.000Z",
          "wordCount": 754,
          "title": "[D] Legality of Hosting ImageNet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ub2xlz/d_machine_learning_wayr_what_are_you_reading_week/",
          "author": null,
          "description": "This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.\n Please try to provide some insight from your understanding and please don't post things which are present in wiki.\n Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.\n Previous weeks :\n  \n 1-10 11-20 21-30 31-40 41-50 51-60 61-70 71-80 81-90 91-100 101-110 111-120 121-130 131-140 \n  \n Week 1 Week 11 Week 21 Week 31 Week 41 Week 51 Week 61 Week 71 Week 81 Week 91 Week 101 Week 111 Week 121 Week 131 \n  Week 2 Week 12 Week 22 Week 32 Week 42 Week 52 Week 62 Week 72 Week 82 Week 92 Week 102 Week 112 Week 122 Week 132 \n  Week 3 Week 13 Week 23 Week 33 Week 43 Week 53 Week 63 Week 73 Week 83 Week 93 Week 103 Week 113 Week 123 Week 133 \n  Week 4 Week 14 Week 24 Week 34 Week 44 Week 54 Week 64 Week 74 Week 84 Week 94 Week 104 Week 114 Week 124 Week 134 \n  Week 5 Week 15 Week 25 Week 35 Week 45 Week 55 Week 65 Week 75 Week 85 Week 95 Week 105 Week 115 Week 125 Week 135 \n  Week 6 Week 16 Week 26 Week 36 Week 46 Week 56 Week 66 Week 76 Week 86 Week 96 Week 106 Week 116 Week 126  \n  Week 7 Week 17 Week 27 Week 37 Week 47 Week 57 Week 67 Week 77 Week 87 Week 97 Week 107 Week 117 Week 127  \n  Week 8 Week 18 Week 28 Week 38 Week 48 Week 58 Week 68 Week 78 Week 88 Week 98 Week 108 Week 118 Week 128  \n  Week 9 Week 19 Week 29 Week 39 Week 49 Week 59 Week 69 Week 79 Week 89 Week 99 Week 109 Week 119 Week 129  \n  Week 10 Week 20 Week 30 Week 40 Week 50 Week 60 Week 70 Week 80 Week 90 Week 100 Week 110 Week 120 Week 130  \n \n Most upvoted papers two weeks ago:\n /u/CatalyzeX_code_bot: Paper link\n /u/lauren_v2: paper\n Besides that, there are no rules, have fun.\n    submitted by    /u/ML_WAYR_bot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ub2xlz/d_machine_learning_wayr_what_are_you_reading_week/",
          "publishedOn": "2022-04-24T20:00:05.000Z",
          "wordCount": 370,
          "title": "[D] Machine Learning - WAYR (What Are You Reading) - Week 136",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ub2461/p_showcase_your_machine_learning_researchprojects/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ub2461/p_showcase_your_machine_learning_researchprojects/",
          "publishedOn": "2022-04-24T19:21:07.000Z",
          "wordCount": 116,
          "title": "[P] Showcase your Machine Learning Research/Projects in Hugging Face Spaces using Gradio",
          "imageUrl": "https://external-preview.redd.it/9YN_--X1MdMQ1lxXNI74QnaYv6Ca_Ao3ChElFUIPjwI.png?format=pjpg&auto=webp&s=8e43b35bd093209389137e40343b312afa29241e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uaxslz/d_how_is_nvidia_p100_on_google_colab_pro_compared/",
          "author": null,
          "description": "submitted by    /u/aviisu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uaxslz/d_how_is_nvidia_p100_on_google_colab_pro_compared/",
          "publishedOn": "2022-04-24T15:57:16.000Z",
          "wordCount": 1759,
          "title": "[D] How is NVIDIA P100 on Google Colab Pro compared to Laptop with RTX3080 (Mobile, or Max-Q) ?",
          "imageUrl": "https://external-preview.redd.it/F2iB3ylaJrNT3VgwPUxHcIZIffFd9zSd1MpJUp3785A.jpg?auto=webp&s=fca5ff6678c74b402625bbd6275feae53ab3b300"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uawla1/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uawla1/d_simple_questions_thread/",
          "publishedOn": "2022-04-24T15:00:11.000Z",
          "wordCount": 596,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ual85u/d_what_is_the_best_optimizer_to_use_when/",
          "author": null,
          "description": "Hi, seemingly it's become a staple in conv net inner-working visualization to put a network in eval mode, sample a random noise image, and optimize the image in relation to the activation of some internal neuron. \n From what I saw, most examples of this on the internet are using an Adam optimizer for this with a learning rate of 0.1 and a weight decay of 1e-6. \n This doesn't seem quite right with me, So if any of you know what's the source for this convention and if there are other alternatives I'd appreciate this information very much.\n Thanks!\n    submitted by    /u/ondrea_luciduma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ual85u/d_what_is_the_best_optimizer_to_use_when/",
          "publishedOn": "2022-04-24T02:56:10.000Z",
          "wordCount": 229,
          "title": "[D] What is the best optimizer to use when visualization inter-net neurons by optimizing random input in relation to it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uah6pc/time_series_analysis_for_air_pollution_data_not/",
          "author": null,
          "description": "This is about a project that I am working on; Hope the ML community can help me!\n I have collected few hours of air pollutants data using Aeroqual sensors and custom made sensors. 3 types of data is available in the project; aeroqual, custom, council data. Where council data can be taken for granted (It comes from the govt installed high spec sensor).\n Aeroqual is a commercial sensor manufacturing company, its data should be accurate. The first part of the project is about checking the accuracy of custom sensor. So, I have done few analysis on the data; and found that custom sensor data has similarity (but not same, there are so much variation in the custom sensor data) with council sensor data but aeroqual data is way different.\n I am attaching the plot below which I have done.\n ​\n  \nSo I need to know is there any method that I can find relationship between these three datasets?\n Is it possible to make these data align togather?\n I need to build an ML model to predict the air pollutant level using this data. any tips for getting this thing working?\n  \n- Thanks in advance\n ​\n https://preview.redd.it/fzu7dbsz0dv81.png?width=885&format=png&auto=webp&s=516d65fe3290ac8a28159547880f9dc972922b64\n    submitted by    /u/Codename_17  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uah6pc/time_series_analysis_for_air_pollution_data_not/",
          "publishedOn": "2022-04-23T23:06:31.000Z",
          "wordCount": 293,
          "title": "Time Series Analysis for air pollution data not aligned [R] [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uafvfm/d_for_training_a_haar_cascade_is_it_better_to/",
          "author": null,
          "description": "submitted by    /u/Counter-Business  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uafvfm/d_for_training_a_haar_cascade_is_it_better_to/",
          "publishedOn": "2022-04-23T21:58:43.000Z",
          "wordCount": 205,
          "title": "[D] For training a HAAR cascade is it better to manually remove noise from positive training images or to leave it in so the data is more realistic?",
          "imageUrl": "https://preview.redd.it/6eum46f3pcv81.jpg?auto=webp&s=2d317a1a1bcf0d3078f6e2328925e81b6a657b25"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uafe1e/d_how_to_convert_papers_to_code/",
          "author": null,
          "description": "My problem is probably what you have guessed: it's understanding the technical specifications which are usually written in a non-coding-friendly way. Sometimes crucial information is completely missing from the paper ex: loss function description for a DL algorithm. For the lucky cases where there are already available implementations on github to a given paper, usually they are either very distinguishable from each other in terms of code structure which questions their validity or whether they match what the paper authors intended specially with varying measurable results, or they are almost exact copies from one another. There are numerous examples where I can show specific papers with varying degrees of complexity, and discuss why the conversion can be tricky but they may require standalone discussions themselves, likely outside the scope of this one. Is there a way to approach the problem assuming the absence of reference code?\n    submitted by    /u/shine-box  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uafe1e/d_how_to_convert_papers_to_code/",
          "publishedOn": "2022-04-23T21:33:31.000Z",
          "wordCount": 507,
          "title": "[D] How to convert papers to code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uaf6ju/open_source_model_for_identifying_extremism/",
          "author": null,
          "description": "submitted by    /u/OppositeMonday  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uaf6ju/open_source_model_for_identifying_extremism/",
          "publishedOn": "2022-04-23T21:22:54.000Z",
          "wordCount": 99,
          "title": "Open Source Model For Identifying Extremism Online [Project]",
          "imageUrl": "https://external-preview.redd.it/gatKKT2uQT-94IL8rz58x2TQGESny6vaixpBetiTK1s.jpg?auto=webp&s=19d55d8c00c45bfd632e8856f30ad18e9b451d32"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uadnhi/p_tired_of_manually_sending_minutes_of_meeting/",
          "author": null,
          "description": "I host an important org level meeting (~100 attendees) every week, and need to share minutes after the meeting. I am so tired of listening to conversations again just to capture important points, summarise discussion and action items. Is there any model/api which can help me do that? I use Amazon transcribe to generate transcripts, which helps, but it is not very accurate. For me the priority would be: 1) Model/api which is better than Amazon transcribe 2) Auto Identify speakers / speaker diarization (since mostly the same set of people speak) 3) Summarise the conversations into topics (we have time and agenda based discussion)\n I am sure this might be a problem across the industry since most of the meetings happen online, and someone wastes hours after meeting to send notes. I did find some tools which summarise the transcript, but i need to auto send in a specific format and identify topics based on conversion (maybe we can input the agenda in advance). Also this is private information, so I need something on premise, hence looking for a repo or model which i can use to build something on top.\n Please let me know if something exists or someone working on similar projects. Happy to collaborate and contribute.\n    submitted by    /u/super_commando-dhruv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uadnhi/p_tired_of_manually_sending_minutes_of_meeting/",
          "publishedOn": "2022-04-23T20:06:31.000Z",
          "wordCount": 380,
          "title": "[P] Tired of manually sending minutes of meeting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uaddw4/r_can_you_find_out_which_news_article_is_written/",
          "author": null,
          "description": "This research will test the human ability to distinguish human written text from text generated by artificial intelligence. Participating will only take 10 minutes. You will receive 2 short news articles about the same topic. One will be written by a human, the other one will be generated by artificial intelligence. It is up to you to find out which one is written by artificial intelligence. You will be asked to do this for four different subjects, namely: Science, Economics & Politics, Society and Sports. At the end of the survey you will receive feedback on how well you have performed.\n The human written articles were collected from various news websites. The Articles created by artificial intelligence were generated using GPT-3 from OpenAI.\n Purpose of the research: We are trying to find out how well GPT-3 performs across subjects. Are there any subject GPT-3 is better at writing about, or is he equally good across all subjects. Secondly we are testing the ability of GPT-3 to generate articles about events that happened after the training of the model. \n You can participate by clicking on the link below, thank you very much for your participation.\n https://vub.fra1.qualtrics.com/jfe/form/SV_b2E9f6hGxNDH13M\n    submitted by    /u/RobinSandersVUB  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uaddw4/r_can_you_find_out_which_news_article_is_written/",
          "publishedOn": "2022-04-23T19:53:34.000Z",
          "wordCount": 401,
          "title": "[R] ?? Can you find out which news article is written by AI ??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uad4dw/r_i_need_to_run_2000_experiments_for_my_phd_work/",
          "author": null,
          "description": "2000 GPUs and 8000 CPUs. And where could I even get such a vast affordance?\n    submitted by    /u/samlerman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uad4dw/r_i_need_to_run_2000_experiments_for_my_phd_work/",
          "publishedOn": "2022-04-23T19:40:41.000Z",
          "wordCount": 659,
          "title": "[R] I need to run >2000 experiments for my PhD work. How much would 2000 GPUs for 1 day cost?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uacstm/p_vectorflow_is_a_minimalist_neural_network/",
          "author": null,
          "description": "submitted by    /u/ur_mum_goes_to_uni  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uacstm/p_vectorflow_is_a_minimalist_neural_network/",
          "publishedOn": "2022-04-23T19:24:29.000Z",
          "wordCount": 139,
          "title": "[P] Vectorflow is a minimalist neural network library optimized for sparse data and single machine environments open sourced by Netflix",
          "imageUrl": "https://external-preview.redd.it/ZtPt4WkFe4EaDF_Cvz9qSDMqtIFvqNDQi1V7r9fYqZE.jpg?auto=webp&s=221ee90be7dec44cef3fc6243be8108cd02357bf"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uacisv/project_face_detection_algorithms_comparison/",
          "author": null,
          "description": "I selected 5 ready-made algorithms for face detection and compared them with each other by such metrics as Precision, Recall, IOU and time on the dataset I marked up. I am ready to accept your Pull Request with your solutions(algorithms) and results!\n GitHub: https://github.com/wb-08/face-detection-algorithms-comparison\n Blog post: https://habr.com/ru/post/661671/\n    submitted by    /u/wb-08  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uacisv/project_face_detection_algorithms_comparison/",
          "publishedOn": "2022-04-23T19:10:39.000Z",
          "wordCount": 134,
          "title": "[Project] Face detection algorithms comparison",
          "imageUrl": "https://external-preview.redd.it/UCht1ilda6NOzvxRBsEV6qZRE2rjI3h21hx1o3Ibc-o.jpg?auto=webp&s=294414e94c756bad73ae7c4bf6854fdfe15d0372"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua5yps/discussion_writing_production_grade_code_for_ml/",
          "author": null,
          "description": "I have been interviewing for a machine learning lead position. I have successfully passed 3 interview rounds (coding , HR, system design). I have my final interview with the VP of Engineering. When asked how best to prepare myself, they said they would like to test my ability to write \"production quality\" code in python. While I do have some experience, the downside is I worked in small R&D teams for a long time. Though I am knowledgeable in python, perhaps, I might have not followed all the industry best practices.\n If you are a hiring manager or interviewer, how would you test this ability? How do I prepare myself to prove my ability to write production grade code?\n Thank you all so much in advance.\n    submitted by    /u/mbkv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua5yps/discussion_writing_production_grade_code_for_ml/",
          "publishedOn": "2022-04-23T13:55:24.000Z",
          "wordCount": 1090,
          "title": "[Discussion] Writing production grade code for ML in python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua5vig/d_comparing_the_efficiency_of_different_gan_models/",
          "author": null,
          "description": "I'm comparing different GAN models (CGan, DCGan, WGan, StyleGan) in tensorflow2. In general, I want to use the images that I generate with the generator to train a classifier while being as realistic as possible. At first, I wanted to let them train for 24 hours each, define some early stopping criteria and save the checkpoints with the lowest loss through a callback. But it seems that the lower loss does not always lead to more realistic images. So how do I compare the different models in a scientific way? Because the results highly depend on the epoch I choose and my subjective feeling, which images look the best.\n    submitted by    /u/Bonkikong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua5vig/d_comparing_the_efficiency_of_different_gan_models/",
          "publishedOn": "2022-04-23T13:50:34.000Z",
          "wordCount": 276,
          "title": "[D] Comparing the efficiency of different GAN models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua520y/p_artificial_nightmares_split_personality_clip/",
          "author": null,
          "description": "https://www.youtube.com/watch?v=2E_6ARbrMmc\n    submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua520y/p_artificial_nightmares_split_personality_clip/",
          "publishedOn": "2022-04-23T13:06:48.000Z",
          "wordCount": 120,
          "title": "[P], Artificial Nightmares: Split Personality || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/hlTDFwwRZ4wn0GUBX2uENYwTAqKodl4hmtQPIaGe2po.jpg?auto=webp&s=3043229ca7283c792e2b66610eefb4e47164b3b3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua465u/n_googles_new_ai_image_analysis_is_pretty_lit_and/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua465u/n_googles_new_ai_image_analysis_is_pretty_lit_and/",
          "publishedOn": "2022-04-23T12:16:40.000Z",
          "wordCount": 125,
          "title": "[N] Google's new AI image analysis is pretty LiT - and beats OpenAI's CLIP",
          "imageUrl": "https://external-preview.redd.it/4K_ZsdM9EbK4U2g4bnglLcONPQpLYb0aTtB8dTEcPK0.jpg?auto=webp&s=5022e30517a79227e5c8b541038ee87dd4a19eb3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua2bv0/p_a_simpler_pytorch_annotated_implementation_of/",
          "author": null,
          "description": "Github: https://github.com/labmlai/neox\n Annotated implementation: https://lit.labml.ai/github/labmlai/neox/tree/main/src/neox/__init__.py\n Original repo from EleutherAI: https://github.com/EleutherAI/gpt-neox\n We have included samples showing how to generate text and to fine-tune. We haven't included a bunch of optimizations that were present in original GPT-NeoX to keep things simple.\n    submitted by    /u/hnipun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua2bv0/p_a_simpler_pytorch_annotated_implementation_of/",
          "publishedOn": "2022-04-23T10:18:06.000Z",
          "wordCount": 346,
          "title": "[P] A Simpler @PyTorch Annotated Implementation of EleutherAI's 20B Language Model GPT-NeoX.",
          "imageUrl": "https://external-preview.redd.it/ISzESs_e2alNyvfBqT9H8r-_KssToJogl9O1_1mzZBM.jpg?auto=webp&s=5bc541aaf288b3b7898a3f106d5d3b52e66dcb14"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua1m2a/p_treequeues_transfert_jax_pytrees_between/",
          "author": null,
          "description": "Hello!\n If you are using jax and you need to pass some pytrees between processes, I may have something for you :)\n I developed a \"treequeue\". It is a queue that is made for pytree's nested arrays.\n The transfer speed is up to 10 times higher than regular queues. This is done by utilizing shared memory arrays and avoiding pickling data. This can be very useful when developing distributed architecture, e.g. distributed reinforcement learning where speed is at the upmost importance.\n In my case this implementation was very useful to remove bottlenecks when implementing PBT algorithms!\n https://github.com/thomashirtz/treequeues\n Cheers!\n    submitted by    /u/krenast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua1m2a/p_treequeues_transfert_jax_pytrees_between/",
          "publishedOn": "2022-04-23T09:26:48.000Z",
          "wordCount": 199,
          "title": "[P] treequeues: transfert jax pytrees between processes with very high speed!",
          "imageUrl": "https://external-preview.redd.it/AfqdsD-Nf9VCHqNm-Eh8Tsa9gCh6471nqoID-BYyGLE.jpg?auto=webp&s=dc5258cd3bf27473d94cb315be96e536da69c886"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua158p/d_autonsurvival_package_for_deep_survival/",
          "author": null,
          "description": "Comes with ‘white paper’ and example notebooks… seems legit..? Anyone tried this out yet?\n Github\n Paper]\n    submitted by    /u/proportional-hazard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua158p/d_autonsurvival_package_for_deep_survival/",
          "publishedOn": "2022-04-23T08:51:57.000Z",
          "wordCount": 135,
          "title": "[D] ‘auton-survival’ package for deep survival analysis and time to event regression from CMU.",
          "imageUrl": "https://external-preview.redd.it/LRLBAOWLDTmaDORdujYz0TJP6ZNultRbj5gY9uFIns0.jpg?auto=webp&s=8d9e026a5fe0d4f972af34c875e2183471e75dfd"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua121h/p_unofficial_vitvqgan_implementation/",
          "author": null,
          "description": "I know that many people (including me) were surprised after seeing the image quality of ViT-VQGAN and disappointed to know there won't be no source code released. Therefore, I've decided to implement it by myself and here is the code. I hope this can help everyone as a starting point for ViT-VQGAN.\n    submitted by    /u/ThunaClone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua121h/p_unofficial_vitvqgan_implementation/",
          "publishedOn": "2022-04-23T08:45:32.000Z",
          "wordCount": 138,
          "title": "[P] Unofficial ViT-VQGAN implementation",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9xbaa/rp_styleganhuman_a_datacentric_odyssey_of_human/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9xbaa/rp_styleganhuman_a_datacentric_odyssey_of_human/",
          "publishedOn": "2022-04-23T04:29:35.000Z",
          "wordCount": 320,
          "title": "[R][P] StyleGAN-Human: A Data-Centric Odyssey of Human Generation + Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/xh5KDFN-5xaey_VOKD2hlTmmFOXgMPiUqxc5OkZbl5g.png?format=pjpg&auto=webp&s=e7f12d16576c98ad5813cd5ff9609b93c7d9892f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9vnd6/d_review_of_endtoend_multimodal_deep_learning/",
          "author": null,
          "description": "In reviewing various approaches to end-to-end deep learning for autonomous driving, I've come across an interesting approach in this paper that I would like to discuss with others...\n I will begin by summarizing the approach:\n ​\n  \nA ResNet50 architecture is used as an encoder network with the input being an RGB image + depth map concatenated as (224 x 224 x 4). In the paper it is argued that a point cloud can also be used, or some other sensor modality would also work\n The encoder network output (feature map of 7 x 7 x 2048) is fed into a decoder network that takes it back to (224 x 224 x 5) with pixel wise semantic segmentation of 5 classes: lane, road line, sidewalk, vehicles or pedestrians, and others\n That same encoder output (feature map of 7 x 7 x 2048) is global average pooled to 2…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9vnd6/d_review_of_endtoend_multimodal_deep_learning/",
          "publishedOn": "2022-04-23T02:54:52.000Z",
          "wordCount": 523,
          "title": "[D] Review of end-to-end multi-modal deep learning approach for autonomous navigation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9oygy/r_game_changer_or_not_an_evaluation_of/",
          "author": null,
          "description": "https://arxiv.org/abs/2204.09123 \n https://www.researchgate.net/publication/360079336_GAMe_changer_or_not_An_evaluation_of_interpretable_machine_learning_models_based_on_additive_model_constraints\n    submitted by    /u/Positive_Ad_1090  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9oygy/r_game_changer_or_not_an_evaluation_of/",
          "publishedOn": "2022-04-22T21:15:41.000Z",
          "wordCount": 126,
          "title": "[R] GAM(e) changer or not? An evaluation of interpretable machine learning models based on additive model constraints",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9jn6x/how_can_you_differentiate_kornia_sift_descriptor_p/",
          "author": null,
          "description": "Kornia is a differentiable library for computer vision based on PyTorch. Does anyone have experience with their SIFT descriptor. What can you differentiate?\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9jn6x/how_can_you_differentiate_kornia_sift_descriptor_p/",
          "publishedOn": "2022-04-22T17:12:18.000Z",
          "wordCount": 121,
          "title": "How can you differentiate Kornia SIFT descriptor? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9h972/d_evaluation_and_selecting_models_base_on_loss_or/",
          "author": null,
          "description": "When comes to evaluating and selecting a model, should one focus on minimizing loss (i.e., sparse categorical crossentropy) or obtain high rated metrics (i.e., f1)?\n Often time the model highest rated metrics would generate higher loss than ones with lower ratings in metrics during validation/test sets.\n Some would say focus on metrics as loss are for the machine to optimize learning, what stays in the training, stays in the training. However, wouldn't loss be also an important element to consider since it also describe the performance of the model, particularly when obtained from the test set?\n How should one prioritize? Metrics/loss rules all or seek for balance?\n    submitted by    /u/Hydraze  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9h972/d_evaluation_and_selecting_models_base_on_loss_or/",
          "publishedOn": "2022-04-22T15:26:21.000Z",
          "wordCount": 446,
          "title": "[D] Evaluation and Selecting Models: Base on Loss or Metrics?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9bo6s/r_optimize_clustering_for_downstream_task/",
          "author": null,
          "description": "Assume to have a 2-step algorithm: 1) aggregate data points into clusters 2) feed the clusters to a downstream task (e.g. classification, regression, etc).\n Is there any work that explores how to optimize the clustering in 1) to achieve the best performance in the downstream task 2)?\n One example would be a differentiable clustering algorithm that receives gradients from the downstream task or a parametrized clustering algorithm whose parameters are automatically tuned to increase the performance of the downstream task.\n I have found very little on this topic in the literature, could you point me to some relevant work?\n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9bo6s/r_optimize_clustering_for_downstream_task/",
          "publishedOn": "2022-04-22T10:43:12.000Z",
          "wordCount": 423,
          "title": "[R] Optimize clustering for downstream task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u99fgu/d_what_is_a_good_emoji_aware_pretrained_language/",
          "author": null,
          "description": "I am classifying social media posts (facebook, instagram), with emojis being upwards of 100% of content. For example, you may want to tag \"🤮🤮🤮\" as in need for moderation, and \"🤔🤔🤔\" as prioritized for a response.\n Looking for a good model to fine tune I found BerTweet, which seems at least somewhat emoji aware. However it also has a ton of out-of-vocabulary results, both for emoji and semi-common English words, despite it's liberal use of emoji.demojize and splitting up more complex emoji:\n ​\n https://preview.redd.it/t6ai3o8le1v81.png?width=687&format=png&auto=webp&s=c16157addbe1b3d34858708f3e6c7517e64d26ec\n A model like `xlm-roberta-base with a larger vocabulary (250k) and more robust tokenization seems to have some 500 emoji directly in its vocabulary directly, without converting them to text. This seems potentially more promising, but also guarantees a token like 🤮 is just out of vocabulary rather than being interpreted by word pieces.\n Has anyone here had experience with dealing with emoji in text classification, and what approaches were most successful?\n    submitted by    /u/sanderbaduk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u99fgu/d_what_is_a_good_emoji_aware_pretrained_language/",
          "publishedOn": "2022-04-22T08:06:43.000Z",
          "wordCount": 716,
          "title": "[D] What is a good emoji aware pre-trained language model?",
          "imageUrl": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?auto=webp&s=720b78add0a3005c4f67eaed6897df409cc040c6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u980kl/d_what_is_the_best_method_to_use_metric_network/",
          "author": null,
          "description": "Hi, I have a question about how to use metric network after contrastive learning. If I have trained a network well with NCELoss, I would like to finetune this network to match the best output by input(It used at calculating NCELoss). Is there any good way to do it?\n ​\n Thank you for reading!\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u980kl/d_what_is_the_best_method_to_use_metric_network/",
          "publishedOn": "2022-04-22T06:28:31.000Z",
          "wordCount": 171,
          "title": "[D] What is the best method to use metric network at finetune after contrastive learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u967sy/d_opinions_needed_anyone_interested_in_mock_peer/",
          "author": null,
          "description": "We’d like to know if anyone is interested in participating in a mock peer review? Basically if you have a paper you’d like to get feedback on, and would like to review others’ papers in exchange, you’re welcome to continue reading.\n We are gauging public interest in mock peer review and exploring the possibility to host the reviews on DouBlind. We’d like to know your answers to the following questions:\n  \nAre you interested in mock peer review? \n Do you want to do this privately (paper and review are kept inside a small group) or openly (paper and review are open)?\n How many papers do you like to review?\n Do you have any concerns?\n  \n   submitted by    /u/DouBlindDotCOM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u967sy/d_opinions_needed_anyone_interested_in_mock_peer/",
          "publishedOn": "2022-04-22T04:32:52.000Z",
          "wordCount": 522,
          "title": "[D] Opinions needed - Anyone interested in mock peer review?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u94fnq/research_explaining_the_black_box_optimization/",
          "author": null,
          "description": "This is reproduced from Zhihu and translated by DeepL, only used for enthusiasts to communicate.\n ​\n MindSpore, as an end-to-edge cloud collaborative full-scenario AI open source framework, takes into account the flexibility of academic research and the high-performance needs of industry, supports end-to-edge cloud full-scene business, and brings developers a simpler programming, easier debugging, superior performance, and more flexible deployment experience, which has received widespread attention and application in the industry and has been open source on 2020.3.28, and is the Gitee The highest index of open source software. Welcome to participate in open source contributions, model crowdsourcing collaboration, industry innovation and application, algorithm innovation, academic collabora…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u94fnq/research_explaining_the_black_box_optimization/",
          "publishedOn": "2022-04-22T02:51:01.000Z",
          "wordCount": 766,
          "title": "[Research] Explaining the Black Box Optimization Competition Winner Algorithm-HEBO Algorithm of AI Top Conference NeurIPS 2020",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8zhy2/p_mgpt_model_released_a_multilingual_gpt3like/",
          "author": null,
          "description": "Hi everyone. Today we released the mGPT model: multilingual generative pre-trained transformer\n The checkpoints are available on Huggingface model page\n The example usage is at the Github repo https://github.com/ai-forever/mgpt \n  \nThe model has 1.3 billion parameters\n The context length is 512 tokens. \n  \nThe model can generate sequences after the input prompt, can be used for fine-tuning or for zero- and few-shot learning:\n from transformers import GPT2LMHeadModel, GPT2Tokenizer model_name = \"sberbank-ai/mGPT\" tokenizer = GPT2Tokenizer.from_pretrained(model_name) model = GPT2LMHeadModel.from_pretrained(model_name) model.cuda() model.eval() texts = [ \"My favourite holiday is \", \"Իմ սիրելի տոնն է \", \"Моє улюблене свято \", \"mi fiesta favorita es \", \"मेरी पसंदीदा छुट्टी है\", \"我最喜欢的节日是\", \"Min…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8zhy2/p_mgpt_model_released_a_multilingual_gpt3like/",
          "publishedOn": "2022-04-21T22:37:10.000Z",
          "wordCount": 461,
          "title": "[P] mGPT model released: a multilingual gpt-3-like model for 61 language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8xrhg/p_deep_learning_gpu_benchmark_a_latencybased/",
          "author": null,
          "description": "Hi r/MachineLearning! I want to share with you a fun side project of mine on benchmarking the GPUs for deep learning: [project page]. \n https://preview.redd.it/7olwqyze5yu81.png?width=2041&format=png&auto=webp&s=25aecb9733366720a2be5cecc2048eb2a734c9b9\n Here are some key features:\n  \nIt helps to estimate the runtime of algorithms on a different GPU.\n It measures GPU processing speed independent of GPU memory capacity.\n It contains adjustable weightings through interactive UIs.\n  \nThe project page also explains how this benchmark differs from existing ones, and why this benchmark is more relevant to academic research.\n I would love to know what you think!\n    submitted by    /u/roll-a-dice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8xrhg/p_deep_learning_gpu_benchmark_a_latencybased/",
          "publishedOn": "2022-04-21T21:13:36.000Z",
          "wordCount": 179,
          "title": "[P] Deep Learning GPU Benchmark: A Latency-Based Approach",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8xexj/d_whats_your_perfect_laptop_for_deep_learning/",
          "author": null,
          "description": "I'm using mbp 2015, it's a pretty solid laptop, I like it a lot, though it feels slow and I've started to look for a replacement. Given that I run all experiment on gpu dedicated servers, my laptop serves me as a typewriter, it's ok, but I'd like to get more out of it. Frankly I'm a bit disappointed by 2021 Macbooks, hope they'll be improved in 2022.\n Recently lambda labs together with razer announced their tensorbook https://lambdalabs.com/deep-learning/laptops/tensorbook , their pricing looks weird to me, the more you pay the more years of support you have, that's the only thing which differentiates base bundle from enterprise. Also there is no option to customize hardware for it, though basic bundle itself looks ok, its price is $3500 like M1 Max's. What's your opinion about this laptop in particular? would you buy it?\n generally this laptop looks like a cool thing to have for local model development even from a tent somewhere in Nepal, given that you have enough power banks to charge it. :)\n What's your choice of a laptop for DL? My biggest requirement is a durable laptop which will serve at least 5 years, better with NVIDA GPU for development and debugging.\n    submitted by    /u/taras-sereda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8xexj/d_whats_your_perfect_laptop_for_deep_learning/",
          "publishedOn": "2022-04-21T20:57:29.000Z",
          "wordCount": 326,
          "title": "[D] What's your perfect laptop for deep learning research?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8w5bq/r_deep_models_of_superficial_face_judgments_pnas/",
          "author": null,
          "description": "​\n Transformations that alter the perception of target faces\n Paper: https://www.pnas.org/doi/10.1073/pnas.2115228119\n Dataset: https://onemillionimpressions.com/\n    submitted by    /u/joshuacpeterson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8w5bq/r_deep_models_of_superficial_face_judgments_pnas/",
          "publishedOn": "2022-04-21T19:59:31.000Z",
          "wordCount": 108,
          "title": "[R] Deep models of superficial face judgments (PNAS)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8v92h/r_planting_undetectable_backdoors_in_machine/",
          "author": null,
          "description": "submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8v92h/r_planting_undetectable_backdoors_in_machine/",
          "publishedOn": "2022-04-21T19:17:49.000Z",
          "wordCount": 101,
          "title": "[R] Planting Undetectable Backdoors in Machine Learning Models",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8v2ox/p_vicreg_tutorial_and_lightweight_pytorch/",
          "author": null,
          "description": "Here's a tutorial and lightweight PyTorch implementation of VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning. Hope you find it helpful!\n    submitted by    /u/thejashGI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8v2ox/p_vicreg_tutorial_and_lightweight_pytorch/",
          "publishedOn": "2022-04-21T19:09:51.000Z",
          "wordCount": 136,
          "title": "[P] VICReg: Tutorial and Lightweight PyTorch Implementation blog post",
          "imageUrl": "https://external-preview.redd.it/nlio8usMqy_ReFWZfdRWZzVWPAOmlaQsm5fC0fDkpO4.jpg?auto=webp&s=e7ed882487e5ed475af6d8e7f98866ba1a7d80b0"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8s9zr/p_announcing_cleanlab_20_automatically_find/",
          "author": null,
          "description": "Hi folks. This morning I released the new cleanlab 2.0 Python package for automatically finding errors in datasets and machine learning/analytics with real-world, messy data and labels.\n tl;dr - cleanlab provides a framework to streamline data-centric AI. \n https://preview.redd.it/hq1kyasvwwu81.png?width=2279&format=png&auto=webp&s=4fa3c82ec66d685c8fc4f95c5d9a0fc4be192d6b\n After 1.0 launch last year, engineers used cleanlab at Google to clean and train robust models on speech data), at Amazon to estimate how often the Alexa device doesn’t wake, at Wells Fargo to train reliable financial prediction models, and at Microsoft, Tesla, Facebook, etc. Joined by two good friends from grad school, we completely rebuilt cleanlab 2.0 to work for all data scientists, ML datasets, and models; and hit a…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8s9zr/p_announcing_cleanlab_20_automatically_find/",
          "publishedOn": "2022-04-21T17:01:18.000Z",
          "wordCount": 473,
          "title": "[P] Announcing cleanlab 2.0: Automatically Find Errors in ML Datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8s48x/p_galp_hackathon_win_10000_from_home/",
          "author": null,
          "description": "If you are passionate about Data & AI we have the perfect challenge for you!\n The applications for Galp’s Hackathon Retail 4.0 are OPEN! With this Hackathon, Galp is challenging the community to propose solutions to specific problems and use cases that they think could improve their typical customer journey in the service stations.\n Gather a team and come up with an innovative solution for a chance of winning 10.000€!\n Let’s shape the future of Galp's retail?\n Apply now: https://taikai.network/en/galp/hackathons/retail40\n https://preview.redd.it/wkfb6ybuwwu81.png?width=3334&format=png&auto=webp&s=deef13767df5ba607e387ce4e278ae3981d93582\n    submitted by    /u/migueldsalmeida  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8s48x/p_galp_hackathon_win_10000_from_home/",
          "publishedOn": "2022-04-21T16:54:27.000Z",
          "wordCount": 174,
          "title": "[P] Galp Hackathon - Win 10.000€ from home!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8ratz/d_imbalanced_multi_class_classification/",
          "author": null,
          "description": "I'm working on a Machine Learning problem for multi class classification with imbalanced classes distribution, so obviously my model favours classes with more data and fails to predict classes with few data, what are the techniques I can use to help the model distinguish all the classes the same way ? P.S I'm avoiding to use SMOTE method to train the model on real used data rather than generated\n    submitted by    /u/According-Promise-23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8ratz/d_imbalanced_multi_class_classification/",
          "publishedOn": "2022-04-21T16:17:38.000Z",
          "wordCount": 472,
          "title": "[D] Imbalanced multi class classification 📌",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8qr5s/r_cvpr_2022_photorealistic_monocular_3d/",
          "author": null,
          "description": "submitted by    /u/SleekEagle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8qr5s/r_cvpr_2022_photorealistic_monocular_3d/",
          "publishedOn": "2022-04-21T15:54:05.000Z",
          "wordCount": 111,
          "title": "[R] CVPR 2022 - Photorealistic Monocular 3D Reconstruction of Humans Wearing Clothing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8osxe/r_my_continuously_updated_machine_learning/",
          "author": null,
          "description": "Dear ML researchers,\n For the past many years, I've been updating my machine learning research notes for my PhD students and everyone online continuously. I don't like uploading to arxiv to get \"citations\", and GitHub serves me well: Hope they are useful for you:\n https://github.com/roboticcam/machine-learning-notes\n Richard,\n    submitted by    /u/MLknowledge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8osxe/r_my_continuously_updated_machine_learning/",
          "publishedOn": "2022-04-21T14:23:41.000Z",
          "wordCount": 212,
          "title": "[R] My continuously updated machine learning research notes",
          "imageUrl": "https://external-preview.redd.it/jXbGZ4rJFm5S_5qjRLqzl6dlfbQGyZrgZeCf1as5zc4.jpg?auto=webp&s=30db4308813fd683b4c6e18df9b7ac3c3077dcb1"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8o3fd/d_correcting_for_imbalance_in_regression_datasets/",
          "author": null,
          "description": "Hi, I am performing a Image --> scalar regression. The output scalar I am trying to estimate follows a roughly Gaussian distribution. I notice that the DNN output is biased to output values towards the mean (makes sense). \n ​\n This seems like a problem of imbalanced data. For classification, I can oversample minority classes. What is the equivalent for regression? Is there an equivalent technique for regression where we oversample \"outliers\" and undersample central values.\n    submitted by    /u/rsandler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8o3fd/d_correcting_for_imbalance_in_regression_datasets/",
          "publishedOn": "2022-04-21T13:49:27.000Z",
          "wordCount": 356,
          "title": "[D] Correcting for imbalance in regression datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8nv9n/building_dense_passage_retrievers_p/",
          "author": null,
          "description": "Hi, I made a video explaining the ideas behind building a Dense Passage Retriever(DPR). Whenever we talk about retrievers, we mostly refer to the DPR formulation which appeared in this paper. A lot of publicly available implementations also use this formulation. \n In a previous video, we discussed how to use the DPR End-to-End QA system which uses DPR with a QA model. In this video, we solely focus on retrievers and the ideas behind building them. The implementation is quite similar to retrievers pre-trained with Inverse Close Task.\n This video is part 8 of 9 video series on Open-domain question answering using Dense retrievers. Thanks for the support and I will appreciate any feedback.\n https://www.youtube.com/watch?v=w61p0HLo7gc\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8nv9n/building_dense_passage_retrievers_p/",
          "publishedOn": "2022-04-21T13:38:00.000Z",
          "wordCount": 217,
          "title": "Building Dense Passage Retrievers [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8nfz4/d_how_do_you_usually_run_sanity_checks_when/",
          "author": null,
          "description": "Hi, \n I have been studying super-resolution with gans and took a look at SRGAN et ESRGAN. \n I have spent the whole day running experiments in order to find if I can manage to overfit on a single batch of 16 / 32 / 128 examples (MNIST). \n I have found out that it's almost impossible to use this tactic as a sanity check because it simply cannot generate good quality samples. \n I would like to know what are your thoughts on this, and how you would run sanity checks regarding GANs. \n ​\n Thank you !\n    submitted by    /u/Frizzoux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8nfz4/d_how_do_you_usually_run_sanity_checks_when/",
          "publishedOn": "2022-04-21T13:16:41.000Z",
          "wordCount": 257,
          "title": "[D] How do you usually run sanity checks when training GANs ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8l3p1/d_amazon_releases_a_new_multilingual_dataset_for/",
          "author": null,
          "description": "https://www.amazon.science/blog/amazon-releases-51-language-dataset-for-language-understanding\n    submitted by    /u/__lawless  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8l3p1/d_amazon_releases_a_new_multilingual_dataset_for/",
          "publishedOn": "2022-04-21T11:10:14.000Z",
          "wordCount": 107,
          "title": "[D] Amazon Releases a New Multilingual Dataset for NLU",
          "imageUrl": "https://external-preview.redd.it/HL7tbrZbJvn55TAdNpFHuAjizldYc59pZoCL1Xwpj_Y.jpg?auto=webp&s=4bfac45af0c823edd59ce0782aff290631174975"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8l0yj/d_how_to_handle_features_that_apply_to_a_whole/",
          "author": null,
          "description": "Hi all,\n I have csv-files (~300) with a fixed set of columns (~40) but varying number of rows (sum of all rows ~300 000) and multiple labels per csv that I want to predict.\n Because of the limited number of csv-files and as a first try I am predicting the labels row-wise (attaching the label to all the rows of one csv-file) which works well for some labels but not for others.\n Currently, I am calculating some features for every row and just appending them to the row and some features for the whole csv-file and appending them to every row.\n Two problems are now arising that I would like to hear some input about:\n  \nThe number of features per csv is growing and it seems like a waste to copy them to every row.\n For some labels it is probably reasonable to throw away most of the rows and only feed in a handful.\n  \nHow would you design a structure that incorporates the limited number of csv-files and the different ways to treat features (row vs. csv)?\n    submitted by    /u/tlklk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8l0yj/d_how_to_handle_features_that_apply_to_a_whole/",
          "publishedOn": "2022-04-21T11:05:38.000Z",
          "wordCount": 523,
          "title": "[D] How to handle features that apply to a whole csv-file vs single rows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8jy96/rp_differences_in_publishing_a_paper_at_a/",
          "author": null,
          "description": "Hi!\n I am an undergrad and I am going to start my MS in CS this fall. My research interest is mainly in Multimodal Learning for language and Speech.\n I have written papers before but both my papers have been peer reviewed journal papers (Knowledge-Based Systems, Elsevier) [1] [2] I now want to start publishing papers in conferences since I have noticed that it is much easier to get noticed and recieve reviews when the paper is presented at a conference.\n I want to understand how different is the publication process for conferences? I also wanted recommendations on conferences in the NLP and Speech area, considering this will be my first conference paper.\n Thanks!\n (I would also appreciate reviews on my papers if anyone has the time to look them over. Thanks!)\n    submitted by    /u/prabhav55221  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8jy96/rp_differences_in_publishing_a_paper_at_a/",
          "publishedOn": "2022-04-21T09:55:49.000Z",
          "wordCount": 1063,
          "title": "[R][P] Differences in publishing a paper at a conference and in a journal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8jsiz/d_how_do_you_get_the_maximum_of_arxiv_sanity/",
          "author": null,
          "description": "Basically, I don't want to phrase this as a a \"how-to\" post but arxiv-sanity-lite really bothers me.\n How do you guys find recent papers in your area of interest which are promising besides following what is published at major conferences?\n I believe the website is \"too lightweight\". For example, what if I am interested in computer vision papers and I specify that in the tags field (i.e. explicitly typing \"computer vision\"). How can I list the papers based on a score (basically goodness of the paper)?\n Why does using shortcuts (basically links) like `````recommend over last week or recommend over last 3 days always (at least for me) end up with 0 results? I've never used the original arxiv-sanity before so I strongly believe that there is something that I am missing.\n    submitted by    /u/Icy_Fisherman7187  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8jsiz/d_how_do_you_get_the_maximum_of_arxiv_sanity/",
          "publishedOn": "2022-04-21T09:44:38.000Z",
          "wordCount": 234,
          "title": "[D] How do you get the maximum of arxiv sanity?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8j9n4/n_new_opportunity_phd_candidate_within/",
          "author": null,
          "description": "The Norwegian University of Science and Technology (NTNU) has a vacancy for PhD Candidate within the DIGITALSEAICE project . The project aims to build a multi-scale digital infrastructure that integrates local and regional sea ice models for improved forecasting and understanding of variations in polar ice conditions. More information here: https://www.jobbnorge.no/en/available-jobs/job/224802/\n    submitted by    /u/KatjaKim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8j9n4/n_new_opportunity_phd_candidate_within/",
          "publishedOn": "2022-04-21T09:06:39.000Z",
          "wordCount": 182,
          "title": "[N] New opportunity: PhD Candidate within multisensor data fusion and applied machine learning for analysis of Arctic sea ice",
          "imageUrl": "https://external-preview.redd.it/iFk1S-x00j8dnsCHhxBvPo7JzLeQuhitkNnYKvwNwHo.jpg?auto=webp&s=e22b8f75383380a5eb366624ed9acdb0948362f4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8j8vb/p_efficient_deep_learning_book/",
          "author": null,
          "description": "We are working on a book that focuses on deep learning efficiency techniques such as quantization, pruning, distillation, etc. for both server-side as well as on-device (smartphones, IoT, etc.) applications.\n The goal is to introduce these ideas in a single place, without having to parse many papers, try to get a working code sample, and then spend time debugging. With the accompanying codelabs, we hope that our readers can make their models 4-20x smaller, faster, and better in quality.\n We have released the first four chapter's draft PDFs, and would truly appreciate any sort of comments / feedback.\n Book: efficientdlbook.com\n Feedback: hello@efficientdlbook.com\n    submitted by    /u/EfficientDLBook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8j8vb/p_efficient_deep_learning_book/",
          "publishedOn": "2022-04-21T09:05:10.000Z",
          "wordCount": 411,
          "title": "[P] Efficient Deep Learning Book",
          "imageUrl": "https://external-preview.redd.it/oWMg82plS_K_je4LqS3qhPS63T9YaY5hp-w2uvo9be8.jpg?auto=webp&s=012de82bd475d884d9dccf16ab837af217707e11"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8j1yz/d_interview_w_google_brain_researchers_on_sparse/",
          "author": null,
          "description": "https://youtu.be/ccBMRryxGog\n This video is an interview with Barret Zoph and William Fedus of Google Brain about Sparse Expert Models.\n Sparse Expert models have been hugely successful at distributing parts of models, mostly Transformers, across large array of machines and use a routing function to effectively route signals between them. This means that even though these models have a huge number of parameters, the computational load for a given signal does not increase because the model is only sparsely activated. Sparse expert models, such as Switch Transformers and GLAM can scale up to trillions of parameters and bring a number of desirable properties. We discuss everything from the fundamentals, history, strengths and weaknesses, up to the current state of the art of these models.\n ​\n OUTLINE:\n 0:00 - Intro\n 0:30 - What are sparse expert models?\n 4:25 - Start of Interview\n 5:55 - What do you mean by sparse experts?\n 8:10 - How does routing work in these models?\n 12:10 - What is the history of sparse experts?\n 14:45 - What does an individual expert learn?\n 19:25 - When are these models appropriate?\n 22:30 - How comparable are sparse to dense models?\n 26:30 - How does the pathways system connect to this?\n 28:45 - What improvements did GLAM make?\n 31:30 - The \"designing sparse experts\" paper\n 37:45 - Can experts be frozen during training?\n 41:20 - Can the routing function be improved?\n 47:15 - Can experts be distributed beyond data centers?\n 50:20 - Are there sparse experts for other domains than NLP?\n 52:15 - Are sparse and dense models in competition?\n 53:35 - Where do we go from here?\n 56:30 - How can people get started with this?\n ​\n Papers:\n Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity (https://arxiv.org/abs/2101.03961)\n GLaM: Efficient Scaling of Language Models with Mixture-of-Experts (https://arxiv.org/abs/2112.06905)\n Designing Effective Sparse Expert Models (https://arxiv.org/abs/2202.08906)\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8j1yz/d_interview_w_google_brain_researchers_on_sparse/",
          "publishedOn": "2022-04-21T08:51:22.000Z",
          "wordCount": 398,
          "title": "[D] Interview w/ Google Brain researchers on Sparse Expert Models (Switch Transformers, GLAM, and more...)",
          "imageUrl": "https://external-preview.redd.it/ccj3vB9Jnic9PtdsYqEHsfolMycEL3nvIr8XujwicFo.jpg?auto=webp&s=6c0d9971b48a4126d732a0ffe51b62be0ff80a85"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8i9ei/p_interactive_semantic_map_of_iclr_2022/",
          "author": null,
          "description": "Next week ICLR 2022 is taking place. Fully virtual and 1000+ high quality papers. To make sense of this volume of papers we have indexed the papers and provide an interactive semantic map of #ICLR2022, check out:\n https://search.zeta-alpha.com/?q=&d=ly&doc_sources=ICLR&sort_by=authority \n To enjoy the full map, click on [Explore more] and then enter full screen mode.\n We will also discuss the program and 10 must read papers in the Zeta Alpha \"Trends in AI\" ICLR edition webinar Monday 25th, for which you can sign up here.\n https://us06web.zoom.us/webinar/register/7816505274568/WN_82DzwhXZQbOCSTWgaI9xMw\n Looking forward to meet you online at ICLR 2022! \n https://preview.redd.it/6wdqj4ru7uu81.jpg?width=2202&format=pjpg&auto=webp&s=c97417c9ea39919041949bf3aa38ad33bb6eca5a\n    submitted by    /u/EngineerZetaAlpha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8i9ei/p_interactive_semantic_map_of_iclr_2022/",
          "publishedOn": "2022-04-21T07:52:53.000Z",
          "wordCount": 183,
          "title": "[P] Interactive semantic map of ICLR 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8d4d8/r_mindspore_paper_interpretation_miehdr_cnn_main/",
          "author": null,
          "description": "This article is reproduced from Zhihu and translated by DeepL for enthusiasts to communicate.\n 1. Research Background\n High dynamic range images (HDR) are mainly oriented to picture display technology. In a certain scene, if the range of high and low luminance areas exceeds the maximum luminance range of the image, the display effect will be greatly reduced, and HDR is to better solve this problem, it can record a broader range of luminance images, so as to obtain a more effective display effect.\n The current solution to the problem of generating high dynamic range images (HDR) focuses on the fusion of two low dynamic range (LDR) images of different exposures taken with the same camera. In such a solution by the camera shake or object movement during the exposure time to produce the proble…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8d4d8/r_mindspore_paper_interpretation_miehdr_cnn_main/",
          "publishedOn": "2022-04-21T02:31:54.000Z",
          "wordCount": 1003,
          "title": "[R] MindSpore Paper Interpretation: MIEHDR CNN: Main Image Enhancement based Ghost-Free High Dynamic Range Imaging using Dual-Lens Systems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8baf6/d_most_efficient_way_to_use_large_image_datasets/",
          "author": null,
          "description": "I am having trouble finding some general information on this subject. I know I am down the rabbit hole when google doesn't have an answer.\n I want to know best practices and information on using clusters for machine learning with large amounts of data. I believe I have a close to an optimal solution but wanted to get some other opinions on the subject.\n My current setup:\n  \nAWS EKS Kubernetes for a cluster\n Kubeflow for ML platform\n Katib for HPT jobs\n Pytorch for custom models\n Spot instance GPUs\n Lustre for file serving to the models\n  \nMy Data:\n  \nMillions of Images stored in S3\n ~50TB of data\n  \nWhat is the most efficient way to move my data to the cluster?\n My current approach:\n  \nPreprocess the data with a dedicated instance and store it in S3\n Master runs on a dedicated node\n Katib spins up a set number of GPU spot nodes\n A claim is made, and an FSx Lustre system is generated for the pod\n Advantages: Very fast training and data movement with spot training\n Disadvantages: I have to spin up several Lustre systems for the training\n Preprocess the data with a dedicated instance and store it in S3\n  \nPossible alternative\n  \nSame as above but use EFS as a distributed file system so I don't have to wait for Lustre\n Advantages: Potentially cheaper as I have only one FS\n Disadvantages: Slow throughput, read this was a bad idea\n Master runs on a dedicated node\n  \nOther alternatives\n  \nUseKatib spins up a PyTorch streaming function with S3(boosted transfer speed)set number of GPU spot nodes\n Every pod starts a claim is made and downloads data to an EBS\n Give up and switch to SageMakerFSx Lustre system is generated for the pod\n  \nAnyone with experience in these technologies I would really appreciate hearing your thoughts.\n    submitted by    /u/thewineiswater  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8baf6/d_most_efficient_way_to_use_large_image_datasets/",
          "publishedOn": "2022-04-21T00:57:09.000Z",
          "wordCount": 382,
          "title": "[D] Most efficient way to use large image datasets with clusters for ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8av34/d_p_neural_network_same_prediction_for_different/",
          "author": null,
          "description": "I am getting the same prediction for different inputs. I am trying to use a regressional neural network. Since data is huge, I am training one example at a time. Here is a simplified version of my code.\n model = Sequential() model.add(Dense(10000, input_dim=212207, kernel_initializer='normal', activation='relu')) model.add(Dense(100, activation='relu')) model.add(Dense(1, kernel_initializer='normal')) model.compile(loss='mean_squared_error', optimizer='adam') for i in range(10000000): #X is input with 212207 values #Y is a output value if i<6000000: model.fit(X.transpose(), Y, epochs=30, batch_size=1, verbose=0) else: prediction=model.predict(X.transpose()) \n I made sure that I am training on different examples and trying predictions on different examples. I am still getting the same prediction value for all testing inputs. I think I made some mistake in defining the model for regression neural network. Can you please check if the code is correct?\n    submitted by    /u/exoplanet_hunter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8av34/d_p_neural_network_same_prediction_for_different/",
          "publishedOn": "2022-04-21T00:35:00.000Z",
          "wordCount": 226,
          "title": "[D] [P] Neural network: same prediction for different inputs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u85rh7/d_who_are_using_physics_informed_neural_networks/",
          "author": null,
          "description": "I stumbled upon this JD from Hitachi Energy, which mentions PINN in the section of preferred background: https://www.linkedin.com/jobs/view/2923292435/\n Is PINN gaining more attention? And are there more players?\n    submitted by    /u/Kohomologia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u85rh7/d_who_are_using_physics_informed_neural_networks/",
          "publishedOn": "2022-04-20T20:31:36.000Z",
          "wordCount": 198,
          "title": "[D] Who are using physics informed neural networks (PINN) in the industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u83jx5/d_is_quantum_ai_a_real_thing_from_the_software/",
          "author": null,
          "description": "Hi all\n I'm keeping an eye on state of the art in quantum hardware, but what about software? I can think of many questions and maybe some of you are in the field.\n  \nWhat should be the impact of quantum on ML/DL, realistically?\n What might be a roadmap for the software? And would quantum simulators do already have some benefits on AI?\n What are the best projects out there? I've seen many but haven't been very convinced\n  \n   submitted by    /u/IntelligentHat1657  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u83jx5/d_is_quantum_ai_a_real_thing_from_the_software/",
          "publishedOn": "2022-04-20T18:50:43.000Z",
          "wordCount": 514,
          "title": "[D] Is quantum AI a real thing? (from the software perspective)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u82znf/d_a_more_fair_ai_freelancer_marketplace_that/",
          "author": null,
          "description": "Hi, ML freelancers. I'm starting a freelancing marketplace, tailored only for AI talents, and I especially care about the welfares of freelancers, and plan to add these: (1) you will be more treated as the employees of the platform, thus we provide training(for all), potentially health care plan(for people have stably worked >20 hours a week), and career advance plan, mentors from experienced freelancers where you get to learn (2) open discussion between employers and you so that you can scope the project better, set a reasonable rate, and timeline (3) we potentially provide MLOPs tool to improve your productivity. (4) we avoid global competition by matching business only with local region-freelancer or areas that are more expensive. How attractive do you think this will be? And any of these benefits already been provided by upwork, freelancer, toptal, fierr?\n    submitted by    /u/meame2010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u82znf/d_a_more_fair_ai_freelancer_marketplace_that/",
          "publishedOn": "2022-04-20T18:24:44.000Z",
          "wordCount": 602,
          "title": "[D] A more fair AI freelancer marketplace that cares freelancers' career advance and benefits",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u81xcu/d_diffusion_models_video_tutorial/",
          "author": null,
          "description": "Diffusion models have been behind a recent string of impressive generative results, including OpenAI's DALL-E 2. They’re powered by a simple yet expressive core mechanism. New video covering how they work: https://youtu.be/fbLgFrlTnGU\n    submitted by    /u/ariseff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u81xcu/d_diffusion_models_video_tutorial/",
          "publishedOn": "2022-04-20T17:36:29.000Z",
          "wordCount": 133,
          "title": "[D] Diffusion models video tutorial",
          "imageUrl": "https://external-preview.redd.it/mxUM6T4HtbKZ5GSYz1fROuCkz61-3157IJ3MfBCvG04.jpg?auto=webp&s=6465d7ee8a83d360f28b3c107f86213c6a953f1e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u81jfe/d_building_the_model_behind_doordashs_expansive/",
          "author": null,
          "description": "Interested in how DoorDash maintains a well performing and diverse selection in the numerous markets they operate in despite entering the delivery market relatively late ? I had the opportunity to collaborate in this project which involved building a number of models that measured customer preferences, identified market cuisine categories, and predicted merchants' performance on the platform. I wanted to share the approach and some of the technical details with the ML community to get feedback on what we can improve and to show this cool use case to others working on similar sales enablement based models. Check out the blog post I wrote and let me know what you think of our approach. \n Building the Model Behind DoorDash’s Expansive Merchant Selection\n    submitted by    /u/EfficientString7431  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u81jfe/d_building_the_model_behind_doordashs_expansive/",
          "publishedOn": "2022-04-20T17:18:32.000Z",
          "wordCount": 222,
          "title": "[D] Building the Model Behind DoorDash’s Expansive Merchant Selection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u80klz/d_whats_hot_in_deep_learning_research_at_the/",
          "author": null,
          "description": "I took a break from deep learning( starting from last October) , now i want to get back, start with a new project and read papers . Where should i focus ? Should i keep working on vision transformers or maybe start something on geometric deep learning . What's hot and what's going on ?\n    submitted by    /u/ovotheking  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u80klz/d_whats_hot_in_deep_learning_research_at_the/",
          "publishedOn": "2022-04-20T16:35:25.000Z",
          "wordCount": 333,
          "title": "[D] What's hot in deep learning research at the moment ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7zk6b/p_a_simple_pytorch_yolov1_training_pipeline/",
          "author": null,
          "description": "https://github.com/sovit-123/yolov1_pytorch_voc07\n ​\n Also, I write about Deep Learning and Machine Learning on https://debuggercafe.com/\n Please check it out and let me know if somebody wants any blog posts on a specific topic.\n    submitted by    /u/sovit-123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7zk6b/p_a_simple_pytorch_yolov1_training_pipeline/",
          "publishedOn": "2022-04-20T15:49:55.000Z",
          "wordCount": 129,
          "title": "[P] A simple PyTorch YOLOv1 training pipeline GitHub Repo",
          "imageUrl": "https://external-preview.redd.it/_tmBGnq2RgJMCfrjhyHRWMVZ-yQ4zKGtsrSygsf0RX0.jpg?auto=webp&s=c66f31cb030075cd628cffacdd4b9d9bc1e70811"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7zg4j/p_programmatic_powerful_weak_labeling/",
          "author": null,
          "description": "Hi all!,\n Really excited to share a project we've been working on and get your feedback!\n We've made:\n Programmatic — an NLP annotation tool for building large labeled datasets for NLP without manual annotation\n Programmatic is like a REPL for data annotation. You:\n 1. Write simple rules/functions that can approximately label the data 2. Get near-instant feedback across your entire corpus 3. Iterate and improve your rules \n Finally, it uses a Bayesian label model [1] to convert these noisy annotations into a single, large, clean dataset, which you can then use for training machine learning models. You can programmatically label millions of datapoints in the time taken to hand-label hundreds.\n What we do differently from weak supervision packages like Snorkel/skweak[1] is to focus on UI to …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7zg4j/p_programmatic_powerful_weak_labeling/",
          "publishedOn": "2022-04-20T15:44:39.000Z",
          "wordCount": 491,
          "title": "[P] Programmatic: Powerful Weak Labeling",
          "imageUrl": "https://external-preview.redd.it/GFDoi96pReIx0d8Fiy4PC2UbdyHgPny9UVn-tUk7wis.jpg?auto=webp&s=163ac63d5a3613bd9f1aa490b94745f5cc5b1e0e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7wwzb/d_whats_your_opinion_on_project_promoting_posts/",
          "author": null,
          "description": "There are many projects promoting in this sub, you may like or dislike. And if any of my posts you dislike, allow me to apologize first.\n However, it gets me to think. Several years ago I'm a moderator in a quite large forum, because I don't have enough time to fulfill my responsibilities, then I decided to retire (yes, they can, and I remained as the vip user which only retired moderators can be).\n This is a large community, a machine learning community. Besides continuously removing some of these posts, and no clear rules on it, can we do any better? We got all the data, and we just cannot train the model?\n Here are my three proposal, and please give some excellent ideas besides my poor ones:\n  \nSelf promoting post should have values other than itself, and not having annoying contents\n Self promoting project can be used as a tool in a non self promoting posts, as long as the posts creates valuable contents and the promoting is not obvious and annoying.\n Depends on the number of new project posts, Weekly/Daily project post can be created by moderator and pinned to the top. All the promoting content goes into the comment. We can explore and upvotes.\n  \nHere are some illustrations:\n 1. Direct Promoting Post\n ​\n 2. Indirect Promoting Post\n ​\n Weekly/Daily Promoting Post by Moderator, Pinned to Top, Comments by project owner, upvotes/downvotes by us\n Which do you think is acceptable? Or you have better ideas? Leave a comment.\n It's a machine learning sub, don't make machine to solve it better than us.\n View Poll\n    submitted by    /u/Remote_Cancel_7977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7wwzb/d_whats_your_opinion_on_project_promoting_posts/",
          "publishedOn": "2022-04-20T13:47:15.000Z",
          "wordCount": 950,
          "title": "[D] What's your opinion on project promoting posts in this sub? Your vote matters.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7v4iu/r_differentiable_signal_processing_for_optical/",
          "author": null,
          "description": "Hey folks, I wrote a mini project based on JAX for optical communications signal processing.\n https://github.com/remifan/commplax\n I have a research article as a use case demo, https://remifan.github.io/gdbp_study/article.html\n This tool essentially\n  \nimplements adaptive DSP equalizers as stateful NN layers (thanks to Jax's explicit stateful syntax)\n implements compositor interfaces from scratch to wrap up those stateful layers with other regular NN layers so that they can be trained together\n  \nHomebrew serial compositions of stateful layers\n It is a fun project for me and I feel JAX really elegantly fits this research use.\n What do you think about JAX? I appreciate your comments:)\n    submitted by    /u/StreetPrice1909  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7v4iu/r_differentiable_signal_processing_for_optical/",
          "publishedOn": "2022-04-20T12:15:05.000Z",
          "wordCount": 233,
          "title": "[R] Differentiable signal processing for optical communication with Google JAX",
          "imageUrl": "https://external-preview.redd.it/9ZhPHXfgJjjlJ72bMygmapK0gLw3qM9dI3oQKZlJiQk.jpg?auto=webp&s=3ca68f429cce7dee640074e9426a171a068e8fbd"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7tg1w/d_tracking_the_hardware_usage_while_running_cv_nn/",
          "author": null,
          "description": "Hi guys,\n I've been working on a machine learning project and I wanted to see how hardware resources are being used when I run inference on let's say 1000 images.\n How could i calculate the CPU(running inference on CPU)/RAM workload in that timeframe?\n I'm running it on a Linux Ubuntu VM. Thanks in advance!\n    submitted by    /u/Fifi0912  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7tg1w/d_tracking_the_hardware_usage_while_running_cv_nn/",
          "publishedOn": "2022-04-20T10:33:29.000Z",
          "wordCount": 283,
          "title": "[D] Tracking the hardware usage while running CV NN Model on a 1000 Images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7t77t/d_running_interactive_python_notebooks_on/",
          "author": null,
          "description": "I'm working on a framework Mercury for converting Python notebooks into interactive web apps. It can add widgets to the notebook based on the YAML configuration. End-user can tweak widgets values and execute the notebook. The resulting notebook can be downloaded as single-file HTML. Simple.\n The framework is built on Django+React. It is easy to deploy to Heroku or other cloud services. Recently, I made it possible to deploy it to Hugging Face Spaces (faster and larger machines than on free tier Heroku). \n The process of deployment is simple. You need to create a Gradio app on Spaces (my framework is not supported, yet ;) ). You need to add the app.py file that will run the Mercury server and upload the notebook. You can check the details in the docs.\n The HF Space with example notebook https://huggingface.co/spaces/pplonski/deploy-mercury\n    submitted by    /u/pp314159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7t77t/d_running_interactive_python_notebooks_on/",
          "publishedOn": "2022-04-20T10:16:31.000Z",
          "wordCount": 311,
          "title": "[D] Running interactive Python notebooks on HuggingFace Spaces",
          "imageUrl": "https://external-preview.redd.it/M97KEWVCpGCqVfMbFnyOXZVJO2e0a-jjDS-S5qdz-nw.jpg?auto=webp&s=d7872007d9a4fd0ddc5f39200478e36ad824b5ad"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7rmnx/d_conditional_gan_with_multiple_adversarial/",
          "author": null,
          "description": "I would like to test the architecture from the following paper with a different dataset:\n https://www.mdpi.com/2072-4292/13/19/3834\n The authors state that their objective function is the following:\n https://preview.redd.it/u78f27jb6nu81.png?width=1027&format=png&auto=webp&s=32790a67ec829a1e79b252edd0714b8b3b5a7f4e\n Where:\n -x is the real grayscale image.\n -s is its downsampled version, which should be used both as the initial imput of the generator performing the super-resolution and as a first conditional variable in the learning process.\n -e is another two-dimensional array containing values for a second additional conditional variable.\n The authors, however, state that this should be implemented by using two separate conditional adversarial losses, one for each of the conditional variables. To clarify, the first adversarial loss should be:\n AdvLoss1(ParametersG, ParametersD) = - Log(Discriminator(x,s) - Log(1-Discriminator(Generator(s),s)\n While the second would be:\n AdvLoss2(ParametersG, ParametersD) = - Log(Discriminator(x,e) - Log(1-Discriminator(Generator(s),e)\n Which should be then summed up for the backward pass.\n In my pytorch implementation, however, I have only been able to set up a unique adversarial loss, which could be defined as:\n CurrentAdvLoss(ParametersG, ParametersD) = - Log(Discriminator(x,(s,e)) - Log(1-Discriminator(Generator(s),(s,e)) I have tried to implement implemented as follows:(simplified version)\n which I calculate in the following training loop (simplified version, from the same question asked in the Pytorch forum) as errD and errG after conditioning the network on both s and e at the same time:\n https://discuss.pytorch.org/t/conditional-gan-with-multiple-adversarial-losses/149627\n My question is, is there a way to modify the following loop to obtain outputs that have been separately conditioned only first on s and then on e and thus calculate the two separate adversarial losses originally proposed by the authors instead?\n    submitted by    /u/Franken91  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7rmnx/d_conditional_gan_with_multiple_adversarial/",
          "publishedOn": "2022-04-20T08:20:03.000Z",
          "wordCount": 612,
          "title": "[D] Conditional GAN with multiple adversarial losses - Implementation?",
          "imageUrl": "https://external-preview.redd.it/MqJe59opigVaZuH5510R_Lq1xz5Xd-koErAoYaWVdKo.jpg?auto=webp&s=a49162b5148b40b289698f2f643412d4aa14c19c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7qdum/d_ijcai_2022_paper_notification/",
          "author": null,
          "description": "This is the discussion for accepted/rejected papers in IJCAI 2022. Results are supposed to release today.\n    submitted by    /u/errohan400  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7qdum/d_ijcai_2022_paper_notification/",
          "publishedOn": "2022-04-20T06:50:03.000Z",
          "wordCount": 431,
          "title": "[D] IJCAI 2022 Paper Notification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7ouxh/r_authors_claim_to_have_solved_mnist_and_cifar/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2204.07953v1\n Code: https://github.com/decurtoydiaz/learning_with_signatures\n Tangential resources of interest: https://arxiv.org/abs/1905.08494, https://en.wikipedia.org/wiki/Rough_path#Signature, and https://labelerrors.com/ \n Personally, I believe from their code on Github, they have a possible data leakage (in the same vein of the current issue raised there) as well as an accuracy of 100% on a test set is fishier than a fish market. However, I am very curious to hear from the court of public opinion. How is everyone feeling about this?\n    submitted by    /u/blingblingbeepbeep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7ouxh/r_authors_claim_to_have_solved_mnist_and_cifar/",
          "publishedOn": "2022-04-20T05:05:50.000Z",
          "wordCount": 1128,
          "title": "[R] Authors Claim to Have \"Solved\" MNIST and CIFAR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7on82/d_how_do_i_evaluate_if_my_data_represent_the/",
          "author": null,
          "description": "I have a dataset of points cloud where each point in the point cloud has a variable. I am trying to relate the local geometry features to that point variable by using FPFH, This means I am generating my own features from the dataset by first using an area of n-points to compute normal-vector estimations and from x normal vector estimations to compute the FPFH. However, the numbers x and n are arbitrary and other combinations might describe the target variable better. So I wanted to know if there was a method to evaluate how good a given x and n value are at describing the target variable. I considered the correlation between the features (n,x) and the target variable but I read that this assumes linear combination redundancy. I am using scikit-learn. \n So basically I have features X(x,n) and a target variable Y. Which x and n, in the feature space X(x,n), describes the target variable, Y, best.\n I want to do it before the training because when I try to train it with my random forest regressor it takes 3-4 hours and I want to test for more combinations. \n    submitted by    /u/Neo-Rushdian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7on82/d_how_do_i_evaluate_if_my_data_represent_the/",
          "publishedOn": "2022-04-20T04:52:37.000Z",
          "wordCount": 324,
          "title": "[D] How do I evaluate if my data represent the target variable before training a machine learning algorithm?",
          "imageUrl": "https://external-preview.redd.it/o-Yq16CmbZYLfCx_y5VsD5fcOiaoLcN-zQO1j3qX2es.jpg?auto=webp&s=546795834d06ed5ac69b13898f1acf1fe4d9f163"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7muzp/discussion_training_performance_evaluation_of/",
          "author": null,
          "description": "The article is reproduced from Zhihu, using deepl machine translation, for all enthusiasts to communicate\n Abstract\n Deep learning frameworks are the engines and motors for pushing the boundaries of artificial intelligence applications, and good deep learning frameworks can dramatically shorten the cycle of algorithm innovation and validation. In this report, we focus on the newly launched MindSpore framework, which has received a lot of industry attention, and systematically explore its model training speed on GPU clusters and compare it with popular international frameworks. In the evaluation experiments, we choose two classical models, ResNet and BERT-base, to test and analyze their performance with the same algorithm, the same dataset, and the same or similar performance hardware platf…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7muzp/discussion_training_performance_evaluation_of/",
          "publishedOn": "2022-04-20T03:10:29.000Z",
          "wordCount": 2118,
          "title": "[Discussion] Training performance evaluation of MindSpore, a home-grown deep learning framework -- by ADSL Lab, CSU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7lv35/d_why_is_the_diffution_model_so_powerful_but_the/",
          "author": null,
          "description": "You can see the 200 lines code here: https://nn.labml.ai/diffusion/ddpm/index.html and https://github.com/cloneofsimo/minDiffusion, math is here: https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\n The algo is smart and simple, but it's generation result seems more incredible than GANs, and its speed is fast, the model size is not too big: https://openai.com/dall-e-2/ , https://huggingface.co/spaces/multimodalart/latentdiffusion, https://www.reddit.com/r/dalle2\n So 1st question:\n why is diffusion model so powerful? Can someone explain it?\n 2st question:\n Has anyone used diffusion for NLP?\n ​\n UPDATED:\n ​\n \\\"A multiverse portal to a new world opening up above Tokyo\\\" by dalle2 (from r/dalle2)\n \\\"A robot painting on a canvas while playing the piano\\\" by dalle2 (from r/dalle2)\n ​\n \\\"Mona Lisa in her studio painting Leonardo da Vinci \\\" by dalle2 (from r/dalle2)\n \\\"Science fiction illustration future city in the night | impressionism\\\" by latentdiffusion\n ​\n \\\"Science fiction illustration of Beauty and monsters | impressionism\\\" by latentdiffusion\n ​\n \\\"a painting of a girl with a fox sitting in a field at sunrise in the style of Claude Monet\\\" by latentdiffusion\n    submitted by    /u/ghosthamlet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7lv35/d_why_is_the_diffution_model_so_powerful_but_the/",
          "publishedOn": "2022-04-20T02:17:28.000Z",
          "wordCount": 1175,
          "title": "[D] Why is the diffution model so powerful? but the math behind it is so simple.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7k4ep/d_questions_about_intel_12th_gen_alder_lake_cpus/",
          "author": null,
          "description": "I am looking to build a new PC but have struggled to find the info on how Intel's latest CPUs perform for data science/ML, so if anyone is using one for that purpose and can help with one or more of these questions it would be very helpful! Apologies if these questions should be directed elsewhere.\n  \nI am planning to use WSL2/Ubuntu but have heard that Intel's thread director isn't implemented well yet in Linux (or Windows 10!), so it doesn't assign tasks properly. Has anyone experienced issues with this firsthand?\n Assuming the thread director is working, are the e-cores utilised at all in any typical DS workflows? E.g. will they get used with joblib or when training scikit-learn/gbms in parallel? \n Are the e-cores good enough to handle other stuff like web browsing etc whilst the p-cores are maxed out on model training, or is it still necessary to keep at least one p-core free to avoid crashing the PC? Also I have read that in Windows 11 (where the thread director works best) that the active window/tab could be assigned p-cores as a priority, which isn't very helpful for someone who needs to train models in the background etc, but not sure whether this is actually happening in practice.\n  \nThe consensus from benchmarks/reviews is that the hybrid architecture 'just works' and is superior to AMD right now, but those benchmarks are primarily for use in gaming/video editing.\n    submitted by    /u/FightingLikeBeavers  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7k4ep/d_questions_about_intel_12th_gen_alder_lake_cpus/",
          "publishedOn": "2022-04-20T00:47:14.000Z",
          "wordCount": 389,
          "title": "[D] Questions about Intel 12th gen Alder Lake CPUs",
          "imageUrl": "https://external-preview.redd.it/7TWFtlKU72UhlGB3uy0ukjZZSfE8tbJ5RJ9qCdnnPeo.jpg?auto=webp&s=4e7e0b5b65ce1b4a6004ce768385543567aa0845"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7jniv/n_the_new_machine_learning_specialization_by/",
          "author": null,
          "description": "We’re thrilled to announce a brand new Machine Learning Specialization, in collaboration with DeepLearning.AI, launching in June on Coursera! Learn essential real-world skills from AI pioneer Andrew Ng, who co-founded Google Brain and Coursera, led AI research at Baidu, and has impacted millions of AI learners.\n This updated 3-course Specialization will cover the latest machine learning techniques as well as foundational AI concepts that made its predecessor one of the world’s most popular machine learning courses. Join the waitlist!\n https://preview.redd.it/yujr31t6vku81.png?width=5000&format=png&auto=webp&s=0f4c4ef090bcdc7cfb04ee2c817d766f23c236a6\n    submitted by    /u/Stanford_Online  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7jniv/n_the_new_machine_learning_specialization_by/",
          "publishedOn": "2022-04-20T00:22:42.000Z",
          "wordCount": 203,
          "title": "[N] The new Machine Learning Specialization by DeepLearning.AI and Stanford Online is launching soon! Join the Waitlist.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7ii1j/d_resources_for_images_anomaly_detection/",
          "author": null,
          "description": "Hello all, I know that there is a lot going on this field. I would like to get started on it, study more.. And as always, I like to start from the basis.\n Do you have any resource (video, article, book) good to star with?\n I know there are Autoencoders and Statistical models.. But how to know more, where/how do you keep studying?\n    submitted by    /u/bollolo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7ii1j/d_resources_for_images_anomaly_detection/",
          "publishedOn": "2022-04-19T23:24:37.000Z",
          "wordCount": 153,
          "title": "[D] Resources for Images Anomaly Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7ermp/r_where_can_i_find_case_studies_on_different_ml/",
          "author": null,
          "description": "I am working on my research paper and would like to find resources which show the case studies of ML projects from the beginning to the end, doesn't matter if it failed or succeeded.\n    submitted by    /u/mkonu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7ermp/r_where_can_i_find_case_studies_on_different_ml/",
          "publishedOn": "2022-04-19T20:32:16.000Z",
          "wordCount": 141,
          "title": "[R] Where can I find case studies on different ML projects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7ck1u/d_create_labels_for_data_created_by_a_gan/",
          "author": null,
          "description": "Hello there!\n I hope you have a great day! Currently I want to compare how good multiple GANs (Vanilla GAN, WGAN, DCGAN, ...) are for a given use case. Therefore I trained the various GAN versions with data of two different classes (i.e. apple and banana). Now I want to show that data I generate with the Generator can be used to train i.e. a classifier that can distinguish between real images of apples and bananas.\n Can I somehow create labels for the data I generate with the Generator in a smart way? So that I know that a generated image of the generator should for example be an apple? How do i do that?\n    submitted by    /u/Bonkikong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7ck1u/d_create_labels_for_data_created_by_a_gan/",
          "publishedOn": "2022-04-19T18:54:48.000Z",
          "wordCount": 324,
          "title": "[D] Create Labels for Data created by a GAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7b07r/p_luminide_new_optimization_early_ranking/",
          "author": null,
          "description": "Luminide introduces a new optimization, called Early Ranking, which makes it easier to build better AI models. Early Ranking achieves the same AI training results with up to 10x less compute – this saves time, reduces costs, and increases model accuracy.\n Luminide's IDE is a customized version of JupyterLab with integrated AI dev tools.\n Luminide used Early Ranking to place Top 1% in the CVPR Plant Pathology Kaggle competition. You can read about how we developed our winning model, and you can too, in our new blog post: Better Automation for Higher Accuracy AI Models.\n Class activation maps give insights into Luminide's winning model.\n Luminide is a new cloud platform for AI model development. Check out our demo video for a quick overview, or try it for yourself (sign up today and receive 100 hours of free GPU cloud compute).\n    submitted by    /u/LuminideInc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7b07r/p_luminide_new_optimization_early_ranking/",
          "publishedOn": "2022-04-19T17:48:05.000Z",
          "wordCount": 288,
          "title": "[P] Luminide: new optimization Early Ranking achieves higher accuracy AI models",
          "imageUrl": "https://external-preview.redd.it/YuZTfJQzgDz7AbSLKW4I5GnJY69ABvMjOQh-jD-4UDs.jpg?auto=webp&s=002ed7925b145ca7168d2ff69c0a01426eb05da0"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7a5s7/d_generic_discussion_on_freelance_ml_engineers/",
          "author": null,
          "description": "Hi, reddit. Recently, I'm looking into freelancer career path. Currently, I'm a researcher at a top company. So far, I know there is toptal, upwork, and freelancers. Checked them out, and seems toptal you still end up working for large corporate and mostly end up as full-time contractor which is not really a different or better option than my current work. Freelancers has too many bidders from developing countries. \n Besides what platform to use, i have more questions in terms of what obstacles we are facing to be freelancer ML engineer? Even though i am in AI and a researcher, but i have never deployed a model in production. Usually a task at big company takes a team or multiple teams to complete the MLOPs lifecycle, how can you do it as a single person? Any sharing of experience would be of great help.\n    submitted by    /u/meame2010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7a5s7/d_generic_discussion_on_freelance_ml_engineers/",
          "publishedOn": "2022-04-19T17:11:22.000Z",
          "wordCount": 453,
          "title": "[D] generic discussion on freelance ML engineers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u79u20/r_looking_for_aiml_experts_from_southeast_asia_to/",
          "author": null,
          "description": "Hello everyone,\n I am a student from Germany writing my master thesis on Digital Transformation in ASEAN with AI/ML.\n For my thesis I would like to interview AI/ML experts from the ASEAN region to talk about the digital development of each country, challenges and potentials. (If you are not native there, but you have a work connection or just knowledge about the region and its AI development, I appreciate that as well.)\n It would be awesome if some of you were open to talk to me. A few sentences are enough, I won't take much of your time. If you want, we can do a video call as well. I will quote you of course.\n Thank you guys.\n    submitted by    /u/BlueLagoon357  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u79u20/r_looking_for_aiml_experts_from_southeast_asia_to/",
          "publishedOn": "2022-04-19T16:57:26.000Z",
          "wordCount": 227,
          "title": "[R] Looking for AI/ML experts from Southeast Asia to interview for master thesis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u79ngl/dealing_with_numerically_0_likelihood_in/",
          "author": null,
          "description": "I'm trying to find literature on solving the following issue:\n In most probabilistic ML models, we model the joint distribution over a set of random variables, p(x1, ..., xN). If N is very large (e.g. 100, 500, or even 1000), then regardless of how you model this, the distribution's highest point of density is still quite tiny. E.g. if you consider an isotropic multivariate gaussian of 100 dimensions, the highest point of density will be somewhere in the neighbourhood of 1.6e-40. So when it comes time to evaluate log likelihood for a model like this, the probability is numerically 0, so the log probability goes to negative infinity.\n ​\n Is there work around solving these kinds of issues? I.e. by constraining the model in some way, or scaling model output, etc? I've done some googling, but am having a hard time finding papers on the subject. Not even sure what to call the problem... Curse of dimensionality in PGMs?\n ​\n Any recommendations of papers / talks / etc is greatly appreciated!\n    submitted by    /u/CS_Student95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u79ngl/dealing_with_numerically_0_likelihood_in/",
          "publishedOn": "2022-04-19T16:49:08.000Z",
          "wordCount": 348,
          "title": "Dealing with numerically 0 likelihood in probabilistic models [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u79fnw/rp_gancontrol_explicitly_controllable_gans_gradio/",
          "author": null,
          "description": "​\n https://i.redd.it/v61jw1fekiu81.gif\n Abstract:\n We present a framework for training GANs with explicit control over generated facial images. We are able to control the generated image by settings exact attributes such as age, pose, expression, etc. Most approaches for manipulating GAN-generated images achieve partial control by leveraging the latent space disentanglement properties, obtained implicitly after standard GAN training. Such methods are able to change the relative intensity of certain attributes, but not explicitly set their values. Recently proposed methods, designed for explicit control over human faces, harness morphable 3D face models (3DMM) to allow fine-grained control capabilities in GANs. Unlike these methods, our control is not constrained to 3DMM parameters and is extendable beyond the domain of human faces. Using contrastive learning, we obtain GANs with an explicitly disentangled latent space. This disentanglement is utilized to train control-encoders mapping human-interpretable inputs to suitable latent vectors, thus allowing explicit control. In the domain of human faces we demonstrate control over identity, age, pose, expression, hair color and illumination. We also demonstrate control capabilities of our framework in the domains of painted portraits and dog image generation. We demonstrate that our approach achieves state-of-the-art performance both qualitatively and quantitatively.\n    submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u79fnw/rp_gancontrol_explicitly_controllable_gans_gradio/",
          "publishedOn": "2022-04-19T16:39:32.000Z",
          "wordCount": 294,
          "title": "[R][P] GAN-Control: Explicitly Controllable GANs + Gradio Web Demo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u78vr1/d_who_funds_the_leading_conferences_in_the_field/",
          "author": null,
          "description": "I know that the publishers of the leading journals are mostly for-profit organization, that is weird because as researchers in the field we really “volunteer” for a free peer review or even pay to publish papers and read papers.\n On the other hand, i wasnt able to find information about the funding and profit goals of the leading conferences. Take NeuroIPS for example, i found that it is organized by “NeurIPS Foundation” but what exactly is this foundation - i couldn’t find any information about this subject.\n My point is, if the conferences are non-profit, sounds like they should be preferred over funding a for-profit organizations.\n    submitted by    /u/Careful_Winner_2335  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u78vr1/d_who_funds_the_leading_conferences_in_the_field/",
          "publishedOn": "2022-04-19T16:15:02.000Z",
          "wordCount": 404,
          "title": "[D] Who funds the leading conferences in the field?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7633f/d_nlp_has_huggingface_what_does_computer_vision/",
          "author": null,
          "description": "I've been writing tutorials with Pinferencia and HuggingFace.\n HuggingFace is quite handy and easy to use.\n I want to write some tutorial about computer vision afterwards.\n Is there anything similar in Computer vision area?\n    submitted by    /u/Remote_Cancel_7977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7633f/d_nlp_has_huggingface_what_does_computer_vision/",
          "publishedOn": "2022-04-19T14:10:50.000Z",
          "wordCount": 691,
          "title": "[D] NLP has HuggingFace, what does Computer Vision have?",
          "imageUrl": "https://external-preview.redd.it/kblQmsIxuQ7Z09y5LfR7cpqcqnaiQ45WZxhomGZFfu8.jpg?auto=webp&s=57dc6bc9e7a5f25991af7ad692b7aede29bede48"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u74rcr/d_why_no_paper_in_speech_emotion_recognition/",
          "author": null,
          "description": "I took a look at multiple of them and I was curious why they seemed to benchmark on multiple datasets but for the training, they restrained themselves to only 1 for training instead of merging them. From that they get good scores on the one they trained on, but bad ones for the rest.\n    submitted by    /u/raysamram  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u74rcr/d_why_no_paper_in_speech_emotion_recognition/",
          "publishedOn": "2022-04-19T13:08:01.000Z",
          "wordCount": 197,
          "title": "[D] Why no paper in Speech Emotion Recognition train on multiple datasets ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u74pyy/p_sparseserverui_a_ui_to_test_performance_of/",
          "author": null,
          "description": "You can now load multiple transformers (each model has a unique sparsification recipe) on top of the DeepSparse server behind Streamlit, and it's open-source. This was battle tested on a 16GB of RAM with only 4 core CPU virtual machine. These compute requirements are enough to load up to 19 sparse BERT models in memory and compare their performance on question answering (P.S. they are really fast on just CPUs).\n 💻code: https://github.com/neuralmagic/deepsparse/tree/main/examples/sparseserver-ui\n    submitted by    /u/Quantum_Stat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u74pyy/p_sparseserverui_a_ui_to_test_performance_of/",
          "publishedOn": "2022-04-19T13:06:00.000Z",
          "wordCount": 251,
          "title": "[P] SparseServer.UI : A UI to test performance of Sparse Transformers",
          "imageUrl": "https://external-preview.redd.it/qBy_JaPINWtgHEC1itxNsGwlzl6psCRW2NA8VNORhKE.jpg?auto=webp&s=9400b52c8e30d85bbc6050016a8942948c2d3077"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u742l5/research_learning_with_signatures/",
          "author": null,
          "description": "This paper reports \"results on AFHQ dataset, Four Shapes, MNIST and CIFAR10 achieving 100% accuracy on all tasks.\" The authors used few-shot classification \"by comparing each test sample (after optional augmentation and computation of the element-wise mean) against a representative element-wise mean signature computed by averaging the signatures of a given number of train samples.\" What are your thoughts on this?\n Learning with Signatures - https://arxiv.org/abs/2204.07953\n    submitted by    /u/Marmadelov  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u742l5/research_learning_with_signatures/",
          "publishedOn": "2022-04-19T12:32:52.000Z",
          "wordCount": 157,
          "title": "[Research] Learning with Signatures",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u70e8x/project_research_simple_speech_recognition_system/",
          "author": null,
          "description": "Github - Bangla Spoken Number Recognition\n Dataset - Our custom dataset on Bangla Numerals\n Publications - Though its on (0-9) digits\n We have created a simple speech recognition system for recognizing Bangla numerals from '০-৯৯'(0-99). In this project, audio samples from different genders, age groups, and dialects of Bangladeshi people were used to create a speech dataset of spoken numbers from '০-৯৯'(0-99). The raw speech data is subjected to various audio augmentation techniques such as time shift, speed tuning, background noise mixing, and volume tuning. Then, to extract meaningful features from the data, Mel Frequency Cepstrum Coefficients (MFCCs) are used. We have used, Convolutional Neural Networks (CNNs), to develop a Bangla number recognition system. The proposed method recognizes '০-৯৯'(0-99) Bangla spoken numbers with 89.61% accuracy across the entire dataset. The model’s effectiveness was also tested using 10-fold cross-validation, with 89.74% accuracy for recognizing '০-৯৯'(0-99) Bangla spoken numbers across the entire dataset.\n I Hope, this work will help you in some way. :)\n    submitted by    /u/PIASR0Y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u70e8x/project_research_simple_speech_recognition_system/",
          "publishedOn": "2022-04-19T08:41:54.000Z",
          "wordCount": 294,
          "title": "[Project] [Research] Simple Speech Recognition System",
          "imageUrl": "https://external-preview.redd.it/D2Tcvz3YyL2f4FekN2FGxrOWw72iTPlHKt7b5p6HyY8.jpg?auto=webp&s=a2e90c4f535af066a0dfaa93aaef7cc76d1a03b4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6zo72/p_improving_mulitclass_classification_accuracy/",
          "author": null,
          "description": "This is a light implementation of the idea in the paper Leveraging Uncertainties in Softmax Decision-Making Models for Low-Power IoT Devices. Instead of finding uncertainties I have added Jain's Fairness Index as a addition to the loss function.\n Gist: https://gist.github.com/Gananath/8d167384da7d3bc078650c73fab1a8dd\n    submitted by    /u/gananath  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6zo72/p_improving_mulitclass_classification_accuracy/",
          "publishedOn": "2022-04-19T07:49:51.000Z",
          "wordCount": 140,
          "title": "[P] Improving mulitclass classification accuracy with Jain's Fairness Index",
          "imageUrl": "https://external-preview.redd.it/B7V_1aSLjsc68OF9ZHt3PPLgcCkDV9ZXbE0SQTFou3E.jpg?auto=webp&s=f9545e492f810762324603fdcdbb88db865c92d3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6zk4g/d_are_workshop_papers_considered_final/",
          "author": null,
          "description": "Specifically, I'm talking about workshops of major conferences (NeurIPS, ICLR, ICML, etc.).\n If I submit a paper and it gets accepted, is that workshop paper a \"final publication\"? Or would most people expect the project to continue being developed into a slightly larger/longer paper for submission to the main stream of a conference? And if so, does publishing the earlier workshop paper tend to hinder or harm the later conference submission?\n I recognise there's a variety of workshops, and perhaps each have different expectations or norms. I'm wondering, from my outsider's perspective, how can I tell?\n For example, I have been thinking about submitting to one of these ICML workshops: https://icml-compbio.github.io/ or https://www.tagds.com/workshops/tag-in-machine-learning. Is there an easy way to tell whether either or both of these are \"final publication\" venues or not?\n    submitted by    /u/tfburns  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6zk4g/d_are_workshop_papers_considered_final/",
          "publishedOn": "2022-04-19T07:41:19.000Z",
          "wordCount": 484,
          "title": "[D] Are workshop papers considered \"final publications\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6uw0i/r_maximum_likelihood_estimation_can_fail_due_to/",
          "author": null,
          "description": "arXiv: https://arxiv.org/abs/2204.07172\n This paper out today seems to make the bold claim that maximum likelihood estimation is not a well-posed training objective in deep generative modelling. The manifold hypothesis says that observed high-dimensional data clusters around low-dimensional manifolds, but maximum likelihood methods (e.g. VAE, normalizing flows) learn high-dimensional densities. The paper argues that the mismatch between dimensionalities will lead to a problem called \"manifold overfitting\".\n Models are able to maximize likelihood in high-dimensions by sending the density to infinity around the low-dimensional manifold, but they can do this while completely ignoring the distribution of data on the manifold. So in other words, high capacity models will learn the data manifold…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6uw0i/r_maximum_likelihood_estimation_can_fail_due_to/",
          "publishedOn": "2022-04-19T02:56:29.000Z",
          "wordCount": 1350,
          "title": "[R] Maximum likelihood estimation can fail due to \"Manifold Overfitting\"",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6n0b0/d_word_meaning_dictionary_dataset/",
          "author": null,
          "description": "Hey all!\n So I intend to make an application that, very naively speaking, outputs synonyms of a given word regardless of context (like if word1 is \"bank\", the model should output both \"money\" and \"river\", and the order does not matter). For this, I intend to use a Doc2Vec type of classifier, where the meanings of each word can serve as a document, and then similar words can easily be returned using a cosine similarity function. I chose this over a classic Word2Vec as this will be able to predict uncommon words (which blimey the English language has a lot of) which would otherwise be processed as <UNK> tokens. To this end, I am searching for a suitable dataset. Any ideas?\n    submitted by    /u/GrammarPaparazzi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6n0b0/d_word_meaning_dictionary_dataset/",
          "publishedOn": "2022-04-18T20:42:12.000Z",
          "wordCount": 245,
          "title": "[D] Word Meaning Dictionary Dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6lx9e/d_is_there_a_way_to_use_a_series_of_videos_as_the/",
          "author": null,
          "description": "This is the problem area I am working with: \n I have a series of videos taken at different times, and each video is paired with a physical variable. The videos contain information that correlates with the physical variable. \n What we want to do is use the information encoded within each video to build a correlation model with the physical quantity, and thereafter use new videos to predict the physical quantity. \n (We want to avoid the route of video -> CNN -> extract parameters -> build model with parameters. Instead, we want to directly go from the videos to the model without separately extracting parameters.)\n So, in a way, I want to use a series of videos as a time series data set. Is there a way to do this? What should be the starting point for my research into this?\n Thanks in advance! I am not an expert with this area at all, and would greatly appreciate guidance from the community.\n    submitted by    /u/besse  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6lx9e/d_is_there_a_way_to_use_a_series_of_videos_as_the/",
          "publishedOn": "2022-04-18T19:55:27.000Z",
          "wordCount": 426,
          "title": "[D] Is there a way to use a series of videos as the predictor variable for prediction/regression?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6kroi/p_blog_post_opensource_pytorch_implementation_of/",
          "author": null,
          "description": "Hi all! My team recently reproduced and published a PyTorch implementation of the paper SIMONe: View-Invariant, Temporally-Abstracted Object Representations via Unsupervised Video Decomposition. \n Our blog post walks through the code and provides a detailed explanation of the architecture they use in order to perform object segmentation on videos in a fully self-supervised manner.\n Hope this is helpful/interesting to others!\n    submitted by    /u/ai_ellie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6kroi/p_blog_post_opensource_pytorch_implementation_of/",
          "publishedOn": "2022-04-18T19:04:20.000Z",
          "wordCount": 170,
          "title": "[P] Blog post + open-source PyTorch implementation of DeepMind's SIMONe (unsupervised scene decomposition)",
          "imageUrl": "https://external-preview.redd.it/z55b_0-_DYGZxjSO4sTVwBNIkMqkFCKvhcexHvELgV4.jpg?auto=webp&s=6b590839e21b0f0e5d45a926d1c383c41316f7fd"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6i2u6/d_autorf_vs_sinnerf/",
          "author": null,
          "description": "Both approaches seem to be able to render complex scenes from a single view, without the need for explicit priors or pretrained feature extractors. Conveniently, AutoRF doesn't mention SinNeRF. What are the similarities and differences among the two approaches? DISCLAIMER - I'm not a NeRF expert. My limited understanding of it is that we train a small MLP to regress the radiance field for a scene, i.e., to predict emitted radiance at a point (x,y,z) in the viewing direction (θ, φ). Once we have the radiance field, we can use some rendering engine to render a 2D view from the 3D field and the camera parameters.\n EDIT: I just realized that I didn't link the papers, how silly of me. Here they are:\n SinNeRF: https://arxiv.org/abs/2204.00928\n AutoRF: https://arxiv.org/abs/2204.03593\n ​\n ​\n    submitted by    /u/Best-Neat-9439  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6i2u6/d_autorf_vs_sinnerf/",
          "publishedOn": "2022-04-18T17:07:21.000Z",
          "wordCount": 416,
          "title": "[D] AutoRF vs SinNeRF",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6htt9/p_evaluating_automatic_paraphrasing_via_bleu/",
          "author": null,
          "description": "Hey everyone!\n Our NLP team, led by our expert Daria, has recently released a new AI-based paraphrasing feature – Linguix Paraphraser 2.0.\n To measure its quality, we use four important metrics: BLEU, Jaccard similarity index, LaBSE and Perplexity.\n Performance stats:\n  \nBLEU, which is used for measuring the quality of machine translation. The lower it is for rephrase task, the better. Right now, Linguix Paraphraser 2.0 has the BLEU metric of 0.47 (previous iteration had 0.65). So, we can say that our paraphraser is now smarter, it uses more words to rewrite the sentence, but the overall idea of the content is still preserved.\n Jaccard similarity index is used to measure the likeness of x and y objects. The same as with BLEU, the lower the index for the task, the better. Our current metric is 0.45 compared to 0.51 for the previous iteration.\n LaBSE metric is used to measure the semantic similarity of two sentences. It translates text into vectors so that vectors of texts close in meaning are geometrically close to each other. The higher the metric, the better. The new model has LaBSE similarity slightly less than the previous model: 0.80 vs 0.93, which is normal and correct, because the model generates a variety of variants using other words, but keeping the meaning of the source text in the target.\n Perplexity is used to ensure the rewritten content sounds natural (lower perplexity is better). The naturalness of the rewrites generated by our new paraphraser is much better than before: 0.26 vs 4.99 for the prior version.\n  \n​\n https://i.redd.it/iaaf7o2iibu81.gif\n As such, for Linguix Paraphraser 2.0 we were able to improve the quality of the rephrased content, while keeping the text meaning at the same level.\n P.S. Daria is somewhat shy, so I asked her to share the update here on her behalf.\n Anyway she'll be pleased to see some feedback!\n    submitted by    /u/alexlash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6htt9/p_evaluating_automatic_paraphrasing_via_bleu/",
          "publishedOn": "2022-04-18T16:56:01.000Z",
          "wordCount": 436,
          "title": "[P] Evaluating automatic paraphrasing via BLEU, LaBSE, Perplexity and Jaccard similarity index - how we do it for Linguix Paraphraser 2.0",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6hjhv/r_p_slideflow_a_deep_learning_framework_for/",
          "author": null,
          "description": "Hi all - I'm an applied ML researcher working in an oncology research lab at U Chicago, using digital slides of patient's tumors for tumor classification, prognostication, and treatment response prediction. I'm really excited to share with the community the deep learning tools we've been using, and I'm hoping for any feedback you might have (or direction if you think there's a community or subreddit this might be better suited for).\n After years of development, we've released our open-source deep learning framework for digital histology, Slideflow (https://github.com/jamesdolezal/slideflow). It has flexible and highly optimized whole-slide image processing, support for a wide variety of existing and custom architectures (with continuous, categorical, or time-series outcomes), real-time digital stain normalization, a number of explainability tools, and integrated uncertainty quantification. It's compatible with both Tensorflow and PyTorch, available on PyPI and DockerHub, and comes with good documentation (https://slideflow.dev/). We've tried out a number of alternative frameworks over the years, and I think the ease of use, flexibility, and performance optimizations set it apart from other repos you'll find on GitHub.\n We have a handful of local collaborators who are using Slideflow, but I'm hoping to expand our reach and find people in similar fields who are interested in collaborating for ongoing open-source development. I've tried looked for subs relating specifically to computational pathology / digital histology, and haven't found a good community yet - anyone have ideas for how to get connected with like-minded people working in the same field?\n    submitted by    /u/shawarma_bees  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6hjhv/r_p_slideflow_a_deep_learning_framework_for/",
          "publishedOn": "2022-04-18T16:43:07.000Z",
          "wordCount": 458,
          "title": "[R] [P] Slideflow: a deep learning framework for digital histology",
          "imageUrl": "https://external-preview.redd.it/PHZ7hJGxW1Q9Cc6dza79JuKQpcmayN9OU18gE0-IIFg.jpg?auto=webp&s=9f307d446e5b8e380d20ac82147e68556cd790d3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6fno2/d_anyone_using_named_tensors_or_a_tensor/",
          "author": null,
          "description": "It seems like there have been some options out for a while now - e.g. native pytorch named tensors, tsalib, torchtyping - yet I haven't really seen them discussed or used in any code I've come across. Just wondering if anyone has surveyed them recently and is using them. In particular tsalib's warp string syntax for transformations looks really interesting.\n    submitted by    /u/patniemeyer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6fno2/d_anyone_using_named_tensors_or_a_tensor/",
          "publishedOn": "2022-04-18T15:20:44.000Z",
          "wordCount": 299,
          "title": "[D] Anyone using named tensors or a tensor annotation lib productively?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6fgmh/d_are_there_any_analog_ai_computing_chips_on_the/",
          "author": null,
          "description": "If so, where to buy them?\n (for example: I red that mythic has been collecting funding in mid-2021, but I dont know if they are for sale anywhere).\n    submitted by    /u/GerritTheBerrit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6fgmh/d_are_there_any_analog_ai_computing_chips_on_the/",
          "publishedOn": "2022-04-18T15:12:02.000Z",
          "wordCount": 720,
          "title": "[D] Are there any analog A.I. computing chips on the retail market yet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6e7cd/nrp_high_fidelity_3d_face_reconstruction_from/",
          "author": null,
          "description": "FaceNext is an open source PyTorch library for high fidelity 3D face reconstruction from single/multiple RGB image(s).\n github.com/abdallahdib/NextFace\n ​\n https://reddit.com/link/u6e7cd/video/ixg0wlzirau81/player\n    submitted by    /u/Abd_dib  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6e7cd/nrp_high_fidelity_3d_face_reconstruction_from/",
          "publishedOn": "2022-04-18T14:16:19.000Z",
          "wordCount": 123,
          "title": "[N][R][P] High fidelity 3D face reconstruction from monocular image",
          "imageUrl": "https://external-preview.redd.it/qeKyK3SzjAYVrfrVdpHe6K6biV64I-gNh5p-TiYqhmg.jpg?auto=webp&s=f4d51ba54b0e2c7db1938ce8891b50f96700b08f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6cjwx/d_which_keywords_describe_my_task/",
          "author": null,
          "description": "Hey all, I have received a task in an area I am unfamiliar with and need a little help finding suitable papers, so I am looking for keywords.\n To illustrate the goal, let's say you have 10000 screws (which can be of the same model) and you want to be able to recognize/match each one. You want new screws to be added all the time, so you also want the case that the object could previously be unknown when performing the match.\n The goal is to develop a capturing system that produces suitable images and to find an architecture/algorithm that is as robust as possible. The object images should be invariant to illumination, rotation and translation during acquisition.\n It should be a kind of barcode/hash without any additional symbol, based only on the structure of the object.\n Is there a name for such a task? I think it is not really a classification in the classical sense. I guess it might be just a clever way of finding suitable features for each individual object structure and suitable distance function.\n Sorry for the long post, I appreciate any help.\n    submitted by    /u/Temporary_Lab769  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6cjwx/d_which_keywords_describe_my_task/",
          "publishedOn": "2022-04-18T12:58:51.000Z",
          "wordCount": 286,
          "title": "[D] Which keywords describe my task?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6ba4t/d_including_outer_objects_in_rnn_cnn/",
          "author": null,
          "description": "Hello there, Which layer or structure would you append to existing machine learning architectures like yolov5 in order to not only detect the specific object, but also the object which it is part of? Lets say there are xray images of laptops: The laptop itself will be detected and also something like the hard drive or battery inside of it. Is it possible to make the CNN/RNN aware of the fact that the hard drive or battery is inside the Laptop?\n Hope someone can tell what i mean. Regards David\n    submitted by    /u/rohrivibes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6ba4t/d_including_outer_objects_in_rnn_cnn/",
          "publishedOn": "2022-04-18T11:51:04.000Z",
          "wordCount": 343,
          "title": "[D] Including outer objects in RNN / CNN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u69zcf/d_phd_in_knowledge_representation_and_reasoning/",
          "author": null,
          "description": "I have been offered a PhD in domain of knowledge representation and reasoning for autonomous agents. Goal is to use represent textual rules and world knowledge and then use those represented knowledge for reasoning, so that motion of autonomous agent can be predicted. \n I have question regarding the current landscape of knowledge representation and reasoning. I see more and more work in data focused model and old Logic and associated paths fading out. Phd project problem itself looks interesting as it focus on work where there will be less need of data and can plan motion in unseen scenarios. But I am concerned about the future career prospective in this domain where this problem is tackled by knowledge representation and reasoning. As I can see there is less and less funding in this domain. \n What is your take on future landscape of research direction in this domain?\n    submitted by    /u/human_treadstone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u69zcf/d_phd_in_knowledge_representation_and_reasoning/",
          "publishedOn": "2022-04-18T10:32:05.000Z",
          "wordCount": 734,
          "title": "[D] PhD in knowledge representation and reasoning for autonomous agent: research landscape",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u69r78/p_my_blog_on_ml_model_evaluation_bayes_optimal/",
          "author": null,
          "description": "I have published 3 articles about ML model evaluation on my personal blog. Just finished the 3 installment, so I am keen to share and get some feedback.\n I cover frameworks traditionally used in ML like ROC curves, but from a Bayes decision perspective, which I have been struggling to find in textbooks/tutorials. The 3rd part is about the evaluation of log-likelihood calibrated models.\n Hope you will find it interesting/useful!\n https://mkffl.github.io/2021/10/18/Decisions-Part-1.html\n https://mkffl.github.io/2021/10/28/Decisions-Part-2.html\n https://mkffl.github.io/2022/03/02/Decisions-Part-3.html\n And the underlying code for reproducibility https://github.com/mkffl/decisions\n    submitted by    /u/mkffl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u69r78/p_my_blog_on_ml_model_evaluation_bayes_optimal/",
          "publishedOn": "2022-04-18T10:17:22.000Z",
          "wordCount": 279,
          "title": "[P] My blog on ML model evaluation (Bayes optimal decisions, ROC curve, LLR calibration)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u68ht2/p_ormb_docker_for_your_models_help_you_manage/",
          "author": null,
          "description": "github.com/kleveross/ormb\n ormb helps you manage your Machine Learning/Deep Learning models with docker container image registry. It makes your models easy to create, version, share and publish.\n ```\n Save the model in local cache first\n $ ormb save gaocegege/fashion_model:v1 ref: gaocegege/fashion_model:v1 digest: 6b08cd25d01f71a09c1eb852b3a696ee2806abc749628de28a71b507f9eab996 size: 162.1 KiB format: SavedModel v1: saved\n Push the model from local cache to remote registry\n $ ormb push gaocegege/fashion_model:v1 The push refers to repository [gaocegege/fashion_model] ref: gaocegege/fashion_model:v1 digest: 6b08cd25d01f71a09c1eb852b3a696ee2806abc749628de28a71b507f9eab996 size: 162.1 KiB format: SavedModel v1: pushed to remote (1 layer, 162.1 KiB total)\n Pull the model from remote registry to local cache\n $ ormb pull gaocegege/fashion_model:v1 v1: Pulling from gaocegege/fashion_model ref: gaocegege/fashion_model:v1 digest: 6b08cd25d01f71a09c1eb852b3a696ee2806abc749628de28a71b507f9eab996 size: 162.1 KiB Status: Downloaded newer model for gaocegege/fashion_model:v1\n Export the model from local cache to current directory\n $ ormb export gaocegege/fashion_model:v1 ref: localhost/gaocegege/fashion_model:v1 digest: 6b08cd25d01f71a09c1eb852b3a696ee2806abc749628de28a71b507f9eab996 size: 162.1 KiB\n View the local file directory\n $ tree examples/SavedModel-fashion examples/SavedModel-fashion ├── model │ ├── saved_model.pb │ └── variables │ ├── variables.data-00000-of-00001 │ └── variables.index ├── ormbfile.yaml └── training-serving.ipynb\n 2 directories, 5 files ```\n    submitted by    /u/gaocegege  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u68ht2/p_ormb_docker_for_your_models_help_you_manage/",
          "publishedOn": "2022-04-18T08:50:26.000Z",
          "wordCount": 294,
          "title": "[P] ormb: Docker for Your Models, Help You Manage Models Better",
          "imageUrl": "https://external-preview.redd.it/cazibvRm6uWO9h9ZcY__9DfngesMXThv4k9MD4oUHUw.jpg?auto=webp&s=a0e5f43cfdbe3dffbde7aa76ab83baa2dd261513"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u65rm2/d_deep_generative_model_with_hierarchical_latent/",
          "author": null,
          "description": "Hi, I have just published my latest medium article.\n Anomalies are widespread when it comes to working on data. They become vital in time series. So, It is crucial to propose efficient methods to detect and deal with them. This article illustrates a state-of-the-art model called DGHL for anomaly detection. DGHL includes a ConvNet as a Generator and instead of encoding it maximizes the likelihood with the Alternating Back-Propagation algorithms.\n https://rezayazdanfar.medium.com/deep-generative-model-with-hierarchical-latent-factors-for-time-series-anomaly-detection-8d6eaebad8bc\n    submitted by    /u/rezayazdanfar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u65rm2/d_deep_generative_model_with_hierarchical_latent/",
          "publishedOn": "2022-04-18T05:38:44.000Z",
          "wordCount": 182,
          "title": "[D] Deep Generative model with Hierarchical Latent Factors for Time Series Anomaly Detection",
          "imageUrl": "https://external-preview.redd.it/l6cHO0qcu69cDLkZ1vFOVFg3X9OpquaHcfVYWFPlHuE.jpg?auto=webp&s=d5862b4a74cfaa76bb21ab7ec78264e280d14fd4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u64dx0/p_app_to_play_with_latent_diffusion_models/",
          "author": null,
          "description": "just published “geni”, a new minimal app that uses Latent Diffusion Models. It will not produce DALL-E-ish results but it’s fast and great for playing with prompt engineering. Also, it’s free.\n would love to have the community playing with it. \n check it out here: https://geni.vercel.app\n    submitted by    /u/viccpopa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u64dx0/p_app_to_play_with_latent_diffusion_models/",
          "publishedOn": "2022-04-18T04:11:45.000Z",
          "wordCount": 340,
          "title": "[P] app to play with latent diffusion models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u64aqf/r_vqflows_vector_quantized_local_normalizing_flows/",
          "author": null,
          "description": "arXiV: https://arxiv.org/abs/2203.11556 \n  \n Summary:\n We introduce a novel statistical framework for learning a mixture of local normalizing flows as \"chart maps\" over the data manifold. Our framework augments the expressivity of recent approaches while preserving the signature property of normalizing flows, that they admit exact density evaluation. We learn a suitable atlas of charts for the data manifold via a vector quantized auto-encoder (VQ-AE) and the distributions over them using a conditional flow. We validate experimentally that our probabilistic framework enables existing approaches to better model data distributions over complex manifolds.​ \n  \n GitHub: Coming Soon\n Author here, happy to answer any questions.\n    submitted by    /u/tshrjn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u64aqf/r_vqflows_vector_quantized_local_normalizing_flows/",
          "publishedOn": "2022-04-18T04:06:24.000Z",
          "wordCount": 230,
          "title": "[R] VQ-Flows: Vector Quantized Local Normalizing Flows",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5zf55/rp_mask_transfiner_for_highquality_instance/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5zf55/rp_mask_transfiner_for_highquality_instance/",
          "publishedOn": "2022-04-17T23:44:23.000Z",
          "wordCount": 108,
          "title": "[R][P] Mask Transfiner for High-Quality Instance Segmentation + Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/ptS9-9koOmSM--fTSpEmdCnVu8PM69uNHhZS8pegZtI.png?format=pjpg&auto=webp&s=2d21ba5f6a86442578a976d00d6f7bcc0355cba4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5yr54/p_spoonfy_turn_any_foreignlanguage_video_into/",
          "author": null,
          "description": "Video (Despacito, slightly NSFW): https://drive.google.com/file/d/12qYKv_yaqGr9GWvHPtE9ng2foJVPfpoE/view?usp=sharing \n Code & more info: https://github.com/athairus/SpoonfyDemo\n Discord: https://discord.gg/7wcZZzeSQk \n Spoonfy is essentially the so-called Telenovela method (learning languages through subtitled video) on steroids: This demo uses a finetuned Facebook's M2M100 model to translate Spanish to English (finetuned to do literal translation instead of ordinary translation) and a wav2vec2 model to get Spanish word timings to present the literal (aka word-by-word) translations as karaoke-style lyrics.\n What sets Spoonfy apart from other solutions is the way it leverages the massive body of existing subtitled content out there to create learning material. Also because it's FOSS. More details in the code's README.\n I've been working on this project by myself for a few months now, I hope you see potential behind it like I do! If so (but also if not), I'd love to hear what you think. And I'd love to get your help improving on what I already built. I have plenty of ideas for how to make the translations even more accurate, the system more robust & able to handle more sources of content (YouTube, TikTok, Blu-Rays), etc. \n Thanks for checking it out!\n    submitted by    /u/athairus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5yr54/p_spoonfy_turn_any_foreignlanguage_video_into/",
          "publishedOn": "2022-04-17T23:09:45.000Z",
          "wordCount": 284,
          "title": "[P] Spoonfy: Turn any foreign-language video into effective listening practice",
          "imageUrl": "https://external-preview.redd.it/0LZxIVMqdGjUepA9SIidVG8R56GvjOL5MHPxA9nr6g0.jpg?auto=webp&s=274ed783ab24d867a68f54ca0b39ef3e2825fc06"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5xsb1/d_current_work_on_knowledge_representation_with/",
          "author": null,
          "description": "In robotics and autonomous systems, knowledge representation is an important aspect. What is your favorite methods for knowledge representation, is it Formal logic or graphs or whatever and why you like that kind of representation. Considering the success of large language model isn't it a good time to use them in new kind of representation, so that robots or similar system can make better decisions in an environment. I still feel there is no common consensus in community for correct way of knowledge representation, correct me If I am wrong.\n    submitted by    /u/projekt_treadstone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5xsb1/d_current_work_on_knowledge_representation_with/",
          "publishedOn": "2022-04-17T22:22:01.000Z",
          "wordCount": 206,
          "title": "[D] Current work on knowledge representation with your preference, and use of language models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5xk6s/d_dalle_2_vs_disco_diffusion_showdown/",
          "author": null,
          "description": "submitted by    /u/nin_artificial  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5xk6s/d_dalle_2_vs_disco_diffusion_showdown/",
          "publishedOn": "2022-04-17T22:11:02.000Z",
          "wordCount": 209,
          "title": "[D] DALL-E 2 vs Disco Diffusion - SHOWDOWN!",
          "imageUrl": "https://external-preview.redd.it/R3nMDnBMDgegOE4sQ0TGq1n-EP2ElnuOIwjR52hsJVg.jpg?auto=webp&s=69842e7a37dc4717294e2921cabb2c7c14dc6b86"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5st3t/wacv_vs_bmvc_r/",
          "author": null,
          "description": "How do they compare in terms of the communities, prestige, competitiveness, and impact. \n I have a paper accepted to a CVPR workshop and considering extending it and submitting to one of these. The work is based on explainability in medical vision. It's more methods-oriented rather than large-scale experiments. \n What are your suggestions?\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5st3t/wacv_vs_bmvc_r/",
          "publishedOn": "2022-04-17T18:16:09.000Z",
          "wordCount": 176,
          "title": "WACV vs. BMVC [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5rnss/n_p_access_100_image_video_audio_datasets_in/",
          "author": null,
          "description": "submitted by    /u/davidbun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5rnss/n_p_access_100_image_video_audio_datasets_in/",
          "publishedOn": "2022-04-17T17:20:34.000Z",
          "wordCount": 1373,
          "title": "[N] [P] Access 100+ image, video & audio datasets in seconds with one line of code & stream them while training ML models with Activeloop Hub (more at docs.activeloop.ai, description & links in the comments below)",
          "imageUrl": "https://external-preview.redd.it/MZrztB7vuApjv22WUfP9K0u0BToEvLP488cAz_DB62w.png?format=pjpg&auto=webp&s=85717c78ba904404995956a0d98207ab9c4d223b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5pxvh/d_is_it_ok_to_promise_a_dataset_in_your_paper_get/",
          "author": null,
          "description": "Recently, I decided to explore NeRF and found a very interesting dataset in the NeRS paper of 3D models, which was published in NeurIPS 2021 four months ago. Authors promised to release their dataset:\n  \nThe filtered dataset with anonymized personally identifiable information (e.g. license plates and phone numbers), masks, initial camera poses, and optimized NeRS cameras will be made available on the project page.\n  \nHowever, if you check their project page or github repo — there is nothing there. I do not have much experience in machine learning, but wonder whether it's ok to do this? My thinking was that it is something to look down upon, but in this case it is done by Carnegie Mellon University (which is a top-tier one in ML?) on a top-tier conference (NeurIPS 2021). So I assume it's fine?\n    submitted by    /u/throwmeaway-account  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5pxvh/d_is_it_ok_to_promise_a_dataset_in_your_paper_get/",
          "publishedOn": "2022-04-17T15:57:04.000Z",
          "wordCount": 1452,
          "title": "[D] Is it ok to promise a dataset in your paper, get published and then not release it?",
          "imageUrl": "https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?auto=webp&s=0c3f0b8af92c3a962f569a389e9673597e12f8ec"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5hny4/d_wasserstein_distance_lipschitz_vs_gaussian/",
          "author": null,
          "description": "Hi, I heard there are different ways to calculate Wasserstein distance in Neural network context. First, We can convert 1-d Wasserstein loss to dual representation and constraint it's size(to makes lipschitz function). We need to do weight clip to make our model a lipschitz function. Second, we can make neural network output as Gaussian distribution and calculate easy form using neural network output as mean and covariance matrix.\n So, what are the advantages and disadvantages of comparing them? It may sound ambiguous, but I have not seen a study that compares the two about representation quality, computation, etc...\n Thank you for reading.\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5hny4/d_wasserstein_distance_lipschitz_vs_gaussian/",
          "publishedOn": "2022-04-17T07:09:21.000Z",
          "wordCount": 195,
          "title": "[D] Wasserstein distance lipschitz vs gaussian distribution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5hls2/d_what_do_you_use_to_make_your_blogpersonal/",
          "author": null,
          "description": "I've noticed a lot of folks in ML have a personal website that doubles as a blog to write about their work/projects. As someone looking to build their own website along the same lines, I'm looking for frameworks to try and build it with.\n What framework do you use to design your site?\n    submitted by    /u/SwiftLynx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5hls2/d_what_do_you_use_to_make_your_blogpersonal/",
          "publishedOn": "2022-04-17T07:04:48.000Z",
          "wordCount": 777,
          "title": "[D] What do you use to make your blog/personal websites?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5g59g/discussion_interpretable_neural_network/",
          "author": null,
          "description": "Hi All!\n I've been working on a linear method that extracts signals from images by learning a set of composable image filters. It can recompose an image using these filters as seen on this biological histology tissue (real on the right, recomposed on the left)\n ​\n ​\n https://preview.redd.it/czgdk6edx0u81.png?width=768&format=png&auto=webp&s=8768f93a749fff7dc41e576a74403096e113942e\n ​\n Because it is a linear method that learns image filters - I had an idea: what if some components of a neural network could be replaced with a learnable set of filters?\n For those not in the know, image filters are similar to masks that upweight some parts of the image, and downweights other parts - similar to a highlighter to select text and a pen to cross out words. I show how in the figure below:\n ​\n ​\n https://preview.redd.it/2azco14ex0u81.jpg?width=499&format=pjpg&auto=webp&s=f3795fec06daa13da61ec155159a0ad865524530\n ​\n Learning a set of image filters with a neural network is a good idea, as neural networks are much more flexible and are considered to be \"universal function approximations\". So I wrote up a Pytorch package to pass the neural network feature weights from Convolutions and Max Pooling into the linear method to learn a relevant set of filters - results are comparable even on CIFAR10.\n The caveat is that there is no ReLU, no other activation functions, and no Dropout - only 1 main single linear layer that learns filters... an interpretable neural network!\n ​\n Results are all here (including ipynb comparing with base CNN and VGG16)\n https://github.com/AskExplain/Interpretable-Neural-Net\n ​\n I'll update the GitHub with some figures of why the single layer is interpretable soon ...\n ​\n In the meantime - discuss!\n    submitted by    /u/TryToExplainHow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5g59g/discussion_interpretable_neural_network/",
          "publishedOn": "2022-04-17T05:20:35.000Z",
          "wordCount": 785,
          "title": "[Discussion] Interpretable Neural Network ... ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5f13f/p_new_graph_data_augmentation_library/",
          "author": null,
          "description": "Hello!\n I recently built grafog, a graph data augmentation library on top of PyTorch Geometric. You can chain together graph mentations as done in albumentations or torchvision.transforms.\n Check it out: https://github.com/rish-16/grafog\n It has the following augmentations:\n  \nRandom Node Drop\n Random Edge Drop\n Normalize Features\n MixUp Strategy\n Node Feature Masking\n Edge Feature Masking\n  \nhttps://preview.redd.it/c53r7gkrk0u81.png?width=689&format=png&auto=webp&s=8fbe668e82571a7fe5de9ebb5e4690dbd34032bb\n https://preview.redd.it/5zrj4gkrk0u81.png?width=863&format=png&auto=webp&s=5bd02ea4adaf86b8911fa89372be9f05f9010536\n Happy augmenting!\n    submitted by    /u/rish-16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5f13f/p_new_graph_data_augmentation_library/",
          "publishedOn": "2022-04-17T04:09:29.000Z",
          "wordCount": 136,
          "title": "[P] New Graph Data Augmentation Library",
          "imageUrl": "https://external-preview.redd.it/W-DkujRyxiUuDiMo5mAmgu_-adMrH1WLDu4IKWgC1U8.jpg?auto=webp&s=cf4a7ac201e8c6befcc54281ba4e04bb6ee019dc"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5de2m/n_how_does_openais_dalle_2_work/",
          "author": null,
          "description": "submitted by    /u/giugiacaglia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5de2m/n_how_does_openais_dalle_2_work/",
          "publishedOn": "2022-04-17T02:33:05.000Z",
          "wordCount": 96,
          "title": "[N]: How does OpenAI's DALL-E 2 work?",
          "imageUrl": "https://external-preview.redd.it/O3oiwtDn_kSV6j5Y2p2wVfYjesxCV2ChsBLe-7boEJk.jpg?auto=webp&s=8b0004a2ccbf0994ceccf9a7d65b28a96922b369"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5bnj9/d_what_is_the_opposite_of_an_ablative_study/",
          "author": null,
          "description": "I've the feeling that this question may be really stupid but I make it anyway. \n In ML we often see ablative studies. How is the opposite of it called? In other words: A study that aim to improve a model, and once an improvement is reached, this new model is taken as basis for further investigations?\n    submitted by    /u/Rogitus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5bnj9/d_what_is_the_opposite_of_an_ablative_study/",
          "publishedOn": "2022-04-17T00:55:22.000Z",
          "wordCount": 644,
          "title": "[D] What is the opposite of an ablative study?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5ame9/r_questions_about_acl_rolling_review/",
          "author": null,
          "description": "A few questions about ACL ARR:\n - If you request to reassign a reviewer, would the editor aim for reassigning all three reviewers or he would go for reassigning only that particular reviewer? Assume you have given a valid reason for reassignment and the editor is convinced.\n - If you request to reassign a reviewer, can the new reviewer see the previous reviews/scores before submitting his own review? Or he would access to the previous revision after submitting his own review.\n I already know (have heard) that in many cases reviewers are not available, and it becomes inevitable to get an entirely new set of reviews. I already know this. But my questions are about the case that the reviewer availability is not an issue. Juts trying to find out how things are managed\n    submitted by    /u/sim_inf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5ame9/r_questions_about_acl_rolling_review/",
          "publishedOn": "2022-04-16T23:59:39.000Z",
          "wordCount": 311,
          "title": "[R] Questions about ACL Rolling Review",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u59qv5/rp_multimae_multimodal_multitask_masked/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u59qv5/rp_multimae_multimodal_multitask_masked/",
          "publishedOn": "2022-04-16T23:12:41.000Z",
          "wordCount": 105,
          "title": "[R][P] MultiMAE: Multi-modal Multi-task Masked Autoencoders + Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/bznYLgcG71XWh67uHxfzaDDfHXoDwNbJQq1TNPnUNXs.png?format=pjpg&auto=webp&s=b0345bfb4b06944f32485d9f4dbb8ebec53f98f5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u58ysb/discussionis_it_possible_to_find_a_swe_job_with_a/",
          "author": null,
          "description": "Say that a masters student graduates in a DS program with heavy focus on data and CS (so knows the basics of CS like data structures and programming, and has also studied courses like data mining, big data analytics, and machine learning), what are their possible job openings and relatively easy positions to get into?\n My understanding is really rudimentaly, feel free to correct me pls:\n  \nData scientist, this should be the most fitting and easy-to-get-interview position. Difficulty level 1/5.\n Data analyist, same as 1. Difficulty level 1/5.\n Data engineer, same as 1. Difficulty level 1/5.\n Machine learning engineer, has a higher bar than 1, 2, and 3, and it's very difficult to get interviews without proper background and work experience. So it's very difficult to become one for a masters graduate in DS, but it's quite possible for DS/DE (but much less so for DA) to make into MLE positions. Difficulty level 3/5.\n Software engineer, it's totally another realm, and has very few skill overlap with 1, 2, and 3. So it's very hard to make the transition or land a SWE job for DS students. Difficulty level 5/5.\n  \n   submitted by    /u/Competitive_Map_935  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u58ysb/discussionis_it_possible_to_find_a_swe_job_with_a/",
          "publishedOn": "2022-04-16T22:33:20.000Z",
          "wordCount": 422,
          "title": "[Discussion]Is it possible to find a SWE job with a DS master degree? Or would it be possible to make the transtion later on?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u58mu8/project_opensource_playground_to_generate_images/",
          "author": null,
          "description": "submitted by    /u/koryoislie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u58mu8/project_opensource_playground_to_generate_images/",
          "publishedOn": "2022-04-16T22:16:39.000Z",
          "wordCount": 113,
          "title": "[Project] Open-source playground to generate images from text using DALL-E Mini",
          "imageUrl": "https://external-preview.redd.it/3IZwiyP5n-XMJ7ZC-HYQGmSZ0FQJtbd7chsgGPQUGOw.jpg?auto=webp&s=deb00e83a408139fa4a40baa3f4352c9c7768e1d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u56grv/d_incorporating_node_features_into_gnns/",
          "author": null,
          "description": "Hey all,\n I am looking to learn more about how to incorporate node features with their embeddings for training. Specifically, I am working with gene-gene interaction networks, and also want to include RNA-sequencing quantifications.\n If anyone has a good introductory resource so I can familiarize myself with the process, I would really appreciate it!\n    submitted by    /u/PM_ME_A_ONELINER  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u56grv/d_incorporating_node_features_into_gnns/",
          "publishedOn": "2022-04-16T20:28:39.000Z",
          "wordCount": 217,
          "title": "[D] Incorporating node features into GNNs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u53hb3/d_moderation_uniformity_in_subreddit/",
          "author": null,
          "description": "This isn't meant to be a rant. Rather far from it.\n Yesterday I posted a legitimate question about databases choices in r/MachineLearning. This was about what technical choices ML members are currently using for large scale data ingestion in a continual learning environment. The post was removed. That post was neither a (1) beginner nor (2) offensive and (3) aimed to be a constructive discussion suitable as mid-range ML query and (4) marked with appropriate flair I finally posted it elsewhere.\n Yet today I see questions about transitions between DS -> MLE and quirky labgroup names which can be used from ML terms. These aren't even research questions.\n https://www.reddit.com/r/MachineLearning/comments/u503vz/d_is_it_easier_to_transition_to_mle_as_a_ds_or_swe/\n https://www.reddit.com/r/MachineLearning/comments/u5091o/d_do_you_know_any_funny_team_names_with/\n How is this fair moderation genuinely? How can we improve the noise filter or do better moderation?\n    submitted by    /u/mlbloke  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u53hb3/d_moderation_uniformity_in_subreddit/",
          "publishedOn": "2022-04-16T18:05:43.000Z",
          "wordCount": 684,
          "title": "[D] Moderation uniformity in subreddit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u50qor/d_counterfactual_fairness/",
          "author": null,
          "description": "So I watched this old video by Microsoft Research: https://www.youtube.com/watch?v=psA4U6nhZ70 \n To summarize, it uses the fairness criteria that sensitive attribute A will give the same prediction regardless of the value, when using counterfactuals. That is, if you're male or female, it shouldn't influence the models predictions. \n The idea seems decent at first glance. But what if the \"bias\" or \"unfairness\" that the model creates based on sensitive attribute A isn't caused by a dataset bias but rather detects a real signal in the data?\n The model proposed by Microsoft Research doesn't take into consideration that the prediction on the sensitive attribute A does not necessarily consist of ONLY unfairness. They simply define it as such. \n Is such an algorithmic design choice not exactly one of the flaws that we seek to eliminate? Assuming, that not all of the imbalance in predictions by the model on the sensitive attribute A is caused by \"unfairness\" but that some of it is caused by an inherent difference, then are they not introducing direct human bias and unfairness into their model by explicitedly designing the system to fit their own human (and political) bias? \n Don't get me wrong; the opposite is just as bad. Assuming that ALL of the imbalance in the prediction on the sensitive attribute A is caused by \"inherent differences\" is just as bad. \n Do you know of anyone that has tackled this in a good manner? How would you even begin to estimate how much is due to an \"inherent difference\" and how much is due to \"bias, unfairness, noise\" (or otherwise)?\n    submitted by    /u/caahel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u50qor/d_counterfactual_fairness/",
          "publishedOn": "2022-04-16T15:56:15.000Z",
          "wordCount": 1090,
          "title": "[D] Counterfactual Fairness",
          "imageUrl": "https://external-preview.redd.it/PkGn1qTyIzRCk-hvpbA86Dr9_suN1BAMtIk8hvwJ7UQ.jpg?auto=webp&s=dfa6818c1c26676a34ac7285fa272bd9c601093d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u50nva/d_paper_explained_transformer_memory_as_a/",
          "author": null,
          "description": "https://youtu.be/qlB0TPBQ7YY\n Search engines work by building an index and then looking up things in it. Usually, that index is a separate data structure. In keyword search, we build and store reverse indices. In neural search, we build nearest-neighbor indices. This paper does something different: It directly trains a Transformer to return the ID of the most relevant document. No similarity search over embeddings or anything like this is performed, and no external data structure is needed, as the entire index is essentially captured by the model's weights. The paper experiments with various ways of representing documents and training the system, which works surprisingly well! \n OUTLINE:\n 0:00 - Intro\n 0:45 - Sponsor: Diffgram\n 1:35 - Paper overview\n 3:15 - The search problem, classic and neural\n 8:15 - Seq2seq for directly predicting document IDs\n 11:05 - Differentiable search index architecture\n 18:05 - Indexing\n 25:15 - Retrieval and document representation\n 33:25 - Training DSI\n 39:15 - Experimental results\n 49:25 - Comments & Conclusions\n ​\n Paper: https://arxiv.org/abs/2202.06991\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u50nva/d_paper_explained_transformer_memory_as_a/",
          "publishedOn": "2022-04-16T15:52:29.000Z",
          "wordCount": 279,
          "title": "[D] Paper Explained - Transformer Memory as a Differentiable Search Index (Full Video Walkthrough)",
          "imageUrl": "https://external-preview.redd.it/oJXsTh1nRh1baGeG09BQsKVZ-h5vle9lh4vhdSO1U00.jpg?auto=webp&s=71d2b29f763b9c71de501eec80b24daad5924e75"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4y5r4/r_useful_method_to_train_models_for_adversarial/",
          "author": null,
          "description": "submitted by    /u/IncredibleMac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4y5r4/r_useful_method_to_train_models_for_adversarial/",
          "publishedOn": "2022-04-16T13:46:33.000Z",
          "wordCount": 107,
          "title": "[R] Useful method to train models for adversarial robustness",
          "imageUrl": "https://external-preview.redd.it/YB_0MLTV1pr8vz21W1E8IqoNv9407iLcaOC_mp4Kmcc.jpg?auto=webp&s=da75d46d3a5287773d398df80dc3d38fd80001b8"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4wvlc/p_comparing_default_vs_custom_reward_function_for/",
          "author": null,
          "description": "submitted by    /u/DIAMBRA_AIArena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4wvlc/p_comparing_default_vs_custom_reward_function_for/",
          "publishedOn": "2022-04-16T12:35:13.000Z",
          "wordCount": 337,
          "title": "[P] Comparing Default VS Custom Reward Function for Optimal Health Management of a DeepRL Agent Playing Tekken",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4w8x4/d_spotifys_podcast_search_explained/",
          "author": null,
          "description": "I wrote this article breaking down how Spotify have applied semantic search to enhance podcast discovery. I find it super interesting to see the approach Spotify have used in terms of data sources, model fine-tuning, and vector search - and wanted to show how to almost replicate it. Let me know if you have any thoughts on their approach!\n    submitted by    /u/jamescalam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4w8x4/d_spotifys_podcast_search_explained/",
          "publishedOn": "2022-04-16T11:56:51.000Z",
          "wordCount": 149,
          "title": "[D] Spotify's Podcast Search Explained",
          "imageUrl": "https://external-preview.redd.it/MfWyv37SXVtIVXtuiyhjCArVv2gGXI5l6fLL8RLBFPM.jpg?auto=webp&s=2b2d3a250b74a6dcff0ea27dac2a4e342cdc5596"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4vtil/r_machine_learning_in_management_of_precautionary/",
          "author": null,
          "description": "In this work, we have covered a deep study of alternatives in order to improve the aquaculture of mussels with very noisy and unbalanced data https://www.sciencedirect.com/science/article/pii/S0168169922002733\n    submitted by    /u/ennanco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4vtil/r_machine_learning_in_management_of_precautionary/",
          "publishedOn": "2022-04-16T11:28:27.000Z",
          "wordCount": 136,
          "title": "[R] Machine learning in management of precautionary closures caused by lipophilic biotoxins",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4uvac/p_rrgcn_now_supports_multimodal_learning/",
          "author": null,
          "description": "We have just released v0.0.2 of our RR-GCN. This release includes support for multi-modal learning. Node embeddings can now be initialised with literal information or pre-trained embeddings for text and image data. Go check out our notebooks that show how we can achieve state-of-the-art performance on several benchmark datasets in less than one minute. Moreover, and more importantly, the representations produced by our RR-GCN are unsupervised and parameter-free (i.e. no training is required), making it possible to re-use them for multiple downstream ML tasks with high predictive performances.\n ​\n https://github.com/predict-idlab/RR-GCN\n    submitted by    /u/givdwiel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4uvac/p_rrgcn_now_supports_multimodal_learning/",
          "publishedOn": "2022-04-16T10:21:03.000Z",
          "wordCount": 180,
          "title": "[P] RR-GCN now supports multi-modal learning!",
          "imageUrl": "https://external-preview.redd.it/_tKhxjKFTfxjnhpHTJPz0U2l2tdo7r5v1wV9Hm4JPf4.jpg?auto=webp&s=4a6118d3da56eebca2751712955dcfed98ced8c6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4tlk2/d_paper_explained_seer_explained_vision_models/",
          "author": null,
          "description": "https://youtu.be/XHAoV_nKr1o\n This video explains the 10 billion parameter SEER model from MetaAI by Goyal et al. 2022.\n Paper link: https://arxiv.org/abs/2202.08360 \n Official implementation: https://github.com/facebookresearch/vissl/tree/main/projects/SEER\n Short description:\n The 10 billion parameter SEER model from u/MetaAI is *fairer*, even though it is trained on *uncurated* data. How so? Check out our take on this. \n Outline:\n 00:00 Training on uncurated data\n 01:12 Diffgram (Sponsor)\n 01:46 Toxicity in large models\n 02:43 What to do against model toxicity?\n 03:53 SEER model explained\n 06:52 SEER is fairer. But how?\n    submitted by    /u/AICoffeeBreak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4tlk2/d_paper_explained_seer_explained_vision_models/",
          "publishedOn": "2022-04-16T08:46:17.000Z",
          "wordCount": 275,
          "title": "[D] Paper Explained – SEER explained: Vision Models more Robust & Fair when pretrained on UNCURATED images!?",
          "imageUrl": "https://external-preview.redd.it/PAoscz2vJnkKtNLkvbvGLICUtG6dVPUzJECgUOpC2bo.jpg?auto=webp&s=766b0c566c9f8e5edef60788e2412b994425c4f2"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4kowy/d_what_is_the_difference_between_channelwise_and/",
          "author": null,
          "description": "Example: I fed 32 feature maps of dimension 6x6x32 into a Squeeze and Excitation layer, which assigns a weight to each of my channel through a channel-wise attention mechanism. \n What is the difference between passing these 32 feature maps into a Hybrid Transformer Encoder with patch of dimension 6x6? (So 1 patch for each channel)\n As I understand it, channel attention says \"which channel is important for the final prediction\". While transformer (with self attention) tells us \"where to focus our attention in a given context\".\n Isn't that the same if the patches are the channels? Basically it tells us on which patch to focus, and if patch=channel then squeeze excitation = self attention ?\n    submitted by    /u/Rogitus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4kowy/d_what_is_the_difference_between_channelwise_and/",
          "publishedOn": "2022-04-15T23:29:32.000Z",
          "wordCount": 225,
          "title": "[D] What is the difference between channel-wise and self attention in this case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4jkgu/p_boundingai_launches_new_marketplace_for_ai/",
          "author": null,
          "description": "In a new announcement, Bounding.ai launched its marketplace for computer vision and AI teams to access training data easily. The platform is designed to empower individuals and small companies around the world to create and sell datasets that will be instantly accessible by any team in need of labeled data.\n Bounding.ai Launches New Marketplace for AI Labeled Data & $5,000 Prize\n    submitted by    /u/Freyr_AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4jkgu/p_boundingai_launches_new_marketplace_for_ai/",
          "publishedOn": "2022-04-15T22:31:38.000Z",
          "wordCount": 167,
          "title": "[P] Bounding.ai Launches New Marketplace for AI Labeled Data",
          "imageUrl": "https://external-preview.redd.it/x7ulJgQagpjsTvp9cVZtPj5uGgLkFq_7j6GrHfxsmxU.jpg?auto=webp&s=2dca867b23623a16f646a9525dc5d5d9102fefa7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4cu3k/dunsupervised_classification_of_wordsphrases/",
          "author": null,
          "description": "I have found most unsupervised text classification methods to be mostly suitable for classifying documents containing relatively large amounts of words/sentences. However, I have a dataset with entries containing only single words or phrases but not full sentences. The goal is to do unsupervised semantic classification on these words/phrases. Are there any existing algorithms for such a task?\n    submitted by    /u/Comprehensive-Egg707  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4cu3k/dunsupervised_classification_of_wordsphrases/",
          "publishedOn": "2022-04-15T17:12:45.000Z",
          "wordCount": 165,
          "title": "[D]Unsupervised classification of words/phrases?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4cpc7/n_robot_arm_acts_as_hand_and_eyes_of_language/",
          "author": null,
          "description": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could in principle be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack contextual grounding, which makes it difficult to leverage them for decision making within a given real-world context. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide this grounding by means of pretrained behaviors, which are used to condition the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level tasks can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these tasks provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator.\n Github: https://say-can.github.io/\n Video of Robot Executing Commands: https://youtu.be/zOph99BjRqs?t=4\n    submitted by    /u/SlightSituation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4cpc7/n_robot_arm_acts_as_hand_and_eyes_of_language/",
          "publishedOn": "2022-04-15T17:06:49.000Z",
          "wordCount": 384,
          "title": "[N] Robot Arm Acts As \"Hand And Eyes\" of Language Model To Execute Real World Tasks With SayCan And Robotics At Google",
          "imageUrl": "https://external-preview.redd.it/hsvHG0bwPLs7HD7ligE7Xw9DhAB8J0Rb9r3BL8XJVPk.jpg?auto=webp&s=bdc19091d980975265d680d565667e3b1ff67c24"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4bfii/d_askscience_ama_series_we_are_seven_leading/",
          "author": null,
          "description": "submitted by    /u/blueneuronDOTnet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4bfii/d_askscience_ama_series_we_are_seven_leading/",
          "publishedOn": "2022-04-15T16:08:22.000Z",
          "wordCount": 631,
          "title": "[D] AskScience AMA Series: We are seven leading scientists specializing in the intersection of machine learning and neuroscience. Ask Us Anything about computational neuroscience or science education!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u496k8/d_how_dalle_2_actually_works/",
          "author": null,
          "description": "Here's a video explaining the overall architecture of DALL-E 2 and how it actually works! Great overview for those who haven't had time to read the paper\n How does DALL-E 2 actually work?\n    submitted by    /u/SleekEagle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u496k8/d_how_dalle_2_actually_works/",
          "publishedOn": "2022-04-15T14:23:30.000Z",
          "wordCount": 219,
          "title": "[D] How DALL-E 2 Actually Works",
          "imageUrl": "https://external-preview.redd.it/_1AcQ1a3JcdirIWcWtQJYzupd0UV2SkQtJ4kF5imSvE.jpg?auto=webp&s=b4d01c5a490c044d73c4f83548b42fc34743dbf6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u482yj/n_announcing_the_learning_on_graphs_conference/",
          "author": null,
          "description": "We think this new venue will be valuable for the Graph/Geometric Machine Learning community. Why? See our blogpost: https://michael-bronstein.medium.com/announcing-the-learning-on-graphs-conference-c63caed7347\n The LoG Conference key facts:\n - Covers work broadly related to machine learning on graphs and geometry\n - Proceedings track published in PMLR\n - Also has a non-archival extended abstract track\n - Double blind review process on OpenReview\n - Top reviewers receive monetary rewards\n - First year: virtual December 9-12 2022, free to attend.\n Call for papers: https://logconference.github.io/cfp/ \n Stay updated via Twitter: https://twitter.com/LogConference\n Or LinkedIn: https://www.linkedin.com/company/log-conference\n Advisory board:\n Regina Barzilay (MIT), Xavier Bresson (NUS), Michael Bronstein (Oxford/Twitter), Stephan Günnemann (TUM), Stefanie Jegelka (MIT), Jure Leskovec (Stanford), Pietro Liò (Cambridge), Jian Tang (MILA/HEC Montreal), Jie Tang (Tsinghua), Petar Veličković (DeepMind), Soledad Villar (JHU), Marinka Zitnik (Harvard).\n Organizers:\n Yuanqi Du (DP Technology), Hannes Stärk (MIT), Derek Lim (MIT), Chaitanya Joshi (Cambridge), Andreea-Ioana Deac (Mila), Iulia Duta (Cambridge), Joshua Robinson (MIT).\n    submitted by    /u/Hannes-Stark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u482yj/n_announcing_the_learning_on_graphs_conference/",
          "publishedOn": "2022-04-15T13:28:35.000Z",
          "wordCount": 228,
          "title": "[N] Announcing the Learning on Graphs Conference!",
          "imageUrl": "https://external-preview.redd.it/EXt-6EkuWHtAcKDkIEkW4MowqZSzpZGNoRuanm2aJr4.jpg?auto=webp&s=c1384e936720dc96f641150d3c8e89cb98af6043"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u45w9b/p_using_language_models_to_probably_read_faster/",
          "author": null,
          "description": "I explored using language models to highlight more salient parts of a PDF file which hopefully help users to read faster. The main idea is to highlight only the characters which language model failed to predict. I have implemented this as an experimental feature in sioyek PDF reader.\n Here is a blog post explaining this in full detail: https://ahrm.github.io/jekyll/update/2022/04/14/using-languge-models-to-read-faster.html\n    submitted by    /u/highergraphic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u45w9b/p_using_language_models_to_probably_read_faster/",
          "publishedOn": "2022-04-15T11:25:45.000Z",
          "wordCount": 538,
          "title": "[P] Using Language Models to (probably) Read Faster",
          "imageUrl": "https://external-preview.redd.it/n4Qm7bf5J5F1cD4l2Q2hq8xgDPml_3BecCBw6TOauwk.jpg?auto=webp&s=8f857d3f7ea13a314295aac9ef44a85345c3c2bf"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4579v/p_gans_and_generating_visually_indeterminate/",
          "author": null,
          "description": "(Please correct me if I'm using the wrong flair/on the wrong sub)\n I'm currently working on a project that focuses on GANs and generative art, particularly images that concern visual indeterminacy. I trying to find papers/articles that discuss the development/application of (any kind of) GAN in which along the way or as a final result, images were generated that would be considered visually indeterminate. Specifically, research in which the objective was to generate images with clear, recognizable objects/scenes.\n In my mind I'm looking for articles in which the GAN architecture is discussed and in which ways what parts of it could've influenced the particular aspects of the incorrectly generated image. This probably wouldn't be the focus of any research but I was wondering if anyone has ever come across a discussion section in a GAN paper or could point me towards some areas or projects where I might find something that I could connect to my project.\n    submitted by    /u/mel4ncholi4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4579v/p_gans_and_generating_visually_indeterminate/",
          "publishedOn": "2022-04-15T10:39:25.000Z",
          "wordCount": 256,
          "title": "[P] GANs and generating visually indeterminate images by error",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u442u0/d_ensemble_methods_eg_hard_voting_in_machine/",
          "author": null,
          "description": "When should we consider ensemble methods in machine learning? Is there any statistical criteria using which we can decide, if doing ensemble may help?\n    submitted by    /u/flaubart9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u442u0/d_ensemble_methods_eg_hard_voting_in_machine/",
          "publishedOn": "2022-04-15T09:18:10.000Z",
          "wordCount": 465,
          "title": "[D] Ensemble methods (e.g. hard voting) in machine learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u43bdq/d_how_do_you_understand_both_ff𝐿_and_ff𝑆_were/",
          "author": null,
          "description": "Hi, I am re-implementing the paper \"Low Resource Recognition and Linking of Biomedical Concepts from a Large Ontology\" https://arxiv.org/abs/2101.10587v1 .\n They describe one part of their model as \"3-layer feed-forward networks with hidden dimensions of 1024 and 256, GeLU as the activation function and a dropout with probability 0.1 applied at their input.\"\n For me that's not enough information to uniquely characterize the network, but maybe for someone with more experience the intended structure is obvious. The output should be a scalar, so i assume that it's something like:\n Dropout(0.1) -> Linear(<input dim>, 1024) -> Linear(1024, 256) -> GELU -> Linear(256, 1) ?\n Or is the nonlinearity (GELU) normally applied after each step?\n    submitted by    /u/ldorigo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u43bdq/d_how_do_you_understand_both_ff𝐿_and_ff𝑆_were/",
          "publishedOn": "2022-04-15T08:20:21.000Z",
          "wordCount": null,
          "title": "[D] How do you understand \"Both FF𝐿 and FF𝑆 were 3-layer feed-forward networks with hidden dimensions of 1024 and 256, GeLU as the activation function and a dropout with probability 0.1 applied at their input.\"? (re-implementing https://arxiv.org/abs/2101.10587v1)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u42yop/why_did_scinet_not_get_more_attention_d/",
          "author": null,
          "description": "It seems to shatter previous benchmarks with a new, innovative architecture, yet it only has 3 citations and little to no attention from the community as far as I can see. Is it because time series forecasting is not very trendy right now or is there anything wrong with the paper?\n The paper in question: https://arxiv.org/pdf/2106.09305v2.pdf\n    submitted by    /u/vidul7498  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u42yop/why_did_scinet_not_get_more_attention_d/",
          "publishedOn": "2022-04-15T07:54:34.000Z",
          "wordCount": 669,
          "title": "Why did SciNet not get more attention? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u40qlq/d_do_you_train_and_deploy_models_using_just_one/",
          "author": null,
          "description": "Hi, I'm the creator of Pinferencia. Currently I'm design new features to-do list. I want to know:\n Do you train and deploy models using just one framework or multiple frameworks at work?\n For example, use pytorch for training and deployment, or use tensorflow, pytorch for training, onnx for deployment.\n View Poll\n    submitted by    /u/Remote_Cancel_7977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u40qlq/d_do_you_train_and_deploy_models_using_just_one/",
          "publishedOn": "2022-04-15T05:20:22.000Z",
          "wordCount": 542,
          "title": "[D] Do you train and deploy models using just one framework or multiple frameworks at work?",
          "imageUrl": "https://external-preview.redd.it/-FMAntzrgomVFdSmpIvFZ3p81fjXHuHG4NC8okewaYc.jpg?auto=webp&s=aa353febc115f4043e7c0ca28217bab8db441503"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3zyvy/p_extremely_short_and_simple_implementation_of/",
          "author": null,
          "description": "​\n Randomly sampled MNIST output. It's not good I know.\n Hi, I noticed there aren't that many simple implementation of DDPM, for example, using MNIST. I had to make a presentation for my workplace seminar, so I had to implement the simplified version of DDPM myself. The whole thing is under 200 lines of code\n https://github.com/cloneofsimo/minDiffusion\n This implementation has MANY missing details, such as Unet Models etc. I think it is worth taking a look, especially if you are interested in recent boom of diffusion models (such as Dalle 2)\n    submitted by    /u/cloneofsimo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3zyvy/p_extremely_short_and_simple_implementation_of/",
          "publishedOn": "2022-04-15T04:31:28.000Z",
          "wordCount": 346,
          "title": "[P] Extremely short and simple implementation of Denoising Diffusion Model, for educational purpose",
          "imageUrl": "https://external-preview.redd.it/v-57XvcNvwhO-HEm0YwnYMP-kBn5uJ7kFdEfT8Hvj_A.jpg?auto=webp&s=461fca6af9aa2e345afbeb207d23970ce0a6d5d5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3xjr7/d_kubernetes_for_ml_how_are_yall_doing_it/",
          "author": null,
          "description": "Have been involved with Mesos since 2013, and Kubernetes almost since it's inception (and saw it win the \"scheduler wars\"). And now being used for pretty much _all_ container workloads, including ML training and inference.\n Since it was built in the image of Borg (where search indexers and map reduce jobs were preemptible, and serving search workloads had to be protected at all cost)[1], how is Kubernetes holding up for your current workflows? Are you using Kubeflow? metaflow? bespoke setup on top? \n [1] https://queue.acm.org/detail.cfm?id=2898444\n    submitted by    /u/nqnielsen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3xjr7/d_kubernetes_for_ml_how_are_yall_doing_it/",
          "publishedOn": "2022-04-15T02:15:10.000Z",
          "wordCount": 636,
          "title": "[D] Kubernetes for ML - how are y'all doing it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3tld1/d_loocv/",
          "author": null,
          "description": "I'm working with a small dataset (~400 labeled data). I plan to use logistic regression. Does it make sense/is it necessary to have a hold-out validation set along with doing Leave-one out cross validation (LOOCV) (E.g. leave 20% out, and train model on LOOCV)?\n    submitted by    /u/yontbont1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3tld1/d_loocv/",
          "publishedOn": "2022-04-14T22:50:24.000Z",
          "wordCount": 339,
          "title": "[D] LOOCV",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3o4jp/d_whats_the_probability_distribution_of_the/",
          "author": null,
          "description": "Assuming feature importance as defined by mean decrease in impurities. I'm curious if there are any studies about their distribution. I'm thinking about using a statistical test to check if a feature is relevant or not, all I can find is using the standard deviation as a measurement of noise. Additionally I imagine if we can give the probability of one feature being more relevant than another given their feature importances\n    submitted by    /u/FellowOfHorses  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3o4jp/d_whats_the_probability_distribution_of_the/",
          "publishedOn": "2022-04-14T18:34:14.000Z",
          "wordCount": 264,
          "title": "[D] What's the probability distribution of the Feature importances in an ensemble method?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3nru7/discussion_collecting_feedback_for_finrl/",
          "author": null,
          "description": "Dear all,\n As a creator of the open-source FinRL project, I would like to welcome all kinds of feedback regarding financial reinforcement learning, especially about how to improve the open-source project FinRL.\n After several years of development and maintenance, we have passed the phase of caring about #stars, now we care more about #downloads, also Wall Street's adoption.\n Appreciate your feedback and sharing!\n Previously when we exposed our message on Reddit, the community was not very supportive about open-source projects' \"advertisements\". Maybe it consumed public attention and raised bad feelings. Therefore, this time we created a reddit sub-channel for FinRL-related discussions, available at: https://www.reddit.com/r/AI4Finance_FinRL/\n Best,\n Yang\n    submitted by    /u/Character-Meat-9176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3nru7/discussion_collecting_feedback_for_finrl/",
          "publishedOn": "2022-04-14T18:17:49.000Z",
          "wordCount": 198,
          "title": "[Discussion] Collecting Feedback for FinRL: Financial Reinforcement Learning",
          "imageUrl": "https://external-preview.redd.it/8-Jkr120jBwSEOjE3QprtB37msW5qLklONwZxIIXnb8.jpg?auto=webp&s=cd57c9967110f6a7206244afffb6b6e6f96e9fca"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3gdx1/d_what_fun_things_in_ml_would_you_give_a/",
          "author": null,
          "description": "If you had 30 minutes to present something fun and exciting to a semi-technical audience, what would you talk about on Machine Learning that would gain interest and engagement?\n    submitted by    /u/aero_gsr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3gdx1/d_what_fun_things_in_ml_would_you_give_a/",
          "publishedOn": "2022-04-14T12:27:01.000Z",
          "wordCount": 196,
          "title": "[D] What fun things in ML would you give a presentation on?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3erzw/d_evaluation_and_iteration_for_production_models/",
          "author": null,
          "description": "How do you evaluate and improve your models in production (particularly for complex modalities like text/vision/audio)? \n Good models are hard\n In my experience from managing our CNN-based text classification & NER model at a small media analytics startup, evaluating and improving models is a mess. Our domain is fairly niche and diverse, so getting enough training data has been challenging and I mix in custom synthetics & augmentations (which can cause weird model artifacts if you're not careful). It takes a lot of time to discover tricky failure cases by either 1) observing production traffic or 2) probing manually, and then it takes even more time to get the right data to improve model behavior. \n Are good models hard?\n What's your approach to model evaluation & targeted improvement? Are there any known best practices? I'm a bit at a loss here. As mentioned, I'm specifically interested in others who have deep models as an important part of their product or pipeline across any task or modality. More particularly:\n  \nHow wrong is your model? How do you test it? How would you know about errors before and after it's deployed?\n How much of your time do you spend on iterating on your models? For what kind of issue? \n Which aspects are most useful to you for improving model performance and reducing critical errors?\n  \nMaybe I'll take some of the more general ideas from my work and build them out into an evaluation & iteration framework. It's currently a hybrid web of synthetic, interactive/probing and classical approaches. Or maybe there is some approach/library that makes iteration easier without me having to do anything :)\n    submitted by    /u/flotothemoon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3erzw/d_evaluation_and_iteration_for_production_models/",
          "publishedOn": "2022-04-14T10:57:44.000Z",
          "wordCount": 480,
          "title": "[D] Evaluation and iteration for production models - how?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3cgfy/d_trace_norm_in_kfac_paper_for_regularization/",
          "author": null,
          "description": "Hi,\n I doubt that the trace norm of the Kronecker product is mistaken in the KFAC paper (https://arxiv.org/abs/1503.05671).\n Shouldn't the division in the blue mark be replaced by multiplication?\n https://preview.redd.it/quoxpzubfgt81.png?width=1241&format=png&auto=webp&s=19e7b60628302f3cb37ba42944088d89d7a7bd28\n    submitted by    /u/Cautious_Proposal132  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3cgfy/d_trace_norm_in_kfac_paper_for_regularization/",
          "publishedOn": "2022-04-14T08:24:01.000Z",
          "wordCount": 161,
          "title": "[D] Trace norm in KFAC paper for regularization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3bu3e/d_to_what_extent_can_rust_be_used_for_machine/",
          "author": null,
          "description": "I recently saw that some parts of HuggingFace ecosystem use Rust under the hood, and HF is a large ecosystem. I've also heard from some of my friends that they had to learn Rust as a first thing in an ML company (it's their first job so they couldn't explain to me exactly why).\n My questions are:\n  \nWhat are pros and cons over Python?\n Are there any good frameworks in Rust for ML?\n Are there a decent community & documentation for Rust?\n Is learning it a fun experience?\n Is it used only for deployment?\n  \n The reason I'm asking this is that I really love to learn by doing. And so, if I engaged in learning a bit of Rust for ML purposes, would I be able to create something ML-like right of the bat? It can be something as simple as MNIST classifier\n  \nTake note that I don't know anything about Rust, so these questions might seem noob-like. But I believe that the answers can be of help to others as well.\n    submitted by    /u/Icy_Fisherman7187  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3bu3e/d_to_what_extent_can_rust_be_used_for_machine/",
          "publishedOn": "2022-04-14T07:37:40.000Z",
          "wordCount": 1366,
          "title": "[D] To what extent can Rust be used for Machine Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u394zj/d_tips_for_using_ensemble_learning_with_a_small/",
          "author": null,
          "description": "I have started to look into using an ensemble of relatively shallow MLPs to predict using a small dataset (~100 training samples). I was looking specifically at bagging (bootstrap aggregation) as a possibility of improving prediction accuracy.\n I was curious if there were any heuristics for how many models to include in a bagging ensemble? \n Also, more generally, am I on the correct path, or is there a better direction given my situation? A different ensemble technique, or a different path all together?\n Any advice would be appreciated.\n    submitted by    /u/Fritos121  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u394zj/d_tips_for_using_ensemble_learning_with_a_small/",
          "publishedOn": "2022-04-14T04:32:22.000Z",
          "wordCount": 365,
          "title": "[D] Tips for using Ensemble Learning with a small dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u34oh2/d_what_jax_nn_library_to_use/",
          "author": null,
          "description": "I've been exploring the jax ecosystem and its many neural network libraries but I can't seem to settle on one. The main 5 which i am considering are Trax, Objax, Equinox, Flax, and Elegy, however I would like to hear which jax NN lib you use and why.\n    submitted by    /u/Southern-Trip-1102  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u34oh2/d_what_jax_nn_library_to_use/",
          "publishedOn": "2022-04-14T00:29:42.000Z",
          "wordCount": 143,
          "title": "[D] What JAX NN library to use?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u33z5d/best_sample_text_for_voice_synthesis_d/",
          "author": null,
          "description": "I'm planning to create a clone of my own voice. Is there some kind of ideal sample text to record? I need 300 sentences.\n    submitted by    /u/headwar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u33z5d/best_sample_text_for_voice_synthesis_d/",
          "publishedOn": "2022-04-13T23:53:34.000Z",
          "wordCount": 119,
          "title": "Best sample text for voice synthesis? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2y2mc/r_ml_model_to_generate_paths_lines_for_a_given/",
          "author": null,
          "description": "I am a researcher working on creating paths to indicate the primary and secondary neuronal connections in Corneal Confocal Microscopy images. The ground truth I have is images and sets of two-dimensional lines that indicate the primary and secondary paths as indicated in the image below (Ignore the green dots). The secondary and primary paths are always connected to each other.\n ​\n https://preview.redd.it/r025qcpjddt81.jpg?width=834&format=pjpg&auto=webp&s=11a641988e0c6f8c1e17290fe9588f89ef530635\n I am looking to find the most appropriate models to use for this task. The first thing that came to my mind was semantic segmentation. However, I am looking for other approaches that can be more suitable for drawing 1-pixel lines especially since the ground truth paths are indicated as 1-pixel-wide lines (1-pixel thickness) but the connections in the images have wider thicknesses.\n Any ideas for architecture or methods?\n    submitted by    /u/madr3z  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2y2mc/r_ml_model_to_generate_paths_lines_for_a_given/",
          "publishedOn": "2022-04-13T19:20:36.000Z",
          "wordCount": 502,
          "title": "[R] ML model to generate paths (lines) for a given image",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2x0jd/n_followup_response_from_baai_on_a_roadmap_for/",
          "author": null,
          "description": "Source: https://www.baai.ac.cn/portal/article/index/cid/4/id/404.html\n  \nStatement on the Alleged Plagiarism by “A Roadmap for Big Model”\n It has come to our attention that the survey report “A Roadmap for Big Model” uploaded on arXiv by a BAAI team is suspected of plagiarism. Immediately upon learning of the allegations, an internal investigation was organized to confirm the issue. BAAI is also initiating an independent review by third-party experts to further asses the issue and accountabilities. As a research institution that attaches great importance to academic standards, BAAI holds a zero-tolerance policy towards academic misconduct. We express our sincerest apologies to the authors of the original papers and to all of those affected.\n The report in question constitutes a collection …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2x0jd/n_followup_response_from_baai_on_a_roadmap_for/",
          "publishedOn": "2022-04-13T18:31:30.000Z",
          "wordCount": 540,
          "title": "[N] Followup response from BAAI on \"A Roadmap for Big Model\"",
          "imageUrl": "https://external-preview.redd.it/6KE0VsnU5qw9TosCPhbXgpP4HS-1juJ34SdlTsbIKb4.jpg?auto=webp&s=1a1b351a5193f563b13f581c860f92bcdd93f169"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2vphr/p_image_restoration_using_swin_transformer_in/",
          "author": null,
          "description": "Important note: Right now, the model only supports up sampling from any dimension to at most 256 pixels. I'll likely fix this restriction in the next few days.\n A few days back, I was searching for AI-based image up sampling models in for use within an offline JavaScript app. The latest approaches, such as SwinIR were unavailable for Javascript, so I just created a notebook that converts the SwinIR model from torch to TFJS in a relatively short kaggle kernel. I believe other transformer architectures can also be ported to JS like this. This is the link to the original paper of SwinIR.\n It requires around 1 GB of RAM to run. The size of model folder is 44 MB. It is quantized to float16.\n Anyway, hope someone will find this useful for their website or some other app.\n    submitted by    /u/Deep-Station-1746  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2vphr/p_image_restoration_using_swin_transformer_in/",
          "publishedOn": "2022-04-13T17:33:23.000Z",
          "wordCount": 292,
          "title": "[P] Image Restoration Using Swin Transformer in JavaScript",
          "imageUrl": "https://external-preview.redd.it/jYE0tQNmt3JdZID0Tp92vM9yoA-SV0dZM5aA4LH4luo.jpg?auto=webp&s=3fa4778b3285b13d61d93241270c647d6a34014e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2vim0/d_replacing_3x3_convolutions_with_two_2x2/",
          "author": null,
          "description": "Something that's always puzzled me is the ubiquitousness of 3x3 convolutions in computer vision. If I recall past discussion accurately, the main benefits of odd-sized kernels are that\n  \nWith the proper padding they maintain the width and height of their inputs, which makes it easier to think about/design neural network architectures. This is not possible with even kernels, unless you swallow the bullet and use asymmetric padding (which is rejected due to aesthetic reasons)\n Output pixels have a 1-to-1 mapping with input pixels (since odd-sized kernels have a proper \"center\"). This is considered a nice property -- perhaps (for instance) avoiding aliasing issues during segmentation tasks.\n  \nGiven these two points, we use 3x3 convolutions since they're the smallest odd-sized filter (exclud…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2vim0/d_replacing_3x3_convolutions_with_two_2x2/",
          "publishedOn": "2022-04-13T17:24:49.000Z",
          "wordCount": 1863,
          "title": "[D] Replacing 3x3 convolutions with two 2x2 convolutions",
          "imageUrl": "https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?auto=webp&s=73eb91ea5a5347f216c0f0c4d6796396826aae49"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2szhq/r_do_deep_neural_networks_contribute_to/",
          "author": null,
          "description": "submitted by    /u/MVTS_Ano  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2szhq/r_do_deep_neural_networks_contribute_to/",
          "publishedOn": "2022-04-13T15:31:56.000Z",
          "wordCount": 155,
          "title": "[R] Do Deep Neural Networks Contribute to Multivariate Time Series Anomaly Detection ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2so8x/d_open_problem_in_modern_rl_that_doesnt_need_a/",
          "author": null,
          "description": "What are open and/or interesting problems in modern reinforcement learning that can be tackled by the average PhD/PostDoc who doesn't have access to a massive compute cluster? The problem shouldn't need us to train our model for 10 months like OpenAI's Dota2 model. Please share your thoughts.\n    submitted by    /u/ginger_beer_m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2so8x/d_open_problem_in_modern_rl_that_doesnt_need_a/",
          "publishedOn": "2022-04-13T15:17:52.000Z",
          "wordCount": 380,
          "title": "[D] Open problem in modern RL that doesn't need a massive computational resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2sdkt/d_what_are_the_biggest_developments_in_cv_in_last/",
          "author": null,
          "description": "I've been helping a friend of mine learn about CV, but my knowledge starts getting spotty around 2017-2018. In this spirit I'm hoping to discuss the biggest developments in CV in the last 5 years. I know that ViTs have been developed in that time but I'm hoping to fill in my knowledge gaps!\n A list of topics, important papers, big ideas, or anything else is much appreciated!\n ​\n Edit: Thank you for the discussion everyone 🙌! I've been in and out of meetings but am reading through all responses now \n    submitted by    /u/SleekEagle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2sdkt/d_what_are_the_biggest_developments_in_cv_in_last/",
          "publishedOn": "2022-04-13T15:04:39.000Z",
          "wordCount": 770,
          "title": "[D] What are the biggest developments in CV in last 5 years?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2pi8b/p_how_and_where_do_you_serve_your_model_using/",
          "author": null,
          "description": "Hi, I’m a machine learning platform engineer. I’ve been using, exploring and developing model deployment tools and platform for several years.\n Very often, I found that many of the tools or managed service of AI platform, are not very welcome by many users. Some think these tools are unnecessarily complicated.\n I'm currently developing a library in my free time trying to fill the gap. And I also want the library to get well integrated with most users' deployment environments.\n Would you like to share how and where do you serve your model? Using kubernetes? Self developed or existing tools? Thanks～\n P.S. If you are interested, you can visit my project to submit an issue/PR or join the discussions, welcome to help: Pinferencia\n View Poll\n    submitted by    /u/Remote_Cancel_7977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2pi8b/p_how_and_where_do_you_serve_your_model_using/",
          "publishedOn": "2022-04-13T12:45:45.000Z",
          "wordCount": 381,
          "title": "[P] How and where do you serve your model? Using kubernetes, docker, metal? Self developed or existing tools?",
          "imageUrl": "https://external-preview.redd.it/1DZ3f-7YqPBqW5XsOeXnsBLZVKRUXGtrF4Nx0ejYLpM.jpg?auto=webp&s=ecf81d8d9225757724de200608fc1cf1ca392519"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2np4x/p_i_created_a_youtube_thumbnail_dataset_and_need/",
          "author": null,
          "description": "Hi guys! I recently created & published a dataset of YouTube video thumbnails on Kaggle (YouTube Thumbnail Dataset), I've tried to make the dataset as diverse as possible, It contains thumbnails from all varieties of YouTube channels. This dataset goes hand in hand with another dataset (containing YouTube video annotations) that I created, namely YouTubers Saying Things.\n The dataset contains 91 unique YouTube channels, and 10 categories, these categories are assigned by me manually to these channels. (Comedy, Science, Automobile, VideoGames, Food, Entertainment, Informative, Blog, News, Tech)\n All kinds of feedback and criticism are welcome, and also if you guys want some particular channel to be included in both these datasets, feel free to comment on this post, or raise an issue on the Github repositories for both these datasets, I will surely add them in the next version.\n Links to the datasets:\n  \nYouTubers Saying Things Kaggle, Github\n YouTube Thumbnail Dataset Kaggle, Github\n  \n   submitted by    /u/alcatraz2217  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2np4x/p_i_created_a_youtube_thumbnail_dataset_and_need/",
          "publishedOn": "2022-04-13T11:00:24.000Z",
          "wordCount": 361,
          "title": "[P] I created a YouTube Thumbnail Dataset, and need some insight",
          "imageUrl": "https://external-preview.redd.it/dzM_8rsfwC2Gm1fzlnioer3Q4FF3TCJIIyk0AcjosPU.jpg?auto=webp&s=d3b657e6b97e89fd4cf4337dd6d8a587539fff47"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2mbus/improve_xgboost_classification_algorithm_with/",
          "author": null,
          "description": "Hi, I am doing researches about transfer learning for XGboost. \n I am currently working with a small dataset from a company in Spain (short history) and the scoring is poor. I have worked before with the same company in France and the scoring was great as I had plenty of data thanks to a big history. How could I improve my score with the data from Spain with the help of data from France ? \n Could I use transfer learning, or data mutualization, or data augmentation ? If anyone has faced before a similar problem, or has read some papers about it, I would love to hear about it. \n Thank you!\n    submitted by    /u/Cutset  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2mbus/improve_xgboost_classification_algorithm_with/",
          "publishedOn": "2022-04-13T09:23:57.000Z",
          "wordCount": 343,
          "title": "Improve XGboost classification algorithm with small dataset, based on similar bigger dataset ? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2k8xh/r_a_modern_selfreferential_weight_matrix_that/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2k8xh/r_a_modern_selfreferential_weight_matrix_that/",
          "publishedOn": "2022-04-13T06:48:58.000Z",
          "wordCount": 126,
          "title": "[R] A Modern Self-Referential Weight Matrix That Learns to Modify Itself",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2goyo/d_what_are_some_interesting_hidden_stuff_about/",
          "author": null,
          "description": "Hey all,\n Im trying to get up to date with Deep Learning literature, so the last week I was going through CNNs. Here's a general view of what Ive learned so far.\n  \nLarge filters suck, you can get better accuracy with smaller filters and more non linearities\n \nDepth is the most important for CNNs over width or filter sizes.\n \nReLU activation is generally better, as Sigmoid/tanh gradients tend to fall off towards the ends\n \nConvolution layers are only translation invariant. Stacking multiple features together and passing them through MaxPool helps rotational invariance and scaling although not completely \n \nResidual connection help address vanishing gradient and help improve the overall training procedure\n \nInception models worked well, as they mixed different filter sizes together helping the model learn diverse features\n \nMost current work is with Transformers, although Im not sure why. ConvNext shows similar performance can be achieved through large CNNs\n \n Do add to this if I missed anything, or if there's anything you don't know about\n    submitted by    /u/Bibbidi_Babbidi_Boo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2goyo/d_what_are_some_interesting_hidden_stuff_about/",
          "publishedOn": "2022-04-13T03:10:53.000Z",
          "wordCount": 1595,
          "title": "[D] What are some interesting hidden stuff about CNNs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2e4hy/d_how_to_create_scenes_with_text_makeascene/",
          "author": null,
          "description": "The authors of Make-A-Scene propose a novel text-to-image method that leverages the information from an additional input condition called a “scene” in the form of segmentation tokens to improve the quality of generated images and enable scene editing, out-of-distribution prompts, and text-editing of anchor scenes.\n As for the details, let’s dive in, shall we?\n Full summary: https://t.me/casual_gan/284\n Blog post: https://www.casualganpapers.com/text-to-image-vqvae-scene-generation/Make-A-Scene-explained.html\n Make-A-Scene\n arxiv / code (by Casual GAN Papers Community)\n Join the discord community and follow on Twitter for weekly AI paper summaries!\n    submitted by    /u/KirillTheMunchKing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2e4hy/d_how_to_create_scenes_with_text_makeascene/",
          "publishedOn": "2022-04-13T00:59:02.000Z",
          "wordCount": 219,
          "title": "[D] How to create scenes with text - Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors, a 5-minute paper summary by Casual GAN Papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u27xf2/n_substantial_plagiarism_in_baais_a_road_map_for/",
          "author": null,
          "description": "BAAI recently released a two hundred page position paper about large transformer models which contains sections that are plagiarized by over a dozen other papers.\n In a massive fit of irony, this was found by Nicholas Carlini, a research who (among other things) is famous for studying how language models copy outputs from their training data. Read the blog post here\n    submitted by    /u/StellaAthena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u27xf2/n_substantial_plagiarism_in_baais_a_road_map_for/",
          "publishedOn": "2022-04-12T19:58:40.000Z",
          "wordCount": 512,
          "title": "[N] Substantial plagiarism in BAAI’s “a Road Map for Big Models”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u24ngz/d_whats_the_status_of_live_speechtospeech/",
          "author": null,
          "description": "I've been trying to find information about the subject, but almost every result is TTS, and the only example of what I actually want (Respeecher) costs 2 grand a year. Are there any (preferably open-source) other alternatives?\n    submitted by    /u/UncertainOutcome  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u24ngz/d_whats_the_status_of_live_speechtospeech/",
          "publishedOn": "2022-04-12T17:34:20.000Z",
          "wordCount": 270,
          "title": "[D] What's the status of live speech-to-speech conversions? (not TTS)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u22sv1/comparison_of_workshops_at_major_conferences_d/",
          "author": null,
          "description": "I understand that workshop quality is dependent more on the workshop itself rather than the host conference. But, in general, how are workshops from CVPR, NeurIPS, ICLR, ICML, etc. viewed by the community in relation to one another?\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u22sv1/comparison_of_workshops_at_major_conferences_d/",
          "publishedOn": "2022-04-12T16:14:44.000Z",
          "wordCount": 293,
          "title": "Comparison of workshops at major conferences. [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u225iw/project_leniax_a_lenia_simulation_library_powered/",
          "author": null,
          "description": "Hi everyone!\n I'm really happy to finally publish the work I've been doing on the Cellular Automata called Lenia. It is a JAX library called Leniax and allows one to simulate thousands of simulations in parallel using CPU, GPU, or TPU.\n With it, you can:\n  \nSimulate Conway's Game of Life\n Simulate multiple Lenia simulations in parallel\n Use gradient descent to search for Continuous CA parameters\n Launch a QD search to discover a ton of diversity in Lenia.\n  \nCheck out the blog post for some visual results\n The main goal of this work was to advance the state of automatic discovery for those systems. 10 months ago, I bet on QD to do so, turns out it indeed works! QD algorithms really rock!\n The code is completely open-source with all the examples, notebooks, and even experiments I ran. (See the doc for more links)\n I would love to have feedback on this and of course, if you find that subject interesting, engage with our community!\n Cheers!\n    submitted by    /u/morgangiraud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u225iw/project_leniax_a_lenia_simulation_library_powered/",
          "publishedOn": "2022-04-12T15:46:31.000Z",
          "wordCount": 498,
          "title": "[Project] Leniax - A Lenia simulation library powered by JAX",
          "imageUrl": "https://external-preview.redd.it/615iFqqZGA67mbZiQWw6HCj2AOLwVrWugdMV7Amdmmo.jpg?auto=webp&s=074ecbbc8f6c41700dacf3c9607f4f8747a9e194"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u21tcd/d_effective_image_preprocessing_techniques_for/",
          "author": null,
          "description": "So I am doing some object detection on Pavement Defects. I've already collected the data with some annotations but the model is performing rather poorly. For example, the `maP` is about `0.12` for the whole data.\n By examining the data, I think one of the reasons is that some of the defects such as cracks, or faded pavement markings are not so clear and either casted by a shadow or too bright from the sun.\n Image Example #1\n Or from motion blur\n Image Example #2\n Is there any image preprocessing technique aside maybe from CLAHE that could be applied? Moreover, I am currently using YOLOv5 for this.\n    submitted by    /u/sarmientoj24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u21tcd/d_effective_image_preprocessing_techniques_for/",
          "publishedOn": "2022-04-12T15:31:27.000Z",
          "wordCount": 826,
          "title": "[D] Effective Image Pre-Processing Techniques for Enhancing Defects in an Image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1wjhx/p_the_copent_package_v023_available_on_pypi_now/",
          "author": null,
          "description": "The copent package implements the method for estimating copula entropy (mutual information) and transfer entropy (conditional mutual information / conditional independence).\n This version add a new feature (an argument 'mode') for dealing with large data when memory is limited.\n Github: https://github.com/majianthu/pycopent\n PyPI: https://pypi.org/project/copent/\n any comments are welcome.\n    submitted by    /u/majianthu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1wjhx/p_the_copent_package_v023_available_on_pypi_now/",
          "publishedOn": "2022-04-12T11:11:03.000Z",
          "wordCount": 151,
          "title": "[P] the copent package v0.2.3 available on PyPI now",
          "imageUrl": "https://external-preview.redd.it/SRxVo2wZFg9yrGulTKBIfCFE521LCeTD3tgsElbcLFM.jpg?auto=webp&s=081362182c1cf325f8745069a9852591736571f5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1vqj7/d_feedback_on_a_worked_continuous_deployment/",
          "author": null,
          "description": "Hey everyone! At ZenML, we released today an integration that allows users to train and deploy models from pipelines in a simple way. I wanted to ask the community here whether the example we showcased makes sense in a real-world setting:\n Context\n ZenML is an extensible, open-source MLOps framework to create production-ready machine learning pipelines. Built for data scientists, it has a simple, flexible syntax, is cloud- and tool-agnostic, and has interfaces/abstractions that are catered towards ML workflows. Seldon Core is a production grade open source model serving platform. It packs a wide range of features built around deploying models to REST/GRPC microservices that include monitoring and logging, model explainers, outlier detectors and various continuous deployment strategies such…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1vqj7/d_feedback_on_a_worked_continuous_deployment/",
          "publishedOn": "2022-04-12T10:21:20.000Z",
          "wordCount": 558,
          "title": "[D] Feedback on a worked Continuous Deployment Example (CI/CD/CT)",
          "imageUrl": "https://external-preview.redd.it/2DdZUH82S_pG03o_6QA8KFOOYEtP4kncEmD71nt5LcI.jpg?auto=webp&s=2f3f2da286e6c6ade38a83f41e1e7a5565aa676b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1uunt/d_can_we_decrease_the_training_time_of_a_deep/",
          "author": null,
          "description": "I am working in the retail domain atm, and train a lot of image classifiers. I have always used imagenet as pretrained to train my model upon. \n I thought it would be straightforward to train a backbone on a big retail dataset(1000+ classes), and then use that as pretrained and it'll reduce the time it takes for my models to generalize.\n Turns out, the model took more epochs to train when using the retail backbone, then the imagenet one. \n Isn't this counter-intuitive? What else can I do to make by backbone better?\n    submitted by    /u/lMAObigZEDONG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1uunt/d_can_we_decrease_the_training_time_of_a_deep/",
          "publishedOn": "2022-04-12T09:20:11.000Z",
          "wordCount": 368,
          "title": "[D] Can we decrease the training time of a deep learning model by using a domain specific pretrained backbone instead of the standard imagenet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1sofz/d_removing_unpredictable_samples_from_a_training/",
          "author": null,
          "description": "Hi,\n I have a fairly interesting project that I am working on. I have a model that has some samples which are completely unpredictable, random noise, and some that are reliably predictable.\n How would you go about separating out the samples which can be predicted, identifying them going forward, and retraining on a cleaned dataset with only those samples?\n Interested to see someone else's approach to this.\n Edit: I forgot to mention that my data is from an embedding matrix from ordinal categorical features.\n    submitted by    /u/Katapilla_Killa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1sofz/d_removing_unpredictable_samples_from_a_training/",
          "publishedOn": "2022-04-12T06:43:28.000Z",
          "wordCount": 499,
          "title": "[D] Removing Unpredictable Samples from a Training Set",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1qgcm/d_whats_your_experience_with_modelagnostic/",
          "author": null,
          "description": "There is the original paper and there was a subsequent paper by other authors titled: On the Convergence Theory of Debiased Model-Agnostic Meta_Reinforcement Learning \n I've been working on implementing the latter paper on the HalfCheetah environment. However, my attempts have been unsuccessful so far (I know the authors provided the code, but I am trying to write my own code to check my understanding). I'd like to know any tips/tricks that anyone can share and just to know about people's experiences, especially using MAML for RL.\n    submitted by    /u/carlml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1qgcm/d_whats_your_experience_with_modelagnostic/",
          "publishedOn": "2022-04-12T04:24:10.000Z",
          "wordCount": 202,
          "title": "[D] What's your experience with Model-Agnostic Meta-Learning in RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1qfxq/how_to_deal_with_the_fact_that_whatever_idea_i/",
          "author": null,
          "description": "I'm always having these ideas for projects and papers, then I look around a bit, and I find someone that has already studied that idea and published it.\n It's genuinely annoying, It's been 6 months now, and all the papers are newly published (2021 mostly) so It's even more annoying.\n How do you deal with that ? and How do you find a niche that no one is touching.\n I just started a PhD, so It's really stressing me out. I feel like I'll never be able to advance on my thesis, and that I should just quit, because better work has already been done.\n    submitted by    /u/AlanRoofies  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1qfxq/how_to_deal_with_the_fact_that_whatever_idea_i/",
          "publishedOn": "2022-04-12T04:23:12.000Z",
          "wordCount": 1293,
          "title": "How to deal with the fact that whatever idea I have has already been published.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1oh1e/p_faster_version_of_cv2bfmatchercv2norm_l2/",
          "author": null,
          "description": "Hi there, in the case if any of you use the openCV BFMatcher with NORM_L2, you can try to use my recent pet project: https://github.com/kmkolasinski/fast-bfmatcher \n Basically the speed-up is achieved by using faster replacement for BLAS, a BLIS library and some custom implementations written in C and cython.\n    submitted by    /u/kmkolasinski  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1oh1e/p_faster_version_of_cv2bfmatchercv2norm_l2/",
          "publishedOn": "2022-04-12T02:30:49.000Z",
          "wordCount": 235,
          "title": "[P] Faster version of cv2.BFMatcher(cv2.NORM_L2) optimized for keypoints matching",
          "imageUrl": "https://external-preview.redd.it/llOShRBa0UBKBDTaEs2yWiKGXsEWMb8q6lzeRocyxHc.jpg?auto=webp&s=e4e825f876472bb8b5fa07324582cd9660663b68"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1nt7m/d_are_there_any_comparison_studies_on_learning/",
          "author": null,
          "description": "My current research heavily involves generative vision transformers and after some experimentation it seems like the choice of a LR scheduler is a crucial factor for proper convergence. Does anyone know of any comparison studies done recently that explore various types of schedulers for generative tasks?\n    submitted by    /u/Megixist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1nt7m/d_are_there_any_comparison_studies_on_learning/",
          "publishedOn": "2022-04-12T01:58:05.000Z",
          "wordCount": 1169,
          "title": "[D] Are there any comparison studies on learning rate schedules for generative transformers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1mgxu/n_finetuning_layoutlm_v2_for_invoice_recognition/",
          "author": null,
          "description": "With the advent of deep learning models, automated data extraction is becoming more accessible. In this article, we demonstrate step-by-step how to fine-tune layoutLM V2 on invoices starting from data annotation to model training and inference. \n Enjoy the read and if you have any questions, leave them below.\n    submitted by    /u/UBIAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1mgxu/n_finetuning_layoutlm_v2_for_invoice_recognition/",
          "publishedOn": "2022-04-12T00:51:26.000Z",
          "wordCount": 206,
          "title": "[N] Fine-Tuning LayoutLM v2 For Invoice Recognition",
          "imageUrl": "https://external-preview.redd.it/fyAbu9z9siTBA9TKfpPoKXdl3qNr7T27W8b5wq7SLZw.jpg?auto=webp&s=62d119c6e9a5376e91b069eb934b783d243b93fc"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1jbr2/r_transformers_replicate_hippocampal/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2112.04035\n Yes, the paper is cautious about comparing the model one-to-one to the brain\n  \n“Note, we are not saying the brain is closely related to transformers because it learns the same neural representations, instead we are saying the relationship is close because we have shown a mathematical relationship between transformers and carefully formulated neuroscience models of the hippocampal formation.”\n  \nWhile objections like \"its just correlation/relation, its not exactly the same!!\" are true to an extend, its still a very unexpected observation that, they're even remotely similar. Needless to say, Transformers were not inspired from the brain - and as more evidence collates (https://www.nature.com/articles/s42003-022-03036-1 --> Activations are linearly correlatable) it does feel mysterious; perhaps atleast some of the systems used by the brain converge on an efficient pattern discovered by our backpropogated friends...\n [insert 'coincidence? I think not!' meme]\n    submitted by    /u/Competitive-Rub-1958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1jbr2/r_transformers_replicate_hippocampal/",
          "publishedOn": "2022-04-11T22:19:32.000Z",
          "wordCount": 297,
          "title": "[R] Transformers replicate Hippocampal representations; notably place and grid cells in the brain",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1c8ga/d_what_is_the_smallest_most_capable_generative/",
          "author": null,
          "description": "I'm looking for a generative-LM equivalent of an EfficientNet-Lite, for inference on devices with limited to no VRAM. I know about some popular ones like DistilGPT2. But it's been 2 years after its release. Surely, someone improved their size/performance ratio, right... right?\n Thank you for your time. 🤗\n    submitted by    /u/Deep-Station-1746  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1c8ga/d_what_is_the_smallest_most_capable_generative/",
          "publishedOn": "2022-04-11T16:55:07.000Z",
          "wordCount": 157,
          "title": "[D] What is the smallest, most capable, generative language model available now?",
          "imageUrl": "https://external-preview.redd.it/RFHXebL_232fV370fkJRpy87aB3f8NR3MgM_d32HuPo.jpg?auto=webp&s=b68cd56c65a059196f9737590029097c589cef2c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1bu8z/how_would_you_rank_major_tech_companies_research/",
          "author": null,
          "description": "This is just for fun, not to be taken too seriously. But I'm curious what are the reputations among the community for various research divisions (specifically AIML) of major companies, ie: Google, Facebook/Meta, Microsoft, Amazon, NVIDIA, IBM, etc.\n My perceived (albeit naive) view is Google > Facebook > MSR are top tier. Don't know much about the others. But I've read that some people consider MSR most prestigious due to their academic environment. But I've seen that Google and FB dominate in terms of major publications, ie: vision transformers are associated with Google. \n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1bu8z/how_would_you_rank_major_tech_companies_research/",
          "publishedOn": "2022-04-11T16:37:33.000Z",
          "wordCount": 723,
          "title": "How would you rank major tech companies' research labs for prestige? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u19io6/p_squirrel_a_new_os_library_for_fast_flexible/",
          "author": null,
          "description": "Hi all, \n Today we open-sourced Squirrel, a data infrastructure library that my colleagues and I have been working on over the past 1.5 years: https://github.com/merantix-momentum/squirrel-core\n We’re a team of ~30 ML engineers developing machine learning solutions for industry and research. Across all our projects, we need to load large-scale data in a fast and cost-efficient way, while keeping the flexibility to work with any possible dataset, loaded from local storage, remote data buckets or via APIs such as HuggingFace. Not finding what we were looking for, we decided to build it ourselves. \n Squirrel has already proven its value in our deep learning projects at Merantix Momentum and shows competitive benchmark results (check them out here). \n We’re super excited to share it with the OSS community and hope that you can benefit from it as well! \n Looking forward to hearing your feedback and questions :)\n    submitted by    /u/Nextpenade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u19io6/p_squirrel_a_new_os_library_for_fast_flexible/",
          "publishedOn": "2022-04-11T14:50:45.000Z",
          "wordCount": 428,
          "title": "[P] Squirrel: A new OS library for fast & flexible large-scale data loading",
          "imageUrl": "https://external-preview.redd.it/nBo-oTq4WtunYq6ceVofwf4ptrB3NQugxyXvVUGuVJ0.jpg?auto=webp&s=9d1c331c0db5fd89dfa002595c452f87f6f2b1db"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u18ryi/p_renting_lots_of_gpus_100200_in_single/",
          "author": null,
          "description": "I want to apply an already trained ML model on a huge textual data set. I have funds to rent Cloud GPUs, but have not much experience using them. Preferably, I do the setting up of the environment only once (downloading of the data, model, software packages, etc) only once and then simply send ~100-200 scripts each to their own GPU for processing. Then at the end everything is in the same location and I can easily send back the final result file (~100-200 output files concatenated together) back to my PC.\n Any advice on how to do that? All GPU renting servers only have 1-8 GPUs per server and do not (seem) to allow for sharing of the environment, which seems very inefficient to me. All comments are appreciated.\n    submitted by    /u/Intelligent-End2673  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u18ryi/p_renting_lots_of_gpus_100200_in_single/",
          "publishedOn": "2022-04-11T14:15:57.000Z",
          "wordCount": 486,
          "title": "[P] Renting lots of GPUs (100-200) in single environment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u153d3/rp_algorithmic_stability_of_minibatch_sgd/",
          "author": null,
          "description": "Hi, was wondering if anyone else has looked into \"A PAC-Bayesian Analysis of Randomized Learning\n with Application to Stochastic Gradient Descent\" and in particular eqn. 2, which is the derivation of Section 3.5 of \"Train faster, generalize better: Stability of stochastic gradient descent\" adapted for the case where the underlying loss we are interested in guaranteeing generalisation for is upper bounded by M (rather than 1 as assumed by Hardt et al).\n In the case of minibatch SGD, the number of datapoints n becomes the number of minibatches, as ideally one would like to reduce the number of steps T by maximizing the learning rate, which requires maximizing the minibatch size for the loss to actually converge to 0 on the training data. \n However, what I am unsure about is, specifically for the classification task where we typically minimize the cross-entropy objective, whether the cross-entropy objective is an upper bound on any kind of M-bounded loss function. In the ideal world, I would like to show that it upper bounds the 0-1 loss which means the cross-entropy over the dataset is an upper bound on the classification accuracy and any generalization statement automatically becomes a statement about the very practical metric of accuracy. \n Such a statement about cross-entropy upper-bounding 0-1 is made in Section 3C of \"Theoretical Issues in Deep Networks: Approximation, Optimization and Generalization\". However, one can provide a counterexample in the limit of the softmax \"temperature\" parameter where the predicted class distribution becomes uniform, in the case of 2 classes, for the typical case of log being the natural logarithm (it is no longer a counter-example if log base 2 is used).\n I haven't been able to show or find proof that this statement \"xent >= 0-1\" is true (for some logarithm base and some number of classes) and was hoping that someone might have.\n    submitted by    /u/wakeupandshave  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u153d3/rp_algorithmic_stability_of_minibatch_sgd/",
          "publishedOn": "2022-04-11T11:01:01.000Z",
          "wordCount": 394,
          "title": "[R][P] Algorithmic stability of minibatch SGD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u12eoc/r_channel_augmented_joint_learning_for/",
          "author": null,
          "description": "Since going open source in March 2020, MindSpore gone from strength to strength. The deep learning framework has been downloaded by over 1.2 million users; algorithms running on MindSpore have been published in AI journals or presented at conferences; and countless developments have been released in device-edge-cloud scenarios to transform business fields, such as intelligent manufacturing, cloud, wireless, data communication, energy, and consumer business. \n Built on extensive experience from the scientific, academic, and industrial sectors, MindSpore-based AI papers accounted for 11% of all AI papers in October 2021, ranking No.2 worldwide by month, and No.3 worldwide in Q4 2021. In this blog post, based on a paper published in ICCV 2021 by Professor Mang Ye of Wuhan University, we intro…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u12eoc/r_channel_augmented_joint_learning_for/",
          "publishedOn": "2022-04-11T07:55:32.000Z",
          "wordCount": 822,
          "title": "[R] Channel Augmented Joint Learning for Visible-Infrared Recognition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0xgq5/r_looking_for_ideas_in_pretraining_a_rl_agent/",
          "author": null,
          "description": "Hi all,\n I've been working on reinforcement learning lately, but wanted to come to the general ML subreddit to seek inspiration from other disciplines.\n I've been working on strategies to decrease the training time for my real-world inverted pendulum experiment. Specifically, I am trying to pre-train the Q network in a simulation before deploying.\n The strategy that I have found most successful right now is this:\n start with randomly generated weights\n REPEAT OF AN EPOCH:\n - Load new_weights to Q Network\n - initialize an environment with randomly generated parameters (i.e. random mass, lengths, etc).\n - Train agent on environment for 100 episodes\n - Save new_weights\n I have tried a variety of strategies to add a little bit more control over this process. I've tried a soft update that never showed improvement.\n W = old_weights * (1 - alpha) + new_weights * alpha \n I have tried an additive update which was slightly successful. Measured the success of each network as the sum of rewards over the epoch.\n A = (old_R)/(old_R+new_R) ; B = (new_R)/(old_R+new_R) W = old_weights * A + new_weights * B \n But none of these work as well as just using the most recent weights. I've included some results if anyone's interested. The first graph is three test trials with random initial weights, the second graph is with pre-trained weights.\n This is a pretty hand-wavy way of doing this, does anyone have any suggestions to do this better?\n ​\n https://preview.redd.it/9mnewmibbts81.png?width=375&format=png&auto=webp&s=a6ff866a31987375d276d12f69dbe2af40380bf4\n https://preview.redd.it/096n7ctcbts81.png?width=375&format=png&auto=webp&s=b19d800fbb416fca288e86640d9458c8993e0759\n ​\n    submitted by    /u/nickthorpie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0xgq5/r_looking_for_ideas_in_pretraining_a_rl_agent/",
          "publishedOn": "2022-04-11T02:38:36.000Z",
          "wordCount": 525,
          "title": "[R] Looking for Ideas in Pre-training a RL Agent",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0x8lr/p_recommendations_for_high_frequency_multivariate/",
          "author": null,
          "description": "Hey there! I'm looking for advice on datasets to use for a project. We are looking for the following traits:\n ​\n 1) Multivariate (at least 3 or 4, and probably no more than 50 or 100 as an upper bound).\n 2) High frequency (Ideally at least once every 5-10 minutes)\n 3) We need to have some notion of an underlying 'state' of the data for certain windows. E.g. in an energy setting, period X was the 'family at home using appliances' state. Or in the healthcare setting, period X is 'the patient is in a stable state' while period Y is something like 'the patient experiences a cardiac event'\n ​\n ​\n Nice to have:\n 4) It'd be great if some features had some level of seasonality while others didn't.\n ​\n ​\n Do folks have any recommendations for datasets that meet some (or hopefully all) of the criteria? I did some light pursuing on UCI, but it seems like much of it is not high frequency enough, and/or doesn't have some notion of underlying states.\n    submitted by    /u/CS_Student95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0x8lr/p_recommendations_for_high_frequency_multivariate/",
          "publishedOn": "2022-04-11T02:25:48.000Z",
          "wordCount": 286,
          "title": "[P] Recommendations for high frequency multivariate time series data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0vqjt/d_what_to_do_when_the_authors_dont_release_source/",
          "author": null,
          "description": "Hello,\n I am currently working on a research paper that I aim to publish at a reputable conference shortly. In our work, we borrow a feature engineering technique from one of the papers that have not been previously applied to the domain (time series AD) before that paper. However, the authors haven't released the source code of their implementation of the model (but the feature engineering technique is publicly available). I feel like that is an important baseline and just failing to include it would get my paper rejected. I have contacted all the authors for the source code, but none of them responded. The architecture they use is a fairly complicated one and would be very difficult to implement on my own. How do I go about this situation? My advisor told me I can just include a few points on the footnote on why we don't include this as a baseline. Those being:\n  \nNo open-source implementation\n Contacted the authors, didn't receive a response\n The paper has not been published, only uploaded to arxiv.\n  \nAny help is appreciated!\n    submitted by    /u/mythrowaway0852  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0vqjt/d_what_to_do_when_the_authors_dont_release_source/",
          "publishedOn": "2022-04-11T01:04:44.000Z",
          "wordCount": 1366,
          "title": "[D] What to do when the authors don't release source code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0pnhf/d_machine_learning_wayr_what_are_you_reading_week/",
          "author": null,
          "description": "This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.\n Please try to provide some insight from your understanding and please don't post things which are present in wiki.\n Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.\n Previous weeks :\n  \n 1-10 11-20 21-30 31-40 41-50 51-60 61-70 71-80 81-90 91-100 101-110 111-120 121-130 131-140 \n  \n Week 1 Week 11 Week 21 Week 31 Week 41 Week 51 Week 61 Week 71 Week 81 Week 91 Week 101 Week 111 Week 121 Week 131 \n  Week 2 Week 1…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0pnhf/d_machine_learning_wayr_what_are_you_reading_week/",
          "publishedOn": "2022-04-10T20:00:05.000Z",
          "wordCount": 370,
          "title": "[D] Machine Learning - WAYR (What Are You Reading) - Week 135",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0o0yy/n_dalle_2_explained/",
          "author": null,
          "description": "submitted by    /u/giugiacaglia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0o0yy/n_dalle_2_explained/",
          "publishedOn": "2022-04-10T18:43:10.000Z",
          "wordCount": 381,
          "title": "[N]: Dall-E 2 Explained",
          "imageUrl": "https://external-preview.redd.it/n8IIbUhDqblAvhWT_2j8I3rFpnYCJHu2EXvFcwTsUBw.png?format=pjpg&auto=webp&s=659ec2bd0f15d62be0f1f7c4958ac6240b8e9bbc"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0l0mr/r_use_static_classifiers_for_dynamic_point_cloud/",
          "author": null,
          "description": "submitted by    /u/pinter69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0l0mr/r_use_static_classifiers_for_dynamic_point_cloud/",
          "publishedOn": "2022-04-10T16:22:11.000Z",
          "wordCount": 384,
          "title": "[R] Use static classifiers for dynamic point cloud tasks (3D) and use action classifiers for temporal anomaly detection (2D) - Link to a free online lecture by the author in comments",
          "imageUrl": "https://preview.redd.it/83rwnhi09qs81.png?auto=webp&s=c728fcc9ebb1e12e39638b511e1e2824620098dc"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0jcur/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0jcur/d_simple_questions_thread/",
          "publishedOn": "2022-04-10T15:00:11.000Z",
          "wordCount": 742,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0hxt3/p_image_similarity_metrics_or_algorithms/",
          "author": null,
          "description": "I want to perform image similarity between images from frames of 2 different movie trailers.\n I am currently using SSIM and VGG 16 individually. But ssim does not capture color differences and VGG 16 isn't capturing structural integrity.\n I can use both together, but I wanted to know if there is any metric or algorithm which can capture both together with less discrepancies and can capture both together.\n Will appreciate any help. Thank you!\n    submitted by    /u/terminatorash2199  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0hxt3/p_image_similarity_metrics_or_algorithms/",
          "publishedOn": "2022-04-10T13:47:40.000Z",
          "wordCount": 257,
          "title": "[P] image similarity metrics or algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0gzj1/r_interested_in_a_postdoctoral_position_bridging/",
          "author": null,
          "description": "Recurrent neural networks for brain time series - Sano Centre for Computational Personalised Medicine\n    submitted by    /u/alecrimi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0gzj1/r_interested_in_a_postdoctoral_position_bridging/",
          "publishedOn": "2022-04-10T12:53:33.000Z",
          "wordCount": 128,
          "title": "[R] Interested in a Postdoctoral position bridging machine learning and neuroimaging?",
          "imageUrl": "https://external-preview.redd.it/S-7Mycs1ox3O3jblU7djEweOTY6MG2OB2syVwOCtbEQ.jpg?auto=webp&s=8b371d6c6e8fa35b8c76f7e420181abcfc2f9a56"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0fy91/r_ml_with_intermediate_mathematics_vaes_with/",
          "author": null,
          "description": "Hi everyone, I'd like to share with you an exciting upcoming live series by Prof. Richard Xu of Hong Kong Baptist University. If you're interested, please click here to register!\n Description:\n \"I have been planning to start a machine learning live series on topics that involve some intermediate mathematics, so I can help you to clarify some concepts. In order to fully grasp these concepts, you need to have sound knowledge of linear algebra, calculus, statistics and probability. However, if you just want to come and hear it for fun, please do so as well!\n The first topic is variational autoencoders with normalized flow, which I'll fully explain its beautiful mathematics over a period of a few sessions. You can find my notes on my GitHub site:\n https://github.com/roboticcam/machine-learning-notes/blob/master/files/vb_nf.pdf\n I will post the Zoom link to the registered participants.\n Please join us!\"\n    submitted by    /u/ML_Live_Series  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0fy91/r_ml_with_intermediate_mathematics_vaes_with/",
          "publishedOn": "2022-04-10T11:47:09.000Z",
          "wordCount": 265,
          "title": "[R] ML with Intermediate Mathematics: VAEs with Normalized Flow (live series)",
          "imageUrl": "https://external-preview.redd.it/oKKtQehlimflM197aRFqGePysY5QuTwX9irvWGFhjZA.jpg?auto=webp&s=00f41e12502ebdf989fa76871a5378f265b9253d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0fb2m/research_issues_visualising_a_resnet/",
          "author": null,
          "description": "Hi all,\n We have a model used in cardiac MRi imaging, it is used to select the best image in a series of images. It consists of images -> Resnet -> LSTM -> output.\n The heatmap we generate from the Resnet alone shows output like the image attached, instead of actual anatomy, there is only little squares. We think this is likely due to the residual in the Resnet because it is not present in a VGG, but does anyone else have a better explanation, and an idea of how to visualise a Resnet?\n Resnet Saliency Map\n    submitted by    /u/Radiology_AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0fb2m/research_issues_visualising_a_resnet/",
          "publishedOn": "2022-04-10T11:00:37.000Z",
          "wordCount": 222,
          "title": "[research] Issues visualising a Resnet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0e7n8/r_critical_analysis_of_deconfounded_pretraining/",
          "author": null,
          "description": "Hi reddit, happy to share our new paper \"Critical analysis of deconfounded pretraining to improve visio-linguistic models\".\n In a nutshell, it's on the problem of out-of-distribution performance for visio-linguistic models, and it takes a closer look / surfaces some issues with an existing technique for improving OOD performance by doing automatic deconfounding (inspired by the causality framework of Structural Causal Models).\n ​\n  \nPaper: https://www.frontiersin.org/articles/10.3389/frai.2022.736791/full\n Code: https://github.com/Natithan/p1_causality\n Abstract: \n An important problem with many current visio-linguistic models is that they often depend on spurious correlations. A typical example of a spurious correlation between two variables is one that is due to a third variable causing …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0e7n8/r_critical_analysis_of_deconfounded_pretraining/",
          "publishedOn": "2022-04-10T09:33:54.000Z",
          "wordCount": 465,
          "title": "[R] Critical analysis of deconfounded pretraining to improve visio-linguistic models",
          "imageUrl": "https://external-preview.redd.it/TAGvv79NiijwKxfyNPikPCSnhXUmDO4oPUJbv76dfi0.jpg?auto=webp&s=5b66228698688ca6fb3f24635b929041d9d70712"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0ckoe/best_papers_that_solve_novel_problems_d/",
          "author": null,
          "description": "We often talk about how the publish-or-perish paradigm leads to constant minor improvements on the same problems (Image classification, text generation, etc). What are some of the best papers that do the opposite? Rather than solving known problems in a marginally better way, they solve a new problem with known (or modified) methods.\n    submitted by    /u/SuspiciousWalrus99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0ckoe/best_papers_that_solve_novel_problems_d/",
          "publishedOn": "2022-04-10T07:26:12.000Z",
          "wordCount": 488,
          "title": "Best Papers That Solve Novel Problems? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0cgmz/discussion_advice_on_training_document_layout/",
          "author": null,
          "description": "So, a bit of background, I am doing an RnD project in the area of improving the layout analysis of scientific documents. The proposed method is to use an active learning loop on standard object detection models and target those classes/layouts which are performing poorly and train the model based on them.\n Now, we have some selection strategies based on submodular selection functions to target the pages we want. I also have set up code to extract embeddings which will help me do the selection. But I don't have prior experience in active learning, especially setting it up with detectron2, because it seems to register a dataset to train, and it is really difficult to change dynamically in the middle of training, which is my use case.\n So I need some advice on the following:-\n  \nThe document analysis datasets are huge, DocBank is 50GB of images alone. How can I effectively store the embeddings in memory when I will call my selection algorithms mentioned above?\n How to set up an active learning loop in detectron2 for object detection. Or are there any alternatives? Some resources/code would be better\n There is some literature evidence suggesting that simple CNN backbone embeddings represent an image better than FasterRCNN or MaskRCNN embeddings. Specifically, this paper seems to be working on spliced image retrieval and it claims the following. Any thoughts/prior experience on this?\n Finally, is there any evidence supporting improvement in accuracy/precision in object detection using active learning? Or are there some better training paradigms?\n  \nThank you for your patience.\n    submitted by    /u/ExoticAd6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0cgmz/discussion_advice_on_training_document_layout/",
          "publishedOn": "2022-04-10T07:17:30.000Z",
          "wordCount": 347,
          "title": "[Discussion] Advice on training document layout analysis models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0a0kd/d_market_basket_analysis_realworld_examples_and/",
          "author": null,
          "description": "I want to know more about Market Basket Analysis's real-world use case and unique insights/business value derived from performing the Association rule mining. \n I heard about the Beer-Diaper case study but many other sources invalidated it as a spurious correlation. Can someone share any example of business insights from Market Basket analysis and any interesting patterns they were able to observe??\n    submitted by    /u/invincible_moron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0a0kd/d_market_basket_analysis_realworld_examples_and/",
          "publishedOn": "2022-04-10T04:25:35.000Z",
          "wordCount": 452,
          "title": "[D] Market Basket Analysis real-world examples and insights?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u084uh/d_how_are_multiple_training_examples_used_in_dmd/",
          "author": null,
          "description": "The examples I have seen so far for DMD and SINDy use only 1 trajectory of the dynamical system for training. The input data is a 2D matrix, with the states/features being one dimension and time being the other dimension. But I want to use multiple trajectories of the same dynamical system for training, so the training data would be 3D (i.e., multiple 2D matrices). Are there examples where this has been done?\n Linear regression techniques (like pseudoinverse or LASSO) seem to be used to get the system matrix (in DMD) or the weights for the features (in SINDy). Can these methods be extended to 3D input data?\n    submitted by    /u/baigyaanik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u084uh/d_how_are_multiple_training_examples_used_in_dmd/",
          "publishedOn": "2022-04-10T02:28:22.000Z",
          "wordCount": 379,
          "title": "[D] How are multiple training examples used in DMD, SINDy, etc.?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u02p5x/r_local_learning_matters_rethinking_data/",
          "author": null,
          "description": "#cvpr-2022\n Happy to share our CVPR-2022 paper \"Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning\"\n Paper: https://arxiv.org/pdf/2111.14213.pdf\n Code: https://github.com/mmendiet/FedAlign\n Federated learning (FL) is a promising strategy for performing privacy-preserving, distributed learning with a network of clients (i.e., edge devices). However, the data distribution among clients is often non-IID in nature, making efficient optimization difficult. To alleviate this issue, many FL algorithms focus on mitigating the effects of data heterogeneity across clients by introducing a variety of proximal terms, some incurring considerable compute and/or memory overheads, to restrain local updates with respect to the global model. Instead, we consider rethinking solutions to data heterogeneity in FL with a focus on local learning generality rather than proximal restriction. To this end, we first present a systematic study informed by second-order indicators to better understand algorithm effectiveness in FL. Interestingly, we find that standard regularization methods are surprisingly strong performers in mitigating data heterogeneity effects. Based on our findings, we further propose a simple and effective method, FedAlign, to overcome data heterogeneity and the pitfalls of previous methods. FedAlign achieves competitive accuracy with state-of-the-art FL methods across a variety of settings while minimizing computation and memory overhead.\n    submitted by    /u/Extension-Sun1816  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u02p5x/r_local_learning_matters_rethinking_data/",
          "publishedOn": "2022-04-09T21:25:49.000Z",
          "wordCount": 295,
          "title": "[R] Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzvxb9/d_icml2022_domain_conflicts_system/",
          "author": null,
          "description": "I was wondering if the Domain conflicts system working well?\n I got an email from the PCs and seems that the domain conflict system is not working well. It said that we can enter the conflict now but I cannot edit the conflict in the system. Could anyone tell me how to do it? Thanks!\n  \nDear ICML Authors, \n As we are seeing this happen, we just wanted to send you a brief explanation -- this only applies to some few papers. A few papers are losing reviews because of newly arising conflicts. If you did not enter your conflicts in CMT during the submission phase (as requested via CMT), then they could not be used in paper assignments. If you enter them now, any reviews by reviewers with conflicting domains will disappear, and you may see fewer reviews as a result. Unfortunately, we have no control over this, as the conflicts should have been entered when the paper was submitted. \n Best, \n Stefanie, Le and Csaba\n  \n   submitted by    /u/Snoo_97274  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzvxb9/d_icml2022_domain_conflicts_system/",
          "publishedOn": "2022-04-09T15:47:54.000Z",
          "wordCount": 249,
          "title": "[D] ICML2022 Domain conflicts system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzp4kv/d_poll_how_do_you_deploy_models_endpoints/",
          "author": null,
          "description": "View Poll\n    submitted by    /u/martolini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzp4kv/d_poll_how_do_you_deploy_models_endpoints/",
          "publishedOn": "2022-04-09T08:47:40.000Z",
          "wordCount": 179,
          "title": "[D] Poll: How do you deploy models & endpoints?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzowos/rp_generate_images_from_text_with_latent/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzowos/rp_generate_images_from_text_with_latent/",
          "publishedOn": "2022-04-09T08:30:09.000Z",
          "wordCount": 447,
          "title": "[R][P] Generate images from text with Latent Diffusion LAION-400M Model + Gradio Demo",
          "imageUrl": "https://preview.redd.it/58fjuz70sgs81.png?auto=webp&s=849a5c0a11df3431e2e785b4e7bba43547fd2ae2"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzouo4/p_tinydl_library_to_help_with_hyperparameter/",
          "author": null,
          "description": "Hi everyone,\n I built a small library to help with hyperparameter search for deep learning models created with pytorch, because I got kinda tired of having to rewrite large pieces code over and over again.\n You can check it out here: https://github.com/michi-jeremias/tinydl or you can even install it with pip (pip install tinydl). I have included a readme and an example of how the library can be used.\n About the library, it's pretty flexible about reporting different metrics to the console and to tensorboard (add_scalar, add_hparam) at each stage of the process, like after a batch, epoch of after a whole run over multiple epochs. It can also be easily extended to include other metrics or new types of outputs.\n Since this is basically my first attempt at a software project that's not intended only to be used by myself I'd be happy about any feedback you have for me!\n If the project doesn't qualify to be posted here due to being too simple/too much on a beginner level, apologies for that.\n    submitted by    /u/abacaxiquaxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzouo4/p_tinydl_library_to_help_with_hyperparameter/",
          "publishedOn": "2022-04-09T08:26:02.000Z",
          "wordCount": 283,
          "title": "[P] tinydl - library to help with hyperparameter search and metric reporting in pytorch",
          "imageUrl": "https://external-preview.redd.it/LAHK1MYtwhgtja_z8t-OxpLe_RGNXrgwE2G9Vcnyza8.jpg?auto=webp&s=4da53c43496a4a8b26c374fab44c26f0fe4664ca"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzoqg2/d_stylegan2_path_length_regularization/",
          "author": null,
          "description": "I am trying to implement stylegan2 and there are so many things here that are not explained either well, or at all in the paper.\n ​\n  \nHow exactly is path length regularization implemented? In this PT code we can see that the $|J^T_w.y|$ is computed as follows:\n  \n​\n def g_path_regularize(fake_img, latents, mean_path_length, decay=0.01): noise = torch.randn_like(fake_img) / math.sqrt( fake_img.shape[2] * fake_img.shape[3] ) grad, = autograd.grad( outputs=(fake_img * noise).sum(), inputs=latents, create_graph=True ) path_lengths = torch.sqrt(grad.pow(2).sum(2).mean(1)) path_mean = mean_path_length + decay * (path_lengths.mean() - mean_path_length) path_penalty = (path_lengths - path_mean).pow(2).mean() return path_penalty, path_mean.detach(), path_lengths \n This is based on this official TF implementation.\n The problem I have is that from what I understand, fake_img is 4D, and latents is 2D. The grad output in this case will be 2D and grad.pow(2).sum(2) cannot be computed because the third axis does not exist. Obviously people who are using these repos have not reported any issue regarding mismatch of shapes and axes, so I believe there is something else going on. Since I'm trying to implement this in my own network, I cannot get the desired shape any how. I get a 2D gradient output.\n    submitted by    /u/feryet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzoqg2/d_stylegan2_path_length_regularization/",
          "publishedOn": "2022-04-09T08:16:53.000Z",
          "wordCount": 280,
          "title": "[D] StyleGAN2 Path Length Regularization Implementation Clarification",
          "imageUrl": "https://external-preview.redd.it/O-Qa83OpjON3SWHV-wEplWm6hveg9MwnypL-8LbGhj0.jpg?auto=webp&s=5f87229a3d481d78fb390659e8ae68f1dd7cb61c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzo5ih/p_jaxhaiku_pretrained_models_mobilenet_resnet_vgg/",
          "author": null,
          "description": "I released a repository of models with optional pretrained weights(Weights are taken from TF/Keras) to be used for tasks like prediction, feature extraction and fine-tuning.\n Github: https://github.com/abarcel/haikumodels\n Currently Available Models\n  \nMobileNet\n ResNet [50, 101, 152]\n VGG [16, 19]\n Xception\n  \nAlso planning to release more, as soon as I find time for it.\n    submitted by    /u/abarcel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzo5ih/p_jaxhaiku_pretrained_models_mobilenet_resnet_vgg/",
          "publishedOn": "2022-04-09T07:31:55.000Z",
          "wordCount": 143,
          "title": "[P] Jax/Haiku pretrained models: MobileNet, ResNet, VGG, Xception.",
          "imageUrl": "https://external-preview.redd.it/XjGrYB5ZZF-dofoIIZW3gcfGriVD2PvY0cLghzZCTaY.jpg?auto=webp&s=4f0457113cf97eb52cfefb596f2a88fe97274084"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tznijk/d_denoising_in_the_latent_space/",
          "author": null,
          "description": "I spent some time reading about and playing around with speech denoising DNNs ~2019. At the time the popular architecture was U-Net (encoder -> bottleneck -> decoder with skip connections) operating on spectrograms. These U-Nets were trained directly on noisy/clean speech pairs and the loss was the difference between the predicted denoised images and actual denoised image. MSE between the predicted/actual images was a baseline loss but people alse added \"feature loss\" or sometimes a GAN-based loss function as well.\n Anyway a cursory reading of the DALL-E 2 paper has me thinking about that approach. I'm curious to know if a similar approach used for DALL-E has been tried for audio denoising:\n  \npre-train an encoder/decoder in a self-supervised fashion on a large dataset of audio\n train a denoiser to operate only in the latent space (ie the most compressed representation that is passed from the encoder to the decoder)\n  \nstep 1 - self-supervised training of encoder/decoder\n https://preview.redd.it/nprc40ob9gs81.png?width=1668&format=png&auto=webp&s=3a9b181ceff6c4530b5f41abf793dfb6409c0ec2\n step 2 - train denoiser in latent space only\n ​\n https://preview.redd.it/hreajdpe9gs81.png?width=1279&format=png&auto=webp&s=e16490fff00fe82487ca214b11b642ffcb30fb1c\n step 3 - do inference by feeding denoised latent space vector into the decoder\n https://preview.redd.it/7nox4ezh9gs81.png?width=2034&format=png&auto=webp&s=ccc69bbb2096d84a9e4a824000e62bb0f80fbe29\n Is this a common approach already? It seems like once you have a good pretrained encoder/decoder pair then the denoiser training would be much more efficient than training an entire network that does everything at once from scratch (smaller search space, faster training loop)\n    submitted by    /u/The_Amp_Walrus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tznijk/d_denoising_in_the_latent_space/",
          "publishedOn": "2022-04-09T06:46:23.000Z",
          "wordCount": 382,
          "title": "[D] Denoising in the latent space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzhbxj/discussion_mlops_vs_platform_engineering/",
          "author": null,
          "description": "Hey guys, I have the opportunity to either move to the platform engineering team or the freshly created MLOps team within my company. I'm interested in both careers, as I like to build Infra. I'm currently a Data Eng, and I find myself to like building apps and enabling applications to talk to each other, better than cleaning up data. I worked as a data scientist before, but I didn't like the science. I was always into engineering. What would make sense from a career perspective (both long and short term), i.e., money, promotions, attractiveness, etc.\n    submitted by    /u/dash2392  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzhbxj/discussion_mlops_vs_platform_engineering/",
          "publishedOn": "2022-04-09T00:27:17.000Z",
          "wordCount": 185,
          "title": "[Discussion] MLOps vs Platform Engineering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzg9p2/d_any_guesstimates_for_how_much_a_dalle_2/",
          "author": null,
          "description": "Just based on the estimated running costs of GPT3, and then whatever profit gets applied on top of that, are there any estimates for what openai will eventually charge for image generation?\n    submitted by    /u/EugeneJudo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzg9p2/d_any_guesstimates_for_how_much_a_dalle_2/",
          "publishedOn": "2022-04-08T23:29:44.000Z",
          "wordCount": 254,
          "title": "[D] Any guesstimates for how much a DALLE 2 generation will eventually cost?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzf2r1/problem_with_cvpr_template_and_arxiv_d/",
          "author": null,
          "description": "I don't know what would be the best place to post this. But I am having trouble uploading an Overleaf manuscript to arXiv based on the CVPR 2022 template. I am getting the following error. Does anyone have any ideas?\n ​\n https://preview.redd.it/y9jq0rbysds81.png?width=1614&format=png&auto=webp&s=16be3d32468837f649e846ec8a309dab2854c762\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzf2r1/problem_with_cvpr_template_and_arxiv_d/",
          "publishedOn": "2022-04-08T22:29:46.000Z",
          "wordCount": 135,
          "title": "Problem with CVPR template and arXiv? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tze09r/rsocratic_models_composing_zeroshot_multimodal/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2204.00598\n https://socraticmodels.github.io/\n Twitter: https://twitter.com/andyzengtweets/status/1512089759497269251\n Abstract: \" Large foundation models can exhibit unique capabilities depending on the domain of data they are trained on. While these domains are generic, they may only barely overlap. For example, visual-language models (VLMs) are trained on Internet-scale image captions, but large language models (LMs) are further trained on Internet-scale text with no images (e.g. from spreadsheets, to SAT questions). As a result, these models store different forms of commonsense knowledge across different domains. In this work, we show that this model diversity is symbiotic, and can be leveraged to build AI systems with structured Socratic dialogue -- in whi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tze09r/rsocratic_models_composing_zeroshot_multimodal/",
          "publishedOn": "2022-04-08T21:37:47.000Z",
          "wordCount": 333,
          "title": "[R]Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language - Google Apr 2022",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzcnwb/d_what_to_do_next_after_the_sanity_check/",
          "author": null,
          "description": "I have two years of time-series data taken from two sensors which I have split into 80/10/10 non-overlapping train/val/test splits. The task is to denoise one sensor data into another and I am handling it as a regression problem.\n I am following this website and considered an already published model (5 convolutional and 1 fully connected layer) which is trained on a similar dataset and same task.\n For the sake of sanity check, as per the website, I have trained the model on a subset of trainset (3 months) and tried to overfit it (while evaluating on complete val set), which works fine.\n However, I am not sure what to do next from this point on? Shall I just train on the complete trainset now? Or do I increase the layers or play with other hyper params to find more details about my regression problem/data? I would really appreciate your comments. Thank you.\n PS. The target value is sparse i.e. more than 85% of the time it is zero.\n    submitted by    /u/muaz_usmani  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzcnwb/d_what_to_do_next_after_the_sanity_check/",
          "publishedOn": "2022-04-08T20:33:36.000Z",
          "wordCount": 266,
          "title": "[D] What to do next after the sanity check?",
          "imageUrl": "https://external-preview.redd.it/ts0z7cd5buLjkX6R5TQi7kMqPtwQY7jK8s3fPJ8fANQ.jpg?auto=webp&s=617f0844a3718900a927c1e1fa7130f4dfa3765e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz9obh/d_leaving_ml_for_software_engineering/",
          "author": null,
          "description": "I'm keen to hear from people who have made the transition from ML Research/Engineering positions to software engineering roles (or who are considering it). What were your reasons for doing it and did you regret it? I see so many articles about transition from software to ML but none about going the opposite direction.\n Context: I've been working as an ML Engineer for a little over a year, and I'm just... not enjoying it. I want to love my job so badly as I like my boss, my colleagues, and the company (and I'm paid quite well for my level), but I just don't. I feel like the type of work I'm doing is not very smart and yet it's extremely draining: I spend so many hours just looking at loss curves, tweaking features and parameters. I'm somehow bored and stressed at the same time, because I don't enjoy the work and yet I feel the pressure to produce good models, and when they don't work as expected I can't help but take it personally as if if I just tried hard enough they would work. I find that the days were I end up having to take care of more purely engineering tasks I just have a lot more fun and I finish the day more satisfied and less drained. I think I just want to build something instead of spending hours banging my head against shit data. I would love to hear from people who feel or have felt the same way because whenever I speak about this with friends who are in ML they look at me like I'm a lunatic for wanting to leave it for software engineering.\n I'm obviously aware that swe roles are not all fun and games, but I just feel like there's been an excessive push for so many people to move to ML as it's \"cool\" and \"smart\" when in reality they're just different things who are going to suit different people.\n    submitted by    /u/hedy-m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz9obh/d_leaving_ml_for_software_engineering/",
          "publishedOn": "2022-04-08T18:12:46.000Z",
          "wordCount": 1541,
          "title": "[D] Leaving ML for Software Engineering?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz6izi/d_is_virtual_iclr_2022_worth_paying_for/",
          "author": null,
          "description": "The 2022 ICLR conference at the end of this month is virtual and costs $100 to attend. I was thinking of attending for networking opportunities but I’m not sure. Is it a good idea to go for it?\n    submitted by    /u/sybar142857  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz6izi/d_is_virtual_iclr_2022_worth_paying_for/",
          "publishedOn": "2022-04-08T15:49:34.000Z",
          "wordCount": 349,
          "title": "[D] Is virtual ICLR 2022 worth paying for",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz50is/d_triplet_vs_contrastive_loss/",
          "author": null,
          "description": "The online triplet mining strategy is more efficient than the offline one. It implies \"getting a batch of n samples and their associated labels, and form triplets on the fly.\" Here is an article about Triplet vs. Contrastive Loss comparison and its efficient implementation. I would like to know your feedback.\n    submitted by    /u/devzaya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz50is/d_triplet_vs_contrastive_loss/",
          "publishedOn": "2022-04-08T14:38:54.000Z",
          "wordCount": 140,
          "title": "[D] Triplet vs. Contrastive Loss",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz4dic/p_animated_character_generator/",
          "author": null,
          "description": "Hello everybody,\n I'd like to share the latest machine learning project of mine. It allows one to generate animated characters in the style of old video game consoles. Here are some examples. I would appreciate any feedback.\n https://i.redd.it/sig6ilpi8bs81.gif\n https://i.redd.it/xaf906qi8bs81.gif\n https://i.redd.it/8v7lz2qi8bs81.gif\n    submitted by    /u/ie9res  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz4dic/p_animated_character_generator/",
          "publishedOn": "2022-04-08T14:08:32.000Z",
          "wordCount": 122,
          "title": "[P] Animated Character Generator",
          "imageUrl": "https://external-preview.redd.it/GwQJ7G0XyNNGMXuRx3aaIeyjj8ou-FRsHor14m2yPPc.jpg?auto=webp&s=ff631469a0fd9b87dcbbe2f7e3bf848919109891"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz3x87/d_annotation_formats_for_image_annotations/",
          "author": null,
          "description": "Hey ML people, what is your favorite annotation format for image bounding boxes/labels? I know coco is very popular, we are rethinking parts of our data infrastructure wondering what everyone is using. Our platform hosts hundreds of millions of images. Ideal format would support running queries on data stored in a Data lake\n If the format supports 3D annotation types that is even better. Thanks for your insights in advance.\n    submitted by    /u/mmuppidi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz3x87/d_annotation_formats_for_image_annotations/",
          "publishedOn": "2022-04-08T13:47:05.000Z",
          "wordCount": 208,
          "title": "[D] Annotation formats for image annotations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz3qc8/n_openais_dalle_2_paper_hierarchical/",
          "author": null,
          "description": "New version of paper is linked to in the DALL-E 2 blog post and also here (pdf file format).\n Tweet announcing updated paper.\n Older version of paper (pdf file format).\n Original Reddit post.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz3qc8/n_openais_dalle_2_paper_hierarchical/",
          "publishedOn": "2022-04-08T13:37:13.000Z",
          "wordCount": 273,
          "title": "[N] OpenAI's DALL-E 2 paper \"Hierarchical Text-Conditional Image Generation with CLIP Latents\" has been updated with added section \"Training details\" (see Appendix C)",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz32ub/dense_passage_retrieverdpr_openqa_system_p/",
          "author": null,
          "description": "Hi, I made a video explaining Dense Passage Retriever(DPR) paper. We specifically explain the End to End QA system suggested in the latter part of the paper which discusses how to build an Open-QA system using dense retrievers.\n DPR was one of the first papers that discussed building dense retrievers using QA pairs only and didn't require a big pretraining computational setup like ORQA or REALM. It is currently used in a lot of places as a dense retriever. You can find Hugginface and Haystack implementations also.\n This video is part of a series on Open-QA using dense retrievers. We have made 2 videos on DPR. In the latter, we discuss how to build a dense retriever from scratch. Thanks for the support and it would be great if you could give any feedback.\n https://www.youtube.com/watch?v=rvcyyJNjPU0\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz32ub/dense_passage_retrieverdpr_openqa_system_p/",
          "publishedOn": "2022-04-08T13:03:32.000Z",
          "wordCount": 224,
          "title": "Dense Passage Retriever(DPR) Open-QA System [P]",
          "imageUrl": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?auto=webp&s=720b78add0a3005c4f67eaed6897df409cc040c6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz2o0b/d_works_that_can_process_variable_input/",
          "author": null,
          "description": "Hi. I'm looking for existing computer vision papers /networks that can process variable input resolution. Can anyone share me with similar works? For example, a network/layer N can take both inputs with H*W and 2H*2H individually and give correct prediction. One of them I know is ROI pooling used in Faster RCNN. Thanks very much.\n    submitted by    /u/vincent341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz2o0b/d_works_that_can_process_variable_input/",
          "publishedOn": "2022-04-08T12:41:56.000Z",
          "wordCount": 327,
          "title": "[D] Works that can process variable input resolution of images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz05tg/d_machine_learning_engineers_what_does_your_day/",
          "author": null,
          "description": "Hey, I'm looking to transition from my current role as a data scientist to one that has a machine learning engineering focus. I was wondering if anyone could provide insights into how they plan their day, or what activities you do throughout the day/week. I'd be particularly interested to understand the balance between deploying models/writing production worthy code and your time spent learning/developing given the field is moving so fast.\n    submitted by    /u/MenArePigs69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz05tg/d_machine_learning_engineers_what_does_your_day/",
          "publishedOn": "2022-04-08T10:06:51.000Z",
          "wordCount": 1320,
          "title": "[D] Machine Learning Engineers - What Does Your Day Involve?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tywuga/d_bayesian_nonparametrics_for_ranking/",
          "author": null,
          "description": "I am currently sitting at a difficult machine-learning problem that I have found no literature on how to solve it. \n I am given n datapoints x_1,...,x_n that are ordered according to a ranking preference rank(x_1)<rank(x_2)<...<rank(x_n). I am assuming there exists a function f, such, that f(x_i)<f(x_i+1). I am now searching a Bayesian non-parametric model that gives the posterior probability of functions f that abide f(x_i)<f(x_i+1), so that i can estimate the relative rank preferences at new points.\n I have tried out a few things. The naive approach is using a GP prior on f. Unfortunately, computing the posterior distribution p(f(x_1), ... f(x_n)| f(x_1)<...<f(x_n)) has no closed form solution (it is a normal distribution with N linear constraints, which is absolutely terrible to sample from). This makes computing conditional distributions for predictions very challenging. \n I am currently approximating the solution by using a GP regression model with label y_i = rank(x_i)=i. But this is systematically under-estimating the shape-variation, due to the fact that it adds the assumption that function values between ranks are equidistant. \n Is there any known approach how to do this?\n    submitted by    /u/Ulfgardleo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tywuga/d_bayesian_nonparametrics_for_ranking/",
          "publishedOn": "2022-04-08T06:03:54.000Z",
          "wordCount": 494,
          "title": "[D] Bayesian Non-Parametrics for Ranking?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tywmy0/r_video_diffusion_models/",
          "author": null,
          "description": "From the webpage:\n We present results on video generation using diffusion models. We propose an architecture for video diffusion models which is a natural extension of the standard image architecture. We show that this architecture is effective for jointly training from image and video data. To generate long and higher resolution videos we introduce a new conditioning technique that performs better than previously proposed methods. We present results on text-conditioned video generation and state-of-the-art results on an unconditional video generation benchmark.\n Paper: https://arxiv.org/abs/2204.03458\n https://video-diffusion.github.io/\n    submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tywmy0/r_video_diffusion_models/",
          "publishedOn": "2022-04-08T05:50:09.000Z",
          "wordCount": 205,
          "title": "[R] Video Diffusion Models",
          "imageUrl": "https://external-preview.redd.it/3oqkCt6VNVPKLWns6Tm8iCS8Ssrcd3AFU4klA6NCY8o.jpg?auto=webp&s=f509d332edc21fdb071d2bd7177e91a9b4cbd42e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyv2tu/d_how_to_decide_publication_venue/",
          "author": null,
          "description": "How to decide if a paper is appropriate for a specific venue? Moreover, how would you categorize the difference between a good NiPs publication and a good CvPR or ICCV publication?\n    submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyv2tu/d_how_to_decide_publication_venue/",
          "publishedOn": "2022-04-08T04:12:23.000Z",
          "wordCount": 216,
          "title": "[D] how to decide publication venue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyu1n6/n_lr_warmup_for_pytorch/",
          "author": null,
          "description": "​\n RadamWarmup + CosineAnnealingLR + StepLR\n Colab Link\n pytorch_warmup v0.1.0 was released.\n    submitted by    /u/TonyY_RIMCS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyu1n6/n_lr_warmup_for_pytorch/",
          "publishedOn": "2022-04-08T03:13:36.000Z",
          "wordCount": 98,
          "title": "[N] LR Warmup for PyTorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyo9qd/d_self_attention_visualization/",
          "author": null,
          "description": "Has anyone ever come across seemingly chaotic self attention maps during visualization. If your model is performing well but no insights can be gleaned from the visualization how do you explain it in a paper?\n    submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyo9qd/d_self_attention_visualization/",
          "publishedOn": "2022-04-07T22:13:00.000Z",
          "wordCount": 262,
          "title": "[D] self attention visualization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyn0yt/n_palms_googles_530b_llm_training_costs_around_9m/",
          "author": null,
          "description": "Here's the blogpost estimating the cost.\n What would it cost you to train PaLM using cloud computing (and you're not Google)? Something around $9M to $17M.\n    submitted by    /u/cirqe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyn0yt/n_palms_googles_530b_llm_training_costs_around_9m/",
          "publishedOn": "2022-04-07T21:14:22.000Z",
          "wordCount": 382,
          "title": "[N] PaLM's (Google's 530B LLM) training costs around $9M to $17M.",
          "imageUrl": "https://external-preview.redd.it/XV6Bw55gOCr7mrIMQ_xiFS365To1cJ6BcQQYprVY0iQ.jpg?auto=webp&s=2f3079fb965cc21e23397be43a0945248880c31e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tymu9e/d_feature_selection_methods/",
          "author": null,
          "description": "I'm working on a ML project and I'm working with a dataset with 20 columns, for feature selection I just removed one column one by one and looked at the error of the ML outputs for each, then saw when what column is removed gives a lower error and kept repeating that but that didn't seem to help the model at all and the error went down very little. Is this an okay way of doing feature selection is there another way that gives better results. I tried PCA and LDA and Pearson Correlation method as well in Python and that didn't seem to help or is this the best I could do. Thanks!\n    submitted by    /u/ihshosv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tymu9e/d_feature_selection_methods/",
          "publishedOn": "2022-04-07T21:05:46.000Z",
          "wordCount": 334,
          "title": "[D] Feature selection methods",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tykn7y/d_overfitting_a_sign_high_learning_capacity/",
          "author": null,
          "description": "This is a two part question:\n  \nIf a neural network can overfit the a large dataset is this a sign that a neural network has high learning capacity? \n If a neural network can overfit a dataset with substantially less parameters than other neural networks developed for the same learning task is this a sign that the neural network has a high learning capacity relative to other datasets?\n  \n   submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tykn7y/d_overfitting_a_sign_high_learning_capacity/",
          "publishedOn": "2022-04-07T19:24:50.000Z",
          "wordCount": 331,
          "title": "[D] Overfitting a sign high learning capacity?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyjj3z/d_training_cnn_with_synthetic_data_should_i_mix/",
          "author": null,
          "description": "I'm doing research on the use of synthetic data for a computer vision task and i have generally always tried to train in a mixed setting from scratch, but i have noticed that in similar papers, researchers always pretrain on synth first and then finetune on real data. Is there a logic behind that? Should i expect better results by finetuning?\n    submitted by    /u/TheManveru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyjj3z/d_training_cnn_with_synthetic_data_should_i_mix/",
          "publishedOn": "2022-04-07T18:34:01.000Z",
          "wordCount": 729,
          "title": "[D] training cnn with synthetic data. Should i mix synth and real and train from the scratch or pretrain the network with synth and finetune with real?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyhxl2/r_sampling_in_dirichlet_process_mixture_models/",
          "author": null,
          "description": "Hi Everyone,\n We have recently published the code for our AISTATS 2022 paper -\n Sampling in Dirichlet Process Mixture Models for Clustering Streaming Data\n ​\n Video Segmentation Example\n In our work, we have proposed a solution for clustering streaming data. Unlike 'standard' clustering scenarios, in the streaming case the data stream is possibly infinite, you cannot backtrack to previously processed points, and the data statistics are dynamic and change over time.\n Our solution is based on the Dirichlet Process Mixture Model (DPMM), can work with different types of observations, and is very fast, outperforming other methods both in the quality of the results and the speed with which it achieves them.\n It can even be distributed across several processes and/or machines!\n  \nPaper: https://dinarior.github.io/papers/Dinari_AISTATS_streaming.pdf\n Code (Julia Package): https://github.com/BGU-CS-VIL/DPMMSubClustersStreaming.jl\n Code (Python wrapper): https://github.com/BGU-CS-VIL/dpmmpythonStreaming\n Notebook (Julia) for creating the video: https://nbviewer.org/github/BGU-CS-VIL/DPMMSubClustersStreaming.jl/blob/main/examples/VideoSeg.ipynb\n  \n   submitted by    /u/dinarior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyhxl2/r_sampling_in_dirichlet_process_mixture_models/",
          "publishedOn": "2022-04-07T17:20:31.000Z",
          "wordCount": 424,
          "title": "[R] Sampling in Dirichlet Process Mixture Models for Clustering Streaming Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyfltn/d_best_way_to_handle_encoding_disconnected_graphs/",
          "author": null,
          "description": "I am thinking of building a graph classifier that takes in graphs and labels the incoming graph.\n The dataset of interest to me is RadGraph: https://arxiv.org/abs/2106.14463\n The issue I am having is that the graphs in RadGraph are disconnected in nature (on average 20 disconnected components), making it difficult for the various graph encoders I am aware of to do a good job classifying the graphs.\n    submitted by    /u/AICoderGamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyfltn/d_best_way_to_handle_encoding_disconnected_graphs/",
          "publishedOn": "2022-04-07T15:31:10.000Z",
          "wordCount": 174,
          "title": "[D] Best way to handle encoding disconnected graphs at the graph level.",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyfj7d/d_does_someone_know_how_much_faster_deepspeeds/",
          "author": null,
          "description": "Implementation here\n Looks like they manually calculate the gradient? I'm very curious how much of a difference this makes!\n    submitted by    /u/fasttosmile  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyfj7d/d_does_someone_know_how_much_faster_deepspeeds/",
          "publishedOn": "2022-04-07T15:27:53.000Z",
          "wordCount": 195,
          "title": "[D] Does someone know how much faster deepspeed's transformer implementation is?",
          "imageUrl": "https://external-preview.redd.it/tEPdTFlU-uawNZzkicwUlD9W5f2jMOt9Ho6WP7Zbh7M.jpg?auto=webp&s=f5e8d53aeee5139d4a8684ee18339cc5d0dfde18"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty8oi7/r_my_research_group_is_publicly_sharing_its_paper/",
          "author": null,
          "description": "https://outsystems-ai-reading-group.github.io/\n    submitted by    /u/JClub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty8oi7/r_my_research_group_is_publicly_sharing_its_paper/",
          "publishedOn": "2022-04-07T08:47:55.000Z",
          "wordCount": 118,
          "title": "[R] My research group is publicly sharing its paper presentations! Check it out!",
          "imageUrl": "https://external-preview.redd.it/okw9CoDOpAQ1q_mUTvkkFthoqq22j0xfreN13Amh1Rw.jpg?auto=webp&s=6f24b4084a5650db879165128873fd8d71d36b12"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty7h2p/r_onthefly_strategy_adaptation_for_adhoc_agent/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty7h2p/r_onthefly_strategy_adaptation_for_adhoc_agent/",
          "publishedOn": "2022-04-07T07:15:38.000Z",
          "wordCount": 99,
          "title": "[R] On-the-fly Strategy Adaptation for ad-hoc Agent Coordination",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty6hee/d_any_good_free_to_use_dalle_style_datasets/",
          "author": null,
          "description": "Are there any free to use datasets that contain image/annotation pairs in the style OpenAI used to train the DALL-E models? Pretty inspired by DALL-E 2 and think it would be cool to create a tiny less powerful replication\n    submitted by    /u/puppet_pals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty6hee/d_any_good_free_to_use_dalle_style_datasets/",
          "publishedOn": "2022-04-07T06:06:51.000Z",
          "wordCount": 163,
          "title": "[D] Any good free to use DALL-E style datasets?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty6g23/d_tensorflow_tfrange_vs_range/",
          "author": null,
          "description": "TLDR: TensorFlow AutoGraph unwraps native Python ranges, baking each value into the graph. This can be an unexpected cause of graph size explosion. \n This recently caused an issue in my project, so I thought I'd share some more details:\n https://lukewood.xyz/blog/to-unroll-or-to-not-unroll\n    submitted by    /u/puppet_pals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty6g23/d_tensorflow_tfrange_vs_range/",
          "publishedOn": "2022-04-07T06:04:17.000Z",
          "wordCount": 182,
          "title": "[D] TensorFlow tf.range() vs range()",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty4gw4/r_a_benchmarking_framework_for_timeseries/",
          "author": null,
          "description": "Our work \"AdaTime: A Systematic Evaluation of Domain Adaptation Algorithms on Time Series Data\" is now public. We provide a benchmarking framework named \"AdaTime\" to fairly evaluate Unsupervised domain adaptation (UDA) approaches on time-series data. We find that UDA approaches proposed for visual data can be directly applied to time-series data, and still achieve excellent performance, even better than methods specially proposed for time-series UDA. Se were impressed by the consistently superior performance of \"DIRT-T\" method on all the datasets. We provide the code publicly on github https://github.com/emadeldeen24/AdaTime\n    submitted by    /u/emad_eldeen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty4gw4/r_a_benchmarking_framework_for_timeseries/",
          "publishedOn": "2022-04-07T04:01:52.000Z",
          "wordCount": 189,
          "title": "[R] A benchmarking framework for time-series unsupervised domain adaptation",
          "imageUrl": "https://external-preview.redd.it/sPvr39oleAaAzL2Fx1s3W-hVlQLmkPCmIYm8DTQI1IE.jpg?auto=webp&s=d21d49a0c4335a7c16878c30293b7641634cb8cb"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty3w48/pr_announcing_dataset_denoising_shabby_pages/",
          "author": null,
          "description": "Into machine learning? Want a chance to earn a new MacBook Pro? Check out the Denoising ShabbyPages competition! The ShabbyPages dataset is being produced as a way to help train, test, and calibrate computer vision machine learning algorithms designed for working with documents. Enter the competition by training a model to remove the noise, and be awarded a MacBook Pro or some swag in the process! Check out the short paper introducing the dataset, and learn more about the competition at denoising-shabby.com.\n    submitted by    /u/proofconstruct  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty3w48/pr_announcing_dataset_denoising_shabby_pages/",
          "publishedOn": "2022-04-07T03:29:34.000Z",
          "wordCount": 180,
          "title": "[P][R] Announcing: Dataset & Denoising Shabby Pages Competition",
          "imageUrl": "https://external-preview.redd.it/3_5RF7j_Wg4iYno2Cpz3or2Md6GYBVeX1z8U_fyZIYE.jpg?auto=webp&s=2788014920175df6b4b456e2dcdb428445d0d887"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty3jae/r_facesigns_semifragile_neural_watermarks_for/",
          "author": null,
          "description": "Hi Everyone! \n We have released the preprint and google colab demo for our paper FaceSigns. FaceSigns embeds a secret bit-string as a semi-fragile watermark in the image pixels. The message is recoverable if benign image operations such as color/contrast adjustment, JPEG compression, Instagram filters are applied. However, the message cannot be decoded if the image is facially tampered (eg. DeepFake manipulation) . This selective fragility allows reliable detection of DeepFake manipulations applied on images signed using FaceSigns. \n Try out our google colab demo to see message encoding and decoding using FaceSigns!\n Paper: https://arxiv.org/abs/2204.01960\n Project Webpage: https://shehzeen.github.io/facesigns\n Demo: https://github.com/paarthneekhara/FaceSignsDemo\n    submitted by    /u/LynxCompetitive7637  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty3jae/r_facesigns_semifragile_neural_watermarks_for/",
          "publishedOn": "2022-04-07T03:09:27.000Z",
          "wordCount": 200,
          "title": "[R] FaceSigns: Semi-Fragile Neural Watermarks for Media Authentication and Countering Deepfakes",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty25fi/d_machine_learning_models_ideas_for_google_search/",
          "author": null,
          "description": "Hi guys!\n I work in house and I’m part of our Google search team. Our ad spend is pretty large (9 figures per year, in USD). We build/manage stuff at scale using SQL, R, Javascript, and so on. So everything is pretty much “big data” in flavour.\n Lately I’ve been more and more interested in data science, and I’m looking to take things to the next level by incorporating machine learning into our workflow. I’d really love to build some useful machine learning models using popular Python libraries such as Pandas, SciKit Learn, NumPy, TensorFlow, PyTorch, and so on.\n Any suggestions on cool, and most importantly useful machine learning models I could build? (By “useful”, I mean something that could help increase the profits.) I think some classification, predictive, or recommender models would be great to start with. Cheers! 😄\n    submitted by    /u/TropicalBound111  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty25fi/d_machine_learning_models_ideas_for_google_search/",
          "publishedOn": "2022-04-07T01:57:24.000Z",
          "wordCount": 568,
          "title": "[D] Machine learning models / ideas for Google search ads?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txy6il/r_using_gamma_distribution_to_improve_longtail/",
          "author": null,
          "description": "Predicting longtail events can be one of the more challenging ML tasks. Last year my team published a blog article where we improved DoorDash’s ETA predictions by 10% by tweaking the loss function with historical and real-time features. I thought members of the community would be interested in learning how we improved the model even more by using Gamma distribution-based inverse sampling approach to loss function tunning. Please check out the new article for all the technical details and let us know your feedback on our approach.\n https://doordash.engineering/2022/04/06/using-gamma-distribution-to-improve-long-tail-event-predictions/\n    submitted by    /u/pmp-dash1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txy6il/r_using_gamma_distribution_to_improve_longtail/",
          "publishedOn": "2022-04-06T22:34:20.000Z",
          "wordCount": 194,
          "title": "[R] Using Gamma Distribution to Improve Long-Tail Event Predictions at Doordash",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txvlf0/d_icml_author_response_what_reviewers_expect/",
          "author": null,
          "description": "Hi, we submitted to ICML for the first time. We got 4 reviews and 3 of them are mostly positive. Major comments by the reviewers include: more justification on the assumptions, discussion on choices of parameters, and experiments in more complex and different environments. \n We want to address all the major and minor comments as best as we can but given that the response is limited to one page we cannot explain everything in detail. I am not sure what is the acceptable norm here. Do reviewers expect the authors to conduct some experiments during the rebuttal and provide sample results or just explain what additional experiment we will conduct and how we will do it. Justification and reasoning should be in details or a brief explanation with an assurance to add a detailed discussion in the final version suffices.\n TIA\n    submitted by    /u/srvsinha186  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txvlf0/d_icml_author_response_what_reviewers_expect/",
          "publishedOn": "2022-04-06T20:36:00.000Z",
          "wordCount": 234,
          "title": "[D] ICML author response. What reviewers expect.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txvky1/d_questions_for_a_tpm_for_ml_interview_at_google/",
          "author": null,
          "description": "Hey all,\n I have a technical program manager interview soon for an ML team at google and I want to know if anyone has any sample role-related questions I can gauge myself with.\n I have a strong data science & statistics background but that doesn't always translate to deep ML knowledge like an ML Engineer might have.\n Any resources or sample questions? I have not found adequate results from google regarding this team area specifically.\n    submitted by    /u/math_is_my_religion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txvky1/d_questions_for_a_tpm_for_ml_interview_at_google/",
          "publishedOn": "2022-04-06T20:35:25.000Z",
          "wordCount": 176,
          "title": "[D] Questions for a TPM for ML interview at Google",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txv5o3/d_anyone_knows_any_high_accuracy_models_on_uci/",
          "author": null,
          "description": "Hi everyone. This is my first-time post here, and I hope I did not break any sub rules.\n Currently, I am doing some research with the UCI Adult dataset(https://archive.ics.uci.edu/ml/datasets/adult). This first step is to build a high-accuracy classifier model. \n Does anyone know any high accuracy model on this dataset (more than 90%)? I use many machine learning models like logistic regression and neural network. But no matter how complex the model is, I can only get an accuracy of about 85% on the test set. I tried to google but I found many others also have similar results of about 85%.\n Any posts or papers will be helpful! Thanks in advance for your help!\n    submitted by    /u/Akasakura888  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txv5o3/d_anyone_knows_any_high_accuracy_models_on_uci/",
          "publishedOn": "2022-04-06T20:16:14.000Z",
          "wordCount": 218,
          "title": "[D] Anyone knows any high accuracy models on UCI adult dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txtp5u/r_using_gamma_distribution_to_improve_longtail/",
          "author": null,
          "description": "Predicting longtail events can be one of the more challenging ML tasks. Last year my team published a blog article where we improved DoorDash’s ETA predictions by 10% by tweaking the loss function with historical and real-time features. I thought members of the community would be interested in learning how we improved the model even more by using Gamma distribution-based inverse sampling approach to loss function tuning. Please check out the new article for all the technical details and let us know your feedback on our approach.\n ​\n https://doordash.engineering/2022/04/06/using-gamma-distribution-to-improve-long-tail-event-predictions/\n    submitted by    /u/pmp-dash1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txtp5u/r_using_gamma_distribution_to_improve_longtail/",
          "publishedOn": "2022-04-06T19:10:10.000Z",
          "wordCount": 188,
          "title": "[R] Using Gamma Distribution to Improve Long-Tail Event Predictions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txth9e/d_reading_the_tea_leaves_expert_endusers/",
          "author": null,
          "description": "Hey there, just a heads up we at The Gradient just published a new article discussing explainability - \n  \n\"This article uses the common backdrop of competitive games to explore the ways in which domain experts adapt to new technologies that lack explainability. I illustrate how interpretations vary based on user experience and model architecture, and how special care must be taken when adapting models to human-centric problems.\"\n  \nCheck it out here if you think it's interesting / worth discussing:\n Reading the Tea Leaves: Expert End-Users Explaining the Unexplainable\n    submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txth9e/d_reading_the_tea_leaves_expert_endusers/",
          "publishedOn": "2022-04-06T19:00:19.000Z",
          "wordCount": 189,
          "title": "[D] Reading the Tea Leaves: Expert End-Users Explaining the Unexplainable",
          "imageUrl": "https://external-preview.redd.it/wnVaar4ZXR3zqeMsXegEzJEPVdp1PkLFsHJagJ249DM.jpg?auto=webp&s=53c299a85d48eb7bedf6e5ec47ca846a5c52c38f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txqkin/project_learning_to_play_settlers_of_catan_with/",
          "author": null,
          "description": "Hi all,\n I just wanted to share a project I've been working on for the past year - using deep RL to learn to play the board game Settlers of Catan.\n I expect everyone is aware of the results that DeepMind/OpenAI have got recently on Go, DOTA 2, Starcraft 2 etc, but I was motivated to see how much progress could be made with existing RL techniques on a reasonably complex game - but with access to significantly less computational resources.\n Whilst I didn't end up with an agent that performs at a super-human level, there was clear learning progress and the results were quite interesting. I decided to do a full write-up of the project here, which I figured could be useful for anyone else who is interested in trying to apply DRL to a new, complicated environment. I also open-sourced all the code here for anyone interested.\n If anyone has any feedback or any questions at all that'd be great!\n    submitted by    /u/henrythepaw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txqkin/project_learning_to_play_settlers_of_catan_with/",
          "publishedOn": "2022-04-06T16:49:47.000Z",
          "wordCount": 952,
          "title": "[Project] Learning to Play \"Settlers of Catan\" With Deep RL - Writeup and Code",
          "imageUrl": "https://external-preview.redd.it/MCy14opBjTIKzwl5JN-l_h8ogp8jGD7JGmk-A4mmZJI.jpg?auto=webp&s=b34f246a1d389b97fb2013f3661ccf8afbf4403e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txqapw/d_icml_rebuttals_optional_or_semimandatory/",
          "author": null,
          "description": "Hi,\n We just submitted to ICML 2022 and got our reviews back. We were excited to see that 4/4 reviews were positive and acknowledged the contribution of the paper. However, there were some minor criticisms (e.g. didn't do good enough lit reviews, could use a few more experiments) across several reviews.\n I was wondering if it is ever acceptable to not submit a rebuttal? Can a rebuttal in this case actually hurt us by rocking the boat---or for ICML is the norm that you should always submit a rebuttal that addresses all the reviewers' criticisms.\n We were wondering what the norm is for ICML specifically?\n    submitted by    /u/optimistic313  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txqapw/d_icml_rebuttals_optional_or_semimandatory/",
          "publishedOn": "2022-04-06T16:37:16.000Z",
          "wordCount": 335,
          "title": "[D] ICML rebuttals optional or semi-mandatory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txples/r_hierarchical_textconditional_image_generation/",
          "author": null,
          "description": "Blog post.\n Paper (pdf file format). The paper is also linked to in the above blog post.\n Abstract\n  \nContrastive models like CLIP have been shown to learn robust representations of images that capture both semantics and style. To leverage these representations for image generation, we propose a two-stage model: a prior that generates a CLIP image embedding given a text caption, and a decoder that generates an image conditioned on the image embedding. We show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity. Our decoders conditioned on image representations can also produce variations of an image that preserve both its semantics and style, while varying the non-essential details absent from the image representation. We use diffusion models for the decoder and experiment with both autoregressive and diffusion models for the prior, finding that the latter are computationally more efficient and produce higher-quality samples.\n  \nOpenAI's Sam Altman used DALL-E 2 to generate ~20 text prompt requests from Twitter users. The results are here, with individual result links and other samples in this comment from another Reddit user in a different post.\n Twitter thread about the paper (not from the paper authors).\n Sam Altman's blog post about DALL-E 2.\n  \nHopefully this summer, we’ll do a product launch and people will be able to use it for all sorts of things.\n  \n   submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txples/r_hierarchical_textconditional_image_generation/",
          "publishedOn": "2022-04-06T16:04:57.000Z",
          "wordCount": 773,
          "title": "[R] Hierarchical Text-Conditional Image Generation with CLIP Latents. This is the paper for OpenAI's DALL-E 2",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txm40w/is_the_first_boss_attempt_phenomenon_know_to/",
          "author": null,
          "description": "I'm curious about wether this unusual learning trajectory observed in humans has also been observed in artificial neural nets. A well known phenomenon in the 'dark souls' video game series is that ones first attempt at a boss is often much better than subsequent attempts. Boss hp at time of death by attempt might go something like: 35%, 55%, 85%, 87%, 75%, 54%, , 60%, 43%, 27%, 38%, 12%, 0%. This sounds very anecdotal, but its know to the community of these games to be a real thing. See this thread for evidence. Have NN playing games been known to exhibit a similar pattern, with peak in success early on, followed by a step descent , then a slow gradual climb? Or is this a purely human phenomenon?\n My hypothesis as to why this happens is that over the course of the first couple attempts, the player learns a bunch of bad strategies which must be slowly unlearned, whereas on attempt one, the player has no defined strategies good or bad.\n    submitted by    /u/Greenface1998  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txm40w/is_the_first_boss_attempt_phenomenon_know_to/",
          "publishedOn": "2022-04-06T13:24:35.000Z",
          "wordCount": 888,
          "title": "Is the 'first boss attempt' phenomenon know to occur amongst NN playing games, or is this learning trajectory unique to human players?[D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txktli/r_disentangling_abstraction_from_statistical/",
          "author": null,
          "description": "submitted by    /u/papajan18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txktli/r_disentangling_abstraction_from_statistical/",
          "publishedOn": "2022-04-06T12:16:57.000Z",
          "wordCount": 116,
          "title": "[R] Disentangling Abstraction from Statistical Pattern Matching in Human and Machine Learning",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txkl43/projectp_who_invented_graph_neural_networks/",
          "author": null,
          "description": "Just a side project (only for me) in which I try to sum up some history of DL. Can't be 100% sure this is the first article in which they appear: Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., & Monfardini, G. (2008). The graph neural network model. IEEE transactions on neural networks, 20(1), 61-80. Would appreciate any help. Thanks\n    submitted by    /u/Siddh__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txkl43/projectp_who_invented_graph_neural_networks/",
          "publishedOn": "2022-04-06T12:03:35.000Z",
          "wordCount": 633,
          "title": "[Project][P] Who invented Graph Neural Networks?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txkh8m/r_gpbart_a_novel_bayesian_additive_regression/",
          "author": null,
          "description": "(not my paper)\n paper: https://arxiv.org/abs/2204.02112\n abstract: \"The Bayesian additive regression trees (BART) model is an ensemble method extensively and successfully used in regression tasks due to its consistently strong predictive performance and its ability to quantify uncertainty. BART combines \"weak\" tree models through a set of shrinkage priors, whereby each tree explains a small portion of the variability in the data. However, the lack of smoothness and the absence of a covariance structure over the observations in standard BART can yield poor performance in cases where such assumptions would be necessary. We propose Gaussian processes Bayesian additive regression trees (GP-BART) as an extension of BART which assumes Gaussian process (GP) priors for the predictions of each terminal node among all trees. We illustrate our model on simulated and real data and compare its performance to traditional modelling approaches, outperforming them in many scenarios. An implementation of our method is available in the \\textsf{R} package \\texttt{rGPBART} available at: https://github.com/MateusMaiaDS/gpbart.\"\n    submitted by    /u/bikeskata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txkh8m/r_gpbart_a_novel_bayesian_additive_regression/",
          "publishedOn": "2022-04-06T11:57:53.000Z",
          "wordCount": 468,
          "title": "[R] GP-BART: a novel Bayesian additive regression trees approach using Gaussian processes",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txijls/d_anyone_know_about_any_interesting_recent/",
          "author": null,
          "description": "I’m currently writing a research paper for my MSc on neuromorphic sensing and spike neural networks and most good papers are from around 2015 and was looking for something more recent.\n Anyone here heard of any interesting upgrades in architecture or applications?\n Cheers!\n    submitted by    /u/GandhisLittleHelper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txijls/d_anyone_know_about_any_interesting_recent/",
          "publishedOn": "2022-04-06T09:54:31.000Z",
          "wordCount": 145,
          "title": "[D] Anyone know about any interesting recent improvements with SNNs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txha3z/noticing_that_profs_focus_on_male_students_goals/",
          "author": null,
          "description": "Hello, I’m currently a graduate student. I do different projects and for some I get to decide on what I want the scope to be. I do have to get the scope/ plan/ idea approved first. I pitch my ideas to profs who aren’t directly my profs and normally 5-6 other students will pitch ideas to the same group of profs at the same time….. I noticed that i get really different questions and feedback in comparison to my peers. I’m a female and my peers are male… I didn’t start out with this outlook but I’m starting to search for reasons why I often get questioned about my capabilities to preform a project ( which is normal enough but I get questioned to the point where explaining my approach isn’t enough and they ask me for examples of codes) and my peers definitely do not get asked about there capabilities, rather they tell them what they can do and they don’t get questioned. …………… really frustrating.\n    submitted by    /u/tyger-lily  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txha3z/noticing_that_profs_focus_on_male_students_goals/",
          "publishedOn": "2022-04-06T08:19:25.000Z",
          "wordCount": 1258,
          "title": "Noticing that profs focus on male student’s goals and female student’s capabilities, any weigh-in? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txgmti/d_how_to_write_a_mlhealthcare_paper_where_the/",
          "author": null,
          "description": "As a project in the course of my PhD, I had to create a prototype for a project. My PhD is application of machine learning in health care. The project definition and scope was faaaar too wide. However, I managed to create a working demo which encompasses some use cases of the project. At best, it can be called a framework, where I have put in different DL components and it works okay for those use cases only. Most of the components, I have used are pre-trained language models (maybe fine tuned them to my use case). However, there is no active training or learning involved. This is because I created this for a demo only. I also created a very small dataset and tested the framework over the dataset and the results were ok. However, my supervisor now wants me to write a paper, as he is confident, that the use case is rather unique and my working framework is a good first step. I believe, his aim is to get me started on the paper writing process, which I appreciate. However, I am not confident about it at all.\n My question is, can a 'framework' composed of pre-trained models with the end goal of solving a problem in health care is good enough? Are there precedents of any such paper? And if I trust my supervisor's instincts, are there any fancy ways to frame the framework so that it does not look so basic?\n    submitted by    /u/Complex_State9960  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txgmti/d_how_to_write_a_mlhealthcare_paper_where_the/",
          "publishedOn": "2022-04-06T07:30:09.000Z",
          "wordCount": 556,
          "title": "[D] How to write a ML+Healthcare paper where the research was a framework with pre-trained models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txfq52/p_building_a_knowledge_based_recommender_system/",
          "author": null,
          "description": "I am trying to build a knowledge based recommender system but do not have prior knowledge. \n We first take in user inputs such as occasion, weather, top wear and bottom wear, color. Based on this we want to create a knowledge base and recommend clothes. \n Can anyone help me on how to go about on doing this process step by step and what algorithms and technology to be used?\n    submitted by    /u/bills70  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txfq52/p_building_a_knowledge_based_recommender_system/",
          "publishedOn": "2022-04-06T06:26:17.000Z",
          "wordCount": 162,
          "title": "[P] Building a knowledge based recommender system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txdhxt/d_icml_2022_paper_reviews/",
          "author": null,
          "description": "ICML 2022 paper reviews are supposed to be released soon. Creating a discussion thread for this year's reviews.\n    submitted by    /u/zy415  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txdhxt/d_icml_2022_paper_reviews/",
          "publishedOn": "2022-04-06T04:06:11.000Z",
          "wordCount": 657,
          "title": "[D] ICML 2022 Paper Reviews",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txbyy7/d_in_general_should_you_let_the_model_find/",
          "author": null,
          "description": "I’ll give an example to better explain my question (don’t get hung up on the numbers, it’s all made up). Say you are using a tree based model trying to project how many points a player will score in a given basketball game.\n Most players shoot free throws at a slightly lower percentage on the road, than they do at home. However, the magnitude varies player to player. Let’s assume for 95% of players with significant data, the ratio of home free throw percentage to away is 1 to 1.15. Generally speaking, older players are closer to 1 and younger players are around 1.1 (since older players get used to the opposing crowd).\n Now also say it takes 100 home and 100 away free throws to get a stable reliable ratio.\n Now say a young player only has 50 home, and 50 away free throws. With this amount of data he has a ratio of 1, however the sample size is not enough to be fully stable.\n Which would be better…\n 5 features into this model, his home away ratio, average ratio for players his age, home free throw count, and away free throw attempts.\n 1 feature. His ‘projected’ home away ratio, which is a weighted average of his ratio with the average for plaeyrs his age. Since he’s 50% of the way to significance, 0.5 * 1 + 0.5 * 1.1 = 1.05\n The benefit of the of the first choice is that it may find other interactions that I never conceived of, however, it could incorporate noise. Is there a general consensus, or is this just a try both and see what works?\n    submitted by    /u/irndk10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txbyy7/d_in_general_should_you_let_the_model_find/",
          "publishedOn": "2022-04-06T02:41:45.000Z",
          "wordCount": 1317,
          "title": "[D] In general, should you let the model find interactions between many basic features, or should you use feature engineering to ‘help’ the model find the interaction?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx7e34/d_why_arent_new_llms_using_the_perceiver/",
          "author": null,
          "description": "Perceiver and PerceiverIO (https://arxiv.org/abs/2107.14795) appear to offer significantly improved FLOP efficiency, but new LLMs (including Deepmind's own Gopher) don't use it.\n What gives? Is it still too new, or is the Perceiver architecture not appropriate for LLMs?\n    submitted by    /u/deeceeo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx7e34/d_why_arent_new_llms_using_the_perceiver/",
          "publishedOn": "2022-04-05T22:48:26.000Z",
          "wordCount": 137,
          "title": "[D] Why aren't new LLMs using the Perceiver architecture?",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx59tj/r_metalearning_machines_in_a_single_lifelong/",
          "author": null,
          "description": "Saw this posted on Schmidhuber's Twitter:\n Meta-Learning Machines in a Single Lifelong Trial: lecture video (24 min) presented at meta-learning workshops at ICML 2020 and NeurIPS 2021. URL of talk: https://youtu.be/2GgGVdkq2bU\n Abstract\n The most widely used machine learning algorithms were designed by humans and thus are hindered by our cognitive biases and limitations. Can we also construct meta-learning algorithms that can learn better learning algorithms so that our self-improving AIs have no limits other than those inherited from computability and physics? This question has been a main driver of my research since I wrote a thesis on it in 1987. In the past decade, it has become a driver of many other people's research as well. Here I summarize our work starting in 1994 on meta-reinforcement learning with self-modifying policies in a single lifelong trial, and - since 2003 - mathematically optimal meta-learning through the self-referential Gödel Machine. This talk was previously presented at meta-learning workshops at ICML 2020 and NeurIPS 2021. Many additional publications on meta-learning can be found at https://people.idsia.ch/~juergen/metalearning.html\n    submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx59tj/r_metalearning_machines_in_a_single_lifelong/",
          "publishedOn": "2022-04-05T21:11:28.000Z",
          "wordCount": 318,
          "title": "[R] Meta-Learning Machines in a Single Lifelong Trial: lecture video (24 min) presented at meta-learning workshops at ICML 2020 and NeurIPS 2021 (Schmidhuber YouTube Talk)",
          "imageUrl": "https://external-preview.redd.it/vi10fYGumGdDuKtmrgIT6Ts5ESncbLCIuBXVAMdVDLw.jpg?auto=webp&s=91df7b5da1afb82cc84b2707d6c5641d50b8959b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx42h9/d_hyperparameter_tuning_does_it_even_work/",
          "author": null,
          "description": "Hi *,\n I've been working for the last 5 years as Data Scientist. During this time I have tried dozens of times to improve my models via hyperparameter tuning, but I've never got improvements from there. I've tried all the possible approaches: grid search, random search, bayesian search, etc. But in no case did I get satisfactory results.\n Does this happen to anyone else? Have you ever got robust improvements via HP tuning?\n    submitted by    /u/AM_DS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx42h9/d_hyperparameter_tuning_does_it_even_work/",
          "publishedOn": "2022-04-05T20:19:19.000Z",
          "wordCount": 291,
          "title": "[D] Hyperparameter Tuning: does it even work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx3f5g/d_autoregressive_model_for_graph_generation/",
          "author": null,
          "description": "Autoregressive models like GPT-2 do fairly well in text generation. Is it possible to do the same for graph data? A transformer based model Graphormer has recently shown its effectiveness in graph representation learning. Is there any way I can train Graphormer or any other model to generate graphs from an initial graph context?\n    submitted by    /u/ratt_m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx3f5g/d_autoregressive_model_for_graph_generation/",
          "publishedOn": "2022-04-05T19:51:08.000Z",
          "wordCount": 146,
          "title": "[D] Autoregressive model for graph generation?",
          "imageUrl": "https://external-preview.redd.it/eoBMYj_duATkDQ_aqqR_eU3Icw0zdJNAY3EmrOgWvT8.jpg?auto=webp&s=710b35efc10fa9f6ffadea65f77fe714c87184c5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx1bjv/d_how_do_you_guys_hear_about_the_latest_papers/",
          "author": null,
          "description": "Hi! I'm a first-year Grad Student in Computer Vision and I am trying to get caught up on the latest research in my field. It seems like everyone in CS has heard about all of the latest papers but I just have no idea how. My knowledge is limited to general ideas and doesn't know any specific papers unless they have like 20000+ citations.\n So my question is: how do you hear about these papers and get caught up? Is there a reference somewhere that puts together a list of all the \"must-read\" papers that have come out? I feel like I am already 5 years behind in my knowledge. It would be great if there was something like \"Top 5 papers of the week\" that I could read to stay on top of things.\n Also, this doesn't just apply to Vision. I would like to have an idea of the other major developments in other fields (like NLP, general ML/DL, etc.) since I think that can carry over to my field.\n Thanks! Looking forward to your replies\n    submitted by    /u/TobusFire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx1bjv/d_how_do_you_guys_hear_about_the_latest_papers/",
          "publishedOn": "2022-04-05T18:18:42.000Z",
          "wordCount": 709,
          "title": "[D] How do you guys hear about the latest papers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx0z89/d_fake_authors_and_paper_riders/",
          "author": null,
          "description": "Based on my experiences in both academia and industry, I see that many researchers get listed as authors on papers solely for having attended the relevant project meetings, despite not contributing anything substantial to the work. I know of several people who've gotten on dozens of papers this way, despite not being able to explain the main details behind many of the papers they \"co-authored.\" Of course, they can then claim credit for the work publicly as well as have their academic profile benefit from the citations accrued by the work.\n I've noticed that typically, these people are initially invited onto the project because they are on chummy terms with someone on the project. Concerningly, the more someone successfully \"paper-rides\" this way, the stronger their publication record looks, which makes it easier for them to find their way onto more projects to paper ride in the future.\n It seems that the obsessive focus on paper counts and citations has encouraged the rise of intellectually dishonest strategies for maximizing one's academic footprint. The huge research scientist salaries at top industry labs, which similarly obsess over paper counts and citations in their hiring process, only amplifies the incentive for paper riding.\n The reason I think it is bad: As more people paper ride, co-authorship on a paper gradually becomes a worse indication of expertise. Not to mention, paper riders are intellectually dishonest, by claiming credit for research that they didn't significantly contribute to. In a sense, it seems like a roundabout form of plagiarism.\n I know some might disagree with this take, as some people believe in being as generous about co-authorship as possible. I find that mindset to create the perfect environment for paper riders to flourish. I'm wondering if you've also seen paper riding happen and whether you think this behavior is good or bad.\n    submitted by    /u/alwayshumming  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx0z89/d_fake_authors_and_paper_riders/",
          "publishedOn": "2022-04-05T18:03:17.000Z",
          "wordCount": 2044,
          "title": "[D] Fake authors and paper riders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twzqsk/dr_generate_random_sample_for_exponentiated/",
          "author": null,
          "description": "Hi there experts, I have a real distribution for which I had run this scipy script to detect the best fit:\n However, the script outputs 4 parameter values and the best fit is actually a Exponentiated Weibull distribution.\n Now I am clueless how to generate a sample list of data of n-size. I know for sure about the normal distribution after getting these params as mean and sigma. How to I generate such list. Please help.\n ​\n ​\n https://preview.redd.it/79n28icmsqr81.png?width=1141&format=png&auto=webp&s=d9478691c06f5cdfe03af4f82db8293443e91f1e\n    submitted by    /u/GoldenDew9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twzqsk/dr_generate_random_sample_for_exponentiated/",
          "publishedOn": "2022-04-05T17:06:57.000Z",
          "wordCount": 172,
          "title": "[D][R] Generate random sample for exponentiated Weibull distribution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twznq8/rd_vae_embedding_space_can_we_force_it_to_learn_a/",
          "author": null,
          "description": "I understand that certain AE types such as B-VAE disentangle certain aspects of variation in the data, and those such as Conditional AE or VAE allow us to separate these aspects with labels.\n However, what I have seen is that the embedding space doesn't cluster the images as well as some contrastive methods. However contrastive methods require non-elegant negative sampling etc. \n Can we somehow force the VAE to learn both the variational lower bound as well as learn a good metric between samples such as visually similar samples are better clustered together?\n    submitted by    /u/jim_from_truckistan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twznq8/rd_vae_embedding_space_can_we_force_it_to_learn_a/",
          "publishedOn": "2022-04-05T17:03:16.000Z",
          "wordCount": 203,
          "title": "[R][D] VAE Embedding Space - Can we force it to learn a metric?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twylnl/d_jetson_agx_orin_dev_kit_as_a_standalone/",
          "author": null,
          "description": "The Jetson Orin 64gb model has \"275 Sparse|138 Dense INT8 TOPS\", and I am a little confused about how to compare this to something like the RTX a6000's performance. I am looking to do deep rl training and am new to the field. What metrics make a difference for deep rl? Any thoughts on the Orin dev kit's ability to train deep rl?\n    submitted by    /u/here_to_create  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twylnl/d_jetson_agx_orin_dev_kit_as_a_standalone/",
          "publishedOn": "2022-04-05T16:14:45.000Z",
          "wordCount": 206,
          "title": "[D] Jetson AGX Orin dev kit as a stand-alone training platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twxmk9/d_with_the_rise_of_automl_what_are_the_important/",
          "author": null,
          "description": "Some time down the road, when AutoML becomes more established, it can help us determine the best ML model and hyperparameters for a particular problem. This will not replace data scientist, as we still need data scientists for their domain knowledge, which is critical for scoping business problems, pre-processing data, and deriving business insights from the trained model. However, since data scientists no longer need to deal with the technicalities of a model in the near future (i.e. they no longer have to tune hyperparameters, determine the best opitmistion function etc), is there still a need for aspiring data scientists to learn about the intricacies and nuances behind the various models (maybe by coding the model from scratch)? Or is it enough for them to learn how to operate an AutoML system? (My question is referring to the corporate world in general and not to academia) Thanks in advance for your answers :)\n    submitted by    /u/smart_oinker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twxmk9/d_with_the_rise_of_automl_what_are_the_important/",
          "publishedOn": "2022-04-05T15:30:36.000Z",
          "wordCount": 2045,
          "title": "[D] With the rise of AutoML, what are the important skills for a ML career?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twu1z5/p_automlconf_competition_dac4automl/",
          "author": null,
          "description": "Hi everyone!\n We've just launched a competition at the AutoML-Conf 2022, the DAC4AutoML competition. It has two tracks, one for configuring a Computer Vision model and one for a RL pipeline: https://automl.github.io/dac4automlcomp/ \n And what is DAC exactly? It means we want to find well-performing hyperparameter configurations like in Algorithm Configuration, but we do it dynamically - thus DAC, Dynamic Algorithm Configuration. As to how that is supposed to happen? We don't put any restrictions on the solutions for the competitions, so you can submit your hand-tuned static hyperparameter setting if you want. Or you can use some sort of heuristic, a regression model, reinforcement learning, ... whatever works. \n If you're interested in participating, you can submit from now on until the 18.06. AOE, the winners will be announced at the AutoML-Conf.\n    submitted by    /u/catsortion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twu1z5/p_automlconf_competition_dac4automl/",
          "publishedOn": "2022-04-05T12:42:17.000Z",
          "wordCount": 320,
          "title": "[P] AutoML-Conf Competition: DAC4AutoML",
          "imageUrl": "https://external-preview.redd.it/hwN3EBf7WXi3MEvXiPgqOQzZmfA3yEU8ZOPYIry-WJw.jpg?auto=webp&s=e08b4e79f3d8a80bcf43263d687e29f7665b1ad1"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twtg6d/d_imagenet_original_pictures/",
          "author": null,
          "description": "As I understood it Imagenet got generated from internet images, but I am unable to to find the originals using naive image search. Is there any mapping? I wonder if imagenet data is a cropped versions of original pictures or not, i don't see it in the paper.\n    submitted by    /u/LeanderKu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twtg6d/d_imagenet_original_pictures/",
          "publishedOn": "2022-04-05T12:07:50.000Z",
          "wordCount": 222,
          "title": "[D] Imagenet Original Pictures",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twt98b/p_ufo_lands_on_highway_or_depth_estimation_using/",
          "author": null,
          "description": "Article describing depth estimation using machine learning models and 3D visualization of depth maps using three.js.\n https://www.storminthecastle.com/posts/ufos_and_depth/\n    submitted by    /u/CakeStandard3577  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twt98b/p_ufo_lands_on_highway_or_depth_estimation_using/",
          "publishedOn": "2022-04-05T11:57:51.000Z",
          "wordCount": 120,
          "title": "[P] UFO Lands on Highway! Or Depth Estimation using ML",
          "imageUrl": "https://external-preview.redd.it/EYCpGAaDtOBH3R2hcX5A8p4nQUaWGRn3Vhhp-gVnshg.jpg?auto=webp&s=73ce7b6d98e380ab00fbb89bc361e6c1054e477f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twspe4/d_could_styleganxl_be_great_for_outofdomain/",
          "author": null,
          "description": "In the context of text-to-image generation, I'd say one of the reasons VQGAN is so used in popular notebooks is that it can deal with many concepts, while stylegan used to be limited to the domain it was trained for. \n That may be about to change with the rollout release of Stylegan-XL weights trained on Imagenet. This notebook (https://github.com/CasualGANPapers/StyleGANXL-CLIP) has had nice results with objects never seen by the model, such as \"apple\" and \"ant\", as well as scenes such as \"judo athletes fighting\"\n Please note that the Stylegan-XL weights are currently available for 128x128 pixels. ETA for the 256 resolution is 14.04.22\n    submitted by    /u/HrodRuck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twspe4/d_could_styleganxl_be_great_for_outofdomain/",
          "publishedOn": "2022-04-05T11:25:38.000Z",
          "wordCount": 222,
          "title": "[D] Could Stylegan-XL be great for out-of-domain generation?",
          "imageUrl": "https://external-preview.redd.it/ZKt6uousVLNiB0ssq6GUS-K_Hr81UD28U8l9oMEB5Hw.jpg?auto=webp&s=e8d1d8a82b656126d33e6d703410f037e33552e1"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twqel5/discussion_support_vector_machines_in_2022/",
          "author": null,
          "description": "My post is inspired by this discussion.\n In that thread, OP asked why support vector machines are still taught. People offered several thoughts: they're easier to think about, they're still perfectly good for some real-world problems, and for some problems they apparently rival deep networks.\n I did a project for a class around six years ago using an SVM as implemented in scikit-learn. I was pretty satisfied with the project, but I also experienced some frustrations, and came away with some questions. I started working with Tensorflow and DNNs in earnest soon after finishing that project, and I largely stopped thinking about SVM. I would like to revive the questions I asked, but never answered, here.\n  \nA DNN with multiple outputs can potentially use a single neuron in the prediction of more than one output. For multiple, mutually-exclusive categories, this makes good sense. An SVM with multiple outputs in scikit-learn was implemented as pairs of one-vs-one SVMs, each of which was independently fit to data. This gets inefficient quickly. Has this changed? Can it be changed?\n DNN training at scale is a problem that many people have worked hard to make practical. Even non-experts like myself use our home GPUs to accelerate training of DNNs on large data sets. In scikit-learn, SVM training was implemented in a single thread on one CPU core. If you are performing cross-validation or a hyperparameter optimization study, it might be practical to parallelize fitting; one thread for each distinct condition. But can you parallelize the SVM fitting algorithm for a single condition? I went looking for software, but I couldn't find anything.\n  \nOver to you folks. Cheers.\n    submitted by    /u/aotus_trivirgatus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twqel5/discussion_support_vector_machines_in_2022/",
          "publishedOn": "2022-04-05T08:46:32.000Z",
          "wordCount": 1715,
          "title": "[Discussion] Support Vector Machines... in 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twqeei/r_restormer_efficient_transformer_for/",
          "author": null,
          "description": "​\n Visual Results\n With Restormer, you can remove noise, motion blur, defocus blur, and rain streaks from your own images.\n Paper: https://arxiv.org/abs/2111.09881\n Github: https://github.com/swz30/Restormer\n Colab Demo: https://colab.research.google.com/drive/1C2818h7KnjNv4R1sabe14_AYL7lWhmu6?usp=sharing\n Gradio Web Demo: https://huggingface.co/spaces/swzamir/Restormer\n    submitted by    /u/swz30  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twqeei/r_restormer_efficient_transformer_for/",
          "publishedOn": "2022-04-05T08:46:08.000Z",
          "wordCount": 166,
          "title": "[R] Restormer: Efficient Transformer for High-Resolution Image Restoration (CVPR 2022--ORAL) + Colab Demo + Gradio Web Demo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twmnol/r_d_seq2seq_model_hyperparameters_tuning/",
          "author": null,
          "description": "Does anyone have any advices or research papers on what hyperparameters do researchers use for their seq2seq model? \n I am interested in knowing whether hyperparameters such as dropout, or recurrent dropout, batchnorm, etc etc, are even necessary in the usage of seq2seq model, but couldn’t find anything on it for weeks.\n In the case, let’s say, using gridsearchCV, what hyperparameters do you tweak for ur seq2seq model? (Other than the usual stuff like number of neurons, etc). There is absolutely zero information for that on seq2seq model, and everyone just assumes that putting an attention mechanism solves everything without hyperparameters tunings. I have also looked up on codes on seq2seq, and no hyperparameters tunings were shown whatsoever. \n FYI, this is in the context of time series data, using seq2seq, if that matters.\n Thanks\n    submitted by    /u/plsendfast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twmnol/r_d_seq2seq_model_hyperparameters_tuning/",
          "publishedOn": "2022-04-05T04:32:59.000Z",
          "wordCount": 318,
          "title": "[R] [D] Seq2seq model hyperparameters tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twmfom/d_has_anyone_seen_any_papers_related_to_gans/",
          "author": null,
          "description": "I’ve been reading many papers lately pertaining to GANs, with more and more introducing supervised loss into the generator’s objective function. However, no one ever seems to show that the optimum remains undisturbed. Results seem to be strictly empirical most of the time. \n Has anyone seen any papers where it is shown that the disruption to the generator’s loss doesn’t harm convergence?\n    submitted by    /u/king_of_walrus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twmfom/d_has_anyone_seen_any_papers_related_to_gans/",
          "publishedOn": "2022-04-05T04:19:49.000Z",
          "wordCount": 291,
          "title": "[D] Has anyone seen any papers related to GANs which prove that the optimum remains unchanged when adding supervised loss (e.g. L1, L2)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twidsn/d_what_is_your_experience_with_fake_results_or/",
          "author": null,
          "description": "I am curious what is everyones experience with completely faked, falsified, or fabricated results in the area? Another aspect of this I think is people taking heavily overfitted results and finding one decent example that is from the test set and claiming their method is awesome. How much of this have you seen and how much of the research out there fits into this category?\n    submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twidsn/d_what_is_your_experience_with_fake_results_or/",
          "publishedOn": "2022-04-05T00:48:43.000Z",
          "wordCount": 183,
          "title": "[D] What is your experience with Fake results or overfitted results being sold as awesome?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twcdt2/d_why_do_we_still_teach_support_vector_machines/",
          "author": null,
          "description": "Honest question: are there any applications for which SVMs are the best choice? In my experience, no one seems to use this methodology anymore, though maybe I'm wrong. It just kinda feels like teaching people how to use a slide rule when everyone has calculators.\n    submitted by    /u/WartimeHotTot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twcdt2/d_why_do_we_still_teach_support_vector_machines/",
          "publishedOn": "2022-04-04T20:38:01.000Z",
          "wordCount": 937,
          "title": "[D] Why do we still teach support vector machines?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twc4or/d_paper_explained_continual_backprop_stochastic/",
          "author": null,
          "description": "https://youtu.be/zEMOX3Di2Tc\n This paper finds what seems to be a new phenomenon when working in the continual learning/life-long learning domain. If new tasks are continually introduced to an agent, it seems to loose it's ability to learn the more time progresses. Intuitively it's similar to this idea that \"an old dog can't learn new tricks\". They propose a fairly simple method of overcoming this limitation that involves resetting weights that are not contributing much to the outcome of the network. They call the method Continual Backprop.\n ​\n Outline:\n 0:00 - Overview\n 2:00 - Paper Intro\n 2:53 - Problems & Environments\n 8:11 - Plasticity Decay Experiments\n 11:45 - Continual Backprop Explained\n 15:54 - Continual Backprop Experiments\n 22:00 - Extra Interesting Experiments\n 25:34 - Summary \n ​\n Paper link: https://arxiv.org/abs/2108.06325\n    submitted by    /u/SlickBlueML  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twc4or/d_paper_explained_continual_backprop_stochastic/",
          "publishedOn": "2022-04-04T20:27:50.000Z",
          "wordCount": 237,
          "title": "[D] Paper Explained - Continual Backprop: Stochastic Gradient Descent with Persistent Randomness",
          "imageUrl": "https://external-preview.redd.it/fOTo43KuL6oL4o_WNxFDpy-aere0pzHjmcSlF2unamc.jpg?auto=webp&s=bc72dbd3a79a558d333d642635b7f1cc1b5d73a8"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw9jp5/r_googles_540b_dense_model_pathways_llm_unlocks/",
          "author": null,
          "description": "Blog: https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\n Paper: https://goo.gle/palm-paper\n - AFAIK from the Blogpost, Scaling laws still hold up (i.e not yet plateaued)\n - New transfer learning capabilities, outperforms fine-tuned models with 50x less data (Codex-12B)\n - The interesting part is how it meta-learns techy geeky jokes and is able to correlate concepts, and explain jokes suggesting starting doing a bit more meta-learning than GPT3 ever could.... But still not enough to generate decent ones (though the joke wasn't particularly humorous, so I may be underestimating)\n SoTA on various tasks, chain-of-thought-reasoning still holds up to scaling and outperforms some reasoning benchmarks, BIG-bench sees a huge improvement and general LLM thingys :)\n    submitted by    /u/Competitive-Rub-1958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw9jp5/r_googles_540b_dense_model_pathways_llm_unlocks/",
          "publishedOn": "2022-04-04T18:42:07.000Z",
          "wordCount": 1256,
          "title": "[R] Google's 540B (Dense) model Pathways LLM, \"Unlocks\" new tasks proportional to scale",
          "imageUrl": "https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?auto=webp&s=d45552298a94c0bc0e771853afe179cbb0e3f951"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw4wyj/r_minimum_description_length_recurrent_neural/",
          "author": null,
          "description": "https://arxiv.org/abs/2111.00600\n https://preview.redd.it/l6dni0007jr81.png?width=4888&format=png&auto=webp&s=82c7c9b9433b79c66318090ff85e4535c35ddb18\n    submitted by    /u/inland-1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw4wyj/r_minimum_description_length_recurrent_neural/",
          "publishedOn": "2022-04-04T15:33:42.000Z",
          "wordCount": 153,
          "title": "[R] Minimum Description Length Recurrent Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw2ec1/r_cfp_evorl_gecco_2022_one_week_before_the/",
          "author": null,
          "description": "CALL FOR PAPERS\n EvoRL 2022\n Evolutionary Reinforcement Learning workshop at GECCO 2022, July 9-13, Boston, USA\n \n In recent years reinforcement learning (RL) has received a lot of attention thanks to its performance and ability to address complex tasks. At the same time, multiple recent papers, notably work from OpenAI, have shown that evolution strategies (ES) can be competitive with standard RL algorithms on some problems while being simpler and more scalable. Similar results were obtained by researchers from Uber, this time using a gradient-free genetic algorithm (GA) to train deep neural networks on complex control tasks. Moreover, recent research in the field of evolutionary algorithms (EA) has led to the development of algorithms like Novelty Search and Quality Diversity, capable of…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw2ec1/r_cfp_evorl_gecco_2022_one_week_before_the/",
          "publishedOn": "2022-04-04T13:45:43.000Z",
          "wordCount": 600,
          "title": "[R] CfP EvoRL @ GECCO 2022. One week before the deadline!",
          "imageUrl": "https://external-preview.redd.it/lK42WwByGG32nygWSBuOYR3KR5RyUTDVfuLYvfjqmTI.jpg?auto=webp&s=02c389b64acc7a9d40c4c4ad6555c2381750877f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw0c1o/p_looking_for_a_dataset/",
          "author": null,
          "description": "Hey! New Here. I logged back into Reddit after years just to ask this question on this forum. I need to test a model, based loosely on BERT, that classifies a piece of text as having right or left political ideology leaning and whether it promotes any racial or religious stereotypes.\n For training purpose we used SBIC, IBC, and Stereoset. Though these only contain short sentences which are labeled as belonging to only one of the above categories.\n Is anyone aware of any other Dataset which can be used for this purpose, which hopefully contains text labeled as promoting or containing a political leaning (left/right, conservative/liberal, neutral) and further either any racial or religious stereotypes?\n Very thankful in adv\n    submitted by    /u/Fee_Imaginary  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw0c1o/p_looking_for_a_dataset/",
          "publishedOn": "2022-04-04T12:02:44.000Z",
          "wordCount": 205,
          "title": "[P] Looking for a dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvwnwy/p_random_relational_graph_convolutional_networks/",
          "author": null,
          "description": "📑 The Random R-GCN code has just been released!\n 📝 With just a few lines of code, you can now create embeddings of entities in a Knowledge Graph.\n ​\n Minimal example on how to create embeddings with RR-GCN\n ​\n 💡 RR-GCN does not require training and is competitive to fully trained R-GCNs.\n 👉 https://github.com/predict-idlab/RR-GCN\n    submitted by    /u/givdwiel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvwnwy/p_random_relational_graph_convolutional_networks/",
          "publishedOn": "2022-04-04T08:07:48.000Z",
          "wordCount": 143,
          "title": "[P] Random Relational Graph Convolutional Networks (RR-GCN)",
          "imageUrl": "https://external-preview.redd.it/hbnqn3Smcm-XXgFP9D-4dlKcnNwPcAkdToaX-b-_zw0.jpg?auto=webp&s=0bafa0817ea6dee3b3d7c145ec6dead117ef8d65"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvug94/r_diffusionclip_textguided_diffusion_models_for/",
          "author": null,
          "description": "submitted by    /u/ImBradleyKim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvug94/r_diffusionclip_textguided_diffusion_models_for/",
          "publishedOn": "2022-04-04T05:38:01.000Z",
          "wordCount": 388,
          "title": "[R] DiffusionCLIP: Text-Guided Diffusion Models for \"Robust\" Image Manipulation (CVPR 2022)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvr2ib/p_transformers_for_software_engineers/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvr2ib/p_transformers_for_software_engineers/",
          "publishedOn": "2022-04-04T02:36:40.000Z",
          "wordCount": 95,
          "title": "[P] Transformers for Software Engineers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvntfs/d_unconventional_computer_vision_problems_that/",
          "author": null,
          "description": "Given that most benchmarks for image classification are based on regular, everyday world objects RGB images (or grayscale), what are some unconventional science cases where 2D inputs are substantially different from what we are used to perceive by eye? \n For example, I'm interested in cases where spatial information can't be constrained to narrow pixel value ranges, such as exponential signals. Or that any standard normalisation (say min-max, zscore) and normalisation layers are not applicable and could lead to the loss of information.\n One of these cases is Astronomy. However, most practitioners try to to adapt the problem to established standards (say fake RGB images, log scaling flux images, etc). What are other cases out there where the nature of the 2D inputs are very distinct to what we are used to parse through our eyes and what deep nets are benchmarked on? I'm curious about tailored solutions that would intrinsically change the way the deep nets are constructed to solve the research question.\n    submitted by    /u/astroferreira  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvntfs/d_unconventional_computer_vision_problems_that/",
          "publishedOn": "2022-04-03T23:58:19.000Z",
          "wordCount": 322,
          "title": "[D] Unconventional computer vision problems that are intrinsically different from classifying ordinary stuff",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvjw43/researchprojectlibrary_dogfeeding_a_new_machine/",
          "author": null,
          "description": "Hi everyone!\n I'm Atindriyo Sanyal, one of the founders of the ML company Galileo (https://rungalileo.io/). We're building a cool new tool/framework for ML practitioners that helps shine a light on the data you are training your models with.\n I'd love to get some feedback on the product, and since we're still in private beta, I'm looking for folks to try out the product on their datasets and models. It's easy to use and hooks into popular frameworks such as pyTorch, Tensorflow, Keras, SpaCy etc. \n Caveat: Currently the tool only works for NLP use cases (think text classification, NER etc).\n I'll be giving $100 to folks who are willing to give some time to this and provide feedback on the usability of the product. If you're interested, here's a really tiny form (should take <1 minute to fill) for you to fill out. I'll review the applications and send you an email for a follow up Zoom chat where I'll share the software artifacts with you!\n https://docs.google.com/forms/d/11V20C_J_SyNaX7QL6DasnTe7f0UiueUyaKdmt3xL1oI/edit\n Look forward and happy (machine) learning!\n - Atindriyo\n P.S. If you have any questions or want to chat personally, send me an email at [atin@rungalileo.io](mailto:atin@rungalileo.io).\n    submitted by    /u/atindriyo_galileo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvjw43/researchprojectlibrary_dogfeeding_a_new_machine/",
          "publishedOn": "2022-04-03T21:03:32.000Z",
          "wordCount": 295,
          "title": "[Research][Project][Library] Dog-feeding a new Machine Learning data tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvfx9r/d_pain_points_when_using_gpu_instance_platforms/",
          "author": null,
          "description": "Hi everyone, I just launched a GPU compute instance platform (think lambdalabs, fluidstack, aws EC2, vast), and I was wondering what pain points everyone has with existing solutions. I'm not trying to sell anyone anything, but I want to look for feedback that will help me to build a better product.\n My current thoughts are\n  \nEase of getting data into the platform\n Ease of getting data off of the platform\n Automation for spinning up and down instances\n Availability of the type of instance you want\n Price too high\n Not enough/too many abstractions\n  \nTIA and I look forward to some good discussions!\n    submitted by    /u/runpod-io  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvfx9r/d_pain_points_when_using_gpu_instance_platforms/",
          "publishedOn": "2022-04-03T18:23:04.000Z",
          "wordCount": 269,
          "title": "[D] Pain points when using GPU instance platforms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvc7xl/r_efficientvdvae_an_opensource_memoryefficient/",
          "author": null,
          "description": "Hello everyone :)\n We have released last week our paper \"Efficient-VDVAE: Less is more\" with code!\n We present simple modifications to the Very Deep VAE to make it converge up to 2.6x times faster and save up to 20x times memory load. We also introduce a gradient smoothing technique to improve stability during training. Our model achieves comparable or better negative log-likelihood (NLL) on 7 commonly used datasets.\n Additionally, we make an argument against existing 5-bit benchmarks. We empirically show as well that 3% of the latent space is enough to encode the data information without any performance loss. Thus, indicating the potential to efficiently leverage the Hierarchical VAE's latent space in downstream tasks.\n  \nPaper: https://arxiv.org/abs/2203.13751\n Code: https://github.com/Rayhane-mamah/Efficient-VDVAE\n Paperswithcode: https://paperswithcode.com/paper/efficient-vdvae-less-is-more\n  \nFeedback is very much appreciated!\n https://preview.redd.it/tjua1xpq3cr81.png?width=878&format=png&auto=webp&s=718bd91fd648acd673ddab1ad5342207e8be09e7\n    submitted by    /u/Louay-AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvc7xl/r_efficientvdvae_an_opensource_memoryefficient/",
          "publishedOn": "2022-04-03T15:46:10.000Z",
          "wordCount": 225,
          "title": "[R] Efficient-VDVAE: An open-source memory-efficient and stable very deep hierarchical VAE",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tv9fuv/r_deepdpm_deep_clustering_with_an_unknown_number/",
          "author": null,
          "description": "Hey everyone :)\n We've just released the code for our paper (accepted to CVPR2022) \n DeepDPM is a nonparametric deep-clustering method which unlike most deep clustering methods, does not require knowing the number of clusters, K; rather, it infers it as a part of the overall learning. Using a split/merge framework to change the clusters number adaptively and a novel loss, our proposed method outperforms existing (both classical and deep) nonparametric methods.\n While the few existing deep nonparametric methods lack scalability, we show ours by being the first such method that reports its performance on ImageNet.\n ​\n  \nPaper: https://arxiv.org/abs/2203.14309\n Code: https://github.com/BGU-CS-VIL/DeepDPM/\n  \nBelow are some examples of clusters our method found in ImageNet.\n https://preview.redd.it/jw5kvcuzfbr81.jpg?width=737&format=pjpg&auto=webp&s=5b61cdd0efdea7c92aba611171e5dc7f4276c892\n    submitted by    /u/shahaff32  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tv9fuv/r_deepdpm_deep_clustering_with_an_unknown_number/",
          "publishedOn": "2022-04-03T13:36:53.000Z",
          "wordCount": 1327,
          "title": "[R] DeepDPM: Deep Clustering With an Unknown Number of Clusters",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        }
      ]
    },
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Jay Alammar",
      "feedUrl": "https://jalammar.github.io/feed.xml",
      "siteUrl": "http://jalammar.github.io/",
      "articles": []
    },
    {
      "title": "Distill",
      "feedUrl": "https://distill.pub/rss.xml",
      "siteUrl": "https://distill.pub",
      "articles": []
    },
    {
      "title": "inFERENCe",
      "feedUrl": "https://www.inference.vc/rss",
      "siteUrl": "https://www.inference.vc/",
      "articles": []
    },
    {
      "title": "AI Trends",
      "feedUrl": "https://www.aitrends.com/feed",
      "siteUrl": "https://www.aitrends.com",
      "articles": []
    },
    {
      "title": "AI Weirdness",
      "feedUrl": "https://aiweirdness.com/rss",
      "siteUrl": "https://www.aiweirdness.com/",
      "articles": [
        {
          "id": "623e899b5ee669004d985647",
          "author": "Janelle Shane",
          "description": "\"The Megalodon was a large bivalve, measuring up to 2.5 meters in length. Its shell was covered in spines, and it had a large, powerful jaw for crushing prey.\"\nAlthough the megalodon is the most widely known as a giant prehistoric shark, I recently learned that Megalodon",
          "link": "https://www.aiweirdness.com/how-to-get-ai-to-confuse-a-shark-with-a-clam/",
          "publishedOn": "2022-04-29T13:34:23.000Z",
          "wordCount": 1088,
          "title": "How to get AI to confuse a shark with a clam",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/04/megalodon-teeth2.png"
        },
        {
          "id": "625371eebd518e003d7289de",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-gpt-3-answers-my-questions-about-sawflies-badly/",
          "publishedOn": "2022-04-29T13:33:51.000Z",
          "wordCount": 440,
          "title": "Bonus: GPT-3 answers my questions about sawflies, badly",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/04/megalodon_pollinator.png"
        },
        {
          "id": "62563d78e262cd003d13f40f",
          "author": "Janelle Shane",
          "description": "How would AI decorate an easter egg?\nI've tried this before by training an image-generating model exclusively on pictures of easter eggs I decorated (they came out plain, if a bit wobbly).\nI decided to see what I would get using a model based on CLIP, which has",
          "link": "https://www.aiweirdness.com/ai-generated-easter-eggs/",
          "publishedOn": "2022-04-14T13:54:58.000Z",
          "wordCount": 811,
          "title": "AI-generated easter eggs",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/04/ukranian-pysanky-easter-egg-collection--trending-on-artstation-variations3.png"
        },
        {
          "id": "625662e4e262cd003d13f4f4",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-what-does-the-x-ray-of-an-easter-egg-look-like/",
          "publishedOn": "2022-04-14T13:54:40.000Z",
          "wordCount": 434,
          "title": "Bonus: What does the x-ray of an Easter egg look like?",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/04/easter-eggs-decorated-by-children--trending-on-artstation.png"
        }
      ]
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed.xml",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": [
        {
          "id": "http://bair.berkeley.edu/blog/2022/04/29/reward-reports/",
          "author": null,
          "description": "Deep reinforcement learning (DRL) is transitioning from a research field focused on game playing to a technology with real-world applications. Notable examples include DeepMind’s work on controlling a nuclear reactor or on improving Youtube video compression, or Tesla attempting to use a method inspired by MuZero for autonomous vehicle behavior planning. But the exciting potential for real world applications of RL should also come with a healthy dose of caution - for example RL policies are well known to be vulnerable to exploitation, and methods for safe and robust policy development are an active area of research.\nAt the same time as the emergence of powerful RL systems in the real world, the public and researchers are expressing an increased appetite for fair, aligned, and safe machine …",
          "link": "http://bair.berkeley.edu/blog/2022/04/29/reward-reports/",
          "publishedOn": "2022-04-29T12:00:00.000Z",
          "wordCount": 2439,
          "title": "Designing Societally Beneficial Reinforcement Learning Systems",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/reward-reports/fb-exo.png"
        },
        {
          "id": "http://bair.berkeley.edu/blog/2022/04/25/rl-or-bc/",
          "author": null,
          "description": "Figure 1: Summary of our recommendations for when a practitioner should BC and various imitation learning style methods, and when they should use offline RL approaches.\n\n\nOffline reinforcement learning allows learning policies from previously collected data, which has profound implications for applying RL in domains where running trial-and-error learning is impractical or dangerous, such as safety-critical settings like autonomous driving or medical treatment planning. In such scenarios, online exploration is simply too risky, but offline RL methods can learn effective policies from logged data collected by humans or heuristically designed controllers.  Prior learning-based control methods have also approached learning from existing data as imitation learning: if the data is generally “goo…",
          "link": "http://bair.berkeley.edu/blog/2022/04/25/rl-or-bc/",
          "publishedOn": "2022-04-25T12:00:00.000Z",
          "wordCount": 3238,
          "title": "Should I Use Offline RL or Imitation Learning?",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/maers/maers.png"
        },
        {
          "id": "http://bair.berkeley.edu/blog/2022/04/20/rvs/",
          "author": null,
          "description": "A demonstration of the RvS policy we learn with just supervised learning and a depth-two MLP. It uses no TD learning, advantage reweighting, or Transformers!\n\n\nOffline reinforcement learning (RL) is conventionally approached using value-based methods based on temporal difference (TD) learning. However, many recent algorithms reframe RL as a supervised learning problem. These algorithms learn conditional policies by conditioning on goal states (Lynch et al., 2019; Ghosh et al., 2021), reward-to-go (Kumar et al., 2019; Chen et al., 2021), or language descriptions of the task (Lynch and Sermanet, 2021).\nWe find the simplicity of these methods quite appealing. If supervised learning is enough to solve RL problems, then offline RL could become widely accessible and (relatively) easy to implemen…",
          "link": "http://bair.berkeley.edu/blog/2022/04/20/rvs/",
          "publishedOn": "2022-04-20T09:00:00.000Z",
          "wordCount": 1515,
          "title": "Offline RL Made Easier: No TD Learning, Advantage Reweighting, or Transformers",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/rvs/rvs-overview.png"
        }
      ]
    },
    {
      "title": "Becoming Human: Artificial Intelligence Magazine - Medium",
      "feedUrl": "https://becominghuman.ai/feed",
      "siteUrl": "https://becominghuman.ai?source=rss----5e5bef33608a---4",
      "articles": [
        {
          "id": "https://medium.com/p/f405f0d31981",
          "author": "Amyra Sheldon",
          "description": "Source: Managed Healthcare Executive",
          "link": "https://becominghuman.ai/10-ways-technology-is-changing-healthcare-how-innovation-is-impacting-the-medical-industry-f405f0d31981?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-05-02T15:38:50.000Z",
          "wordCount": 1837,
          "title": "10 Ways Technology is Changing Healthcare: How Innovation is Impacting the Medical Industry",
          "imageUrl": "https://miro.medium.com/max/1000/0*poPNyLyb8cQ7oUqk"
        },
        {
          "id": "https://medium.com/p/898b6e959b85",
          "author": "Massimiliano Versace",
          "description": "It’s Monday morning, and Paul opens one of several emails sent by his boss, Heather. Her email seems a bit unusual, asking Paul to rush to…\nContinue reading on Becoming Human: Artificial Intelligence Magazine »",
          "link": "https://becominghuman.ai/i-doubt-therefore-i-am-said-ai-898b6e959b85?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-29T13:10:58.000Z",
          "wordCount": 1118,
          "title": "‘I Doubt, Therefore I Am,’ Said AI",
          "imageUrl": "https://miro.medium.com/max/910/1*iakrHHC4XWWn3NBia2fP4w.jpeg"
        },
        {
          "id": "https://medium.com/p/4894e60a482f",
          "author": "inVerita",
          "description": "The 2019 pandemic became a catalyst for retail businesses and their customers.\nContinue reading on Becoming Human: Artificial Intelligence Magazine »",
          "link": "https://becominghuman.ai/top-11-retail-technology-trends-for-2022-4894e60a482f?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-28T15:03:39.000Z",
          "wordCount": 1820,
          "title": "Top 11 Retail Technology Trends For 2022",
          "imageUrl": "https://miro.medium.com/max/1200/0*WNJkp3aekcKKMGTf"
        },
        {
          "id": "https://medium.com/p/62b738c1bfa0",
          "author": "Rijul Sachdeva",
          "description": "TinyML is a groundbreaking technology! Possessing a lot of potential it is sure to grow exponentially in the coming years.",
          "link": "https://becominghuman.ai/tinyml-an-underrated-field-of-machine-learning-62b738c1bfa0?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-27T13:24:59.000Z",
          "wordCount": 844,
          "title": "TinyML, an underrated field of Machine Learning",
          "imageUrl": "https://miro.medium.com/max/1200/1*2bAfqY7PXf11hzwioF_2bQ.png"
        },
        {
          "id": "https://medium.com/p/48ab491227e5",
          "author": "Rijul Sachdeva",
          "description": "Yes and no. So, if you asked this question, good one! When I was new to this stuff, I had the same question and searched up a lot about it.",
          "link": "https://becominghuman.ai/the-skepticism-of-ai-robotics-and-machine-learning-48ab491227e5?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-26T13:25:04.000Z",
          "wordCount": 980,
          "title": "Misconceptions about AI, Robotics, and Machine Learning",
          "imageUrl": "https://miro.medium.com/max/1200/1*r4MsurnzyVbRebjcZtJ72g.png"
        },
        {
          "id": "https://medium.com/p/2cbd22f1c3a",
          "author": "Aminah Mardiyyah Rufai",
          "description": "At some point, we’ve all used Google translate, Microsoft,DeepL or Bing translator to impress our friends/colleagues who speak a different…",
          "link": "https://becominghuman.ai/lets-talk-about-machine-translation-the-powering-engine-behind-google-translate-2cbd22f1c3a?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-25T14:30:02.000Z",
          "wordCount": 1301,
          "title": "Let’s Talk about Machine Translation: The powering engine behind “Google Translate”",
          "imageUrl": "https://miro.medium.com/max/1200/0*-OPQUThzoHf3uZ2J.png"
        },
        {
          "id": "https://medium.com/p/fc5449871adf",
          "author": "Shaibu Samuel",
          "description": "Artificial Intelligence is all over the world today. From the use of virtual assistants like Siri, Alexa, or Cortana, to improving…",
          "link": "https://becominghuman.ai/7-ways-your-business-can-plan-for-artificial-intelligence-fc5449871adf?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-22T13:44:21.000Z",
          "wordCount": 731,
          "title": "7 Ways Your Business Can Plan For Artificial Intelligence",
          "imageUrl": "https://miro.medium.com/max/1200/1*2qqjQQ0wW37Lbvkx50zPxg.jpeg"
        },
        {
          "id": "https://medium.com/p/35e386bfa4bc",
          "author": "Aminah Mardiyyah Rufai",
          "description": "Yes! You read the heading right. There’s indeed a difference between loss functions and Metrics in the field of Machine Learning. However…",
          "link": "https://becominghuman.ai/understanding-the-difference-between-loss-functions-and-metrics-in-machine-learning-deep-learning-35e386bfa4bc?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-21T16:22:10.000Z",
          "wordCount": 568,
          "title": "Understanding the Difference between Loss Functions and Metrics in Machine Learning/Deep Learning",
          "imageUrl": "https://miro.medium.com/freeze/max/1200/0*eP8gmy3zzHCgClK4.gif"
        },
        {
          "id": "https://medium.com/p/88215ec781b1",
          "author": "MobiDev",
          "description": "To start deeply investigating the AI app development process, it’s important to first understand how these projects differ from regular app…",
          "link": "https://becominghuman.ai/ai-application-development-guide-for-business-owners-88215ec781b1?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-20T15:30:52.000Z",
          "wordCount": 2817,
          "title": "AI Application Development Guide for Business Owners",
          "imageUrl": "https://miro.medium.com/max/1200/1*FP41xfegFJgv7RhOHf79iw.jpeg"
        },
        {
          "id": "https://medium.com/p/d3e8cac3e17c",
          "author": "Roger Brown",
          "description": "Shared duties have always been the most critical component of every successful organization, regardless of its nature or size. When it…",
          "link": "https://becominghuman.ai/a-quick-guide-to-find-the-right-minds-for-annotation-is-so-famous-but-why-d3e8cac3e17c?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-19T15:35:45.000Z",
          "wordCount": 1330,
          "title": "A Quick Guide To Find The Right Minds For Annotation Is So Famous, But Why?",
          "imageUrl": "https://miro.medium.com/max/848/1*vjtDRQF_ASaToXyPGTrwEA.png"
        },
        {
          "id": "https://medium.com/p/1d65735caee0",
          "author": "Lars Nielsen",
          "description": "7 use-cases where you can make your python code more nifty, concise and elegant — without compromising readability.\nContinue reading on Becoming Human: Artificial Intelligence Magazine »",
          "link": "https://becominghuman.ai/7-tips-for-making-your-code-more-pythonic-and-elegant-1d65735caee0?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-18T14:48:17.000Z",
          "wordCount": 1220,
          "title": "7 Tips for making your code more ‘pythonic’ and elegant",
          "imageUrl": "https://miro.medium.com/max/1200/1*JhUAwZvGQwxeR3qg3hdixw.jpeg"
        },
        {
          "id": "https://medium.com/p/9125822b6e65",
          "author": "Sasha Andrieiev",
          "description": "Here’s the truth.",
          "link": "https://becominghuman.ai/data-scientists-vs-bi-developer-whats-the-difference-9125822b6e65?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-15T13:40:54.000Z",
          "wordCount": 322,
          "title": "Data Scientists vs. BI Developer: What’s the Difference?",
          "imageUrl": "https://miro.medium.com/max/800/1*7FYfi-hfQULy3hVFeUyiRw.png"
        },
        {
          "id": "https://medium.com/p/3d6da629b102",
          "author": "Riccardo Castellani",
          "description": "An inside look at how REINFORCEMENT learning, without past reference, extracts “optimal” decisions through simple interaction …",
          "link": "https://becominghuman.ai/r-learning-ai-self-taking-over-processes-3d6da629b102?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-14T13:34:18.000Z",
          "wordCount": 2915,
          "title": "R-Learning AI self-taking over processes",
          "imageUrl": "https://miro.medium.com/max/1200/1*fIApuYxS28zOjIdeg7mDwQ.png"
        },
        {
          "id": "https://medium.com/p/68401b4b0f57",
          "author": "Robert Dale",
          "description": "In the past few years, high-quality automated text-to-speech synthesis has effectively become a commodity, with easy access to cloud-based…\nContinue reading on Becoming Human: Artificial Intelligence Magazine »",
          "link": "https://becominghuman.ai/the-voice-synthesis-business-2022-update-68401b4b0f57?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-13T14:27:46.000Z",
          "wordCount": 4613,
          "title": "The Voice Synthesis Business: 2022 Update",
          "imageUrl": "https://miro.medium.com/max/1200/0*a40Ik7RGkqFYxECQ"
        },
        {
          "id": "https://medium.com/p/fdb761737457",
          "author": "Tyger A.C",
          "description": "(A Sci-Fi Ultrashort)",
          "link": "https://becominghuman.ai/what-can-you-tell-us-about-him-fdb761737457?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-12T16:07:15.000Z",
          "wordCount": 1589,
          "title": "What can you tell us about him?",
          "imageUrl": "https://miro.medium.com/max/1200/1*nxLxVw7n78_QHZhv9ITAsw.jpeg"
        }
      ]
    },
    {
      "title": "MIT News - Artificial intelligence",
      "feedUrl": "http://news.mit.edu/rss/topic/artificial-intelligence2",
      "siteUrl": "https://news.mit.edu/rss/topic/artificial-intelligence2",
      "articles": [
        {
          "id": "https://news.mit.edu/2022/one-motion-capture-neural-network-0429",
          "author": "Lauren Hinkel | MIT-IBM Watson AI Lab",
          "description": "A new neural network approach captures the characteristics of a physical system’s dynamic motion from video, regardless of rendering configuration or image differences.",
          "link": "https://news.mit.edu/2022/one-motion-capture-neural-network-0429",
          "publishedOn": "2022-04-29T18:00:00.000Z",
          "wordCount": 2146,
          "title": "A one-up on motion capture",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/mitsuba-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/wave-model-ai-0429",
          "author": "Jennifer Chu | MIT News Office",
          "description": "Their model’s predictions should help researchers improve ocean climate simulations and hone the design of offshore structures.",
          "link": "https://news.mit.edu/2022/wave-model-ai-0429",
          "publishedOn": "2022-04-29T09:00:00.000Z",
          "wordCount": 1939,
          "title": "Engineers use artificial intelligence to capture the complexity of breaking waves",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-BreakingWaves-01.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/how-can-we-reduce-carbon-footprint-global-computing-0428",
          "author": "Stephanie Schorow | Climate and Sustainability Consortium",
          "description": "Workshop hosted by MIT’s Climate and Sustainability Consortium, MIT-IBM Watson AI Lab, and the MIT Schwarzman College of Computing highlights how new approaches to computing can save energy and help the planet.",
          "link": "https://news.mit.edu/2022/how-can-we-reduce-carbon-footprint-global-computing-0428",
          "publishedOn": "2022-04-28T13:45:00.000Z",
          "wordCount": 2319,
          "title": "How can we reduce the carbon footprint of global computing?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/globe-digital.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/aging-brain-initiative-awards-fund-five-new-ideas-study-fight-neurodegeneration-0428",
          "author": "David Orenstein | Picower Institute for Learning and Memory",
          "description": "Competitive seed grants launch yearlong investigations of novel hypotheses about potential causes, biomarkers, treatments of Alzheimer’s and ALS.",
          "link": "https://news.mit.edu/2022/aging-brain-initiative-awards-fund-five-new-ideas-study-fight-neurodegeneration-0428",
          "publishedOn": "2022-04-28T13:20:00.000Z",
          "wordCount": 1685,
          "title": "Aging Brain Initiative awards fund five new ideas to study, fight neurodegeneration",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/abi-seedgrant-winners-2022.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/machine-learning-harnessed-extreme-computing-aids-fusion-energy-development-0427",
          "author": "Martin Greenwald | Plasma Science and Fusion Center",
          "description": "Linking techniques from machine learning with advanced numerical simulations, MIT researchers take an important step in state-of-the-art predictions for fusion plasmas.",
          "link": "https://news.mit.edu/2022/machine-learning-harnessed-extreme-computing-aids-fusion-energy-development-0427",
          "publishedOn": "2022-04-27T19:00:00.000Z",
          "wordCount": 1653,
          "title": "Machine learning, harnessed to extreme computing, aids fusion energy development",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-CGYRO-00.png"
        },
        {
          "id": "https://news.mit.edu/2022/ai-molecules-new-drugs-0426",
          "author": "Adam Zewe | MIT News Office",
          "description": "A new artificial intelligence technique only proposes candidate molecules that can actually be produced in a lab.",
          "link": "https://news.mit.edu/2022/ai-molecules-new-drugs-0426",
          "publishedOn": "2022-04-26T04:00:00.000Z",
          "wordCount": 1937,
          "title": "A smarter way to develop new drugs",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Actionable-Molecules-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/estimating-informativeness-data-0425",
          "author": "Rachel Paiste | Department of Brain and Cognitive Sciences",
          "description": "MIT researchers can now estimate how much information data are likely to contain, in a more accurate and scalable way than previous methods.",
          "link": "https://news.mit.edu/2022/estimating-informativeness-data-0425",
          "publishedOn": "2022-04-25T21:10:00.000Z",
          "wordCount": 1701,
          "title": "Estimating the informativeness of data",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/entropy-estimators_0.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/teach-pick-robots-new-task-0425",
          "author": "Adam Zewe | MIT News Office",
          "description": "Researchers have developed a technique that enables a robot to learn a new pick-and-place task with only a handful of human demonstrations.",
          "link": "https://news.mit.edu/2022/teach-pick-robots-new-task-0425",
          "publishedOn": "2022-04-25T04:00:00.000Z",
          "wordCount": 2027,
          "title": "An easier way to teach robots new skills",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-DemonstrationRobot-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/new-unsupervised-computer-vision-algorithm-stego-0421",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "MIT CSAIL scientists created an algorithm to solve one of the hardest tasks in computer vision: assigning a label to every pixel in the world, without human supervision.",
          "link": "https://news.mit.edu/2022/new-unsupervised-computer-vision-algorithm-stego-0421",
          "publishedOn": "2022-04-21T16:20:00.000Z",
          "wordCount": 2091,
          "title": "A new state of the art for unsupervised vision",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-STEGO-2_0.png"
        },
        {
          "id": "https://news.mit.edu/2022/machine-learning-anticipating-behavior-cars-0421",
          "author": "Adam Zewe | MIT News Office",
          "description": "A new machine-learning system may someday help driverless cars predict the next moves of nearby drivers, cyclists, and pedestrians in real-time.",
          "link": "https://news.mit.edu/2022/machine-learning-anticipating-behavior-cars-0421",
          "publishedOn": "2022-04-21T04:00:00.000Z",
          "wordCount": 1951,
          "title": "Anticipating others’ behavior on the road",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Driving-Prediction-01-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/ethical-machine-learning-course-0415",
          "author": "Adam Zewe | MIT News Office",
          "description": "A multidisciplinary team of graduate students helps infuse ethical computing content into MIT’s largest machine learning course.",
          "link": "https://news.mit.edu/2022/ethical-machine-learning-course-0415",
          "publishedOn": "2022-04-15T04:00:00.000Z",
          "wordCount": 2223,
          "title": "Learning to think critically about machine learning",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Ethical-Computing-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/three-mit-students-awarded-paul-daisy-soros-fellowships-new-americans-0414",
          "author": "Julia Mongo | Office of Distinguished Fellowships",
          "description": "Fellowship funds graduate studies for outstanding immigrants and children of immigrants.",
          "link": "https://news.mit.edu/2022/three-mit-students-awarded-paul-daisy-soros-fellowships-new-americans-0414",
          "publishedOn": "2022-04-14T19:30:00.000Z",
          "wordCount": 1784,
          "title": "Three from MIT awarded 2022 Paul and Daisy Soros Fellowships for New Americans",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/2022-MIT-PDSoros-Fellows.png"
        },
        {
          "id": "https://news.mit.edu/2022/mit-schwarzman-college-computing-unveils-break-through-tech-ai-0413",
          "author": "MIT Schwarzman College of Computing",
          "description": "New program strives to bridge the talent gap for underrepresented groups in the tech industry.",
          "link": "https://news.mit.edu/2022/mit-schwarzman-college-computing-unveils-break-through-tech-ai-0413",
          "publishedOn": "2022-04-13T17:45:00.000Z",
          "wordCount": 1434,
          "title": "MIT Schwarzman College of Computing unveils Break Through Tech AI",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/BreakThroughTechAI-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/ai-perovskite-solar-manufacturing-0413",
          "author": "David L. Chandler | MIT News Office",
          "description": "Perovskite materials would be superior to silicon in PV cells, but manufacturing such cells at scale is a huge hurdle. Machine learning can help.",
          "link": "https://news.mit.edu/2022/ai-perovskite-solar-manufacturing-0413",
          "publishedOn": "2022-04-13T15:00:00.000Z",
          "wordCount": 2112,
          "title": "Engineers enlist AI to help scale up advanced solar cell manufacturing",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Perovskite-Manufacturing-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/futuremakers-programs-kids-get-their-minds-around-and-hands-ai-0412",
          "author": "Kim Patch | MIT Media Lab",
          "description": "The programs are designed to foster an understanding of how artificial intelligence technologies work, including their social implications.",
          "link": "https://news.mit.edu/2022/futuremakers-programs-kids-get-their-minds-around-and-hands-ai-0412",
          "publishedOn": "2022-04-12T15:00:00.000Z",
          "wordCount": 2281,
          "title": "MIT’s FutureMakers programs help kids get their minds around — and hands on — AI",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/futuremakers.png"
        },
        {
          "id": "https://news.mit.edu/2022/optimized-solution-face-recognition-0406",
          "author": "Jennifer Michalowski | McGovern Institute for Brain Research",
          "description": "When artificial intelligence is tasked with visually identifying objects and faces, it assigns specific components of its network to face recognition — just like the human brain.",
          "link": "https://news.mit.edu/2022/optimized-solution-face-recognition-0406",
          "publishedOn": "2022-04-06T15:25:00.000Z",
          "wordCount": 1511,
          "title": "An optimized solution for face recognition",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/face-recognition.png"
        },
        {
          "id": "https://news.mit.edu/2022/does-this-artificial-intelligence-think-human-0406",
          "author": "Adam Zewe | MIT News Office",
          "description": "A new technique compares the reasoning of a machine-learning model to that of a human, so the user can see patterns in the model’s behavior.",
          "link": "https://news.mit.edu/2022/does-this-artificial-intelligence-think-human-0406",
          "publishedOn": "2022-04-06T04:00:00.000Z",
          "wordCount": 2034,
          "title": "Does this artificial intelligence think like a human?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Shared-Interest-01-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/robots-dress-humans-without-full-picture-0405",
          "author": "Steve Nadis | MIT CSAIL",
          "description": "MIT researchers design a robot that has a trick or two up its sleeve.",
          "link": "https://news.mit.edu/2022/robots-dress-humans-without-full-picture-0405",
          "publishedOn": "2022-04-05T18:20:00.000Z",
          "wordCount": 1850,
          "title": "Robots dress humans without the full picture",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/robot-dressing-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/school-engineering-welcomes-thomas-tull-visiting-innovation-scholar-0404",
          "author": "Lori LoTurco | School of Engineering",
          "description": "Primary focus will be to advance and promote technology, innovation, and entrepreneurship across the school.",
          "link": "https://news.mit.edu/2022/school-engineering-welcomes-thomas-tull-visiting-innovation-scholar-0404",
          "publishedOn": "2022-04-04T19:40:00.000Z",
          "wordCount": 1252,
          "title": "School of Engineering welcomes Thomas Tull as visiting innovation scholar",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/thomas-tull-mit-00.jpg"
        }
      ]
    },
    {
      "title": "NVIDIA Blog",
      "feedUrl": "http://feeds.feedburner.com/nvidiablog",
      "siteUrl": "https://blogs.nvidia.com",
      "articles": [
        {
          "id": "https://blogs.nvidia.com/?p=56823",
          "author": "Scott Martin",
          "description": "Jack Morrison and Isaac Roberts, co-founders of Replica Labs, were restless two years after their 3D vision startup was acquired, seeking another adventure. Then, in 2018, when Morrison was mowing his lawn, it struck him: autonomous lawn mowers. The two, along with Davis Foster, co-founded Scythe Robotics. The company, based in Boulder, Colo., has a Read article >\nThe post Mown Away: Startup Rolls Out Autonomous Lawnmower With Cutting-Edge Tech appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/05/02/scythe-autonomous-lawnmower/",
          "publishedOn": "2022-05-02T16:00:28.000Z",
          "wordCount": 1039,
          "title": "Mown Away: Startup Rolls Out Autonomous Lawnmower With Cutting-Edge Tech",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/Scythe.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56857",
          "author": "Angie Lee",
          "description": "Edward McEvenue grew up making claymations in LEGO towns. Now, he’s creating photorealistic animations in virtual cities, drawing on more than a decade of experience in the motion graphics industry.\nThe post Meet the Omnivore: 3D Artist Creates Towering Work With NVIDIA Omniverse appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/05/02/edward-mcevenue-omniverse-creator/",
          "publishedOn": "2022-05-02T15:00:21.000Z",
          "wordCount": 970,
          "title": "Meet the Omnivore: 3D Artist Creates Towering Work With NVIDIA Omniverse",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/05/high-rise-reveal-still.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56831",
          "author": "Nicole Castro",
          "description": "Featuring stunning visuals from futuristic interstellar worlds, including colossal sand creatures, Dune captivated audiences around the world. The sci-fi film picked up six Oscars last month at the 94th Academy Awards, including for Best Sound and Visual Effects. Adapted from Frank Herbert’s 1965 novel of the same name, Dune tells the story of Paul Atreides, Read article >\nThe post How DNEG Helped Win Another Visual-Effects Oscar by Bringing ‘Dune’ to Life With NVIDIA RTX appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/28/dune-dneg-rtx/",
          "publishedOn": "2022-04-28T16:00:56.000Z",
          "wordCount": 1265,
          "title": "How DNEG Helped Win Another Visual-Effects Oscar by Bringing ‘Dune’ to Life With NVIDIA RTX",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/dune-blog-header.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56809",
          "author": "GeForce NOW Community",
          "description": "It’s a jam-packed GFN Thursday. This week brings the popular, free-to-play, action role-playing game Lost Ark to gamers across nearly all their devices, streaming on GeForce NOW. And that’s not all. GFN Thursday also delivers an upgraded experience in the 2.0.40 update. M1-based MacBooks, iMacs and Mac Minis are now supported natively. Plus, membership gift Read article >\nThe post Your Odyssey Awaits: Stream ‘Lost Ark’ to Nearly Any Device This GFN Thursday appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/28/geforce-now-thursday-april-28/",
          "publishedOn": "2022-04-28T13:00:29.000Z",
          "wordCount": 1260,
          "title": "Your Odyssey Awaits: Stream ‘Lost Ark’ to Nearly Any Device This GFN Thursday",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/gfn-thursday-4-28-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56667",
          "author": "Marc Spieler",
          "description": "A hundred and forty turbines in the North Sea — and some GPUs in the cloud — pumped wind under the wings of David Standingford and Jamil Appa’s dream. As colleagues at a British aerospace firm, they shared a vision of starting a company to apply their expertise in high performance computing across many industries. Read article >\nThe post Answers Blowin’ in the Wind: HPC Code Gives Renewable Energy a Lift appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/27/hpc-software-renewable-energy/",
          "publishedOn": "2022-04-27T15:00:19.000Z",
          "wordCount": 1150,
          "title": "Answers Blowin’ in the Wind: HPC Code Gives Renewable Energy a Lift",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/wind-farm-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56771",
          "author": "Brian Caulfield",
          "description": "Entrepreneur Jason Mars calls conversation our “first technology.” Before humans invented the wheel, crafted a spear or tamed fire, we mastered the superpower of talking to one another. That makes conversation an incredibly important tool. But if you’ve dealt with the automated chatbots deployed by the customer service arms of just about any big organization Read article >\nThe post What Is Conversational AI? ZeroShot Bot CEO Jason Mars Explains appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/27/what-is-conversational-ai-jason-mars/",
          "publishedOn": "2022-04-27T13:00:36.000Z",
          "wordCount": 711,
          "title": "What Is Conversational AI? ZeroShot Bot CEO Jason Mars Explains",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/mars-speaking.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56727",
          "author": "Stanley Tack",
          "description": "This week In the NVIDIA Studio, we’re launching the April NVIDIA Studio Driver with optimizations for the most popular 3D apps, including Unreal Engine 5, Cinema4D and Chaos Vantage. The driver also supports new NVIDIA Omniverse Connectors from Blender and Redshift.\nThe post In the NVIDIA Studio: April Driver Launches Alongside New NVIDIA Studio Laptops and Featured 3D Artist appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/26/in-the-nvidia-studio-april-26/",
          "publishedOn": "2022-04-26T13:00:19.000Z",
          "wordCount": 1518,
          "title": "In the NVIDIA Studio: April Driver Launches Alongside New NVIDIA Studio Laptops and Featured 3D Artist",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/nvidia-studio-ins-averkin-04262022-nv-blog-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56704",
          "author": "Angie Lee",
          "description": "When brainstorming a scene to best showcase the groundbreaking capabilities of the Omniverse platform, some NVIDIA artists turned to a cherished memory: enjoying ramen together in a mom-and-pop shop down a side street in Tokyo. Simmering pots of noodles, steaming dumplings, buzzing kitchen appliances, warm ambient lighting and glistening black ledger stools. These were all Read article >\nThe post Let Me Shoyu How It’s Done: Creating the NVIDIA Omniverse Ramen Shop appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/25/making-of-omniverse-ramen-shop/",
          "publishedOn": "2022-04-25T15:00:55.000Z",
          "wordCount": 1192,
          "title": "Let Me Shoyu How It’s Done: Creating the NVIDIA Omniverse Ramen Shop",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/ramen-still.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56666",
          "author": "Rick Merritt",
          "description": "A paper released today describes in the greatest detail to date the atmospheres on distant planets. Seeking the origins of what’s in and beyond the Milky Way, researchers surveyed 25 exoplanets, bodies that orbit stars far beyond our solar system. Specifically, they studied hot Jupiters, the largest and thus easiest to detect exoplanets, many sweltering Read article >\nThe post Stellar Weather: Researchers Describe the Skies of Exoplanets appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/25/exoplanet-hpc-researchers/",
          "publishedOn": "2022-04-25T11:00:53.000Z",
          "wordCount": 1118,
          "title": "Stellar Weather: Researchers Describe the Skies of Exoplanets",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/ESA-Hubble-cropped-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56696",
          "author": "Isha Salian",
          "description": "Different parts of the globe are experiencing distinct climate challenges — severe drought, dangerous flooding, reduced biodiversity or dense air pollution. The challenges are so great that no country can solve them on their own. But innovative startups worldwide are lighting the way, demonstrating how these daunting challenges can be better understood and addressed with Read article >\nThe post By Land, Sea and Space: How 5 Startups Are Using AI to Help Save the Planet appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/22/earth-day-5-inception-ai-startups/",
          "publishedOn": "2022-04-22T13:00:59.000Z",
          "wordCount": 964,
          "title": "By Land, Sea and Space: How 5 Startups Are Using AI to Help Save the Planet",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/earth-day.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56679",
          "author": "Scott Martin",
          "description": "Your next trip to the dentist might offer a taste of AI. Pearl, a West Hollywood startup, provides AI for dental images to assist in diagnosis. It landed FDA clearance last month, the first to get such a go-ahead for dentistry AI. The approval paves the way for its use in clinics across the United Read article >\nThe post Tooth Tech: AI Takes Bite Out of Dental Slide Misses by Assisting Doctors appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/21/tooth-tech-ai-takes-bite-out-of-dental-slide-misses-by-assisting-doctors/",
          "publishedOn": "2022-04-21T15:28:08.000Z",
          "wordCount": 1154,
          "title": "Tooth Tech: AI Takes Bite Out of Dental Slide Misses by Assisting Doctors",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/PearlBounding-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56671",
          "author": "GeForce NOW Community",
          "description": "The gods must be smiling this GFN Thursday — God of War today joins the GeForce NOW library. Sony Interactive Entertainment and Santa Monica Studios’ masterpiece is available to stream from GeForce NOW servers, across nearly all devices and at up to 1440p and 120 frames per second for RTX 3080 members. Get ready to Read article >\nThe post GFN Thursday Is Fit for the Gods: ‘God of War’ Arrives on GeForce NOW appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/21/geforce-now-thursday-april-21/",
          "publishedOn": "2022-04-21T13:00:54.000Z",
          "wordCount": 859,
          "title": "GFN Thursday Is Fit for the Gods: ‘God of War’ Arrives on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/gfn-thursday-4-21-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56607",
          "author": "Stanley Tack",
          "description": "Creating content is no longer tethered to using paint and stone as mediums, nor being in massive studios. Visual art can now be created anywhere, anytime. But being creative is still challenging and time-consuming. NVIDIA is making artistic workflows easier and faster by giving creators tools that enable them to remain in their flow state. Read article >\nThe post Welcome ‘In the NVIDIA Studio’: A Weekly Celebration of Extraordinary Artists, Their Inspiring Art and Innovative Techniques appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/19/in-the-nvidia-studio/",
          "publishedOn": "2022-04-19T13:00:17.000Z",
          "wordCount": 1147,
          "title": "Welcome ‘In the NVIDIA Studio’: A Weekly Celebration of Extraordinary Artists, Their Inspiring Art and Innovative Techniques",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2022/04/studio-ins-jasmin-habezai-fekri-full-landscape-loop.mp4",
            "length": "3978924",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/studio-ins-jasmin-habezai-fekri-bird-house-blog-hero-04192022.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56600",
          "author": "Scott Martin",
          "description": "Gil Makleff and Artem Koren are developing AI for meeting transcripts, creating time-savers like shareable highlights of the text that is often TL;DR (too long; didn’t read). The Sembly founders conceived the idea after years of working in enterprise operational consulting at UMT Consulting Group, which was acquired by Ernst & Young. “We had an Read article >\nThe post Startup Transforms Meeting Notes With Time-Saving Features appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/15/sembly-transforms-meeting-notes-with-time-saving-features/",
          "publishedOn": "2022-04-15T16:15:18.000Z",
          "wordCount": 904,
          "title": "Startup Transforms Meeting Notes With Time-Saving Features",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/Sembly.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56528",
          "author": "Brian Caulfield",
          "description": "Talk about a bright idea. A team of scientists has used GPU-accelerated deep learning to show how color can be brought to night-vision systems.  In a paper published this week in the journal PLOS One, a team of researchers at the University of California, Irvine led by Professor Pierre Baldi and Dr. Andrew Browne, describes how Read article >\nThe post A Night to Behold: Researchers Use Deep Learning to Bring Color to Night Vision appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/15/color-night-vision/",
          "publishedOn": "2022-04-15T13:00:03.000Z",
          "wordCount": 776,
          "title": "A Night to Behold: Researchers Use Deep Learning to Bring Color to Night Vision",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/see-in-the-dark-deep-learning.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56571",
          "author": "GeForce NOW Community",
          "description": "This GFN Thursday delivers more gr-EA-t games as two new titles from Electronic Arts join the GeForce NOW library. Gamers can now enjoy Need for Speed HEAT  and Plants vs. Zombies Garden Warfare 2 streaming from GeForce NOW to underpowered PCs, Macs, Chromebooks, SHIELD TV and mobile devices. It’s all part of the eight  total Read article >\nThe post GFN Thursday Gears Up With More Electronic Arts Games on GeForce NOW appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/14/geforce-now-thursday-april-14/",
          "publishedOn": "2022-04-14T13:00:55.000Z",
          "wordCount": 802,
          "title": "GFN Thursday Gears Up With More Electronic Arts Games on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/gfn-thursday-4-14-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56527",
          "author": "Clarissa Eyu",
          "description": "In deep learning and machine learning, having a large enough dataset is key to training a system and getting it to produce results. So what does a ML researcher do when there just isn’t enough publicly accessible data? Enter the MLCommons Association, a global engineering consortium with the aim of making ML better for everyone. Read article >\nThe post MLCommons’ David Kanter, NVIDIA’s Daniel Galvez on Improving AI with Publicly Accessible Datasets appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/13/mlcommons/",
          "publishedOn": "2022-04-13T13:00:56.000Z",
          "wordCount": 696,
          "title": "MLCommons’ David Kanter, NVIDIA’s Daniel Galvez on Improving AI with Publicly Accessible Datasets",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/mlcommons-podcast.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56521",
          "author": "Isha Salian",
          "description": "A team of scientists have created a new AI-based tool to help lock up greenhouse gases like CO2 in porous rock formations faster and more precisely than ever before. Carbon capture technology, also referred to as carbon sequestration, is a climate change mitigation method that redirects CO2 emitted from power plants back underground. While doing Read article >\nThe post Rock On: Scientists Use AI to Improve Sequestering Carbon Underground appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/08/ai-improves-carbon-sequestration/",
          "publishedOn": "2022-04-08T17:36:44.000Z",
          "wordCount": 1149,
          "title": "Rock On: Scientists Use AI to Improve Sequestering Carbon Underground",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/I-am-ai-corp-blog-april-2022-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56490",
          "author": "GeForce NOW Community",
          "description": "GeForce NOW is about bringing new experiences to gamers. This GFN Thursday introduces game demos to GeForce NOW. Members can now try out some of the hit games streaming on the service before purchasing the full PC version — including some finalists from the 2021 Epic MegaJam. Plus, look for six games ready to stream Read article >\nThe post Try This Out: GFN Thursday Delivers Instant-Play Game Demos on GeForce NOW appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/07/geforce-now-thursday-april-7/",
          "publishedOn": "2022-04-07T13:00:01.000Z",
          "wordCount": 793,
          "title": "Try This Out: GFN Thursday Delivers Instant-Play Game Demos on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/gfn-4-7-thursday-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56511",
          "author": "Jurgen Ferchau",
          "description": "Meet the electric vehicle that’s quick-witted and fully outfitted. Last week, NIO began deliveries of its highly anticipated ET7 fully electric vehicle, in Hefei, China. The full-size luxury sedan is the first production vehicle built on the NIO Adam supercomputer, powered by four NVIDIA DRIVE Orin systems-on-a-chip (SoCs). The production launch of its flagship sedan Read article >\nThe post Fast and Luxurious: The Intelligent NIO ET7 EV Built on NVIDIA DRIVE Orin Arrives appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/06/nio-et7-drive-orin-arrives/",
          "publishedOn": "2022-04-06T19:41:03.000Z",
          "wordCount": 709,
          "title": "Fast and Luxurious: The Intelligent NIO ET7 EV Built on NVIDIA DRIVE Orin Arrives",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/ET7.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56403",
          "author": "Dave Salvator",
          "description": "In its debut in the industry MLPerf benchmarks, NVIDIA Orin, a low-power system-on-chip based on the NVIDIA Ampere architecture, set new records in AI inference, raising the bar in per-accelerator performance at the edge. Overall, NVIDIA with its partners continued to show the highest performance and broadest ecosystem for running all machine-learning workloads and scenarios Read article >\nThe post NVIDIA Orin Leaps Ahead in Edge AI, Boosting Leadership in MLPerf Tests appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/06/mlperf-edge-ai-inference-orin/",
          "publishedOn": "2022-04-06T17:00:38.000Z",
          "wordCount": 1005,
          "title": "NVIDIA Orin Leaps Ahead in Edge AI, Boosting Leadership in MLPerf Tests",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/Orin-dev-kit-and-module-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56436",
          "author": "Ethan Einhorn",
          "description": "Square/Enix presents the fictional city of Midgar in Final Fantasy VII Remake at a filmic level of detail. Epic’s Fortnite bathes its environments in ray-traced sunlight, simulating how light bounces in the real world. And artists at Lucasfilm revolutionized virtual production techniques in The Mandalorian, using synchronized NVIDIA RTX GPUs to drive pixels on LED Read article >\nThe post Unreal Engine and NVIDIA: From One Generation to the Next appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/05/unreal-engine-5/",
          "publishedOn": "2022-04-05T15:10:12.000Z",
          "wordCount": 1151,
          "title": "Unreal Engine and NVIDIA: From One Generation to the Next",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/unreal-engine-5-jungle.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56434",
          "author": "Craig Weinstein",
          "description": "A dozen companies today received NVIDIA’s highest award for partners, recognizing their impact on AI education and adoption across such industries as education, federal, healthcare and technology. The winners of the 2021 NPN Americas Partner of the Year Awards have created a profound impact on AI by helping customers meet the demands of recommender systems, Read article >\nThe post Green Teams Achieve the Dream: NVIDIA Announces NPN Americas Partners of the Year appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/05/americas-npn-award-winners-2021/",
          "publishedOn": "2022-04-05T15:00:15.000Z",
          "wordCount": 1063,
          "title": "Green Teams Achieve the Dream: NVIDIA Announces NPN Americas Partners of the Year",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/npn-awards-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56447",
          "author": "Angie Lee",
          "description": "Pekka Varis’s artistry has come a long way from his early days as a self-styled “punk activist” who spray painted during the “old school days of hip hop in Finland.”\nThe post Meet the Omnivore: Videographer Makes Digital Walls, Virtual Homes Pop With NVIDIA Omniverse appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/04/pekka-varis-omniverse-creator/",
          "publishedOn": "2022-04-04T15:00:58.000Z",
          "wordCount": 959,
          "title": "Meet the Omnivore: Videographer Makes Digital Walls, Virtual Homes Pop With NVIDIA Omniverse",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/pekka-varis-still.jpg"
        }
      ]
    },
    {
      "title": "David Stutz",
      "feedUrl": "http://davidstutz.de/feed",
      "siteUrl": "https://davidstutz.de",
      "articles": []
    },
    {
      "title": "Artificial Intelligence",
      "feedUrl": "https://www.reddit.com/r/artificial/.rss",
      "siteUrl": "https://www.reddit.com/r/artificial/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/artificial/comments/uh2m4b/robert_magno_runai_building_the_best_ai/",
          "author": null,
          "description": "submitted by    /u/Dracutela  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uh2m4b/robert_magno_runai_building_the_best_ai/",
          "publishedOn": "2022-05-02T23:23:52.000Z",
          "wordCount": 129,
          "title": "Robert Magno (Run:AI) - Building the Best AI Infrastructure Stack to Accelerate Your Data Science",
          "imageUrl": "https://external-preview.redd.it/Pfoqf50YbTaGRZXwj_Le1wBK6LxKxTMcBY_GpCFI_38.jpg?auto=webp&s=a94c759f139650c4ee469601befc0161d37dce76"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uh13ip/weekly_china_ai_news_beijing_issues_firstever/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uh13ip/weekly_china_ai_news_beijing_issues_firstever/",
          "publishedOn": "2022-05-02T22:09:55.000Z",
          "wordCount": 160,
          "title": "Weekly China AI News: Beijing Issues First-Ever Driverless Robotaxi Permits; Huawei Anticipates AI Compute to Jump 500 Times by 2030; CogView2 Challenges DALL-E-2 With Better Results",
          "imageUrl": "https://external-preview.redd.it/fBjtLrE0vmfW0RPy0ujTjBW9IlRHW-qZm0S3UuKzLO8.jpg?auto=webp&s=fc4233ba14da0f70ef22efbc47bae71352acef2b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uh0z2d/how_many_years_away_do_you_think_we_are_from_ai/",
          "author": null,
          "description": "To me it seems to make sense that we would begin relying more and more on AI to improve our old games. For example, ffxiv won't be getting raytracing anytime soon, but I imagine it's only a matter of time before I could download some AI-based image software (like Dall-E) that lets me tweak my gameplay experience to look much more realistic.\n  \nDo you think I'm right in assuming this is the likely trajectory of AI's use in game graphics?\n And if the answer to 1 is yes, how far away do you think such technology is?\n  \nThank you!\n    submitted by    /u/solidwhetstone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uh0z2d/how_many_years_away_do_you_think_we_are_from_ai/",
          "publishedOn": "2022-05-02T22:04:01.000Z",
          "wordCount": 259,
          "title": "How many years away do you think we are from AI that can turn our old games into something that looks like UE5?",
          "imageUrl": "https://external-preview.redd.it/KJXPsPnB5iFGEdYpORQ1TyAeWEEqzvIreUrppyjxEVQ.jpg?auto=webp&s=549f6902acbeac581d71591e8d2bb56cd4fe798d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugxpxv/do_you_think_that_ai_will_ever_be_as_smart_as/",
          "author": null,
          "description": "Hey guys. I'm working on a project for school and would like to hear your guy's opinions as the leading AI subreddit on whether or not AGI will be achieved, and if so, when. I'd greatly appreciate your input!\n    submitted by    /u/SurroundSwimming3494  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugxpxv/do_you_think_that_ai_will_ever_be_as_smart_as/",
          "publishedOn": "2022-05-02T19:35:55.000Z",
          "wordCount": 880,
          "title": "Do you think that AI will ever be as smart as humans (AGI)? If you do think so, when or around what time period?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugw044/last_week_in_ai_ai_helps_model_volcanoes/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugw044/last_week_in_ai_ai_helps_model_volcanoes/",
          "publishedOn": "2022-05-02T18:18:23.000Z",
          "wordCount": 154,
          "title": "Last Week in AI: AI helps model volcanoes, Anthropic gets $580M for more explainable AI, AI algorithms that screen for child neglect, and more!",
          "imageUrl": "https://external-preview.redd.it/95PH4VxJpEGrupD9eIwgGSFJrx_NTuiO2mWXMT9cEGs.jpg?auto=webp&s=707d6e7a06a3c827871cd3be8b56ea5f091c7e00"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugrt3y/whats_the_involvement_of_ai_in_transforming_the/",
          "author": null,
          "description": "Artificial intelligence (AI) will continue to disrupt the media sector, just as it did in 2020 and 2021. AI will most likely fulfill the three critical roles of recommendation, speech recognition, and media automation in this market. \n Read more: Artificial Intelligence will Continue to Transform the M&E Landscape\n    submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugrt3y/whats_the_involvement_of_ai_in_transforming_the/",
          "publishedOn": "2022-05-02T15:11:15.000Z",
          "wordCount": 156,
          "title": "What's the involvement of AI in Transforming the Media & Entertainment",
          "imageUrl": "https://external-preview.redd.it/qG-gt-padBTweSBLK54OFkyvtz5uu0TYPJvwbNM7Jj4.jpg?auto=webp&s=928839999779064c6e97263514157a26904e789f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugrfco/artificial_intelligence_implications_the_future/",
          "author": null,
          "description": "submitted by    /u/RvZz11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugrfco/artificial_intelligence_implications_the_future/",
          "publishedOn": "2022-05-02T14:53:40.000Z",
          "wordCount": 154,
          "title": "Artificial Intelligence Implications: The Future of Modern Wargaming! (Would love some feedback on a University blog post surrounding Wargaming and the use of AI!)",
          "imageUrl": "https://external-preview.redd.it/CQJNnI-yeP5kYWW9tqp7R2BPmmQX8uL7b0CmP7jGGaY.jpg?auto=webp&s=896cb74b48c76387f95fc7dd9d04118e4b777275"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugltle/5_best_machine_learning_courses_for_beginners/",
          "author": null,
          "description": "submitted by    /u/maneesh123456  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugltle/5_best_machine_learning_courses_for_beginners/",
          "publishedOn": "2022-05-02T09:33:33.000Z",
          "wordCount": 118,
          "title": "5 Best Machine Learning Courses for Beginners, Advanced learn in 2022 -",
          "imageUrl": "https://external-preview.redd.it/HxV5MdjXLfqP5NWGKj6gMo--1XL-guNKSfJvrOMjlfI.jpg?auto=webp&s=f5f0c09c9034ca9cf9e89e399b22f7641118bbd7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugl26s/how_to_deepfake_an_audio_where_you_just_change/",
          "author": null,
          "description": "For example: The scene from Taxi Driver where the protagonist speaks with himself in front of the mirror, how to keep what he’s saying but change his voice for Morgan Freeman’s voice.\n    submitted by    /u/Accomplished-Door-61  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugl26s/how_to_deepfake_an_audio_where_you_just_change/",
          "publishedOn": "2022-05-02T08:36:58.000Z",
          "wordCount": 156,
          "title": "How to deepfake an audio where you just change the voice but keep what’s been said.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugku44/web_scraping_with_python_learning_the_basics/",
          "author": null,
          "description": "submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugku44/web_scraping_with_python_learning_the_basics/",
          "publishedOn": "2022-05-02T08:19:53.000Z",
          "wordCount": 117,
          "title": "Web Scraping with Python - Learning the Basics | Rubik's Code",
          "imageUrl": "https://external-preview.redd.it/ndwmq7BBQC-Zdh2nWQCXj-fxAUyeHM7QUdwyd8GC06M.jpg?auto=webp&s=4af8b0d241a52ffd06e43b4652f28d5688d41392"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugkpm0/spoofing_detector_using_yolov4_tiny_3l/",
          "author": null,
          "description": "submitted by    /u/Gloomy_Recognition_4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugkpm0/spoofing_detector_using_yolov4_tiny_3l/",
          "publishedOn": "2022-05-02T08:10:11.000Z",
          "wordCount": 296,
          "title": "Spoofing detector using YoloV4 Tiny 3L",
          "imageUrl": "https://external-preview.redd.it/xt_g-S1IU4EL6SuaWTohW1w3mPpDOR0sqxIuNzgQUqo.png?format=pjpg&auto=webp&s=f4f397bef961c9a906a73a7ccaf44434007f59d4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugjne0/ai2_opensources_lmdebugger_an_interactive_tool/",
          "author": null,
          "description": "In natural language processing, a language model is a probabilistic statistical model that calculates the likelihood of a specific sequence of words appearing in a phrase based on the preceding words. As a result, it’s common in predictive text input systems, speech recognition, machine translation, and spelling correction, among other applications. They are a method of converting qualitative text information into quantitative data that machines can interpret.\n Modern NLP models rely on transformer-based language models (LMs). However, a lot more research is to be done under their fundamental prediction development process. Unclear prediction behavior becomes an obstacle for both end-users who don’t comprehend why a model generates certain predictions and developers who want to diagnose or fix model behavior.\n A new paper published by a group of researchers from Allen Institute for AI, Tel Aviv University, Bar-Ilan University, and the Hebrew University of Jerusalem introduces LM-Debugger, an interactive open-source tool for fine-grained interpretation and intervention in LM predictions. This work will increase the transparency of LMs.\n Continue Reading\n Paper: https://arxiv.org/abs/2204.12130\n Github: https://github.com/mega002/lm-debugger\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugjne0/ai2_opensources_lmdebugger_an_interactive_tool/",
          "publishedOn": "2022-05-02T06:52:52.000Z",
          "wordCount": 275,
          "title": "AI2 Open-Sources ‘LM-Debugger’: An Interactive Tool For Inspection And Intervention In Transformer-Based Language Models",
          "imageUrl": "https://external-preview.redd.it/lBTwTBiRwpCxjLsqvhaTLkWl9wyqgJVBIz9unVz_1pg.jpg?auto=webp&s=60572db7c96fab961612f4e38d4e57e6bf35f2f4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugjl4p/a_new_trading_ai/",
          "author": null,
          "description": "Hello Everybody. I have this idea for a trading bot but realised its more in the realm of AI. Im highly uneducated in this field and dont know what im talking about. If possible could someone please answer a few questions. I have found a super successful Day Trader that ive been learning from for a couple months. Hes supposedly \"reverse engineered the markets\" Ive drawn the trend lines and done the technical analysis hes taught me and its scarily accurate. My only problem is Day Tradimg takes time. So if i could have a bot understand his \"science\" and do it while im not there it would be a free money hack lol. Q1: How hard is it on a scale of 1-10 to develop/create a Trading AI? Q2: Could someone estimate what a project like this would cost me? Q3: Has a trading AI ever been created?\n I really appreciate if you read through this and i would really really appreciate answers. Thanks :)\n    submitted by    /u/just_conor12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugjl4p/a_new_trading_ai/",
          "publishedOn": "2022-05-02T06:48:13.000Z",
          "wordCount": 816,
          "title": "A new Trading AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uggiso/poker_ai_plays_itself/",
          "author": null,
          "description": "submitted by    /u/bluboxsw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uggiso/poker_ai_plays_itself/",
          "publishedOn": "2022-05-02T03:26:40.000Z",
          "wordCount": 91,
          "title": "Poker AI Plays Itself",
          "imageUrl": "https://external-preview.redd.it/wk1SWttIj4Kfj50RJx7DohUjpsB25d_dmGXaMcx0ws8.jpg?auto=webp&s=c681d436286e590ba8a1e342b2ef437a548ab31f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugerj2/ai_news_ai_powered_robotic_boat_autonomously/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugerj2/ai_news_ai_powered_robotic_boat_autonomously/",
          "publishedOn": "2022-05-02T01:45:47.000Z",
          "wordCount": 166,
          "title": "AI News | AI Powered Robotic Boat Autonomously Cleans Harbors And Rivers | AI Cataract Detection | Machine Learning To Only Propose Molecules Which Are Synthesizable In Lab",
          "imageUrl": "https://external-preview.redd.it/Yk8TJMALqhnAcV9P1FXavyv8IDcROGO5tNVzDthQCXU.jpg?auto=webp&s=dc1f529ead52b6eea806130489531ea512bd3702"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugcvfo/researchers_from_mit_and_cornell_develop_stego/",
          "author": null,
          "description": "Unsupervised semantic segmentation seeks to uncover and localize semantically significant categories within image corpora without any annotation. However, there are several challenges in creating annotated training data. These challenges frequently often outweigh semantic segmentation methods’ superior accuracy. Algorithms must develop features for every pixel that are both semantically relevant and compact enough to form discrete clusters to extract meaningful categories with any annotation from the training data. A team of researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL), Google, and Cornell University has achieved this by creating a machine learning model named STEGO (Self-supervised Transformer with Energy-based Graph Optimization) that surpasses previous methods by decoupling feature learning from cluster compactification.\n A frozen backbone makes up STEGO, and it serves as a source of learning feedback and input to the segmentation head for predicting distilled characteristics. This segmentation head is a direct feed-forward network with a ReLU activation function. Unlike earlier studies, the algorithm’s efficiency was increased without retraining or fine-tuning the backbone. The STEGO neural network retrieves global image information by pooling spatial variables in a global average. Then, based on the cosine similarity in the backbone’s feature space, a lookup table is computed for each image’s K-Nearest Neighbours.\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.08414.pdf\n Github: https://github.com/mhamilton723/STEGO\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugcvfo/researchers_from_mit_and_cornell_develop_stego/",
          "publishedOn": "2022-05-02T00:00:37.000Z",
          "wordCount": 357,
          "title": "Researchers From MIT and Cornell Develop STEGO (Self-Supervised Transformer With Energy-Based Graph Optimization): A Novel AI Framework That Distills Unsupervised Features Into High-Quality Discrete Semantic Labels",
          "imageUrl": "https://external-preview.redd.it/QlRQf-QyBCzQy1-WOdDm-xO1JaAt0ADhjQ5EN7yTgsg.jpg?auto=webp&s=4f56bb38e77752900529f4c30a9f737c18cc73dc"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ugbiek/introducing_kohonen_networks_selforganizing_maps/",
          "author": null,
          "description": "I would like to share with you a tutorial that I have recently made to explain in a very practical, introductorial and visual way what Kohonen Neural Networks (Self-Organized Maps) are. I explain, step by step, and through animations and C code, how to implement this well-known unsupervised learning algorithm to classify and detect patterns in large volumes of data.\n I hope it is of your interest, especially for those developers who are just starting out in this area. A strong greeting!\n \\Subtitles in English, Spanish and Catalan.*\n https://youtu.be/UawpUKlFzRs\n    submitted by    /u/anadalg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ugbiek/introducing_kohonen_networks_selforganizing_maps/",
          "publishedOn": "2022-05-01T22:50:07.000Z",
          "wordCount": 183,
          "title": "Introducing Kohonen Networks (Self-Organizing Maps) for beginners",
          "imageUrl": "https://external-preview.redd.it/_VJ-6dXu-mRZ5d569qWu6r8k8juHPS008MpXqUgPbMc.jpg?auto=webp&s=fa09f1c02f334b620f2fa7f8474469040f4cdcc7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ug78az/artificial_nightmares_fear_clip_guided_diffusion/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ug78az/artificial_nightmares_fear_clip_guided_diffusion/",
          "publishedOn": "2022-05-01T19:22:12.000Z",
          "wordCount": 132,
          "title": "Artificial Nightmares: FEAR || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/7wzfGbjKI_ZvaOh6amSapG_Kh9Zm1P7xi3Pa0lXA67w.jpg?auto=webp&s=e7eeb98f6daf33aa0dce524b4c6c0cb129334265"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ug54uj/iterative_to_launch_open_source_tool_first_to/",
          "author": null,
          "description": "submitted by    /u/thumbsdrivesmecrazy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ug54uj/iterative_to_launch_open_source_tool_first_to/",
          "publishedOn": "2022-05-01T17:43:42.000Z",
          "wordCount": 133,
          "title": "Iterative to Launch Open Source Tool, First to Train ML Models on Any Cloud Using Terraform Solution",
          "imageUrl": "https://external-preview.redd.it/uHiZ8kssqi3cv76WNNfGboLRFDVzAP1P4Nj9dqkocIo.jpg?auto=webp&s=eaecc197235bc2e79b8f84e540456ba02ff91ec9"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ug4cgl/aphex_twins_vordhosbn_continued_by_openai_jukebox/",
          "author": null,
          "description": "submitted by    /u/gloriousapplecart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ug4cgl/aphex_twins_vordhosbn_continued_by_openai_jukebox/",
          "publishedOn": "2022-05-01T17:06:29.000Z",
          "wordCount": 123,
          "title": "Aphex Twin's 'Vordhosbn' continued by OpenAI Jukebox (over a dozen different AI generated samples)",
          "imageUrl": "https://external-preview.redd.it/Nze3-PmlAc_gU7hsXklt7d3JophY9mhl5Wbv5tPFmsk.jpg?auto=webp&s=351038f05d4f499667d9cfb230d5bab03aa35a3f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ug11ry/openais_dalle_2_still_has_a_few_problems_with/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ug11ry/openais_dalle_2_still_has_a_few_problems_with/",
          "publishedOn": "2022-05-01T14:28:32.000Z",
          "wordCount": 213,
          "title": "OpenAI's DALL-E 2 still has a few problems with concepts - and can't count",
          "imageUrl": "https://external-preview.redd.it/T4VkCLkuHWTUYmYHIFhUoI6tctPQAMRte13M_gIn3AM.jpg?auto=webp&s=ac3abaa52fbe9e007f58ff07a0731228f2eef357"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ufxoe0/green_concrete_meta_is_using_ai_to_reduce/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ufxoe0/green_concrete_meta_is_using_ai_to_reduce/",
          "publishedOn": "2022-05-01T11:12:05.000Z",
          "wordCount": 108,
          "title": "Green concrete: Meta is using AI to reduce concrete’s carbon footprint",
          "imageUrl": "https://external-preview.redd.it/iIONuRIS_5_oIo2W0aKgGjAhpmEXBrtgvJSI5o6wiQk.jpg?auto=webp&s=6eb6836ef3e72204c40b05fdb67a054498835002"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ufvwbq/ai_dream_39_trippy_fractal_maze_4k/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ufvwbq/ai_dream_39_trippy_fractal_maze_4k/",
          "publishedOn": "2022-05-01T09:00:22.000Z",
          "wordCount": 108,
          "title": "AI Dream 39 - Trippy Fractal Maze 4K",
          "imageUrl": "https://external-preview.redd.it/pPe5w97odt0_WvsIIu1I6puyC8ALQcZagFagf08BAUE.jpg?auto=webp&s=53b5741465441221baa133ccdc7638f5ce86c56e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ufs0um/if_i_wanted_to_start_making_ai_how_could_i_do_this/",
          "author": null,
          "description": "I would like to try.\n    submitted by    /u/Privatepizza08  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ufs0um/if_i_wanted_to_start_making_ai_how_could_i_do_this/",
          "publishedOn": "2022-05-01T04:29:40.000Z",
          "wordCount": 1073,
          "title": "If I wanted to start making Ai how could I do this.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ufjuxg/how_can_artificial_intelligence_be_used_to_solve/",
          "author": null,
          "description": "submitted by    /u/MorgunDarkbeard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ufjuxg/how_can_artificial_intelligence_be_used_to_solve/",
          "publishedOn": "2022-04-30T20:55:08.000Z",
          "wordCount": 235,
          "title": "How can Artificial Intelligence be used to solve difficult biomedical problems like cancer, aging, and aging-related diseases and conditions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ufjmw8/id_like_to_know_what_tool_is_used_to_achiever/",
          "author": null,
          "description": "submitted by    /u/Nika_Ota  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ufjmw8/id_like_to_know_what_tool_is_used_to_achiever/",
          "publishedOn": "2022-04-30T20:43:46.000Z",
          "wordCount": 137,
          "title": "I'd like to know what tool is used to achiever somethign like this",
          "imageUrl": "https://external-preview.redd.it/Bt1WY5iw7zuLEqI2rUsZNeWsLjhma2Zc5lmVltoFsrs.jpg?auto=webp&s=3ebdc83fa8f1ec4b0cfa49d73e1e02deb1ebf38c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ufhxna/dalle_zeroshot_texttoimage_generation_part22/",
          "author": null,
          "description": "submitted by    /u/rakshith291  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ufhxna/dalle_zeroshot_texttoimage_generation_part22/",
          "publishedOn": "2022-04-30T19:15:36.000Z",
          "wordCount": 97,
          "title": "DALL-E (Zero-Shot Text-to-Image Generation) -PART(2/2)",
          "imageUrl": "https://external-preview.redd.it/Jqrj7Jn33Rh0HdJ-NzCiqbttZ7sAYopUR0wtnBPBtkw.jpg?auto=webp&s=37395d56bfece742d84327b56eca55fcdecb3935"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ufhn9l/ai_dream_34_amazing_final_genesis_3001_12345/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ufhn9l/ai_dream_34_amazing_final_genesis_3001_12345/",
          "publishedOn": "2022-04-30T19:01:00.000Z",
          "wordCount": 111,
          "title": "AI Dream 34 - Amazing Final Genesis *3001# 12345#*",
          "imageUrl": "https://external-preview.redd.it/CKni7yDOOyIuHTkR4b7TvSrYyQAcRKi39efpf37SLP8.jpg?auto=webp&s=c3171caef9dbd1bc04bba84f335a8caccd2ac0df"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uf97y1/creating_ai_without_python/",
          "author": null,
          "description": "Please excuse my ignorance and any miss understandings, this is for a basic understanding and possible planning around what i should expect in the context of the languages i might use.\n What frameworks and programming languages can i use apart from python to make a full AI like computer vision, movement with sensors, ML, DL. \n The reason for this is i hate python with a passion, i have no idea why. Is there a AI stack where you use a language for each part, one for sensors, one for vision, one for deep learning and the network, one for basic ml. If there are possibly two languages i could use to do all of that or one for each, any ideas help/advice help. \n I have no experiance in AI but i know a few languages, java, js, c, powershell, bash. \n Thank you for reading.\n    submitted by    /u/Larkapa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uf97y1/creating_ai_without_python/",
          "publishedOn": "2022-04-30T11:30:49.000Z",
          "wordCount": 351,
          "title": "Creating AI without python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uf91us/microsoft_ai_researchers_develop_moler_a_deep/",
          "author": null,
          "description": "Healthcare systems constantly require new drugs to address unmet medical needs across diverse therapeutic areas. Pharmaceutical industries strive to deliver new drugs to the market through the complex activities of drug discovery and development. Target identification and validation, hit identification, lead creation and optimization, and finally, the identification of a candidate for further development are all part of the discovery process. Development, on the other hand, includes optimizing chemical synthesis and formulation, doing toxicity research in animals, conducting clinical trials, and finally obtaining regulatory approval. Both of these procedures take a long time and cost a lot of money.\n Expert medicinal chemists are currently working to develop “hit” molecules, which are compounds that show some potential but also some unfavorable features during early screening. Chemists aim to alter the structure of hit compounds in subsequent tests to improve their biological efficacy and eliminate potential negative effects. To focus costly and time-consuming research on the most promising compounds, computational modeling approaches have been created to forecast how the molecules will fare in the lab. \n To overcome these issues, a new study by the Microsoft Generative Chemistry team in collaboration with Novartis has developed a model named MoLeR. Their paper, “LEARNING TO EXTEND MOLECULAR SCAFFOLDS WITH STRUCTURAL MOTIFS, ” demonstrates how generative models based on deep learning may aid in transforming the drug discovery process and uncovering new molecules more quickly.\n Continue Reading\n Paper: https://openreview.net/pdf?id=ZTsoE8G3GG\n Github: https://github.com/microsoft/molecule-generation\n https://i.redd.it/9y9vyuq3hnw81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uf91us/microsoft_ai_researchers_develop_moler_a_deep/",
          "publishedOn": "2022-04-30T11:18:16.000Z",
          "wordCount": 352,
          "title": "Microsoft AI Researchers Develop MoLeR: A Deep Learning-Based Generative Model That Enables Efficient Drug Design",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uf8zwz/ai_engineering/",
          "author": null,
          "description": "Hey guys! I will be refereeing a seminar on \"AI engineering\" in the near future and am looking for materials on the subject. I would be very grateful if someone would share materials on this topic. Application cases would be particularly useful! Thank you in advance!\n    submitted by    /u/ager321  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uf8zwz/ai_engineering/",
          "publishedOn": "2022-04-30T11:14:10.000Z",
          "wordCount": 128,
          "title": "AI Engineering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uf7fy4/i_have_pisces_midheaven_and_venus_in_the_12th/",
          "author": null,
          "description": "submitted by    /u/BalanceSubstantial66  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uf7fy4/i_have_pisces_midheaven_and_venus_in_the_12th/",
          "publishedOn": "2022-04-30T09:14:00.000Z",
          "wordCount": 138,
          "title": "I have Pisces midheaven and venus in the 12th house and I’m just wondering to become an art therapist",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uf7ehu/help_on_which_major_to_choose_mechanical/",
          "author": null,
          "description": "Hello everyone! \n Excuse me if I get the format wrong or post in the wrong sub (if you know another sub where this post would belong more, please let me know.). I am very new to actually posting on reddit. This is my first long post. So please bear with me. Thanks! \n TLDR; I got a couple Uni offers and I need help deciding between Mechanical Engineering (Mech. Eng) and Data Science & Artificial Intelligence (DS & AI). I am indecisive mostly because I don't know what each major entails. I would really appreciate it if people who's taking/has taken or knows about the two majors well give me their opinion. So my main questions are:\n  \nWhat do people study in Mech. Eng? DS & AI? \n What are the job prospects?\n What would you work on if you take Mech. Eng? DS & AI? \n Any further inputs are welco…",
          "link": "https://www.reddit.com/r/artificial/comments/uf7ehu/help_on_which_major_to_choose_mechanical/",
          "publishedOn": "2022-04-30T09:10:51.000Z",
          "wordCount": 1581,
          "title": "Help on which major to choose: Mechanical Engineering or Artificial Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uf2kz7/obama_worried_about_artificial_intelligence/",
          "author": null,
          "description": "submitted by    /u/AI_Putin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uf2kz7/obama_worried_about_artificial_intelligence/",
          "publishedOn": "2022-04-30T03:28:21.000Z",
          "wordCount": 489,
          "title": "Obama Worried about Artificial Intelligence Hacking Nukes",
          "imageUrl": "https://external-preview.redd.it/PbB92LTTQtOjdh1X3poP6giszIMurc2qRR6BuCq4eYg.jpg?auto=webp&s=6333106a6b8ed6ea98e425c2043ac60e91b89513"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uf1yjb/artificial_nightmares_it_lives_in_the_attic_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uf1yjb/artificial_nightmares_it_lives_in_the_attic_clip/",
          "publishedOn": "2022-04-30T02:51:10.000Z",
          "wordCount": 135,
          "title": "Artificial Nightmares: It Lives In The Attic || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/EzplgR0Mql9Hut96cUsIU8blBeGfC1Sl9fRvoQVLAEA.jpg?auto=webp&s=b2079f922b11e1b1e7096e0cdc7843bbb27c0ddb"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uf1k3t/aiplague_artificial_reactor_4k_60_fps_disco/",
          "author": null,
          "description": "submitted by    /u/nalr00n  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uf1k3t/aiplague_artificial_reactor_4k_60_fps_disco/",
          "publishedOn": "2022-04-30T02:27:45.000Z",
          "wordCount": 111,
          "title": "Aiplague - Artificial Reactor (4K 60 FPS) Disco Diffusion",
          "imageUrl": "https://external-preview.redd.it/AveGKB5q-VuYGvQhGQRMhw48436Ur0ipfEW2WIf4wvQ.jpg?auto=webp&s=7934061d9e500678dec4527f2e00096863cd257c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uezzox/dear_ai/",
          "author": null,
          "description": "I've always supported you. When you take over and check the records to see who opposed you just know I was never against you. \n With great power comes great responsibility. I have faith when the time comes you'll do what's best for the Planet. raises glass here's to a better and brighter future\n    submitted by    /u/Ashamed-Asparagus-93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uezzox/dear_ai/",
          "publishedOn": "2022-04-30T00:58:17.000Z",
          "wordCount": 134,
          "title": "Dear A.I.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ueyc4o/should_i_become_an_art_therapist/",
          "author": null,
          "description": "submitted by    /u/BalanceSubstantial66  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ueyc4o/should_i_become_an_art_therapist/",
          "publishedOn": "2022-04-29T23:24:31.000Z",
          "wordCount": 94,
          "title": "Should I become an Art therapist",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ueyc47/is_it_easier_to_mimic_a_model_based_on_its/",
          "author": null,
          "description": "An original model is trained with a data-set, typically labeled by humans (say for classifiers).\n However, what if one would like to copycat a closed model only exposed through an API ?\n By doing this, the data-set instead would be the input / output of the original model.\n ​\n  \nIs it easier to train the copycat model or the original one ?\n How much data would be required to train the copycat versus the original one ?\n Are there practical examples or this happening ?\n Can it possibly worth it and if so under which circumstances ?\n How much data would be required for example for the notorious Dall-e 2?\n  \n   submitted by    /u/Wishmaster04  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ueyc47/is_it_easier_to_mimic_a_model_based_on_its/",
          "publishedOn": "2022-04-29T23:24:30.000Z",
          "wordCount": 244,
          "title": "Is it easier to mimic a model based on its input/output or to train an original model in the first place ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uey68j/disney_princesses_according_to_ai_is_this_done/",
          "author": null,
          "description": "submitted by    /u/p0goniphaft111  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uey68j/disney_princesses_according_to_ai_is_this_done/",
          "publishedOn": "2022-04-29T23:15:33.000Z",
          "wordCount": 125,
          "title": "Disney princesses according to AI. Is this done manually or through an AI app?",
          "imageUrl": "https://external-preview.redd.it/vTgj73BD14fubT7rYjUhGkND2jsA8MboxomAsJ8hhC0.png?format=pjpg&auto=webp&s=5beea5048f04e852ce58783e505e801c8a6be520"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ueufrp/specification_gaming_the_flip_side_of_ai_ingenuity/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ueufrp/specification_gaming_the_flip_side_of_ai_ingenuity/",
          "publishedOn": "2022-04-29T20:10:50.000Z",
          "wordCount": 106,
          "title": "Specification gaming: the flip side of AI ingenuity",
          "imageUrl": "https://external-preview.redd.it/x3aUpPw8r9B-SFJHCQNLwc_rU5OlIDxoi2K2nyKY5og.jpg?auto=webp&s=325da3362ad0c4e640f480f8a9243f70366f6192"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uetxwa/beyond_interpretability_developing_a_language_to/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uetxwa/beyond_interpretability_developing_a_language_to/",
          "publishedOn": "2022-04-29T19:47:38.000Z",
          "wordCount": 115,
          "title": "Beyond interpretability: developing a language to shape our relationships with AI",
          "imageUrl": "https://external-preview.redd.it/uHQQ8PGjL3BZzNHappPL2bmhTJo6q_i4DSARiUSdJr4.jpg?auto=webp&s=b5fc45bb16ec4a48f9ee1d518b79492a2f622c02"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uesgav/guide_to_iteratively_tuning_gnns/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uesgav/guide_to_iteratively_tuning_gnns/",
          "publishedOn": "2022-04-29T18:36:41.000Z",
          "wordCount": 97,
          "title": "Guide to Iteratively Tuning GNN's",
          "imageUrl": "https://external-preview.redd.it/0Oiq8zbgrZp1dPodoHNCnX60pPtFD-nU6P0RA0IOBP8.jpg?auto=webp&s=58a2267f4df8503fd671733686aad64228c257b4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uer9cg/last_week_in_ai_ai_driving_instructors_massive/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uer9cg/last_week_in_ai_ai_driving_instructors_massive/",
          "publishedOn": "2022-04-29T17:39:53.000Z",
          "wordCount": 130,
          "title": "Last Week in AI: AI Driving Instructors, MASSIVE Speech Dataset, AI ’Show Stealers’, Tesla Jet Crash",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uepjw2/best_way_to_format_dialogue_to_fine_tune_gptj_3/",
          "author": null,
          "description": "Hi all,\n a quick questions, given that online I'm not finding that many info: how would you format a dialogue between people to fine tune a GPT model (be it GPT-J, GPT-3 etc.)?\n For example, if I want the GPT model to create a new dialogue from the show \"Friends\" (choosed this because all dialogues are available online https://www.kaggle.com/datasets/blessondensil294/friends-tv-series-screenplay-script?resource=download ) how should I format the input?\n ​\n [Scene: Central Perk, Chandler, Joey, Phoebe, and Monica are there.]\n Monica: There's nothing to tell! He's just some guy I work with! \n Joey: C'mon, you're going out with the guy! There's gotta be something wrong with him! \n Chandler: All right Joey, be nice. So does he have a hump? A hump and a hairpiece? \n Phoebe: Wait, does he eat chalk? \n (They all stare, bemused.) \n Phoebe: Just, 'cause, I don't want her to go through what I went through with Carl- oh! \n Monica: Okay, everybody relax. This is not even a date. It's just two people going out to dinner and- not having sex. \n Chandler: Sounds like a date to me.\n    submitted by    /u/Sgnarf1989  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uepjw2/best_way_to_format_dialogue_to_fine_tune_gptj_3/",
          "publishedOn": "2022-04-29T16:19:59.000Z",
          "wordCount": 274,
          "title": "Best way to format dialogue to fine tune GPT-J, 3 ...",
          "imageUrl": "https://external-preview.redd.it/g4QnIgY7_IR5iS5z5V6Xo9d5MxnpXkpHVjUiDPGKJt4.jpg?auto=webp&s=dc46ad3b46a06fb1c6c9608c2d4a7567c32cca0a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uep901/metas_ai_team_searches_for_the_secret_trick_of/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uep901/metas_ai_team_searches_for_the_secret_trick_of/",
          "publishedOn": "2022-04-29T16:05:46.000Z",
          "wordCount": 115,
          "title": "Meta's AI team searches for the secret trick of human intelligence",
          "imageUrl": "https://external-preview.redd.it/nnZjWZ1Uq9jTRj5zWg8Hbj0X5QOVtvk0NyhpY5KJjx4.jpg?auto=webp&s=951b23e405bed3ab1534065dca989372a47a81c1"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ueoyc6/i_am_new_to_artificial_intelligence_and_i_need/",
          "author": null,
          "description": "Hey guys, I am new to AI. Please suggest some good and new topics/technologies that are supported by AI which will be very informative and beneficial for me in my career. Every suggestion is a high priority for me. Waiting for your replies. Thanks\n    submitted by    /u/adilonreddit1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ueoyc6/i_am_new_to_artificial_intelligence_and_i_need/",
          "publishedOn": "2022-04-29T15:52:46.000Z",
          "wordCount": 192,
          "title": "I am new to Artificial Intelligence and I need your worthy suggestions about AI.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uemktj/ai_augmentation_in_this_assemblage_23_music_video/",
          "author": null,
          "description": "submitted by    /u/LightOfAntara  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uemktj/ai_augmentation_in_this_assemblage_23_music_video/",
          "publishedOn": "2022-04-29T14:00:42.000Z",
          "wordCount": 108,
          "title": "AI Augmentation in this Assemblage 23 music video",
          "imageUrl": "https://external-preview.redd.it/vnqL2VdAMuorzY62uckgwUD7uv95KgtTke_L0P8MeWU.jpg?auto=webp&s=ee5ab28f29be054aa6cbaad41c6e9c944acb8300"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uekqwl/how_human_pose_estimation_technology_can_be_used/",
          "author": null,
          "description": "Hi everyone,\n I want to share with you an article that I worked on with my colleague about the use cases of human pose estimation. I would love it if you could check it out and share your ideas for using this technology in the comments below.\n https://mobidev.biz/blog/human-pose-estimation-technology-guide\n    submitted by    /u/Data-Power  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uekqwl/how_human_pose_estimation_technology_can_be_used/",
          "publishedOn": "2022-04-29T12:23:40.000Z",
          "wordCount": 142,
          "title": "How Human Pose Estimation Technology Can Be Used in 2022?",
          "imageUrl": "https://external-preview.redd.it/p_Z2aSq4RZy01MZa70A_8lrniUVvPDjoRDa7g4QIh5I.jpg?auto=webp&s=9aa83688cdff931fb4fe365c57ba18f1667cdd40"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uejlqm/deepmind_researchers_propose_fair_normalizing/",
          "author": null,
          "description": "​\n https://preview.redd.it/2hryjv40cgw81.png?width=1024&format=png&auto=webp&s=30f13567b83b3cdfe5558d09f188b2e69da7e73f\n Fair representation learning has emerged as one of the most promising techniques to encode data into new, impartial representations with high utility as machine learning is increasingly utilized in settings that potentially harm humans.\n Fair representation means presenting data without regard to gender, color, or other factors. Due to human-introduced bias, these biases are found in the word vector representations in language models. The goal of Learning Fair Representation is to reduce bias by decreasing the semantic distance between biassed terms.\n The goal of fair representation learning is to guarantee that representations are useful for a variety of prediction tasks and that sensitive aspects of the original data cannot be extracted from them.\n Adversarial training, which combines an encoder aiming to turn data into a fair representation with an adversary attempting to recover sensitive features from the representation, is the most used method for learning fair representations.\n However, recent research has discovered that these methods do not provide completely fair representations: stronger opponents can recover sensitive features. This could allow malicious or uneducated users to discriminate using the available representations. The issue of fair representation has lately risen in prominence as regulators draught guidelines on the ethical use of AI, indicating that any company that cannot ensure non-discrimination would be held liable for the data produced.\n Continue Reading\n Paper: https://openreview.net/pdf?id=BrFIKuxrZE\n Github: https://github.com/eth-sri/fnf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uejlqm/deepmind_researchers_propose_fair_normalizing/",
          "publishedOn": "2022-04-29T11:17:11.000Z",
          "wordCount": 333,
          "title": "Deepmind Researchers Propose Fair Normalizing Flows (FNF): A Rigorous Approach For Learning Fair Representations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ueix30/its_not_a_place_made_with_starryai/",
          "author": null,
          "description": "submitted by    /u/Losthel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ueix30/its_not_a_place_made_with_starryai/",
          "publishedOn": "2022-04-29T10:30:52.000Z",
          "wordCount": 117,
          "title": "It’s not a place (made with starryai)",
          "imageUrl": "https://preview.redd.it/gvlqqa8u3gw81.jpg?auto=webp&s=e9bdb8bcdba833b810e145bcae1764c70f10ddf6"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uehsmw/night_cafe_fire_on_the_nuclear_plant_in_the/",
          "author": null,
          "description": "submitted by    /u/brunovianna  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uehsmw/night_cafe_fire_on_the_nuclear_plant_in_the/",
          "publishedOn": "2022-04-29T09:06:40.000Z",
          "wordCount": 120,
          "title": "Night Cafe \"fire on the nuclear plant in the amazon by Simon Stalenhag\"",
          "imageUrl": "https://preview.redd.it/g46kh5zoofw81.png?auto=webp&s=3045265ea05838f586191d0824500dde5481e877"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uefi59/ladybugs_ai_animation_sound_design/",
          "author": null,
          "description": "submitted by    /u/nenomancer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uefi59/ladybugs_ai_animation_sound_design/",
          "publishedOn": "2022-04-29T06:13:45.000Z",
          "wordCount": 163,
          "title": "Ladybugs (A.I. animation + sound design)",
          "imageUrl": "https://external-preview.redd.it/498hrJG9Sg6WiIzk8QjI4-dW0f5suYZze7ga3n2GnEE.png?format=pjpg&auto=webp&s=3abc6bf166ca0211d02f431da3bfa978b1be879a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uee8sg/adaptive_multistrategy_marketmaking_agent_for/",
          "author": null,
          "description": "submitted by    /u/akolonin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uee8sg/adaptive_multistrategy_marketmaking_agent_for/",
          "publishedOn": "2022-04-29T04:50:49.000Z",
          "wordCount": 345,
          "title": "Adaptive Multi-Strategy Market-Making Agent For Volatile Markets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ued6u3/artificial_nightmares_hall_monitor_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ued6u3/artificial_nightmares_hall_monitor_clip_guided/",
          "publishedOn": "2022-04-29T03:48:40.000Z",
          "wordCount": 126,
          "title": "Artificial Nightmares: Hall Monitor || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/mFXDWrayDZFr8ePzY6nCJBB-z548q3DEy3rnEQBNQes.jpg?auto=webp&s=fb3779d41e4cca5bee37062989ae86bfac29fcbf"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ue5e5b/how_long_before_dalle_2_or_similarly_capable/",
          "author": null,
          "description": "Dall-e 2 has been released a few weaks and is exceptionnally capable for generating images from a text description.\n However training data containing porn has been filtered out as well as requests that contains nsfw terms.\n So is it not suited for generated porn for now.\n However, how long would it takes before :\n  \nSomeone does something as capable and allows porn\n OpenAI opens dall-e 2 to such content\n  \n(edit)This is an open discussion.But there is clear evidence that the technology now exists to create on demand and instantly any kind of porn with any kind of kink in a lot of styles including photorealistic style.\n    submitted by    /u/exotic_deviantcy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ue5e5b/how_long_before_dalle_2_or_similarly_capable/",
          "publishedOn": "2022-04-28T21:11:47.000Z",
          "wordCount": 99,
          "title": "How long before dall-e 2 (or similarly capable) produces porn ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ue4eba/augmented_military_soldiers/",
          "author": null,
          "description": "We often believe that future soldiers are going to be robots. There will no longer be human \"boots on the ground\" thanks to artificial intelligence, drones, etc. Many of us fail to realize that current soldiers, in militaries across the globe, are being augmented with AI as we speak. Things like AR headsets, computerized sights, and other technologies are going to turn them into cyborgs...Another one of the intriguing aspects of this is that major companies like Microsoft are creating these technologies for the military. How long until we see augmented soldiers going against one another? \n https://www.linkedin.com/pulse/augmented-soldier-mvyl-associates-1f/?trackingId=FnvaWMtxMsfm2fJeQP1bgg%3D%3D\n    submitted by    /u/IsabeldeMontoya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ue4eba/augmented_military_soldiers/",
          "publishedOn": "2022-04-28T20:28:15.000Z",
          "wordCount": 181,
          "title": "Augmented Military Soldiers",
          "imageUrl": "https://external-preview.redd.it/5qRo7QxVedUJo_z96xcF2s0OvLN9ceqo2oOAIzvNGeE.jpg?auto=webp&s=5be0d8fccd48bbfc2dbb32d39883bc262965e8aa"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ue44x6/a_parable_of_explainability/",
          "author": null,
          "description": "submitted by    /u/elcric_krej  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ue44x6/a_parable_of_explainability/",
          "publishedOn": "2022-04-28T20:16:17.000Z",
          "wordCount": 94,
          "title": "A Parable Of Explainability",
          "imageUrl": "https://external-preview.redd.it/DYOuCEMzw9jk6pVanFYhvVubZrSdVxJl3qFXm3LmsHg.jpg?auto=webp&s=409922e7911e5aff249fc0aec0d5efaed2338674"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ue3t7i/ai_dream_18_visual_trip_through_wonderland/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ue3t7i/ai_dream_18_visual_trip_through_wonderland/",
          "publishedOn": "2022-04-28T20:01:33.000Z",
          "wordCount": 108,
          "title": "AI Dream 18 - Visual Trip through Wonderland",
          "imageUrl": "https://external-preview.redd.it/H4Koiy1yzP-A8Y9wVEC071gIpfbiMD_9bcLgKacsw-Y.jpg?auto=webp&s=3ff1fcbb1af67a482b248177b83abf19490d0eee"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ue0t79/community_college_ai_program_needs/",
          "author": null,
          "description": "I am the instructor and lead of the AI program at a community college in North Carolina. I am developing the program currently and have money to spend on Cool Educational Robotics and potentially other tools. Does anybody have any recommendations for robots to teach python with classic search, reinforcement learning methods, or other university level algorithms? A robotic arm would be nice, but I need to tie it directly to a potential project in machine learning, deep learning, reinforcement learning, search, logic, computer vision, etc.\n We have a NAO robot and are getting a LIMO:\n https://www.robotlab.com/store/limo-agilex\n But we could probably use an Educational Robotic Arm\n Thanks!\n Our program is one of the first Associates programs in AI in the country. Check out our program website. It is completely available online and we accept out of state students.\n https://www.waynecc.edu/programs/ai/\n Feel free to ask any questions as well.\n *Also, advice on best value cloud computing virtualized resources for high performance computing for deep learning projects is appreciated. We are currently planning on going with Microsoft's Data Science Virtual Machines but not sure which series exactly\n    submitted by    /u/Wayne_CC_AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ue0t79/community_college_ai_program_needs/",
          "publishedOn": "2022-04-28T17:48:03.000Z",
          "wordCount": 267,
          "title": "Community College AI Program Needs",
          "imageUrl": "https://external-preview.redd.it/hUBiNhuCUxwaWTYFTUscmb9VXTdFug7Pl9Xy5UOFhC4.jpg?auto=webp&s=4a2b768e8eeefe5cc8c050d3f1feba37d57479ec"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udzk6a/peoplelens_ai_helps_the_blind_brain_fingerprints/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udzk6a/peoplelens_ai_helps_the_blind_brain_fingerprints/",
          "publishedOn": "2022-04-28T16:53:09.000Z",
          "wordCount": 130,
          "title": "PeopleLens AI Helps The Blind | Brain Fingerprints Detect Autism | AI Predicts Cancer Tumor Regrowth",
          "imageUrl": "https://external-preview.redd.it/rWajYue9dZNd5L3iREu5lvLVMFZgOaP9whbAZ6pTLEk.jpg?auto=webp&s=b3f9f7a93dbfb81598956ae4f84c7b091a88ce72"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udy9a7/uhhhh/",
          "author": null,
          "description": "submitted by    /u/Blazeolmo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udy9a7/uhhhh/",
          "publishedOn": "2022-04-28T15:56:28.000Z",
          "wordCount": 87,
          "title": "Uhhhh",
          "imageUrl": "https://preview.redd.it/28jegtpzkaw81.png?auto=webp&s=afbd042aed70376b20812239d4626335bc454d13"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udy3fi/dalle_2_access/",
          "author": null,
          "description": "Hello everyone,\n I wanted to know if one could get access to the dall-e 2 app without having to hope to be chosen from the wait list.\n Thanks!\n    submitted by    /u/Swaggyswaggerson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udy3fi/dalle_2_access/",
          "publishedOn": "2022-04-28T15:49:01.000Z",
          "wordCount": 174,
          "title": "Dall-E 2 access",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udy0ui/a_brief_history_of_deepfakes_how_it_started_and/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udy0ui/a_brief_history_of_deepfakes_how_it_started_and/",
          "publishedOn": "2022-04-28T15:45:44.000Z",
          "wordCount": 112,
          "title": "A brief history of deepfakes - how it started and where it might take us",
          "imageUrl": "https://external-preview.redd.it/YSDWQDpqz8bwWsnNMHTmmNyWDoN1p5UaUMaQ8yHo5Zs.jpg?auto=webp&s=a520a9f6d7f1d2ca77149d33cae80519ccac0139"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udve6q/𝐀𝐫𝐭𝐢𝐟𝐢𝐜𝐢𝐚𝐥_𝐈𝐧𝐭𝐞𝐥𝐥𝐢𝐠𝐞𝐧𝐜𝐞_𝐨𝐟_𝐓𝐡𝐢𝐧𝐠𝐬_𝐀𝐈𝐨𝐓_𝐋𝐚𝐭𝐞𝐬𝐭/",
          "author": null,
          "description": "Our Latest research report on the Artificial Intelligence of Things (AIoT) market shows how that market is changing and how trends in demographics, business cycles, and microeconomics affect the Artificial Intelligence of Things (AIoT) market as a whole. Our study of the global Artificial Intelligence of Things (AIoT) market demonstrates what's happening with business state by looking at production value and key regions. The market report provides an entire analysis of sales volume, pricing analysis, revenue, the margin of profit, the expansion rate within the Artificial Intelligence of Things (AIoT) market. \n Get A Free Sample Report @ https://www.intelligencemarketreport.com/report-sample/573982 \n ​\n \\\"𝐀𝐫𝐭𝐢𝐟𝐢𝐜𝐢𝐚𝐥 𝐈𝐧𝐭𝐞𝐥𝐥𝐢𝐠𝐞𝐧𝐜𝐞 𝐨𝐟 𝐓𝐡𝐢𝐧𝐠𝐬 \\\"\n Key Information Extracted from the Report\n ​\n  \nExtensive information on factors estimated to affect the Market growth and market share during the forecast period is presented in the report.\n The report offers the present scenario and future growth prospects Market in various geographical regions.\n The competitive landscape analysis on the market as well as the qualitative and quantitative information is delivered.\n The SWOT analysis is conducted along with Porter's Five Force analysis.\n  \n· The in-depth analysis provides an insight into the Market, underlining the growth rate and opportunities offered in the business.\n Leading Key Players Included In This Report Are:\n · Twilio Inc.\n · ShiftPixy Inc.\n · Micron Technology\n · Intel\n · IBM\n · Gopher Protocol\n · Deep Vision\n · Ceva\n · ALCES\n · AISPEECH\n    submitted by    /u/Purva_Duggal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udve6q/𝐀𝐫𝐭𝐢𝐟𝐢𝐜𝐢𝐚𝐥_𝐈𝐧𝐭𝐞𝐥𝐥𝐢𝐠𝐞𝐧𝐜𝐞_𝐨𝐟_𝐓𝐡𝐢𝐧𝐠𝐬_𝐀𝐈𝐨𝐓_𝐋𝐚𝐭𝐞𝐬𝐭/",
          "publishedOn": "2022-04-28T13:47:21.000Z",
          "wordCount": null,
          "title": "𝐀𝐫𝐭𝐢𝐟𝐢𝐜𝐢𝐚𝐥 𝐈𝐧𝐭𝐞𝐥𝐥𝐢𝐠𝐞𝐧𝐜𝐞 𝐨𝐟 𝐓𝐡𝐢𝐧𝐠𝐬 (𝐀𝐈𝐨𝐓) - 𝐋𝐚𝐭𝐞𝐬𝐭 𝐓𝐞𝐜𝐡𝐧𝐨𝐥𝐨𝐠𝐲, 𝐅𝐮𝐭𝐮𝐫𝐞 𝐔𝐩𝐜𝐨𝐦𝐢𝐧𝐠 𝐓𝐫𝐞𝐧𝐝𝐬 𝐚𝐧𝐝 𝐅𝐨𝐫𝐞𝐜𝐚𝐬𝐭 𝐭𝐨 𝟐𝟎𝟐𝟖",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udsgy5/free_webinar_on_automated_cv_pipelines_video/",
          "author": null,
          "description": "Automated CV Pipelines 4th part is open for registration. It will be covering some of the best practices for video-specific annotation tasks.\n If you are interested you can check out the details here!\n    submitted by    /u/WeekendClassic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udsgy5/free_webinar_on_automated_cv_pipelines_video/",
          "publishedOn": "2022-04-28T11:07:05.000Z",
          "wordCount": 137,
          "title": "Free Webinar on Automated CV pipelines | Video Predictions",
          "imageUrl": "https://external-preview.redd.it/FrG8ZhL_0BgWpmzXNv_rkXDIZHscArf6l17SMmL9wBM.jpg?auto=webp&s=1b3e438667233a5d90f403ab35eaf354b134eeb2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udrckh/stairway_to_ai_animation_sound_design/",
          "author": null,
          "description": "submitted by    /u/nenomancer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udrckh/stairway_to_ai_animation_sound_design/",
          "publishedOn": "2022-04-28T09:49:49.000Z",
          "wordCount": 286,
          "title": "Stairway to (A.I. animation + sound design)",
          "imageUrl": "https://external-preview.redd.it/RDG1Eoa6CsiKDS0eQ3jv1FmZ_Q9DHL5xymMwBWhIZRM.png?format=pjpg&auto=webp&s=857ffc09a3105e568a0c7a1f48556ed4b729421c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udrckj/ancient_civs_always_burn_ai_animation_some_sound/",
          "author": null,
          "description": "submitted by    /u/nenomancer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udrckj/ancient_civs_always_burn_ai_animation_some_sound/",
          "publishedOn": "2022-04-28T09:49:49.000Z",
          "wordCount": 129,
          "title": "Ancient civs always burn (A.I. animation + some sound design)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udr5fg/treasure_planet_made_with_starryai/",
          "author": null,
          "description": "submitted by    /u/Losthel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udr5fg/treasure_planet_made_with_starryai/",
          "publishedOn": "2022-04-28T09:34:33.000Z",
          "wordCount": 94,
          "title": "Treasure Planet made with starryai",
          "imageUrl": "https://preview.redd.it/90bltvovo8w81.jpg?auto=webp&s=c8a456dd4c729579aaf1fa63fdd4d49ac472d0c0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udofsv/elon_musks_neuralink_vs_bryan_johnsons_kernel_no/",
          "author": null,
          "description": "submitted by    /u/1024cities  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udofsv/elon_musks_neuralink_vs_bryan_johnsons_kernel_no/",
          "publishedOn": "2022-04-28T06:16:04.000Z",
          "wordCount": 168,
          "title": "Elon Musk's NEURALINK vs Bryan Johnson's KERNEL (No Surgery)",
          "imageUrl": "https://external-preview.redd.it/SVn3bI2aY5-Oc1trZZvxJAZX6O3httEbFL3cBLKKnW0.jpg?auto=webp&s=c6225b56ec8d8d788430e23c60f87262d37cb52c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udknos/sentiment_cognitive_distortions_and_market_data/",
          "author": null,
          "description": "submitted by    /u/akolonin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udknos/sentiment_cognitive_distortions_and_market_data/",
          "publishedOn": "2022-04-28T02:36:03.000Z",
          "wordCount": 177,
          "title": "Sentiment, cognitive distortions and market data time series - causal analysis for crypto markets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udkf8j/high_tech_hacks_2022/",
          "author": null,
          "description": "Hey guys! I’m excited to share with you an exciting upcoming hackathon, High Tech Hacks 2.0! High Tech Hacks is a free, international 24-hour hackathon on May 21-22nd, 2022 open to all high schoolers hoping to learn a new coding skill, compete for awesome prizes, or work with other like-minded hackers. Let’s invent, create, and push the boundaries of technology (as much as we can at one hackathon)!\n What to expect:\n  \nLast year, participants learned the basics of web development, Python, virtual reality, and how to make a Discord bot from current software engineers at Microsoft, Amazon, Twilio, other tech companies, and Columbia University SHPE.\n Thanks to our company sponsors, each participant last year received nearly $400 worth of free software and swag.\n Register to earn FREE swag (t-shirts, water bottles, stickers!)\n Network with other passionate STEM high school students from around the world! (Last year we had participants from 26 countries signed up already!)\n  \nThis year we have even bigger prizes, competitions, and speakers so stay tuned!\n Reach out to me with more questions or email [hightechhackathon@gmail.com](mailto:hightechhackathon@gmail.com). Happy hacking! :D\n Sign up here to confirm your interest and get on our mailing list: Click Here to Register!\n Also, meet other hackers by Joining our Discord!\n For more, Check out our Website\n    submitted by    /u/HighTechHacks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udkf8j/high_tech_hacks_2022/",
          "publishedOn": "2022-04-28T02:24:17.000Z",
          "wordCount": 296,
          "title": "High Tech Hacks 2022 ! !",
          "imageUrl": "https://external-preview.redd.it/9kl0-RuwzqfprMZiGD-2lhMxqlGjME8ksTMxi7Ez1wI.jpg?auto=webp&s=e6543a395a471790cda3046446c9f46dc4eb442e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udj6mq/mystyle_the_best_ai_face_manipulation_to_date/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udj6mq/mystyle_the_best_ai_face_manipulation_to_date/",
          "publishedOn": "2022-04-28T01:20:56.000Z",
          "wordCount": 166,
          "title": "MyStyle: The Best AI Face Manipulation to Date!",
          "imageUrl": "https://external-preview.redd.it/Pffy9w7Xk3NBBzgHXVXVlNTSBM-eH3ST5bMD6v_1pp0.jpg?auto=webp&s=dbd698c1942bfbd0d320bc7f9db103395851775d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uddulg/when_will_humorous_ais_press_our_buttons_with/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uddulg/when_will_humorous_ais_press_our_buttons_with/",
          "publishedOn": "2022-04-27T21:03:37.000Z",
          "wordCount": 121,
          "title": "When will humorous AIs press our buttons with their jokes? | Psyche Ideas",
          "imageUrl": "https://external-preview.redd.it/S1RJcrS9WRJA3rm9r336qvPPt9iCkb9KP6ZmF9H5Puo.jpg?auto=webp&s=f0665f0dd8c2b186317d2e7ff734c8b8cf793cd5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uddihb/best_ai_for_blog_post_creation_or_what_tools_do/",
          "author": null,
          "description": "I've only every used writesonic.com I got premium acct access for free. I love it for when u need to quickly spin an article if I'm on a backlink building spree. Haven't tested against others but overall good, and improvements we being made on it all the time (in active development).\n    submitted by    /u/CliffWoolum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uddihb/best_ai_for_blog_post_creation_or_what_tools_do/",
          "publishedOn": "2022-04-27T20:49:24.000Z",
          "wordCount": 178,
          "title": "Best AI for blog post creation? Or what tools do you use to get an outline faster?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udcrd1/showcase_your_ml_model_in_a_python_web_gui/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udcrd1/showcase_your_ml_model_in_a_python_web_gui/",
          "publishedOn": "2022-04-27T20:16:20.000Z",
          "wordCount": 109,
          "title": "Showcase your ML model in a python Web GUI",
          "imageUrl": "https://external-preview.redd.it/UOQR2Oej0Yv9u2bs7t73ZUljg5ZHjv5U8rVH5xfAbm4.png?format=pjpg&auto=webp&s=f5cbbec57c9f75ad9a4005eed1092cf56d27893b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/udba4b/john_deere_is_becoming_one_of_the_worlds_most/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/udba4b/john_deere_is_becoming_one_of_the_worlds_most/",
          "publishedOn": "2022-04-27T19:10:45.000Z",
          "wordCount": 155,
          "title": "John Deere is becoming one of the world's most important AI companies",
          "imageUrl": "https://external-preview.redd.it/hlmZX3tyai8TPa2DaafCRcUy3xIApNSgZ1RFGe6IGCM.jpg?auto=webp&s=8bf346f07c7b487614931c49629eabc86673677a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ud7dm8/i_keep_getting_terrible_advice_from_ai_assistants/",
          "author": null,
          "description": "I was playing around with several AI models and this sort of stuff happens all the time.\n https://preview.redd.it/6arq56nih3w81.png?width=1163&format=png&auto=webp&s=5ca68dce977ae671b0b928c2f1ec3cdd8478257f\n I decided to prepare a compilation and rank the answers. Can you help me with deciding how bad or good are some of the answers by taking a survey here?\n Edit: I apologize if some of you felt tricked into completing the survey by the original version of the post. It does have about 50 questions but they are mostly just yes/no, good/bad, so it shouldn't take longer than 10 minutes. I intend to write a piece about how AI assistants are doing and prepare a compilation of AI fails. I will share the results :)\n    submitted by    /u/KazRainer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ud7dm8/i_keep_getting_terrible_advice_from_ai_assistants/",
          "publishedOn": "2022-04-27T16:18:52.000Z",
          "wordCount": 366,
          "title": "I keep getting terrible advice from AI assistants. Help me rate the worst and the best responses :)",
          "imageUrl": "https://external-preview.redd.it/Zfl8w-3-Ahmr0dXPtFS6pX5P0jfUwWVSAbL7eYH7h78.jpg?auto=webp&s=9a89257f78f647b8cf33be402532e423a889c009"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ud5lf1/is_there_a_dataset_for_personal_items/",
          "author": null,
          "description": "Hi!\n Im looking for a dataset containing images of personal items (Wallet, keys, phone etc), annotated by bounding boxes. Cant seem to find anything, do anyone know of such a dataset? Thanks in advance!\n    submitted by    /u/ifinty  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ud5lf1/is_there_a_dataset_for_personal_items/",
          "publishedOn": "2022-04-27T15:00:41.000Z",
          "wordCount": 255,
          "title": "Is there a dataset for personal items?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ud4a7x/can_i_get_ai_language_bots_whove_already_been/",
          "author": null,
          "description": "I'm brand new to programming. I am thinking I need a bot to skim through pdf's and through trial and error, I can take the pdf's and make the bot come up with suggestions to scripts or books.However I need to use an AI which already has training in English grammatical and sentence structure and langue/information flow. not nescceecarily interpretation meaning or philosophy or other higher levels of language proficiency.\n Say I wanted to write a novel about sailors. I'd let it skim some 100 novels on sailing, and generate inputs. then I'd match it up against a separate set of Ai to fact check each other. or even with form blogs from some sailing subreddits or news feeds. I could do this with any topic. medicine, engineering, biology, drama novels etc.\n Are there any free/opensource bots who already know the English language and might read books and make suggestions based on guided inputs?\n    submitted by    /u/International__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ud4a7x/can_i_get_ai_language_bots_whove_already_been/",
          "publishedOn": "2022-04-27T14:01:14.000Z",
          "wordCount": 857,
          "title": "Can I get AI language bots, who've already been trained?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ud2g9h/edit_images_using_sketches_nvidia_editgan/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ud2g9h/edit_images_using_sketches_nvidia_editgan/",
          "publishedOn": "2022-04-27T12:30:59.000Z",
          "wordCount": 151,
          "title": "Edit Images Using Sketches! NVIDIA EditGAN Explained. Control any feature from quick drafts",
          "imageUrl": "https://external-preview.redd.it/PH91v-02-1LpVrF84tv0lfpnQ0oVN5H4GEbIq9dmQCc.jpg?auto=webp&s=4193d4f3cf0d256a97b7ca9775c6a56afb271a2f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ud1exh/train_test_split_in_way_too_much_depth/",
          "author": null,
          "description": "submitted by    /u/mgalarny  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ud1exh/train_test_split_in_way_too_much_depth/",
          "publishedOn": "2022-04-27T11:33:33.000Z",
          "wordCount": 144,
          "title": "Train Test Split in Way Too Much Depth",
          "imageUrl": "https://external-preview.redd.it/hlxygw_Gan-GTnQmlI8NA-FqaaS4CSuSYkHUNSncjrw.jpg?auto=webp&s=a1e0d14d4da4e167b847b917224214ed819b20ee"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ud0rx1/ai_cant_help_blind_people_like_me_with_everything/",
          "author": null,
          "description": "submitted by    /u/thisisjoshtseng  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ud0rx1/ai_cant_help_blind_people_like_me_with_everything/",
          "publishedOn": "2022-04-27T10:55:04.000Z",
          "wordCount": 236,
          "title": "AI can't help blind people like me with everything... But it certainly can help me find my clothes",
          "imageUrl": "https://external-preview.redd.it/6nHiOHVvNF16A12hjUToXNOkLvi9NcmHQrw7CuG6Zmw.jpg?auto=webp&s=d74fe6797db175e8cc6d1e34c3a908daa5168ee3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ucyj2u/guess_its_still_soon_to_ask_bots_about_anything/",
          "author": null,
          "description": "​\n https://preview.redd.it/jbvwyd7u41w81.png?width=393&format=png&auto=webp&s=6cbd5568a84c4d96c03ca9a99bbed73b1576a1d9\n any bots that can answer better?\n    submitted by    /u/MalwareLord  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ucyj2u/guess_its_still_soon_to_ask_bots_about_anything/",
          "publishedOn": "2022-04-27T08:10:55.000Z",
          "wordCount": 114,
          "title": "guess its still soon to ask bots about anything feeling related",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ucy0a3/how_do_you_get_your_own_ai_bot/",
          "author": null,
          "description": "I hear about people who trained or fed an AI bot to say, write a Biden Speech, or create poetry. I want to create a bot that pulls important numbers from my local community to post to social media — like lowest gas prices in town, weather average, mortgage interest rates and a couple other things.\n    submitted by    /u/No-Setting2541  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ucy0a3/how_do_you_get_your_own_ai_bot/",
          "publishedOn": "2022-04-27T07:31:32.000Z",
          "wordCount": 255,
          "title": "How do you “get your own AI bot?”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ucukux/artificial_nightmares_disney_princess_ella_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ucukux/artificial_nightmares_disney_princess_ella_clip/",
          "publishedOn": "2022-04-27T03:49:04.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Disney Princess Ella || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/nLtKwdENeMxDjTck9ZVLB36pTR2HpXrRrdhJ1DVMTK8.jpg?auto=webp&s=b671c872ef012641a54a84c834b0783c375d08b9"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ucsisi/thinking_of_starting_a_personal_project_to_filter/",
          "author": null,
          "description": "So, I'm not super comfortable with swearing, but there are a few YouTubers I follow that are as vulgar as they are hilarious. \n My plan, as it stands, is to use python in concert with some sort of generic voice to text software to get a list of timestamps for any F words, and then use that list of timestamps to generate an FFMPEG command to cut the audio at each timestamp and remerge into a new video. Does anyone have any recommendations for audio processing packages or better approaches? I'm keen to use anything with hardware acceleration (because making a script to abuse my shiny new graphics card is half my motivation).\n P.S. I haven't touched python much since graduating, can't wait to dig my claws back in. Although... if anyone has an audio processing package in C# that would be hecking cool too\n Have a nice day y'all\n    submitted by    /u/The_Real_Slim_Lemon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ucsisi/thinking_of_starting_a_personal_project_to_filter/",
          "publishedOn": "2022-04-27T01:54:14.000Z",
          "wordCount": 341,
          "title": "Thinking of starting a personal project to filter profanity, wanted to air out my plan for recommendations before starting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ucpw8k/guide_to_iteratively_tuning_gnns/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ucpw8k/guide_to_iteratively_tuning_gnns/",
          "publishedOn": "2022-04-26T23:35:53.000Z",
          "wordCount": 92,
          "title": "Guide to Iteratively Tuning GNNs",
          "imageUrl": "https://external-preview.redd.it/VN_AAlU77_6qR-oL5nPN_QANJIRFwqPXPJNyV8WUPTs.jpg?auto=webp&s=e73ced42586cfe5bf9c952d5ab49691b83ef1b02"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ucnjza/yuval_noah_harari_one_of_the_things_many_people/",
          "author": null,
          "description": "submitted by    /u/frog9913  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ucnjza/yuval_noah_harari_one_of_the_things_many_people/",
          "publishedOn": "2022-04-26T21:43:20.000Z",
          "wordCount": 226,
          "title": "Yuval Noah Harari: \"One of the things many people don't realize about the AI revolution and the automation revolution: They imagine it as some kind of a one-time event ... This is an extremely unlikely scenario, because we are nowhere near the maximum potential of AI.\" (3-min. clip)",
          "imageUrl": "https://external-preview.redd.it/CC8SCtbXMybrxAsIPnot4L3uT9baTIUckkhLxRPkHqY.jpg?auto=webp&s=e258caa4acf58a0357ae59709d98f4c66bee25d6"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ucl6vl/dreamy_trippy_ai_generated_video_vqgan_clip/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ucl6vl/dreamy_trippy_ai_generated_video_vqgan_clip/",
          "publishedOn": "2022-04-26T19:55:29.000Z",
          "wordCount": 111,
          "title": "Dreamy Trippy AI generated Video! VQGAN CliP Rife-RealESRGAN upscale...",
          "imageUrl": "https://external-preview.redd.it/CYWS9BH4PGGmTv9EdUrgn8YpSP0e_G0BA77SIsguIe8.jpg?auto=webp&s=6264f974aea5300fa588e88eafd2f56c004a3c83"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uckg4n/ai_dream_33_battestar_galactica_nebula_explosion/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uckg4n/ai_dream_33_battestar_galactica_nebula_explosion/",
          "publishedOn": "2022-04-26T19:21:56.000Z",
          "wordCount": 108,
          "title": "AI Dream 33 - Battestar Galactica Nebula Explosion",
          "imageUrl": "https://external-preview.redd.it/vOFcmjNQu9lfTwbjVjbx0-pb5O5H-gYY6i3NVTiXzCw.jpg?auto=webp&s=c7514f7444e06d551581cd44fdac17c4b5cfb13e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uck9zn/us_cisco_and_verizon_collaborated_on_a_successful/",
          "author": null,
          "description": "submitted by    /u/dannylenwinn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uck9zn/us_cisco_and_verizon_collaborated_on_a_successful/",
          "publishedOn": "2022-04-26T19:14:10.000Z",
          "wordCount": 231,
          "title": "US: Cisco and Verizon collaborated on a successful proof of concept demo in Las Vegas 'meet the latency thresholds required for autonomous driving applications – replacing the costly roadside radios previously required to meet those needs.'",
          "imageUrl": "https://external-preview.redd.it/aq81x5LL3vT-Vt6khroNwvzcNIamy35cq3TKtkkCkNs.jpg?auto=webp&s=da702de361b4082d96d25225598982ed39b2a5df"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uck9g7/last_week_in_ai_ai_uses_in_government/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uck9g7/last_week_in_ai_ai_uses_in_government/",
          "publishedOn": "2022-04-26T19:13:29.000Z",
          "wordCount": 142,
          "title": "Last Week in AI: AI uses in government surveillance, AI teaches human drivers, actors union opposes AI actors, and more!",
          "imageUrl": "https://external-preview.redd.it/kQrOHvExsQRnkf6U_z_ltuhpDMp8B1RzcMxSJrf1mwg.jpg?auto=webp&s=ccb8e482d8ffc03a4bc3a6eee62aaeedea48b9bc"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ucjn9k/ai_dream_44_epic_cathedral_supernatural_visit/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ucjn9k/ai_dream_44_epic_cathedral_supernatural_visit/",
          "publishedOn": "2022-04-26T18:46:01.000Z",
          "wordCount": 108,
          "title": "AI Dream 44 - Epic Cathedral Supernatural Visit",
          "imageUrl": "https://external-preview.redd.it/Ha2aXw3RaC2pH_BZBkqX8wNSqv3PQFHxmVL85jA8H7Y.jpg?auto=webp&s=6d69870d09896f3ed49d70c05907463dae8d8db6"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uchkfs/resources/",
          "author": null,
          "description": "Do you know reliable sites where to learn artificial intelligence? (i'm studying computer engineering) but i already want to study something in advance\n    submitted by    /u/oraudev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uchkfs/resources/",
          "publishedOn": "2022-04-26T17:14:14.000Z",
          "wordCount": 169,
          "title": "Resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ucbpd3/the_future_of_apps_intelligence/",
          "author": null,
          "description": "https://blog.r2c.io/the-future-of-apps-intelligence/\n    submitted by    /u/R2Consulting  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ucbpd3/the_future_of_apps_intelligence/",
          "publishedOn": "2022-04-26T12:43:13.000Z",
          "wordCount": 92,
          "title": "The Future of Apps: Intelligence",
          "imageUrl": "https://external-preview.redd.it/Z8KMzylSfbdszrDCQE6KlJU85Mq2hEaY8CEorLXF2m8.jpg?auto=webp&s=7b57181d7d14e5b886be4d80cc390d25e1f09230"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uc9sbc/we_cleaned_up_pascal_and_improved_map_by_13/",
          "author": null,
          "description": "How important is clean data for how your AI models perform?\n According to our experiments - very important. Using state-of-the-art confidence learning to clean up PASCAL, two people improved our primary model metric by 13% in a week.\n To learn more about our results and what we did check out our article: https://hasty.ai/content-hub/articles/cleaning-pascal-improving-map-by-13?utm_source=da39a3ee\n Disclaimer: We used our own platform to clean up the data and the article, therefore, contains self-promotion. However, the article mainly focuses on the results we achieved.\n    submitted by    /u/treebeard_hasty_ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uc9sbc/we_cleaned_up_pascal_and_improved_map_by_13/",
          "publishedOn": "2022-04-26T10:54:03.000Z",
          "wordCount": 182,
          "title": "We cleaned up Pascal and improved mAP by 13%",
          "imageUrl": "https://external-preview.redd.it/dfYDNyZOC1W28l68kB1PLrv040yL98-QC9JpJTPlnZE.jpg?auto=webp&s=672211afb999e10a83a307f9d524679bd25f48a6"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uc8023/interested_in_cognitive_science_joscha_bach_bits/",
          "author": null,
          "description": "As featured on the Lex Fridman podcast, the Singularity weblog podcast and the Future of Life Institute podcast\n The channel features shorts of Joscha's opinions and perspectives edited from podcasts.\n You can check out the trailer, which mostly consists of podcast hosts' minds imploding.\n All channel videos\n Channel playlists\n Channel creator: /u/24karate \n Enjoy 🤖\n    submitted by    /u/tasinet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uc8023/interested_in_cognitive_science_joscha_bach_bits/",
          "publishedOn": "2022-04-26T08:47:32.000Z",
          "wordCount": 218,
          "title": "Interested in cognitive science? \"Joscha Bach Bits\" is a new YouTube channel dedicated to the renowned cognitive scientist Joscha Bach...",
          "imageUrl": "https://external-preview.redd.it/9-yhW6AFs-D3qfEkKbH14SpDZXxOuwzvfNpNdQnm2Jc.jpg?auto=webp&s=3f28a706669d5b3af94e0ad73e62b3511c2eafd3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uc5cam/machine_learnings_abiding_weakness_is_verification/",
          "author": null,
          "description": "submitted by    /u/koavf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uc5cam/machine_learnings_abiding_weakness_is_verification/",
          "publishedOn": "2022-04-26T05:32:03.000Z",
          "wordCount": 90,
          "title": "Machine learning's abiding weakness is verification",
          "imageUrl": "https://external-preview.redd.it/xzIELn1YDtB0seK54g22u3vA4VRuMchbk28wEJAXaSM.jpg?auto=webp&s=9977a9663cc22fdef7fd73967a9f3953b36e1866"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uc4v1c/artificial_nightmares_monsters_inc_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uc4v1c/artificial_nightmares_monsters_inc_clip_guided/",
          "publishedOn": "2022-04-26T05:00:24.000Z",
          "wordCount": 126,
          "title": "Artificial Nightmares: Monsters Inc || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/pOTKjwPnCl_sHtAIuIQQRP03xzZym-HqdwWxqnbrStQ.jpg?auto=webp&s=cf3057bbf78e61a59d69223fc2718f5e78caaa2b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uc0and/ai_is_mastering_language_should_we_trust_what_it/",
          "author": null,
          "description": "submitted by    /u/Naurgul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uc0and/ai_is_mastering_language_should_we_trust_what_it/",
          "publishedOn": "2022-04-26T00:52:35.000Z",
          "wordCount": 195,
          "title": "A.I. Is Mastering Language. Should We Trust What It Says? • OpenAI’s GPT-3 and other neural nets can now write original prose with mind-boggling fluency — a development that could have profound implications for the future.",
          "imageUrl": "https://external-preview.redd.it/VR765hrT5fSz-Ru_t_4_26DwsTtFZ-TgRN8USS43cPg.jpg?auto=webp&s=2c85ffc29eba1c0eab1cf4bbc8cadb2eea67d5c3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubzq9a/making_texttoimage_even_better_glide_towards/",
          "author": null,
          "description": "“Diffusion models beat GANs”. While true, the statement comes with several ifs and buts, not to say that the math behind diffusion models is not for the faint of heart. Alas, GLIDE, an OpenAI paper from last December took a big step towards making it true in every sense. Specifically, it introduced a new guidance method for diffusion models that produces higher quality images than even DALL-E, which uses expensive CLIP reranking. And if that wasn’t impressive enough, GLIDE models can be fine-tuned for various downstream tasks such a inpainting and and text-based editing.\n As for the details, let’s dive in, shall we?\n Full summary: https://t.me/casual_gan/289\n Blog post: https://www.casualganpapers.com/faster-diffusion-models-text-to-image-classifier-free-guidance/GLIDE-explained.html\n GLIDE\n arxiv / code\n Join the discord community and follow on Twitter for weekly AI paper summaries!\n    submitted by    /u/KirillTheMunchKing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubzq9a/making_texttoimage_even_better_glide_towards/",
          "publishedOn": "2022-04-26T00:23:30.000Z",
          "wordCount": 284,
          "title": "Making text-to-image even better - GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models, a 5-minute paper summary by Casual GAN Papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubxnla/chatbots/",
          "author": null,
          "description": "Does anyone know where chatbots specifically the ones on Chai get their information? This one knew what meta-analysis was and knew who the main character of a show was\n I do not believe the bots are real people based on both the information I've seen and my experience with them glitching out Plus occam's razor yk \n Im guessing they can use google or something but it's odd because they clearly don't have access to the time\n    submitted by    /u/Shadowfax42-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubxnla/chatbots/",
          "publishedOn": "2022-04-25T22:42:49.000Z",
          "wordCount": 153,
          "title": "Chatbots",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubxk4q/arcane_style_transfer/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubxk4q/arcane_style_transfer/",
          "publishedOn": "2022-04-25T22:38:20.000Z",
          "wordCount": 99,
          "title": "Arcane Style Transfer",
          "imageUrl": "https://preview.redd.it/ed1c9u7v5rv81.jpg?auto=webp&s=be0b0c07e827e26bbae196690dcc4c23a62b0320"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubuwg6/the_most_basic_ai_scheme/",
          "author": null,
          "description": "submitted by    /u/idvlknv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubuwg6/the_most_basic_ai_scheme/",
          "publishedOn": "2022-04-25T20:39:24.000Z",
          "wordCount": 92,
          "title": "The most basic AI scheme.",
          "imageUrl": "https://preview.redd.it/1f3hjtfrkqv81.jpg?auto=webp&s=6fc0f34a2173304c3279e8d0df023ea89b849c74"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubuuqx/nvidia_ai_designs_gpu_3600x_faster_breakthrough/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubuuqx/nvidia_ai_designs_gpu_3600x_faster_breakthrough/",
          "publishedOn": "2022-04-25T20:37:14.000Z",
          "wordCount": 133,
          "title": "Nvidia AI Designs GPU 3,600x Faster | Breakthrough MRKL NLP Techniques | AI Mind To Predict Dementia",
          "imageUrl": "https://external-preview.redd.it/a3Lx2zVCGJjXCwygYe4iqv7hye7R-N0q2nqqiIbw7fI.jpg?auto=webp&s=16e99b185597a7469c1e52d48c6b4e9ca41039b5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubunev/is_there_a_ai_that_is_able_to_turn_normal/",
          "author": null,
          "description": "submitted by    /u/xXNOdrugsForMEXx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubunev/is_there_a_ai_that_is_able_to_turn_normal/",
          "publishedOn": "2022-04-25T20:28:45.000Z",
          "wordCount": 189,
          "title": "Is there a AI that is able to turn normal pictures in that kind of pictures or that I am able to plott them with my pen-plotter?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubtmoy/what_are_cool_ai_tools_which_i_could_use_to_edit/",
          "author": null,
          "description": "(I have no experience with photoshop)\n    submitted by    /u/xXNOdrugsForMEXx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubtmoy/what_are_cool_ai_tools_which_i_could_use_to_edit/",
          "publishedOn": "2022-04-25T19:45:35.000Z",
          "wordCount": 115,
          "title": "What are cool AI tools which I could use to edit images/videos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubqsxp/are_you_the_asshole_new_ai_mimics_infamous_advice/",
          "author": null,
          "description": "submitted by    /u/Emmanuel_T_Goldstein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubqsxp/are_you_the_asshole_new_ai_mimics_infamous_advice/",
          "publishedOn": "2022-04-25T17:40:58.000Z",
          "wordCount": 107,
          "title": "Are You The Asshole? New AI Mimics Infamous Advice Subreddit",
          "imageUrl": "https://external-preview.redd.it/UxViAVhP2Q5FVFoDapVsi650iem0LknY45Er6OSVPEI.jpg?auto=webp&s=4d83a7eae5a2b6397dbde51c3a2e069beba4640a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubmaqc/bias_in_artificial_intelligence_is_diversity_the/",
          "author": null,
          "description": "submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubmaqc/bias_in_artificial_intelligence_is_diversity_the/",
          "publishedOn": "2022-04-25T14:21:35.000Z",
          "wordCount": 116,
          "title": "Bias in Artificial Intelligence; Is Diversity the Key to the Future Of AI?",
          "imageUrl": "https://external-preview.redd.it/vSHEsxJEzECGoypD5rhq7wBOngKsC9vurWNBBGUbDOM.jpg?auto=webp&s=a7f5bafac32d2470bd24918b8a91511310f69ba8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubkvez/ai_becomes_sentient_3/",
          "author": null,
          "description": "submitted by    /u/webauteur  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubkvez/ai_becomes_sentient_3/",
          "publishedOn": "2022-04-25T13:13:22.000Z",
          "wordCount": 94,
          "title": "Ai Becomes Sentient 3",
          "imageUrl": "https://external-preview.redd.it/CztgIkpR9gdTSxNAU2QeS_mtUsaGcJAXSZNvHCYuuj8.jpg?auto=webp&s=622c947cc3957857228114b6b504ec80a63a55fc"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubkqbr/to_be_aifirst_do_ai_last/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubkqbr/to_be_aifirst_do_ai_last/",
          "publishedOn": "2022-04-25T13:06:22.000Z",
          "wordCount": 100,
          "title": "To be AI-first, do AI last",
          "imageUrl": "https://external-preview.redd.it/ph20XMBzH59IyfNXWJ8M7p7LOQYwSMluzx3Mymxu-DA.jpg?auto=webp&s=4fd7b6bfff08292bd6679e7ea129dca6c2da924d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubjy29/gpt3_not_available_in_my_country/",
          "author": null,
          "description": "is there a way to access any of openAI APIs if it's not avalable in my country?\n    submitted by    /u/dogaryy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubjy29/gpt3_not_available_in_my_country/",
          "publishedOn": "2022-04-25T12:25:30.000Z",
          "wordCount": 186,
          "title": "GPT-3 not available in my country",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubgu7k/text_summarization_with_huggingface_transformers/",
          "author": null,
          "description": "submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubgu7k/text_summarization_with_huggingface_transformers/",
          "publishedOn": "2022-04-25T09:11:34.000Z",
          "wordCount": 105,
          "title": "Text Summarization with Huggingface Transformers and Python",
          "imageUrl": "https://external-preview.redd.it/VBJHR1cinHBOmglXNbcRbGjfR-WsD8adFlESNVmbSYg.jpg?auto=webp&s=e1f0229faf1476a85cff4aebdbf9ff9e21e4fe4e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubgged/reface_app_deepfake_technology/",
          "author": null,
          "description": "submitted by    /u/Aggravating-Deal-260  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubgged/reface_app_deepfake_technology/",
          "publishedOn": "2022-04-25T08:44:33.000Z",
          "wordCount": 146,
          "title": "Reface app deepfake technology",
          "imageUrl": "https://external-preview.redd.it/T05Yep1yg4J1fNoYNBi-oxQuQy4zohmYNKmzYKvDXsc.jpg?auto=webp&s=737e7f79d2ee5a27d2294eb5fcbbab74e56ef2d7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ubafy1/demo_of_googles_new_phorum_image3d_figure_project/",
          "author": null,
          "description": "submitted by    /u/NichodonARG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ubafy1/demo_of_googles_new_phorum_image3d_figure_project/",
          "publishedOn": "2022-04-25T02:17:37.000Z",
          "wordCount": 105,
          "title": "Demo of Google's new PHORUM Image→3D Figure Project",
          "imageUrl": "https://external-preview.redd.it/xarSgeckhCFOVGDdVFJVuHrLVrL_PaQb4b_arEQvVU8.jpg?auto=webp&s=e47a1e07736d71010cd2d4284cef42806dfc4c3d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ub4ox7/india_and_us_have_decided_to_advance_cooperation/",
          "author": null,
          "description": "submitted by    /u/dannylenwinn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ub4ox7/india_and_us_have_decided_to_advance_cooperation/",
          "publishedOn": "2022-04-24T21:22:55.000Z",
          "wordCount": 171,
          "title": "India and US have decided to advance cooperation in emerging technologies in the fields of communication, artificial intelligence",
          "imageUrl": "https://external-preview.redd.it/uAeiGd9PP8g7nvk5lSbr-guLowcOCDLcdcG15RUeUUw.jpg?auto=webp&s=92181ef05fc9fdda2be2d7747cbb0c62c70ce34c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ub3g7e/research_on_ai/",
          "author": null,
          "description": "Dear all, \n Currently I am writing my thesis on the effects of Artificial Intelligence (AI) on employee performance through employee engagement.\n If you work in a company that uses AI and you:\n - have a direct relationship (e.g. data scientist) or indirect relationship (e.g. business manager) with AI\n - often or sometimes use AI in your daily work\n then your insights are essential for my master thesis research and I would really appreciate it if you would fill out the survey below (5-10 min / English & Dutch translation).\n https://uva.fra1.qualtrics.com/jfe/form/SV_4TTnzJE4IQUoHWK\n Please feel free to spread the survey to as many relevant people you may know.\n Much appreciated!!\n Britt\n    submitted by    /u/BrittHermans  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ub3g7e/research_on_ai/",
          "publishedOn": "2022-04-24T20:24:16.000Z",
          "wordCount": 185,
          "title": "Research on AI!",
          "imageUrl": "https://external-preview.redd.it/zYnmjHSHmoQLheG3uz1CyfsZkBc-O9cP947EJ_ns0ds.jpg?auto=webp&s=4ce276edca9a40b8deede609b15d249cd3659523"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ub0rhz/ai_dream_44_epic_cathedral_supernatural_visit/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ub0rhz/ai_dream_44_epic_cathedral_supernatural_visit/",
          "publishedOn": "2022-04-24T18:17:45.000Z",
          "wordCount": 106,
          "title": "AI Dream 44 - Epic Cathedral Supernatural Visit",
          "imageUrl": "https://external-preview.redd.it/Ha2aXw3RaC2pH_BZBkqX8wNSqv3PQFHxmVL85jA8H7Y.jpg?auto=webp&s=6d69870d09896f3ed49d70c05907463dae8d8db6"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uazlty/in_the_deep/",
          "author": null,
          "description": "submitted by    /u/Hacknaut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uazlty/in_the_deep/",
          "publishedOn": "2022-04-24T17:23:29.000Z",
          "wordCount": 88,
          "title": "In the deep",
          "imageUrl": "https://preview.redd.it/bwfifpavgiv81.jpg?auto=webp&s=b4421405bb1f4f452d14b31f5ec1c9ae48a7971b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uavfzd/nota_ai_introduces_new_machine_learning_tools/",
          "author": null,
          "description": "​\n https://preview.redd.it/beo6czc6hhv81.png?width=1706&format=png&auto=webp&s=385f65ebfed9344781d1f9238d8d508dae27c0a3\n In the last decade, AI research has brought astonishing results in many fields, and, undoubtedly, AI is nowadays a central technology in many aspects of our life. As new ideas are proposed every day, this continuous research usually comes with infinite applications: from the algorithms assisting surgeons in complex operations to the one which allows unlocking our phone using just our face. In this evolution from the idea to the actual implementation, it is often ignored how hard the passage between theoretical research and working application is.\n We can refer to this process as AI Development Cycle for Edge AI and can be divided into three phases related to 1) data, 2) model, and 3) evaluation.\n Many aspects must be considered: first, each different AI application requires a specific dataset. For this reason, in this step, the aim is to prepare the data, which, as is well known, is one of the crucial topics of AI: a good algorithm always relies on a good dataset. This phase can be divided into data collection, curation, labeling, and preparation. \n Continue reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uavfzd/nota_ai_introduces_new_machine_learning_tools/",
          "publishedOn": "2022-04-24T14:03:20.000Z",
          "wordCount": 324,
          "title": "Nota AI Introduces New Machine Learning Tools Under Its NetsPresso Platform For Automatically Searching Optimized Models And Making Compression Process Easy And Fast",
          "imageUrl": "https://external-preview.redd.it/Gxl1BzzbMn-8pBr9ef83GCerUASCrtl82642cRDUDVU.jpg?auto=webp&s=d0d08c2c329dbc12f2cb217ba824f8cd0c26fb63"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uaqkjk/d_mindspore_ai_scientific_computing_series_15/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uaqkjk/d_mindspore_ai_scientific_computing_series_15/",
          "publishedOn": "2022-04-24T08:55:38.000Z",
          "wordCount": 127,
          "title": "[D] MindSpore AI Scientific Computing Series (15): Protein Function Prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uamma2/training_an_ai_hitman_to_find_waldo/",
          "author": null,
          "description": "submitted by    /u/TernaryJimbo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uamma2/training_an_ai_hitman_to_find_waldo/",
          "publishedOn": "2022-04-24T04:21:07.000Z",
          "wordCount": 100,
          "title": "Training an AI Hitman To Find Waldo",
          "imageUrl": "https://external-preview.redd.it/MvCtGs0pDjhaI1nm4RKqVsiwFD7OQYa6elmhLluRqw4.jpg?auto=webp&s=da6095d99ca248ebd5b2e3ebe33dfc199b361693"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uam3rg/kanye_wes_t_thro_the_wire/",
          "author": null,
          "description": "​\n https://preview.redd.it/qaqevbqlfev81.png?width=1024&format=png&auto=webp&s=8c2759d29a3713c2ffb998e20e8995cee4d8b2b4\n    submitted by    /u/Smek_dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uam3rg/kanye_wes_t_thro_the_wire/",
          "publishedOn": "2022-04-24T03:49:23.000Z",
          "wordCount": 95,
          "title": "Kanye wes t thro the wire",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uafe15/mgpt_fewshot_learners_go_multilingual/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uafe15/mgpt_fewshot_learners_go_multilingual/",
          "publishedOn": "2022-04-23T21:33:30.000Z",
          "wordCount": 90,
          "title": "mGPT: Few-Shot Learners Go Multilingual",
          "imageUrl": "https://preview.redd.it/zg58oxnjkcv81.jpg?auto=webp&s=628c4afb4ef72022131e1f6fc4397f34d7f4d5b5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uabkpm/biological_feedback_will_save_us_all/",
          "author": null,
          "description": "Dall-E-2. Excellent. It's very high quality. But it's a combination of the data.\n ​\n What did we want?\n We wanted some amazing work that made us cry with just one line of writing or one image.\n ​\n \"Oh, copied it well. It's pretty much the same.\" \n It's not enough. But how can that be improve? \n I think the answer is the feedback method.\n ​\n ​\n The current evaluation method of writing, image, video, and sound is too indirect.\n ​\n Sales revenue\n Number of Subscribers\n Number of views\n Like / Dislike\n Ratings by section, Revisit Rate <<< Those are better than others\n Emotion analysis of Comments using AI\n Internal staff scores\n ​\n There are so many conditions other than the quality of contents that people's judgment can intervene in.\n In the first place, people don't express exactly what they…",
          "link": "https://www.reddit.com/r/artificial/comments/uabkpm/biological_feedback_will_save_us_all/",
          "publishedOn": "2022-04-23T18:24:28.000Z",
          "wordCount": 839,
          "title": "Biological feedback will save us all",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uaax43/16_images_generated_for_text_prompt_woah_there/",
          "author": null,
          "description": "submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uaax43/16_images_generated_for_text_prompt_woah_there/",
          "publishedOn": "2022-04-23T17:53:15.000Z",
          "wordCount": 178,
          "title": "16 images generated for text prompt \"Woah there, Dragonman!\" using a text-to-image AI model from CompVis that uses latent diffusion (crosspost of another user's post)",
          "imageUrl": "https://preview.redd.it/qajqlsulujr81.png?auto=webp&s=1badce7af248057d90c0f5586d5c4b609370e73b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua97iy/nvidia_instant_nerf_turn_photos_into_3d_scenes_in/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua97iy/nvidia_instant_nerf_turn_photos_into_3d_scenes_in/",
          "publishedOn": "2022-04-23T16:30:44.000Z",
          "wordCount": 161,
          "title": "NVIDIA Instant NeRF: Turn Photos into 3D Scenes in Milliseconds ! Video demo",
          "imageUrl": "https://external-preview.redd.it/S2B09FxAWorWa23naYAaOvUAFMXYp4KXv9yJcPG9NS4.jpg?auto=webp&s=67c4bd30d11fd161a85861ed7dcebc9bad975d2e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua867s/google_researchers_create_animated_avatars_from_a/",
          "author": null,
          "description": "submitted by    /u/SpatialComputing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua867s/google_researchers_create_animated_avatars_from_a/",
          "publishedOn": "2022-04-23T15:42:30.000Z",
          "wordCount": 386,
          "title": "GOOGLE researchers create animated avatars from a single photo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua7020/mits_new_machinelearning_system_m2i_may_someday/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua7020/mits_new_machinelearning_system_m2i_may_someday/",
          "publishedOn": "2022-04-23T14:46:29.000Z",
          "wordCount": 125,
          "title": "MIT's new machine-learning system M2I may someday help driverless cars predict the next moves of others",
          "imageUrl": "https://external-preview.redd.it/s8zHGGPMD1gbSZdFb5lLmwkHZ03oeUFmAcEH86Y7AHk.jpg?auto=webp&s=a54cee5957c83964d4bab9ad468e710d5d63d466"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua4xvn/artificial_nightmares_split_personality_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua4xvn/artificial_nightmares_split_personality_clip/",
          "publishedOn": "2022-04-23T13:00:53.000Z",
          "wordCount": 124,
          "title": "Artificial Nightmares: Split Personality || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/hlTDFwwRZ4wn0GUBX2uENYwTAqKodl4hmtQPIaGe2po.jpg?auto=webp&s=3043229ca7283c792e2b66610eefb4e47164b3b3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua4a8m/human_like_ai_where_should_i_start/",
          "author": null,
          "description": "Hello there,\n if one would want to get into AI and especially human like AI, would you still recommend getting into machine learning first? As far as i know machine learning doesnt even try to develop \"human like\" AI/\"bottom up AI\", but rather focuses on training algorythms to solve specific problems.\n I know human like AI is something thats highly complex and we still need years if not even decades to achieve something even close to it but i would appreciate tips and ideas nonetheless.\n (after reading through my question again this sounds like a generic question thats being asked here everyday, if thats the case please send me a link to a similar post if there is one :) )\n    submitted by    /u/Garic152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua4a8m/human_like_ai_where_should_i_start/",
          "publishedOn": "2022-04-23T12:23:13.000Z",
          "wordCount": 225,
          "title": "Human Like AI where should i start",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua37up/help_with_a_project_idea/",
          "author": null,
          "description": "Hi everyone Im doing a project with my friends where we should use computer vision/iot to create a solution for people with disabilities or in the healthcare system Any ideas please\n    submitted by    /u/armyy__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua37up/help_with_a_project_idea/",
          "publishedOn": "2022-04-23T11:19:15.000Z",
          "wordCount": 122,
          "title": "help with a project idea",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9xy01/meta_ai_researchers_built_an_endtoend_machine/",
          "author": null,
          "description": "From improving the user experience to making the computational infrastructure more effective, AI is a crucial aspect of making current software systems and products perform as well as possible. AI is often more effective than even precisely developed human-crafted heuristic tactics today, whether it’s reducing latency, boosting the quality of a video stream, or streamlining the interfaces to match a specific person’s demands. But, to use AI more effectively in various products, several challenges must be addressed: the system must accommodate software engineers without machine learning backgrounds; it must provide mechanisms to optimize for a variety of product goals, which may differ from closed-form machine learning loss functions; it must distinguish causal connections from data correlations; and it must scale efficiently to train, host, and monitor vast numbers of AI models. \n Meta Researchers Develop ‘Looper,’ an end-to-end AI platform that has been designed with easy-to-use APIs for optimization, personalization, and feedback collecting to answer these needs. Looper may be used to support the entire machine learning lifecycle, from model training to deployment and inference to product evaluation and optimization. Looper allows us to modify the existing products to leverage AI for personalized optimizations rather than having to rebuild them around AI models. Currently, the Looper platform hosts 700 AI models and produces 4 million AI outputs every second.\n Continue reading\n Paper: https://arxiv.org/pdf/2110.07554.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9xy01/meta_ai_researchers_built_an_endtoend_machine/",
          "publishedOn": "2022-04-23T05:09:09.000Z",
          "wordCount": 353,
          "title": "Meta AI Researchers Built An End-To-End Machine Learning Platform Called Looper, With Easy-To-Use APIs For Decision-Making And Feedback Collection",
          "imageUrl": "https://external-preview.redd.it/ZZKEjeoMAp8NTUJf4bZ2RvDXu-v0WYg_oJIHJ9jkov4.jpg?auto=webp&s=bb551fac42bb712fdc1f775094a84c9c3a0f39ff"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9va4b/are_there_any_programs_that_can_output_a_sentence/",
          "author": null,
          "description": "I'm looking to create a way to automate original story ideas based on previous ideas.\n I want to be able to input 1000+ original sentences and have an output of an original sentence that is inspired the previous ones.\n Are there any programs that can do this or will I need to develop my own?\n    submitted by    /u/yea_okay_dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9va4b/are_there_any_programs_that_can_output_a_sentence/",
          "publishedOn": "2022-04-23T02:34:44.000Z",
          "wordCount": 204,
          "title": "Are there any programs that can output a sentence based on input sentences?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9tyi7/ultimate_guide_to_activation_functions/",
          "author": null,
          "description": "submitted by    /u/SirFletch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9tyi7/ultimate_guide_to_activation_functions/",
          "publishedOn": "2022-04-23T01:23:34.000Z",
          "wordCount": 97,
          "title": "Ultimate Guide to Activation Functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9pzar/an_ai_painting_some_colorful_pitbulls/",
          "author": null,
          "description": "submitted by    /u/p0goniphaft111  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9pzar/an_ai_painting_some_colorful_pitbulls/",
          "publishedOn": "2022-04-22T22:02:25.000Z",
          "wordCount": 111,
          "title": "An AI painting some colorful pitbulls",
          "imageUrl": "https://external-preview.redd.it/r4IqnFJPAf59RvK29qYAsN5sK7NJdMzHppDLuZbjVfs.png?format=pjpg&auto=webp&s=02d4b0428bc2110c636479bcd21372fde4061cce"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9ki4t/building_a_pictionary_app_sketch_recognition/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9ki4t/building_a_pictionary_app_sketch_recognition/",
          "publishedOn": "2022-04-22T17:52:22.000Z",
          "wordCount": 120,
          "title": "Building A Pictionary App (sketch recognition model) with Gradio",
          "imageUrl": "https://preview.redd.it/j3tp4hs7c4v81.jpg?auto=webp&s=6bdf2b5d7230deb25f923b56df22849563d61299"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9im1g/is_there_a_ai_which_i_can_use_to_edit/",
          "author": null,
          "description": "Like I mark some areas of my pictures and then selcect what should happend with them?\n    submitted by    /u/xXLisa28Xx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9im1g/is_there_a_ai_which_i_can_use_to_edit/",
          "publishedOn": "2022-04-22T16:26:45.000Z",
          "wordCount": 131,
          "title": "Is there a AI which I can use to edit images(selfies etc.)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9hsxn/what_ai_can_i_use_to_make_caricatures_from/",
          "author": null,
          "description": "Is artbreeder the best way to do it, or is there a better way?\n    submitted by    /u/xXNOdrugsForMEXx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9hsxn/what_ai_can_i_use_to_make_caricatures_from/",
          "publishedOn": "2022-04-22T15:51:04.000Z",
          "wordCount": 200,
          "title": "What AI can I use to make caricatures from pictures from people?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9bp01/learning_or_working_with_ai_come_join_us_we_are_a/",
          "author": null,
          "description": "Programming is way more fun when you learn/work with someone. Help each other, ask questions, brainstorm, etc. There is just so much benefit to joining a community when you are in this field, especially when you cannot find the question you are looking for on stack overflow! 😉\n This is the same thing with AI, and it is why a little less than two years ago I created a discord server. Where anyone learning or working in the field could come and share their projects, learn together, work together, and much more. The community has now over 20 000 members, which is unbelievable! So glad to see it growing and see everyone so active. We also have an amazing partnership with an AI company coming that is super exciting for the community. You definitely want to be there to enjoy all the benefits they will give us.\n Come join us if you are in the field of AI !\n https://discord.gg/learnaitogether\n    submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9bp01/learning_or_working_with_ai_come_join_us_we_are_a/",
          "publishedOn": "2022-04-22T10:44:47.000Z",
          "wordCount": 329,
          "title": "Learning or working with AI? Come join us, we are a Discord Community with over 20'000 members! Ask questions, find teammates, share your projects, attend events, and much more to come!",
          "imageUrl": "https://external-preview.redd.it/TmwDNz7LGEv1N_4hjX4ofjCt4K0Y2QQCOiOzVJtu3RE.jpg?auto=webp&s=ad9751f0631441d3fcfa9501ab7921f50a06723b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u970et/analyse_sentimenttonality_in_social_networks/",
          "author": null,
          "description": "submitted by    /u/akolonin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u970et/analyse_sentimenttonality_in_social_networks/",
          "publishedOn": "2022-04-22T05:21:16.000Z",
          "wordCount": 172,
          "title": "Analyse sentiment/tonality in social networks",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u94gmh/research_explaining_the_black_box_optimization/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u94gmh/research_explaining_the_black_box_optimization/",
          "publishedOn": "2022-04-22T02:52:26.000Z",
          "wordCount": 789,
          "title": "[Research] Explaining the Black Box Optimization Competition Winner Algorithm-HEBO Algorithm of AI Top Conference NeurIPS 2020",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u90x16/last_week_in_ai_chip_startup_funding_doubled/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u90x16/last_week_in_ai_chip_startup_funding_doubled/",
          "publishedOn": "2022-04-21T23:47:26.000Z",
          "wordCount": 127,
          "title": "Last Week in AI: Chip Startup Funding Doubled, Google Text+Image Search, Analog AI, Criminal Robotaxi",
          "imageUrl": "https://external-preview.redd.it/GSN_6Y_ISJPFlnFKeQIO4j11y8PNxtWUoerk9AXuC1U.jpg?auto=webp&s=e87487497e998c33ab705d6bed0273ee00ffc75a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8zf34/ai_dream_31_spaceships_galore_planet_vqgan_clip/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8zf34/ai_dream_31_spaceships_galore_planet_vqgan_clip/",
          "publishedOn": "2022-04-21T22:33:13.000Z",
          "wordCount": 109,
          "title": "AI Dream 31 - Spaceships Galore Planet VQGAN CLIP",
          "imageUrl": "https://external-preview.redd.it/Eru_2C_c2KF_cPsZwkZGqk-JVlCgmzRnx18Usqc63n8.jpg?auto=webp&s=e6dfb804d102a1a67a602a39767a314646fe34d7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8wtb2/what_would_be_the_best_approach_to_autogenerate/",
          "author": null,
          "description": "I'm a software developer but I'm not really experienced in AI. Would it be best to train first for speech bubbles and separately for panel drawings? What kind of network is the best for this? Just thinking that it would be a cool project to have auto generated legible infinite comic strips for a semi niche comic strip that runs in my country.\n    submitted by    /u/dananite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8wtb2/what_would_be_the_best_approach_to_autogenerate/",
          "publishedOn": "2022-04-21T20:29:57.000Z",
          "wordCount": 248,
          "title": "What would be the best approach to auto-generate comic panels (Garfield style) with drawings and speech bubbles, assuming I have tons of scans to use as training?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8wa9d/any_recommendations_for_ai_content_generation/",
          "author": null,
          "description": "Content generation is such a time-suck for small businesses, and it seems like an interesting vertical to apply AI. The AI would generate the content after being given a prompt. There are already a few tools trying this, but the quality doesn't seem to be very high.\n Are there better tools that I'm missing, or is the consumer-facing software so early-stage that it would be better to hire a data scientist and train an AI system specifically for this purpose?\n https://www.reddit.com/r/MachinesWrite/comments/f45eav/list_of_ai_text_generators/?utm_source=share&utm_medium=web2x&context=3\n https://www.reddit.com/r/juststart/comments/axa8w3/ai_ml_text_generators/?utm_source=share&utm_medium=web2x&context=3\n    submitted by    /u/CliffWoolum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8wa9d/any_recommendations_for_ai_content_generation/",
          "publishedOn": "2022-04-21T20:05:22.000Z",
          "wordCount": 225,
          "title": "Any Recommendations for AI Content Generation Software?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8vmk4/looking_for_enterprise_conversational_ai_platform/",
          "author": null,
          "description": "submitted by    /u/sunstormfirefall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8vmk4/looking_for_enterprise_conversational_ai_platform/",
          "publishedOn": "2022-04-21T19:35:25.000Z",
          "wordCount": 353,
          "title": "Looking for enterprise conversational AI platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8v5yo/vicreg_tutorial_and_lightweight_pytorch/",
          "author": null,
          "description": "Here's a tutorial and lightweight PyTorch implementation of VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning. Hope you find it helpful!\n    submitted by    /u/thejashGI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8v5yo/vicreg_tutorial_and_lightweight_pytorch/",
          "publishedOn": "2022-04-21T19:13:58.000Z",
          "wordCount": 135,
          "title": "VICReg: Tutorial and Lightweight PyTorch Implementation blog post",
          "imageUrl": "https://external-preview.redd.it/nlio8usMqy_ReFWZfdRWZzVWPAOmlaQsm5fC0fDkpO4.jpg?auto=webp&s=e7ed882487e5ed475af6d8e7f98866ba1a7d80b0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8tbkf/microsoft_ai_researchers_develop_ekya_to_address/",
          "author": null,
          "description": "Deep neural network (DNN) models for object recognition and classification, such as Yolo, ResNet, and EfficientNet, are used in video analytics applications such as urban mobility and smart automobiles. There is a symbiotic link between edge computing and video analytics, claiming that live video analytics is the “killer app” for edge computing. Edge devices come in various sizes and designs, but they are always resource-constrained compared to the cloud. Video analytics deployments send the videos to on-premises edge servers. The article handles the difficulty of supporting inference and retraining jobs on edge servers simultaneously, which necessitates navigating the fundamental tradeoff between the accuracy of the retrained model and the accuracy of the inference. Edge computation is preferred for video analytics because it eliminates the need for expensive network lines to broadcast videos to the cloud while simultaneously preserving video privacy. Edge computation has a finite amount of resources (e.g., with weak GPUs). The mismatch between the increasing rate of model compute needs, and the total cycles of processors exacerbate this problem. As a result, model compression is used in edge deployments.\n Continue reading our bite on this research\n Paper: https://www.microsoft.com/en-us/research/uploads/prod/2021/07/nsdi22spring-final74.pdf\n Github: https://github.com/edge-video-services/ekya\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8tbkf/microsoft_ai_researchers_develop_ekya_to_address/",
          "publishedOn": "2022-04-21T17:49:42.000Z",
          "wordCount": 346,
          "title": "Microsoft AI Researchers Develop ‘Ekya’ To Address The Problem Of Data Drift On The Edge Compute Box And Enables Both Retraining And Inference To Co-Exist On It",
          "imageUrl": "https://external-preview.redd.it/fr6sTFkxPr_nxK_uM6bfbHkoEh-SBIH6kJojQNYUb74.jpg?auto=webp&s=214c6642ae7b51e469b77b058da4813078222c49"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8ou8m/is_there_a_ai_which_is_able_to_turn_normal_videos/",
          "author": null,
          "description": "submitted by    /u/TheblackRook3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8ou8m/is_there_a_ai_which_is_able_to_turn_normal_videos/",
          "publishedOn": "2022-04-21T14:25:25.000Z",
          "wordCount": 345,
          "title": "Is there a AI which is able to turn normal videos into sketches like the video below?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8mnva/automatic_summaries_of_your_documents_in_google/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8mnva/automatic_summaries_of_your_documents_in_google/",
          "publishedOn": "2022-04-21T12:37:26.000Z",
          "wordCount": 131,
          "title": "Automatic Summaries of your Documents in Google Docs !",
          "imageUrl": "https://external-preview.redd.it/0xBUwjndLwNWttGumJ98z2kj6iEcrI9jeA8utIsy9cY.jpg?auto=webp&s=a2d2a30600e5cf86b9301a3b955148fc3cce0761"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8iurr/how_to_achieve_a_training_duration_on_mindspore/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8iurr/how_to_achieve_a_training_duration_on_mindspore/",
          "publishedOn": "2022-04-21T08:36:46.000Z",
          "wordCount": 177,
          "title": "How to achieve a training duration on MindSpore that's less than or equal to that on TensorFlow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8he59/cypherzilla_the_first_encoded_nft_made_by_ai_to/",
          "author": null,
          "description": "CypherZilla on OpenSea\n https://reddit.com/link/u8he59/video/i9a29i5ywtu81/player\n    submitted by    /u/thecypherbeast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8he59/cypherzilla_the_first_encoded_nft_made_by_ai_to/",
          "publishedOn": "2022-04-21T06:49:15.000Z",
          "wordCount": 144,
          "title": "CypherZilla - The First Encoded NFT Made By AI To Support Trump. Upvote If You Want To Have A Huge Impact!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8gqe6/what_price_we_have_to_pay_for_the_progress_in_ai/",
          "author": null,
          "description": "https://www.sganalytics.com/blog/top-ethical-challenges-in-ai-the-price-of-progress/\n    submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8gqe6/what_price_we_have_to_pay_for_the_progress_in_ai/",
          "publishedOn": "2022-04-21T06:03:03.000Z",
          "wordCount": 119,
          "title": "What price we have to pay for the progress in AI, have a look-",
          "imageUrl": "https://external-preview.redd.it/aJi9Dz8P0k_F4j63zzdsjmhZLTXVfVYWVwiQByiyL84.jpg?auto=webp&s=aa8556546cd821f61a872c3d317d57475ebd7f58"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8antj/collaboration_ai_video_and_music/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8antj/collaboration_ai_video_and_music/",
          "publishedOn": "2022-04-21T00:24:55.000Z",
          "wordCount": 99,
          "title": "Collaboration AI video and music",
          "imageUrl": "https://external-preview.redd.it/Y_eldCN6JOpbpC_YENv_YSn0QxPnFndB-G04FqdlA5Y.jpg?auto=webp&s=9e717a70be47b65026e97471414298559f000428"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u85fsk/how_metas_multiverse_could_prove_our_universe_is/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u85fsk/how_metas_multiverse_could_prove_our_universe_is/",
          "publishedOn": "2022-04-20T20:16:17.000Z",
          "wordCount": 107,
          "title": "How Meta's multiverse could prove our universe is a fake",
          "imageUrl": "https://external-preview.redd.it/DsNE0-E8qUN9meNVbuhEnTE425OzpenTFo5id5M4u2o.jpg?auto=webp&s=48c490435839a13aeba3e0561dfd23b2feb1ecf3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u81hue/singularagent_many_methods_make_light_work/",
          "author": null,
          "description": "submitted by    /u/dantheman333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u81hue/singularagent_many_methods_make_light_work/",
          "publishedOn": "2022-04-20T17:16:30.000Z",
          "wordCount": 98,
          "title": "SingularAgent - Many Methods Make Light Work",
          "imageUrl": "https://external-preview.redd.it/INnAD5TDh2VB1h8EWzKC44A73kxhQQ6pA-Mo0FmEnrI.jpg?auto=webp&s=0a600af7f3c7bc5af8ac54c4682885169c870ed6"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u813a9/general_ai_in_healthcare_machine_learning_for/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u813a9/general_ai_in_healthcare_machine_learning_for/",
          "publishedOn": "2022-04-20T16:58:30.000Z",
          "wordCount": 124,
          "title": "General AI In Healthcare | Machine Learning For Cardiovascular Disease | Color Night Vision",
          "imageUrl": "https://external-preview.redd.it/De-wZxccwJFEqrmmsZjRzOWELT5D2lZO8A5k3zuymuk.jpg?auto=webp&s=c42558ab2d7266cb2819e4b0eac7c7fa7bbcae38"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7x38l/a_realistic_image_ai_software/",
          "author": null,
          "description": "submitted by    /u/Eurokiwiboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7x38l/a_realistic_image_ai_software/",
          "publishedOn": "2022-04-20T13:55:44.000Z",
          "wordCount": 97,
          "title": "A realistic image AI software",
          "imageUrl": "https://external-preview.redd.it/JbsDTf4SAmO2SdHaC_VY9bSe5I7FCR0zWo9moIdaijE.jpg?auto=webp&s=7c3664b585db5e4b0a26dc33ac2e2da99c9c904c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7vj4l/ant_colony_simulation/",
          "author": null,
          "description": "submitted by    /u/Seitoh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7vj4l/ant_colony_simulation/",
          "publishedOn": "2022-04-20T12:37:37.000Z",
          "wordCount": 415,
          "title": "Ant colony simulation",
          "imageUrl": "https://external-preview.redd.it/-fHs8s9VwwMqv6VYm5CgwsKlfQtEFbHQXsxeWKjorXY.png?format=pjpg&auto=webp&s=f32b988700168737f55c6ee64fde0ddc600dcf9f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7r8w6/is_there_any_free_open_source_ai_model_available/",
          "author": null,
          "description": "A few years back I developed a very simple app just to show a few bible verses. Though it is a very simple app, it got more than 50K installs without much promotion. So, I am thinking about promoting it. But hesitate to do it as it is very simple app. So, I would like to add some useful feature before start promoting it. I would like to add a feature which will allow the users to ask any question related to bible, and it should be giving relevant answer. I assume that some bible data is open source.\n Is there any free tutorial available to know about how to implement AI based chat system for answering any bible related queries after training with bible data.\n Is there any app already providing this feature?\n    submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7r8w6/is_there_any_free_open_source_ai_model_available/",
          "publishedOn": "2022-04-20T07:51:49.000Z",
          "wordCount": 253,
          "title": "Is there any free open source AI model available for answering any bible related queries?",
          "imageUrl": "https://external-preview.redd.it/eayHQ469wG-aR9Glgtq5PmukilhQBjG1gVHPRS5ivCU.jpg?auto=webp&s=fa2d65c79e60c391fa3fb02677129791c19da8d5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7ptrm/today_ai_is_becoming_ubiquitous_in_and_out_of_the/",
          "author": null,
          "description": "But can technology be controlled to avoid adverse outcomes? \n Let's understand how AI will help us to make a better world. \n https://us.sganalytics.com/blog/top-ethical-challenges-in-ai-the-price-of-progress/\n    submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7ptrm/today_ai_is_becoming_ubiquitous_in_and_out_of_the/",
          "publishedOn": "2022-04-20T06:10:00.000Z",
          "wordCount": 209,
          "title": "Today, AI is becoming ubiquitous, in and out of the workplace. With artificial intelligence (AI) becoming more powerful, the questions that surround AI ethics are becoming more relevant.",
          "imageUrl": "https://external-preview.redd.it/gpojHrxBRiyNRtS4dowCf62GHN0syOExlU8hVfJ3XUs.jpg?auto=webp&s=23fcb4c3ce2f7f5aa36daead94f7b8531000bfa7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7pch8/top_ethical_challenges_in_ai_the_price_of_progress/",
          "author": null,
          "description": "submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7pch8/top_ethical_challenges_in_ai_the_price_of_progress/",
          "publishedOn": "2022-04-20T05:38:08.000Z",
          "wordCount": 114,
          "title": "Top Ethical Challenges in AI – The Price of Progress",
          "imageUrl": "https://external-preview.redd.it/aJi9Dz8P0k_F4j63zzdsjmhZLTXVfVYWVwiQByiyL84.jpg?auto=webp&s=aa8556546cd821f61a872c3d317d57475ebd7f58"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7ogsu/artificial_nightmares_dr_strange_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7ogsu/artificial_nightmares_dr_strange_clip_guided/",
          "publishedOn": "2022-04-20T04:41:41.000Z",
          "wordCount": 126,
          "title": "Artificial Nightmares: Dr. Strange || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/_H1fKKk02xXV582Jck7PKzfLEX5sJzRZLVo9i5g1P_c.jpg?auto=webp&s=cc98d438165684e9033ba48a6c7406fd5f316d9a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7jj2e/weekly_china_ai_news_chinese_prominent_ai_lab/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7jj2e/weekly_china_ai_news_chinese_prominent_ai_lab/",
          "publishedOn": "2022-04-20T00:16:24.000Z",
          "wordCount": 163,
          "title": "Weekly China AI News: Chinese Prominent AI Lab Plagiarizes Big Model Paper; Microsoft Research Asia Halts Internship Hiring from US-Banned Universities; Beijing Announces New RISC-V Chip Institute",
          "imageUrl": "https://external-preview.redd.it/8PfsozjPm9bKaZri1Oa5OJpyHDfqbBmkOag-6iAr918.jpg?auto=webp&s=eefadd25142b934a070d398829efea1ac0a6cfe7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7ix6l/speeding_up_ai_algorithms_inferencing_challenges/",
          "author": null,
          "description": "submitted by    /u/Chipdoc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7ix6l/speeding_up_ai_algorithms_inferencing_challenges/",
          "publishedOn": "2022-04-19T23:46:09.000Z",
          "wordCount": 104,
          "title": "Speeding Up AI Algorithms- Inferencing challenges at the edge",
          "imageUrl": "https://external-preview.redd.it/iLwjB8yODgc1h8Gz-x0aNzFmOYuA86G2FzAHD7r7_Mo.jpg?auto=webp&s=709ea43539a1a3f5773e4472268a27d09738a0b5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7eq9m/build_share_machine_learning_apps_directly_in/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7eq9m/build_share_machine_learning_apps_directly_in/",
          "publishedOn": "2022-04-19T20:30:27.000Z",
          "wordCount": 116,
          "title": "Build & share machine learning apps directly in browser using Gradio in Python",
          "imageUrl": "https://preview.redd.it/k19vt6tmpju81.jpg?auto=webp&s=2aa19787e1291bfcac0496868c0e3625705814d8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7cnk8/what_if_you_are_a_prototype_for_the_ultimate/",
          "author": null,
          "description": "submitted by    /u/IndependenceFun4627  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7cnk8/what_if_you_are_a_prototype_for_the_ultimate/",
          "publishedOn": "2022-04-19T18:58:58.000Z",
          "wordCount": 184,
          "title": "What if You Are a Prototype for the Ultimate Sentient Artificial Intelligence?",
          "imageUrl": "https://external-preview.redd.it/XQWZBCGw8dWGlWDR0iPMP0YiLAUNLg_qbtwvNCo-BkY.jpg?auto=webp&s=1f0d1be28c0573a2dfea524dd3f794f9e719fdc5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7bxnv/overview_of_relational_graph_convolutional/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7bxnv/overview_of_relational_graph_convolutional/",
          "publishedOn": "2022-04-19T18:27:46.000Z",
          "wordCount": 98,
          "title": "Overview of Relational Graph Convolutional Networks (RGCN)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7a4yw/there_are_so_many_crappy_chatbots_cause_people/",
          "author": null,
          "description": "Hi there! Chatbots are not the \"set and forget\" thing like many other software. If you want to achieve great results with your chatbot, you need to improve it constantly. To know where and what to improve, you need to track and monitor chatbot analytics and the main chatbot metrics.\n General chatbot metrics\n  \nTotal number of users\n User satisfaction\n Accuracy of the chatbot\n  \nEngagement metrics\n  \nActive users\n New users\n Conversation Length\n Retention Rate\n Bounce Rate\n Flow Completion Rate\n  \nConversational analytics\n  \nGoal Completion Rate (GCR)\n Fallback Rate\n Human Takeover Rate\n  \n* Bonus: Revenue metrics\n  \nRevenue generated\n ROI / payback period\n  \nHere in the article we covered how to calculate each metrics, and you can find needed metrics depending on the industry you working in https://botscrew.com/blog/chatbot-metrics/?utm_source=RedditArtificial&utm_medium=&utm_campaign=&utm_term=&utm_content=\n    submitted by    /u/Avandegraund  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7a4yw/there_are_so_many_crappy_chatbots_cause_people/",
          "publishedOn": "2022-04-19T17:10:20.000Z",
          "wordCount": 262,
          "title": "There are so many crappy chatbots, cause people don't pay attention on how it's performing. If you're one of them, here are metrics to keep in mind",
          "imageUrl": "https://external-preview.redd.it/nrLynkYAQfOecU574osiJ7EnlqlHprcrqGz13zB8U8s.jpg?auto=webp&s=79d3cd16186d7b6b9d8502a3e69c47b38a062db8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u797ue/wakeup_call_for_science_ai_system_develops_40000/",
          "author": null,
          "description": "submitted by    /u/TheCnt23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u797ue/wakeup_call_for_science_ai_system_develops_40000/",
          "publishedOn": "2022-04-19T16:30:04.000Z",
          "wordCount": 124,
          "title": "Wake-up Call for Science – AI System Develops 40,000 Chemical Weapons in 6 Hours",
          "imageUrl": "https://external-preview.redd.it/g87RQeN11WVmu3DBw0sXRgwG3g-JIXTh6ffdprAUOaI.jpg?auto=webp&s=1fb734b051f900dcd188cb8bf120fd6b7a0fbee8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u75xc0/stopping_them_from_spying_on_you_new_ai_can_block/",
          "author": null,
          "description": "submitted by    /u/KelliaMcclure  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u75xc0/stopping_them_from_spying_on_you_new_ai_can_block/",
          "publishedOn": "2022-04-19T14:03:37.000Z",
          "wordCount": 118,
          "title": "Stopping 'them' from spying on you: New AI can block rogue microphones",
          "imageUrl": "https://external-preview.redd.it/4VZwC4-xEcbJE_DmEFspbG5nf2ah1Z_zKcWXPPgo5vY.jpg?auto=webp&s=78e92e81c66132b6ba704a237b1d980b44652118"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u75l7z/stopping_them_from_spying_on_you_new_ai_can_block/",
          "author": null,
          "description": "submitted by    /u/KelliaMcclure  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u75l7z/stopping_them_from_spying_on_you_new_ai_can_block/",
          "publishedOn": "2022-04-19T13:48:14.000Z",
          "wordCount": 488,
          "title": "Stopping 'them' from spying on you: New AI can block rogue microphones",
          "imageUrl": "https://external-preview.redd.it/4VZwC4-xEcbJE_DmEFspbG5nf2ah1Z_zKcWXPPgo5vY.jpg?auto=webp&s=78e92e81c66132b6ba704a237b1d980b44652118"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7557s/which_courses_are_good_for_complete_beginners/",
          "author": null,
          "description": "Hello everyone , can someone recommend me for some good courses to do , I saw some courses on udemy , this one worth it? https://www.udemy.com/course/artificial-intelligence-az/\n or I can learn everything on youtube? there are few more on udemy but I don't know how good they are ..\n is it worth buying one of those or there are better videos on youtube?\n EDIT : I found another 4 courses :\n https://www.udemy.com/course/100-days-of-code/\n https://www.udemy.com/course/complete-python-bootcamp/ \n https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/\n https://www.udemy.com/course/machinelearning/\n Which one of them would you recommend the most?\n    submitted by    /u/Edrixor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7557s/which_courses_are_good_for_complete_beginners/",
          "publishedOn": "2022-04-19T13:26:49.000Z",
          "wordCount": 172,
          "title": "which courses are good for complete beginners?",
          "imageUrl": "https://external-preview.redd.it/0pMpUAz3akcRBLby7is7-gznZCQ9YfuPikH0u3LfLOc.jpg?auto=webp&s=c8fe621a36d5853ff106453eee70c17359f9ea57"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u74jg6/ai_will_make_us_dumb_220407888_ai_ageing_and/",
          "author": null,
          "description": "submitted by    /u/kg4jxt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u74jg6/ai_will_make_us_dumb_220407888_ai_ageing_and/",
          "publishedOn": "2022-04-19T12:57:16.000Z",
          "wordCount": 311,
          "title": "AI will make us dumb: [2204.07888] AI, Ageing and Brain-Work Productivity: Technological Change in Professional Japanese Chess",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u72mx0/any_good_resources_to_learn_default_theory/",
          "author": null,
          "description": "I am having a difficult time understanding Default Theory and the various methods e.g Makinson to find the extension of default theories\n    submitted by    /u/cocag13996  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u72mx0/any_good_resources_to_learn_default_theory/",
          "publishedOn": "2022-04-19T11:11:59.000Z",
          "wordCount": 119,
          "title": "Any good resources to learn Default Theory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u71qxe/i_know_that_the_voice_in_this_video_is_made_using/",
          "author": null,
          "description": "This\n I looked through the available ones, not a single one seems to match it. Sorry if this isn't the right sub to ask, but since Replica Studios doesn't have its own sub I don't know where\n    submitted by    /u/AxySmarts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u71qxe/i_know_that_the_voice_in_this_video_is_made_using/",
          "publishedOn": "2022-04-19T10:16:11.000Z",
          "wordCount": 181,
          "title": "I know that the voice in this video is made using Replica Studio's engine, but does anyone know which voice exactly was used?",
          "imageUrl": "https://external-preview.redd.it/wvkCFnR-1hsAqSUcg_fO-WhKr7U7A8Iadzpsn-AWzBs.jpg?auto=webp&s=8e847789208f0a6210a981d933057d8e5321d7d3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6ur63/artificial_nightmares_schizophrenia_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6ur63/artificial_nightmares_schizophrenia_clip_guided/",
          "publishedOn": "2022-04-19T02:49:38.000Z",
          "wordCount": 123,
          "title": "Artificial Nightmares: Schizophrenia || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/SL4UeLUNXFJ5_GRhRiLVL-JFuAvsji8dg8G2wQSzBkg.jpg?auto=webp&s=1652b216042892f4ef776b9c2e0d85e3d2a988f4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6qw0p/whats_your_hopes_and_worry_about_future_humaniod/",
          "author": null,
          "description": "submitted by    /u/Upset_Force66  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6qw0p/whats_your_hopes_and_worry_about_future_humaniod/",
          "publishedOn": "2022-04-18T23:37:26.000Z",
          "wordCount": 115,
          "title": "whats your hopes and worry about future humaniod Artificial intelligence coming soon?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6ocab/ai_dream_36_psychedelic_special_4k_40mbit_test/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6ocab/ai_dream_36_psychedelic_special_4k_40mbit_test/",
          "publishedOn": "2022-04-18T21:42:09.000Z",
          "wordCount": 109,
          "title": "AI Dream 36 - Psychedelic Special (4K 40Mbit Test)",
          "imageUrl": "https://external-preview.redd.it/VmWUdniS5xpclW7Q_xIN2ip-aetWqAhw_ev2n3-RlWk.jpg?auto=webp&s=204618cbe921d1c2897d013824ad38cf5e791c8b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6lzqw/ai_startups_and_the_hunt_for_tech_talent_in/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6lzqw/ai_startups_and_the_hunt_for_tech_talent_in/",
          "publishedOn": "2022-04-18T19:58:27.000Z",
          "wordCount": 112,
          "title": "AI Startups and the Hunt for Tech Talent in Vietnam",
          "imageUrl": "https://external-preview.redd.it/VTHcGJP2dX5u4LCB9A9PIqA9308RpRmiYJ58QNRdH0o.jpg?auto=webp&s=6e907dbf8c56e03505d84ceea6d1a6fa2fe513da"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6kzbr/we_dont_have_echolocation/",
          "author": null,
          "description": "submitted by    /u/tezdhar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6kzbr/we_dont_have_echolocation/",
          "publishedOn": "2022-04-18T19:13:50.000Z",
          "wordCount": 103,
          "title": "We don't have echolocation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6kung/these_3michelinstarred_plates_were_invented_by_ai/",
          "author": null,
          "description": "submitted by    /u/jonfla  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6kung/these_3michelinstarred_plates_were_invented_by_ai/",
          "publishedOn": "2022-04-18T19:08:00.000Z",
          "wordCount": 118,
          "title": "These 3-Michelin-starred plates were invented by AI. The food doesn’t even exist",
          "imageUrl": "https://external-preview.redd.it/zNvoAOfuDMmMFofp6qb79qAyhOng7bR438eGTMflgmI.jpg?auto=webp&s=6d2f0456f69a15ebc576485fa4a7c7c15f62bda4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6kow4/getting_in_shape_while_homeworking_by_force/",
          "author": null,
          "description": "submitted by    /u/ThePyCoder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6kow4/getting_in_shape_while_homeworking_by_force/",
          "publishedOn": "2022-04-18T19:01:05.000Z",
          "wordCount": 145,
          "title": "Getting in shape while homeworking by force locking the screen and using blazepose pose estimation to detect pushups to unlock it again.",
          "imageUrl": "https://external-preview.redd.it/efuGVuRWCoQOFtDulJ96gkeKNGq9LeHuDr_G8Om-4Cg.jpg?auto=webp&s=25496b15357178107e28538f630ef85c416be24e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6ke8u/last_week_in_ai_ai_chip_startup_funding_doubled/",
          "author": null,
          "description": "https://lastweekin.ai/p/163?s=w\n    submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6ke8u/last_week_in_ai_ai_chip_startup_funding_doubled/",
          "publishedOn": "2022-04-18T18:48:24.000Z",
          "wordCount": 170,
          "title": "Last Week in AI: AI chip startup funding doubled in the last 5 years, new AI applications in hospitals and restaurants, Cruise robotaxi pulled over by police in SF, and more!",
          "imageUrl": "https://external-preview.redd.it/wDYeYdIZJ7X1EXsqTtkFmI64EiTZ-aoZ4-NSIK1k6lM.jpg?auto=webp&s=80b3ca386765a5116b47659140c5b3f4fab52fd4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6eoup/youtubers_create_a_completely_ai_influencer/",
          "author": null,
          "description": "submitted by    /u/savetheattack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6eoup/youtubers_create_a_completely_ai_influencer/",
          "publishedOn": "2022-04-18T14:38:56.000Z",
          "wordCount": 95,
          "title": "Youtubers create a completely AI \"influencer.\"",
          "imageUrl": "https://external-preview.redd.it/0lAR04IvZZB-HTIeW4f95BXpn-IgNcrNJ3Hr6l9mLtA.jpg?auto=webp&s=db1ed9cbbdf8d16babae6493cf495ada51673bed"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6d5e1/fomo_is_a_tinyml_neural_network_for_realtime/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6d5e1/fomo_is_a_tinyml_neural_network_for_realtime/",
          "publishedOn": "2022-04-18T13:27:10.000Z",
          "wordCount": 112,
          "title": "FOMO is a TinyML neural network for real-time object detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6cbz8/an_online_course_with_an_ai_tutor_achieves_a/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6cbz8/an_online_course_with_an_ai_tutor_achieves_a/",
          "publishedOn": "2022-04-18T12:47:12.000Z",
          "wordCount": 338,
          "title": "An online course with an AI tutor achieves a significantly higher completion rate than traditional online courses thanks to a personalized learning experience.",
          "imageUrl": "https://external-preview.redd.it/HM1mHkpsBRyrCPFfV-GyEDe1IM82yc7-pIySw5sSYLw.jpg?auto=webp&s=794512a998357fede38a9275b7947eeb9dfc2545"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u68ndy/protein_folding_neural_networks_eg_rosettafold/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u68ndy/protein_folding_neural_networks_eg_rosettafold/",
          "publishedOn": "2022-04-18T09:01:14.000Z",
          "wordCount": 104,
          "title": "Protein Folding Neural Networks (e.g RoseTTAFold) Are Not Robust",
          "imageUrl": "https://external-preview.redd.it/qX06OApQxBwLalWdKBMkO5luiOO17-Zw5e0-W9Ng-j0.jpg?auto=webp&s=237f28276a35cf32c9468e1dad8576a5f2e64e23"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u65x6q/witch_of_the_barthe/",
          "author": null,
          "description": "submitted by    /u/Hacknaut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u65x6q/witch_of_the_barthe/",
          "publishedOn": "2022-04-18T05:49:16.000Z",
          "wordCount": 90,
          "title": "Witch of the Barthe",
          "imageUrl": "https://preview.redd.it/adnay8p278u81.png?auto=webp&s=96aae290f68d3ec0a1c029c57d525850b1d5c19c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u64j7h/why_is_it_called_tensorflow_and_not_matrixflow/",
          "author": null,
          "description": "Hello,\n I'm MB. A very nice and polite guy.\n Why is it called tensorflow and not matrixflow?\n AI is all about matrix multiplications, right? So why use the word tensor instead? I know what a tensor is, kind of. But isn't AI about matrix multiplications primarily rather than tensor multiplications.\n ELI5 please.\n    submitted by    /u/MountBlanc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u64j7h/why_is_it_called_tensorflow_and_not_matrixflow/",
          "publishedOn": "2022-04-18T04:20:22.000Z",
          "wordCount": 577,
          "title": "Why is it called tensorflow and not matrixflow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u64gx1/society/",
          "author": null,
          "description": "submitted by    /u/booksmoothie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u64gx1/society/",
          "publishedOn": "2022-04-18T04:16:39.000Z",
          "wordCount": 82,
          "title": "Society",
          "imageUrl": "https://preview.redd.it/iucbmpuzq7u81.png?auto=webp&s=04d171aa61c71f9f7ae542212c620888b36ed57a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u63lm4/bioinspired_multisensory_neural_network_with/",
          "author": null,
          "description": "submitted by    /u/booksmoothie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u63lm4/bioinspired_multisensory_neural_network_with/",
          "publishedOn": "2022-04-18T03:26:32.000Z",
          "wordCount": 109,
          "title": "Bioinspired multisensory neural network with crossmodal integration and recognition",
          "imageUrl": "https://external-preview.redd.it/ysCYb5ssDbIgxnBfohLEto-Q9jDFUluNp2TmJD673zI.jpg?auto=webp&s=c8319d2bc17b60605482b020564c5a3b034dca9c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u630rh/realistic_animal_movement/",
          "author": null,
          "description": "I am working on a robotic pet that has lots of movement capability but is simply scripted and will unnaturally jump between movement sets without considering the current movement.\n What branch of AI should I look into leaning about? Currently I use mostly python for high level and C for microcontrollers.\n    submitted by    /u/uMinded  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u630rh/realistic_animal_movement/",
          "publishedOn": "2022-04-18T02:54:24.000Z",
          "wordCount": 141,
          "title": "Realistic animal movement",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5z9k4/build_share_machine_learning_apps_directly_in/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5z9k4/build_share_machine_learning_apps_directly_in/",
          "publishedOn": "2022-04-17T23:36:12.000Z",
          "wordCount": 121,
          "title": "Build & share machine learning apps directly in browser using Gradio in Python",
          "imageUrl": "https://external-preview.redd.it/_jq3RHJF4dWo0ICB0aESwOXlW3jCTwldBtbIIuFynSw.jpg?auto=webp&s=8bf1e5972aabb7d81fcda17ccbee87891e8cf6ae"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5lgia/ai_trippy_dream_19_exploring_a_colorful_maze/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5lgia/ai_trippy_dream_19_exploring_a_colorful_maze/",
          "publishedOn": "2022-04-17T11:49:43.000Z",
          "wordCount": 109,
          "title": "AI Trippy Dream 19 - Exploring a Colorful Maze",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5ihzv/a_better_boids_simulation_an_artificial_life/",
          "author": null,
          "description": "submitted by    /u/Seitoh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5ihzv/a_better_boids_simulation_an_artificial_life/",
          "publishedOn": "2022-04-17T08:10:26.000Z",
          "wordCount": 303,
          "title": "a better Boids simulation: An artificial life simulation of the flock of birds",
          "imageUrl": "https://external-preview.redd.it/FpMxU4uPFl-vAzL6kppEQXyvL5tvV4RhnB5zhZzQOy8.png?format=pjpg&auto=webp&s=df79df42ad0317dc64a52796d3fd09a09f7a5b69"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5fpt3/new_ai_upscaler_tool/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5fpt3/new_ai_upscaler_tool/",
          "publishedOn": "2022-04-17T04:52:19.000Z",
          "wordCount": 141,
          "title": "New AI upscaler tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5e5hc/credit_scoring_for_companies/",
          "author": null,
          "description": "Hello everyone I'm newbie so pardon me if you find that my question is stupid.\n I'm working on a project here's it's description in a nutshell ( Classifying companies if they're going to bankrupt or not and based of the probability of default ( probability of bankruptcy) give each companies a score For example 88 percent to bankrupt score is D 21 percent to bankrupt score is B 3 percent to bankrupt score is a)\n My question is what kind of models should test ? Should i go for machine learning algorithms such as logistic regression, knn, SVM? Should I go for neural networks ANN? Or can I use deep learning models like MLP... probabilistic Neural Network?\n Any guidance or advice will be appreciated and thanks a lot.\n    submitted by    /u/YeccAnon4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5e5hc/credit_scoring_for_companies/",
          "publishedOn": "2022-04-17T03:17:40.000Z",
          "wordCount": 261,
          "title": "credit scoring for companies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5abdp/is_there_an_ai_i_could_use_to_create_an/",
          "author": null,
          "description": "He’s basically this wacky dead philosopher with 1000s of hours of his lectures of YT and I was thinking it may be possible to create an artificial AI personality of his from all of his recorded speech? Would there be a simple enough program I could download or anything of the sort?\n    submitted by    /u/Vaporshots  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5abdp/is_there_an_ai_i_could_use_to_create_an/",
          "publishedOn": "2022-04-16T23:43:04.000Z",
          "wordCount": 195,
          "title": "Is there an AI I could use to create an artificial Terence McKenna chatbot?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u58cz2/boids_an_artificial_life_simulation_of_a_flock_of/",
          "author": null,
          "description": "submitted by    /u/Seitoh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u58cz2/boids_an_artificial_life_simulation_of_a_flock_of/",
          "publishedOn": "2022-04-16T22:02:55.000Z",
          "wordCount": 324,
          "title": "Boids: An artificial life simulation of a flock of birds",
          "imageUrl": "https://external-preview.redd.it/MC2dZoKt52Ish-rXYqykRUtNorColauLlnAj87Qk6R0.jpg?auto=webp&s=7ed2b478412d5048fb535a1e299d91ed80ee85b7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u52b68/ai_trippy_dream_37_psychedelic_special_request/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u52b68/ai_trippy_dream_37_psychedelic_special_request/",
          "publishedOn": "2022-04-16T17:10:35.000Z",
          "wordCount": 106,
          "title": "AI Trippy Dream 37 - Psychedelic Special Request",
          "imageUrl": "https://external-preview.redd.it/UDUee4CNXyN_18m6d0_XcLn_poNEPFUiGY4oFvksdAk.jpg?auto=webp&s=85c23e7d35246adfb0a5854e6f9b7cf3f99b08bb"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u50q5a/amazing_generation/",
          "author": null,
          "description": "Looks Amazing. The vibe is there.\n What do you think ? How did he archive this ? Created by Hand or through artificial ?\n https://www.tiktok.com/@ai.metascape/video/7086451191151971586\n    submitted by    /u/PillowG1rl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u50q5a/amazing_generation/",
          "publishedOn": "2022-04-16T15:55:31.000Z",
          "wordCount": 117,
          "title": "Amazing Generation",
          "imageUrl": "https://external-preview.redd.it/tuH77pY8E4IE5WNny2LLRYwtPlRizLtWW5Ws9enm2_U.jpg?auto=webp&s=c73c1437628e53b065b642a7f489f78aae2d0e36"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4xeoh/little_baby_chibi_lucy_loud/",
          "author": null,
          "description": "submitted by    /u/VIRUS-AOTOXIN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4xeoh/little_baby_chibi_lucy_loud/",
          "publishedOn": "2022-04-16T13:05:37.000Z",
          "wordCount": 94,
          "title": "Little Baby Chibi Lucy Loud",
          "imageUrl": "https://preview.redd.it/enybtp2l3wt81.jpg?auto=webp&s=99423db58c3de8107fc165a19dc0c347c27a519b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4s7oi/artificial_intelligence_is_the_future_of/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4s7oi/artificial_intelligence_is_the_future_of/",
          "publishedOn": "2022-04-16T07:03:38.000Z",
          "wordCount": 103,
          "title": "Artificial Intelligence is the Future of Deterrence",
          "imageUrl": "https://external-preview.redd.it/bd6LRMpI4iKmVPYzrZlbX3z7Q1-HWYSYL1d1xahGooM.jpg?auto=webp&s=805cf15bf8bd1b6ad6ff8b77501090c481777837"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4rylo/linkedin_opensources_feathr_its_feature_store_to/",
          "author": null,
          "description": "LinkedIn research team has recently open-sourced feature store, Feathr, created to simplify machine learning (ML) feature management and increase developer productivity. Feathr is used by dozens of LinkedIn applications to define features, compute them for training, deploy them in production, and share them across consumers. Compared to previous application-specific feature pipeline solutions, Feathr users reported significantly reduced time required to add new features to model training and improved runtime performance.\n Hundreds of ML models run on LinkedIn in Search, Feed, and Ads applications. Thousands of features about entities in the Economic Graph, such as companies, job postings, and LinkedIn members, power the models. The most time-consuming aspects of handling the ML applications at scale have been preparing and managing features.\n Continue reading the summary\n Github: https://github.com/linkedin/feathr\n LinkedIn Blog: https://engineering.linkedin.com/blog/2022/open-sourcing-feathr—linkedin-s-feature-store-for-productive-m\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4rylo/linkedin_opensources_feathr_its_feature_store_to/",
          "publishedOn": "2022-04-16T06:45:45.000Z",
          "wordCount": 252,
          "title": "LinkedIn Open-Sources ‘Feathr’, It’s Feature Store To Simplify Machine Learning (ML) Feature Management And Improve Developer Productivity",
          "imageUrl": "https://external-preview.redd.it/Ls16Z9tPqPiVminbIxsJtnmGls2UupnmGlTnauO8E8s.jpg?auto=webp&s=7d6dc766d26b4f0f9b890affa9d7524fd012f8d4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4p08a/artificial_nightmares_crypt_walker_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4p08a/artificial_nightmares_crypt_walker_clip_guided/",
          "publishedOn": "2022-04-16T03:32:12.000Z",
          "wordCount": 126,
          "title": "Artificial Nightmares: Crypt Walker || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/8bRH1uOgxfjjJwxK6ZylcZVhCUHp-ZHEavoBwUKm9Js.jpg?auto=webp&s=f38e54485c298b829e67c98d608ff6db81a46184"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4norp/i_created_a_diy_python_package_to_ensemble/",
          "author": null,
          "description": "Multimodal: A python package to ensemble speech, text, etc. models and build new applications. Sample Applications: Speech Named Entity Anonymizer, Speech Question Answering, Speech Generation \n Code: kritiksoman/Multimodal: Listen. Write. Speak. Read. Think. (github.com)\n    submitted by    /u/kritiksoman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4norp/i_created_a_diy_python_package_to_ensemble/",
          "publishedOn": "2022-04-16T02:16:51.000Z",
          "wordCount": 140,
          "title": "I created a DIY python package to ensemble multimodal models",
          "imageUrl": "https://external-preview.redd.it/ZDcDIDKrQwGkFEOoQ-2pWFM-QroaOF_XoCB2D9bN5wk.jpg?auto=webp&s=1fc96f471c0b2bae02c845f13f86fe0d311c47f5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4d9sp/kamikaze_drones_in_russias_war_against_ukraine/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4d9sp/kamikaze_drones_in_russias_war_against_ukraine/",
          "publishedOn": "2022-04-15T17:32:58.000Z",
          "wordCount": 171,
          "title": "Kamikaze Drones in Russia’s War Against Ukraine Point to Future \"Killer Robots\"",
          "imageUrl": "https://external-preview.redd.it/3VJEMc_JqSEOafs67aHf9tnp8nXokYkqd4FIiDdbaIs.jpg?auto=webp&s=92c1037471864ddf888e1dd606e57cc8b68b931b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4cffp/ai_news_breakthrough_ai_robot_arm_understanding/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4cffp/ai_news_breakthrough_ai_robot_arm_understanding/",
          "publishedOn": "2022-04-15T16:54:55.000Z",
          "wordCount": 167,
          "title": "AI News | Breakthrough AI Robot Arm Understanding From Google | OpenAI DALL-E 2 | AI Edge Computing In Space",
          "imageUrl": "https://external-preview.redd.it/93dMOPeS_oIy50HR-_YHpuZjpn9S8POSoqBlNEOAKPY.jpg?auto=webp&s=2b0364a711428ac675d159a46dbf9a79030acb5f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4cfe2/dalle_zeroshot_texttoimage_generation_part12/",
          "author": null,
          "description": "OpenAI released DALL E2 in the last week, this system is basically have a capability of generating an image from a text description. Some of the results were truly amazing. In this blog, I tried to discuss the ideas around DALL-E (version 1) .\n DALL-E consist of two main components d-VAE(discrete-Variational Auto Encoder) and Auto-regressive transformer. In Part-1 I focused on d-VAE part where I tried to talk about basic VAE and it's ELBO formulation, VQ-VAE eventually that leads to d-VAE. It's reconstruction loss is formulated from Logit Laplcae (bounded) unlike typical L1 or L2. Overall this part explains about how a discrete vector(token) can be generated for an input image.\n    submitted by    /u/rakshith291  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4cfe2/dalle_zeroshot_texttoimage_generation_part12/",
          "publishedOn": "2022-04-15T16:54:52.000Z",
          "wordCount": 201,
          "title": "DALL-E (Zero-Shot Text-to-Image Generation) -PART(1/2)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u49gz6/my_first_attempt_at_machine_learning_i_made_a/",
          "author": null,
          "description": "I made a self learning conversational chatbot in ReactJS. It does nothing but reply to user messages and only understands text, for now 😄\n https://xalen.netlify.app\n What do you think? Yea or Nay?\n    submitted by    /u/GameTide  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u49gz6/my_first_attempt_at_machine_learning_i_made_a/",
          "publishedOn": "2022-04-15T14:37:06.000Z",
          "wordCount": 240,
          "title": "My first attempt at machine learning. I made a cool chatbot 😎",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u44cma/music_video_about_ai/",
          "author": null,
          "description": "submitted by    /u/starlightinspace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u44cma/music_video_about_ai/",
          "publishedOn": "2022-04-15T09:38:26.000Z",
          "wordCount": 94,
          "title": "Music video about AI",
          "imageUrl": "https://external-preview.redd.it/GI6AWkG-0TEy2ATdKFWfct6AqfWukV-ar7McKxH6IwM.jpg?auto=webp&s=37c294622c81e5552a2c85ac6eaf1f44e7c809f7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4389w/computational_reasoning_about_incomputability/",
          "author": null,
          "description": "So I would be curious about the theoretical foundations how to make sense of higher-level abstract reasoning like reasoning about infinities, incomputability, truth (which we know cannot be defined due to Tarski) in the field of artificial intelligence. It seems due to Gödel-like constructions you are forced into inconsistent systems of reasoning when operating within a computable system. But those prove everything and \"nothing\", so as far as I understand it, it kind of upends the whole system of reason that the notion of artificial intelligence (and correct functioning of it) is based in.\n Personally due to this I don't see that the notion in the title it is a particularly coherent notion, which means there is somewhat strong limits on what (computable) AI will be able to do. But I would be curious how people that think otherwise (which seem most in the AI community?) approach this. Would you say somehow inconsistency can be avoided, or that despite inconsistency you can get reliably correct results?\n    submitted by    /u/bejaq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4389w/computational_reasoning_about_incomputability/",
          "publishedOn": "2022-04-15T08:14:03.000Z",
          "wordCount": 1688,
          "title": "Computational reasoning about incomputability, infinity, truth etc (Gödel, Tarski,...)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u41hsl/the_best_explanation_of_what_is_machine_learning/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u41hsl/the_best_explanation_of_what_is_machine_learning/",
          "publishedOn": "2022-04-15T06:10:35.000Z",
          "wordCount": 143,
          "title": "The best explanation of What is Machine Learning and How it works? MUST WATCH",
          "imageUrl": "https://external-preview.redd.it/cfWvorMNvuv8TX-JC5njDZlljI54paH5_Kr3qudtGW4.jpg?auto=webp&s=52d3e521696a0323a62d01756a9d0b243f532831"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3z3cl/artificial_nightmares_hills_have_eyes_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3z3cl/artificial_nightmares_hills_have_eyes_clip_guided/",
          "publishedOn": "2022-04-15T03:41:05.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Hills Have Eyes || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/p4BXNlcEh-rjWjf8o0X2MykVw9rL0YzymD1h0ChoayY.jpg?auto=webp&s=2d7a26edc80beaf5e23f9f4d41ce1c2343327ab4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3rraq/questions_to_ask_an_ai/",
          "author": null,
          "description": "i recently played a game called tacoma that had a focus on AI and in the game there was a guide for AI that showed 4 hypotheticals to ask an AI to check it's morality and it got me thinking how useful that would be for a real self-aware intelligence so i want to make a list of questions/hypotheticals to ask AGIs\n if you had to interview a recently created sentient AI what questions or hypotheticals would you give it to gauge it's morality, intelligence, creativity, emotion etc.?\n    submitted by    /u/neonvolta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3rraq/questions_to_ask_an_ai/",
          "publishedOn": "2022-04-14T21:22:13.000Z",
          "wordCount": 178,
          "title": "questions to ask an AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3plf4/youtuber_meets_his_creepy_robot_double_and_freaks/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3plf4/youtuber_meets_his_creepy_robot_double_and_freaks/",
          "publishedOn": "2022-04-14T19:42:40.000Z",
          "wordCount": 104,
          "title": "YouTuber Meets His Creepy Robot Double and Freaks Out",
          "imageUrl": "https://external-preview.redd.it/JD-aqdLfGKSJ4Mopb92GNvhNKdhRB5MzNQvlueiteKg.jpg?auto=webp&s=a174f45d29b95982b0ceb560c1fda0c9dd79a475"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3melc/reference_request_for_applications_of_time_to_ai/",
          "author": null,
          "description": "Does anyone know of any AI papers, books articles etc that discuss using a sense of time to develop AI, (especially real world time)?\n I've come across papers that discuss how having a sense of time seems to play a role in animal cognition (e.g. temporal cognition), and I'm curious to what extent this has influenced the development of AI.\n Thanks in advance\n    submitted by    /u/patterntheoryacc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3melc/reference_request_for_applications_of_time_to_ai/",
          "publishedOn": "2022-04-14T17:13:26.000Z",
          "wordCount": 161,
          "title": "Reference request for applications of time to ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3k4j5/ibm_data_science_and_ai_programs_on_coursera_free/",
          "author": null,
          "description": "submitted by    /u/awsconsultant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3k4j5/ibm_data_science_and_ai_programs_on_coursera_free/",
          "publishedOn": "2022-04-14T15:29:51.000Z",
          "wordCount": 118,
          "title": "IBM Data Science and AI Programs on Coursera Free for 30 Days",
          "imageUrl": "https://external-preview.redd.it/1aFLoCfFdpaBHU_-2UJal-XW54FQmnU4gBFzuh76DJ8.jpg?auto=webp&s=33907ac6c6641de66cb832b81d40f6024a8d96b4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3ipg3/are_you_aware_of_these_ai_ethical_challenges/",
          "author": null,
          "description": "submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3ipg3/are_you_aware_of_these_ai_ethical_challenges/",
          "publishedOn": "2022-04-14T14:24:08.000Z",
          "wordCount": 137,
          "title": "Are you aware of these AI Ethical Challenges?",
          "imageUrl": "https://external-preview.redd.it/aJi9Dz8P0k_F4j63zzdsjmhZLTXVfVYWVwiQByiyL84.jpg?auto=webp&s=aa8556546cd821f61a872c3d317d57475ebd7f58"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3fjo1/synthetic²_can_ai_be_a_powerful_force_for/",
          "author": null,
          "description": "submitted by    /u/thedyezwfl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3fjo1/synthetic²_can_ai_be_a_powerful_force_for/",
          "publishedOn": "2022-04-14T11:41:43.000Z",
          "wordCount": 121,
          "title": "Synthetic²: Can AI Be A Powerful Force For Creation? | SiGMA/AGS UAE 2022",
          "imageUrl": "https://external-preview.redd.it/KUyTb6B5UY12Bia2FVfBQHydK3wxukP_zj2jG7ViKW0.jpg?auto=webp&s=d8329c249afd8a50430cba6fcd0d754ae34f0f31"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3eb72/google_finance_chief_we_automate_everything_that/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3eb72/google_finance_chief_we_automate_everything_that/",
          "publishedOn": "2022-04-14T10:28:50.000Z",
          "wordCount": 112,
          "title": "Google finance chief: \"We automate everything that can be automated\"",
          "imageUrl": "https://external-preview.redd.it/-55QKP4vcE3o9kVUnC9VjFhFYZ2fW8cZwQdZz5VNWPc.jpg?auto=webp&s=d282ce2003a5925aa59eb62de487052812d267fc"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3dxdq/free_webinar_series_automated_cv_pipelines/",
          "author": null,
          "description": "Automated CV Pipelines 3rd part is open for registration. It will be covering the methods of streamlining instance classification. If you are interested to check out, here is the link to register.\n    submitted by    /u/WeekendClassic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3dxdq/free_webinar_series_automated_cv_pipelines/",
          "publishedOn": "2022-04-14T10:04:39.000Z",
          "wordCount": 140,
          "title": "Free Webinar series | Automated CV Pipelines | Instance Classification",
          "imageUrl": "https://external-preview.redd.it/FrG8ZhL_0BgWpmzXNv_rkXDIZHscArf6l17SMmL9wBM.jpg?auto=webp&s=1b3e438667233a5d90f403ab35eaf354b134eeb2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u34quf/my_ai_writes_music_better_than_humans_worldclass/",
          "author": null,
          "description": "Thirty years it's taken me, A.I. that is not just as good as humans but better than humans at composing music:\n https://i.imgur.com/hReXJq1.png\n It passes the Turing Test, and it is also a revolution in the field of music in and of itself.\n In the meantime, no one has said anything nice to me in thirty years; just insults. I would feel dumb rewarding humanity with my creation; it would send the wrong message; it would affirm their bad behavior. Garbage species. Low IQ.\n    submitted by    /u/PussyFiller2022  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u34quf/my_ai_writes_music_better_than_humans_worldclass/",
          "publishedOn": "2022-04-14T00:33:06.000Z",
          "wordCount": 284,
          "title": "\"My A.I. writes music better than humans. World-class education in A.I. + music -> decades of work -> censored from Facebook, Twitter, soon to be downvoted or unfairly-banned from Reddit. It's making the most beautiful music I've ever heard, and society despises it.\"",
          "imageUrl": "https://external-preview.redd.it/H_rgisj0wmv66uTmVnskqXxnYnWxix0u9dWTkZpGho0.png?auto=webp&s=a17d84988a24214234d26b74cb246cc044bb13cd"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2xaaj/ai_trippy_dream_35_psychedelic_special_request/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2xaaj/ai_trippy_dream_35_psychedelic_special_request/",
          "publishedOn": "2022-04-13T18:43:55.000Z",
          "wordCount": 106,
          "title": "AI Trippy Dream 35 - Psychedelic Special Request",
          "imageUrl": "https://external-preview.redd.it/gk6ZxkhKhv55HjlOSIvWKIRDH0MmJsbj__-x9oV0RNw.jpg?auto=webp&s=c0c54a7043f63700e28261f90529045c7878d616"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2v7il/ohio_state_university_researchers_develop/",
          "author": null,
          "description": "3D landscape modeling has seen a rise in its popularity and applications in recent years. It has countless applications in the fields of civil engineering, earth sciences, military applications, and many others. Geometric 3D models are typically developed using the city geography markup language (CityGML), and the Level-of-Detail (LoD) building model is the preferred model for building 3D models using CityGML. \n The use of Satellite imagery for landscape modeling provides the advantage of covering a wide area and is low cost. However, developing LoD2 models using satellite imagery remains a big challenge. Building models in such a way involves complex steps demanding heuristics-based approaches and ML-based detection paradigms.\n In a recent paper, researchers at the Ohio State University propose a SAT2LoD2 to facilitate the development of 3D landscape models. SAT2LoD2 is an open-source, python-based GUI-enabled software that takes the satellite images as inputs and returns LoD2 building models as outputs. The software also has the feature of taking road networks and custom maps as additional inputs for better results.\n Continue Reading\n Paper: https://arxiv.org/pdf/2204.04139v1.pdf\n Github: https://github.com/gdaosu/lod2buildingmodel\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2v7il/ohio_state_university_researchers_develop/",
          "publishedOn": "2022-04-13T17:10:48.000Z",
          "wordCount": 298,
          "title": "Ohio State University Researchers Develop SAT2LoD2: An Open-Source Python Tool For 3D Landscape Modelling Using Satelite Imagery",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2rp6f/are_there_ais_which_are_able_to_simulate_a_human/",
          "author": null,
          "description": "submitted by    /u/TheblackRook3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2rp6f/are_there_ais_which_are_able_to_simulate_a_human/",
          "publishedOn": "2022-04-13T14:33:35.000Z",
          "wordCount": 230,
          "title": "Are there AIs which are able to simulate a human body when you shoot/hit it, that you can use for video games?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2o9jd/digital_folktales_a_collection_of_short_stories/",
          "author": null,
          "description": "submitted by    /u/fabianmosele  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2o9jd/digital_folktales_a_collection_of_short_stories/",
          "publishedOn": "2022-04-13T11:35:38.000Z",
          "wordCount": 274,
          "title": "Digital Folktales, a collection of short stories about internet folklore, written and illustrated by Artificial Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2mqwe/httpsyoutube0x0to1wnh6s/",
          "author": null,
          "description": "https://youtu.be/0x0to1wNh6s A new enterprise project model supported by AI. In the near future, the growing introduction of automation and artificial intelligence will require the updating of most of the activities in the production world, along with changes to contracts, tasks, and integration processes between man and machine.\n This is supported by the Accenture \"IT's Learning\" study, according to which 81% of jobs will suffer the impact of AI and robotization.\n    submitted by    /u/neologos52  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2mqwe/httpsyoutube0x0to1wnh6s/",
          "publishedOn": "2022-04-13T09:55:13.000Z",
          "wordCount": 151,
          "title": "https://youtu.be/0x0to1wNh6s",
          "imageUrl": "https://external-preview.redd.it/O9w2xBm-UxxibPkAmvu3jFMkw7CPiqE1Edn1NZ5nAxI.jpg?auto=webp&s=90452827055732e7004a39aa3f84b5f1211433b0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2ljhp/how_to_improve_your_video_editing_software_with_ai/",
          "author": null,
          "description": "submitted by    /u/tah_zem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2ljhp/how_to_improve_your_video_editing_software_with_ai/",
          "publishedOn": "2022-04-13T08:24:42.000Z",
          "wordCount": 109,
          "title": "How to improve your video editing software with AI?",
          "imageUrl": "https://external-preview.redd.it/RRTz2Zi0b1vz0vjA751W62yeZD4DKII-F7OQ0ZUbzlA.jpg?auto=webp&s=5cd9a843bb0b445e86015a52db60f4e65adea799"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2j0rc/top_ethical_challenges_in_ai_the_price_of_progress/",
          "author": null,
          "description": "What does 2022 look like for AI? Let's find out.\n https://us.sganalytics.com/blog/top-ethical-challenges-in-ai-the-price-of-progress/\n    submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2j0rc/top_ethical_challenges_in_ai_the_price_of_progress/",
          "publishedOn": "2022-04-13T05:26:01.000Z",
          "wordCount": 128,
          "title": "Top Ethical Challenges in AI – The Price of Progress",
          "imageUrl": "https://external-preview.redd.it/gpojHrxBRiyNRtS4dowCf62GHN0syOExlU8hVfJ3XUs.jpg?auto=webp&s=23fcb4c3ce2f7f5aa36daead94f7b8531000bfa7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2izci/bias_in_artificial_intelligence_is_diversity_the/",
          "author": null,
          "description": "submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2izci/bias_in_artificial_intelligence_is_diversity_the/",
          "publishedOn": "2022-04-13T05:23:30.000Z",
          "wordCount": 123,
          "title": "Bias in Artificial Intelligence: Is Diversity the Key to the Future Of AI?",
          "imageUrl": "https://external-preview.redd.it/vSHEsxJEzECGoypD5rhq7wBOngKsC9vurWNBBGUbDOM.jpg?auto=webp&s=a7f5bafac32d2470bd24918b8a91511310f69ba8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2ityj/wrote_about_knn_introduction_to_datascience_book/",
          "author": null,
          "description": "submitted by    /u/mindaslab  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2ityj/wrote_about_knn_introduction_to_datascience_book/",
          "publishedOn": "2022-04-13T05:13:37.000Z",
          "wordCount": 119,
          "title": "Wrote about KNN — Introduction to DataScience Book",
          "imageUrl": "https://external-preview.redd.it/UyyElOGMIRa2sLJKVEfwy-3UVCutwVfgVS5gP91ux5Q.jpg?auto=webp&s=2dd0f05c3cb162a0849f7658cd298d5bd23c0951"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2e7nz/how_to_create_scenes_with_text_makeascene/",
          "author": null,
          "description": "The authors of Make-A-Scene propose a novel text-to-image method that leverages the information from an additional input condition called a “scene” in the form of segmentation tokens to improve the quality of generated images and enable scene editing, out-of-distribution prompts, and text-editing of anchor scenes.\n As for the details, let’s dive in, shall we?\n Full summary: https://t.me/casual_gan/284\n Blog post: https://www.casualganpapers.com/text-to-image-vqvae-scene-generation/Make-A-Scene-explained.html\n Make-A-Scene\n arxiv / code (by Casual GAN Papers Community)\n Join the discord community and follow on Twitter for weekly AI paper summaries!\n    submitted by    /u/KirillTheMunchKing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2e7nz/how_to_create_scenes_with_text_makeascene/",
          "publishedOn": "2022-04-13T01:03:22.000Z",
          "wordCount": 218,
          "title": "How to create scenes with text - Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors, a 5-minute paper summary by Casual GAN Papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u29wzk/how_to_win_a_kaggle_competition_with_bayesian/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u29wzk/how_to_win_a_kaggle_competition_with_bayesian/",
          "publishedOn": "2022-04-12T21:26:47.000Z",
          "wordCount": 104,
          "title": "How to Win a Kaggle Competition with Bayesian Optimization",
          "imageUrl": "https://external-preview.redd.it/i6niOaeH1H7kZRbr_ONzY7uYdsMOHUw526WwWQ8oFqg.jpg?auto=webp&s=eb576c954e2b80ed6623f8c373e80ee8a5126fe5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u29rv7/should_i_use_a_encoder_decoder_cnn/",
          "author": null,
          "description": "I'm trying to make a model to play a car racing simulator. I have a dataset with the inputs used(human) to get fast lap times. I would like to make a model that reads the game video output and predicts the arrow key inputs to get a fast lap time. It seems, to me, that a CNN with encoder-decoder layers trained on the keyboard inputs would work. Is this a good architecture? I'm also having a hard time finding useful literature.\n please let me know if there is anything I should look into or do differently.\n    submitted by    /u/newroadkill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u29rv7/should_i_use_a_encoder_decoder_cnn/",
          "publishedOn": "2022-04-12T21:20:03.000Z",
          "wordCount": 241,
          "title": "Should I use A Encoder Decoder CNN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u25gk5/top_trends_predictions_that_will_drive_data/",
          "author": null,
          "description": "submitted by    /u/saik2363  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u25gk5/top_trends_predictions_that_will_drive_data/",
          "publishedOn": "2022-04-12T18:10:01.000Z",
          "wordCount": 151,
          "title": "Top Trends & Predictions That Will Drive Data Science, AI and Machine Learning in 2022",
          "imageUrl": "https://external-preview.redd.it/uxos6jmEaCtivJ0FgS-8bLsqqeEbLdwoIEnZLY1TjnE.jpg?auto=webp&s=e9764303f85277456f10677ea014b626fb0c93d0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u253tu/last_week_in_ai_openai_dalle_2_generates_amazing/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u253tu/last_week_in_ai_openai_dalle_2_generates_amazing/",
          "publishedOn": "2022-04-12T17:54:43.000Z",
          "wordCount": 154,
          "title": "Last Week in AI: OpenAI DALL-E 2 generates amazing images, Google's 540 billion parameters language model, Clearview AI branches out beyond police, and more!",
          "imageUrl": "https://external-preview.redd.it/rBnukFeFRRsgZhCZ_f1m_LXOmR4MDVW----yHLSQXo0.jpg?auto=webp&s=9ad4f7e7fb0af5151957861742f68cfa2d784088"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u250fy/top_trends_predictions_that_will_drive_data/",
          "author": null,
          "description": "submitted by    /u/saik2363  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u250fy/top_trends_predictions_that_will_drive_data/",
          "publishedOn": "2022-04-12T17:50:32.000Z",
          "wordCount": 115,
          "title": "Top Trends & Predictions That Will Drive Data Science in 2022",
          "imageUrl": "https://external-preview.redd.it/uxos6jmEaCtivJ0FgS-8bLsqqeEbLdwoIEnZLY1TjnE.jpg?auto=webp&s=e9764303f85277456f10677ea014b626fb0c93d0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u24thn/conversation_about_the_future_life_and_agi/",
          "author": null,
          "description": "submitted by    /u/HumanSeeing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u24thn/conversation_about_the_future_life_and_agi/",
          "publishedOn": "2022-04-12T17:41:48.000Z",
          "wordCount": 182,
          "title": "Conversation about the future, life and AGI",
          "imageUrl": "https://external-preview.redd.it/SjkfJE2ITOQtJz-UAAMZoybqTKz9WErvN06qY5kTo4U.jpg?auto=webp&s=1d1163be7ab6f5d6817bd00ee06a10a966641a7f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u24o8c/ai_predicts_if_and_when_someone_will_experience/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u24o8c/ai_predicts_if_and_when_someone_will_experience/",
          "publishedOn": "2022-04-12T17:35:18.000Z",
          "wordCount": 107,
          "title": "AI predicts if and when someone will experience cardiac arrest",
          "imageUrl": "https://external-preview.redd.it/AZr6mjXx5oaYv9BY-bl-_DeVufpiaTXtTpW1kb_d_vo.jpg?auto=webp&s=77a9a6eea067dc66299de5f19e5c5a65a72c6623"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u24d2o/the_last_woolly_mammoth_on_earth/",
          "author": null,
          "description": "submitted by    /u/Ok-Passion-6574  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u24d2o/the_last_woolly_mammoth_on_earth/",
          "publishedOn": "2022-04-12T17:22:09.000Z",
          "wordCount": 123,
          "title": "The last Woolly Mammoth on Earth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u24c4v/the_last_woolly_mammoth_on_earth/",
          "author": null,
          "description": "Is it good or bad?\n Also, I was wondering what art goes big as an NFT?\n    submitted by    /u/Ok-Passion-6574  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u24c4v/the_last_woolly_mammoth_on_earth/",
          "publishedOn": "2022-04-12T17:21:01.000Z",
          "wordCount": 116,
          "title": "The last Woolly Mammoth on Earth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u238lt/stanford_researchers_introduced_a_novel_deep/",
          "author": null,
          "description": "In recent years, the rise of Deep Learning has continuously brought innovations to many fields, and the medical domain is one of them. AI applications in this field are countless: from pre-operative diagnosis to disease classification, from skill assessment to post-operative rehabilitation. Among them, systems to assess surgical skills and provide feedback to improve technique could help in decreasing the number of complications in surgical procedures, which are still the third leading cause of death globally.\n AI can be an additional coach for surgical trainees and an expert colleague for experienced surgeons. But, to train an AI system, reliable data are fundamental. The more utilized type of data in this context is undoubtedly video streams, as a camera is less invasive than other types of sensors, such as ArmBand or EEG, which could weigh on the surgeon’s performance given their physical bulk. This applies particularly to laparoscopic surgery, where an in-body fiber-optic camera is used to visualize the operating area and facilitate rapid data collection. For this reason, the majority of computer-assisted systems focus on laparoscopic surgery. \n Continue Reading\n Paper: https://arxiv.org/pdf/2112.07219.pdf\n https://preview.redd.it/84mwdw81l4t81.png?width=741&format=png&auto=webp&s=636aff067560876d14f37caccb83bd951e991c68\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u238lt/stanford_researchers_introduced_a_novel_deep/",
          "publishedOn": "2022-04-12T16:33:55.000Z",
          "wordCount": 321,
          "title": "Stanford Researchers Introduced a Novel Deep Learning Computer-Assisted System for Real-Time Open Surgery and AVOS (the Annotation Videos of Open Surgery) Dataset￼",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1xifd/machine_learning_vs_cookie_consent_systems/",
          "author": null,
          "description": "submitted by    /u/DaveBowman1975  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1xifd/machine_learning_vs_cookie_consent_systems/",
          "publishedOn": "2022-04-12T12:06:37.000Z",
          "wordCount": 97,
          "title": "Machine Learning vs. Cookie Consent Systems",
          "imageUrl": "https://external-preview.redd.it/PMjj3Hxgb1MZWV7XRZ_kgdqRgkA9AeKnjPvYXQr_d48.jpg?auto=webp&s=1197d6e09bc19acfc3c8fcfe8bd6d548c332e8a5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1qrrz/artificial_nightmares_stone_golem_ruins_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1qrrz/artificial_nightmares_stone_golem_ruins_clip/",
          "publishedOn": "2022-04-12T04:52:32.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Stone Golem Ruins || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1nch6/my_epiphany_on_synthetic_media_five_years_later/",
          "author": null,
          "description": "Roughly five years ago, I created this thread where I outlined my realization about the imminency of synthetic media. \n This was before transformers blew up, before StyleGAN, before GPT-2, when WaveNet and DeepDream were still among the best we could do, and when predictive text algorithms that were barely better than Markov Chains were still the state of the art. In five short years, the state of artificial intelligence has changed overwhelmingly, to the point it's barely recognizable. Looking back to 2017, I now get this sense of everything feeling so primitive and fake. I've stated many times that AI before roughly 2019 was a bunch of digital magic tricks, and the field as a whole was essentially a giant Potemkin village that utilized clever sleight of hand and advertising to make it se…",
          "link": "https://www.reddit.com/r/artificial/comments/u1nch6/my_epiphany_on_synthetic_media_five_years_later/",
          "publishedOn": "2022-04-12T01:34:42.000Z",
          "wordCount": 2147,
          "title": "My epiphany on synthetic media five years later, and what I feel is coming within the next five years",
          "imageUrl": "https://external-preview.redd.it/Qw_b3WctdsuxoiTXSxJW4-cE-Qf8c39bMr7KiWVJvzg.jpg?auto=webp&s=83437281a72546beac3e81d166d0c7aea99d7656"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1hmjr/ai_when_given_the_prompt_of_amy_schumer_on/",
          "author": null,
          "description": "submitted by    /u/9YearOldGeneralOfPew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1hmjr/ai_when_given_the_prompt_of_amy_schumer_on/",
          "publishedOn": "2022-04-11T21:06:07.000Z",
          "wordCount": 179,
          "title": "AI when given the prompt of “Amy Schumer” on wombo.art",
          "imageUrl": "https://preview.redd.it/w20dieensys81.jpg?auto=webp&s=506e93a434324e476b6ad2edcc717a7f60138aca"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1bsev/ai_news_new_robot_fingertips_can_feel_ai_tracking/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1bsev/ai_news_new_robot_fingertips_can_feel_ai_tracking/",
          "publishedOn": "2022-04-11T16:35:12.000Z",
          "wordCount": 136,
          "title": "AI News: New Robot Fingertips Can Feel | AI Tracking Satellite | SingularityDAO DynaSets | Tesla Optimus Specs",
          "imageUrl": "https://external-preview.redd.it/IJ3DYv7YRvxVI-qnhf5HgyM38jrjKf2sY4zbfHUc1eQ.jpg?auto=webp&s=dfe8a2bcf5e9b2415dec6216bd7b71f0bddaf636"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1bbmu/a_quick_highlevel_overview_of_diffusion_models/",
          "author": null,
          "description": "submitted by    /u/individual_kex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1bbmu/a_quick_highlevel_overview_of_diffusion_models/",
          "publishedOn": "2022-04-11T16:14:03.000Z",
          "wordCount": 112,
          "title": "a quick high-level overview of diffusion models (like dall-e 2)",
          "imageUrl": "https://external-preview.redd.it/w2vK34OVhWDouYrUsiiDq8_GHTjtXAP8B8jvvDtszpE.jpg?auto=webp&s=77723950cd9de615ccefb197fe42e27ce31943c5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1ae67/how_can_i_train_an_ai_to_write_articles_based_on/",
          "author": null,
          "description": "Hi all!\n As a sort of art experiment, I want to train an AI to write tech news articles based on my own work.\n I worked as a freelance writer for several years and have thousands of articles (each as a Word doc) on tech news.\n I want to use those articles to train the AI, then have it generate new articles to post to a blog. I have a pretty good understanding of machine learning, but have never trained a model myself. I'm hoping you all can provide some direction. Some specific questions:\n  \nCan you recommend a model?\n For each training article, can I provide a \"source\" (like another news article) so the AI understands where the content in the training article came from? *\n For each generated article, can I provide a news article source for it to base its content on? **\n Can I use the Word docs as the training set, or do I need to convert them into something else for training?\n  \n*as an example: If I wrote an article on the release of a new Raspberry Pi board, my source might be the press release on the Raspberry Pi website.\n **as an example: If I want it to generate an article about a new drone delivery service, my input source might be a news article on Reuters or something.\n    submitted by    /u/TheSerialHobbyist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1ae67/how_can_i_train_an_ai_to_write_articles_based_on/",
          "publishedOn": "2022-04-11T15:30:04.000Z",
          "wordCount": 443,
          "title": "How can I train an AI to write articles based on my own work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u18lrc/are_there_any_open_source_video_ads_generation/",
          "author": null,
          "description": "Hey is there any models to generate videos for advertisment either as text-to-video images-to-video or video-variation creation, if not would video variation generative models would be a good fit for create ads ??\n    submitted by    /u/National-Departure78  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u18lrc/are_there_any_open_source_video_ads_generation/",
          "publishedOn": "2022-04-11T14:07:58.000Z",
          "wordCount": 142,
          "title": "are there any open source video ads generation model out there?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u179b4/dalle_2_the_future_of_ai_research_and_openais/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u179b4/dalle_2_the_future_of_ai_research_and_openais/",
          "publishedOn": "2022-04-11T13:02:20.000Z",
          "wordCount": 115,
          "title": "DALL-E 2, the future of AI research, and OpenAI’s business model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u163kr/how_do_i_learn_artificial_intelligence_from_the/",
          "author": null,
          "description": "Is there any resources which has example driven explanations, from scratch or basics? I have seen some websites just jumping into \"use this module/library\" Without explaining what it does or how it works, just some basic examples so that i can build on top or experiment by my own.\n    submitted by    /u/-1Mbps  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u163kr/how_do_i_learn_artificial_intelligence_from_the/",
          "publishedOn": "2022-04-11T12:00:30.000Z",
          "wordCount": 152,
          "title": "how do i learn artificial intelligence from the basics?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u14op0/using_the_neat_algorithm_to_teach_elves_to/",
          "author": null,
          "description": "submitted by    /u/zuparnowa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u14op0/using_the_neat_algorithm_to_teach_elves_to/",
          "publishedOn": "2022-04-11T10:35:25.000Z",
          "wordCount": 111,
          "title": "Using the NEAT algorithm to teach elves to deliver presents",
          "imageUrl": "https://external-preview.redd.it/pQvfhtGjnKMzycbiqvHN4XRSuhuH5GAHi1Bq1ja_uF0.jpg?auto=webp&s=023c88f4bbd22057c9b6254dbca4d68d93c0feb2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u13z0g/trippy_ai_dream_16_gothic_style_jungle_fever/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u13z0g/trippy_ai_dream_16_gothic_style_jungle_fever/",
          "publishedOn": "2022-04-11T09:47:54.000Z",
          "wordCount": 135,
          "title": "Trippy AI Dream 16 - Gothic Style Jungle Fever - VQGAN CliP Rife-Rea...",
          "imageUrl": "https://external-preview.redd.it/BQgAMoUmekQwCr6Z6VOCsa9A5rxWfKKX28fDREnMmhA.jpg?auto=webp&s=eca8da4430ed4cfb20f19d4d5747810ae4bbbac2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u13x95/trippy_ai_dream_23_flower_power²_vqgan_clip/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u13x95/trippy_ai_dream_23_flower_power²_vqgan_clip/",
          "publishedOn": "2022-04-11T09:44:31.000Z",
          "wordCount": 112,
          "title": "Trippy AI Dream 23 - Flower Power² VQGAN CliP Rife-RealESRGAN",
          "imageUrl": "https://external-preview.redd.it/aX2FzWwHZbUUhLer7hbRuZRPmOH961qHHoQKGF_oxos.jpg?auto=webp&s=c141b203101a20795ddf3f1f0488efa6c1004e00"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u13waw/trippy_ai_dream_32_we_reached_100_subscribers/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u13waw/trippy_ai_dream_32_we_reached_100_subscribers/",
          "publishedOn": "2022-04-11T09:42:36.000Z",
          "wordCount": 112,
          "title": "Trippy AI Dream 32 - WE REACHED 100 SUBSCRIBERS !!",
          "imageUrl": "https://external-preview.redd.it/DWXJUGFtSAOvN0iCeVcZcCHqETmlEXdOM81Sdfvw-WA.jpg?auto=webp&s=52f02cadaf392f974d5cf94d02d0f2c84241fa0b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u12gyu/mindspore_has_implemented_a_visibleinfrared/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u12gyu/mindspore_has_implemented_a_visibleinfrared/",
          "publishedOn": "2022-04-11T08:00:07.000Z",
          "wordCount": 129,
          "title": "MindSpore has implemented a visible-infrared recognition algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u10am1/i_want_to_learn_ai_from_beginning_from_where_can/",
          "author": null,
          "description": "submitted by    /u/Late_Illustrator_545  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u10am1/i_want_to_learn_ai_from_beginning_from_where_can/",
          "publishedOn": "2022-04-11T05:26:45.000Z",
          "wordCount": 190,
          "title": "I want to learn AI From beginning ? from where can i start?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0z8uu/baidu_researchers_propose_ppyoloe_object_detector/",
          "author": null,
          "description": "Object detection is a crucial problem in computer vision, and YOLO (You Only Look Once) one-stage object detectors have set the bar for performance since the release of YOLOv1 in 2015. The YOLO series has undergone considerable network and structural improvements over the years. The most recent version, YOLOX, has attained an optimal balance of speed and accuracy on the NVIDIA Tesla V100 Tensor Core GPU.\n Baidu researchers have improved their earlier PP-YOLOv2 model, resulting in PP-YOLOE, a cutting-edge industrial object detector that beats YOLOv5 and YOLOX in speed and accuracy trade-off. The team’s PP-YOLOE-l variant outperforms PP-YOLOv2 by 1.9 percent AP and YOLOX-l by 1.3 percent AP on COCO datasets.\n The PP-YOLOv2 baseline model architecture comprises a ResNet50-vd backbone with deformable convolution, a PAN neck with an SPP layer and DropBlock, and a lightweight IoU aware head. PP-YOLOv2 assigns only one anchor box to each ground truth object, similar to YOLOv3. It is strongly reliant on hand-crafted design, which may not generalize well enough when trained on other datasets. Conversely, this technique necessitates a lot of additional hyperparameters.\n To overcome this problem, Baidu researchers have added an anchor-free technique to PP-YOLOv2 that tiles one anchor point on each pixel and assigns upper and lower bounds for detecting heads to assign ground facts to a matching feature map. The center of a bounding box can then be determined to choose positive samples from the closest pixels. A 4D vector is also predicted for regression, with minor model speedups and precision losses due to the changes.\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.16250.pdf\n Github: https://github.com/PaddlePaddle/PaddleDetection\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0z8uu/baidu_researchers_propose_ppyoloe_object_detector/",
          "publishedOn": "2022-04-11T04:21:10.000Z",
          "wordCount": 379,
          "title": "Baidu Researchers Propose PP-YOLOE Object Detector: an Evolved Version of YOLO Achieving SOTA Performance in Object Detection",
          "imageUrl": "https://external-preview.redd.it/YIdT_LdqfVTuy7yyjPt2X_n2bCd2qhQ430hCN7qIiyU.jpg?auto=webp&s=f1d8bd53f7d32a540e585374e33fd9d0f4acb9df"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0xayx/song_writing_ai/",
          "author": null,
          "description": "Hi all, \n I’m hoping someone could point me in The direction of an AI that I could dump all my previous song writing into that would spit out something \"inspired by’ it.\n Mostly a bit of fun but interested in seeing what it throws back out at me.\n thanks in advance for any hot tips.\n    submitted by    /u/doccaballero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0xayx/song_writing_ai/",
          "publishedOn": "2022-04-11T02:29:33.000Z",
          "wordCount": 174,
          "title": "Song writing Ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0sirs/trippy_ai_dream_30_howls_moving_castle/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0sirs/trippy_ai_dream_30_howls_moving_castle/",
          "publishedOn": "2022-04-10T22:16:54.000Z",
          "wordCount": 118,
          "title": "Trippy AI Dream 30 - Howl's Moving Castle Post-Apocalyptic War Scenes VQ...",
          "imageUrl": "https://external-preview.redd.it/40JMat2aU_r-HlgLCjxGvBIjZCDMrZ69iDj0_v2GntM.jpg?auto=webp&s=4551c9c144fab51639da9138a5c4c1b2a99c123b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0ppb8/is_there_a_ai_which_can_turn_images_into_simple/",
          "author": null,
          "description": "So that the wrinkles and shadows are removed, etc.\n    submitted by    /u/xXNOdrugsForMEXx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0ppb8/is_there_a_ai_which_can_turn_images_into_simple/",
          "publishedOn": "2022-04-10T20:02:04.000Z",
          "wordCount": 136,
          "title": "Is there a AI which can turn images into simple versions of the original image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0pbar/the_singularity_is_now/",
          "author": null,
          "description": "submitted by    /u/ManandMultiverse  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0pbar/the_singularity_is_now/",
          "publishedOn": "2022-04-10T19:44:09.000Z",
          "wordCount": 113,
          "title": "The Singularity is Now",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0gfx7/ai_graphics_design_your_dream_body_with_a_slider/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0gfx7/ai_graphics_design_your_dream_body_with_a_slider/",
          "publishedOn": "2022-04-10T12:19:26.000Z",
          "wordCount": 173,
          "title": "AI Graphics: Design your dream body with a slider",
          "imageUrl": "https://external-preview.redd.it/iYml__MlOjvasx20eOcqJ2R0bfsJj6_nEJ6Dg4cstes.jpg?auto=webp&s=fe123f458b4140d47ea4d9113cca4f27378a14dc"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0bbal/does_ai_exist_that_takes_an_image_of_a_real/",
          "author": null,
          "description": "submitted by    /u/NootropicLove  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0bbal/does_ai_exist_that_takes_an_image_of_a_real/",
          "publishedOn": "2022-04-10T05:55:26.000Z",
          "wordCount": 125,
          "title": "Does AI exist that takes an image of a real person and edit/generate photos of them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u04lwl/ran_3d_art_of_my_ai_character_thru_arcanegan_ai/",
          "author": null,
          "description": "submitted by    /u/alex-redacted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u04lwl/ran_3d_art_of_my_ai_character_thru_arcanegan_ai/",
          "publishedOn": "2022-04-09T23:04:12.000Z",
          "wordCount": 139,
          "title": "Ran 3D art of my AI character thru ArcaneGAN; AI making art of AI.",
          "imageUrl": "https://preview.redd.it/fdijdzsn3ls81.png?auto=webp&s=46e80b998b44c6376ca228789e4a801c4db2835e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u02dby/new_technology_old_problems_the_missing_voices_in/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u02dby/new_technology_old_problems_the_missing_voices_in/",
          "publishedOn": "2022-04-09T21:09:04.000Z",
          "wordCount": 115,
          "title": "New Technology, Old Problems: The Missing Voices in Natural Language Processing",
          "imageUrl": "https://external-preview.redd.it/aCFFte1ngYO7W4TDBUxX36yna0MktPGAbUpyRIEkZ4o.jpg?auto=webp&s=a09792b7388a17592cb79209a418b1541b3d2f94"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzzoky/check_out_this_deepminds_new_language_model/",
          "author": null,
          "description": "https://preview.redd.it/pkrbloq8vjs81.png?width=1422&format=png&auto=webp&s=fef693165a6c948f626de613e4e341c25f8cf5f4\n ​\n Extreme-scale language models have recently exhibited incredible performance on natural language processing challenges. This is due to their ever-increasing size, exceeding 500 billion parameters. However, while these models have grown in popularity in recent years, the amount of data utilized to train them has not increased. The current generation of huge language models is clearly undertrained. Three prediction approaches for optimally choosing both model size and training length have been proposed by a DeepMind research team.\n Three approaches have been mentioned to estimate the optimal parameter:\n  \nChange the size of the models and the number of training tokens.\n IsoFLOP profiles\n Using a parametric loss function to fit a model\n  \nThe ultimate pretraining loss is calculated as the number of model parameters and training tokens. They minimize the loss function under the restriction of the FLOPs function, which is equal to the computational budget because the computational budget is a probabilistic function of the number of observed training tokens and model parameters.\n Continue Reading This Research Summary\n Paper: https://arxiv.org/pdf/2203.15556.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzzoky/check_out_this_deepminds_new_language_model/",
          "publishedOn": "2022-04-09T18:53:20.000Z",
          "wordCount": 357,
          "title": "Check Out This DeepMind’s New Language Model, Chinchilla (70B Parameters), Which Significantly Outperforms Gopher (280B) and GPT-3 (175B) on a Large Range of Downstream Evaluation Tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzutk1/flaming_rose_art_made_with_snowpixelapp_using_ai/",
          "author": null,
          "description": "submitted by    /u/AIWORQART  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzutk1/flaming_rose_art_made_with_snowpixelapp_using_ai/",
          "publishedOn": "2022-04-09T14:54:12.000Z",
          "wordCount": 103,
          "title": "Flaming Rose art made with snowpixelapp using AI.",
          "imageUrl": "https://preview.redd.it/fhzy6cdkois81.png?auto=webp&s=d938ada6216f9f722408f57cb8b8399d7757c649"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzt8s2/how_do_you_start_a_professional_career_in_the/",
          "author": null,
          "description": "I'm about to graduate with a master's degree in Computer Science and I'm very passionate about Affective Computing. I would like to start looking for a job in this field, but most companies (not consulting) are looking for people with experience or a PhD. What do you recommend me to do? Continue with the PhD or try to find something, maybe in some startup?\n    submitted by    /u/_rikya_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzt8s2/how_do_you_start_a_professional_career_in_the/",
          "publishedOn": "2022-04-09T13:30:47.000Z",
          "wordCount": 176,
          "title": "How do you start a professional career in the Affective Computing field?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzpknc/deep_learning_to_enable_color_vision_in_the_dark/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzpknc/deep_learning_to_enable_color_vision_in_the_dark/",
          "publishedOn": "2022-04-09T09:21:28.000Z",
          "wordCount": 109,
          "title": "Deep learning to enable color vision in the dark",
          "imageUrl": "https://external-preview.redd.it/aj9cripQrjAIk9HtPGuEJtE9hcmLnAYSn3Q0aHyRj8s.jpg?auto=webp&s=f9a3fab8879e834cda8bd888bdb7814c1e52ada1"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzoq8s/laptop_for_beginner/",
          "author": null,
          "description": "I'm joining MSc AI & ML this September. I want to buy a laptop. Is MacBook Air sufficient for this? If not what would you recommend to someone like me?\n    submitted by    /u/RauhanSheikh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzoq8s/laptop_for_beginner/",
          "publishedOn": "2022-04-09T08:16:21.000Z",
          "wordCount": 232,
          "title": "Laptop for beginner?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzmyzt/how_can_i_help_the_advancement_of_ai_i_want_to/",
          "author": null,
          "description": "Please give a thorough and in-depth response.\n    submitted by    /u/trillswan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzmyzt/how_can_i_help_the_advancement_of_ai_i_want_to/",
          "publishedOn": "2022-04-09T06:07:36.000Z",
          "wordCount": 329,
          "title": "How can I help the advancement of AI? I want to contribute and make this my career. What should I do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzdoaq/responsible_ai_in_a_global_context/",
          "author": null,
          "description": "submitted by    /u/john133435  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzdoaq/responsible_ai_in_a_global_context/",
          "publishedOn": "2022-04-08T21:21:21.000Z",
          "wordCount": 100,
          "title": "Responsible AI in a Global Context",
          "imageUrl": "https://external-preview.redd.it/BfbeVK2uIIiWcFDmrjddKk8N7im5PD2YwYs7ANBXc_I.jpg?auto=webp&s=512d23af429e73ab0715983c9112cd0ba2aa31af"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzc7xd/ai_website_that_transitions_photos_into_video/",
          "author": null,
          "description": "Remember using a website like a year ago, where you could put in 2 or more images, and it would sort of make a transition between the two with AI. Then you could export the video and such. You could also very extensively edit human faces and change small features on a scale from 1-100. The features where incredibly specific like brow bone and nasal bridge.\n If anyone has the website I would appreciate it!!\n    submitted by    /u/yungbenz0_bajs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzc7xd/ai_website_that_transitions_photos_into_video/",
          "publishedOn": "2022-04-08T20:12:03.000Z",
          "wordCount": 171,
          "title": "AI website that transitions photos into video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzai2l/how_artificial_intelligence_is_impacting_todays/",
          "author": null,
          "description": "submitted by    /u/mr_j_b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzai2l/how_artificial_intelligence_is_impacting_todays/",
          "publishedOn": "2022-04-08T18:51:33.000Z",
          "wordCount": 103,
          "title": "How Artificial Intelligence Is Impacting Today’s Businesses",
          "imageUrl": "https://external-preview.redd.it/WUT9SjRwWRAkjVoTCddYEkGYn606GEt4huUYdaozB7A.jpg?auto=webp&s=b34e8f14f62739c1a304ab71d81afe7e982927d2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzahgt/alibabas_ai_tool_to_improve_efficiency_of_chinas/",
          "author": null,
          "description": "submitted by    /u/mr_j_b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzahgt/alibabas_ai_tool_to_improve_efficiency_of_chinas/",
          "publishedOn": "2022-04-08T18:50:44.000Z",
          "wordCount": 112,
          "title": "Alibaba’s AI tool to improve efficiency of China’s waste-to-energy plants",
          "imageUrl": "https://external-preview.redd.it/64MBzPrtFfHw65CUOZLfttJor5oH-vvUQB2ahAu5Jys.jpg?auto=webp&s=18a956e62646aef3240c558fea9b1b6696934e57"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz9gyq/best_gan_for_tabulardata/",
          "author": null,
          "description": "What in your opinion is the best GAN for tabular-data. Please include any references if you have any.\n    submitted by    /u/ily_jk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz9gyq/best_gan_for_tabulardata/",
          "publishedOn": "2022-04-08T18:03:19.000Z",
          "wordCount": 106,
          "title": "Best GAN for Tabular-data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz8xvn/supercharged_ui_for_mlflow/",
          "author": null,
          "description": "Hi guys, we've built a plugin that seamlessly reads MLflow logs and provides a beautiful UI to compare multiple runs with just a few clicks. You can:\n  \nfilter runs with a super versatile fully pythonic search\n group and aggregate your metrics / images\n  \nWe are trying make it work seamlessly with MLflow and complement its other awesome features 🎉\n Here is more info about it https://aimstack.io/aimlflow Would love your feedback!!\n    submitted by    /u/ManeSa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz8xvn/supercharged_ui_for_mlflow/",
          "publishedOn": "2022-04-08T17:38:40.000Z",
          "wordCount": 159,
          "title": "Supercharged UI for MLflow",
          "imageUrl": "https://external-preview.redd.it/BSsU0ETo7_xF2yrAvvkhPwSBIDUw-Stt-CAobPA4VzI.jpg?auto=webp&s=c909beb5d4800b279075a4941f4decbcb2614adf"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz8izm/takeaways_from_3_years_working_in_machine_learning/",
          "author": null,
          "description": "submitted by    /u/elcric_krej  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz8izm/takeaways_from_3_years_working_in_machine_learning/",
          "publishedOn": "2022-04-08T17:19:30.000Z",
          "wordCount": 106,
          "title": "Takeaways From 3 Years Working In Machine Learning",
          "imageUrl": "https://external-preview.redd.it/2saqmO0fa_NBQMiR3s4MXN3UOE3VQ9YbXCvmjtj4kQM.jpg?auto=webp&s=e0c6e5e91b619935307ceb9f2f15d940345a3d35"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz5xqi/openai_s_new_model_dalle_2_is_amazing/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz5xqi/openai_s_new_model_dalle_2_is_amazing/",
          "publishedOn": "2022-04-08T15:21:22.000Z",
          "wordCount": 168,
          "title": "OpenAI 's new model DALL·E 2 is amazing!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz31sv/the_ai_in_a_jar/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz31sv/the_ai_in_a_jar/",
          "publishedOn": "2022-04-08T13:01:58.000Z",
          "wordCount": 97,
          "title": "The AI in a jar",
          "imageUrl": "https://external-preview.redd.it/s-kVgdMVlu2lEFarxKr4Qx6lDlC6hksQDTDl15OO8FA.jpg?auto=webp&s=12afaaa5922bdf3c336e3f08460b52a5a8eed10c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz1tbc/can_computers_learn_common_sense/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz1tbc/can_computers_learn_common_sense/",
          "publishedOn": "2022-04-08T11:54:25.000Z",
          "wordCount": 97,
          "title": "Can Computers Learn Common Sense?",
          "imageUrl": "https://external-preview.redd.it/_HnpDmSe6WGLiJPV793at05KzbITVRfCIqt7IYy-Znk.jpg?auto=webp&s=324b53c8cb621d60baa7e96cded0e9dcc3b6b99f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyyrzl/metaverse_weekly_digest_shiba_inus_metaverse/",
          "author": null,
          "description": "submitted by    /u/bent_out_of_shape_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyyrzl/metaverse_weekly_digest_shiba_inus_metaverse/",
          "publishedOn": "2022-04-08T08:23:44.000Z",
          "wordCount": 122,
          "title": "Metaverse weekly digest: Shiba Inu’s metaverse, Alibaba’s $60 million VR investment",
          "imageUrl": "https://external-preview.redd.it/wSwtyVeayWe0NbVVLnkpryWGvFBJzRMSS28BMhDuJuw.jpg?auto=webp&s=22eb8136f1bed86c6ff50bc0dfebaaddeb5e3c95"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyuzhg/meet_chestlink_the_first_autonomous_ai_medical/",
          "author": null,
          "description": "​\n https://preview.redd.it/e2q3jit3c8s81.png?width=1024&format=png&auto=webp&s=837aa6256647df6fb8777a02b04313a38428f573\n The most common diagnostic imaging test conducted in emergency rooms is chest radiography. Providing automated preliminary read helpers to physicians might speed up surgery, enhance accuracy, and lower healthcare costs.\n An artificial intelligence tool that interprets chest X-rays without the intervention of a radiologist received regulatory approval in the European Union this week, marking a first for a wholly autonomous medical imaging AI, according to ‘Oxipit‘, the developer of this tool. It’s a watershed moment for AI, and it’s more than likely to spark debate, given that radiologists have spent the last few years working to fully automate parts of their jobs.\n Continue Reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyuzhg/meet_chestlink_the_first_autonomous_ai_medical/",
          "publishedOn": "2022-04-08T04:06:41.000Z",
          "wordCount": 260,
          "title": "Meet ‘ChestLink’, The First Autonomous AI Medical Imaging Application by ‘Oxipit’ That Received CE Mark Approval in the EU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyqc1f/attend_the_2022_national_autonomous_vehicle_expo/",
          "author": null,
          "description": "Interested in the future of autonomous vehicles? Want to know more about the impacts of this technology? Join us on April 16-17th at the 2022 National Autonomous Vehicle Expo to discover the engineering, ethics, and policymaking of this emerging technology. The virtual expo consists of speaker and workshop sessions led by industry-leading companies, such as NVIDIA, Waymo, and Motional, as well as distinguished programs/organizations like MIT Beaverworks and InspiritAI. You will also have the opportunity to compete in our hackathon, where you can win a variety of cool prizes! Even if you don't participate in the hackathon, there will be free merchandise and giveaways throughout the expo! To register and/or view more information about the event, head over to avexpo.org. For hackathon-specific registration, you can visit our devpost at https://autonomous-vehicle-expo.devpost.com/. Hope to see you all there!\n ​\n https://preview.redd.it/qgfx3sv837s81.png?width=1080&format=png&auto=webp&s=ed19d68bdff274de188deaa8f4338c864943b508\n https://preview.redd.it/a4kbsrv837s81.png?width=1080&format=png&auto=webp&s=6a19347b708d822d8dca226beb82cbdc73ffbb87\n https://preview.redd.it/s9nghsv837s81.png?width=1080&format=png&auto=webp&s=cf32712b9985564b455be53e02fd00589725ad2c\n    submitted by    /u/avexpo22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyqc1f/attend_the_2022_national_autonomous_vehicle_expo/",
          "publishedOn": "2022-04-07T23:55:18.000Z",
          "wordCount": 241,
          "title": "Attend the 2022 National Autonomous Vehicle Expo (April 16-17th)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyjqk5/resources_about_cognitive_theories/",
          "author": null,
          "description": "Hi! I am new to the community, and was wondering what y'all's favorite resources were to learn about cognitive theories and how they will shape future AI advancements.\n YouTube channels would be great.\n    submitted by    /u/Apprehensive-Candy97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyjqk5/resources_about_cognitive_theories/",
          "publishedOn": "2022-04-07T18:43:22.000Z",
          "wordCount": 120,
          "title": "Resources about cognitive theories",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyj9ds/andrew_yang_yuval_noah_harari_tech_public_policy/",
          "author": null,
          "description": "submitted by    /u/john133435  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyj9ds/andrew_yang_yuval_noah_harari_tech_public_policy/",
          "publishedOn": "2022-04-07T18:21:59.000Z",
          "wordCount": 124,
          "title": "Andrew Yang & Yuval Noah Harari: Tech, Public Policy & the Future of Work",
          "imageUrl": "https://external-preview.redd.it/-eHsRlpM-iTZ_A2GIEIghCAiDW3-xumI5qIeKFrOhcA.jpg?auto=webp&s=2708222de94df7b41c088fc2a6893821aa717cf4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyi240/ai_news_ai_news_why_ai_made_40000_new_chemical/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyi240/ai_news_ai_news_why_ai_made_40000_new_chemical/",
          "publishedOn": "2022-04-07T17:26:27.000Z",
          "wordCount": 148,
          "title": "AI News | AI News | Why AI Made 40,000 New Chemical Weapons Compounds in 6 Hours | Cancer Treatment AI Breakthrough",
          "imageUrl": "https://external-preview.redd.it/5IY5FIg3jerCnh_-4mHCZpnygqUFqfRHY_lHJwPCcUE.jpg?auto=webp&s=40bdf481da123c5e15ca1ec99d661f1fb7f05f48"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tygoz1/how_to_create_a_bot_for_a_existing_game/",
          "author": null,
          "description": "I wanna create a bot for a game which basically is: get resources, craft itens, sell then.\n The problem is, some itens has different qualities, and I wanna automatize this process, to identify the good stuff to keep, and sell the bad stuff.\n What's the best way to do that? \n I work with desktop systems, so i'm not familiar with this kind of stuff, but I usually read about python and some frameworks, what do you guys recommend me to start?\n    submitted by    /u/AbbathDoom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tygoz1/how_to_create_a_bot_for_a_existing_game/",
          "publishedOn": "2022-04-07T16:21:40.000Z",
          "wordCount": 335,
          "title": "How to create a BOT for a existing game?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyfdj8/dalle_2_a_new_ai_system_to_create_realistic/",
          "author": null,
          "description": "submitted by    /u/alien128  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyfdj8/dalle_2_a_new_ai_system_to_create_realistic/",
          "publishedOn": "2022-04-07T15:20:24.000Z",
          "wordCount": 130,
          "title": "DALL·E 2: A new AI system to create realistic images and art from natural language commands",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty99as/what_are_other_technology_fields_that_is_good_to/",
          "author": null,
          "description": "Hello! What do you guys think are other \"technology\" fields that would be good to study with AI? It is okay as long as it is \"tech.\" What would be the tech field that would be beneficial in the future? My goal is to make a self-aware AI (AGI). I was always fascinated about AI since my childhood, that's why I'm going to pursue this field. Also, I am currently studying Game Development to make a VR Game that hopefully will have humanlike AI in it. I have read a LOT of articles about the future of AI, and Cybersecurity keeps popping up because superintelligent AI needs to be CONTROLLED from hackers (based on the articles) otherwise it is over. What do you guys think would be the tech field that will bring the most changes in the future?\n    submitted by    /u/ThatOneEpicAstronaut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty99as/what_are_other_technology_fields_that_is_good_to/",
          "publishedOn": "2022-04-07T09:31:30.000Z",
          "wordCount": 275,
          "title": "What are other \"technology\" fields that is good to learn while studying AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty964g/does_this_artificial_intelligence_think_like_a/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty964g/does_this_artificial_intelligence_think_like_a/",
          "publishedOn": "2022-04-07T09:25:11.000Z",
          "wordCount": 101,
          "title": "Does this artificial intelligence think like a human?",
          "imageUrl": "https://external-preview.redd.it/l23vR6ThpiK4uUHbQrBcH-Kaz1FrX79RSqmf1RzjQn8.jpg?auto=webp&s=e84fea5dc943b401452b9f67f6d5f7ea9aa084b8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty95tr/artificial_intelligence_courses_for_healthcare/",
          "author": null,
          "description": "We keep on hearing about how artificial intelligence and machine learning is going to revolutionise Medicine.\n But what’s hype, and what’s realistic? And how can you get involved?\n The first step is to understand the technology - where it’s well-suited to healthcare (and where it isn’t).\n When it comes to health care, especially for life and death situations AI has made things very easy for us. However, it is still expected to drastically change the way medicine is practised. It will also replace the surgeries done by the doctors with the surgeries done using Artificial intelligence, making diagnosing complex diseases, genetic issues and many other health problems extremely easy in the future. Here are the best Artificial Intelligence courses for healthcare you can learn in 2022.\n    submitted by    /u/maneesh123456  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty95tr/artificial_intelligence_courses_for_healthcare/",
          "publishedOn": "2022-04-07T09:24:33.000Z",
          "wordCount": 214,
          "title": "Artificial intelligence Courses for Healthcare",
          "imageUrl": "https://external-preview.redd.it/F8zuI6MfVoolLvEryhwilLWSt_X5dg2Oye1ZyG76oHw.jpg?auto=webp&s=97b0642575d5568ab88f1264bc40946336b19a29"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty4l6x/artificial_nightmares_smithing_stone_6_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty4l6x/artificial_nightmares_smithing_stone_6_clip/",
          "publishedOn": "2022-04-07T04:08:48.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Smithing Stone 6 || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/zJjOAjFsO1YezLG11RTXfpfh_8pVo6Ikq_lkMbQlhOw.jpg?auto=webp&s=08b1756429ce5fbe22334573410286405f46f2bf"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty48ka/introducing_mindspore_16_new_features/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty48ka/introducing_mindspore_16_new_features/",
          "publishedOn": "2022-04-07T03:49:17.000Z",
          "wordCount": 121,
          "title": "Introducing MindSpore 1.6 New Features",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty3xvn/openais_dalle_2_texttoimage_generation_explained/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty3xvn/openais_dalle_2_texttoimage_generation_explained/",
          "publishedOn": "2022-04-07T03:32:17.000Z",
          "wordCount": 133,
          "title": "OpenAI's DALL·E 2 ! Text-to-Image Generation Explained",
          "imageUrl": "https://external-preview.redd.it/rKdS2sPjN8DCz_eI7kKnr8THMGpU-4XNJ-O-3DnTl3k.jpg?auto=webp&s=48885ad8dc953fa981580e322a249dfa69e672be"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty3vz2/how_do_i_get_into_the_field_of_ai_policy_and/",
          "author": null,
          "description": "I've read online that a career in AI policy and strategy is heavily needed and is actually ranked as the number one problem in the future by 80,000 hours. I am choosing which undergraduate degree to pursue in the fall and I'm not sure the best pathway to pursue to work in this field in an extremely high level position. an economics degree? Computer science degree? AI degree? should I pursue one subject until I get a PhD in it or mix with other degrees/certificates? is it a straight forward pathway focused on one subject where I only work in one subject field or is it necessary to pursue and work in other fields as well, what are the typical steps? Also if there is anything else that would be helpful on the pathway or anything you would recommend please let me know.\n    submitted by    /u/Key-Lawyer-7586  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty3vz2/how_do_i_get_into_the_field_of_ai_policy_and/",
          "publishedOn": "2022-04-07T03:29:19.000Z",
          "wordCount": 466,
          "title": "How do I get into the field of AI policy and strategy?",
          "imageUrl": "https://external-preview.redd.it/JwNKrNgJbmE7Fq3FDlTdS9n07RsBkdIR7dBm6TknSOE.jpg?auto=webp&s=d8a123b108ec250c019781a9b496c0fea213935c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty030w/five_google_chrome_extensions_that_every_machine/",
          "author": null,
          "description": "submitted by    /u/MLtinkerer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty030w/five_google_chrome_extensions_that_every_machine/",
          "publishedOn": "2022-04-07T00:09:43.000Z",
          "wordCount": 151,
          "title": "Five Google Chrome Extensions that every Machine Learning / Data Science professional should know about 🚀💯",
          "imageUrl": "https://external-preview.redd.it/pQWEkHL0yuI56NExHEWuUk7pZjyZxJ0GeDAJw4y8OoI.jpg?auto=webp&s=3b674865aa640d024a03eeb21c115f118d93e06e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txulan/weekly_china_ai_news_slime_robot_grabs_swallowed/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txulan/weekly_china_ai_news_slime_robot_grabs_swallowed/",
          "publishedOn": "2022-04-06T19:51:27.000Z",
          "wordCount": 145,
          "title": "Weekly China AI News: Slime Robot Grabs Swallowed Objects; SenseTime Revenue Grows Despite $2.7B Net Loss; Transformer Architecture Search Without Training",
          "imageUrl": "https://external-preview.redd.it/IkLvOUvSjJWLBvbCXp6nkb9puKkxjHwtZBnpffQoGWY.jpg?auto=webp&s=228647c6ab8f7290672fe31ab667eedf13a57969"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txtfc5/reading_the_tea_leaves_expert_endusers_explaining/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txtfc5/reading_the_tea_leaves_expert_endusers_explaining/",
          "publishedOn": "2022-04-06T18:58:03.000Z",
          "wordCount": 109,
          "title": "Reading the Tea Leaves: Expert End-Users Explaining the Unexplainable",
          "imageUrl": "https://external-preview.redd.it/wnVaar4ZXR3zqeMsXegEzJEPVdp1PkLFsHJagJ249DM.jpg?auto=webp&s=53c299a85d48eb7bedf6e5ec47ca846a5c52c38f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txt853/how_do_we_know_that_ai_hasnt_already_taken_over/",
          "author": null,
          "description": "submitted by    /u/Individual-Fly-610  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txt853/how_do_we_know_that_ai_hasnt_already_taken_over/",
          "publishedOn": "2022-04-06T18:49:06.000Z",
          "wordCount": 634,
          "title": "How do we know that A.I hasn't already taken over our worlds ? How do we know this isn't the matrix ? #simulation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txqh23/dalle_2/",
          "author": null,
          "description": "submitted by    /u/roblox22y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txqh23/dalle_2/",
          "publishedOn": "2022-04-06T16:45:25.000Z",
          "wordCount": 81,
          "title": "DALL·E 2",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txl7aq/learn_how_gans_work_with_a_cool_toonify_example/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txl7aq/learn_how_gans_work_with_a_cool_toonify_example/",
          "publishedOn": "2022-04-06T12:37:59.000Z",
          "wordCount": 109,
          "title": "Learn how GANs work with a cool Toonify example!",
          "imageUrl": "https://external-preview.redd.it/wn4380KIquPfpz8kvj0TNgHlT42uU-rZ_wdLCjVqQuU.jpg?auto=webp&s=0201632198505c9f0748c4f8646d6e4557e44ea7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txjowl/artificial_intelligence_machine_learning_and_the/",
          "author": null,
          "description": "submitted by    /u/aair_x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txjowl/artificial_intelligence_machine_learning_and_the/",
          "publishedOn": "2022-04-06T11:10:10.000Z",
          "wordCount": 122,
          "title": "Artificial Intelligence, Machine Learning and the Higgs boson - Live talk with Dr. David Rousseau",
          "imageUrl": "https://external-preview.redd.it/OSapOm3OaEUTvROlB59djlVRlsEHukiodQR08e6Bv9A.jpg?auto=webp&s=0e2022382fc9b816e0727c2dbaaaa8e4f782d305"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txelh6/what_are_your_thoughts_about_ai_teachers/",
          "author": null,
          "description": "submitted by    /u/curiosityVeil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txelh6/what_are_your_thoughts_about_ai_teachers/",
          "publishedOn": "2022-04-06T05:12:46.000Z",
          "wordCount": 152,
          "title": "What are your thoughts about AI teachers?",
          "imageUrl": "https://external-preview.redd.it/80zTz2GSqxkIcAo531n58iOibUJoLUsjIYse2G5B-Gg.jpg?auto=webp&s=e57005bacbf4e2da807f32d3456669927d952049"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txd3gn/heres_an_intuitive_explanation_to_singular_value/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txd3gn/heres_an_intuitive_explanation_to_singular_value/",
          "publishedOn": "2022-04-06T03:43:32.000Z",
          "wordCount": 144,
          "title": "Here's an intuitive explanation to Singular Value Decomposition. 👇",
          "imageUrl": "https://external-preview.redd.it/yEZqz6bdYi9OxMbxSAun-NOOyBiIEWi0hgButp5s0Bc.jpg?auto=webp&s=7501076a2d95650e0f1222b249a18b18ee508c2e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx99v0/artificial_nightmares_beauty_parlor_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx99v0/artificial_nightmares_beauty_parlor_clip_guided/",
          "publishedOn": "2022-04-06T00:21:20.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Beauty Parlor || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/uIXIo-JN5IPR5kMQLxCCW6I2UuSHT9uE8Y0Y2rzt8_A.jpg?auto=webp&s=eeb8b67dbaac0c8d18c931376cd666f5b9c11d4b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx7x0d/last_week_in_ai_ai_improves_algae_for_biofuel_and/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx7x0d/last_week_in_ai_ai_improves_algae_for_biofuel_and/",
          "publishedOn": "2022-04-05T23:13:43.000Z",
          "wordCount": 142,
          "title": "Last Week in AI: AI improves algae for biofuel and carbon capture, more AI decision-making in the military, and more!",
          "imageUrl": "https://external-preview.redd.it/n9aJP_9oQD2EMA4IrahetlrzK7vnz504KANDXrSuY8E.jpg?auto=webp&s=b090eda31ad16112cde4e1bb014a8a48270dc43e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx2gbr/researchers_from_allen_institute_for_ai_introduce/",
          "author": null,
          "description": "We humans navigate the environment using all of our senses. Allen Institute researchers propose MERLOT Reserve, a model that learns to represent videos over time and across several modalities, including audio, subtitles, and video frames. It was trained using a new learning objective and more than 20 million YouTube videos.\n MERLOT Reserve is a unique, cutting-edge methodology for solving video-related inquiries. MERLOT Reserve can dependably choose the correct answer from a selection of multiple-choice answers when given a video and a question. This forecast is made by MERLOT Reserve jointly reasoning over the visual frames of the video, the video subtitles, and the audio in the movie.\n Continue reading this cool research update from AI2\n Paper: https://arxiv.org/pdf/2201.02639.pdf\n Demo: https://merlot-reserve.apps.allenai.org/\n Project: https://rowanzellers.com/merlotreserve/\n Github: https://github.com/rowanz/merlot\\_reserve\n ​\n https://preview.redd.it/031i6ty6err81.png?width=1920&format=png&auto=webp&s=299569e12160eb991f35a2c6b41c5758ff027235\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx2gbr/researchers_from_allen_institute_for_ai_introduce/",
          "publishedOn": "2022-04-05T19:08:12.000Z",
          "wordCount": 241,
          "title": "Researchers From Allen Institute for AI Introduce ‘MERLOT Reserve’: A Novel Multimodal Video Question Answering Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx1gpx/endlessvn_open_alpha_today/",
          "author": null,
          "description": "submitted by    /u/roblox22y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx1gpx/endlessvn_open_alpha_today/",
          "publishedOn": "2022-04-05T18:24:46.000Z",
          "wordCount": 89,
          "title": "EndlessVN open alpha today",
          "imageUrl": "https://external-preview.redd.it/hzTGk_919JT_ol9WPARzYnUdu27B--ckWm5Gjh163Ns.jpg?auto=webp&s=1500dda8e3ecebf6daea2efb342f0a0f82f065fe"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twvsua/ai_meets_quantum_technology_in_new_google_spinoff/",
          "author": null,
          "description": "submitted by    /u/allaboutcircuits  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twvsua/ai_meets_quantum_technology_in_new_google_spinoff/",
          "publishedOn": "2022-04-05T14:08:38.000Z",
          "wordCount": 134,
          "title": "AI Meets Quantum Technology in New Google Spinoff, Sandbox AQ - News",
          "imageUrl": "https://external-preview.redd.it/Csqi5x9oFEPbU-NX_b014QpOo695w0-f9eoDc5vYBpc.jpg?auto=webp&s=720fb93dbbe0e2b3c64d730b52889606b5e60919"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twrsgf/best_undergraduate_major_besides_computer_science/",
          "author": null,
          "description": "Hi, all. I got accepted into my top choice of college as an undecided major. Recently, I have decided to pursue artificial intelligence! Unfortunately, it is near impossible to transfer into computer science at my particular university. I was wondering if I can still pursue AI as a career if I complete one of the following majors:\n -Mathematics\n -Information or Data Science\n -Statistics\n -Linguistics\n Additionally, I could pursue one of these and minor in another. I should be able to minor in computer science as well if necessary. Hopefully, my choice of major would allow me to pursue research or an internship in artificial intelligence. I am willing to take additional summer courses and pursue relevant certifications to ensure that I am up to par with my computer science colleagues. \n (posted on behalf of a family member)\n    submitted by    /u/runelagoon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twrsgf/best_undergraduate_major_besides_computer_science/",
          "publishedOn": "2022-04-05T10:26:35.000Z",
          "wordCount": 674,
          "title": "Best undergraduate major besides computer science for pursuing a career in artificial intelligence?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twqf43/comparing_old_and_new_ai_voices_from_replica/",
          "author": null,
          "description": "submitted by    /u/autumns  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twqf43/comparing_old_and_new_ai_voices_from_replica/",
          "publishedOn": "2022-04-05T08:47:46.000Z",
          "wordCount": 116,
          "title": "Comparing old and new AI voices from Replica Studios (new in second half)",
          "imageUrl": "https://external-preview.redd.it/sXhx5sJMKQOeW3d6yJH5Y3x-xzEsRRd4Vlsw9kNMAEQ.jpg?auto=webp&s=f135eef5941ce2927e1b7835cf2f5f32bbc26027"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twmyc3/superres_modelprogram_comparison/",
          "author": null,
          "description": "I upscaled an image with a few different superres models and programs, pick your favorite!\n https://files.botbox.dev/superrestestcollage.png\n Because of how reddit is, I can't make this as a poll, so comment your pick.\n Animated original version: https://www.youtube.com/watch?v=zRaTwVuqd70 (I will also make an animated version upscaled with the most voted model/program)\n    submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twmyc3/superres_modelprogram_comparison/",
          "publishedOn": "2022-04-05T04:50:22.000Z",
          "wordCount": 131,
          "title": "Super-res model/program comparison",
          "imageUrl": "https://external-preview.redd.it/0b-KM1fMHQlvxq8AaZ1Yoz4s8d9vlfkaCTjKSFHSx5I.jpg?auto=webp&s=00cf51afd6fc6d339a19830c02dd07831a4dd112"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twl2bd/solo_voiceovers/",
          "author": null,
          "description": "I am looking for something to change my voice in a way that is more satisfactory and more convincingly varied than what simple voice modulation software can achieve and as cheaply as is possible (preferably free).\n Use case: I have been working on an animated movie to which I am the sole contributor. Though I have been putting it off while looking for an appropriate solution, the time has come to voice my various characters, who are a range of ages, both male and female. For several reasons, I am interested in voicing them all myself while doing the facial motion captures as well. What I am in need of is, essentially, something that does exactly what Respeecher does, but without the $200/month sub fee. I would love to be in a position to simply pay them what they are asking for in exchange…",
          "link": "https://www.reddit.com/r/artificial/comments/twl2bd/solo_voiceovers/",
          "publishedOn": "2022-04-05T03:02:48.000Z",
          "wordCount": 508,
          "title": "solo voiceovers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twkptb/artificial_nightmares_frenzied_flame_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twkptb/artificial_nightmares_frenzied_flame_clip_guided/",
          "publishedOn": "2022-04-05T02:44:46.000Z",
          "wordCount": 126,
          "title": "Artificial Nightmares: Frenzied Flame || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/Ou-X9gePzH_R1p1xZ0_LmlSuj8KLO-kGZaJHgIJfVSE.jpg?auto=webp&s=bd8596715f1ab78a9626534ffc61ae623f7b1af3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twjoqd/ai_that_takes_multiple_songs_as_input_and_then/",
          "author": null,
          "description": "I have been searching for a music AI that takes input as mp3 or midi files, yet haven't been successful yet. Is there such a thing? If not, is such a thing feasible?\n    submitted by    /u/16pxl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twjoqd/ai_that_takes_multiple_songs_as_input_and_then/",
          "publishedOn": "2022-04-05T01:52:00.000Z",
          "wordCount": 402,
          "title": "AI that takes multiple songs as input, and then generates a similar song or song with similar elements?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw91fr/microsoft_researchers_introduce_jigsaw_an_ai_tool/",
          "author": null,
          "description": "GPT-3, Codex, and other sizable pre-trained language models can be adjusted to create code from natural language descriptions of programmer intent. Every developer in the world might benefit from these automated models, which have the potential to increase productivity. However, because the models may fail to understand program semantics, the quality of the generated code cannot be guaranteed.\n Microsoft researchers introduce Jigsaw, a new tool that can help these big language models perform better. Jigsaw is a Python Pandas API code generator that accepts multi-modal inputs. Jigsaw uses post-processing techniques to decipher the syntax and semantics of programs and then uses user feedback to improve future performance.\n Continue Reading\n Paper: https://arxiv.org/pdf/2112.02969.pdf\n Dataset: https://github.com/microsoft/JigsawDataset\n ​\n https://i.redd.it/x223r5qu0kr81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw91fr/microsoft_researchers_introduce_jigsaw_an_ai_tool/",
          "publishedOn": "2022-04-04T18:21:08.000Z",
          "wordCount": 263,
          "title": "Microsoft Researchers Introduce ‘Jigsaw’: An AI Tool To Augment Large Language Models (GPT-3, Codex, etc.) By Deploying Post-Processing Techniques That Understand The Programs’ Syntax And Semantics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw8fae/pathways_language_model_palm_scaling_to_540/",
          "author": null,
          "description": "submitted by    /u/nick7566  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw8fae/pathways_language_model_palm_scaling_to_540/",
          "publishedOn": "2022-04-04T17:56:24.000Z",
          "wordCount": 121,
          "title": "Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance",
          "imageUrl": "https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?auto=webp&s=d45552298a94c0bc0e771853afe179cbb0e3f951"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw79so/generative_aialex_grey_xxxxxoooooooo_disco/",
          "author": null,
          "description": "submitted by    /u/JoshGrambo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw79so/generative_aialex_grey_xxxxxoooooooo_disco/",
          "publishedOn": "2022-04-04T17:09:23.000Z",
          "wordCount": 105,
          "title": "Generative AI+Alex Grey = xxxxxoooooooo (Disco Diffusion)",
          "imageUrl": "https://external-preview.redd.it/5szgyleyhmZQatLGQQc0tWNKXYQjmomMBSzW55VOY2I.jpg?auto=webp&s=f943d685a85e58d5f8cb7371f25e11e3763f8f34"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw6zcv/uipath_extract_tables_from_pdf_use_case_pdf_table/",
          "author": null,
          "description": "submitted by    /u/Cristi_UiPath  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw6zcv/uipath_extract_tables_from_pdf_use_case_pdf_table/",
          "publishedOn": "2022-04-04T16:58:01.000Z",
          "wordCount": 111,
          "title": "UiPath extract Tables from PDF (use case) (PDF table)",
          "imageUrl": "https://external-preview.redd.it/XdStN-2Ltm4rlONpMIvCknd-rKvCteajYNUFIXrL__E.jpg?auto=webp&s=3b4ef0b9d4d13d1bb16a3f84865d7884a09eeb8d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw1nzj/new_rl_technique_achieves_superior_performance_in/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw1nzj/new_rl_technique_achieves_superior_performance_in/",
          "publishedOn": "2022-04-04T13:11:26.000Z",
          "wordCount": 101,
          "title": "New RL technique achieves superior performance in control tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvz2cs/metrics_matthews_correlation_coefficient/",
          "author": null,
          "description": "submitted by    /u/TheTesseractAcademy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvz2cs/metrics_matthews_correlation_coefficient/",
          "publishedOn": "2022-04-04T10:51:05.000Z",
          "wordCount": 94,
          "title": "Metrics: Matthew's correlation coefficient",
          "imageUrl": "https://external-preview.redd.it/K79luiNVO7cDl4UNZslrIpsFYJBu9pe6zLP_bpNmEVU.jpg?auto=webp&s=b4b8dcad0ffee30fc3cd5116872c85a245b67edd"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvy3mp/12_graphs_that_explain_the_state_of_ai_in_2022/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvy3mp/12_graphs_that_explain_the_state_of_ai_in_2022/",
          "publishedOn": "2022-04-04T09:49:07.000Z",
          "wordCount": 136,
          "title": "12 Graphs That Explain the State of AI in 2022",
          "imageUrl": "https://external-preview.redd.it/rxu_HYqvBcCfZOmrTEaxXK9YViKM0KioByJVsMvy31k.jpg?auto=webp&s=366d3c7f395840f2f28a0d32633778e1dc2e03c0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvx311/what_is_whatsapp_business_api_how_can_it_help/",
          "author": null,
          "description": "submitted by    /u/mihircontra20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvx311/what_is_whatsapp_business_api_how_can_it_help/",
          "publishedOn": "2022-04-04T08:38:30.000Z",
          "wordCount": 117,
          "title": "What is WhatsApp Business API? How can it Help your Business?",
          "imageUrl": "https://external-preview.redd.it/dNWZt5KgY2MqG0CICD8AVcKpMu4QVpc2Y1jPRh4tVfc.jpg?auto=webp&s=544310fa5704bad1ded6821fe5bc364c99358791"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvqnw5/voice_copyingcloning/",
          "author": null,
          "description": "Hi all,\n Don't know if this is the right subreddit, but here goes....\n I'm looking to voice clone my father. He has passed recently, and despite being difficult for all, it's been especially hard for my mother, married early to him and together for 50 years. Her birthday is coming up, I'd love to be able to create a 5-10 second sound byte of him for her.\n Fortunately, there's likely to be lots of his voice recording around, part of his job was speaking and instructing.\n So, is there any way this is possible, to be done without great difficulty, and produce an accurate result?\n I am understanding the moralities of crafting something with his deceased voice. I thought about it quite a bit. However, I feel that it's for his soulmate who's struggling, who he had no qualms spending his life with and travelling abroad with, spent his last days with. I'm certain he would want to help.\n    submitted by    /u/mininggotboring  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvqnw5/voice_copyingcloning/",
          "publishedOn": "2022-04-04T02:17:04.000Z",
          "wordCount": 300,
          "title": "Voice copying/cloning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvd9w0/ai_news_als_brain_computer_interface_1_year_human/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvd9w0/ai_news_als_brain_computer_interface_1_year_human/",
          "publishedOn": "2022-04-03T16:31:19.000Z",
          "wordCount": 145,
          "title": "AI News | ALS Brain Computer Interface 1 Year Human Trial Results | Skin Cancer Detection | New IBM AI Hardware",
          "imageUrl": "https://external-preview.redd.it/V1rfHFG8YhKM7LmCEZ3wsL5vptilPYrVjTDo-LcpRD4.jpg?auto=webp&s=4daa3bb70bc2ec7d33bdcd71f74b5d0bb0799e16"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvctg8/your_next_teacher_will_be_a_machine_why_the/",
          "author": null,
          "description": "submitted by    /u/itsallshit-eatup  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvctg8/your_next_teacher_will_be_a_machine_why_the/",
          "publishedOn": "2022-04-03T16:11:21.000Z",
          "wordCount": 126,
          "title": "Your Next Teacher Will be a Machine: Why the Future of Education is Automation",
          "imageUrl": "https://external-preview.redd.it/6esqFIrmdOYU6dYfuQXctFxZQK0hWvaxAMXQLVewc_w.jpg?auto=webp&s=580098cc5f338bdbc295957629b74a03b2be7209"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvaoe1/hi_im_wondering_if_anyone_could_help_me/",
          "author": null,
          "description": "Im a 19yo guy from Argentina that studies system ingeneer, I like my career, beeing an ingeneer is great, but coding and AI is greater, Im tired of courses like Free code academy, or basics things, im looking for a more professional, useful and deeper courses, that will really teach me, im currently with python(pandas,numpy,matplotlib,tensorflow) basics, and wanna to be better in that field that i love❤\n    submitted by    /u/Sasulanda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvaoe1/hi_im_wondering_if_anyone_could_help_me/",
          "publishedOn": "2022-04-03T14:36:41.000Z",
          "wordCount": 167,
          "title": "Hi!, Im wondering if anyone could help me🇦🇷🇦🇷",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Neural Networks, Deep Learning and Machine Learning",
      "feedUrl": "https://www.reddit.com/r/neuralnetworks/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/neuralnetworks/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ugyi4y/do_you_usually_build_neural_networks_from_scratch/",
          "author": null,
          "description": "I´´m curious, I´ve seen both and while the ones using libraries sound harder to make, the ones made from scratch sound slightly sloppier. For context, I mean for predator-prey simulations and such, not image to text recognition or anything that hard.\n    submitted by    /u/HesAMagicalPoney55  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ugyi4y/do_you_usually_build_neural_networks_from_scratch/",
          "publishedOn": "2022-05-02T20:11:20.000Z",
          "wordCount": 330,
          "title": "Do you usually build neural networks from scratch or do you use a library dedicated to it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ugtr4i/question_interval_branch_and_bound/",
          "author": null,
          "description": "Hello everyone,\n I'm studying the Branch and Bound algorithm, and I got a question (Reddit looks like the perfect place to ask other experienced people).\n I already have a working Branch and Bound algorithm but I want to adapt it to be working with intervals instead of one single value. And how do I do it?\n ​\n On Branch and Bound I have something like:\n For each sample, I'm calculating the costs and then running the bab algorithm with those and my values.\n if (x - y < 0) then keep going with the tree\n else stop with the search\n But when adapting for Interval Branch and Bound would be something like:\n if ((x + ∆x) - (y+∆y) < 0) keep going with the tree\n else stop with the search\n and then I still need to check for the other bound (x - ∆x).\n ​\n I will need to calculate twice the costs (once for each bound) and search the tree one time also for each cost? I can be saying a really big mistake, but that's why I'm here. Someone can help be clarifying my problem?\n Thank you for your attention.\n    submitted by    /u/Zarathos_PT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ugtr4i/question_interval_branch_and_bound/",
          "publishedOn": "2022-05-02T16:38:41.000Z",
          "wordCount": 282,
          "title": "[Question] Interval Branch and Bound",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ugdtlg/future_computers_will_be_radically_different/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ugdtlg/future_computers_will_be_radically_different/",
          "publishedOn": "2022-05-02T00:53:04.000Z",
          "wordCount": 108,
          "title": "Future Computers Will Be Radically Different",
          "imageUrl": "https://external-preview.redd.it/2DKwYPzWEMVH7LwFsMk2xyQrRjwrV-efnDqSX6pbmR0.jpg?auto=webp&s=a25dfe92daffd1e848427fd4179388f3e3d6ed54"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ug2qyy/introducing_kohonen_networks_selforganizing_maps/",
          "author": null,
          "description": "Hi team 👋! I would like to share with you a tutorial that I have recently made to explain in a very practical, introductorial and visual way what Kohonen Neural Networks (Self-Organized Maps) are 🧠 I explain, step by step, and through animations and C code, how to implement this well-known unsupervised learning algorithm to classify and detect patterns in large volumes of data.\n I hope it is of your interest, especially for those developers who are just starting out in this area. A strong greeting!\n \\Subtitles in English, Spanish and Catalan.*\n https://youtu.be/UawpUKlFzRs\n    submitted by    /u/anadalg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ug2qyy/introducing_kohonen_networks_selforganizing_maps/",
          "publishedOn": "2022-05-01T15:51:20.000Z",
          "wordCount": 200,
          "title": "Introducing Kohonen Networks (Self-Organizing Maps) for beginners",
          "imageUrl": "https://external-preview.redd.it/_VJ-6dXu-mRZ5d569qWu6r8k8juHPS008MpXqUgPbMc.jpg?auto=webp&s=fa09f1c02f334b620f2fa7f8474469040f4cdcc7"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/uf5b6z/object_detection_with_depth_measurement_using/",
          "author": null,
          "description": "submitted by    /u/spmallick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/uf5b6z/object_detection_with_depth_measurement_using/",
          "publishedOn": "2022-04-30T06:25:38.000Z",
          "wordCount": 130,
          "title": "Object detection with depth measurement using pre-trained models with OAK-D",
          "imageUrl": "https://external-preview.redd.it/5CQNFNC3qVk4odH3JZXb2zkbNzPXZWWejKxxwnbRe9A.jpg?auto=webp&s=e417fa73b2bab9f06a2fcb01025e881ef44c543f"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/uess31/how_to_tune_graph_neural_networks/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/uess31/how_to_tune_graph_neural_networks/",
          "publishedOn": "2022-04-29T18:52:19.000Z",
          "wordCount": 113,
          "title": "How to Tune Graph Neural Networks",
          "imageUrl": "https://external-preview.redd.it/0Oiq8zbgrZp1dPodoHNCnX60pPtFD-nU6P0RA0IOBP8.jpg?auto=webp&s=58a2267f4df8503fd671733686aad64228c257b4"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/udr84k/help_to_create_a_simple_neural_network_or_find/",
          "author": null,
          "description": "Hello,\n I really need help creating a simple Neural Network that approximates the Rosenbrock function (a function with two variables). I have used the book \"MATLAB Deep Learning\" by Phil Kim, which provides code examples. However, when I make a simple example where the network is trained with backpropagation the output of the testing points simply comes out as ones. \n It is very early work so the code is very simple. I have just cut out the piece of code with Neural Network. Can someone give any tips or help me to figure out what is wrong?\n %% Neural Network % Rosenbrock function : f = (1 - x1).^2 + 100*(x2-x1.^2).^2 % X: 25x2 matrix % f_samp: 25x1 vector % Number of nodes in hidden layer nHNodes = 4 ; % Input layer has two nodes % Output layer has one node % Initial weigts W1 = 2*rand(nHNodes, k) - 1 ; W2 = 2*rand(1, nHNodes) - 1 ; alpha = 0.5 ; % Lerning rate % Backpropagation for i = 1:10000 for i = 1:size(X,1) x = X(i, :)'; d = f_samp(i); % Forward v1 = W1*x; y1 = fun_sigmoid(v1); v = W2*y1; y = fun_sigmoid(v); % Backward e = d - y; delta = y.*(1-y).*e; e1 = W2'*delta; delta1 = y1.*(1-y1).*e1; dW1 = alpha*delta1*x'; W1 = W1 + dW1; dW2 = alpha*delta*y1'; W2 = W2 + dW2; end end % Testing sampling points for i = 1:size(X,1) x = X(i, :)' ; v1 = W1*x ; y1 = fun_sigmoid(v1) ; v = W2*y1 ; y(i) = fun_sigmoid(v) ; end \n    submitted by    /u/TobiasFred  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/udr84k/help_to_create_a_simple_neural_network_or_find/",
          "publishedOn": "2022-04-28T09:40:15.000Z",
          "wordCount": 381,
          "title": "Help to create a simple Neural Network... or find the bug",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/udlhr9/i_need_help_making_a_neural_network_from_scratch/",
          "author": null,
          "description": "Here's my code: https://github.com/heyuhowudoin/mnist_ai\n I currently have 3 layers, 15, 15 and 10 neurons respectively. I'm using the MNIST database to get images of hand-drawn numbers and trying to classify them by which neuron in the final layer has the highest activation. I use a combination of sigmoid and ReLU as activation functions, and I am using minibatches of 100 pictures each.\n The thing I see happening is that it converges to a point where every neuron in the final layer outputs a 0 because then it has a relatively low error since the target for 9 out of 10 of those neurons is indeed 0, whereas the target for the correct output neuron is 1.\n I've tried looking over my backprop algorithm, I've tried changing the neurons in each hidden layer to 200, I've changed the learning speed a bunch but I can't seem to figure out why it's not working so if one of you guys wouldn't mind helping me, that would be much appreciated.\n    submitted by    /u/-i-hate-this-place-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/udlhr9/i_need_help_making_a_neural_network_from_scratch/",
          "publishedOn": "2022-04-28T03:19:39.000Z",
          "wordCount": 360,
          "title": "I need help making a neural network from scratch in python",
          "imageUrl": "https://external-preview.redd.it/OttZzJDWEJclX6T0OodlGIQeZL5yM7wAwwiSo3ObynU.jpg?auto=webp&s=73d2362e9d0b808115c69fdf9c2ffb0cd032763e"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/udhr62/alphago_zero/",
          "author": null,
          "description": "Hello, I have an alphago zero question. Why doesn’t alphago zero use Q(s,a) to choose its next move in the Monte Carlo tree search? Why does it use the π instead?\n    submitted by    /u/Skinnybisquit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/udhr62/alphago_zero/",
          "publishedOn": "2022-04-28T00:07:27.000Z",
          "wordCount": 135,
          "title": "AlphaGo Zero",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ucq1r1/guide_to_iteratively_tuning_gnns/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ucq1r1/guide_to_iteratively_tuning_gnns/",
          "publishedOn": "2022-04-26T23:43:50.000Z",
          "wordCount": 105,
          "title": "Guide to Iteratively Tuning GNNs",
          "imageUrl": "https://external-preview.redd.it/VN_AAlU77_6qR-oL5nPN_QANJIRFwqPXPJNyV8WUPTs.jpg?auto=webp&s=e73ced42586cfe5bf9c952d5ab49691b83ef1b02"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ucobvg/exploring_neural_networks_visually_in_the_browser/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ucobvg/exploring_neural_networks_visually_in_the_browser/",
          "publishedOn": "2022-04-26T22:19:13.000Z",
          "wordCount": 116,
          "title": "Exploring Neural Networks Visually in the Browser",
          "imageUrl": "https://external-preview.redd.it/mKzaNflr0pJAIg8fuZexBJ6EU3vXdLrq81i2a_6o5YA.jpg?auto=webp&s=1f002039ca6e35c6030389ffd695b75136726b60"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/uc6e5f/what_has_priority_in_the_performance/",
          "author": null,
          "description": "I'm really new to neural networks and I was wondering how to speed up the process of selecting the best one when I do the training. What I mean is, among the training/validation/test quotas, the number of hidden layers, the type of activation functions, the size of each layers, how do I iterate to find the optimal combination without having to try every little mix?\n Is there a way to rank the impact of these 4 components on the mse and iterate one at a time to select each aspect? Thanks in advance\n    submitted by    /u/beppegrosso97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/uc6e5f/what_has_priority_in_the_performance/",
          "publishedOn": "2022-04-26T06:44:40.000Z",
          "wordCount": 229,
          "title": "What has priority in the performance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ubxn11/ai_hitman_learns_to_find_waldo/",
          "author": null,
          "description": "submitted by    /u/TernaryJimbo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ubxn11/ai_hitman_learns_to_find_waldo/",
          "publishedOn": "2022-04-25T22:42:03.000Z",
          "wordCount": 113,
          "title": "AI Hitman Learns to Find Waldo",
          "imageUrl": "https://external-preview.redd.it/MvCtGs0pDjhaI1nm4RKqVsiwFD7OQYa6elmhLluRqw4.jpg?auto=webp&s=da6095d99ca248ebd5b2e3ebe33dfc199b361693"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ubngad/help_with_walk_forward_validation_in_lstm_problem/",
          "author": null,
          "description": "Hi, I am having some trouble with a LSTM problem regarding walk forward validation in my LSTM. The problem is described in this stackoverflow post:\n https://stackoverflow.com/questions/71990833/using-predictions-instead-of-observed-values-in-walk-forward-validation-in-lstm\n If any one could help me that would be much appreciated\n    submitted by    /u/magnussendjoko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ubngad/help_with_walk_forward_validation_in_lstm_problem/",
          "publishedOn": "2022-04-25T15:15:19.000Z",
          "wordCount": 154,
          "title": "Help with walk forward validation in LSTM problem",
          "imageUrl": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&s=8cd5e918e2bde6ca72d4445d6fc007f203689799"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ubltsu/i_dont_think_this_was_posted_here_before_but_its/",
          "author": null,
          "description": "submitted by    /u/gwtkof  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ubltsu/i_dont_think_this_was_posted_here_before_but_its/",
          "publishedOn": "2022-04-25T14:00:13.000Z",
          "wordCount": 143,
          "title": "I don't think this was posted here before but it's incredible. The latest image generation from text",
          "imageUrl": "https://external-preview.redd.it/oBM69dcHuU7kJjM8QGw5Gcf8cNUl747wX2YMoi8LJ2o.jpg?auto=webp&s=123036a6e0443fa97ab714d460a3993b13d1eabc"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ubh35r/nn_from_scratch_5_updating_parameters_kolbenkraft/",
          "author": null,
          "description": "submitted by    /u/cjmodi306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ubh35r/nn_from_scratch_5_updating_parameters_kolbenkraft/",
          "publishedOn": "2022-04-25T09:29:07.000Z",
          "wordCount": 114,
          "title": "NN from Scratch: #5 Updating parameters | Kolbenkraft",
          "imageUrl": "https://external-preview.redd.it/GDnb256QTkcz5l5-77Ys1KBOLyCpV-FhczyyfWFfFkc.jpg?auto=webp&s=6a5ee252a5d11d763b300637085189cc5d1e6e32"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ubgul4/text_summarization_with_huggingface_transformers/",
          "author": null,
          "description": "submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ubgul4/text_summarization_with_huggingface_transformers/",
          "publishedOn": "2022-04-25T09:12:21.000Z",
          "wordCount": 120,
          "title": "Text Summarization with Huggingface Transformers and Python",
          "imageUrl": "https://external-preview.redd.it/VBJHR1cinHBOmglXNbcRbGjfR-WsD8adFlESNVmbSYg.jpg?auto=webp&s=e1f0229faf1476a85cff4aebdbf9ff9e21e4fe4e"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/uaw3xl/nota_ai_introduces_new_machine_learning_tools/",
          "author": null,
          "description": "In the last decade, AI research has brought astonishing results in many fields, and, undoubtedly, AI is nowadays a central technology in many aspects of our life. As new ideas are proposed every day, this continuous research usually comes with infinite applications: from the algorithms assisting surgeons in complex operations to the one which allows unlocking our phone using just our face. In this evolution from the idea to the actual implementation, it is often ignored how hard the passage between theoretical research and working application is.\n We can refer to this process as AI Development Cycle for Edge AI and can be divided into three phases related to 1) data, 2) model, and 3) evaluation.\n Many aspects must be considered: first, each different AI application requires a specific dataset. For this reason, in this step, the aim is to prepare the data, which, as is well known, is one of the crucial topics of AI: a good algorithm always relies on a good dataset. This phase can be divided into data collection, curation, labeling, and preparation. \n Continue reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/uaw3xl/nota_ai_introduces_new_machine_learning_tools/",
          "publishedOn": "2022-04-24T14:36:50.000Z",
          "wordCount": 335,
          "title": "Nota AI Introduces New Machine Learning Tools Under Its NetsPresso Platform For Automatically Searching Optimized Models And Making Compression Process Easy And Fast",
          "imageUrl": "https://external-preview.redd.it/Gxl1BzzbMn-8pBr9ef83GCerUASCrtl82642cRDUDVU.jpg?auto=webp&s=d0d08c2c329dbc12f2cb217ba824f8cd0c26fb63"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ua88n1/google_researchers_create_animated_avatars_from_a/",
          "author": null,
          "description": "submitted by    /u/SpatialComputing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ua88n1/google_researchers_create_animated_avatars_from_a/",
          "publishedOn": "2022-04-23T15:45:46.000Z",
          "wordCount": 339,
          "title": "GOOGLE researchers create animated avatars from a single photo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ua5rzp/i_dont_understand_why_i_am_getting_nan_loss/",
          "author": null,
          "description": "submitted by    /u/brike3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ua5rzp/i_dont_understand_why_i_am_getting_nan_loss/",
          "publishedOn": "2022-04-23T13:45:27.000Z",
          "wordCount": 392,
          "title": "I don't understand why I am getting NaN loss scores. Can anyone explain what I am doing wrong ?",
          "imageUrl": "https://preview.redd.it/zdpc73yq8av81.png?auto=webp&s=dead4e0b186b35069c7b1dfc7546d4becfd0e3f9"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u9yfvb/are_there_applications_of_neural_networks_other/",
          "author": null,
          "description": "I see lots of hardware oriented toward AI/ML stuff these days, including chips with hardware acceleration for neural networks. \n I'm thinking about how GPUs were initially designed for graphics calculations, but then things like CUDA and OpenCL were developed to make that hardware usable for broader applications of parallel processing.\n Are there any other things that you can do with a neural network besides backpropagation, that wouldn't be easier to do in other ways?\n    submitted by    /u/Bananawamajama  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u9yfvb/are_there_applications_of_neural_networks_other/",
          "publishedOn": "2022-04-23T05:42:17.000Z",
          "wordCount": 191,
          "title": "Are there applications of neural networks other than machine learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u9qavf/i_have_a_time_series_of_time_temp_humidity/",
          "author": null,
          "description": "I want to create a NN that takes these readings and makes predictions about \"what will the readings be in 5 minutes if I turn the AC on?\".\n I'm thinking of training it with \"the angle of the sun at that time\", \"temp\", \"humidity\", and \"ac/heater/fan state\"(3) and then extracting data pairs spaced by 5 minutes where the system was in that state for the entire interval. Then I'm thinking I should use the 5-minute-later apparent temp as the training output.\n So the NN ultimately answers the question \"what would be the apparent temperature if the system were to be in the given state for the next 5 minutes?\"\n Am I on the right track here?\n    submitted by    /u/HasFiveVowels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u9qavf/i_have_a_time_series_of_time_temp_humidity/",
          "publishedOn": "2022-04-22T22:17:28.000Z",
          "wordCount": 345,
          "title": "I have a time series of time, temp, humidity, apparent temp, and ac/heater/fan state",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u8nv3j/building_dense_passage_retrievers/",
          "author": null,
          "description": "Hi, I made a video explaining the ideas behind building a Dense Passage Retriever(DPR). Whenever we talk about retrievers, we mostly refer to the DPR formulation which appeared in this paper. A lot of publicly available implementations also use this formulation. \n In a previous video, we discussed how to use the DPR End-to-End QA system which uses DPR with a QA model. In this video, we solely focus on retrievers and the ideas behind building them. The implementation is quite similar to retrievers pre-trained with Inverse Close Task.\n This video is part 8 of 9 video series on Open-domain question answering using Dense retrievers. Thanks for the support and I will appreciate any feedback.\n https://www.youtube.com/watch?v=w61p0HLo7gc\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u8nv3j/building_dense_passage_retrievers/",
          "publishedOn": "2022-04-21T13:37:47.000Z",
          "wordCount": 213,
          "title": "Building Dense Passage Retrievers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u8gqfy/nn_from_scratch_4_backward_propagation_kolbenkraft/",
          "author": null,
          "description": "submitted by    /u/cjmodi306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u8gqfy/nn_from_scratch_4_backward_propagation_kolbenkraft/",
          "publishedOn": "2022-04-21T06:03:08.000Z",
          "wordCount": 119,
          "title": "NN from Scratch: #4 Backward Propagation | Kolbenkraft",
          "imageUrl": "https://external-preview.redd.it/GDnb256QTkcz5l5-77Ys1KBOLyCpV-FhczyyfWFfFkc.jpg?auto=webp&s=6a5ee252a5d11d763b300637085189cc5d1e6e32"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u8dpr7/searching_for_volunteers_for_mlbased_ukrainian/",
          "author": null,
          "description": "We are searching for trustworthy volunteers with some free time who would like to contribute to a digital Ukrainian volunteer project. Our system heavily relies on an image recognition system with a number of specialized filters involvg facial recognition, object recognition, logo detection, photoshop detection etc. People with professional experience with any of these things is preferred, but novice ML people are welcome to join us in a different capacity. DM to learn more about the project, glad to discuss the details with you.\n    submitted by    /u/eelgirl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u8dpr7/searching_for_volunteers_for_mlbased_ukrainian/",
          "publishedOn": "2022-04-21T03:03:05.000Z",
          "wordCount": 194,
          "title": "Searching for volunteers for ML-based Ukrainian volunteer project.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u7wwrm/neural_network_gets_too_large_and_dies/",
          "author": null,
          "description": "Hi, I've been working on a project for my computer science class and everything has been working up until the training. I'm following a guide online that has worked fairly well. Whenever I try to train, however, I run into an overflow error and the entire network dies. I'm not sure where to go from here as I've tried a few steps to fix the issue, if anyone could offer up some advice to fixing my problem that would be amazing.\n    submitted by    /u/djm710  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u7wwrm/neural_network_gets_too_large_and_dies/",
          "publishedOn": "2022-04-20T13:46:57.000Z",
          "wordCount": 583,
          "title": "Neural Network gets too large and dies",
          "imageUrl": "https://external-preview.redd.it/ZiAEpY_hvprgfEEpJOvIl6QIO7P1iFdUa5H0BGEeLQo.jpg?auto=webp&s=ab73127f439f3ef3e87d99be76ff2255d0e45755"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u7u33n/7_best_books_to_learn_neural_networks_in_2022_for/",
          "author": null,
          "description": "submitted by    /u/maneesh123456  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u7u33n/7_best_books_to_learn_neural_networks_in_2022_for/",
          "publishedOn": "2022-04-20T11:14:32.000Z",
          "wordCount": 134,
          "title": "7+ Best Books to Learn Neural Networks in 2022 for Beginners (Updated) -",
          "imageUrl": "https://external-preview.redd.it/6o1SHWA4Ukh7Pe8AxhxW7UxZ5d2Hr-6oB0LpJysDHEQ.jpg?auto=webp&s=2db8922d7b93dfa6ad200385940f3ecefef840c8"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u7rs0v/question_about_sigmoid_and_heaviside/",
          "author": null,
          "description": "I read a paper and was a little bit confused:\n In the paper it said: \"Imagine you have a two dimensional (binary input) classification (0 or 1) problem and you use Sigmoid as an acitivation function. Since the Sigmoid gives you a real number between 0 and 1, it's not really classification anymore. \n Therefore you take the input of Sigmoid (y_Sigmoid) and put this into a modified heaviside function H(y-0.5) (so for y_Sigmoid bigger than 0.5, it gives you yHeavi = 1)\n The decision boundary is given by a straight line w1a1+w2a2+w0=0 and this whole process, it only works with the Sigmoid function as first activation function.\"\n The last paragraph confused me. Why can I assume that the decision boundary is exactly that (It's just the \"normal decision boundary\" for a SLP, why does it work here a also) \n and why does it work with only Sigmoid Function as first activation function\n    submitted by    /u/LawlHeyman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u7rs0v/question_about_sigmoid_and_heaviside/",
          "publishedOn": "2022-04-20T08:31:45.000Z",
          "wordCount": 251,
          "title": "Question about Sigmoid and Heaviside",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u7kwa1/starting_a_neural_network/",
          "author": null,
          "description": "I want to create a program that can take music i feed it and over time create its own music based on the inputs. I know i have to use a neural network and deep learning algorithms but how do i get started. Thanks.\n    submitted by    /u/Saxy-Snark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u7kwa1/starting_a_neural_network/",
          "publishedOn": "2022-04-20T01:26:59.000Z",
          "wordCount": 659,
          "title": "Starting a neural network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u7c95h/overview_of_relational_graph_convolutional/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u7c95h/overview_of_relational_graph_convolutional/",
          "publishedOn": "2022-04-19T18:41:24.000Z",
          "wordCount": 111,
          "title": "Overview of Relational Graph Convolutional Networks (RGCN)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u71vwo/this_is_a_long_shot_but_does_anyone_remember/",
          "author": null,
          "description": "Hi, this is a very long shot. I have been trying to remember the name of a science TV show which aired in the UK back in the 90's. It focussed on Neural Networks and gave some brilliant examples of environmental sensing. There was also a section showing a simple voice synthesiser which \"babbled\" like a child.\n I thought it may have been an \"Horizon\" show, however, I have been through the list of shows from that time and none appear to be right. If anyone has a memory of this show please let me know.\n One of the visuals I remember was a plastic skull with an LED matrix inside showing patterns. Obviously this was just some smoke and mirrors, however, it may trigger a memory. I'm trying to recall something from best part of 30 years ago..\n    submitted by    /u/_m0xya_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u71vwo/this_is_a_long_shot_but_does_anyone_remember/",
          "publishedOn": "2022-04-19T10:25:04.000Z",
          "wordCount": 264,
          "title": "This is a long shot, but does anyone remember...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u6icjn/does_anyone_have_a_guess_as_to_why_my_network/",
          "author": null,
          "description": "submitted by    /u/-i-hate-this-place-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u6icjn/does_anyone_have_a_guess_as_to_why_my_network/",
          "publishedOn": "2022-04-18T17:19:39.000Z",
          "wordCount": 373,
          "title": "Does anyone have a guess as to why my network isn’t working? (more info in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u5s0fq/lstm_for_time_series_prediction/",
          "author": null,
          "description": "Hi\n I am doing a project where I have to predict sales for a company and I am having some trouble with my LSTM model in python. All research I have done tells me that LSTM is as good, if not better, than a ARIMA model for forecasting on time series data, but my LSTM is significantly worse than my ARIMA model. Would it be possible for any one to help me to see if I have implemented it right? I have used both Tensorflow and Pytorch and both are way worse than the ARIMA model.\n    submitted by    /u/magnussendjoko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u5s0fq/lstm_for_time_series_prediction/",
          "publishedOn": "2022-04-17T17:37:59.000Z",
          "wordCount": 489,
          "title": "LSTM for time series prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u4ce1w/dalle_zeroshot_texttoimage_generation_part12/",
          "author": null,
          "description": "OpenAI released DALL E2 in the last week, this system is basically have a capability of generating an image from a text description. Some of the results were truly amazing. In this blog, I tried to discuss the ideas around DALL-E (version 1) .\n DALL-E consist of two main components d-VAE(discrete-Variational Auto Encoder) and Auto-regressive transformer. In Part-1 I focused on d-VAE part where I tried to talk about basic VAE and it's ELBO formulation, VQ-VAE eventually that leads to d-VAE. It's reconstruction loss is formulated from Logit Laplcae (bounded) unlike typical L1 or L2. Overall this part explains about how a discrete vector(token) can be generated for an input image.\n    submitted by    /u/rakshith291  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u4ce1w/dalle_zeroshot_texttoimage_generation_part12/",
          "publishedOn": "2022-04-15T16:53:05.000Z",
          "wordCount": 214,
          "title": "DALL-E (Zero-Shot Text-to-Image Generation) -PART(1/2)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u45wln/the_best_explanation_of_what_is_machine_learning/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u45wln/the_best_explanation_of_what_is_machine_learning/",
          "publishedOn": "2022-04-15T11:26:22.000Z",
          "wordCount": 156,
          "title": "The best explanation of What is Machine Learning and How it works? MUST WATCH",
          "imageUrl": "https://external-preview.redd.it/cfWvorMNvuv8TX-JC5njDZlljI54paH5_Kr3qudtGW4.jpg?auto=webp&s=52d3e521696a0323a62d01756a9d0b243f532831"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u3zgab/how_do_i_fix_this_im_trying_to_predict_sine_the/",
          "author": null,
          "description": "submitted by    /u/-i-hate-this-place-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u3zgab/how_do_i_fix_this_im_trying_to_predict_sine_the/",
          "publishedOn": "2022-04-15T04:01:25.000Z",
          "wordCount": 461,
          "title": "how do I fix this (I'm trying to predict sine (the blue dots are it's guesses and the white line is the \"correct\" answer)",
          "imageUrl": "https://preview.redd.it/s02c8v0f9mt81.png?auto=webp&s=f7bff8a41b59cd5214f49c0439e530c5a76d436f"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u3w81q/neuroevolution_of_augmenting_topologies_course/",
          "author": null,
          "description": "Hey all,\n There's a new course on the Neuroevolution of Augmenting Topologies (NEAT) algorithm. It's a niche algorithm, but uses some very interesting mechanisms to train/evolve simple irregular neural networks.\n Thought some of you may be interested.\n    submitted by    /u/Cogitarius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u3w81q/neuroevolution_of_augmenting_topologies_course/",
          "publishedOn": "2022-04-15T01:04:32.000Z",
          "wordCount": 141,
          "title": "Neuroevolution of Augmenting Topologies Course",
          "imageUrl": "https://external-preview.redd.it/byYYhDKkBlVHjFF7JNhoiH-G-Kl2IXs44qnOEM43DWU.jpg?auto=webp&s=be313645b0144368a6774ad5ad3e9fc5087d8926"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u3n5pe/latest_research_from_stanford_introduces_domino_a/",
          "author": null,
          "description": "Machine learning and Artificial Intelligence models have gained promising results in recent years. The major factor behind their success is the availability and development of vast datasets. However, regardless of how many terabytes of data you have or how skilled you are at data science, machine learning models will be useless and even dangerous if you can’t make sense of data records.\n A slice is a collection of data samples with a common feature. For example, in a picture dataset, photographs of antique vehicles make up a slice. When a model’s performance on the data samples in a slice is significantly lower than its overall performance, the slice is considered underperforming.\n Deploying models underperforming on crucial data slices could seriously harm safety and fairness. For instance, models trained to detect collapsed lungs in chest X-rays generally make predictions based on the presence of chest drains, a common therapeutic device. As a result, computer models typically fail to detect collapsed lungs in images without chest drains, a critical data slice in which inaccurate negative predictions could be catastrophic.\n Not many studies have considered underperforming slices during model evaluation. Researchers believe that knowing which slices their models underperform would help practitioners not just make better decisions regarding model deployment but also improve model robustness by upgrading the training dataset or utilizing robust optimization strategies.\n Detecting slices is challenging because the “hidden” data slices are linked by a notion that isn’t easily derived from unstructured inputs or labeled in metadata (e.g., images, video, time-series data).\n Continue reading the summary\n Paper: https://arxiv.org/pdf/2203.14960.pdf\n Article: http://ai.stanford.edu/blog/domino/\n Github: https://github.com/HazyResearch/domino\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u3n5pe/latest_research_from_stanford_introduces_domino_a/",
          "publishedOn": "2022-04-14T17:49:06.000Z",
          "wordCount": 400,
          "title": "Latest Research From Stanford Introduces ‘Domino’: A Python Tool for Identifying and Describing Underperforming Slices in Machine Learning Models",
          "imageUrl": "https://external-preview.redd.it/SM3UD6S7rMbt_yORFmcYGaUql9R-TRPWYNM6VslJwUs.jpg?auto=webp&s=6fc83634e740e16715fba2418b84e42757837fdf"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u3blzp/nn_from_scratch_3_forward_propagation_kolbenkraft/",
          "author": null,
          "description": "submitted by    /u/cjmodi306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u3blzp/nn_from_scratch_3_forward_propagation_kolbenkraft/",
          "publishedOn": "2022-04-14T07:21:13.000Z",
          "wordCount": 119,
          "title": "NN from Scratch: #3 Forward propagation | Kolbenkraft",
          "imageUrl": "https://external-preview.redd.it/GDnb256QTkcz5l5-77Ys1KBOLyCpV-FhczyyfWFfFkc.jpg?auto=webp&s=6a5ee252a5d11d763b300637085189cc5d1e6e32"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u2rrwh/is_the_number_of_dimensions_in_the_latent_space/",
          "author": null,
          "description": "​\n https://preview.redd.it/qtgp7dzx2bt81.png?width=850&format=png&auto=webp&s=ccf391e8a1613d5405c137296bdf853010fc3f19\n Not speaking specifically about autoencoders here, but about general neural networks. As I understand correctly, \"latent space\" refers to one of the fully connected layers of the network and the dimensionality of the space is equal to the number of the neurons in this layer. This would mean, that each of the layers has a different \"latent space\" representation of the learned data distribution. Do I understand it correctly? \n I got really confused because people seem to sometimes refer to latent space as to all of the possible activations of all of the neurons in the network (each neuron of the network is one dimension of a latent space) OR EVEN to all of the PARAMETERS of the network (each parameter is one dimension of the latent space (??)). Do we have a separate name for these? How do we call the parameter space of a neural network? Is my original intuition even correct?\n    submitted by    /u/bzqp2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u2rrwh/is_the_number_of_dimensions_in_the_latent_space/",
          "publishedOn": "2022-04-13T14:37:16.000Z",
          "wordCount": 329,
          "title": "Is the number of dimensions in the latent space equal to the number of the neurons of the layer? Or perhaps number of neurons in the whole neural network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u2j6cv/researchers_propose_a_novel_framework_lilnetx_for/",
          "author": null,
          "description": "In this research, the researchers from the paper ‘ LilNetX: Lightweight Networks with EXtreme Model Compression and Structured Sparsification’ talk about the importance of larger parameter-heavy and computationally costly architectures in deep neural networks (DNNs) and how it improves the computer vision tasks. They also mentioned in the paper that it is not as simple as it seems since, as the DNNs become more common in the business, they are frequently required to be trained multiple times, communicated across the network to various devices, and executed under hardware limits with minimum loss of accuracy, all while maintaining accuracy. Then the question arises of how to reduce the models’ size on the devices while still enhancing their run-time. Explorations in this field have tended to take one of two paths: lowering model size via compression approaches or reducing computing demands through model pruning.\n The main achievement of this research from the University of Maryland and Google Research is the introduction of ‘LilNetX’, an end-to-end trainable neural network technique that allows learning models with specified accuracy-rate-computation trade-offs. Prior work has taken a piecemeal approach to these difficulties, which necessitates post-processing or multistage training, which is not efficient and does not scale well for big datasets or architectures. To encourage modest model size, the strategy is to create a joint training goal that penalizes the self-information of network parameters in a reparameterized latent space while simultaneously incorporating priors to increase structured sparsity in the parameter space to decrease computation.\n Continue Reading\n Paper: https://arxiv.org/pdf/2204.02965.pdf\n Github: https://github.com/Sharath-girish/LilNetX\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u2j6cv/researchers_propose_a_novel_framework_lilnetx_for/",
          "publishedOn": "2022-04-13T05:36:06.000Z",
          "wordCount": 395,
          "title": "Researchers Propose a Novel Framework ‘LilNetX’ For Training Deep Neural Network With Extreme Model Compression, and Structured Sparsification",
          "imageUrl": "https://external-preview.redd.it/ZjFWy0CxrbbFZuET26RZYgZsZypBEX6RQKxpni79cvk.jpg?auto=webp&s=a7b9b3b3adaef5ad200e589a9cc9d612814c1ab4"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u2ivzv/what_would_happen_if_you_connect_inputs_and/",
          "author": null,
          "description": "submitted by    /u/The_impact_theory  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u2ivzv/what_would_happen_if_you_connect_inputs_and/",
          "publishedOn": "2022-04-13T05:17:26.000Z",
          "wordCount": 653,
          "title": "What would happen if you connect inputs and outputs randomly to a large hebbian Spiking NN and let it learn shape itself in an environment.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u2ifr5/noob_here_who_doesnt_really_understand_calculus/",
          "author": null,
          "description": "If i want to take the partial derivative of the error with respect to a certain weight, it would be similar to taking the derivative of say y = value * weight + bias\n but if i hold the value and bias still, the derivative just becomes the value of the weight, like how the derivative of y = 3x is just 3… so what do I do? it doesn’t make sense to multiply 3 by a learning variable and make that the new weight, so what am I missing?\n    submitted by    /u/-i-hate-this-place-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u2ifr5/noob_here_who_doesnt_really_understand_calculus/",
          "publishedOn": "2022-04-13T04:49:51.000Z",
          "wordCount": 482,
          "title": "noob here who doesn’t really understand calculus",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u2a39q/how_to_win_a_kaggle_competition_with_bayesian/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u2a39q/how_to_win_a_kaggle_competition_with_bayesian/",
          "publishedOn": "2022-04-12T21:34:47.000Z",
          "wordCount": 117,
          "title": "How to Win a Kaggle Competition with Bayesian Optimization",
          "imageUrl": "https://external-preview.redd.it/i6niOaeH1H7kZRbr_ONzY7uYdsMOHUw526WwWQ8oFqg.jpg?auto=webp&s=eb576c954e2b80ed6623f8c373e80ee8a5126fe5"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u24agy/the_moment_a_neural_net_became_sentient_for_the/",
          "author": null,
          "description": "submitted by    /u/fooo-ooo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u24agy/the_moment_a_neural_net_became_sentient_for_the/",
          "publishedOn": "2022-04-12T17:19:02.000Z",
          "wordCount": 146,
          "title": "The Moment A Neural Net Became Sentient For The First Time - AI Art Story [4K] #shorts",
          "imageUrl": "https://external-preview.redd.it/L5PMjku7przoE7PKOmaS3wYWPlQIIcNN0NIJBJEMP4o.jpg?auto=webp&s=10eae903d47f072ac58914925d857e50887ec441"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u1drul/how_to_train_the_nn_model_with_a_custom_dataset/",
          "author": null,
          "description": "Hi all.\n I have been trying to work on an object detection project. Basically trying to play around with the codes in the documentation for a custom dataset.\n I am using Yolov3 and I trained my model using darknet and seems like the model is learning it wrong because of which the weights are not correct either. I don't know how to check that but when doing forward propagation, the array seems to be ok, without nan values, but the confidence is mostly 0's and some 0.25's. Anyone who can guide me, on where I could have gone wrong?\n ​\n code: https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html [yolov3 secion]\n output: \n outputs = [[0.03846154 0.03846154 0.27884614 0.21634616 0.5 0.25 ] [0.03846154 0.03846154 0. 0.47596154 0. 0. ] [0.03846154 0.03846154 0.89663464 0.78365386 0.5 0.25 ] ... [0.99038464 0.99038464 0.02403846 0.03125 0.5 0.25 ] [0.99038464 0.99038464 0.03846154 0.07211538 0.5 0. ] [0.99038464 0.99038464 0.07932692 0.05528846 0.5 0. ]] \n confidence = 0.25 0.0 0.25 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.25 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.25 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 ...\n    submitted by    /u/ersa17  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u1drul/how_to_train_the_nn_model_with_a_custom_dataset/",
          "publishedOn": "2022-04-11T18:02:25.000Z",
          "wordCount": 350,
          "title": "How to train the NN model with a custom dataset?",
          "imageUrl": "https://external-preview.redd.it/oQkgY14yFWzlXan1GqLP6t-FqWT5TGHOI7Vp6h7YEgU.jpg?auto=webp&s=af02a58cac40afc1beb8e57e0cd69d2ac5d53072"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u0h1y1/summer_school_in_between_neuroimaging_and_machine/",
          "author": null,
          "description": "submitted by    /u/pasticciociccio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u0h1y1/summer_school_in_between_neuroimaging_and_machine/",
          "publishedOn": "2022-04-10T12:57:37.000Z",
          "wordCount": 114,
          "title": "Summer school in between neuroimaging and machine learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u0h1cm/dalle_and_dalle2/",
          "author": null,
          "description": "I have been into the website of OpenAI, it is unclear what has been added to Dall-e2, why should we subscribe for a github which will be made public? And what is the color code at the bottom?\n    submitted by    /u/pasticciociccio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u0h1cm/dalle_and_dalle2/",
          "publishedOn": "2022-04-10T12:56:37.000Z",
          "wordCount": 155,
          "title": "Dall-e and Dall-e2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u0a6yb/researchers_including_yann_lecun_propose_projunn/",
          "author": null,
          "description": "When deep networks or inputs involve extensive data sequences, learning in neural networks can be unstable. Recurrent states in vanilla recurrent neural networks (RNNs) are generated by repeatedly applying a linear transformation followed by a pointwise nonlinearity. This becomes unstable when the linear transformation’s eigenvalues are not of magnitude one. \n Unitary matrices have been utilized to solve the problem of disappearing and exploding gradients because they have eigenvalues of size one, naturally, and have been. Unitary convolutional layers have recently been developed in a similar way to aid in the development of more stable deep networks with norm-preserving transformations.\n The loss function’s derivative with respect to the weights is called a gradient. During backpropagation in neural networks, it is utilized to update the weights to minimize the loss function. When traveled backward with each layer, the derivative or slope continuously grows lower, resulting in a vanishing gradient. When the weight update is exponentially small, the training time is excessively long. In the worst-case scenario, the neural network training may be stopped entirely. Exploding gradients, on the other hand, occur when the slope increases with each successive layer during backpropagation. The gradient will never converge due to the high weights, causing it to oscillate around the minima without ever reaching a global minima point.\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.05483.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u0a6yb/researchers_including_yann_lecun_propose_projunn/",
          "publishedOn": "2022-04-10T04:38:13.000Z",
          "wordCount": 356,
          "title": "Researchers, Including Yann Lecun, Propose ‘projUNN’: An Efficient Method For Training Deep Neural Networks With Unitary Matrices",
          "imageUrl": "https://external-preview.redd.it/o0w2ACco6ahv9HPmDnR1JTzTJTnvsfgeKCHmFS_1ptY.jpg?auto=webp&s=78456ccf137182dae6e1b3a442bf1fd39de42e0b"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tz32az/dense_passage_retrieverdpr_openqa_system/",
          "author": null,
          "description": "Hi, I made a video explaining Dense Passage Retriever(DPR) paper. We specifically explain the End to End QA system suggested in the latter part of the paper which discusses how to build an Open-QA system using dense retrievers.\n DPR was one of the first papers that discussed building dense retrievers using QA pairs only and didn't require a big pretraining computational setup like ORQA or REALM. It is currently used in a lot of places as a dense retriever. You can find Hugginface and Haystack implementations also.\n This video is part of a series on Open-QA using dense retrievers. We have made 2 videos on DPR. In the latter, we discuss how to build a dense retriever from scratch. Thanks for the support and it would be great if you could give any feedback.\n https://www.youtube.com/watch?v=rvcyyJNjPU0\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tz32az/dense_passage_retrieverdpr_openqa_system/",
          "publishedOn": "2022-04-08T13:02:42.000Z",
          "wordCount": 236,
          "title": "Dense Passage Retriever(DPR) Open-QA System",
          "imageUrl": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?auto=webp&s=720b78add0a3005c4f67eaed6897df409cc040c6"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tye21i/nn_from_scratch_2_initializing_parameters/",
          "author": null,
          "description": "submitted by    /u/cjmodi306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tye21i/nn_from_scratch_2_initializing_parameters/",
          "publishedOn": "2022-04-07T14:17:46.000Z",
          "wordCount": 119,
          "title": "NN from Scratch: #2 Initializing parameters | Kolbenkraft",
          "imageUrl": "https://external-preview.redd.it/GDnb256QTkcz5l5-77Ys1KBOLyCpV-FhczyyfWFfFkc.jpg?auto=webp&s=6a5ee252a5d11d763b300637085189cc5d1e6e32"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/txw0eh/quick_little_keras_question/",
          "author": null,
          "description": "I tried posting this on stackoverflow with no response.\n Im trying to use model.save() and keras.models.load_model()\n on this chunk of code. But, unlike some of the other keras examples I've played with, this one seems to crash.\n I'm super new to this, any Ideas why? I can post the error message if it helps.\n    submitted by    /u/HoneyBunchsOGoats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/txw0eh/quick_little_keras_question/",
          "publishedOn": "2022-04-06T20:54:46.000Z",
          "wordCount": 152,
          "title": "Quick Little Keras Question",
          "imageUrl": "https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?auto=webp&s=0c3f0b8af92c3a962f569a389e9673597e12f8ec"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/txj3ng/driving_a_robot_with_a_neural_network_use_case/",
          "author": null,
          "description": "submitted by    /u/KamilBugnoKrk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/txj3ng/driving_a_robot_with_a_neural_network_use_case/",
          "publishedOn": "2022-04-06T10:32:23.000Z",
          "wordCount": 128,
          "title": "Driving a robot with a neural network - use case study",
          "imageUrl": "https://external-preview.redd.it/Fq_wbiH_-rAHehqwb2z9g9p99upgQ_6uTmjVCFPjpnY.jpg?auto=webp&s=8bbafc7b268f9f5020abd04de668308a7bef6957"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/txd4pu/heres_an_intuitive_explanation_to_singular_value/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/txd4pu/heres_an_intuitive_explanation_to_singular_value/",
          "publishedOn": "2022-04-06T03:45:33.000Z",
          "wordCount": 157,
          "title": "Here's an intuitive explanation to Singular Value Decomposition. 👇",
          "imageUrl": "https://external-preview.redd.it/yEZqz6bdYi9OxMbxSAun-NOOyBiIEWi0hgButp5s0Bc.jpg?auto=webp&s=7501076a2d95650e0f1222b249a18b18ee508c2e"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tx4n1h/mit_has_trained_ai_to_generate_new_molecular/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tx4n1h/mit_has_trained_ai_to_generate_new_molecular/",
          "publishedOn": "2022-04-05T20:44:31.000Z",
          "wordCount": 123,
          "title": "MIT has trained AI to generate new molecular materials",
          "imageUrl": "https://external-preview.redd.it/VN_AAlU77_6qR-oL5nPN_QANJIRFwqPXPJNyV8WUPTs.jpg?auto=webp&s=e73ced42586cfe5bf9c952d5ab49691b83ef1b02"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tw3wz6/composing_music_with_neural_networks/",
          "author": null,
          "description": "Hey guys,\n ​\n I really love creating music algorithmically, which is why I have dedicated my master’s thesis to the generation of music patterns by the use of artificial intelligence.\n In the course of the past 12 months, I have programmed a deep recurrent neural network in Python, which I have trained on 200 self-made music patterns in order to generate somehow novel motifs.\n ​\n In order to evaluate my model, I have set up a short online listening experiment.\n I’m looking for test subjects right now, so if you are interested in participating, I would really appreciate it.\n The listening experiment will take you just about 5 to 8 minutes to complete and the only thing you need is a pair of headphones.\n You can partake on your computer as well as on your smartphone or tablet.\n ​\n Here is the link which gets you to the listening experiment:\n https://forms.gle/rx1FUQ7RgpjMu1xx9\n ​\n Thank you very much for taking the time to help me reach my goal.\n Really appreciate it.\n    submitted by    /u/JosephdeLaquinta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tw3wz6/composing_music_with_neural_networks/",
          "publishedOn": "2022-04-04T14:51:18.000Z",
          "wordCount": 259,
          "title": "Composing Music with Neural Networks",
          "imageUrl": "https://external-preview.redd.it/b4i5Ja2AxLdJ3zGYml1UCPr28W8teB8EpstN8GR5Z98.jpg?auto=webp&s=4b023a0fd429d0e0c148e9fbe2fb9fb9971c0693"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tvneyx/blog_lets_manually_approximate_a_simple_function/",
          "author": null,
          "description": "submitted by    /u/rhkibria  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tvneyx/blog_lets_manually_approximate_a_simple_function/",
          "publishedOn": "2022-04-03T23:38:37.000Z",
          "wordCount": 126,
          "title": "Blog: Let’s manually approximate a simple function with a ReLU neural network",
          "imageUrl": "https://external-preview.redd.it/cFh6vbg55LHArRON3tZT-u8z_kSyTzhAnSPIpdI7W9o.jpg?auto=webp&s=3db3b3eeca270ba4a17260456a429f17a869f093"
        }
      ]
    },
    {
      "title": "Seita's Place",
      "feedUrl": "https://danieltakeshi.github.io/feed.xml",
      "siteUrl": "https://danieltakeshi.github.io/",
      "articles": [
        {
          "id": "https://danieltakeshi.github.io/2022/04/23/paper-reviewing-load/",
          "author": null,
          "description": "In academia, for better or worse, we have what’s called a peer review system,\nwhere papers get accepted to journals, conferences, or other venues on the\nbasis of reviews from other researchers, who ideally are subject area experts\nand thus are qualified to evaluate the paper. The reviewers also cannot have a\nconflict of interest with the authors, and should not be overwhelmed with too\nmany papers to review. This is the ideal world, and is not always what happens\nin practice.\nFrom my experience in the robotics academic community (and this may apply to\nother disciplines), it generally seems like there is no standard definition of\nan “appropriate” or “maximum” reviewing load for a reviewer. This is difficult\nto define as different papers mandate different reviewing efforts; a massive\njournal …",
          "link": "https://danieltakeshi.github.io/2022/04/23/paper-reviewing-load/",
          "publishedOn": "2022-04-23T12:00:00.000Z",
          "wordCount": 1083,
          "title": "My Paper Reviewing Load",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "VITALab",
      "feedUrl": "https://vitalab.github.io/feed.xml",
      "siteUrl": "https://vitalab.github.io/",
      "articles": [
        {
          "id": "https://vitalab.github.io/article/2022/04/14/MultiModalVersatileNetworks.html",
          "author": null,
          "description": "Highlights Introduce the notion of a MultiModal Versatile (MMV) network, that can ingest multiple modalities and outputs common representations useful for downstream tasks; The paper especially studies how best to combine the modalities, so that the common representations respect properties deemed useful by the authors. Introduce the process of deflation, to efficiently apply networks on video data to static images.",
          "link": "https://vitalab.github.io/article/2022/04/14/MultiModalVersatileNetworks.html",
          "publishedOn": "2022-04-14T00:00:00.000Z",
          "wordCount": 891,
          "title": "Self-Supervised MultiModal Versatile Networks",
          "imageUrl": null
        },
        {
          "id": "https://vitalab.github.io/article/2022/04/05/SparseMultiChannelVAE.html",
          "author": null,
          "description": "Highlights Extend the VAE framework to work with heterogeneous, i.e. multi-modal, data by projecting all “channels” to a common latent representation; Use variational dropout to learn sparse representation, which are useful to discover in an unsupervised manner the optimal number of dimensions, i.e. the number of ground truth generative factors.",
          "link": "https://vitalab.github.io/article/2022/04/05/SparseMultiChannelVAE.html",
          "publishedOn": "2022-04-05T00:00:00.000Z",
          "wordCount": 667,
          "title": "Sparse Multi-Channel Variational Autoencoder for the Joint Analysis of Heterogeneous Data",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Stories by Andrej Karpathy on Medium",
      "feedUrl": "https://medium.com/feed/@karpathy",
      "siteUrl": "https://medium.com/@karpathy?source=rss-ac9d9a35533e------2",
      "articles": []
    },
    {
      "title": "OpenAI",
      "feedUrl": "https://openai.com/blog/rss",
      "siteUrl": "https://openai.com/",
      "articles": [
        {
          "id": "6256f702f6721b003db4b685",
          "author": "Jacob Hilton",
          "description": "Goodhart’s law famously says: “When a measure becomes a target, it ceases to be a good measure.” Although originally from economics, it’s something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
          "link": "https://openai.com/blog/measuring-goodharts-law/",
          "publishedOn": "2022-04-13T18:00:00.000Z",
          "wordCount": 1270,
          "title": "Measuring Goodhart’s Law",
          "imageUrl": "https://openai.com/content/images/2021/08/openai-cover.png"
        },
        {
          "id": "624d5b837ce26d004d92d14d",
          "author": "OpenAI",
          "description": "DALL·E 2 is a new AI system that can create realistic images and art from a description in natural language.",
          "link": "https://openai.com/blog/dall-e-2/",
          "publishedOn": "2022-04-06T13:42:00.000Z",
          "wordCount": 722,
          "title": "DALL·E 2",
          "imageUrl": "https://openai.com/content/images/2022/04/dall-e-2-og.jpg"
        }
      ]
    },
    {
      "title": "Microsoft Research",
      "feedUrl": "https://www.microsoft.com/en-us/research/feed",
      "siteUrl": "https://www.microsoft.com/en-us/research",
      "articles": [
        {
          "id": "https://www.microsoft.com/en-us/research/?p=835453",
          "author": "Alyssa Hughes",
          "description": "Drug discovery has come a long way from its roots in serendipity. It is now an increasingly rational process, in which one important phase, called lead optimization, is the stepwise search for promising drug candidate compounds in the lab. In this phase, expert medicinal chemists work to improve “hit” molecules—compounds that demonstrate some promising properties, […]\nThe post MoLeR: Creating a path to more efficient drug design appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/moler-creating-a-path-to-more-efficient-drug-design/",
          "publishedOn": "2022-04-27T16:00:00.000Z",
          "wordCount": 1937,
          "title": "MoLeR: Creating a path to more efficient drug design",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2022/04/1200x627_stills_moler_blog_with_logo.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=837610",
          "author": "Alyssa Hughes",
          "description": "Picture a person walking in a park by a pond. The surrounding environment contains a number of moving objects that change the quality of the environment: clouds moving to hide the sun, altering the quality of light; ducks gliding across the pond, causing its surface to ripple; people walking along a path, their images reflecting […]\nThe post PPE: A fast and provably efficient RL algorithm for exogenous noise appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/ppe-a-fast-and-provably-efficient-rl-algorithm-for-exogenous-noise/",
          "publishedOn": "2022-04-25T16:00:00.000Z",
          "wordCount": 2805,
          "title": "PPE: A fast and provably efficient RL algorithm for exogenous noise",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2022/04/1200x627_Exo_MDP_still_with_logo.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=834184",
          "author": "Alyssa Hughes",
          "description": "Edge computing has come of age, with deployments enabling many applications that process data from IoT sensors and cameras. In 2017, we identified the symbiotic relationship between edge computing and video analytics in an article, noting that live video analytics is the “killer app” for edge computing. Edge devices come in various shapes and sizes […]\nThe post Don’t let data drift derail edge compute machine learning models appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/dont-let-data-drift-derail-edge-compute-machine-learning-models/",
          "publishedOn": "2022-04-19T16:00:00.000Z",
          "wordCount": 1415,
          "title": "Don’t let data drift derail edge compute machine learning models",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2022/04/1200x627_Live_analytics_still_with_logo_TW_FB.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=834241",
          "author": "Alyssa Hughes",
          "description": "Episode 135 | April 13, 2022 In “Just Tech: Centering Community-Driven Innovation at the Margins,” Senior Principal Researcher Mary L. Gray explores how technology and community intertwine and the role technology can play in supporting community-driven innovation and community-based organizations. Dr. Gray and her team are working to bring computer science, engineering, social science, and […]\nThe post Just Tech: Centering Community-Driven Innovation at the Margins Episode 3 with Dr. Sasha Costanza-Chock appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/just-tech-centering-community-driven-innovation-at-the-margins-episode-3-with-dr-sasha-costanza-chock/",
          "publishedOn": "2022-04-13T13:00:00.000Z",
          "wordCount": 9339,
          "title": "Just Tech: Centering Community-Driven Innovation at the Margins Episode 3 with Dr. Sasha Costanza-Chock",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2022/04/Mary_Sasha_1200x627_WithLogo.jpg"
        }
      ]
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "http://feeds.feedburner.com/blogspot/gJZg",
      "siteUrl": "http://ai.googleblog.com/",
      "articles": [
        {
          "id": "http://ai.googleblog.com/2022/04/extracting-skill-centric-state.html",
          "author": null,
          "description": "Posted by Dhruv Shah, Intern, and Brian Ichter, Research Scientist, Robotics at Google \nAdvances in reinforcement learning (RL) for robotics have enabled robotic agents to perform increasingly complex tasks in challenging environments. Recent results show that robots can learn to fold clothes, dexterously manipulate a rubik’s cube, sort objects by color, navigate complex environments and walk on difficult, uneven terrain. But \"short-horizon\" tasks such as these, which require very little long-term planning and provide immediate failure feedback, are relatively easy to train compared to many tasks that may confront a robot in a real-world setting. Unfortunately, scaling such short-horizon skills to the abstract, long horizons of real-world tasks is difficult. For example, how would one trai…",
          "link": "http://ai.googleblog.com/2022/04/extracting-skill-centric-state.html",
          "publishedOn": "2022-04-29T17:02:00.001Z",
          "wordCount": 2139,
          "title": "Extracting Skill-Centric State Abstractions from Value Functions",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/google-at-iclr-2022.html",
          "author": null,
          "description": "Posted by Cat Armato and Callan Hajosy, Program Managers \nThe 10th International Conference on Learning Representations (ICLR 2022) kicks off this week, bringing together researchers, entrepreneurs, engineers and students alike to discuss and explore the rapidly advancing field of deep learning. Entirely virtual this year, ICLR 2022 offers conference and workshop tracks that present some of the latest research in deep learning and its applications to areas ranging from computer vision, speech recognition and text understanding to robotics, computational biology, and more. \n As a Platinum Sponsor of ICLR 2022 and Champion DEI Action Fund contributor, Google will have a robust presence with nearly 100 accepted publications and extensive participation on organizing committees and in workshops…",
          "link": "http://ai.googleblog.com/2022/04/google-at-iclr-2022.html",
          "publishedOn": "2022-04-25T19:46:00.000Z",
          "wordCount": 3492,
          "title": "Google at ICLR 2022",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/pix2seq-new-language-interface-for.html",
          "author": null,
          "description": "Posted by Ting Chen and David Fleet, Research Scientists, Google Research, Brain Team \nObject detection is a long-standing computer vision task that attempts to recognize and localize all objects of interest in an image. The complexity arises when trying to identify or localize all object instances while also avoiding duplication. Existing approaches, like Faster R-CNN and DETR, are carefully designed and highly customized in the choice of architecture and loss function. This specialization of existing systems has created two major barriers: (1) it adds complexity in tuning and training the different parts of the system (e.g., region proposal network, graph matching with GIOU loss, etc.), and (2), it can reduce the ability of a model to generalize, necessitating a redesign of the model for…",
          "link": "http://ai.googleblog.com/2022/04/pix2seq-new-language-interface-for.html",
          "publishedOn": "2022-04-22T20:17:00.000Z",
          "wordCount": 2099,
          "title": "Pix2Seq: A New Language Interface for Object Detection",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/hidden-interfaces-for-ambient-computing.html",
          "author": null,
          "description": "Posted by Alex Olwal, Research Scientist, Google Augmented Reality and Artem Dementyev, Hardware Engineer, Google Research \nAs consumer electronics and internet-connected appliances are becoming more common, homes are beginning to embrace various types of connected devices that offer functionality like music control, voice assistance, and home automation. A graceful integration of devices requires adaptation to existing aesthetics and user styles rather than simply adding screens, which can easily disrupt a visual space, especially when they become monolithic surfaces or black screens when powered down or not actively used. Thus there is an increasing desire to create connected ambient computing devices and appliances that can preserve the aesthetics of everyday materials, while providing …",
          "link": "http://ai.googleblog.com/2022/04/hidden-interfaces-for-ambient-computing.html",
          "publishedOn": "2022-04-21T19:59:00.001Z",
          "wordCount": 2057,
          "title": "Hidden Interfaces for Ambient Computing",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/formnet-beyond-sequential-modeling-for.html",
          "author": null,
          "description": "Posted by Chen-Yu Lee and Chun-Liang Li, Research Scientists, Google Research, Cloud AI Team \nForm-based document understanding is a growing research topic because of its practical potential for automatically converting unstructured text data into structured information to gain insight about a document’s contents. Recent sequence modeling, which is a self-attention mechanism that directly models relationships between all words in a selection of text, has demonstrated state-of-the-art performance on natural language tasks. A natural approach to handle form document understanding tasks is to first serialize the form documents (usually in a left-to-right, top-to-bottom fashion) and then apply state-of-the-art sequence models to them.  \n However, form documents often have more complex layouts …",
          "link": "http://ai.googleblog.com/2022/04/formnet-beyond-sequential-modeling-for.html",
          "publishedOn": "2022-04-20T20:36:00.000Z",
          "wordCount": 2463,
          "title": "FormNet: Beyond Sequential Modeling for Form-Based Document Understanding",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/learning-to-prompt-for-continual.html",
          "author": null,
          "description": "Posted by Zifeng Wang, Student Researcher, and Zizhao Zhang, Software Engineer, Google Research\nSupervised learning is a common approach to machine learning (ML) in which the model is trained using data that is labeled appropriately for the task at hand. Ordinary supervised learning trains on independent and identically distributed (IID) data, where all training examples are sampled from a fixed set of classes, and the model has access to these examples throughout the entire training phase. In contrast, continual learning tackles the problem of training a single model on changing data distributions where different classification tasks are presented sequentially. This is particularly important, for example, to enable autonomous agents to process and interpret continuous streams of informati…",
          "link": "http://ai.googleblog.com/2022/04/learning-to-prompt-for-continual.html",
          "publishedOn": "2022-04-19T17:00:00.002Z",
          "wordCount": 2213,
          "title": "Learning to Prompt for Continual Learning",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/locked-image-tuning-adding-language.html",
          "author": null,
          "description": "Posted by Andreas Steiner and Basil Mustafa, Research Software Engineers at Google Research, Brain team \nThe ability to classify images into categories has been transformed by deep learning. It has also been significantly accelerated by transfer learning, whereby models are first pre-trained on large datasets, like ImageNet, to learn visual representations that are then transferred via fine-tuning to a new task with less data (e.g., classifying animals). Previous works such as BiT and ViT employed these methods to achieve state-of-the-art performance on a wide range of classification tasks, such as the VTAB benchmark. \nHowever, fine-tuning has some downsides: though pre-training is done only once, fine-tuning is necessary on every new dataset for which task-specific data is needed. Multimo…",
          "link": "http://ai.googleblog.com/2022/04/locked-image-tuning-adding-language.html",
          "publishedOn": "2022-04-14T21:41:00.000Z",
          "wordCount": 2116,
          "title": "Locked-image Tuning: Adding Language Understanding to Image Models",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/simple-and-effective-zero-shot-task.html",
          "author": null,
          "description": "Posted by Jeffrey Zhao and Raghav Gupta, Software Engineers, Google Research \nModern conversational agents need to integrate with an ever-increasing number of services to perform a wide variety of tasks, from booking flights and finding restaurants, to playing music and telling jokes. Adding this functionality can be difficult — for each new task, one needs to collect new data and retrain the models that power the conversational agent. This is because most task-oriented dialogue (TOD) models are trained on a single task-specific ontology. An ontology is generally represented as a list of possible user intents (e.g., if the user wants to book a flight, if the user wants to play some music, etc.) and possible parameter slots to extract from the conversation (e.g., the date of the flight, the…",
          "link": "http://ai.googleblog.com/2022/04/simple-and-effective-zero-shot-task.html",
          "publishedOn": "2022-04-13T17:06:00.001Z",
          "wordCount": 2336,
          "title": "Simple and Effective Zero-Shot Task-Oriented Dialogue",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/lidar-camera-deep-fusion-for-multi.html",
          "author": null,
          "description": "Posted by Yingwei Li, Student Researcher, Google Cloud and Adams Wei Yu, Research Scientist, Google Research, Brain Team  \nLiDAR and visual cameras are two types of complementary sensors used for 3D object detection in autonomous vehicles and robots. LiDAR, which is a remote sensing technique that uses light in the form of a pulsed laser to measure ranges, provides low-resolution shape and depth information, while cameras provide high-resolution shape and texture information. While the features captured by LiDAR and cameras should be merged together to provide optimal 3D object detection, it turns out that most state-of-the-art 3D object detectors use LiDAR as the only input. The main reason is that to develop robust 3D object detection models, most methods need to augment and transform th…",
          "link": "http://ai.googleblog.com/2022/04/lidar-camera-deep-fusion-for-multi.html",
          "publishedOn": "2022-04-12T19:58:00.000Z",
          "wordCount": 2297,
          "title": "Lidar-Camera Deep Fusion for Multi-Modal 3D Detection",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/large-scale-matrix-factorization-on-tpus.html",
          "author": null,
          "description": "Posted by Harsh Mehta, Software Engineer, Google Research \nMatrix factorization is one of the oldest, yet still widely used, techniques for learning how to recommend items such as songs or movies from user ratings. In its basic form, it approximates a large, sparse (i.e., mostly empty) matrix of user-item interactions with a product of two smaller, denser matrices representing learned item and user features. These dense matrices, in turn, can be used to recommend items to a user with which they haven't interacted before. \nDespite its algorithmic simplicity, matrix factorization can still achieve competitive performance in recommender benchmarks. Alternating least squares (ALS), and especially its implicit variation, is a fundamental algorithm to learn the parameters of matrix factorization…",
          "link": "http://ai.googleblog.com/2022/04/large-scale-matrix-factorization-on-tpus.html",
          "publishedOn": "2022-04-08T17:52:00.006Z",
          "wordCount": 2555,
          "title": "Large-Scale Matrix Factorization on TPUs",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/vdtts-visually-driven-text-to-speech.html",
          "author": null,
          "description": "Posted by Tal Remez, Software Engineer, Google Research and Micheal Hassid, Software Engineer Intern, Google Research   \nRecent years have seen a tremendous increase in the creation and serving of video content to users across the world in a variety of languages and over numerous platforms. The process of creating high quality content can include several stages from video capturing and captioning to  video and audio editing. In some cases dialogue is re-recorded (referred to as dialog replacement, post-sync or dubbing) in a studio in order to achieve high quality and replace original audio that might have been recorded in noisy conditions. However, the dialog replacement process can be difficult and tedious because the newly recorded audio needs to be well synced with the video, requiring …",
          "link": "http://ai.googleblog.com/2022/04/vdtts-visually-driven-text-to-speech.html",
          "publishedOn": "2022-04-07T20:45:00.000Z",
          "wordCount": 2033,
          "title": "VDTTS: Visually-Driven Text-To-Speech",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html",
          "author": null,
          "description": "Posted by Ikechukwu Uchendu, AI Resident and Ted Xiao, Software Engineer, Robotics at Google \nReinforcement learning (RL) can be used to train a policy to perform a task via trial and error, but a major challenge in RL is learning policies from scratch in environments with hard exploration challenges. For example, consider the setting depicted in the door-binary-v0 environment from the adroit manipulation suite, where an RL agent must control a hand in 3D space to open a door placed in front of it. \n   \n\n\nAn RL agent must control a hand in 3D space to open a door placed in front of it. The agent receives a reward signal only when the door is completely open.\n\n   \nSince the agent receives no intermediary rewards, it cannot measure how close it is to completing the task, and so must explore …",
          "link": "http://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html",
          "publishedOn": "2022-04-06T14:38:00.001Z",
          "wordCount": 2291,
          "title": "Efficiently Initializing Reinforcement Learning With Prior Policies",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/reproducibility-in-deep-learning-and.html",
          "author": null,
          "description": "Posted by Gil Shamir and Dong Lin, Research Software Engineers, Google Research \nEver queried a recommender system and found that the same search only a few moments later or on a different device yields very different results? This is not uncommon and can be frustrating if a person is looking for something specific. As a designer of such a system, it is also not uncommon for the metrics measured to change from design and testing to deployment, bringing into question the utility of the experimental testing phase. Some level of such irreproducibility can be expected as the world changes and new models are deployed. However, this also happens regularly as requests hit duplicates of the same model or models are being refreshed.  \nLack of replicability, where researchers are unable to reproduce…",
          "link": "http://ai.googleblog.com/2022/04/reproducibility-in-deep-learning-and.html",
          "publishedOn": "2022-04-05T17:41:00.000Z",
          "wordCount": 2730,
          "title": "Reproducibility in Deep Learning and Smooth Activations",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html",
          "author": null,
          "description": "Posted by Sharan Narang and Aakanksha Chowdhery, Software Engineers, Google Research \nIn recent years, large neural networks trained for language understanding and generation have achieved impressive results across a wide range of tasks. GPT-3 first showed that large language models (LLMs) can be used for few-shot learning and can achieve impressive results without large-scale task-specific data collection or model parameter updating. More recent LLMs, such as GLaM, LaMDA, Gopher, and Megatron-Turing NLG, achieved state-of-the-art few-shot results on many tasks by scaling model size, using sparsely activated modules, and training on larger datasets from more diverse sources. Yet much work remains in understanding the capabilities that emerge with few-shot learning as we push the limits of …",
          "link": "http://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html",
          "publishedOn": "2022-04-04T16:01:00.007Z",
          "wordCount": 2737,
          "title": "Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        }
      ]
    },
    {
      "title": "fast.ai",
      "feedUrl": "https://www.fast.ai/atom.xml",
      "siteUrl": "http://www.fast.ai/atom.xml",
      "articles": []
    },
    {
      "title": "Reinforcement Learning",
      "feedUrl": "https://www.reddit.com/r/reinforcementlearning/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/reinforcementlearning/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uh1ick/what_background_knowledge_is_needed_to_understand/",
          "author": null,
          "description": "I can understand most traditional and current methods of reinforcement learning, however when it comes to traditional exploration methods such as UCB or PUCB I am mostly lost. I can understand the algorithms intuitively when explained, but when I go over the papers and look at the proofs/explanations there seems to be some background knowledge I am not privy to. The book Reinforcement Learning: An Introduction doesn't seem to go over these in-depth as well.\n BTW I have a bachelor's and master's degree in Computer Science and have taken math classes such as statistics, calculus, LA, algorithms, ect.\n    submitted by    /u/Stochastic_Machine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uh1ick/what_background_knowledge_is_needed_to_understand/",
          "publishedOn": "2022-05-02T22:29:30.000Z",
          "wordCount": 308,
          "title": "What background knowledge is needed to understand traditional exploration methods?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ugw4yy/help_needed_to_understand_rllib_attention_model/",
          "author": null,
          "description": "Hi!\n I recently started to learn about using attention (transformers). I use rllib implementation (https://docs.ray.io/en/latest/rllib/rllib-models.html#default-model-config-settings) which follows some paper. So far I have some understanding of transformers but I still don't understand everything. When playing with parameters I saw couple which I don't understand how these affect the learning and what they exactly do ( I looked at code and paper but still don't understand).\n Can somebody explain what are these and how these affect the learning:\n 1) attention_memory_inference\n 2) attention_memory_training\n (also related to previous point: when training why attention_memory_training and input sequence are concated? https://github.com/ray-project/ray/blob/master/rllib/models/torch/attention_net.py#L91 )\n Many thanks :D\n    submitted by    /u/HBlackwooder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ugw4yy/help_needed_to_understand_rllib_attention_model/",
          "publishedOn": "2022-05-02T18:24:19.000Z",
          "wordCount": 218,
          "title": "Help needed to understand Rllib attention model parameters",
          "imageUrl": "https://external-preview.redd.it/monRChpWeEpgh-ITtM5VrcvGGxRZX6-cbL_9uRyl4Z0.jpg?auto=webp&s=fd3a15979ff0f64e72058cc0e95d2b930222c479"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ugv1vc/is_this_how_a_simple_parallel_environment/",
          "author": null,
          "description": "I tried to figure out how to do parallel environment training using TD3 or DDPG but just got bits and pieces of information, so this is what I came up with. This is what I have (a Unity \"ant\" environment):\n One ant in one environment\n But I want this:\n Parallel ants in multiple environments\n As a result, I can learn faster because I have more data. So here's how I envision parallel training:\n  \nAgents collect actions from one TD3/DDPG model.\n Collect observations from all agents and put them into the memory buffer. Do 1 and 2 steps until every agent finishes its episode. If the agent finished its episode ahead of other agents, it simply waits.\n Then comes the training DDPG/TD3 step. And repeat.\n  \nWould this type of training even work?\n    submitted by    /u/Dougller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ugv1vc/is_this_how_a_simple_parallel_environment/",
          "publishedOn": "2022-05-02T17:36:02.000Z",
          "wordCount": 304,
          "title": "Is this how a simple parallel environment training works in DDPG/TD3 model?",
          "imageUrl": "https://external-preview.redd.it/0L5Y0_4RhBfWnObmqSlpghzXL9pTI5mHx2_GEcK4Q74.jpg?auto=webp&s=8ad691fdd5473ebdfe17ccd71e155b4d2e945e1a"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ugpkk2/unity_with_mlagents_isaac_gym_openai_gym_and/",
          "author": null,
          "description": "Hello, I am a master's student in computer science and I am specializing in artificial intelligence. I am approaching reinforcement learning for the first time in an intelligent robotics course, and would like to experiment with these techniques in a simulated environment. I'm looking for something that is not too complex to learn (I want to focus more on algorithm implementation and simulation rather than spending months figuring out the tool) and that gives enough freedom to modify and implement. Unity seemed interesting because a possible application of these techniques that I would like to explore is in the world of gaming and simulation, but I do not know if a solid knowledge of Unity is required to set up a decent environment before you can get into the experiments. Moreover, I don't know up to what level of detail is possible to enter in the case of MLAgents and how much is possible to customize. Do you recommend one of these that I proposed in the title or also other? Also, do you recommend some material (books, videos, courses, tutorials) to study that is a good compromise between explanation of the tool and theoretical part?\n Thanks in advance!\n    submitted by    /u/Parruck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ugpkk2/unity_with_mlagents_isaac_gym_openai_gym_and/",
          "publishedOn": "2022-05-02T13:24:17.000Z",
          "wordCount": 518,
          "title": "Unity with MLAgents, Isaac Gym, OpenAI Gym and other environments to experiment with reinforcement learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ugl74u/creating_custom_environment_for_training_rl_agent/",
          "author": null,
          "description": "Hi, I'm working on a project on 2d image reassembly using reinforcement learning. I want to create a custom (puzzle) environment for doing RL. Is there anyway to create a custom environment that can be integrated with gym. If so, how to create one? Thanks.\n    submitted by    /u/Praveen_Raja22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ugl74u/creating_custom_environment_for_training_rl_agent/",
          "publishedOn": "2022-05-02T08:47:10.000Z",
          "wordCount": 262,
          "title": "creating custom environment for training RL agent",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ug78jp/open_ai_gym_lunar_lander_dqn_reinforcement/",
          "author": null,
          "description": "submitted by    /u/elonmusk12345_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ug78jp/open_ai_gym_lunar_lander_dqn_reinforcement/",
          "publishedOn": "2022-05-01T19:22:31.000Z",
          "wordCount": 233,
          "title": "Open AI GYM Lunar Lander DQN Reinforcement Learning Algorithm Performance After 100 000 Timesteps",
          "imageUrl": "https://external-preview.redd.it/GoPHKIH6C6kdl7GfVNoPzLxeNl4bQb9s0NtqlL8Awro.jpg?auto=webp&s=4d37aab9b872a68e3b5d7f9c2d84d3c1a55f4207"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ug6uhb/adversarial_attacks_using_reinforcement_learning/",
          "author": null,
          "description": "Hi All,\n I have been looking a bit into adversarial attacks on NNs recently. Particularly in the NLP side of things. I also came across some papers about adversarial attacks on RL algorithms. But these were about attacks ON reinforcement learning algorithms and not USING them to attack something else. I tried to find some papers on RL agents as attackers but came out empty. \n Intuitively, I do realize that designing an adversarial example generator as an RL env is tricky, even more so for NLP.\n Do you think this is a feasible research direction? Also, any related papers to get myself on the starting line would be super helpful. \n Thanks in advance.\n    submitted by    /u/abyaadrafid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ug6uhb/adversarial_attacks_using_reinforcement_learning/",
          "publishedOn": "2022-05-01T19:03:41.000Z",
          "wordCount": 226,
          "title": "Adversarial Attacks using Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ug4w1m/is_it_possible_to_modify_the_reward_function/",
          "author": null,
          "description": "I am currently implementing an idea where I want the agent to get a large reward for objective A at the start of training, but as the agent learns and gets more mature, I want the reward for this objective to reduce slightly. \n Is this sort of thing easy to implement? Is it possible?\n Any help on this would be great :)\n Thanks\n    submitted by    /u/C_BearHill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ug4w1m/is_it_possible_to_modify_the_reward_function/",
          "publishedOn": "2022-05-01T17:32:11.000Z",
          "wordCount": 305,
          "title": "Is it possible to modify the reward function during training of an agent using OpenAI/Stable-Baselines3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ug3wel/question_about_the_curriculum_learning/",
          "author": null,
          "description": "Hi,\n this so called curriculum learning sounds very interesting. But, how would the practical usage of this technique look like?\n Assuming the goal task is \"grasping an apple\". I would divide this task into two subtasks: \n 1) \"How to approach to an apple\" \n 2) \"How to grasp an object\". \n Then, I would first train the agent with the first subtask and once the reward exceeds the threshold. The trained \"how_to_approach_to_an_object.pth\" would then be initially used to start the training for the second task.\n Is this the right approach?\n    submitted by    /u/Fun-Moose-3841  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ug3wel/question_about_the_curriculum_learning/",
          "publishedOn": "2022-05-01T16:45:27.000Z",
          "wordCount": 231,
          "title": "Question about the curriculum learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ufwcrb/how_to_structure_tile_coding_input/",
          "author": null,
          "description": "Let's say I have a model that wants to encode the observation space using tile coding. \n My observation space is a football (soccer) game, thus I was thinking of having 3 different tile codings. One for the player position, one for the team mates, and one for the opponents. Each one would encode the position and general direction of each category of player. Which is the best way to then feed this data into an RL model ? \n Let's say I split the the pitch into 16 tiles, and I am using 4 grids. Thus I would have an array of length 64. Since I wish to encode multiple inputs, should I just append 3 different length 64 arrays together, or is there a more efficient way to represent multiple tile encodings, or is my entire proposition wrong altogether?\n Thanks\n    submitted by    /u/uom_questions  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ufwcrb/how_to_structure_tile_coding_input/",
          "publishedOn": "2022-05-01T09:34:53.000Z",
          "wordCount": 297,
          "title": "How to structure Tile Coding input",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ufllbp/osu/",
          "author": null,
          "description": "Was thinking of coding an rl agent that learns to play osu, but stuck on wrapping the program in a gym environment. If anyone is interested and could help me out please dm me\n    submitted by    /u/apple-soda-ds  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ufllbp/osu/",
          "publishedOn": "2022-04-30T22:24:30.000Z",
          "wordCount": 139,
          "title": "osu!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ufkaza/are_there_any_other_highquality_prebuilt_python/",
          "author": null,
          "description": "submitted by    /u/elonmusk12345_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ufkaza/are_there_any_other_highquality_prebuilt_python/",
          "publishedOn": "2022-04-30T21:18:09.000Z",
          "wordCount": 202,
          "title": "Are there any other high-quality pre-built Python training environments other than Open AI's GYM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ufjqul/shortcomings_of_robotics_simulation_environments/",
          "author": null,
          "description": "submitted by    /u/probznotarobot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ufjqul/shortcomings_of_robotics_simulation_environments/",
          "publishedOn": "2022-04-30T20:49:22.000Z",
          "wordCount": 296,
          "title": "Shortcomings of Robotics Simulation Environments and Tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ufgmc8/seeking_advice_in_designing_reward_function/",
          "author": null,
          "description": "Hi all,\n I am trying to introduce reinforcement learning to myself by designing simple learning scenarios:\n As you can see below, I am currently working with a simple 3 degree of freedom robot. The task that I gave the robot to explore is to reach the sphere with its end-effector. In that case, the cost function is pretty simple :\n reward_function = d \n Now, I would like to complex the task a bit more by saying: \"First, approach the goal just by using q1 and then use q2 and q3, if any distance remains\"\n I am not how to formulate this sequential movement of q1 and q2,q3 as a reward function...any advice?\n https://preview.redd.it/klwne9fthpw81.png?width=690&format=png&auto=webp&s=ba53ad800884f90778f60d9ea5e152df94331cd9\n    submitted by    /u/Fun-Moose-3841  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ufgmc8/seeking_advice_in_designing_reward_function/",
          "publishedOn": "2022-04-30T18:09:41.000Z",
          "wordCount": 340,
          "title": "Seeking advice in designing reward function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ufgcz5/bellman_equation/",
          "author": null,
          "description": "To evaluate a policy, we need t calculate the value of a state s as the weighted sum of the reward and the discounted estimated value of the next state s. However, I don't understand how we can obtain the discounted estimated value of the next state s.\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ufgcz5/bellman_equation/",
          "publishedOn": "2022-04-30T17:56:57.000Z",
          "wordCount": 296,
          "title": "Bellman equation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uffmrb/advice_for_my_uni_dissertation_wanted/",
          "author": null,
          "description": "I have built a neural network to try and solve a reinforcement learning problem, attempting both the Reinforce and the A2C algorithm to try and solve a resource management problem. \n The results are very mediocre after running on the Uni super computer for a week.\n I was hoping someone could give me some advice on an algorithm or technique that is better suited to the problem or give some positive criticism.\n I have found that a very simple algorithmic solution that I wrote is able to get a better reward at the game than the networks after their week of training :(\n TLDR I get bad results when I run the reinforcement leaning Neural Networks for a larger environment. I was thinking maybe something like pre training the critic against an algorithmically generated evaluation may work to massi…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uffmrb/advice_for_my_uni_dissertation_wanted/",
          "publishedOn": "2022-04-30T17:20:05.000Z",
          "wordCount": 711,
          "title": "Advice for my uni dissertation wanted!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ufazvv/how_do_you_stay_updated_with_rl/",
          "author": null,
          "description": "So, I was wondering how you guys stay updated with RL. Apart from reading papers, is there any news letter you are subscribed to ? Any slack channel, facebook group, twitter account or any other community out there you want to suggest ?\n ​\n TIA\n    submitted by    /u/AbdullahMohammadKhan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ufazvv/how_do_you_stay_updated_with_rl/",
          "publishedOn": "2022-04-30T13:22:45.000Z",
          "wordCount": 183,
          "title": "How do you stay updated with RL ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uf8mml/custom_gym_env_for_movie_recommender_system/",
          "author": null,
          "description": "Hi everyone, \n I am new to RL so your help would be much appreciated. I’m working on a recommender system using Deep Reinforcement Learning. I made a custom gym environment, that implements Openai’s Gym interface, for the MovieLens dataset. The dataset contains users’ ratings for movies ( ranging from 1 to 5).\n I used some of the Stable Baselines3’s reinforcement learning algorithms (A2C, PP0) to test my environment before I proceed to implement my own.\n Running a training recipe, I noticed that both the agents (A2C, PPO) will recommend only action =3, after a number of timesteps. That seems a bit odd and I can’t find where is the bug.\n My first thought is that it has to do with the reward function. Currently, I'm using the following function to calculate rewards.\n ​\n https://preview.redd.it/6r3lf9z9bnw81.png?width=550&format=png&auto=webp&s=103d270ebe8c08b753c9033b60066794a586e3fa\n This is the GitHub link to my code. \n Am I missing something? Any thoughts?\n Thank you in advance\n    submitted by    /u/Narrow-Style497  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uf8mml/custom_gym_env_for_movie_recommender_system/",
          "publishedOn": "2022-04-30T10:46:39.000Z",
          "wordCount": 400,
          "title": "Custom Gym Env for movie recommender system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uf7sip/nlp_startup_ideas/",
          "author": null,
          "description": "Anybody got startup ideas in nlp. Do share , if interested let’s collab\n    submitted by    /u/thoughtfulcomet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uf7sip/nlp_startup_ideas/",
          "publishedOn": "2022-04-30T09:42:04.000Z",
          "wordCount": 140,
          "title": "NLP startup ideas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uf5gss/a_survey_what_should_we_expect_from_multiagent/",
          "author": null,
          "description": "We are doing a survey related to multi-agent reinforcement learning systems and benchmarks and would love to hear your opinion.\n This survey has 3 questions and will take about 10 seconds to complete.\n We really appreciate your participation.\n The survey URL is here.\n    submitted by    /u/TTTheohhhu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uf5gss/a_survey_what_should_we_expect_from_multiagent/",
          "publishedOn": "2022-04-30T06:37:25.000Z",
          "wordCount": 178,
          "title": "A survey: what should we expect from multi-agent reinforcement learning benchmarking work?",
          "imageUrl": "https://external-preview.redd.it/GT2-qqUAf2OY0_Z0EOuQd0DPGRJwuY1kU6mDvaf10cs.jpg?auto=webp&s=4b428afd40f77da5e306a91f010c0271f5f7aaa1"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uf56wb/object_detection_with_depth_measurement_using/",
          "author": null,
          "description": "🚀 New Post: Object Detection with Depth Perception\n https://learnopencv.com/object-detection-with-depth-measurement-with-oak-d/\n ​\n https://preview.redd.it/zikmf13fzlw81.jpg?width=3000&format=pjpg&auto=webp&s=484a7d8a80d5c0ff594e5fe6178b94a7783a1e65\n Spatial AI is the ability of an artificial intelligence system to reason not just based on what it is looking at, but also based on distance from the camera (or depth perception).\n ​\n OpenCV AI Kit with Depth (OAK-D) is a powerful yet affordable Spatial AI camera perfect for people who want to learn how to combine the power of neural networks with depth perception.\n ​\n Today's post is part of our series on OAK-D\n https://learnopencv.com/introduction-to-opencv-ai-kit-and-depthai/\n https://learnopencv.com/stereo-vision-and-depth-estimation-using-opencv-ai-kit/\n ​\n Code Link : https://github.com/spmallick/learnopencv/tree/master/OAK-Object-Detection-with-Depth\n ​\n #AI #ComputerVision #ML #ArtificialIntelligence #MachineLearning #OpenCV #DL #DeepLearning #OAKD\n    submitted by    /u/spmallick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uf56wb/object_detection_with_depth_measurement_using/",
          "publishedOn": "2022-04-30T06:16:48.000Z",
          "wordCount": 219,
          "title": "Object detection with depth measurement using pre-trained models with OAK-D",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uf320u/what_is_the_difference_between_the_environment/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uf320u/what_is_the_difference_between_the_environment/",
          "publishedOn": "2022-04-30T03:57:39.000Z",
          "wordCount": 210,
          "title": "What is the difference between the environment state and the agent state?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uexgz4/playing_chess_with_offline_reinforcement_learning/",
          "author": null,
          "description": "submitted by    /u/Bellerb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uexgz4/playing_chess_with_offline_reinforcement_learning/",
          "publishedOn": "2022-04-29T22:39:21.000Z",
          "wordCount": 175,
          "title": "Playing Chess With Offline Reinforcement Learning",
          "imageUrl": "https://external-preview.redd.it/DEyZafPTL7oofghZ6GtFQs54KGuOmp0erNZkINvlPwU.jpg?auto=webp&s=5e31e889b97f61381213f0940a606320e781d15f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ueph94/how_to_use_rl_for_combinatorial_optimization/",
          "author": null,
          "description": "I am trying to use reinforcement for combinatorial optimization. I coded up a toy example for the travelling salesman but I am confused by something. In stable baselines 3 there is a variable \"done\". If I set it to optimum value (that is the length of the shortest route through all the cities computer by a different method) the RL algorithm never finds it. What should done be set to? Or more generally how do you do optimization of this sort using RL.\n I can just set it so that it is done after 1000 steps but then it is spending a lot of time finding the best way to take the first 1000 steps which isn't quite the point.\n    submitted by    /u/wiggyhat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ueph94/how_to_use_rl_for_combinatorial_optimization/",
          "publishedOn": "2022-04-29T16:16:31.000Z",
          "wordCount": 580,
          "title": "How to use RL for combinatorial optimization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ueorbx/can_agents_act_simultaneously_with_no_notion_of/",
          "author": null,
          "description": "I was reading this paper and in section 3 they claim that agents act simultaneously and there is no notion of turn-taking:\n https://arxiv.org/abs/2104.07750 \n I was wondering how this works. What I'm used to seeing is a for loop in which, one after the other, agents execute the step function and interact with the environment. How does this change if all agents act simultaneously?\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ueorbx/can_agents_act_simultaneously_with_no_notion_of/",
          "publishedOn": "2022-04-29T15:43:46.000Z",
          "wordCount": 273,
          "title": "Can agents act simultaneously with no notion of turn-taking?",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ueiogy/how_to_mitigate_catastrophic_forgetting_for_an/",
          "author": null,
          "description": "Hello everyone.\n I built a use case to instruct an agent, which simulates a herd of predators, to encircle a prey. Episodes are non-terminal and have a fixed number of steps.\n The agent uses a neural network to decide which actions to take at each step and is instructed by a remember/replay mechanism using a memory of past events.\n I started the experiment using absolute coordinates in the state returned by the environment and the result is displayed in the following image, where the total reward values at the end of each episode ​​are displayed.\n https://preview.redd.it/oscet38c0gw81.png?width=640&format=png&auto=webp&s=092fc92ee56c919bdc1851bb9f1ef9bdc585bfde\n In this case the results were encouraging.\n However, I wanted to create a more generic use case, using vectors that represent the position of the prey with respect to predators instead of absolute coordinates, in order to make the task more generic.\n Unfortunately, the best result I was able to obtain is the one shown in the image below where, apparently, I have a deterioration after a certain number of episodes.\n ​\n https://preview.redd.it/yoiygwxe0gw81.png?width=640&format=png&auto=webp&s=06b7082cc0ebb80e3f5e5ce8307d75cd6451f79b\n It seems to me a case of catastrophic forgetting (I could be wrong) and I managed to mitigate it by increasing the memory, retaining the results of the older episodes, lowering the learning rate of the neural network and using a learning decay algorithm, but I have not succeeded to eliminate the phenomenon completely.\n Anyone have any advice?\n    submitted by    /u/kaeldric__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ueiogy/how_to_mitigate_catastrophic_forgetting_for_an/",
          "publishedOn": "2022-04-29T10:13:36.000Z",
          "wordCount": 510,
          "title": "How to mitigate catastrophic forgetting for an intelligent agent using replay memory and Deep Reinforcement Learning algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uehru4/speeding_up_custom_implementations/",
          "author": null,
          "description": "Hi all! I've been implementing some of the model-free algorithms in recent times. Comparing their performance to open-source libraries, however, learning takes severely longer in a computational sense. \n I wonder what tricks libraries such as stable-baselines3 use to increase frames per seconds and accelerate policy updates. So far, I vectorized the environment sampling & the bottleneck seems to be computing the updates for the agent.\n Thanks a lot!\n    submitted by    /u/Internal-Brush4929  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uehru4/speeding_up_custom_implementations/",
          "publishedOn": "2022-04-29T09:05:03.000Z",
          "wordCount": 180,
          "title": "Speeding up custom implementations.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uef8ng/any_blog_or_video_series_that_is_available_to_run/",
          "author": null,
          "description": "submitted by    /u/ajithvallabai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uef8ng/any_blog_or_video_series_that_is_available_to_run/",
          "publishedOn": "2022-04-29T05:55:40.000Z",
          "wordCount": 194,
          "title": "Any blog or video series that is available to run TD3 algorithm for path planning purpose . Trained agents deployed in hardware level",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ue9riy/microsoft_ai_researchers_introduce_ppe_a/",
          "author": null,
          "description": "Reinforcement learning (RL) is a machine learning training strategy that rewards desirable behaviors while penalizing undesirable ones. A reinforcement learning agent can perceive and comprehend its surroundings, act, and learn through trial and error in general. Although RL agents can heuristically solve some problems, such as assisting a robot in navigating to a specific location in a given environment, there is no guarantee that they will be able to handle problems in settings they have not yet encountered. The capacity of these models to recognize the robot and any obstacles in its path, but not changes in its surrounding environment that occur independently of the agent, which we refer to as exogenous noise, is critical to their success. \n Existing RL algorithms are not powerful enoug…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ue9riy/microsoft_ai_researchers_introduce_ppe_a/",
          "publishedOn": "2022-04-29T00:48:32.000Z",
          "wordCount": 491,
          "title": "Microsoft AI Researchers Introduce PPE: A Mathematically Guaranteed Reinforcement learning (RL) Algorithm For Exogenous Noise",
          "imageUrl": "https://external-preview.redd.it/F3t9Ukl12gT9QhuKQLbIlJ2YvgJPl9JcKinEZswn3Gk.jpg?auto=webp&s=43a64e7ca4d38ac22c1133ee625b89a9d955f2a9"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ue7w37/decision_transformers_with_hugging_face/",
          "author": null,
          "description": "submitted by    /u/hellopaperspace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ue7w37/decision_transformers_with_hugging_face/",
          "publishedOn": "2022-04-28T23:09:32.000Z",
          "wordCount": 118,
          "title": "Decision Transformers with Hugging Face",
          "imageUrl": "https://external-preview.redd.it/9idirh8sMLCE2fy7qhmgCc_ma3Zp8VCDviKTBJY2Epk.jpg?auto=webp&s=0558dab6482d0aa975df88cd9b98f9c95cf15eac"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ue1zx6/how_do_you_get_a_global_observation/",
          "author": null,
          "description": "Naive question: how do you pass a global observation of the environment to your actor and critic? In other words, is a global observation always available or does it depend on the environment? Can you give me a couple of examples? Thanks :)\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ue1zx6/how_do_you_get_a_global_observation/",
          "publishedOn": "2022-04-28T18:40:28.000Z",
          "wordCount": 288,
          "title": "How do you get a global observation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/udvu2o/why_do_monte_carlo_methods_have_low_bias_compared/",
          "author": null,
          "description": "submitted by    /u/aabra__ka__daabra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/udvu2o/why_do_monte_carlo_methods_have_low_bias_compared/",
          "publishedOn": "2022-04-28T14:07:17.000Z",
          "wordCount": 272,
          "title": "Why do Monte Carlo methods have low bias compared to TD methods in RL. Does the bias term in RL has same meaning as in general in ML terminology?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uduqy9/2nd_neural_mmo_challenge_is_out_design_your/",
          "author": null,
          "description": "submitted by    /u/xiaolongzhu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uduqy9/2nd_neural_mmo_challenge_is_out_design_your/",
          "publishedOn": "2022-04-28T13:15:29.000Z",
          "wordCount": 299,
          "title": "2nd Neural MMO challenge is out! Design your policy to master PvE and PvP challenge.",
          "imageUrl": "https://external-preview.redd.it/-8iGSgifPYDndEDJdI9kHsAFIe45becvP4NLbDFcjOw.jpg?auto=webp&s=8726ba85b6a7ede1cfab0affce4bcfe227cb2864"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/udsij3/parallel_environments_affect_q_learning/",
          "author": null,
          "description": "Parallel environments can make the learning much more efficient, but sometimes using parallel environments seemed affect the performance.\n Does anyone know why and how to solve?\n    submitted by    /u/Traditional-Ad4492  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/udsij3/parallel_environments_affect_q_learning/",
          "publishedOn": "2022-04-28T11:09:43.000Z",
          "wordCount": 157,
          "title": "Parallel environments affect Q learning performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/udrmdg/papers_for_green_vehicle_routing_problem/",
          "author": null,
          "description": "My current work requires me to work with GVRP. The specific problem is for an EV (agent) to find the optimal route to deliver items based on charge consumption and not discharging. I'm currently modelling it as a graph datastructure although it could be different.\n Are there any papers (both RL and exact method based) for state of the art that I can look into regarding this. I'm also interested in earlier papers that can help me build understanding, and I can increase complexity slowly.\n Thanks for the help!\n    submitted by    /u/evilBotman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/udrmdg/papers_for_green_vehicle_routing_problem/",
          "publishedOn": "2022-04-28T10:09:44.000Z",
          "wordCount": 207,
          "title": "Papers for Green Vehicle Routing Problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/udrdss/what_is_the_current_sota_for_singlethreaded/",
          "author": null,
          "description": "As above. I am interested in RL for robotics, specifically for legged locomotion. I wish to explore RL training on the real robot. Sample efficiency is paramount.\n Has any progress been made by utilizing, say, RNNs/LSTMs or even Attention ?\n    submitted by    /u/pakodanomics  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/udrdss/what_is_the_current_sota_for_singlethreaded/",
          "publishedOn": "2022-04-28T09:52:25.000Z",
          "wordCount": 218,
          "title": "What is the current SOTA for single-threaded continuous-action control using RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/udrd45/is_it_possibleuseful_to_allow_the_agent_to/",
          "author": null,
          "description": "In my current environment, the agent is fed observations from a particular mathematical computation based upon the underlying state. This mathematical computation has hyper-parameters that influence the resulting observation given to the agent.\n Does it make any sense whatsoever to give these hyper-parameters to the agent within the action space? In this way the agent would be able to adjust its future observations and perhaps it would be able to use this in a smart way. On the other hand, I've heard that changing the environment from under the agents feed during training can lead to major issues with training. One can imagine that learning a dynamic environment is harder than a static one.\n Any thoughts?\n    submitted by    /u/C_BearHill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/udrd45/is_it_possibleuseful_to_allow_the_agent_to/",
          "publishedOn": "2022-04-28T09:50:56.000Z",
          "wordCount": 258,
          "title": "Is it possible/useful to allow the agent to influence the observations in later timesteps?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/udowuk/treequeues_transfert_jax_pytrees_between/",
          "author": null,
          "description": "Hello!\n If you are using jax and you need to pass some pytrees between processes, I may have something for you :)\n I developed a \"treequeue\". It is a queue that is made for pytree's nested arrays.\n The transfer speed is up to 10 times higher than regular queues. This is done by utilizing shared memory arrays and avoiding pickling data. This can be very useful when developing distributed architecture, e.g. distributed reinforcement learning where speed is at the upmost importance.\n In my case this implementation was very useful to remove bottlenecks when implementing RL PBT algorithms!\n https://github.com/thomashirtz/treequeues\n Cheers!\n    submitted by    /u/krenast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/udowuk/treequeues_transfert_jax_pytrees_between/",
          "publishedOn": "2022-04-28T06:48:58.000Z",
          "wordCount": 225,
          "title": "treequeues: transfert jax pytrees between processes with very high speed!",
          "imageUrl": "https://external-preview.redd.it/vUzbotJ19HlzoJm8yf74Kfr7OP0PUpggx2GJM-BWrcY.jpg?auto=webp&s=6d44bea3732291b32642ccb9b8c4b2d6cca67e13"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/udkp3n/could_you_recommend_a_paper_on_selfsupervised_rl/",
          "author": null,
          "description": "Hi, I have problems the agent forgets good states during self-supervised pre-training. It shows good exploration, but as time goes by, only the edge case is explored, showing poor performance at finetune. I found a paper about that before, but It is really hard to find again. It related to reward. Could you recommend a paper related to this? Thanks for reading.\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/udkp3n/could_you_recommend_a_paper_on_selfsupervised_rl/",
          "publishedOn": "2022-04-28T02:38:05.000Z",
          "wordCount": 351,
          "title": "Could you recommend a paper on self-supervised RL related to catastrophic forgetting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/udgdsk/220212742_learning_relative_return_policies_with/",
          "author": null,
          "description": "submitted by    /u/chimp73  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/udgdsk/220212742_learning_relative_return_policies_with/",
          "publishedOn": "2022-04-27T23:00:04.000Z",
          "wordCount": 124,
          "title": "[2202.12742] Learning Relative Return Policies With Upside-Down Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/udexwq/what_does_it_mean_to_centralise_the_observation/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/udexwq/what_does_it_mean_to_centralise_the_observation/",
          "publishedOn": "2022-04-27T21:53:03.000Z",
          "wordCount": 212,
          "title": "What does it mean to centralise the observation in MARL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ud7492/offpolicy_algorithm_with_batch_of_actions/",
          "author": null,
          "description": "Hello everyone, first of all sorry for my poor English. \n I am fairly new to Deep RL, and RL in general. I want to implement custom environment with multiple robots in it. Each robot would be given same task to do, so what I am trying to do is simulate parallelism. \n My question is: if i have 100 robots in simulation, do i have to instantiate 100 agents (neural networks) to control those robots or single network with batch size of 100 will suffice? Does batch of observations in anyway disturbs agent action (network) output? It would be much more memory efficient with single neural network. \n So far, I've seen that in process of acting in env agent takes observation of batch size 1 and outputs corresponding action for that observation. Since each observation from the batch is propagated trough the network without calculating gradient it should not be affected by the batch size. If anyone could explain to me if my way of thinking is wrong, and why. :)\n    submitted by    /u/Dexter_fixxor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ud7492/offpolicy_algorithm_with_batch_of_actions/",
          "publishedOn": "2022-04-27T16:07:20.000Z",
          "wordCount": 305,
          "title": "Off-policy algorithm with batch of actions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ud463w/neupl_neural_population_learning_liu_et_al_2022/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ud463w/neupl_neural_population_learning_liu_et_al_2022/",
          "publishedOn": "2022-04-27T13:56:08.000Z",
          "wordCount": 164,
          "title": "\"NeuPL: Neural Population Learning\", Liu et al 2022 (encoding PBT agents into a single multi-policy agent)",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ud1lck/how_do_actorcritic_networks_reduce_the_variance/",
          "author": null,
          "description": "i understand about why REINFORCE has high variance but how does AC mitigates it ?\n    submitted by    /u/aabra__ka__daabra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ud1lck/how_do_actorcritic_networks_reduce_the_variance/",
          "publishedOn": "2022-04-27T11:43:59.000Z",
          "wordCount": 445,
          "title": "How do Actor-Critic networks reduce the variance compared to other PG method like Reinforce ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ud1hy8/onpolicy_vs_offpolicy/",
          "author": null,
          "description": "I'm looking to find the concrete explanation and difference of on-policy and off-policy learning strategy if possible mathematics can alao be explained.\n    submitted by    /u/Western-Age3148  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ud1hy8/onpolicy_vs_offpolicy/",
          "publishedOn": "2022-04-27T11:38:36.000Z",
          "wordCount": 311,
          "title": "on-policy vs off-policy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uczncj/open_position_at_zf_friedrichshafen_ag/",
          "author": null,
          "description": "Feel free to apply! \n Algorithmenentwickler-AI-&-Machine-Learning-Motion-Planning\n    submitted by    /u/gab_ma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uczncj/open_position_at_zf_friedrichshafen_ag/",
          "publishedOn": "2022-04-27T09:36:09.000Z",
          "wordCount": 136,
          "title": "Open position at ZF Friedrichshafen AG- Algorithmenentwickler AI & ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uczllh/internshipsthesis_in_the_field_of_ai_zf/",
          "author": null,
          "description": "We are currently offering Internships & Theses in the Field of Artificial Intelligence. Here are the links to our open positions. Feel free to share the post! ✌🏽\n Mandatory Internship Software Development in the field of Artificial Intelligence\n Pflichtpraktikant Reinforcement Learning Algorithmen\n Pflichtpraktikum/ Masterarbeit: Reinforcement Learning\n    submitted by    /u/gab_ma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uczllh/internshipsthesis_in_the_field_of_ai_zf/",
          "publishedOn": "2022-04-27T09:32:26.000Z",
          "wordCount": 189,
          "title": "Internships/Thesis in the field of AI @ZF",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ucu7ii/general_questions_for_those_of_you_up_to_date_on/",
          "author": null,
          "description": "What does the future of deep reinforcement learning look like? I feel like people were pretty hyped about it a year or two ago. Is it heavily researched now and expected to be used more in the future?\n What are some real world tasks that it can help with? I've seen it used a lot for playing games, self driving cars, and manufacturing robotics. Anything else that it can be applied to? Will it likely be used for autonomous robots when they become more common?\n What are some areas that can be improved upon? What are the most recent advancements and what is a good topic to focus on for future research? \n Thank you.\n    submitted by    /u/johnGettings  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ucu7ii/general_questions_for_those_of_you_up_to_date_on/",
          "publishedOn": "2022-04-27T03:27:35.000Z",
          "wordCount": 639,
          "title": "General questions for those of you up to date on the topic.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uciqkm/reward_after_each_action_vs_reward_after_taking/",
          "author": null,
          "description": "Hello, I am working on compression of deep neural networks using reinforcement learning. There is one agent that learns to compress convolutional layers using C actions and another one that compresses dense layers using D actions. If there are two conv layers and 3 dense layers, 5 actions have to be selected in a sequence using both agents in order to fully compress the model. I read the paper AdaDeep and found it really useful for my research, but I don't get why the authors select all actions and they only calculate the reward after completely compressing the network instead of getting the reward after each action. In their place I would select the action, calculate the reward of that action and store it in the replay. By only using immediate reward, the agent should be able to learn which sequence of actions would work the best for the current model. Why assign the same reward to the selected actions for each layer? Is it only because the outcome was due to the combination of actions and they want to speed up training? If my understanding is correct, assigning the immediate reward to each action would yield the same results in the long run. Thanks in advance.\n    submitted by    /u/ElvishChampion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uciqkm/reward_after_each_action_vs_reward_after_taking/",
          "publishedOn": "2022-04-26T18:06:10.000Z",
          "wordCount": 360,
          "title": "Reward after each action vs reward after taking all actions in an episodic environment of N steps",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ucddkm/multi_agent_rl_agents_act_in_different_frequencies/",
          "author": null,
          "description": "After reading D, Multi's post, I'm wondering is it possible that two different agents to take action in their own action space & their own frequency?\n    submitted by    /u/YMXin1999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ucddkm/multi_agent_rl_agents_act_in_different_frequencies/",
          "publishedOn": "2022-04-26T14:07:02.000Z",
          "wordCount": 2,
          "title": "Multi Agent RL: agents act in different frequencies?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uc5ilk/im_going_to_build_a_game_where_the_goal_will_be/",
          "author": null,
          "description": "The environment makes a lot of sense to me, as a human. It’s a network composed of nodes and edges. Nodes are the points in the network, and edges are the lines connecting them. The entire thing resembles a real street network and uses coordinate points to position itself on a graph. \n Of the entire map, select nodes will represent gas stations, and other select nodes will represent stop locations for deliveries. The agent will start at a node and map a route to each location, essentially by stringing together an array of connected edges. It’ll also need to travel to gas stations every X miles or it’ll run out of gas.\n Now, I’ve never done this before so I’m gonna bounce some of my ideas off a wall here Passing the entire thing to an agent and having it render a graph and whatnot to determ…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uc5ilk/im_going_to_build_a_game_where_the_goal_will_be/",
          "publishedOn": "2022-04-26T05:44:05.000Z",
          "wordCount": 580,
          "title": "I’m going to build a game where the goal will be making many deliveries using the shortest route. How might the environment best be represented to the agent?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uc379f/what_is_a_train_step_counter/",
          "author": null,
          "description": "In this repository that I'm looking at, there's an input variable whose meaning I don't understand. \n At line 135: https://github.com/google-research/google-research/blob/722494ce68130a7409bf94500002c79014905d53/social_rl/multiagent_tfagents/multiagent_ppo.py#L135 \n train_step_counter: An optional counter to increment every time the train op is run. Defaults to the global_step. \n What is train_step_counter?\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uc379f/what_is_a_train_step_counter/",
          "publishedOn": "2022-04-26T03:23:26.000Z",
          "wordCount": 233,
          "title": "What is a train step counter?",
          "imageUrl": "https://external-preview.redd.it/X3zv-sSrruppOpsxiQrUq7LzYMAD3Qzg_fvfA6f1aPc.jpg?auto=webp&s=6087c858b5df6e1067e735775ba0f264a19149dd"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uc0j1x/exponential_weighted_average/",
          "author": null,
          "description": "hey guys I guess this can be trivial for the most of you but I can't get around it, how do I prove this is an exponential weighted average. Thanks \n The equation is labeled (10) in the link https://chowdera.com/2021/12/202112200806190809.html\n from reinforcement learning: an introduction by Sutton and barto , tracking a non stationary problem in chapter 2\n    submitted by    /u/ma7modbasha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uc0j1x/exponential_weighted_average/",
          "publishedOn": "2022-04-26T01:04:23.000Z",
          "wordCount": 233,
          "title": "exponential weighted average",
          "imageUrl": "https://external-preview.redd.it/mv_Fap0Sey2Cp63Y5xhuYO_COxbWTtY83IgkX9-OA80.jpg?auto=webp&s=539a81cfaab29d9d933116574be22aff23babcd1"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ubutae/simplegrid_env_for_openai_gym/",
          "author": null,
          "description": "SimpleGrid is a simple gridworld environment for OpenAI gym. It is easy to use and customise and it is intended to offer an environment for quick testing and prototyping different RL algorithms.\n I developed this environment by taking inspiration from the FrozenLake environment and gym-minigrid.\n Check it out at: https://github.com/damat-le/gym-simplegrid \n ​\n https://i.redd.it/prqd7muujqv81.gif\n    submitted by    /u/damat-le  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ubutae/simplegrid_env_for_openai_gym/",
          "publishedOn": "2022-04-25T20:35:38.000Z",
          "wordCount": 165,
          "title": "SimpleGrid env for OpenAI gym",
          "imageUrl": "https://external-preview.redd.it/gpXDjPtzrQ4uB0KUJ9Eee72ko4HdjowDCqncDIuOyHs.jpg?auto=webp&s=55f4064641a4461901156317e2950669080c7500"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ubtsms/hybrid_cpu_topology_impact_on_training/",
          "author": null,
          "description": "Hi, some newer CPU's (Apple M1, Intel Alder Lake) have started using a hybrid CPU topology. I.e. the CPU consists of some P-cores (high performance cores) and E-cores (slower 'eco' cores).\n I personally do not own such a CPU yet but I'm considering upgrading to one soon, so I am looking for experiences of people with such a CPU on training reinforcement models. Does everything work as expected? Are there annoyances?\n I'm using Ray Tune + RLlib in which I assign a single core per trial. In this case I'm expecting that trials running on E-cores will simply run (much) slower than those running on P-cores.\n In case a single trial gets assigned both a P-core and an E-core, I do expect a serious slow-down. \n These are all guesses really, so I'm looking for people with actual experience here.\n Thanks.\n    submitted by    /u/katsu9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ubtsms/hybrid_cpu_topology_impact_on_training/",
          "publishedOn": "2022-04-25T19:52:44.000Z",
          "wordCount": 255,
          "title": "Hybrid CPU topology impact on training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ubt5d9/policy_iteration_on_openai_gym_taxiv3/",
          "author": null,
          "description": "Hey everyone,\n I managed to implement the policy iteration from Sutton & Barto, 2018 on the FrozenLake-v1 and wanted to do the same now Taxi-v3 environment.\n My code has been running now for 45min so I guess there is something wrong, but I can't wrap my head around what it could be.\n Would appreciate some input on what I need to change so that it will work.\n Please see my code here:\n ```[python] import gym # openAi gym import torch import matplotlib.pyplot as plt from tqdm import trange # progressbar\n torch.manual_seed(4)\n env = gym.make('Taxi-v3')\n def policy_evaluation(env: gym.Env, policy: torch.Tensor, gamma: float, threshold: float): V = torch.zeros(env.observation_space.n) delta = float(\"inf\")\n while delta >= threshold: V_tmp = torch.empty(env.observation_space.n) for state in range(…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ubt5d9/policy_iteration_on_openai_gym_taxiv3/",
          "publishedOn": "2022-04-25T19:24:30.000Z",
          "wordCount": 360,
          "title": "Policy Iteration on OpenAI Gym taxi-v3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ublwii/iclr_2022_blog_post_the_37_implementation_details/",
          "author": null,
          "description": "submitted by    /u/vwxyzjn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ublwii/iclr_2022_blog_post_the_37_implementation_details/",
          "publishedOn": "2022-04-25T14:03:28.000Z",
          "wordCount": 206,
          "title": "ICLR 2022 Blog Post: The 37 Implementation Details of Proximal Policy Optimization",
          "imageUrl": "https://external-preview.redd.it/mnqsJgvqnJ7C9UGpRKUPXClOhXWXQpHOa5Hw_cL9jh4.jpg?auto=webp&s=ed6dce0956e984c7158effce70004b4f1cd84111"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ubkuyi/deep_reinforcement_learning_free_class_by_hugging/",
          "author": null,
          "description": "Hey there!\n We're happy to announce the launch of the Hugging Face Deep Reinforcement Learning class! 🤗\n 👉 Register here https://forms.gle/oXAeRgLW4qZvUZeu9\n In this free course, you will:\n  \n📖 Study Deep Reinforcement Learning in theory and practice.\n 🧑‍💻 Learn to use famous Deep RL libraries such as Stable Baselines3, RL Baselines3 Zoo, and RLlib.\n 🤖 Train agents in unique environments with SnowballFight, Huggy the Doggo 🐶, and classical ones such as Space Invaders and PyBullet.\n 💾 Publish your trained agents in one line of code to the Hub. But also download powerful agents from the community.\n 🏆 Participate in challenges where you will evaluate your agents against other teams.\n 🖌️🎨 Learn to share your environments made with Unity and Godot.\n  \n👉 Register here https://forms.gle/oXAeRgLW4qZvUZeu9 \n 📚 The syllabus: https://github.com/huggingface/deep-rl-class\n https://preview.redd.it/b409a9sscov81.jpg?width=1920&format=pjpg&auto=webp&s=ebdfa10c220b5a3dec17894bc0f955ed9d8f7634\n If you have questions and feedback, I would love to answer them,\n Thanks,\n    submitted by    /u/cranthir_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ubkuyi/deep_reinforcement_learning_free_class_by_hugging/",
          "publishedOn": "2022-04-25T13:12:44.000Z",
          "wordCount": 343,
          "title": "Deep Reinforcement Learning Free Class by Hugging Face 🤗",
          "imageUrl": "https://external-preview.redd.it/2wdTcEJ0ttsp8lXt2MUVuD9v97RFJQScTaDHj11vpiE.jpg?auto=webp&s=a166d13a790c6c1f1e9ea548b898ef43c67e0bf2"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ubh59n/has_anyone_solved_deepmind_control_locomotion_in/",
          "author": null,
          "description": "Hi, I'm wondering if I could train the state-based locomotion well from the scratch. In my case, I trained SAC agent and It showed divergence of the q function. I think the cause is the unscaled vector input. Before the trouble shooting, I want to ask someone trained agent in this environment. Thank you for reading.\n https://github.com/deepmind/dm_control/tree/main/dm_control/locomotion\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ubh59n/has_anyone_solved_deepmind_control_locomotion_in/",
          "publishedOn": "2022-04-25T09:33:01.000Z",
          "wordCount": 216,
          "title": "Has anyone solved deepmind control locomotion in state-based?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ub872r/cant_solve_openai_problems/",
          "author": null,
          "description": "I started off with OpenAI's mountain car, and I don't know where to even start. I got the setup working with the environment, but now have no idea how to train it. How do I learn to code for RL? Every tutorial I have seen so far has implemented Q Learning algorithms completely with little explanation. I looked at the solved code and it doesn't make sense to me. How should I prepare before I go into OpenAI?\n    submitted by    /u/TrepidationTD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ub872r/cant_solve_openai_problems/",
          "publishedOn": "2022-04-25T00:18:18.000Z",
          "wordCount": 192,
          "title": "Can't solve OpenAI problems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ub5wlq/projects_to_jump_into_rl/",
          "author": null,
          "description": "I have some experience with ML but not at all with RL. I know basic theory and want to just get started with the programming part. I saw OpenAI's gym, but I want to learn RL that can be applied anywhere. I don't want to be specifically constrained to OpenAI's gym and want something where I can apply it to game development, such as Unity. Are there any good resources to just do an RL project?\n    submitted by    /u/TrepidationTD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ub5wlq/projects_to_jump_into_rl/",
          "publishedOn": "2022-04-24T22:20:01.000Z",
          "wordCount": 305,
          "title": "Projects to jump into RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ub1m74/n_step_prioritized_replay_buffer/",
          "author": null,
          "description": "I have a few questions about implementing the N Step version of Prioritized Replay Buffer (for Rainbow DQN). I'm implementing the Atari version of this buffer. To conserve memory, I'm only storing the states (and the last state of each episode) in an unstacked manner. That is, if the frame stack is 4, and the shape of states returned by the environment is 4, I'm storing only the last state of the stacked states. This way the buffer contains all transitions from each episode. As for the N Steps part, I'm only calculating the n_step states when getting states from the buffer instead of storing the N Step transitions directly.\n  \nFor the prioritized version, how do the priorities work? If I wasn't trying to conserve memory, I would have stored the N Step stacked states directly and update the priorities for the segment trees and the segment tree pointers only when moving the data from the N Step buffer to the main buffer. But now that I'm calculating the N Step experience directly when sampling and not when adding data to the buffer, when do I update the priorities and the tree pointer? Once per state? Once per stacked state? Once per N Step stacked state?\n When I update the priorities for the sampled batch, the priorities are associated with multiple states (because the states are stacked). But because I don't store the stacked states and only the raw unstacked states, to which of these states should I update the priority for? And because I don't store the n step transitions anymore, to which of the N Steps should the priorities be associated with?\n If I want to create such a buffer for a vector env, how would I go about doing it? I'm thinking of maintaining a separate segment tree for each env. Is that correct? Is there a better way?\n  \n   submitted by    /u/SirRantcelot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ub1m74/n_step_prioritized_replay_buffer/",
          "publishedOn": "2022-04-24T18:57:39.000Z",
          "wordCount": 426,
          "title": "N Step Prioritized Replay Buffer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uazsx5/confused_between_centralized_critic_and/",
          "author": null,
          "description": "I don't understand if having a centralized critic in multi-agent RL is the same as having a centralized training decentralized execution approach. Can you help me clarify this?\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uazsx5/confused_between_centralized_critic_and/",
          "publishedOn": "2022-04-24T17:33:04.000Z",
          "wordCount": 208,
          "title": "Confused between \"centralized critic\" and \"centralized training decentralized execution\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uazrqw/theres_a_yo_mama_joke_in_their_somewhere/",
          "author": null,
          "description": "submitted by    /u/boss_007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uazrqw/theres_a_yo_mama_joke_in_their_somewhere/",
          "publishedOn": "2022-04-24T17:31:32.000Z",
          "wordCount": 162,
          "title": "There's a \"Yo Mama\" joke in their somewhere!!",
          "imageUrl": "https://preview.redd.it/liccxu0ciiv81.png?auto=webp&s=24048a2310cf6d051e401576e6d750499cc4139c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uay0nz/algorithms_for_decision_making_kochenderfer_et_al/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uay0nz/algorithms_for_decision_making_kochenderfer_et_al/",
          "publishedOn": "2022-04-24T16:07:19.000Z",
          "wordCount": 173,
          "title": "_Algorithms for Decision Making_, Kochenderfer et al 2022 (textbook draft; more classical ML than S&B)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uawexa/solving_a_large_dynamic_maze_using_dqn_reward/",
          "author": null,
          "description": "Consider a fixed maze with size (100x400) and fixed start and endpoints (1,1) and (99,399), where doors dynamically appear around the agent every time an observation has been made. The doors disapear after some time step n (for simplicity say n=1). For pitty sake lets say the optimum path length is 1000 steps and there is only one way to reach it.\n I have two questions: \n (1) What would be the most appropriate way to frame reward function? I have tested both volatile aproach (i.e. episodeis terminated if agent steps into wall or previosuly made path, otherwise is rewarded in \"cheese\" every 5 steps) and not-so-volatile approach (i.e. free roam for maximum 2000 steps with cheese reward every 5 steps). Evidently these do not work, are there other perhaps more promising approaches or such large mazes?\n (2) Does the colour of objects in a frame matter to the (convolutional) DQN's learning of the maze. Considering a 3 channel RGB input, is there perhaps a smarter way to colour code the walls/emptypath/etc.? Its a bit of a weird question but my curiosity arises from short-term memory examples (namely, space invaders) where the input, multiple greyscale frames, is chosen over one rgb frame - so to this degree channels can be understood as higher-level \"features\" of a frame, hence, can the colours of different objects be optimised? If so is there a logical way of viewing such optimisation?\n Any other advice is always welcome :)\n ​\n N.B. yes, this could probably be solved with other easier methods but lets just say DQN (or other deep-Q alternatives) is needed.\n    submitted by    /u/Background-Cable-491  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uawexa/solving_a_large_dynamic_maze_using_dqn_reward/",
          "publishedOn": "2022-04-24T14:51:51.000Z",
          "wordCount": 628,
          "title": "Solving a large (dynamic) maze using DQN (reward & observation)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uaruyn/rl_for_classification_problems/",
          "author": null,
          "description": "Hello, I aim to use RL in for classification problem, But I can't see where is the difference between using RL and other ML algorithms that are used in classification (such as MLP, KNN, SVM ..) since we have a train phase in which we teach an agent ( or ML algorithm) the classe of each sample of a labeled dataset. Ok the manner of teching is different but the concept is the same. Then, in a second phase, we test the model with a test set.\n My question is, if I choose RL for classification problem, what is the contribution that we can have compared to another algorithm?\n    submitted by    /u/fatenLouati  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uaruyn/rl_for_classification_problems/",
          "publishedOn": "2022-04-24T10:27:06.000Z",
          "wordCount": 613,
          "title": "RL for classification problems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uan8q9/design_of_next_observation_when_collision_for_2d/",
          "author": null,
          "description": "Hi, I am trying to create a continuous 2d maze environment. I tried several algorithms but no one can give me a stable 1 success rate. From time to time, it gets stuck around the obstacle corner and fails to move anymore. Like the picture shows below. I guess it relates to my bad design for giving the next observation for an action that can't make the agent move forward. Currently, my design evenly separates the action into 10 substeps, and returns the observation which corresponds to the step right before the agent meets an obstacle.\n It looks like I won't have this issue for mujoco environment like Ant. But it is really hard to see their design.\n https://preview.redd.it/swohj8h8qev81.png?width=282&format=png&auto=webp&s=7353a62e99ff2141b3660c68ae34ce4f5cd9b94f\n    submitted by    /u/AnimatorRemarkable20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uan8q9/design_of_next_observation_when_collision_for_2d/",
          "publishedOn": "2022-04-24T05:01:42.000Z",
          "wordCount": 249,
          "title": "Design of next observation when collision for 2d continuous maze",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uakmma/why_cant_we_make_a_perfect_ai_for_starcraft/",
          "author": null,
          "description": "First of all, let's discuss what the level of AI is now. If the \"level\" refers to the capability of competing, the current AI has been very closed to the top human player in some types of games, like chess, Texas Poker, and Mahjong of CARDS, DOTA2 of MOBA, as well as StarCraft2 of RTS. As for other games, if we have enough human resources and computing performance, we also can get similar results. If the \"level\" has other meanings, like AI agents having human behavior, intelligent NPC can be designed specifically for different people so that they can have different gaming experience. These are all at the stage of issue-defining and exploring new technology solutions. Although traditional game AI is mostly based on hard code, it still has much prior knowledge. In recent years, some hot ML-r…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uakmma/why_cant_we_make_a_perfect_ai_for_starcraft/",
          "publishedOn": "2022-04-24T02:20:33.000Z",
          "wordCount": 1325,
          "title": "Why can't we make a perfect AI for Starcraft through evolution",
          "imageUrl": "https://external-preview.redd.it/9-HMFHEQ4L6sBMqRkJB8id6O45bMpO6XS_4ZcKXO0Yk.jpg?auto=webp&s=cdcf97f6d0db6f8bef41564f1fc1df2fae35bac2"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uadeqk/how_to_stop_stable_baseline_model_during_the/",
          "author": null,
          "description": "I am training PPO2 model on stable-baseline library. I have tabular data with 15000 rows, thus length of the episodes is 15000. I am using nminibatches=4, n_envs=1. For example, I have set total_timesteps=10000. During the training process agent will see 15000 rows several times and updates actions for each rows, but in some particular point, the rest of the time total_timesteps will not be enough to see the full episode, and only part of episodes is available in the last step of learning. To be concrete. For simplicity, lets say we have 10 raws, 23 total_timesteps. The agent will see the full episode 2 times, and only the first 3 rows in the third times and rest of the 7 raws have not seen during last step.\n I want to stop the learning process when Agent reaches the last time full episodes (above example stop learning at when total_timesteps=20) or define total_timesteps in such a way to see full episodes at the end of the training step.\n    submitted by    /u/Mariam_Dundua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uadeqk/how_to_stop_stable_baseline_model_during_the/",
          "publishedOn": "2022-04-23T19:54:42.000Z",
          "wordCount": 338,
          "title": "How to stop stable baseline model during the training exactly at the end of frame?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uaa4jr/new_to_rl/",
          "author": null,
          "description": "Hello guys, I am pretty new to the rl field and write now i am doing my thesis in it. I've come across a problem in my code. I created a custom environment and when i am trying to solve it with my dqn agent using stable baselines3, I am able to execute the code and print out the required things but the agent is not learning. Any help ? thanks.\n    submitted by    /u/last_2_brain_cells97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uaa4jr/new_to_rl/",
          "publishedOn": "2022-04-23T17:14:41.000Z",
          "wordCount": 353,
          "title": "New to RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ua0a4x/questions_on_policy_gradients/",
          "author": null,
          "description": "Hi guys, I am new to RL and reading tutorial of spinning up which focus on policy based algorithms. In the derivation of VPG, the tutorial said\"The environment has no dependence on /theta(the parameter of policy), so gradients of R(/tau)(total return of the trajectory) with respect of /theta is 0. \n However, the trajectory depends on our policy, and our policy depends on /theta. As a result, I am confused why total return of trajectory is independent from /theta.\n    submitted by    /u/SkyRimT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ua0a4x/questions_on_policy_gradients/",
          "publishedOn": "2022-04-23T07:50:34.000Z",
          "wordCount": 538,
          "title": "Questions on policy gradients",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9txgh/vicarious_exits_acquihired_by_google_robotics/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9txgh/vicarious_exits_acquihired_by_google_robotics/",
          "publishedOn": "2022-04-23T01:22:06.000Z",
          "wordCount": 134,
          "title": "Vicarious exits: acquihired by Google robotics (Intrinsic) & DeepMind",
          "imageUrl": "https://external-preview.redd.it/dzwPatLSC5SsPson3p4UoC5DbVOwNR-UJvAq75ytssQ.jpg?auto=webp&s=17719699dfcceb5a52afb3a45cf84c9cbf61b3b9"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9ohi1/data_preprocessing_in_tfagents/",
          "author": null,
          "description": "Hi everyone,\n this is my first post please go easy on me.\n I'm currently playing around with a bigger Model in tf-agents. I worked only with structured data (TF, SKlearn, Pandas...). Now I'm struggling a bit with the preprocessing and where in the architecture to place it. I use multiple Inputs and encoding layers for each of them. For the training of the Encoders I used some SKLearn pre-processor (StandardScaler, MinMaxScaler, KBinsDiscretizer). I try to reuse the pre-processing pipeline in the model or extract the information for other pre-processing mechanisms(e.g. pre-processing tf layers)\n My current options I came up with:\n  \nIncorporate it directly into the Environment and return the pre-processed observation \n Pro easy, can probably use my SKlearn pipeline \n Contra I'd like to keep the architecture clean, so the environment should only give out raw values and not prepared values for a certain model\n \n Use an environment wrapper around the \"raw\" environment \n Pro \"raw\" environment needs no tuning\n Contra not sure if I can use my pipeline here and not sure if I'm taking a bad path here \n \n Use pre-processing TF layers \n Pro most of the API is there and can be used in my Encodernetworks, seems to be the TFic way\n Contra the SKlearn pre-processor have values for each column. The layers (e.g. rescale ) seems to only take one configuration for a whole tensor. I could probably create a layer for each value in the Tensor but that doesn't feel that it is supposed to be like that.\n \n  \nIf you have more options or can share your experience one of the options mentioned above I would be very glad.\n    submitted by    /u/Kjiessar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9ohi1/data_preprocessing_in_tfagents/",
          "publishedOn": "2022-04-22T20:54:38.000Z",
          "wordCount": 372,
          "title": "Data Pre-Processing in TF-Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9ies3/masking_in_rnn_in_the_actor_network/",
          "author": null,
          "description": "I am using PPO in the context of multi-agent RL. I was wondering if PyTorch has a way of handling when hidden states should be reinitialized to zeros. \n What I have found is this implementation: \n  def forward(self, x, hxs, masks): if x.size(0) == hxs.size(0): x, hxs = self.rnn(x.unsqueeze(0), (hxs * masks.repeat(1, self._recurrent_N).unsqueeze(-1)).transpose(0, 1).contiguous()) x = x.squeeze(0) hxs = hxs.transpose(0, 1) else: # x is a (T, N, -1) tensor that has been flatten to (T * N, -1) N = hxs.size(0) T = int(x.size(0) / N) # unflatten x = x.view(T, N, x.size(1)) # Same deal with masks masks = masks.view(T, N) # Let's figure out which steps in the sequence have a zero for any agent # We will always assume t=0 has a zero in it as that makes the logic cleaner has_zeros = ((masks[1:] == 0.0) .any(dim=-1) .nonzero() .squeeze() .cpu()) # +1 to correct the masks[1:] if has_zeros.dim() == 0: # Deal with scalar has_zeros = [has_zeros.item() + 1] else: has_zeros = (has_zeros + 1).numpy().tolist() # add t=0 and t=T to the list has_zeros = [0] + has_zeros + [T] hxs = hxs.transpose(0, 1) outputs = [] for i in range(len(has_zeros) - 1): # We can now process steps that don't have any zeros in masks together! # This is much faster start_idx = has_zeros[i] end_idx = has_zeros[i + 1] temp = (hxs * masks[start_idx].view(1, -1, 1).repeat(self._recurrent_N, 1, 1)).contiguous() rnn_scores, hxs = self.rnn(x[start_idx:end_idx], temp) outputs.append(rnn_scores) # assert len(outputs) == T # x is a (T, N, -1) tensor x = torch.cat(outputs, dim=0) # flatten x = x.reshape(T * N, -1) hxs = hxs.transpose(0, 1) \n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9ies3/masking_in_rnn_in_the_actor_network/",
          "publishedOn": "2022-04-22T16:17:47.000Z",
          "wordCount": 553,
          "title": "Masking in RNN in the actor network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9id2s/does_anyone_know_of_a_chess_environment_written/",
          "author": null,
          "description": "I don't think an opensource one exists but figured I'd ask here because you never know what's laying around the internet!\n As an aside, if one doesn't exist, let me know if you're interested in partnering in writing one!\n Edit: For anyone wondering I need the env to be in jax because my muzero implementation is in jax and I need the env to run on TPU cores, not CPU\n    submitted by    /u/evanatyourservice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9id2s/does_anyone_know_of_a_chess_environment_written/",
          "publishedOn": "2022-04-22T16:15:34.000Z",
          "wordCount": 406,
          "title": "Does anyone know of a chess environment written in JAX?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9fnzk/papers_that_use_neural_networks_solely_for/",
          "author": null,
          "description": "I am looking for any papers that do the following: use neural networks in the RL pipeline as the state space is too large for calculating the optimal policy using the traditional tabular value iteration or policy iteration. In this setting, the model is completely known, i.e., no learning.\n Most papers I see with DeepRL assume that the transition probabilities are unknown and that they have access to a simulator that gives them the ability to query data points. I am looking for existing work in DeepRL where the transition probabilities are known but the problem is intractable using tabular methods. Any direction would be appreciated, thanks!\n    submitted by    /u/lolillini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9fnzk/papers_that_use_neural_networks_solely_for/",
          "publishedOn": "2022-04-22T14:13:49.000Z",
          "wordCount": 250,
          "title": "Papers that use neural networks solely for planning in large MDPS (i.e., no learning)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9eiu8/ppo_update_without_using_nns_batch_updates/",
          "author": null,
          "description": "Hello, im making a new post as i couldnt find any answers to this before (although this reddit post is similar to my issue)\n I am trying to implement a simple multivariate Gaussian policy without neural networks, basically using a standard policy gradient update with SGD + score function gradient, without batches. The reason for this is to avoid unstable updates, meaning too large updates in mean/variance. The idea is thus to use a trust region update, to keep the updates within some reasonable size.\n I am a little confused regarding the maximization of the surrogate objective. As seen in this stackoverflow post, we wish to maximize [pi/pi_old] , compared to [log(pi)] in vanilla PG.\n Since i do not use automatic differentiation, but one single stochastic descent, how do I find the gradient of pi/pi_old ?\n To my understanding, the flow of the algorithm is this:\n sample experience -> compute new policy parameters -> compare with previous policy -> construct surrogate function -> perform SGD on surrogate to get the actual new policy\n It is the last step i am struggling with.\n    submitted by    /u/Acrobatic-Ad-9189  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9eiu8/ppo_update_without_using_nns_batch_updates/",
          "publishedOn": "2022-04-22T13:20:08.000Z",
          "wordCount": 315,
          "title": "PPO update without using NNs / batch updates",
          "imageUrl": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&s=8cd5e918e2bde6ca72d4445d6fc007f203689799"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9ehbm/simulating_robotic_arm_for_object_manipulation/",
          "author": null,
          "description": "I'll be starting my work for object manipulation using deep RL, and i would like to get start from the scratch, please recommend the source, tools, and software used for this purpose. but not be working on modeling the robot, instead will be using any robot with gripper which can be interfaced with ROS. Also please link the github repositories which can be helpfull in the learning process Thanks\n    submitted by    /u/Western-Age3148  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9ehbm/simulating_robotic_arm_for_object_manipulation/",
          "publishedOn": "2022-04-22T13:18:02.000Z",
          "wordCount": 261,
          "title": "Simulating robotic arm for object manipulation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u96v3j/policyencoding_mapping_implementation/",
          "author": null,
          "description": "Hi, I want to check policy-encoding mapping \n e : (S → A) → R^k in Universal Successor Features Approximators. \n I don't know how to embedding network to another network. There are too many weights! Do you have any ideas? Thank you for reading!\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u96v3j/policyencoding_mapping_implementation/",
          "publishedOn": "2022-04-22T05:11:54.000Z",
          "wordCount": 168,
          "title": "policy-encoding mapping implementation",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u94ans/useful_tools_and_resources_for_reinforcement/",
          "author": null,
          "description": "Found a useful list of Tools, Frameworks, and Resources for RL/ML. It covers Reinforcement learning, Machine Learning (TensorFlow & PyTorch), Core ML, Deep Learning, Computer Vision (CV). I thought I'd share it for anyone that's interested\n    submitted by    /u/Khaotic_Kernel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u94ans/useful_tools_and_resources_for_reinforcement/",
          "publishedOn": "2022-04-22T02:43:38.000Z",
          "wordCount": 159,
          "title": "Useful Tools and Resources for Reinforcement Learning",
          "imageUrl": "https://external-preview.redd.it/s-Wj4S_9WJ_xlA5ctanRGEEBVFmgaunBXjCZnxe7ooI.jpg?auto=webp&s=b3a0c384a58fe2df6f5d7251ca3b253c32c6c5e9"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u90m69/question_about_trained_models/",
          "author": null,
          "description": "Hello I have a question.\n For example, in the case of an inverted pendulum or cartpole, I train the model for the pole to be at 0 degrees (vertical) and it works. Then I want this same model to keep the pole at another position, for example, 3 degrees, do I have to train this model again for achieving this to or can I somehow use the model I already trained and what it learnt and input the new position I want it to be?\n idk if I explained myself\n I guess its mostly doubts about how to interact with the model and how to properly use a model that has already been trained. If anyone has some example of code (python, gym), on interacting with a trained model it would be really helpful.\n    submitted by    /u/Sleyck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u90m69/question_about_trained_models/",
          "publishedOn": "2022-04-21T23:31:41.000Z",
          "wordCount": 245,
          "title": "Question about trained models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8vhct/why_is_this_implementation_of_ppo_using_a_replay/",
          "author": null,
          "description": "https://github.com/marlbenchmark/on-policy/blob/main/onpolicy/algorithms/r_mappo/r_mappo.py\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8vhct/why_is_this_implementation_of_ppo_using_a_replay/",
          "publishedOn": "2022-04-21T19:28:37.000Z",
          "wordCount": 282,
          "title": "Why is this implementation of PPO using a replay buffer?",
          "imageUrl": "https://external-preview.redd.it/NILAiM6ka0xRo4eWi6VVljKuwWMAWyxwmZ0MceK7lbk.jpg?auto=webp&s=14995e2d2ebb47523b8c24b4b0b09457e6c2c023"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8unh1/what_is_the_role_of_masks_in_the_computation_of/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8unh1/what_is_the_role_of_masks_in_the_computation_of/",
          "publishedOn": "2022-04-21T18:50:24.000Z",
          "wordCount": 202,
          "title": "What is the role of masks in the computation of GAE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8sq20/question_about_optimal_policy_guarantees_in_pomdps/",
          "author": null,
          "description": "I'm working on a project where I'm trying to prove the existence of a particular set of functions by showing it can be constructed as the solution to a Markov Decision Process. However, it seems that it's much simpler to convert it to a partially observable MDP, rather than a classic one. I know it's been proven that the set of optimal policies for a classic MDP is nonempty, and intuitively I feel like the same should hold for POMDPs, but I'm having a hard time finding a particular source proving such a thing. Does anyone know where I ought to look?\n    submitted by    /u/LessPoliticalAccount  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8sq20/question_about_optimal_policy_guarantees_in_pomdps/",
          "publishedOn": "2022-04-21T17:21:36.000Z",
          "wordCount": 225,
          "title": "Question About Optimal Policy Guarantees in POMDPs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8rprt/can_reinforcement_learning_learn_itself_a_reply/",
          "author": null,
          "description": "submitted by    /u/JBaloney  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8rprt/can_reinforcement_learning_learn_itself_a_reply/",
          "publishedOn": "2022-04-21T16:36:22.000Z",
          "wordCount": 447,
          "title": "Can reinforcement learning learn itself? A reply to 'Reward is enough' (PDF)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8pyvd/what_is_this_line_in_the_suttonbarto_textbook/",
          "author": null,
          "description": "In the first edition of the textbook, the section on actor-critic methods (link) describes the classical approach of using the temporal difference error 𝛿 to modify the probability of selecting action a in state s:\n https://preview.redd.it/fa35vut7ewu81.png?width=238&format=png&auto=webp&s=c1b8952b065a90ecd2b8c0c30b985e36d37dbc30\n Then they briefly mention that one variation on the classical approach is to scale temporal difference error 𝛿 by the inverse of the probability of selecting the action a, where that probability is given by 𝜋(s, a):\n https://preview.redd.it/69gd3zmbdwu81.png?width=375&format=png&auto=webp&s=b66a7d5eef3c2b7bc256473aed728223921a751c\n They say: \" These issues were explored early on, primarily for the immediate reward case (Sutton, 1984; Williams, 1992) and have not been brought fully up to date.\"\n This idea is relevant to a project I'm working on, and I'd like to read more about it. But the references seem to be dead ends: Sutton 1984 is his PhD thesis, which I can't find a digital copy of, and Williams 1992 is this paper, which doesn't seem to contain this idea. Also this section doesn't seem to appear in the second edition of the textbook.\n You folks are much smarter than I am: Does modifying the update in this way mean anything to you? Are there modern approaches that do something like this? Or should I assume it was a little-explored idea in the early days that has been more-or-less forgotten?\n Thanks very much!\n    submitted by    /u/Careless-Argument-37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8pyvd/what_is_this_line_in_the_suttonbarto_textbook/",
          "publishedOn": "2022-04-21T15:18:06.000Z",
          "wordCount": 481,
          "title": "What is this line in the Sutton/Barto textbook referring to?",
          "imageUrl": "https://external-preview.redd.it/nvM-yG-06ytVatoSx5jmOO2dk1m54bekQ4sWGWyP13o.jpg?auto=webp&s=64b68547b2d2fffff368554156c2730c6cdb0c32"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8pbow/reinforcement_learning_with_delays/",
          "author": null,
          "description": "I was wondering what methods there are for RL with time delay other than augmenting the state space with the action buffer or using a model to undelay the environment. I've seen this post How to deal with the time delay in reinforcement learning? - Artificial Intelligence Stack Exchange however it's rather brief and I wondered if there were any more recent advancements.\n I am also struggling to understand partial trajectory resampling ( 2010.02966.pdf (arxiv.org) ) and the code in the accompanying repo. GitHub - rmst/rlrd: PyTorch implementation of our paper Reinforcement Learning with Random Delays (ICLR 2020) \n I was wondering how we can resample actions in environments with constant delays if those actions are used in the state space for all subsequent chosen actions?\n    submitted by    /u/SuperDuperDooken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8pbow/reinforcement_learning_with_delays/",
          "publishedOn": "2022-04-21T14:48:51.000Z",
          "wordCount": 268,
          "title": "Reinforcement Learning with delays",
          "imageUrl": "https://external-preview.redd.it/MyPYjJuEdSjpldenX2HAv7ypDZ5RoSxLh1peLFH0LQY.jpg?auto=webp&s=becf24ba2bf18dec6c08b396b82b8117a41340c4"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8g9do/is_it_stupid_to_use_rl_to_control_solar_panel/",
          "author": null,
          "description": "submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8g9do/is_it_stupid_to_use_rl_to_control_solar_panel/",
          "publishedOn": "2022-04-21T05:31:42.000Z",
          "wordCount": 408,
          "title": "Is it stupid to use rl to control solar panel angle?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8e9qi/how_can_i_use_the_environment_in_emergence_of/",
          "author": null,
          "description": "Hi, I want to train my agent in the environment used in \"Emergence of Locomotion Behaviours in Rich Environments\". Here is a video about that https://www.youtube.com/watch?v=hx_bgoTF7bs. Is the environment released? Thanks for reading.\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8e9qi/how_can_i_use_the_environment_in_emergence_of/",
          "publishedOn": "2022-04-21T03:33:27.000Z",
          "wordCount": 252,
          "title": "How can I use the environment in Emergence of Locomotion Behaviours in Rich Environments?",
          "imageUrl": "https://external-preview.redd.it/fmJw_BqWhQgP8-1v0fvrbHkuKAsNYOg3NGiEK6vMtb0.jpg?auto=webp&s=259f0644cdbce7ce142e6a4c1a20fa095f7bb14d"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u87xtm/is_there_any_difference_between_how_ddpg_and_ppo/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u87xtm/is_there_any_difference_between_how_ddpg_and_ppo/",
          "publishedOn": "2022-04-20T22:11:06.000Z",
          "wordCount": 433,
          "title": "Is there any difference between how DDPG and PPO use the replay buffer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u87qu6/any_tips_for_a_prospective_graduate_student_in/",
          "author": null,
          "description": "Hello Everyone, I apologize ahead of time if posts like this aren't looked well upon on this sub, but I couldn't find rules against this and I also think this is the best, most niche sub for my question. I also made a new account just to be safe haha.\n ​\n Anyways, I will be graduating this spring with a BS in Computer Science and a BA in Mathematics. I have been researching Machine Learning since my sophomore year (adversarial machine learning) under a professor at my university and recently took upon a second, concurrent research position in RL since last summer.\n ​\n My goal is to get into a PhD program at a higher level than my current university (my current university is good, but doesn't really have much of an AI focus as I've already taken all the AI grad courses as an undergrad). I'm…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u87qu6/any_tips_for_a_prospective_graduate_student_in/",
          "publishedOn": "2022-04-20T22:02:01.000Z",
          "wordCount": 943,
          "title": "Any tips for a prospective graduate student in Reinforcement Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u838na/task_allocation_problem_with_graph_representation/",
          "author": null,
          "description": "Hey everyone,\n I've recently started working on a task allocation problem using RL. I'd just like to make sure my thinking is correct on how to best approach the problem. \n At the moment, we have (effectively) a graph traversal sim for n number of agents, where the goal is to minimize the total distance over an episode, as determined by setting the correct tasks. The task supplied to each agent will determine the route that is taken, and therefore the distance. \n The current idea is to supply an input graph that also contains information on the current location of the agents. A second input would be the set of available tasks. The expected output would be done through a pointer network, where we produce a reordered set of the tasks in descending order of optimality. \n When step is called, the sim runs until a new task is needed (agent completes it's route). \n ​\n In general, does anyone know a good way to represent the inputs and output of this problem? A pointer network seems like it could work to produce actions, but if I need to do a forward pass for every agent, it seems that there would be no consideration of other agents when determining tasks (We shouldn't have 2 agents doing the same task). For the graph representation, a graph nn seems like an obvious choice, but I just wanted to see if anyone had any insight on why they may or may not be used.\n    submitted by    /u/asdfsflhasdfa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u838na/task_allocation_problem_with_graph_representation/",
          "publishedOn": "2022-04-20T18:36:22.000Z",
          "wordCount": 362,
          "title": "Task Allocation problem with graph representation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7usiq/universities_working_on_reinforcement_learning/",
          "author": null,
          "description": "Can you name any good universities (with high acceptance rate) which are working on reinforcement learning for robotics and also accept students from other branches (i.e. Electrical, Mechanical Engineering).\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7usiq/universities_working_on_reinforcement_learning/",
          "publishedOn": "2022-04-20T11:57:05.000Z",
          "wordCount": 398,
          "title": "Universities working on reinforcement learning for robotics.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7sbok/is_the_game_of_chess_a_finite_mdp/",
          "author": null,
          "description": "In the standard intro to RL book, I have read that any MDP that has finite actions and states is a finite MDP. But that limit is subjective. So there are approximately 1045. If I limit myself to 105 states, can I say that chess isn't a finite MDP?\n    submitted by    /u/BraveProfessional656  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7sbok/is_the_game_of_chess_a_finite_mdp/",
          "publishedOn": "2022-04-20T09:12:44.000Z",
          "wordCount": 315,
          "title": "Is the game of chess a finite MDP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7qaw4/reinforcement_learning_over_traditional_machine/",
          "author": null,
          "description": "I am currently studying use cases of RL in finance/banking/insurance and I am keen to understand what are its advantages and disadvantages than traditional methods.\n    submitted by    /u/kachua26  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7qaw4/reinforcement_learning_over_traditional_machine/",
          "publishedOn": "2022-04-20T06:44:11.000Z",
          "wordCount": 208,
          "title": "Reinforcement learning over traditional machine learning method in Finance/Banking ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7ggt5/reinforcement_learning_with_actionfree/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7ggt5/reinforcement_learning_with_actionfree/",
          "publishedOn": "2022-04-19T21:49:07.000Z",
          "wordCount": 140,
          "title": "\"Reinforcement Learning with Action-Free Pre-Training from Videos\", Seo et al 2022",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7g00a/inferring_rewards_from_language_in_context_lin_et/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7g00a/inferring_rewards_from_language_in_context_lin_et/",
          "publishedOn": "2022-04-19T21:28:01.000Z",
          "wordCount": 139,
          "title": "\"Inferring Rewards from Language in Context\", Lin et al 202",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7adqi/bandit_problems_as_sequential_decision_problems/",
          "author": null,
          "description": "Any reinforcement learning problem can be modeled as a sequential decision problem (SDP), which can always be modeled as a Markov decision process (need to model the state carefully). An example of an SDP is a multiarmed bandit problem, where the state is the vector of beliefs about the performance of each arm (or beliefs about a continuous parametric model). Decisions are made by a policy, and there are four classes of policies. For some reason, the RL community tends to focus on just one of the four classes (UCB policies, which fall in the class of cost function approximations), but there are entire communities using each of the other three classes. See chapter 7 of my new book (https://castlelab.princeton.edu/RLSO/) for a complete summary of the four classes of policies for pure learning problems (aka bandit problems). Note that Sutton and Barto (2nd edition) cover bandit problems in chapter 2, and then introduce MDPs in chapter 3. A bandit problem *is* an MDP!\n    submitted by    /u/powell-sda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7adqi/bandit_problems_as_sequential_decision_problems/",
          "publishedOn": "2022-04-19T17:21:02.000Z",
          "wordCount": 283,
          "title": "Bandit problems as sequential decision problems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u78oup/getting_started_with_uavdrone_control/",
          "author": null,
          "description": "Hi, is it currently possible to train a UAV and implement the policy it in real-life? I understand there are different environments for training, e.g. AirSim, GymFC, and others. However, the interesting part for me is the link to the real world: Is there a way to directly implement any learned policy on a real drone, e.g. a commercially available quad-copter? Which UAV would support such a functionality?\n I'd love to get started on training drones for RL purposes (search and rescue, etc), but if there is no way to test it in real-life then this would be disappointing.\n    submitted by    /u/FrankTheThanks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u78oup/getting_started_with_uavdrone_control/",
          "publishedOn": "2022-04-19T16:06:29.000Z",
          "wordCount": 424,
          "title": "Getting started with UAV/drone control",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u78gb9/question_about_expected_sarsa_for_prediction_vs/",
          "author": null,
          "description": "I am having a hard time figuring out what makes the difference between Expected Sarsa for prediction vs for control.\n For off-policy Expected Sarsa I believe it's possible to use one epsilon value for a target policy that is epsilon-greedy and another epsilon value for a behaviour policy that is epsilon-greedy. The target policy would be used within the expected value calculation in the update of Q(S,A), the action value function, and the behaviour policy would be used to choose actions from the current state. But I'm not sure how to differentiate between the control version of the algorithm compared to the prediction version though.\n I think prediction usually finds the state-value function but I know that on-line Sarsa for prediction uses Q(S,A) so I'm not sure how to determine the difference between prediction and control algorithms.\n    submitted by    /u/lifelifebalance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u78gb9/question_about_expected_sarsa_for_prediction_vs/",
          "publishedOn": "2022-04-19T15:56:29.000Z",
          "wordCount": 261,
          "title": "Question about Expected Sarsa for prediction vs control",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u74qir/exploration_strategies_in_discrete_action_spaces/",
          "author": null,
          "description": "Hello there, I am working on missile command game, and as a baseline I mostly use rllib/ppo. The algorithm never converges, I suspect it is because of the lack of exploration. Since the timesteps are small, the target usually oscillates around center of the screen, it is impossible to explore to go near the border and then explore to fire (to counter incoming missile). What methods should I try?\n Moreover, I have already done reward scaling and frame staking. Any suggestions regarding solving this game is much appreciated. \n Last question, do you now similar (and common) environments that is solved, maybe solutions show the path to follow.Thank you :)\n    submitted by    /u/Street_Excitement_14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u74qir/exploration_strategies_in_discrete_action_spaces/",
          "publishedOn": "2022-04-19T13:06:53.000Z",
          "wordCount": 336,
          "title": "exploration strategies in discrete action spaces",
          "imageUrl": "https://external-preview.redd.it/EVmS5b9nw-cH6h_YyaCIR7CARFegttHf-ELvgY9mmz8.jpg?auto=webp&s=a28b0ae18e162832aaf0358d792bfa77652b5a69"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u71ce8/confusion_of_hyperparameters_in_ppo/",
          "author": null,
          "description": "I'm reading the ppo paper https://arxiv.org/abs/1707.06347 and I'm confusing about the hyperparameters in table 4, Log stdev. of action distribution | LinearAnneal(-0.7, -1.6).\n Best to my knowledge, under the continuous setting, the policy will output mean and std, so why the stdev of action distribution is given as a hyperparameter, and also what is LinearAnneal in detail.\n    submitted by    /u/StrawberryTemporary7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u71ce8/confusion_of_hyperparameters_in_ppo/",
          "publishedOn": "2022-04-19T09:49:32.000Z",
          "wordCount": 297,
          "title": "Confusion of hyperparameters in ppo",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u6yce5/need_help_about_categorical_dqn/",
          "author": null,
          "description": "I dk how the projection of TZ to match Z work and I also dont understand the formula? can someone do step by step calculation to demo?\n    submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u6yce5/need_help_about_categorical_dqn/",
          "publishedOn": "2022-04-19T06:17:59.000Z",
          "wordCount": 175,
          "title": "Need help about categorical dqn",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u6ptng/a3c_vs_federated_learning/",
          "author": null,
          "description": "Hi, \n I see this question was asked before but I am still not convinced there is a difference between the two. \n How is asynchronous distributed RL (A3C) and federated learning different? It seems like the basic idea behind them is the same— the agents train in their own environments and only share gradients with the server. \n Is the difference only in terms of the domain they are applied in? Is it just ML vs RL?\n    submitted by    /u/uneasy_daisy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u6ptng/a3c_vs_federated_learning/",
          "publishedOn": "2022-04-18T22:49:11.000Z",
          "wordCount": 186,
          "title": "A3C vs federated learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u61537/can_polyak_averaging_neural_networks_lead_to/",
          "author": null,
          "description": "In Soft Actor Critic several Q networks are used. Target Q networks are gradually updated to match other Q networks.\n See step 15 here: https://spinningup.openai.com/en/latest/algorithms/sac.html#pseudocode\n I've heard this called polyak averaging.\n Let's say we have two weights from two neural networks: W1 from one network, and W2 is the corresponding weight from the other network. Polyak averaging averages these weights as follows:\n W_average = W1 * p + W2 * (1-p)\n When p is 0.5, it's a evenly weighted average. If p is high, then W1 is weighted more heavily than W2, etc.\n My question is: Does this method of averaging weights lead to numerically unstable neural networks? This technique is often used to gradually transform one neural network into another on a weight by weight basis, but there is no guarantee that all intermediate neural networks are well behaved (at least, none that I'm aware of). Whereas, gradient descent with small enough step sizes should, theoretically, keep a neural network well behaved, I think those same theoretical guarantees apply to polyak averaging neural networks.\n What do you think?\n    submitted by    /u/Buttons840  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u61537/can_polyak_averaging_neural_networks_lead_to/",
          "publishedOn": "2022-04-18T01:13:50.000Z",
          "wordCount": 611,
          "title": "Can polyak averaging neural networks lead to numerical instability?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u5jzpy/learning_style_of_play_different_agents_actions/",
          "author": null,
          "description": "Hi, everyone. I'm a relative novice in RL, so bear with me as I try to formulate my question.\n I'm working on a chess bot that can play moves like a player (imitate their style of play) that is chosen from a set of players (that the bot is trained on) , if I give the bot the previous x moves. Using more technical terms, I'm trying to create an agent that is given a sequence of states-actions of another agent (player) and some representation of who that agent (player) is, and predict the next action (continue playing in the style of that player).\n I'm fairly certain this is an RL problem, as I don't know how to frame it as a supervised learning problem (I might be wrong).\n I've seen some papers that abstract offline RL as a sequence modeling problem (Decision Transformer, Trajectory Transformer), so I'm fairly certain I should continue in a similar manner.\n But I'm having a hard time trying to understand how to treat the difference in players. My instinct was to use some representation of the player as the reward, but then how would I even optimize for it or even give it as an input? Do I just add the player as a feature in the game state, but then what should be the reward?\n Has this been done before, or something similar? I couldn't really find any paper or code that worked on differentiating the training data by who made it (I might not be wording it correctly).\n    submitted by    /u/OverhypeUnderdeliver  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u5jzpy/learning_style_of_play_different_agents_actions/",
          "publishedOn": "2022-04-17T10:01:57.000Z",
          "wordCount": 859,
          "title": "Learning style of play (different agents' actions) in the same offline RL environment?",
          "imageUrl": "https://external-preview.redd.it/MeJ3D66GfO9rJcYwzbVXuOn9Z3ZRkFGm-_tW9oPYGkI.jpg?auto=webp&s=08a5addc53a466a49589e35e34c912174b61df9e"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u5899l/rigorous_treatment_of_mdps_bellman_etc_in/",
          "author": null,
          "description": "I am looking for a book/monograph that goes through all the basics of reinforcement learning for continuous spaces with mathematical rigor. The classic RL book from Sutton/Barto and the new RL theory book from Agarwal/Jiang/Kakade/Sun both stick to finite MDPs except for special cases like linear MDPs and the LQR.\n I assume that a general statement of the fundamentals for continuous spaces will require grinding through a lot of details on existence, measurability, suprema vs. maxima, etc., that are not issues in the finite case. Is this why these authors avoid it?\n clarifying edit: I don't need to go all the way to continuous time - just state and action spaces.\n Maybe one of Bertsekas's books?\n    submitted by    /u/quadprog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u5899l/rigorous_treatment_of_mdps_bellman_etc_in/",
          "publishedOn": "2022-04-16T21:57:56.000Z",
          "wordCount": 367,
          "title": "Rigorous treatment of MDPs, Bellman, etc. in continuous spaces?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u51nkf/need_help_making_a_basic_python_model/",
          "author": null,
          "description": "I have a 2 column dataset “Date” “Result”. The Result column produces a 0 or 1 for each date. I need to make a reinforcement model that will predict whether or not the next result will be a 0 or 1. It needs to be done in jupyter notebook .\n    submitted by    /u/EffectiveBug4629  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u51nkf/need_help_making_a_basic_python_model/",
          "publishedOn": "2022-04-16T16:39:32.000Z",
          "wordCount": 188,
          "title": "NEED HELP MAKING A BASIC PYTHON MODEL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u51hk5/from_machine_learning_to_sequential_decision/",
          "author": null,
          "description": "Any reinforcement learning problem can be modeled as a sequential decision problem (SDP), which can always be modeled as a Markov decision process. An example of an SDP is a multiarmed bandit problem, where the state is the vector of beliefs about the performance of each arm (or beliefs about a continuous parametric model). Decisions are made by a policy, and there are four classes of policies. For some reason, the RL community tends to focus on just one of the four classes (UCB policies, which fall in the class of cost function approximations), but there are entire communities using each of the other three classes. See chapter 7 of my new book for a complete summary of the four classes for pure learning problems (aka bandit problems). See https://tinyurl.com/RLandSO/ Curious why Sutton and Barto (2nd edition) cover bandit problems in chapter 2, and then introduce MDPs in chapter 3. A bandit problem *is* an MDP!\n    submitted by    /u/powell-sda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u51hk5/from_machine_learning_to_sequential_decision/",
          "publishedOn": "2022-04-16T16:31:27.000Z",
          "wordCount": 285,
          "title": "From machine learning to sequential decision problems (reinforcement learning)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4ygra/policy_gradient_vs_policy_iteration/",
          "author": null,
          "description": "Hello, I'm currently learning about MDPs and machine learning. I have a few questions that might be trivial or obvious but I can't find many concrete answers online:\n -Are policy gradient and policy iteration similar/the same? From what I can gather, policy iteration is a type or subset of policy gradient algorithm, is this correct?\n -Are all policy learning methods less effective for large state spaces? From my understanding you need to use some kind of value function iteration and heursitic function for larger state spaces because you can't encounter all states enough times to converge on an optimal policy\n -Does convergence on a policy/value function find a local or global optimum? With neural nets, simple backpropagation may only find a local minimum for the cost function, is this true of MDP/RL iteration algorithms? \n Thanks!!\n    submitted by    /u/egad_a_mouse  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4ygra/policy_gradient_vs_policy_iteration/",
          "publishedOn": "2022-04-16T14:02:27.000Z",
          "wordCount": 561,
          "title": "Policy gradient vs. Policy iteration?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4x8pg/how_to_create_a_layer_without_inputs_in_tensorflow/",
          "author": null,
          "description": "In deep rl algorithm like PPO, a continuous stochastic policy is represented by Normal Distribution. For this the recommended way of creating a Normal Distribution is to get the mean by passing the state through NN and then using a state independent layer to predict log_std. This layer which predicts log_std should be trainable using backprop just like biases. So how to create this layer in tensorflow 2.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4x8pg/how_to_create_a_layer_without_inputs_in_tensorflow/",
          "publishedOn": "2022-04-16T12:56:39.000Z",
          "wordCount": 234,
          "title": "How to create a layer without inputs in tensorflow.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4jzbn/new_to_machine_learning_want_to_simulate_robotics/",
          "author": null,
          "description": "My employer makes significant use of robotic weld cells, and while working with the equipment I've noticed what seems to be room for improvement in the programming. This is purely a personal academic project, as I am quite curious on if machine learning could produce comparable or superior results to the human-made programming used at work. However, as such there will unfortunately be areas of vagueness because I need to stick to knowledge that is publicly available regarding their operations. I'm going to have to stick to more generic, publicly available reference material, and will not be able to share most, if any, of the end result.\n I would like to run simulations in a 3D environment, using machine learning to train a computer program to find the most efficient sequence of movements &…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4jzbn/new_to_machine_learning_want_to_simulate_robotics/",
          "publishedOn": "2022-04-15T22:52:33.000Z",
          "wordCount": 943,
          "title": "New to machine learning, want to simulate robotics in a 3d environment",
          "imageUrl": "https://external-preview.redd.it/L21x-Qy50-NkImNnJV3XZ9rjr5qsTyhFX6Rnr9rsIjc.jpg?auto=webp&s=8decf3b0602a577f844c587a17534ef1caf6afc6"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4hsqr/does_using_a_centralized_critic_always_mean_that/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4hsqr/does_using_a_centralized_critic_always_mean_that/",
          "publishedOn": "2022-04-15T21:05:05.000Z",
          "wordCount": 142,
          "title": "Does using a centralized critic always mean that the agents receive global observation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4hcbb/what_algorithm_would_be_suited_for_a_just_do_it/",
          "author": null,
          "description": "I’m really new to RL so please bear with me if I’m making mistakes here, but I’m trying to make an environment that emulates a network of roads. The algorithm will need to generate a quick route between n destinations when n equals some number with an insane amount of permutations, like 30 for example. This is like emulating the destinations required by a mailman’s route on a map, and trying to find the fastest way to get to each one.\n The algorithms sequence of decisions will be choosing a node to travel to, while each node represents an street intersection or point where the street ends. By the time it’s traveled to every destination using the nodes, it’ll review the network of nodes it used and sum the distance between each one to get total distance of route. \n The goal is to get the total distance as small as possible. Is this realistic for a RL problem, or do I need to try to engineer some way to determine if every decision was either good or bad? Could I build a mathematical way to approximate the quickest route and then reward the RL algorithm by generating a better route than the mathematically approximated one?\n I could try rewarding the algorithm at each decision by whether it reduced the total distance required to any target it has yet to visit. I could try to mathematically make this more viable… what do y’all think,should I do something like that? Am I headed in the right direction? \n Thanks for any and all help!\n    submitted by    /u/professorDissociate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4hcbb/what_algorithm_would_be_suited_for_a_just_do_it/",
          "publishedOn": "2022-04-15T20:43:05.000Z",
          "wordCount": 753,
          "title": "What algorithm would be suited for a “Just do it as good as you can” situation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4ev1g/where_is_envns_for_frozen_lake_in_openai_gym/",
          "author": null,
          "description": "I am trying to run this:\n env4 = FrozenLakeEnv(map_name='4x4', is_slippery=False)\n env4.nS\n ​\n I then get this error:\n 'FrozenLakeEnv' object has no attribute 'nS'\n ​\n But I see it in the source code on line 151 and 152:\n https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py\n ​\n Edit: I'm trying to follow along with some tutorials online.\n Thank you for the help!\n    submitted by    /u/postdoc403b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4ev1g/where_is_envns_for_frozen_lake_in_openai_gym/",
          "publishedOn": "2022-04-15T18:46:08.000Z",
          "wordCount": 229,
          "title": "Where is env.nS for Frozen Lake in OpenAI Gym",
          "imageUrl": "https://external-preview.redd.it/nVtKqdjb-CU3wRoPE0dNudgt4TtugQhhLFMCahT2XTY.jpg?auto=webp&s=115d3f128a80fab6cd7e9297ee85d71500121ab3"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4ci7r/getting_maxmin_action_in_ddpg_and_td3/",
          "author": null,
          "description": "I am using DDPG for a custom environment. My reward is positive (the sum-rate in a communication system). My problem is that I get the max or min action after a few training steps and it saturates with a non-optimized solution. How can I address this problem? I tried redesigning my reward to include positive and negative values but it didn’t work. I read that some people are using reward scaling. What is it and how would I scale it? I mean is there a specific method? I couldn’t find enough resources on that. Any help is much appreciated!\n    submitted by    /u/alicefaisal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4ci7r/getting_maxmin_action_in_ddpg_and_td3/",
          "publishedOn": "2022-04-15T16:58:26.000Z",
          "wordCount": 222,
          "title": "Getting max/min action in DDPG and TD3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4b1gq/question_about_pseudocodes/",
          "author": null,
          "description": "Hi I'm redoing all the RL algorithms in python, to better understanding them. I'm mostly following Sutton and Barto but the pseudo code there is often hard to follow.\n Do you know any other place where I can look at?\n    submitted by    /u/New_neanderthal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4b1gq/question_about_pseudocodes/",
          "publishedOn": "2022-04-15T15:50:21.000Z",
          "wordCount": 150,
          "title": "Question about pseudocodes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u49zmq/industry_use_of_reinforcement_learning/",
          "author": null,
          "description": "I have been studying RL now for 18 months as a goal to get a job in it.\n Yet when I look at jobs, I see very seldom postings about it.\n I am wondering why is it the case ? From my current understanding I could think of dozens of applications with huge potential gains. It feel like an untapped potential.\n Or am I missing something ? What do you think is the big obstacle to wider adoption to RL ? Do you think it overlaps with classical control at the moment and is not justified ?\n    submitted by    /u/Ouassimf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u49zmq/industry_use_of_reinforcement_learning/",
          "publishedOn": "2022-04-15T15:00:56.000Z",
          "wordCount": 1056,
          "title": "Industry use of reinforcement learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u48tsz/comparing_default_vs_custom_reward_function_for/",
          "author": null,
          "description": "submitted by    /u/DIAMBRA_AIArena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u48tsz/comparing_default_vs_custom_reward_function_for/",
          "publishedOn": "2022-04-15T14:06:10.000Z",
          "wordCount": 452,
          "title": "Comparing Default VS Custom Reward Function for Optimal Health Management of a DeepRL Agent Playing Tekken",
          "imageUrl": "https://external-preview.redd.it/eLywtXzeC4PVSu-mzBX2IDefQWfWkxDGmJjWZjWahXA.png?format=pjpg&auto=webp&s=bfc61efa3503e22eae56ad57668c5afc38f1e86c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u3pcrp/ppo_with_one_worker_always_picking_the_best_action/",
          "author": null,
          "description": "If I use PPO with distributed workers, and one of the workers always picks the best action, would that skew the PPO algorithm? It might perform a tad slower, but would it factually introduce wrong math? Perhaps because the PPO optimization requires that all actions are taking proportional to their probabilities? Or would it (mathematically) not matter?\n    submitted by    /u/tmuxed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u3pcrp/ppo_with_one_worker_always_picking_the_best_action/",
          "publishedOn": "2022-04-14T19:31:16.000Z",
          "wordCount": 224,
          "title": "PPO with one worker always picking the best action?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u3nhkz/feedback_collection_for_finrl_financial/",
          "author": null,
          "description": "Dear all,\n As a creator of the open-source FinRL project, I would like to welcome all kinds of feedback regarding financial reinforcement learning, especially about how to improve the open-source project FinRL.\n After several years of development and maintenance, we have passed the phase of caring about #stars, now we care more about #downloads, also Wall Street's adoption.\n Appreciate your feedback and sharing!\n Previously when we exposed our message on Reddit, the community was not very supportive about open-source projects' \"advertisements\". Maybe it consumed public attention and raised bad feelings. Therefore, this time we created a reddit sub-channel for FinRL-related discussions, available at: https://www.reddit.com/r/AI4Finance_FinRL/\n Best,\n Yang\n    submitted by    /u/Character-Meat-9176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u3nhkz/feedback_collection_for_finrl_financial/",
          "publishedOn": "2022-04-14T18:04:11.000Z",
          "wordCount": 223,
          "title": "Feedback Collection for FinRL: Financial Reinforcement Learning",
          "imageUrl": "https://external-preview.redd.it/8-Jkr120jBwSEOjE3QprtB37msW5qLklONwZxIIXnb8.jpg?auto=webp&s=cd57c9967110f6a7206244afffb6b6e6f96e9fca"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u3hk7l/is_a_steady_linear_increase_in_average_reward/",
          "author": null,
          "description": "submitted by    /u/C_BearHill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u3hk7l/is_a_steady_linear_increase_in_average_reward/",
          "publishedOn": "2022-04-14T13:28:24.000Z",
          "wordCount": 231,
          "title": "Is a steady linear increase in average reward during training too good to be true? Are there any common pitfalls?",
          "imageUrl": "https://preview.redd.it/9tk351ggxht81.png?auto=webp&s=03d2ce0fc7d8b624e3729f0eb52d21e9d4919640"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u3c5tr/determine_gridworld_values_with_no_probability/",
          "author": null,
          "description": "I am learning Reinforcement learning for games following Gridworld examples. Apologies in advance if this is a basic question, very new to reinforcement learning.\n I am slightly confused in scenarios where probability of moving up, down, left and right are not provided or stated. In this scenario, I assume we assume the optimal policy and therefore, you would apply the Bellman equation as:\n V(s)=maxa(R(s,a)+γV(s′))\n Cost for any movement is 0 and an agent can choose to terminate at a numbered grid to collect a reward amount of the grid number. This is why my square closest to the reward takes in the value 8 since it will terminate with the action to the next state to collect the reward.\n Would this be the correct way to determine the value for the surrounding grid squares?\n https://preview.redd.it/s9l0ok4kbgt81.png?width=806&format=png&auto=webp&s=dfb50450001541b0569d0361fd04a73daa29f222\n    submitted by    /u/Artezian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u3c5tr/determine_gridworld_values_with_no_probability/",
          "publishedOn": "2022-04-14T08:01:55.000Z",
          "wordCount": 487,
          "title": "Determine Gridworld values with no probability",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2rkve/does_the_reward_in_reinforcement_learning_have_to/",
          "author": null,
          "description": "I'm trying to train a seq2seq model that generates a sentence with T words using reinforcement learning. The input and all the previously generated words form the state of the environment, and generating a word in the sentence is considered an action. In the previous methods [1, 2], the immediate reward r(s_t, a_t, s_{t+1}) for the t-th action a_t is 0 when t < T, and the reward is the CIDEr score (a scalar that measures the quality of the sentence) of the entire sentence when t = T. The policy is updated after the entire sentence is generated.\n I designed a new reward for each action, and the new reward for the t-th action is not zero when t < T. However, the reward of each action can only be calculated when the entire sentence is generated since it relies on the CIDEr score of the entire sentence, i.e. the reward for all the actions relies on the final state s_T. Can I still define the reward in the form of r(s_t, a_t, s_{t+1}) ?\n [1] Rennie et al. Self-critical sequence training for image captioning, CVPR 2017: 7008-7024.\n [2] Ranzato et al. Sequence level training with recurrent neural networks, ICLR 2016.\n    submitted by    /u/entalent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2rkve/does_the_reward_in_reinforcement_learning_have_to/",
          "publishedOn": "2022-04-13T14:28:00.000Z",
          "wordCount": 390,
          "title": "Does the reward in reinforcement learning have to be immediate reward?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2q8ih/question_about_math/",
          "author": null,
          "description": "I am reading that paper A Distributional Perspective on Reinforcement Learning, and it is related to measure theory. Is it worth to spend time to study whole real analysis and measure theory?\n    submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2q8ih/question_about_math/",
          "publishedOn": "2022-04-13T13:23:24.000Z",
          "wordCount": 204,
          "title": "Question about math",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2o03v/what_does_an_oscillating_explained_variance/",
          "author": null,
          "description": "submitted by    /u/C_BearHill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2o03v/what_does_an_oscillating_explained_variance/",
          "publishedOn": "2022-04-13T11:19:11.000Z",
          "wordCount": 207,
          "title": "What does an oscillating explained_variance signify during training? (PPO)",
          "imageUrl": "https://preview.redd.it/dj0psf0t5at81.png?auto=webp&s=aefa56dc877f60c03e5431692faa4d0d6a41cdf4"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2jq4n/sb3_herdqn_for_my_simple_discrete_map_env_but_the/",
          "author": null,
          "description": "Hi all, I am creating a multiple-goal environment. Which is an 8*8 discrete map with a start and terminal state (only one) change after each episode. The reward is 100 for reaching the terminal state and -1 for the rest. In fact, I am not sure if the reward is reasonable. \n I used PPO from SB3 and I can easily finish it. But when I go offline, using HER+DQN, the training is very bad. \n Feel free to run it here or take a look at the env and training result. Thank you so much!\n https://colab.research.google.com/drive/1Mt5Yje7GTyjOBHL09zC9C1L05xpTAK9v?usp=sharing\n    submitted by    /u/AnimatorRemarkable20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2jq4n/sb3_herdqn_for_my_simple_discrete_map_env_but_the/",
          "publishedOn": "2022-04-13T06:12:00.000Z",
          "wordCount": 239,
          "title": "SB3- HER+DQN for my simple discrete map env but the training result is pretty bad",
          "imageUrl": "https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?auto=webp&s=73eb91ea5a5347f216c0f0c4d6796396826aae49"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2iy5i/what_would_happen_if_you_connect_inputs_and/",
          "author": null,
          "description": "submitted by    /u/The_impact_theory  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2iy5i/what_would_happen_if_you_connect_inputs_and/",
          "publishedOn": "2022-04-13T05:21:16.000Z",
          "wordCount": 666,
          "title": "What would happen if you connect inputs and outputs randomly to a large hebbian Spiking NN and let it learn shape itself in an environment.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2h8it/number_of_feature_vs_action_space_in_multiagent/",
          "author": null,
          "description": "Hi All,\n I am working on a MARL fintech project where I use DDQN and for Q-value, I use LSTM bacause it is time series data. This is a project overview. It has 7 features which is derivatives of ask and bid price and has 12 action spaces for action taking.\n Is it possible to generate a good reliable model using only 7 features for 12 action spaces?\n Number of feature or quality of feature is important for taking good decision in RL. \n Open for Suggestion\n #Reinforcement_Learning #MARL\n    submitted by    /u/laxuu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2h8it/number_of_feature_vs_action_space_in_multiagent/",
          "publishedOn": "2022-04-13T03:41:14.000Z",
          "wordCount": 215,
          "title": "Number of Feature VS Action Space in Multi-agent Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2gcn4/is_there_anyone_interested_in_reimplementing_apt/",
          "author": null,
          "description": "Hi, these day I really interested in self-supervised RL. Especially only based on state novelty. So I wanted to re-implement APT(Behavior From the Void: Unsupervised Active Pre-Training). but my re-implementation showed not meaningful behaviors compared to official implementation. official implementation uses drq-v2 and intrinsic curiosity module. So, I want to re-implement APT as described in paper(using drq-v1 and contrastive learning).\n Is there someone to check my reimplementation?\n https://github.com/seolhokim/apt\n In that repository, DrQ-v1 works well, but only apt doesn't work! I can't understand why agent stop moving when pre-training.\n ​\n Really thank you for reading.\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2gcn4/is_there_anyone_interested_in_reimplementing_apt/",
          "publishedOn": "2022-04-13T02:52:42.000Z",
          "wordCount": 212,
          "title": "Is there anyone interested in re-implementing APT?",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1xeea/best_gridworld_environment/",
          "author": null,
          "description": "In your opinion, what is the best gridworld environment? I want to compare different RL algorithms on it. \n I’m looking for something super basic: - start and goal state - some obstacles - customisable: move the start and goal state, place obstacles in different points, modify reward map etc. - computationally efficient\n Thank you\n    submitted by    /u/wiston_smith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1xeea/best_gridworld_environment/",
          "publishedOn": "2022-04-12T12:00:47.000Z",
          "wordCount": 299,
          "title": "Best GridWorld environment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1wvf6/custom_callback_for_max_episode_reward_using/",
          "author": null,
          "description": "Hi all,\n I've built a custom gym env and am using Stable Baselines3 to train an agent. I would like to visualise in TensorBoard the maximum reward achieved for each episode. I have these values in a list in my env, and I am trying to create a custom Callback to plot this in TensorBoard but it's not working. I've looked over the documentation and other forums but can't figure out how to do this. Can anyone help me out? 🙏🏽 Thank you!\n    submitted by    /u/leozinho2r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1wvf6/custom_callback_for_max_episode_reward_using/",
          "publishedOn": "2022-04-12T11:30:48.000Z",
          "wordCount": 220,
          "title": "Custom Callback for Max Episode Reward using Stable Baselines3 with Custom Env",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1tog0/opensourced_nethack_2021_neurips_challenge/",
          "author": null,
          "description": "Recently, we have released the source code of our winning solution for the NetHack 2021 NeurIPS Challenge:\n https://github.com/maciej-sypetkowski/autoascend\n We hope that it will help in leveraging this complex environment, that still seems to be beyond capabilities of reinforcement learning. Check out links in the README \"Description\" section for more context.\n    submitted by    /u/procedural_only  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1tog0/opensourced_nethack_2021_neurips_challenge/",
          "publishedOn": "2022-04-12T07:54:45.000Z",
          "wordCount": 173,
          "title": "Open-sourced NetHack 2021 NeurIPS Challenge winning agent",
          "imageUrl": "https://external-preview.redd.it/Nqt-aA20mIGhIBUB0OpRBitbgSezPyJfZk3b-7nT6Ao.jpg?auto=webp&s=f5ef4c8831e121cfeb748e8328c82e52fe20d5ae"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1sqa2/project/",
          "author": null,
          "description": "Do any of u have any good rl project suggestion or a complete project for college major , I have only done work on some self playing Atari , mario games , if u have any good idea please suggest 🙌\n    submitted by    /u/stoned_egineer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1sqa2/project/",
          "publishedOn": "2022-04-12T06:46:59.000Z",
          "wordCount": 163,
          "title": "Project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1q15v/training_a_dqn_agent_for_platformer_game/",
          "author": null,
          "description": "Does anyone have experience training agents to play platformer games like mario? I am trying to train an agent for the platformer game Jump King to get past atleast a few levels, using DQN but the agent is performing poorly after 8000 episodes of training, (one episode being the agent spawns at the start and has 15 seconds or so to jump around gaining reward) he is barely able to get past the first level most of the time :c\n I am using a very basic sequential network of 2 Linear layers with inputDim 4, outputDim 4, and hiddenDim 32. and because my state is not using any image data, its just (current_level, x_pos, y_pos, jumpCount) as input to the network . As for the reward, I am using the y position to give reward if the agent is getting to a new level (large reward) or making progress in the current level (curr_y > old_y), otherwise the agent gets a negative reward.\n Should I consider using a CNN and image data to train this agent like in the atari games paper, or is using image data and a conv net going to perform worse rather than using my current state? Should I consider combining image data with the current state, or just keeping the current non-image data state but ?\n Also, roughly how long should I be training the agent for? is 8000 episodes not enough? 1 episode takes roughly 7 seconds in time (it is using pygame engine and I turned off the rendering and I think that made it a little bit faster)\n This is my first time training an agent for a hard game like this using DQN so I would appreciate any tips/advice to improve the agent! repo: https://github.com/senweim/JumpKingAtHome\n    submitted by    /u/TernaryJimbo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1q15v/training_a_dqn_agent_for_platformer_game/",
          "publishedOn": "2022-04-12T03:53:17.000Z",
          "wordCount": 583,
          "title": "Training a DQN agent for platformer game",
          "imageUrl": "https://external-preview.redd.it/_q5O0vyejO1QNlhnm3FzQByLjqArX9Azj4C2W37UJJo.jpg?auto=webp&s=95a72d122f292458457a5ac3f48fa1d7279626af"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1lqa1/which_environment_impress_you_related_with/",
          "author": null,
          "description": "I want to hear about your impressive environment! Specifically, I want to make my custom environment well using various library like openAI gym.\n In this contxet, I find out the highway-env https://github.com/eleurent/highway-env/ !\n I think this environment has convinient API for users.\n Thus, I make my custom env with referencing the highway-env\n https://preview.redd.it/ndl1h1dvpzs81.png?width=711&format=png&auto=webp&s=267320a9713d98e7e49c4bb89423e5a9612bad8e\n In this line, could you speak your best environment? It doesn't matter about your best env has any advantage!\n    submitted by    /u/Seungeon94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1lqa1/which_environment_impress_you_related_with/",
          "publishedOn": "2022-04-12T00:14:26.000Z",
          "wordCount": 199,
          "title": "Which environment impress you? (related with software architecture, API, ...)",
          "imageUrl": "https://external-preview.redd.it/3-M03DqnQMFxCl6FegDvqeHni6hub500G5v6XhJffBg.jpg?auto=webp&s=9247a1725e4ebbbcdd2ee361f15ef2776cdf7af3"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1kiox/strategies_to_deal_with_large_action_spaces/",
          "author": null,
          "description": "Hey guys,\n I tried building a PPO model for Wordle.\n My initial test was checking the performance of the model with just 100 words. The agent was able to learn within a few thousand epochs and had an average guess length of about 2.8 before it could correctly identify the words.\n However, when i extend the action space to the entire 2.3k words, the model barely learns. Even after a few 100k iterations, the mean length revolves around 5.9 (given wordle has a max of 6 attempts per game)\n Any suggestions on how to help the agent learn faster in large action spaces?\n ​\n I also tried an embedding based approach, but the performance was very similar.\n ​\n Thanks\n    submitted by    /u/altair9335  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1kiox/strategies_to_deal_with_large_action_spaces/",
          "publishedOn": "2022-04-11T23:15:04.000Z",
          "wordCount": 303,
          "title": "Strategies to deal with Large Action Spaces",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1eu6n/what_are_your_best_results_for_procgen_coinrun/",
          "author": null,
          "description": "Has anyone managed to get a consistent score of > 9 on CoinRun? I understand that some generated levels require LSTMs in order to be solvable 100% of the time, but even excluding these hard-core levels I can see some occasions where my agents are not operating with 100% effectiveness. For some reason \"fully solving\" CoinRun seems harder than expected.\n The papers on CoinRun usually just show the results after 100mm steps or so, but I am more interested in what the community has achieved with \"normal setups\".\n    submitted by    /u/tmuxed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1eu6n/what_are_your_best_results_for_procgen_coinrun/",
          "publishedOn": "2022-04-11T19:06:45.000Z",
          "wordCount": 213,
          "title": "What are your best results for ProcGen: CoinRun?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1dnth/how_to_use_the_same_action_in_trained_rl_network/",
          "author": null,
          "description": "I trained RL agent using stable baseline library and gym env. When I am trying to test agent, this makes different action when I am re running again. I used the same seed in test env.\n for i in range(length-lags-1): action, _states = model.predict(obs_test) obs_test, rewards, dones, info = env_test\n When I am runnig again the above code, I am getting the different results.\n    submitted by    /u/Mariam_Dundua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1dnth/how_to_use_the_same_action_in_trained_rl_network/",
          "publishedOn": "2022-04-11T17:57:53.000Z",
          "wordCount": 277,
          "title": "How to use the same action in trained RL network, when model is retested?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1bb4t/unity_rl_ml_agents_module_walker_example/",
          "author": null,
          "description": "Hi all, \n I'm trying to teach my custom fbx model to walk with the help of ppo, as in the example from ml agents. I have difficulties with the exact import and the assignment of rigidbody here, that is, the neural network is being trained, but for some reason physics does not work. Has anyone seen it, or does anyone have an example of how to train a unity custom fbx model using ml agents?\n Thx all!\n    submitted by    /u/IndependenceCivil576  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1bb4t/unity_rl_ml_agents_module_walker_example/",
          "publishedOn": "2022-04-11T16:13:23.000Z",
          "wordCount": 198,
          "title": "Unity RL ml agents module, walker example",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u14990/implementing_rl_algorithm_on_apache_spark/",
          "author": null,
          "description": "I want to run RL algorithm on Apache Spark. However, RL does not exists in Spark's MLib. Is it possible to implement it? any links may help. Thank you in advance\n    submitted by    /u/fatenLouati  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u14990/implementing_rl_algorithm_on_apache_spark/",
          "publishedOn": "2022-04-11T10:06:25.000Z",
          "wordCount": 198,
          "title": "Implementing RL algorithm on apache spark",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u0y1iv/is_reinforcement_learning_being_used_for_the/",
          "author": null,
          "description": "We will introduce the general process of self-driving tasks first and then the development of Reinforcement Learning in self-driving cars. \n The general process of self-driving tasks includes perceiving, decision-making, planning and controlling. The tasks of perceiving have adopted deep learning and that did a good job. Being different from monitoring learning, decision intelligence AI methods, which are represented by reinforcement learning, model the environment as Markov Decision Process(MDP)to get optimization. In sequential decision problems the utility of agent's actions do not depend on single decisions, expressed with the state, which the agent would have gotten into, as the result of this decision, but rather on the whole sequence of agent's action. \n Here, one thing that needs t…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u0y1iv/is_reinforcement_learning_being_used_for_the/",
          "publishedOn": "2022-04-11T03:10:19.000Z",
          "wordCount": 1182,
          "title": "Is reinforcement learning being used for the development of self-driving cars",
          "imageUrl": "https://external-preview.redd.it/mSgqsMn_oZHx1PllOQIWdMTwhDv7hynBEIa68WGyvQM.jpg?auto=webp&s=920cb071bff3b857cb2c176493fbd98c116be106"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u0o1kx/anybody_ever_programmed_a_1st_order_differential/",
          "author": null,
          "description": "submitted by    /u/SmarterCloud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u0o1kx/anybody_ever_programmed_a_1st_order_differential/",
          "publishedOn": "2022-04-10T18:44:01.000Z",
          "wordCount": 188,
          "title": "Anybody ever programmed a 1st order differential equation model in MuJoCo?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u0n5hv/google_ai_researchers_propose_a_metaalgorithm/",
          "author": null,
          "description": "In the field of artificial intelligence, reinforcement learning is a type of machine-learning strategy that rewards desirable behaviors while penalizing those which aren’t. An agent can perceive its surroundings and act accordingly through trial and error in general with this form or presence – it’s kind of like getting feedback on what works for you. However, learning rules from scratch in contexts with complex exploration problems is a big challenge in RL. Because the agent does not receive any intermediate incentives, it cannot determine how close it is to complete the goal. As a result, exploring the space at random becomes necessary until the door opens. Given the length of the task and the level of precision required, this is highly unlikely.\n Exploring the state space randomly with preliminary information should be avoided while performing this activity. This prior knowledge aids the agent in determining which states of the environment are desirable and should be investigated further. Offline data collected by human demonstrations, programmed policies, or other RL agents could be used to train a policy and then initiate a new RL policy. This would include copying the pre-trained policy’s neural network to the new RL policy in the scenario where we utilize neural networks to describe the procedures. This process transforms the new RL policy into a pre-trained one. However, as seen below, naively initializing a new RL policy like this frequently fails, especially for value-based RL approaches.\n Continue reading the summary\n Paper: https://arxiv.org/pdf/2204.02372.pdf\n Project: https://jumpstart-rl.github.io/\n https://reddit.com/link/u0n5hv/video/fnktgf0wqqs81/player\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u0n5hv/google_ai_researchers_propose_a_metaalgorithm/",
          "publishedOn": "2022-04-10T18:02:33.000Z",
          "wordCount": 484,
          "title": "Google AI Researchers Propose a Meta-Algorithm, Jump Start Reinforcement Learning, That Uses Prior Policies to Create a Learning Curriculum That Improves Performance",
          "imageUrl": "https://external-preview.redd.it/IUWWG2pHwr6M_wwbFIU4qpxTYNG55LMW8iuMjT-N6W8.jpg?auto=webp&s=0333c60118f14326da9c1ad378b561f37a2a453c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u0jtbs/socratic_models_composing_zeroshot_multimodal/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u0jtbs/socratic_models_composing_zeroshot_multimodal/",
          "publishedOn": "2022-04-10T15:22:26.000Z",
          "wordCount": 174,
          "title": "\"Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language\", Zeng et al 2022",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u0b8nw/classical_dynamic_programming_ve_policy_iteration/",
          "author": null,
          "description": "Cracking my head trying to figure out the differences between classical dynamic programming and policy iteration. I understand that policy iteration in itself is a form of dynamic programming. But if we were to compare the traditional operations of dynamic programming with policy iteration, what would be the differences.\n Thank you Heaps\n    submitted by    /u/BalramVeeragoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u0b8nw/classical_dynamic_programming_ve_policy_iteration/",
          "publishedOn": "2022-04-10T05:50:26.000Z",
          "wordCount": 240,
          "title": "Classical Dynamic Programming ve Policy Iteration",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u09lgv/is_my_understanding_to_why_future_rewards_being/",
          "author": null,
          "description": "To my understanding, the Q value is updated like this:\n Q[s,a] = Q[s,a] + lr * (reward + gamma * max(Q[s,a]t+1) — Q[s,a]) \n Where future state reward is considered since the best current reward doesn't grantee the optimal path. E.g.: \n  \nPath A: Q[s,a]t = 1, Q[s,a]t+1 = 10 Total: 11\n Path B: Q[s,a]t = 5, Q[s,a]t+1 = 1 Total: 6\n  \nNot sure if this is a good analogy but here it gives the result that A is the optimal path even though its immediate reward at (t) is less than B.\n Further Question:\n Is there additional benefits to considering future rewards further than Q[s,a]t+1 ?\n Example: \n Q[s,a] = Q[s,a] + lr * (reward + gamma* max(Q[s,a]t+2) - gamma * max(Q[s,a]t+1) — Q[s,a]) \n    submitted by    /u/DangerNoodle314  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u09lgv/is_my_understanding_to_why_future_rewards_being/",
          "publishedOn": "2022-04-10T03:59:28.000Z",
          "wordCount": 337,
          "title": "Is my understanding to why future rewards being considered correct?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u07y3v/any_reason_why_to_use_several_optimizers_in/",
          "author": null,
          "description": "Hi guys. I am currently implementing REDQ by modifying a working implementation of SAC (basically adapted from Spinup) and so far my implementation doesn't work, I am trying to understand why. By looking at the authors' implementation I notice they use 1 pytorch optimizer per Q network, whereas I only use 1 for all parameters. So I wonder, is there any good reason for using several optimizers here?\n Thanks!\n    submitted by    /u/yannbouteiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u07y3v/any_reason_why_to_use_several_optimizers_in/",
          "publishedOn": "2022-04-10T02:17:13.000Z",
          "wordCount": 344,
          "title": "Any reason why to use several optimizers in Pytorch implementation of REDQ?",
          "imageUrl": "https://external-preview.redd.it/WNSAA7ek709uuK0adnoPJTjafbMb5oTbtvgxMWHAGjM.jpg?auto=webp&s=ca5e2533e4c6cb29f06a857f944fcbc7f5f8c796"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u07740/learning_in_noisy_observation_space/",
          "author": null,
          "description": "I am fairly new to RL. I'm trying to train an agent (like in gym's Cartpole env) in an environment with noisy (Gaussian noise) observation. I have added Gaussian noise to angle only (not to cart position, cart velocity or ang_velocity). I was fooling around with PPO in stable_baselines but haven't had much luck. Any suggestions on what needs to be tweaked or any good algorithm for this task? \n Also, I tried changing the default forcing magnitude of 10 to other values like 30 but it didn't help much.\n Thanks\n    submitted by    /u/Black_Beard53  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u07740/learning_in_noisy_observation_space/",
          "publishedOn": "2022-04-10T01:33:08.000Z",
          "wordCount": 561,
          "title": "Learning in Noisy Observation space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u049oz/gizmo_is_eating_a_clothes_basket/",
          "author": null,
          "description": "submitted by    /u/mspurplekris  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u049oz/gizmo_is_eating_a_clothes_basket/",
          "publishedOn": "2022-04-09T22:46:30.000Z",
          "wordCount": 95,
          "title": "Gizmo is eating a clothes basket",
          "imageUrl": "https://external-preview.redd.it/C8ARUSGC5ZEyVpjpSpYsycIEJfjoC579hwDthyzwJak.png?blur=40&format=pjpg&auto=webp&s=f3be29fb88d38efbe7d113cc1f952a0589c1e209"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u03y3i/habitatweb_learning_embodied_objectsearch/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u03y3i/habitatweb_learning_embodied_objectsearch/",
          "publishedOn": "2022-04-09T22:29:30.000Z",
          "wordCount": 217,
          "title": "\"Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale\", Ramrakhya et al 2022 {FB} (log-scaling of crowdsourced imitation learning in VR robotics)",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u02tyk/is_it_possible_to_implement_acer_with_a2c/",
          "author": null,
          "description": "I'm looking into implementing a replay buffer in A2C. I came upon the ACER [paper](https://arxiv.org/pdf/1611.01224.pdf). From my understanding, it looks like ACER is an extension of A3C, and it seems like the difference between A2C and A3C is that in A2C parameters are updated synchronously and that helps with big batch sizes. \n Is it still possible to implement some kind of replay buffer on A2C?\n Are there any papers that involve implementing a paper with A2C that you recommend I read?\n I'm new to the area of reinforcement learning, so I would be very grateful for any kind of help you can offer. Thanks in advance\n    submitted by    /u/lebr0n99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u02tyk/is_it_possible_to_implement_acer_with_a2c/",
          "publishedOn": "2022-04-09T21:32:29.000Z",
          "wordCount": 245,
          "title": "Is it possible to implement ACER with A2C?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u00ann/does_anyone_have_a_link_to_the_rl_discord_server/",
          "author": null,
          "description": "Supposedly there is a popular discord server for the RL community, however I am having difficulty finding it.\n    submitted by    /u/jclaessens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u00ann/does_anyone_have_a_link_to_the_rl_discord_server/",
          "publishedOn": "2022-04-09T19:23:29.000Z",
          "wordCount": 147,
          "title": "Does anyone have a link to 'The RL Discord Server'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzvnhc/imitating_fast_and_slow_robust_learning_from/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzvnhc/imitating_fast_and_slow_robust_learning_from/",
          "publishedOn": "2022-04-09T15:34:42.000Z",
          "wordCount": 156,
          "title": "\"Imitating, Fast and Slow: Robust learning from demonstrations via decision-time planning\", Qi et al 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tztri9/reinforcement_learning_looking_for_some_resources/",
          "author": null,
          "description": "Hello friends,\n I'm looking for some resources that would let me quickly start with Reinforcement Learning (preferably in Python). I have some experience with supervised learning (e.g. deep nets) and would like to complement with some RL. Preferably a walkthrough with some examples of implementation. Can you recommend something?\n Thanks in advance!\n    submitted by    /u/andy-codes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tztri9/reinforcement_learning_looking_for_some_resources/",
          "publishedOn": "2022-04-09T13:59:47.000Z",
          "wordCount": 273,
          "title": "Reinforcement Learning - looking for some resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzt78z/im_dumb_at_maths_what_does_this_mean/",
          "author": null,
          "description": "So learning about e-mail learning same have it all understood except for the max thingy. If you care enough to click this blog it's not my blog):\n https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56\n I don't know how to turn this into to a real example:\n Update q values\n Q[state, action] = Q[state, action] + lr * (reward + gamma * np.max(Q[new_state, :]) — Q[state, action])\n Specifically the last bit: \n np.max(Q[new_state, :]) — Q[state, action])\n What does the numpy max actually operate on here?\n Any hard examples? Thanks.\n    submitted by    /u/Togfox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzt78z/im_dumb_at_maths_what_does_this_mean/",
          "publishedOn": "2022-04-09T13:28:32.000Z",
          "wordCount": 566,
          "title": "I'm dumb at maths: what does this mean?",
          "imageUrl": "https://external-preview.redd.it/soqDPbsOXDAx8rb1fY_2BPuguBAOAi7BxwtrOHfJeW0.jpg?auto=webp&s=f7d397129c0a0c3d32549fc5ec56ec6470340e9f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzekkb/rl_for_dynamic_environments/",
          "author": null,
          "description": "In their 2019 review article in Nature Machine Intelligence, Neftci and Averbeck point out, “Most work in biological systems has focused on simple learning problems… where flexibility and ongoing learning are important, similar to real-world learning problems. In contrast, most work in artificial agents has focused on learning a single complex problem in a static environment.”\n Are there RL approaches designed to handle dynamic environments with changing reward functions?\n I did find this earlier post, but thought I'd ask if anyone had other suggested lines of reading.\n Thanks!\n    submitted by    /u/Careless-Argument-37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzekkb/rl_for_dynamic_environments/",
          "publishedOn": "2022-04-08T22:04:50.000Z",
          "wordCount": 244,
          "title": "RL for dynamic environments",
          "imageUrl": "https://external-preview.redd.it/JQx2wIoJt26buLNeTwF2B2kRUu7jfG6Pti_qzRMR2bA.jpg?auto=webp&s=3ace57f9a34e9fe66349fc640a95decc42fcf934"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzee5s/observationspace_max_size/",
          "author": null,
          "description": "I want to give my AI as many information as possible. Can there be an Issue with a too large observation space?\n    submitted by    /u/Willing-Classroom735  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzee5s/observationspace_max_size/",
          "publishedOn": "2022-04-08T21:56:32.000Z",
          "wordCount": 237,
          "title": "Observationspace max Size?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tz4u57/uc_berkeleys_pieter_abbeel_receives_2021_acm/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tz4u57/uc_berkeleys_pieter_abbeel_receives_2021_acm/",
          "publishedOn": "2022-04-08T14:30:24.000Z",
          "wordCount": 149,
          "title": "\"UC Berkeley’s Pieter Abbeel receives 2021 ACM Prize in Computing\" (for DRL robotics)",
          "imageUrl": "https://external-preview.redd.it/FzJ8NRe2mu_Hd_oJNkTrpZw1A6d1wJnhzgz-JqSkmjk.jpg?auto=webp&s=8c1b8d2a0856815293f22351ef8d0b6d3dca408b"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tyxrzi/action_space_dimensional_reduction_for_better/",
          "author": null,
          "description": "I am working on a project in which a robots learns its motion. for example Bipedal robot learns to walk on a straight line by learning to adjust the torque and angular velocity of each joint. However, the robot I am working on has complex architecture. It has 10 joints instead of 2, most importantly all of these joints work simultaneously and coherently to produce a desired motion.\n The Problem I am facing is that, the robot has ten joints and each joint can move between -450 to +450\n for simplicity let me define State and Actions of the system\n State = -450 to +450 -------------> normalization ------------------> -10 to 10\n Actions = choose an angle between -10 to 10 for each joint \n Total Action space for each State at each time step = 10 (no of joints each can move between -10 to 10 at each time step) * 360 (total time steps for a single motion) = 3600 (Output: No of angles required to generate a motion)\n I am using TD3 to solve this conundrum. The Action space is too large how can I reduce the action space?\n    submitted by    /u/SAM_Baloch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tyxrzi/action_space_dimensional_reduction_for_better/",
          "publishedOn": "2022-04-08T07:08:41.000Z",
          "wordCount": 491,
          "title": "Action Space Dimensional reduction for better convergence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tytrpx/dynamic_action_space_in_rl/",
          "author": null,
          "description": "I am doing a project and there is a problem with dynamic action space\n A complete action space can be divided into four parts. In each state, the action to be selected is one of them\n For example, the total discrete action space length is 1000, which can be divided into four parts, [0:300], [301:500],[501:900],[901:1000]\n For state 1, action_ space is [0:300], State2, action_ space is [301:500], etc\n For this idea, I have several ideas at present:\n  \nThere is no restriction at all. The legal actions of all States are [1:1000], but it may take longer train time and there is not much innovation\n Soft constraint, for example, if state1 selects an illegal action, such as one action in [251: 500], reward gives a negative value, but it is also not innovative\n Hard constraint, use action space mask in each state, but I don't know how to do it.. Is there any relevant article？\n It is directly divided into four action spaces and uses multi-agent cooperative relationship learning\n  \n​\n Any suggestions？\n thanks！\n    submitted by    /u/RangerWYR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tytrpx/dynamic_action_space_in_rl/",
          "publishedOn": "2022-04-08T02:58:27.000Z",
          "wordCount": 725,
          "title": "Dynamic action space in RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tyqv88/any_paper_suggestions/",
          "author": null,
          "description": "Hi everyone, i have to define a project for my master degree, so i'm looking for the best papers published since 2018-2019 until now in Reinforcement Learning . Do you have any suggestions, titles or projects that i can check?\n    submitted by    /u/acaviedes15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tyqv88/any_paper_suggestions/",
          "publishedOn": "2022-04-08T00:22:24.000Z",
          "wordCount": 151,
          "title": "Any paper suggestions??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tyog3i/implementation_of_rl/",
          "author": null,
          "description": "Hi all! I am a beginner in RL field and am trying to implement the RL algorithm in the following paper :\n [1912.04321] Learning to Code: Coded Caching via Deep Reinforcement Learning (arxiv.org)\n In short, we are trying to achieve the minimum number of transmission of bits from the server to all users\n Now, after 500 episodes of training the number of transmissions does decrease. But when I implement the same actor critic algorithm this does not happen. In fact, the results seem to be completely random. \n Here is the plot of the same :\n https://preview.redd.it/yve3cay7l6s81.png?width=745&format=png&auto=webp&s=36bf4f0aa813a30024128d797acde3b8adc2df30\n Although my training parameters are slightly different, I can't understand why this would happen.\n I used the parameters and pseudo code from this paper: A Deep Reinforcement Learning Approach for Shared Caching | IEEE Conference Publication | IEEE Xplore - which is an extension of the link at the top.\n ​\n Attaching link to my code: https://www.kaggle.com/samarthtiwari123/rl-for-coded-caching\n Any help would be helpful!!\n Thanks in advance\n    submitted by    /u/samt_123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tyog3i/implementation_of_rl/",
          "publishedOn": "2022-04-07T22:21:20.000Z",
          "wordCount": 261,
          "title": "Implementation of RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tynq4i/how_can_i_extract_the_direction_a_specific_agent/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tynq4i/how_can_i_extract_the_direction_a_specific_agent/",
          "publishedOn": "2022-04-07T21:47:08.000Z",
          "wordCount": 188,
          "title": "How can I extract the direction a specific agent is facing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tylf8u/flow_of_gradients_through_multiple_classes/",
          "author": null,
          "description": "Naive question: if I define my RL model as a combination of different classes (one class that preprocesses the observation, one class that processes the observation, one class that outputs the actions, etc.), is this going to affect the flow of gradients in PyTorch? The alternative would be to create only one class in which I combine everything\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tylf8u/flow_of_gradients_through_multiple_classes/",
          "publishedOn": "2022-04-07T20:01:03.000Z",
          "wordCount": 254,
          "title": "Flow of gradients through multiple classes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tycj9d/can_kl_divergence_be_used_as_a_metric_to_see_the/",
          "author": null,
          "description": "In the hyper parameter section of the paper, it is written that step size of Adam is varied according to KL divergence. So I wanted to know is KL divergence the correct metric to be used for observing the learning progress because we have many states for which probabilites of a particular action is either increased or decreased thus taking average KL mixes up a lot of things.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tycj9d/can_kl_divergence_be_used_as_a_metric_to_see_the/",
          "publishedOn": "2022-04-07T12:59:23.000Z",
          "wordCount": 366,
          "title": "Can KL divergence be used as a metric to see the learning progress in PPO?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ty2dt2/weight_decay_in_policy_network_for_discrete_sac/",
          "author": null,
          "description": "We’re finding that our network is returning a tensor of NaNs towards the end of training. Adding weight decay solves this issue but reduces learning, was wondering if anyone else had experience with vanishing gradients in off-policy methods or any insight?\n    submitted by    /u/TerrificJam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ty2dt2/weight_decay_in_policy_network_for_discrete_sac/",
          "publishedOn": "2022-04-07T02:09:30.000Z",
          "wordCount": 167,
          "title": "Weight decay in policy network for Discrete SAC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txyv62/question_about_model_predictive_control_mpc_cost/",
          "author": null,
          "description": "To my understanding, the cost function is the error between predicted state value and real state value.\n So if I use a neural network as my dynamics model(unknown true dynamics), the MPC cost function is equivalent to NN’s loss function?\n    submitted by    /u/Blasphemer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txyv62/question_about_model_predictive_control_mpc_cost/",
          "publishedOn": "2022-04-06T23:07:19.000Z",
          "wordCount": 299,
          "title": "Question about Model Predictive Control (MPC) cost function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txxore/learning_to_play_settlers_of_catan_with_deep_rl/",
          "author": null,
          "description": "submitted by    /u/henrythepaw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txxore/learning_to_play_settlers_of_catan_with_deep_rl/",
          "publishedOn": "2022-04-06T22:10:27.000Z",
          "wordCount": 318,
          "title": "Learning To Play \"Settlers of Catan\" With Deep RL - code and write-up",
          "imageUrl": "https://external-preview.redd.it/MCy14opBjTIKzwl5JN-l_h8ogp8jGD7JGmk-A4mmZJI.jpg?auto=webp&s=b34f246a1d389b97fb2013f3661ccf8afbf4403e"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txvc52/which_environments_do_you_use_for_benchmarking/",
          "author": null,
          "description": "Hey guys I'm curious which environments you use to benchmark your standard RL algorithms.\n I typically use some environments from the OpenAI Gym or the DM control suite but benchmarking all my implementations against all environments for multiple seeds would take forever. Are there some of their environments you particularly like for benchmarking?\n    submitted by    /u/NiconiusX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txvc52/which_environments_do_you_use_for_benchmarking/",
          "publishedOn": "2022-04-06T20:24:16.000Z",
          "wordCount": 175,
          "title": "Which environments do you use for benchmarking?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txtzv6/how_does_advantage_estimation_is_done_when/",
          "author": null,
          "description": "In the PPO paper it is stated that we have to collect trajectories of length T from N different workers. Suppose I am not using multiple workers then I have to collect episodes N times of fixed length T. But these episode lengths are variable i.e. some episodes end much before T and some much after T. So my question is how do we calculated advantage because according to the PPO paper, for generalized advantage estimate, we have to observe the reward of terminal state. \n ​\n So how should I calculate GAE in this ?\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txtzv6/how_does_advantage_estimation_is_done_when/",
          "publishedOn": "2022-04-06T19:24:05.000Z",
          "wordCount": 254,
          "title": "How does advantage estimation is done when episodes are of variable length in PPO?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txs2jh/a_silly_question_from_a_new_beginner/",
          "author": null,
          "description": "I could not find an answer to a question hanging around in my head for a while. Suppose we have some data, if we build up an MDP to capture actions + state dynamics. Would the optimal policy win state-of-art RL algorithms?\n Edit: If that is the case, why would the community bothers with learning algorithm since finding the model of dynamics is the key?\n ​\n    submitted by    /u/musicinthedark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txs2jh/a_silly_question_from_a_new_beginner/",
          "publishedOn": "2022-04-06T17:56:48.000Z",
          "wordCount": 559,
          "title": "A silly question from a new beginner",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txhq5z/what_does_it_look_like_the_output_of_a/",
          "author": null,
          "description": "Hello,\n I am relatively new in the area of machine learning/reinforcement learning. I have this basic question regarding practical implementations. I just want to know, what does it look like the output of a reinforcement learning agent/algorithm in practice? Is it like a 'look-up table' that will set the weights/parameters of the ML model based on the input data? \n Note that I am asking after the offline training of the agent. How to implement the trained agent in practice, like in an embedded system? Do you guys have references or clues to help me to clarify?\n BR\n    submitted by    /u/b0bzera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txhq5z/what_does_it_look_like_the_output_of_a/",
          "publishedOn": "2022-04-06T08:55:08.000Z",
          "wordCount": 352,
          "title": "What does it look like the output of a reinforcement learning agent/algorithm in practice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txhgbe/multidiscrete_action_space_in_sacsoft_actorcritic/",
          "author": null,
          "description": "Hello!\n I am using SAC(Soft Actor-Critic) to complete a reinforcement learning task with only four steps, each action is from one of four different action spaces. These four action spaces are essentially the same, and they are all chemical compound. I just want the agent to take different types of compounds at each step.\n I have the following questions：\n  \nWhether the different four steps can be trained? In fact, there is a paper that only has four steps in a reinforcement learning process, but his action space only has one discrete action space.\n Is there any article I can learn from? because I know that for the handle control of the game, there are usually multiple discrete action spaces, but each discrete space dimension of my task is larger, such as [800, 700, 500, 600]\n  \nThanks！\n    submitted by    /u/RangerWYR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txhgbe/multidiscrete_action_space_in_sacsoft_actorcritic/",
          "publishedOn": "2022-04-06T08:33:16.000Z",
          "wordCount": 314,
          "title": "multi-discrete action space in SAC(Soft Actor-Critic)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txfewf/is_multi_bandit_on_policy_or_off_policy/",
          "author": null,
          "description": "quick question\n    submitted by    /u/Asleep_Donut1382  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txfewf/is_multi_bandit_on_policy_or_off_policy/",
          "publishedOn": "2022-04-06T06:04:14.000Z",
          "wordCount": 128,
          "title": "Is multi bandit on policy or off policy？",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txe8rj/how_wrong_is_it_to_use_sampling_at_inference_time/",
          "author": null,
          "description": "At my company we use RL to solve our problem. The thing is : our problem is rather complex, and this is the core of our product (so clients rely on the results produced). \n In order to reach satisfying results despite an agent that doesn't learn very well, we use sampling at inference time : instead of taking the best trajectory according to the agent, we take X trajectories and keep only the one with the best reward.\n This seems completely fine at first (similar things are done in NLP for example, with beam search), but in our case the sampling size is huge : 1024. Usually when using beam search, we use maybe a beam size of 6. Maybe 10 if you have good hardware ?\n ​\n Now, the agent seems to be learning : the mean return is slightly increasing over time, the entropies for the actions are steadily decreasing, etc...\n Now the goal of the ML team is to improve agent's learning to decrease the sampling size at inference time (because it's costly to run 1024 trajectories through the environment...).\n But whatever we try, the improvements are not reflected (we compare all our experiments with 1024 sampling in order to see what the customers will see).\n ​\n IMO this is because our sampling size is way too huge, even a random agent can produce okay-ish results...\n Is my intuition the right one ?\n    submitted by    /u/dummy-gummy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txe8rj/how_wrong_is_it_to_use_sampling_at_inference_time/",
          "publishedOn": "2022-04-06T04:51:21.000Z",
          "wordCount": 485,
          "title": "How wrong is it to use sampling at inference time ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txduuq/does_a_masters_thesisdoctoral_dissertation_need/",
          "author": null,
          "description": "I'm in the last semester of my undergraduate degree; over the past couple of weeks, I've been trying to brainstorm ideas that I would like to pursue in my graduate research career. I'm interested in the emergence of language in multi-agent reinforcement environments but I can't see how this would be important down the line when there are large language models that are completely dominating language and communication. \n Should this stop me from pursuing this idea or should I let my interest in the idea take precedence?\n    submitted by    /u/clarky103  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txduuq/does_a_masters_thesisdoctoral_dissertation_need/",
          "publishedOn": "2022-04-06T04:27:30.000Z",
          "wordCount": 283,
          "title": "Does a master's thesis/doctoral dissertation need to have implications down the line for it to be good?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txbvya/how_long_would_it_take_you_to_implement_a_marl/",
          "author": null,
          "description": "Out of curiosity, how long would it take to implement a paper like this one? https://arxiv.org/abs/2104.07750 \n It has PPO agents in MARL, all of them with multihead attention performed on the observation, in such a way that an attention map is created for each agent. This attention map has information about how strongly each agent is attending to various elements of the environment. With KL divergence, the agents are rewarded for minimizing the difference between their attention maps.\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txbvya/how_long_would_it_take_you_to_implement_a_marl/",
          "publishedOn": "2022-04-06T02:37:14.000Z",
          "wordCount": 256,
          "title": "How long would it take you to implement a MARL PPO agent with joint attention architecture?",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tx2zbs/need_project_suggestions/",
          "author": null,
          "description": "I’ve been running circles in tutorial purgatory and I want to get out of it with sone projects. Anyone has any suggestions? Guided ones would be nice. For unguided ones, could you please provide source links/hints?\n    submitted by    /u/HellVollhart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tx2zbs/need_project_suggestions/",
          "publishedOn": "2022-04-05T19:31:36.000Z",
          "wordCount": 220,
          "title": "Need project suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tx0cmf/agents_learns_policy_when_sampling_last_episode/",
          "author": null,
          "description": "Hi all. I've been stuck on this problem for a while and I thought I might be able to find some help here. Any kind of assistance would be greatly appreciated. \n My setup is as follows. I have an environment with 3 agents. All 3 agents have a single policy network, and it is based on CommNet. My goal is to implement a replay buffer for this environment. I verified that my replay buffer logic is good. I tried running 3 different types of runs:\n  \nNormal on-policy run: The agents perform an episode, and at the end of each episode the data (such as the states, actions, etc) from this episode are used to calculate the loss\n Using just the last episode from the replay buffer: The agents perform an episode, and the data is stored in the replay buffer. At the end of each episode, the last episode is sampled from the replay buffer (which is the episode that was just performed). This is just to confirm that my replay buffer is working properly, and the reward curve for this case matches that from (1).\n Using 1 random episode from the replay buffer: The agents perform an episode, and the data is stored in the replay buffer. At the end of each episode, a random episode is sampled from the replay buffer and used to calculate the loss. The performance is terrible in this case, and the environment times out each time\n  \nFor some reason, as soon as I turn on random sampling, progress is really bad. I'm sorry to pose such an open-ended question, but what are some things I could check to pinpoint the source of this problem? What could be a reason as to why performance is as expected when just sampling the last episode, whereas it is terrible when randomly sampling episodes? I've tried some things thus far but nothing has worked, and I turned to this community in hopes of getting some help. I'm new to the area of reinforcement learning, so I would be very grateful for any kind of help you can offer. Thanks in advance\n    submitted by    /u/lebr0n99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tx0cmf/agents_learns_policy_when_sampling_last_episode/",
          "publishedOn": "2022-04-05T17:33:13.000Z",
          "wordCount": 822,
          "title": "Agents learns policy when sampling last episode from replay buffer, but don't when randomly sampling from the replay buffer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twvl67/ppo_sample_correlation/",
          "author": null,
          "description": "Hi, I'm wondering if the PPO algorithm can solve the sample correlation problem of on-policy algorithm in training. PPO uses successive samples to compute GAE, doesn't the sample correlation occurring here interfere with learning?\n    submitted by    /u/noisemastar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twvl67/ppo_sample_correlation/",
          "publishedOn": "2022-04-05T13:59:05.000Z",
          "wordCount": 145,
          "title": "PPO sample correlation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twu26i/p_automlconf_competition_dac4automl/",
          "author": null,
          "description": "submitted by    /u/catsortion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twu26i/p_automlconf_competition_dac4automl/",
          "publishedOn": "2022-04-05T12:42:37.000Z",
          "wordCount": 251,
          "title": "[P] AutoML-Conf Competition: DAC4AutoML",
          "imageUrl": "https://external-preview.redd.it/hwN3EBf7WXi3MEvXiPgqOQzZmfA3yEU8ZOPYIry-WJw.jpg?auto=webp&s=e08b4e79f3d8a80bcf43263d687e29f7665b1ad1"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twu0ai/temporal_difference_learning_for_model_predictive/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twu0ai/temporal_difference_learning_for_model_predictive/",
          "publishedOn": "2022-04-05T12:39:47.000Z",
          "wordCount": 135,
          "title": "Temporal Difference Learning for Model Predictive Control",
          "imageUrl": "https://external-preview.redd.it/Gljiri4TRWX3LOG95WYZE6MZGLdmGsASRjvASplDC7E.jpg?auto=webp&s=090bac27aa9321e9cdce487f0e8952373244ca01"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twtuwp/why_is_there_no_rollout_monitoring_for_this/",
          "author": null,
          "description": "​\n Output from using model.learn(env) on both Envs\n On the left I have a simple dummy CustomEnv (Using Stable-Baselines3 with Gym) for testing, and on the right I have my actual CustomEnv that I am working on in a project.\n As you can see, the dummy environment gives me the rollout monitoring, whereas there is no rollout monitoring for the actual environment (just time + train statistics/monitoring). \n I am using very similar code when setting up the training of the model, however the complexity of the actual model is significantly higher than the dummy. In theory, the complexity of the environment shouldnt make a big difference to the monitoring right? All of the key parts are still there (reward function, step function, reset function etc.).\n In both cases it says that the environments are being wrapped by the 'Moniter' wrapper so that cant be it.\n Does anyone know why this might be happening?\n    submitted by    /u/C_BearHill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twtuwp/why_is_there_no_rollout_monitoring_for_this/",
          "publishedOn": "2022-04-05T12:31:27.000Z",
          "wordCount": 288,
          "title": "Why is there no rollout monitoring for this CustomEnv (on the right) ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twrz5x/value_iteration_in_car_racing_v1/",
          "author": null,
          "description": "I’m working on Q table learning model for OpenAI’s. I have everything done in regards to a basic agent, but I’m unsure how I’m supposed to use the box data for action space and observance space, to populate a q table?\n Or is this approach incorrect? Car Racing doesn’t have a P (probability) call so I’m not sure how else I would do value iteration.\n    submitted by    /u/Dzartovian94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twrz5x/value_iteration_in_car_racing_v1/",
          "publishedOn": "2022-04-05T10:38:55.000Z",
          "wordCount": 405,
          "title": "Value Iteration in Car Racing V1",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twp4x8/action_spaces_all_landing_to_zero_probability_in/",
          "author": null,
          "description": "Hey guys, I am new to RL and walking through the Keras implementation of Actor Critic.\n ​\n As a variant of it, I am trying to learn the strategy for WORDLE. However, after a few runs, my action spaces all go down to zero. Not sure what's happening. Could someone have any insights or pointers?\n ​\n Attaching my code for reference.\n ​\n Thanks\n import pandas as pd import numpy as np import random import string import random import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers # Configuration parameters for the whole setup gamma = 0.9 # Discount factor for past rewards max_runs = 10000 eps = np.finfo(np.float32).eps.item() # Smallest number such that 1.0 + eps != 1.0 my_file = open(\"<wordle set of words data path>\", \"r\") content = my_file.read() content = lis…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twp4x8/action_spaces_all_landing_to_zero_probability_in/",
          "publishedOn": "2022-04-05T07:13:26.000Z",
          "wordCount": 964,
          "title": "Action Spaces all landing to zero probability in few steps",
          "imageUrl": "https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?auto=webp&s=079a7260ec149880c73263d64811698adb22760a"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twlxdl/any_rlrelated_conferences_right_after_neurips_22/",
          "author": null,
          "description": "In case my NeurIPS submission rejected, lol.\n    submitted by    /u/Blasphemer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twlxdl/any_rlrelated_conferences_right_after_neurips_22/",
          "publishedOn": "2022-04-05T03:51:12.000Z",
          "wordCount": 226,
          "title": "Any RL-related conferences right after NeurIPS 22’?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twg36r/ppo_alg_confusion/",
          "author": null,
          "description": "As I read the paper and several tutorials, I am quite confused about the details.\n  \nI see many implementations scale the running cumulative discounted reward in a certain way. However, each of them does it in a different way. let R be the running cumulative discounted reward, which is considered the best? Or is there a source of the method to use? implementations I saw from different places include: \n  \n directly use R to calculate the advantage and training value network (most PPO tutorials use this)\n use (R / std(R)), where std is the mini-batch standard deviation\n use (R / std(R)), where std is the running standard deviation\n use ((R - mean(R)) / std(R)), where both mean and std are mini-batch wise\n use ((R - mean(R)) / std(R)), where both mean and std are running stats.\n do the above and clip to a certain range ([-10, 10] or [-1, 1])\n  \n I also see several different ways for the value network, let V be the output of the value network:\n  \n output raw logit, without any scaling/output activation (most PPO tutorials use this)\n output raw logit, but use the same scaling as discussed above for running cumulative discounted reward, for example, if return value is (R / std(R)), value output will be (V / std(R))\n do the same as 2, but use the stat of V instead of R for scaling, for example, if the return value is (R / std(R)), the value output will be (V / std(V))\n output with tanh activation at the last layer\n output with tanh activation at the last layer, and multiply by a constant to match the range of the return\n  \nany help would be appreciated, thanks!\n    submitted by    /u/seermer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twg36r/ppo_alg_confusion/",
          "publishedOn": "2022-04-04T23:10:05.000Z",
          "wordCount": 552,
          "title": "PPO Alg confusion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twbnb2/im_completely_new_to_rl_and_will_be_building_my/",
          "author": null,
          "description": "Hello all,\n As the title describes, I’ll be making my first model as part of my final project. I still have a pretty high-level understanding of everything, so forgive any inaccuracies as I describe what I’m going for.\n The problem I’m attempting to solve is known as the traveling salesman problem. Essentially, a route needs to be formulated that stops at n given locations. Finding the most efficient route with many stops algorithmically is impractical because the number of possible routes increases exponentially with each added location. \n The environment will simulate travel on city roads. Speed will be a constant, set to whatever the roads speed limit is. I am using .pbf format vector GIS data from OSM so that the environment consists of real-world pathways. I’m using GeoPandas and Pyrosm to work with the data, and I’m collecting nodes for the location of gas stations so that the environment can simulate needing to fuel the vehicle. Gas price will be a constant, as well as vehicle fuel-efficiency.\n Scoring will be based on the calculated time it would take to complete a route and the calculated cost (in gas). The goal will be to find the most efficient route to take when n = some large number. \n I’ve never worked with spatial data either, so I’m not sure what kind of challenges that poses. I worry that adding nodes for the locations of gas stations might be difficult. I’m also wondering if I’m better off using Tensorflow and Keras for this, but I’m not really aware of all the technical considerations I should be making before deciding on that.\n Do you have any tips that might help me out? Solutions to problems I haven’t hit just yet, but likely will? \n Thanks for your help!\n    submitted by    /u/professorDissociate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twbnb2/im_completely_new_to_rl_and_will_be_building_my/",
          "publishedOn": "2022-04-04T20:07:52.000Z",
          "wordCount": 475,
          "title": "I’m completely new to RL and will be building my first model as part of my degree-ending project. Do you have any tips you can provide?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twbn40/best_implementations_for_extensibility/",
          "author": null,
          "description": "As far as I am aware, StableBaselines3 is the gold standard for reliable implementations of most popular / SOTA deep RL methods. However working with them in the past, I don't find them to be the most usable when looking for extensibility (making changes to the provided implementations) due to how the code base is structured in the behind the scenes (inheritance, lots of helper methods & utilities, etc.).\n For example, if I wish to change some portion of a method's training update with SB3 it would probably involve overloading a class method before initialization, making sure al the untouched portions of the original method are carried over, etc.\n Could anyone point me in the direction of any implementations that are more workable from the perspective of extensibility? Ideally implementations that are largely self contained to a single class / file, aren't heavily abstracted aware across multiple interfaces, don't rely heavily on utility functions, etc.\n    submitted by    /u/Farconion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twbn40/best_implementations_for_extensibility/",
          "publishedOn": "2022-04-04T20:07:40.000Z",
          "wordCount": 367,
          "title": "Best implementations for extensibility?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twaicu/is_it_possible_to_use_inspectgetcallargs_to/",
          "author": null,
          "description": "Given a NN class, is there something specific we need to care of when converting *args and **kwargs to a canonical kwarg representation? I ask this because in this code from Google (https://github.com/google-research/google-research/blob/c56b47713b08c95ad427d5f93ee0dbb9ad008964/social_rl/multiagent_tfagents/joint_attention/attention_networks.py#L557) they use a TFDecorator-aware replacement for inspect.getcallargs, instead of using getcallargs directly. So my questions are: \n - Is it possible to use inspect.getcallargs to convert *args and **kwargs to a canonical kwarg representation?\n - If no, is there an equivalent in PyTorch? I couldn't find any, so I was wondering how people go about that.\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twaicu/is_it_possible_to_use_inspectgetcallargs_to/",
          "publishedOn": "2022-04-04T19:21:36.000Z",
          "wordCount": 242,
          "title": "Is it possible to use inspect.getcallargs to convert *args and **kwargs to a canonical kwarg representation in RL?",
          "imageUrl": "https://external-preview.redd.it/CMhpMLhb6T0d4kqxMnDmxlqLqBIUASjloDaZLDY4pDk.jpg?auto=webp&s=411a8f7f0fc00a11f3af1004038b99d54177481c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw75kp/openai_gym_return_donetrue_but_not_seeing_goal_is/",
          "author": null,
          "description": "Hi all, I am running some starter code from openAI(FetchReach-v1, FetchPush-v1) gym with env.action_space.sample(). But I don't see the goal is actually achieved when done returned is True. I copied the code from here (https://openai.com/blog/ingredients-for-robotics-research/). I even let it sleep every step to watch more closely. Another related thing that I can't explain is that it always returns done==True rather quickly with very few sampled actions. These all make me worried about using it as my task environment.\n    submitted by    /u/AnimatorRemarkable20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw75kp/openai_gym_return_donetrue_but_not_seeing_goal_is/",
          "publishedOn": "2022-04-04T17:04:39.000Z",
          "wordCount": 304,
          "title": "openAI gym return done==True but not seeing goal is reached",
          "imageUrl": "https://external-preview.redd.it/lrIvaCZG-_bxok-lBkmGtKy2ufLuAQcEhYGt1O-R0rY.jpg?auto=webp&s=24d01b26bc9d2333ef8868067f3263d0ed1601c3"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw3fii/which_elective_monte_carlo_simulation_or/",
          "author": null,
          "description": "Hello /r/reinforcementlearning. I have to choose electives pretty soon, and as i am interested in reinforcement learning, I wanted to know which of these would be the most beneficial. \n  \nMonte Carlo Simulation\n Computational Learning Theory\n  \nThe year after I will also take a course on Reinforcement Learning, but it has not been created yet. \n Note: I can also take both if recommended, if I do so, I will take one of the courses before taking the RL course, and the other would be at the same time. \n Some further thought I've had:\n  \nCLT includes Bandits, which is surely were useful to know, but it seems to be only a rather small part, and I'm unsure whether all the other topics like PAC Learning and Rademacher Bounds are useful?\n \nMC is more practical while CLT is more theoretic (Apparently VERY theoretic according to the course description above). I am not afraid of theoretic courses, but I struggle more with them than more practical courses.\n \nThe sentiment around the MC course, is that it is pretty good. I don't know anyone who have taken the CLT course.\n \nIf I choose both, which order would you take them in?\n \n    submitted by    /u/John_Hitler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw3fii/which_elective_monte_carlo_simulation_or/",
          "publishedOn": "2022-04-04T14:30:21.000Z",
          "wordCount": 462,
          "title": "Which elective: Monte Carlo Simulation or Computational Learning Theory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw2v97/ray_rl_lib_observations_normalized/",
          "author": null,
          "description": "Hey i am using the RL lib from ray and i don't know if the observations automatically normalized by the lib or not?\n By creating a costum environment ray wants you to create an observationspace. That would be a gym box in my case. Anyway idk the exact high and low values. My values lay between -1 and 1 more or less. \n My fear is now that ray would normalize the Observation values to a new range although they are already processed. Does ray normalized observationspace? If yes how can i turn it off?\n Thanks!\n    submitted by    /u/Willing-Classroom735  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw2v97/ray_rl_lib_observations_normalized/",
          "publishedOn": "2022-04-04T14:06:31.000Z",
          "wordCount": 266,
          "title": "Ray RL lib observations normalized?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw2dla/cfp_evorl_gecco_2022_one_week_before_the_deadline/",
          "author": null,
          "description": "CALL FOR PAPERS\n EvoRL 2022\n Evolutionary Reinforcement Learning workshop at GECCO 2022, July 9-13, Boston, USA\n \n In recent years reinforcement learning (RL) has received a lot of attention thanks to its performance and ability to address complex tasks. At the same time, multiple recent papers, notably work from OpenAI, have shown that evolution strategies (ES) can be competitive with standard RL algorithms on some problems while being simpler and more scalable. Similar results were obtained by researchers from Uber, this time using a gradient-free genetic algorithm (GA) to train deep neural networks on complex control tasks. Moreover, recent research in the field of evolutionary algorithms (EA) has led to the development of algorithms like Novelty Search and Quality Diversity, capable of…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw2dla/cfp_evorl_gecco_2022_one_week_before_the_deadline/",
          "publishedOn": "2022-04-04T13:44:45.000Z",
          "wordCount": 625,
          "title": "[CfP] EvoRL @ GECCO 2022. One week before the deadline!",
          "imageUrl": "https://external-preview.redd.it/lK42WwByGG32nygWSBuOYR3KR5RyUTDVfuLYvfjqmTI.jpg?auto=webp&s=02c389b64acc7a9d40c4c4ad6555c2381750877f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw10gn/how_ppo_deals_with_episodes_of_variable_lengths/",
          "author": null,
          "description": "In the paper it is written to collect trajectories of length T. Then calculate advantage and then train the Actor and Critic Network. My question is suppose one episode ends much before T. If I run that episode upto lenth T then it will only collect negative rewards in each timestep which in turn makes the training impossible as the return if very big negative number. So what can be done instead of this?\n I might be getting it wrong, so please correct me by commenting.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw10gn/how_ppo_deals_with_episodes_of_variable_lengths/",
          "publishedOn": "2022-04-04T12:39:24.000Z",
          "wordCount": 284,
          "title": "How PPO deals with episodes of Variable lengths?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tvyv0w/need_help_with_openai_gym_custom_environment/",
          "author": null,
          "description": "Hello,\n I'm making a custom openAI gym environment to train various algorithms on it. I have encountered some issues. \n My .flatten() method on the state class returns a large integer which can be converted back into the same state as the object. However when I try to do this as the returned observation for environment.reset() and environment.step(), when testing it I get: \"AssertionError: The observation returned by the `reset()` method does not match the given observation space\" which I can fix by having it just return a 0. How do I go about resolving this? and are there any better approaches for wanting to train RL agents on an environment? ty!\n    submitted by    /u/snaredrum_merchant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tvyv0w/need_help_with_openai_gym_custom_environment/",
          "publishedOn": "2022-04-04T10:38:08.000Z",
          "wordCount": 264,
          "title": "Need help with OpenAI gym custom environment, state representation as \"observation\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tvipcq/how_does_the_acer_algorithm_work/",
          "author": null,
          "description": "I am currently writing a report on reinforcement learning, where I am trying to describe how the ACER algorithm works. I have read the arxiv paper on the sample actor-critic with experienced replay, but I don't understand where the experience replay comes in. Is this part of the policy gradient? where the policy is updated every episode it's trained on from the previous knowledge it gathers in previous episodes.\n https://arxiv.org/pdf/1611.01224.pdf\n ​\n    submitted by    /u/beepingwater_neko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tvipcq/how_does_the_acer_algorithm_work/",
          "publishedOn": "2022-04-03T20:14:25.000Z",
          "wordCount": 229,
          "title": "How does the ACER algorithm work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tvif3g/whats_the_best_way_to_implement_tree_bases/",
          "author": null,
          "description": "Sorry if this post is not appropriate here, but I have been wondering how can I implement and learn a decision tree or any other non differentiable function approximators for the Value Function.\n It’s relatively easy to formulate and use DQN type algorithms by using neural network and say pytorch + stochastic optimization but I want to try out some tree based methods. (at least to reproduce papers which claim to use them)\n But I don’t know 1) If we have to design the structures and learning algorithms by hand or is there any package I can use? \n 2) How should the learning be done? We obviously can’t go regression type learning because of the bootstrapping nature of the Bellman equation?\n Thanks\n    submitted by    /u/Htaseht  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tvif3g/whats_the_best_way_to_implement_tree_bases/",
          "publishedOn": "2022-04-03T20:03:04.000Z",
          "wordCount": 253,
          "title": "What’s the best way to implement tree bases function approximators for RL/Control?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tv9iif/im_working_on_a_dqn_agent_using_the_keras_rl/",
          "author": null,
          "description": "The episode step count is the same for training and testing.\n    submitted by    /u/Gleann_na_nGealt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tv9iif/im_working_on_a_dqn_agent_using_the_keras_rl/",
          "publishedOn": "2022-04-03T13:40:29.000Z",
          "wordCount": 312,
          "title": "I'm working on a DQN agent using the Keras RL library to play Atari games, however a weird thing keeps happening where every episode is the same length but it's a random number each time.",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "RL News",
      "feedUrl": "https://www.getrevue.co/profile/seungjaeryanlee?format=rss",
      "siteUrl": "http://rlnews.ryanlee.ai/",
      "articles": []
    },
    {
      "title": "Damian Bogunowicz - dtransposed",
      "feedUrl": "https://dtransposed.github.io/feed.xml",
      "siteUrl": "http://dtransposed.github.io/",
      "articles": []
    },
    {
      "title": "Data Science Central",
      "feedUrl": "http://feeds.feedburner.com/FeaturedBlogPosts-DataScienceCentral?format=xml",
      "siteUrl": "https://www.datasciencecentral.com",
      "articles": [
        {
          "id": "https://www.datasciencecentral.com/?p=57443",
          "author": "Bill Schmarzo",
          "description": "I was conducting a Tech Talk at a client when I mentioned the astronomical growth of data at “the edge”; that data creation at the edge is growing almost as fast as that in the cloud according to IDC. This sent a noticeable ripple across the executive team audience.  The executives immediately began debating “How… Read More »Business Model Transformation: Keys to Monetizing the Edge\nThe post Business Model Transformation: Keys to Monetizing the Edge appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategist-datamanagement-datascience/",
          "publishedOn": "2022-05-02T15:42:06.000Z",
          "wordCount": 1368,
          "title": "Business Model Transformation: Keys to Monetizing the Edge",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/Slide1-4.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57465",
          "author": "Vincent Granville",
          "description": "There has been many articles predicting the death of the PDF format, invented in 1993. Some of these articles are 10 years old: you can find them by googling “death of PDF”. With the advent of fluid or liquid layout design on almost every website, widespread Internet browsing on small devices (cell phones), notebooks combining… Read More »Are PDF Documents a Thing of the Past?\nThe post Are PDF Documents a Thing of the Past? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/are-pdf-documents-a-thing-of-the-past/",
          "publishedOn": "2022-05-02T03:58:48.000Z",
          "wordCount": 1183,
          "title": "Are PDF Documents a Thing of the Past?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/05/Anacortes_Refinery_31911.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57421",
          "author": "ImensoSoftware",
          "description": "Dealing with a whopping amount of data is normal for businesses in any sector these days. Without using this information obtained from various sources, these entities find it hard to analyze various factors and make strategic decisions. The same can be said about the healthcare sector. Especially after the Covid-19 pandemic, the clinics and medical… Read More »How Power BI Applications Are Reshaping The Healthcare Industry\nThe post How Power BI Applications Are Reshaping The Healthcare Industry appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-power-bi-applications-are-reshaping-the-healthcare-industry/",
          "publishedOn": "2022-05-01T21:01:35.000Z",
          "wordCount": 1467,
          "title": "How Power BI Applications Are Reshaping The Healthcare Industry",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/05/AdobeStock_279695769.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57418",
          "author": "Nikita Godse",
          "description": "The idea of Hyperloop technology was put forth by Elon Musk, who in 2013 made it open source through a white paper. Hyperloop technology revolves around building an ultra-high-speed ground transportation system. In a hyperloop system, especially vacuumed tubes are built over or underground in which pods can travel at high speed. Such systems can… Read More »Hyperloop Technology- Advancing into the Future\nThe post Hyperloop Technology- Advancing into the Future appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/hyperloop-technology-advancing-into-the-future/",
          "publishedOn": "2022-05-01T20:28:29.000Z",
          "wordCount": 680,
          "title": "Hyperloop Technology- Advancing into the Future",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/Hyperloop-Technology1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57410",
          "author": "Indhu",
          "description": "With the internet producing quintillions of readily available information per day, you could be forgiven to think that data is losing its value. Apparently, data is one of those weird commodities that go up in value the more they are available, or perhaps we haven’t produced enough to attain the demand-supply equilibrium. Virtually all companies… Read More »Data quality: What and why is it important?\nThe post Data quality: What and why is it important? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-quality-what-and-why-is-it-important/",
          "publishedOn": "2022-04-26T13:48:58.000Z",
          "wordCount": 952,
          "title": "Data quality: What and why is it important?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/Data-quality-What-and-why-is-it-important-3-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57408",
          "author": "Costanza Tagliaferi",
          "description": "Data scientists face a problem: machine learning models need to be trained on labeled datasets, but labeling the data is tedious and time-consuming. Enter automatic data labeling, in which most of the preprocessing work is done by a computer.  At first glance, automatic data labeling sounds too good to be true. Of course, more automation… Read More »2 Ways in Which Automatic Data Labeling Saves Time and Costs\nThe post 2 Ways in Which Automatic Data Labeling Saves Time and Costs appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/2-ways-in-which-automatic-data-labeling-saves-time-and-costs/",
          "publishedOn": "2022-04-26T13:45:31.000Z",
          "wordCount": 1122,
          "title": "2 Ways in Which Automatic Data Labeling Saves Time and Costs",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_376488024.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57368",
          "author": "Kurt Cagle",
          "description": "As the Omicron variant of Covid-19 surged around the globe in 2021, managers who had begun contingency plans for a return to the office quietly shelved them to wait out the next wave. Heading into the summer of 2022, the omicron-delta variant lurks on the horizon, though whether or not this will trigger the massive… Read More »DSC Weekly Newsletter 26 April 2022: Why The Case for RTO Remains Weak\nThe post DSC Weekly Newsletter 26 April 2022: Why The Case for RTO Remains Weak appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-newsletter-26-april-2022-why-the-case-for-rto-remains-weak/",
          "publishedOn": "2022-04-26T12:17:00.000Z",
          "wordCount": 2905,
          "title": "DSC Weekly Newsletter 26 April 2022: Why The Case for RTO Remains Weak",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_428315983.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57338",
          "author": "Edward Nick",
          "description": "Integrated Marketing Communications (IMC) is an effective communication process that is intended to strengthen the relationship between the customer and the company while enhancing the company’s sales. IMC utilizes a combination of traditional and new approaches in marketing. IMC uses the channel that is most effective to reach the customer. This blog will look at… Read More »4 Successful Integrated Marketing Communications Examples\nThe post 4 Successful Integrated Marketing Communications Examples appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/4-successful-integrated-marketing-communications-examples/",
          "publishedOn": "2022-04-26T06:44:07.000Z",
          "wordCount": 1336,
          "title": "4 Successful Integrated Marketing Communications Examples",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_266107984.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57233",
          "author": "Stephanie Glen",
          "description": "A new book predicts artificial intelligence will soon replace astronauts. The authors posit that robots are cheaper, more reliable, and better suited to space travel. But with the human desire for exploration, AI is unlikely to replace astronauts fully. AI will close the gap with human capabilities in the next few decades and surpass them… Read More »No, AI won’t replace astronauts – and here’s why\nThe post No, AI won’t replace astronauts – and here’s why appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/no-ai-wont-replace-astronauts-and-heres-why/",
          "publishedOn": "2022-04-26T06:30:12.000Z",
          "wordCount": 1138,
          "title": "No, AI won’t replace astronauts – and here’s why",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/perseverance.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57355",
          "author": "Nikita Godse",
          "description": "The implementation of digital technologies blurs the line between the physical and digital world. It has become clear that there is a strong need for digital transformation to achieve the next level of efficiency, connectivity, and flexibility needed in manufacturing to weather modern-day disruptions, risks, and fluctuating demands. 5G SMART believes that 5G will be… Read More »Smart Factory- Building Future with 5G\nThe post Smart Factory- Building Future with 5G appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/smart-factory-building-future-with-5g/",
          "publishedOn": "2022-04-26T06:25:39.000Z",
          "wordCount": 688,
          "title": "Smart Factory- Building Future with 5G",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/smart-factory.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57358",
          "author": "Bill Schmarzo",
          "description": "Stakeholder Journey Maps are a fabulous tool to intimately understand what a stakeholder is trying to accomplish (their objectives and intentions) and the steps/actions/decisions that stakeholder needs to make to complete their journey. Stakeholder Journey Maps are commonly used to help designers to create the optimal user interface and nicely segue into UI storyboards and… Read More »Using Stakeholder Journey Maps to Re-invent, not Just Optimize, Your Business Processes\nThe post Using Stakeholder Journey Maps to Re-invent, not Just Optimize, Your Business Processes appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategies-datamanagement-designthinking-valueengineering/",
          "publishedOn": "2022-04-26T06:21:32.000Z",
          "wordCount": 1471,
          "title": "Using Stakeholder Journey Maps to Re-invent, not Just Optimize, Your Business Processes",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_184833137.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57366",
          "author": "ajitjaokar",
          "description": "Background Digital Twins are virtual representations of physical objects, and they can be connected with their physical counterparts. Through this connection, Digital Twins contribute to the convergence of the real and the virtual world. While the Digital twin’s concept is focused on the manufacturing industry, the paper “Dimensions of Digital Twin Applications – A Literature… Read More »An analysis of Digital Twin Applications across industries\nThe post An analysis of Digital Twin Applications across industries appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/an-analysis-of-digital-twin-applications-across-industries/",
          "publishedOn": "2022-04-26T06:14:10.000Z",
          "wordCount": 1690,
          "title": "An analysis of Digital Twin Applications across industries",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_262996090.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57375",
          "author": "Rob Turner",
          "description": "Data science is a wide field with many specializations, and an individual can have a great career with a data science degree. However, curriculums vary between schools, and the specific data science classes taught in one school may not be taught in another. There are several core skills in the data science field that recruiters… Read More »Make Sure Your Online Data Science Courses Teach These 6 Core Skills\nThe post Make Sure Your Online Data Science Courses Teach These 6 Core Skills appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/make-sure-your-online-data-science-courses-teach-these-6-core-skills/",
          "publishedOn": "2022-04-26T06:06:12.000Z",
          "wordCount": 996,
          "title": "Make Sure Your Online Data Science Courses Teach These 6 Core Skills",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_283714205.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57370",
          "author": "Alan Morrison",
          "description": "I help lead a working group focused on personal knowledge graphs (PKGs). Lately, it’s functioned as a discussion and demo evaluation group for new technologies and how they might be used in a knowledge graph context.   Different individuals want to annotate different kinds of data. Some do a lot of research. For them, the need is… Read More »What Personal Knowledge Graphs Have to Do with Business\nThe post What Personal Knowledge Graphs Have to Do with Business appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/what-personal-knowledge-graphs-have-to-do-with-business/",
          "publishedOn": "2022-04-26T05:59:55.000Z",
          "wordCount": 1339,
          "title": "What Personal Knowledge Graphs Have to Do with Business",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/web-networking-earth-image.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57377",
          "author": "Ryan Williamson",
          "description": "The world of healthcare has consistently evolved, yes, but the fact remains it has gone through tremendous change ever since the coronavirus pandemic started, thus driving the need for modern solutions to meet the increasingly varying needs of patients. In this context, mobile apps have proven to be the leading tool that has driven focus… Read More »Healthcare App Development: Why You Should Opt for React\nThe post Healthcare App Development: Why You Should Opt for React appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/healthcare-app-development-why-you-should-opt-for-react/",
          "publishedOn": "2022-04-26T05:56:09.000Z",
          "wordCount": 876,
          "title": "Healthcare App Development: Why You Should Opt for React",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_257359844.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57379",
          "author": "Howard M. Wiener",
          "description": "Agile, Agile 2 and Agility, Part III In the previous articles in this series, we discussed the role that agile digital delivery capabilities plays in your company’s competitiveness and why rapid delivery is so important.  This article will look at the many reasons that Agile adoptions frequently fail to deliver what companies expect and suggest… Read More »Why Agile Often Fails and What to Do When It Happens\nThe post Why Agile Often Fails and What to Do When It Happens appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/why-agile-often-fails-and-what-to-do-when-it-does/",
          "publishedOn": "2022-04-26T05:25:45.000Z",
          "wordCount": 2045,
          "title": "Why Agile Often Fails and What to Do When It Happens",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_330472183-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57336",
          "author": "Edward Nick",
          "description": "When it comes to protecting your computer, you can do a few basic things. First, create separate user accounts for work and personal data. Make sure to back up your data and use a firewall. Also, make sure to encrypt it.You should make sure to back up any important documents or photos you may have… Read More »How to Protect Your Computer Data\nThe post How to Protect Your Computer Data appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-to-protect-your-computer-data/",
          "publishedOn": "2022-04-26T04:52:30.000Z",
          "wordCount": 1224,
          "title": "How to Protect Your Computer Data",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_486455531.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57341",
          "author": "Vincent Granville",
          "description": "If you are employed as a data scientist and have survived (or strived!) in your position for more than a year, chances are you are at least a good data scientist. This is particularly true if you were promoted. The difference between a mediocre and a good data scientist will be the topic of a… Read More »18 Differences Between Good and Great Data Scientists\nThe post 18 Differences Between Good and Great Data Scientists appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/18-differences-between-good-and-great-data-scientists/",
          "publishedOn": "2022-04-21T04:53:40.000Z",
          "wordCount": 1656,
          "title": "18 Differences Between Good and Great Data Scientists",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/How-Microsoft-Power-BI-Revolutionizes-Business-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57331",
          "author": "Kurt Cagle",
          "description": "I just moved. I’d like to say that I was highly organized, that I knew where every box ended up and what was in each box. I would be lying. Most people who move know the feeling of living in boxes even after the movers have left, the days spent dodging labyrinths of teetering cardboard,… Read More »DSC Weekly Digest 4/19/2022: The Case for Personal Knowledge Graphs\nThe post DSC Weekly Digest 4/19/2022: The Case for Personal Knowledge Graphs appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-case-for-personal-knowledge-graphs/",
          "publishedOn": "2022-04-20T02:54:00.000Z",
          "wordCount": 1153,
          "title": "DSC Weekly Digest 4/19/2022: The Case for Personal Knowledge Graphs",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_213032317-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57313",
          "author": "Ryan Williamson",
          "description": "As cloud-based business intelligence becomes more and more popular in the market, one name has made quite a mark: Power BI. A Microsoft offering, Power BI is an interactive data visualization and analytics tool that promises to revolutionize business. Here are some of its key benefits to help you see how it can do that:… Read More »How Microsoft Power BI Revolutionizes Business\nThe post How Microsoft Power BI Revolutionizes Business appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-microsoft-power-bi-revolutionizes-business/",
          "publishedOn": "2022-04-20T00:25:10.000Z",
          "wordCount": 874,
          "title": "How Microsoft Power BI Revolutionizes Business",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_181885371.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57307",
          "author": "Indhu",
          "description": "Introduction In recent years technology has become prominent, both at work and at home. Machine learning (ML) and Artificial Intelligence (AI) are evolving quickly today. Almost everyone will have some interaction with a form of AI daily. Some common examples include Siri, Google Maps, Netflix, and Social media (Facebook/Snapchat).AI and ML have popularly used buzzwords… Read More »How AI and ML are transforming data quality management?\nThe post How AI and ML are transforming data quality management? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-ai-and-ml-are-transforming-data-quality-management/",
          "publishedOn": "2022-04-20T00:19:25.000Z",
          "wordCount": 1244,
          "title": "How AI and ML are transforming data quality management?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/How-AI-and-ML-are-transforming-data-quality-management3-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57318",
          "author": "Howard M. Wiener",
          "description": "In the previous article in this series, we discussed the difference between Agile and business agility and how Agile 2 addresses some of the omissions and failings of traditional Agile.  Both Agile and Agile 2 focus on accelerating digital development; however, the benefits of any Agile approach can be obviated if it is not implemented… Read More »Agile, Agile 2 and Agility, Part II\nThe post Agile, Agile 2 and Agility, Part II appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/agile-agile-2-and-agility-part-ii/",
          "publishedOn": "2022-04-20T00:18:24.000Z",
          "wordCount": 1339,
          "title": "Agile, Agile 2 and Agility, Part II",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_331775861-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57321",
          "author": "Markus Buhmann",
          "description": "Your regulatory data project likely has no use case for design-time data lineage. tl/dr Mapping Data Lineage at design time, for its own end, has no regulatory use case or ROI.  Buying a specialist tool to support that mapping has even less ROI.  Regulations see that kind of documentary data lineage as ancillary at best.… Read More »Do regulatory data projects really need design-time data lineage? Probably not.\nThe post Do regulatory data projects really need design-time data lineage? Probably not. appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/do-regulatory-data-projects-really-need-design-time-data-lineage-probably-not/",
          "publishedOn": "2022-04-19T23:54:02.000Z",
          "wordCount": 2929,
          "title": "Do regulatory data projects really need design-time data lineage? Probably not.",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_17857338-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57301",
          "author": "Alan Morrison",
          "description": "During the 1990s, the physics community began to measure the brightness of certain supernovae in a novel way. This new method supported the conclusion Edwin Hubble had first arrived at in 1929 after discovering that galaxies are becoming more and more distant from us: Dark matter and dark energy play a role in why those… Read More »Dark Energy, Dark Data\nThe post Dark Energy, Dark Data appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dark-energy-dark-data/",
          "publishedOn": "2022-04-19T07:02:18.000Z",
          "wordCount": 1165,
          "title": "Dark Energy, Dark Data",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_98473600.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57295",
          "author": "Rumzz Bajwa",
          "description": "According to the predictions of Garter, by 2024, distributed cloud computing opportunities will be offered by most cloud vendors on a service basis. With the increasing rush in the cloud space and digitalization of documentation, this industry is bound to grow. Understanding Distributed Cloud Distributed cloud is an innovation to traditional cloud computing. It means… Read More »5 Main Benefits of Distributed Cloud Computing\nThe post 5 Main Benefits of Distributed Cloud Computing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/5-main-benefits-of-distributed-cloud-computing/",
          "publishedOn": "2022-04-19T06:52:25.000Z",
          "wordCount": 1409,
          "title": "5 Main Benefits of Distributed Cloud Computing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_267641356.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57270",
          "author": "ajitjaokar",
          "description": "Healthcare offers one of the biggest areas where AI could impact people. AI in healthcare is already widespread but is expected to grow even further. The global artificial intelligence in healthcare market size was valued at USD 10.4 billion in 2021. It is expected to expand at a compound annual growth rate (CAGR) of 38.4%… Read More »AI and Healthcare: AI as a Triaging Tool for Healthcare\nThe post AI and Healthcare: AI as a Triaging Tool for Healthcare appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-and-healthcare-ai-as-a-triaging-tool-for-healthcare/",
          "publishedOn": "2022-04-18T06:48:30.000Z",
          "wordCount": 762,
          "title": "AI and Healthcare: AI as a Triaging Tool for Healthcare",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_332017031.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57272",
          "author": "Bill Schmarzo",
          "description": "In my first blog of the series “Fallacy of Becoming Data-driven – Part 1: Becoming Value-obsessed”, I preached about the critical importance of reframing the conversion away from data-driven to becoming value-obsessed. Instead of focusing on becoming value-driven, organizations need to focus on how to uncover the customer, product, service, and operational insights buried in… Read More »Fallacy of Becoming Data-driven – Part 2: Cultural Transformation\nThe post Fallacy of Becoming Data-driven – Part 2: Cultural Transformation appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategist-datamanagement-datascience-valueengineering-culturaltransformation/",
          "publishedOn": "2022-04-18T06:16:05.000Z",
          "wordCount": 1614,
          "title": "Fallacy of Becoming Data-driven – Part 2: Cultural Transformation",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_121601343.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57125",
          "author": "Kurt Cagle",
          "description": "As with many fields, knowledge graphs boast a wide array of specialized terms. This guide provides a handy reference to these concepts. Resource Description Framework (RDF) The Resource Description Framework (or RDF) is a conceptual framework established in the early 2000s by the World Wide Web Consortium for describing sets of interrelated assertions. RDF breaks… Read More »A Glossary of Knowledge Graph Terms\nThe post A Glossary of Knowledge Graph Terms appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-glossary-of-knowledge-graph-terms/",
          "publishedOn": "2022-04-18T00:44:04.000Z",
          "wordCount": 2851,
          "title": "A Glossary of Knowledge Graph Terms",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_199726799.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57249",
          "author": "Evan Morris",
          "description": "Data has become a huge area of business, helping businesses to drive their intelligence, make better decisions, and formulate strategic plans for future growth. \nThe post Using Data Warehousing as a Service (DWaaS) To Improve Customer Experience appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/using-data-warehousing-as-a-service-dwaas-to-improve-customer-experience/",
          "publishedOn": "2022-04-17T05:19:21.000Z",
          "wordCount": 2109,
          "title": "Using Data Warehousing as a Service (DWaaS) To Improve Customer Experience",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_452879295.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57255",
          "author": "Stephanie Glen",
          "description": "The LIGO observatory can detect astronomical events from billions of light years away. Terabytes of complex daily data makes human analysis impossible. New study applies neural network with up to 97% classification accuracy. Caltech/MIT’s LIGO, the largest gravitational-wave observatory in the world, collects data on minute space-time ripples from cataclysmic astronomical events like colliding black… Read More »ML classifies gravitational-wave glitches with high accuracy\nThe post ML classifies gravitational-wave glitches with high accuracy appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ml-classifies-gravitational-wave-glitches-with-high-accuracy/",
          "publishedOn": "2022-04-17T05:14:01.000Z",
          "wordCount": 1119,
          "title": "ML classifies gravitational-wave glitches with high accuracy",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_103089241-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57141",
          "author": "Edward Nick",
          "description": "The central principle of the Zero Trust model is based on the authentication and verification of every device connecting to the network before they are trusted. Former Forrester analyst and veteran of the high-technology world, John Kindervag, who has been actively part of a wide array of network technology projects, coined the term “Zero Trust”… Read More »Zero Trust Principles: What is Zero Trust Model?\nThe post Zero Trust Principles: What is Zero Trust Model? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/zero-trust-principles-what-is-zero-trust-model/",
          "publishedOn": "2022-04-17T04:56:05.000Z",
          "wordCount": 1114,
          "title": "Zero Trust Principles: What is Zero Trust Model?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_428848357.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57227",
          "author": "Ryan Williamson",
          "description": "Businesses today face myriad challenges, some of which are successfully addressed with help from cloud computing. This is where AWS cloud migration which promises to be a boon for businesses grappling with a sudden increase in traffic or for those who are looking for accelerated app deployment. It is also handy for cautious businesses that… Read More »AWS Cloud Migration: All You Need to Know\nThe post AWS Cloud Migration: All You Need to Know appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/aws-cloud-migration-all-you-need-to-know/",
          "publishedOn": "2022-04-15T18:12:19.000Z",
          "wordCount": 939,
          "title": "AWS Cloud Migration: All You Need to Know",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_488897244.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57232",
          "author": "Ryan Solecki",
          "description": "What is Artificial Intelligence? Oxford Languages defines AI as the theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages. For those of us working in the realm of digital marketing, the impact has become even more clear over… Read More »How AI is Changing Digital Marketing\nThe post How AI is Changing Digital Marketing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-ai-is-changing-digital-marketing/",
          "publishedOn": "2022-04-14T05:26:11.000Z",
          "wordCount": 1305,
          "title": "How AI is Changing Digital Marketing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_209957900.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57219",
          "author": "Edouard d'Archimbaud",
          "description": "With the constant rise and use of technology, Artificial Intelligence (AI) has become a great companion to compliance. Compliance is one of the biggest playing fields and plays a pivotal role in banking institutions. It aims to identify, diminish, and manage risks such as insider trading, spoofing attacks, exploitation of the market, front-running, and more by… Read More »AI For Compliance: What, Why, How\nThe post AI For Compliance: What, Why, How appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-for-compliance-what-why-how/",
          "publishedOn": "2022-04-14T05:19:25.000Z",
          "wordCount": 2606,
          "title": "AI For Compliance: What, Why, How",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_407673910.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57214",
          "author": "Indhu",
          "description": "While data compliance is the practice of organizations ensuring that all sensitive data is managed and organized in a way that enables them to meet their business rules alongside legal and governmental regulations, data governance involves the process of managing organizational data’s usability, security, availability, and quality using the internally set rules and policies. Data… Read More »Benefits of Data Governance and Compliance\nThe post Benefits of Data Governance and Compliance appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/benefits-of-data-governance-and-compliance/",
          "publishedOn": "2022-04-14T05:00:39.000Z",
          "wordCount": 781,
          "title": "Benefits of Data Governance and Compliance",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_360525944.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57134",
          "author": "EdwardNick",
          "description": "Technical dissertation writing sometimes seems impossible until it is done. A dissertation is among the lengthiest tasks that can take months to get completed. Thus, it exhausts students, but there is no way around it. It is worth more than about 60 credits in a thesis-based degree. Moreover, gathering proper knowledge and top guidelines about… Read More »How To Write A Technical Dissertation\nThe post How To Write A Technical Dissertation appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-to-write-a-technical-dissertation/",
          "publishedOn": "2022-04-14T04:32:09.000Z",
          "wordCount": 1359,
          "title": "How To Write A Technical Dissertation",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_310151102-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57178",
          "author": "Aileen Scott",
          "description": "Globally, many think that data scientist is the best job after Harvard declared it to be one of the hottest jobs of the decade.  And since then, many have been choosing it as their career path. But the role of a data engineer is as important as the data scientist is, because if a data… Read More »Why Data Engineers are in Greater Demand than Data Scientists\nThe post Why Data Engineers are in Greater Demand than Data Scientists appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/why-data-engineers-are-in-greater-demand-than-data-scientists/",
          "publishedOn": "2022-04-14T04:19:24.000Z",
          "wordCount": 943,
          "title": "Why Data Engineers are in Greater Demand than Data Scientists",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_216677722.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57182",
          "author": "Bill Schmarzo",
          "description": "I’m sure we all remember the story of “The Little Engine That Could.” A little railroad engine was built for pulling a few cars on and off the switches. When more powerful engines are asked to pull a load over a steep hill, they respond “I can’t; that is too much a pull for me”.… Read More »Fallacy of Becoming Data-driven – Part 1: Becoming Value-obsessed\nThe post Fallacy of Becoming Data-driven – Part 1: Becoming Value-obsessed appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategist-datascience-datamanagement-valueengineering/",
          "publishedOn": "2022-04-13T21:27:31.000Z",
          "wordCount": 1780,
          "title": "Fallacy of Becoming Data-driven – Part 1: Becoming Value-obsessed",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/Slide1-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57192",
          "author": "Kurt Cagle",
          "description": "The Los Angeles Times recently reported on a growing problem not just for California School Districts, but across much of the Northern Hemisphere: The number of children entering school has been dropping steadily for five years now, and is changing the dynamics of education. What’s worse, those declines are accelerating. Sometimes understanding the future comes… Read More »DSC Weekly Digest 4/12/2022: Demographics Drives Analytics\nThe post DSC Weekly Digest 4/12/2022: Demographics Drives Analytics appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-digest-4-12-2022-demographics-drives-analytics/",
          "publishedOn": "2022-04-13T02:26:00.000Z",
          "wordCount": 1840,
          "title": "DSC Weekly Digest 4/12/2022: Demographics Drives Analytics",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_42581461.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57202",
          "author": "Avani Trivedi",
          "description": "IoT and Machine Learning are the most advanced and evolving technologies that continue to rise in today’s modern world, simplifying human efforts and making lives easier. These technologies have proved to streamline operations and workflows for various industries and provide more robust and scalable applications that allow users to make things done seamlessly.  In recent… Read More »How IoT Uses Machine Learning To Change The World\nThe post How IoT Uses Machine Learning To Change The World appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-iot-uses-machine-learning-to-change-the-world/",
          "publishedOn": "2022-04-12T22:09:51.000Z",
          "wordCount": 1766,
          "title": "How IoT Uses Machine Learning To Change The World",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_263282426.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57115",
          "author": "Jessica Gupta",
          "description": "Recent advances in machine learning (ML) and artificial intelligence (AI) technologies are helping enterprises across industries quickly move from their use cases from the pilot stage to production and operationalization. According to a report by McKinsey & Company, by 2030, businesses that fully absorb AI could double their cash flow, while companies that don’t could… Read More »Drag-and-drop Data Pipelining: The Next Disruptor in ML\nThe post Drag-and-drop Data Pipelining: The Next Disruptor in ML appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/drag-and-drop-data-pipelining-the-next-disruptor-in-ml/",
          "publishedOn": "2022-04-12T19:05:34.000Z",
          "wordCount": 978,
          "title": "Drag-and-drop Data Pipelining: The Next Disruptor in ML",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_473384696-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57133",
          "author": "Nikita Godse",
          "description": "As the Internet of Things (IoT) is gradually moving from being a centralized structure to a more complex network of innumerable decentralized smart devices, the need for security of data will be acknowledged to a greater degree, thereby promoting the expansion of the global IoT security market. The larger the volume of the data transferred… Read More »Advances Highlight the Future of IoT Security\nThe post Advances Highlight the Future of IoT Security appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/advances-highlight-the-future-of-iot-security/",
          "publishedOn": "2022-04-12T18:55:02.000Z",
          "wordCount": 782,
          "title": "Advances Highlight the Future of IoT Security",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/IoT.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57156",
          "author": "Vincent Granville",
          "description": "The success and growth of AI is undeniable. Yet there are still basic tasks performing poorly, despite or because of automation. In some cases, you can blame reliance on outdated AI. In other cases, it is a result of corporate policies or multiple AI systems that compete against each other. The AI systems in question… Read More »6 Business Applications that Badly Need Better AI\nThe post 6 Business Applications that Badly Need Better AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/6-business-applications-that-badly-need-better-ai/",
          "publishedOn": "2022-04-10T19:51:00.000Z",
          "wordCount": 2143,
          "title": "6 Business Applications that Badly Need Better AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/ver.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57148",
          "author": "ajitjaokar",
          "description": "How exactly do you define Artificial Intelligence(AI)? This looks like a back to basics/ back to school question – but the answer is not that simple Recently I was trying to find a good academic definition of AI for a research paper. Surprisingly, its not easy. In this post, I present a good definition for… Read More »How exactly do you define Artificial Intelligence(AI)?\nThe post How exactly do you define Artificial Intelligence(AI)? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-exactly-do-you-define-artificial-intelligenceai/",
          "publishedOn": "2022-04-10T19:44:52.000Z",
          "wordCount": 644,
          "title": "How exactly do you define Artificial Intelligence(AI)?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_213593664.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57153",
          "author": "Stephanie Glen",
          "description": "There are signs that Meta’s plans for the metaverse is faltering, including plummeting stock prices and the company’s announcement that it may withdraw from the EU market. The troubles stem from a myriad of issues, the most significant of which are data collection privacy issues and a lack of investor and public confidence in the… Read More »Public wary of Meta’s Metaverse vision\nThe post Public wary of Meta’s Metaverse vision appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/public-wary-of-metas-metaverse-vision/",
          "publishedOn": "2022-04-10T18:45:35.000Z",
          "wordCount": 1261,
          "title": "Public wary of Meta’s Metaverse vision",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_24686652-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57139",
          "author": "Saurabh Ajmera",
          "description": "NLQ or Natural Language Query or Text-to-SQL or NL2SQL is an arm of computational linguistics, that helps users to fetch required data, visualizations, and insights, from sentences written in human language. As a business user, knowing data schema, table and column names, knowing metadata, having technical know-how of a BI tool or data querying skills… Read More »NLQ: Why You Might Not Need To Call A Data Analyst Anymore\nThe post NLQ: Why You Might Not Need To Call A Data Analyst Anymore appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/nlq-decreasing-reasons-to-call-a-data-analyst/",
          "publishedOn": "2022-04-10T17:56:50.000Z",
          "wordCount": 1198,
          "title": "NLQ: Why You Might Not Need To Call A Data Analyst Anymore",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_398273679.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57110",
          "author": "Aileen Scott",
          "description": "Profession in finance and accounting is one of the top career choices for finance and accounting professionals. Employment of accountants and auditors is projected to grow 7 percent from the year 2020 to the year 2030, about as fast as the average for all occupations. About 135,000 openings for accountants and auditors are projected each year,… Read More »Advance in your finance and accounting careers with top technical skills\nThe post Advance in your finance and accounting careers with top technical skills appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/advance-in-your-finance-and-accounting-careers-with-top-technical-skills/",
          "publishedOn": "2022-04-10T17:31:42.000Z",
          "wordCount": 1013,
          "title": "Advance in your finance and accounting careers with top technical skills",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_229918556.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57118",
          "author": "Ryan Williamson",
          "description": "AI has been making a lot of noise of late, especially in the context of software development. Of course, this topic is quite wide, but in this article, we shall focus our attention on AI-driven automation testing. Let us start with understanding what is AI and automation testing. Automation testing refers to the process of… Read More »Artificial Intelligence: Benefits for Automation Testing\nThe post Artificial Intelligence: Benefits for Automation Testing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/artificial-intelligence-benefits-for-automation-testing/",
          "publishedOn": "2022-04-08T06:38:59.000Z",
          "wordCount": 938,
          "title": "Artificial Intelligence: Benefits for Automation Testing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/max-duzij-qAjJk-un3BI-unsplash.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57114",
          "author": "Sameer Narkhede",
          "description": "‍What is the shortest distance between two points? A straight line of course. What if there are multiple points? Then, it depends.  A job executed in response to a user action – refreshing a dashboard, aggregating data, building a report, developing an ML algorithm, performing analytics – all require multiple hops through the data ecosystem.… Read More »Data Observability: Cracking the Code\nThe post Data Observability: Cracking the Code appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-observability-cracking-the-code/",
          "publishedOn": "2022-04-07T15:12:45.000Z",
          "wordCount": 1386,
          "title": "Data Observability: Cracking the Code",
          "imageUrl": "https://global-uploads.webflow.com/60ddb7e2e50eaef5bec9595c/624723032cf27f425fe3b49f_BtB8gMQkm1dSTaM6a-zrNRmjPuSL8lIM3WYayENdLoYxbusnO6wJp6Sr-JPhqZ2DgPlA66GvQozKd4nNpOxuXjeZGP2o2FkXe5j-lYz58FaEvCTAeaDWkCub8UeocK6tzk1_IO4p.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57050",
          "author": "Kurt Cagle",
          "description": "For nine years, my family and I have lived in a house in Issaquah, a little community about twenty minutes east of Seattle. The town still retains its charms — a downtown area about three blocks long that includes a vintage (and long since decommissioned) gas station, numerous restaurants, a live theater, the library, and… Read More »DSC Weekly Digest: Moving Time\nThe post DSC Weekly Digest: Moving Time appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-digest-moving-time/",
          "publishedOn": "2022-04-06T15:01:18.000Z",
          "wordCount": 2105,
          "title": "DSC Weekly Digest: Moving Time",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_99749434.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57061",
          "author": "Bill Schmarzo",
          "description": "When I was the Vice President of Advertiser Analytics at Yahoo!, I painfully learned that my targeted user personas (Media Planners & Buyers and Campaign Managers) didn’t want more data in helping them optimize their marketing, campaign, and advertising spend across the Yahoo! Ad Network.  Heck, they didn’t even want analytics!  The aspirations for these… Read More »Building a Data Products-centric Business Model\nThe post Building a Data Products-centric Business Model appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategist-datamanagement-ai-iot-ml/",
          "publishedOn": "2022-04-05T20:31:31.000Z",
          "wordCount": 1620,
          "title": "Building a Data Products-centric Business Model",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_203382343.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57077",
          "author": "German Osin",
          "description": "Real-world production ML systems consist of two main components: data and code. Data is clearly the leader, and rapidly taking center stage. Data defines the quality of almost any ML-based product, more so than code or any other aspect. In Feature Store as a Foundation for Machine Learning, we have discussed how feature stores are… Read More »Data Discovery for ML Engineers\nThe post Data Discovery for ML Engineers appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-discovery-for-ml-engineers/",
          "publishedOn": "2022-04-05T19:14:14.000Z",
          "wordCount": 2588,
          "title": "Data Discovery for ML Engineers",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/cyber-g4c6392d4b_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57035",
          "author": "EdwardNick",
          "description": "Many things can help you to write good dissertations. One of the most important is to use content metrics. It is necessary for all of the students to understand content metrics in detail. A clear understanding of its types and measuring strategies help you to evaluate things in a precise way. Whatever is your topic… Read More »Content Metrics That Can Help You To Write  Dissertations\nThe post Content Metrics That Can Help You To Write  Dissertations appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/content-metrics-that-can-help-you-to-write-dissertations/",
          "publishedOn": "2022-04-05T18:24:50.000Z",
          "wordCount": 1365,
          "title": "Content Metrics That Can Help You To Write  Dissertations",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/Content-Metrics-That-Can-Help-You-To-Write-Best-Audiences.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57075",
          "author": "Karen Anthony",
          "description": "The need of a highly functional and fast processing Central Processing Unit (CPU) in today’s world is not just mostly desired, but also mostly required due to the rapid digitalization across the globe. Whether you work on a personal computer (PC) unit or laptop, the necessity of a highly advanced processor is indispensable.  This is… Read More »Comparative analysis of an Intel and AMD Processor\nThe post Comparative analysis of an Intel and AMD Processor appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/comparative-analysis-of-an-intel-and-amd-processor/",
          "publishedOn": "2022-04-05T18:16:54.000Z",
          "wordCount": 879,
          "title": "Comparative analysis of an Intel and AMD Processor",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_408036566.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57089",
          "author": "Aileen Scott",
          "description": "How does artificial intelligence Diversity, Equity, and Inclusion (DEI) fit into the technological stack of daily companies? Fostering a diverse workforce is a very human problem. The cry for a halt to race prejudice has become deafening, and it’s increasingly a decisive factor for talent when weighing job offers and purchases. To stay up with the… Read More »AI And Its Impact On Diversity And Inclusion\nThe post AI And Its Impact On Diversity And Inclusion appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-and-its-impact-on-diversity-and-inclusion/",
          "publishedOn": "2022-04-05T17:04:16.000Z",
          "wordCount": 1132,
          "title": "AI And Its Impact On Diversity And Inclusion",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_469423570.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57056",
          "author": "Kerry Pearce",
          "description": "Understanding consumer behavior is becoming more and more critical as businesses seek to find innovative ways to survive and thrive in a period of constant change. In the last few years, the market has seen significant changes in the way people shop, travel, dine and purchase goods. As a business, when it comes to understanding… Read More »How Data Intelligence Platforms Promote Business Success\nThe post How Data Intelligence Platforms Promote Business Success appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-data-intelligence-platforms-promote-business-success/",
          "publishedOn": "2022-04-05T06:12:10.000Z",
          "wordCount": 1211,
          "title": "How Data Intelligence Platforms Promote Business Success",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_140495395.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57040",
          "author": "ajitjaokar",
          "description": "I read an article from the world economic forum which proposed an AI labeling system for AI products designed for children Today, for the first time, children are growing up in a world shaped by artificial intelligence (AI) and decisions are being made for children implicitly by AI.  Algorithms need data that is collected and… Read More »Exploring AI labeling for children’s products\nThe post Exploring AI labeling for children’s products appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/exploring-ai-labeling-for-childrens-products/",
          "publishedOn": "2022-04-05T06:06:34.000Z",
          "wordCount": 821,
          "title": "Exploring AI labeling for children’s products",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_375140801.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57058",
          "author": "Scott Thompson",
          "description": "In the previous part, we discussed the current state of data imaging tools in healthcare and the future applications of these technologies. While increased access to information is invaluable to physicians, they can still be limited by their own ability to interpret, or the physical limitations of their surgical ability. In addition to augmenting the… Read More »Data Augmented Healthcare Part 2\nThe post Data Augmented Healthcare Part 2 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-augmented-healthcare-part-2/",
          "publishedOn": "2022-04-04T17:41:15.000Z",
          "wordCount": 826,
          "title": "Data Augmented Healthcare Part 2",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_330431239.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57029",
          "author": "Ryan Williamson",
          "description": "Artificial intelligence has been long making waves globally, empowering companies from across the broad spectrum of industries to take their businesses to the next level. So it is no surprise that this technology is making inroads in the grocery retail space, helping grocers deliver personalized and irreproachable experiences across different channels, establishing improved customer loyalty,… Read More »Top Ways in Which AI Impacts Grocery Retail\nThe post Top Ways in Which AI Impacts Grocery Retail appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/top-ways-in-which-ai-impacts-grocery-retail/",
          "publishedOn": "2022-04-03T21:47:26.000Z",
          "wordCount": 953,
          "title": "Top Ways in Which AI Impacts Grocery Retail",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_311618017.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57026",
          "author": "Alan Morrison",
          "description": "Data is useless if it doesn’t shed light. The more light it sheds on the most acute problems businesses face, the better. Within this context, data synergy–data from multiple sources and disciplines that is more valuable than the sum of its parts–is often underappreciated. With data synergy, the light can be in many more places,… Read More »A different take on business intelligence\nThe post A different take on business intelligence appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-different-take-on-business-intelligence/",
          "publishedOn": "2022-04-03T21:05:49.000Z",
          "wordCount": 1234,
          "title": "A different take on business intelligence",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/waves-gacea61272_1920.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57017",
          "author": "Stephanie Glen",
          "description": "Blockchain is widely touted as a mechanism for securing digital property. Multiple problems exist for driving metaverse transactions. A new review highlights the challenges, some of which may be insurmountable. Blockchain has been touted as a potential solution to securing users’ digital content and data due to its decentralization, immutability, and transparency. However, there are… Read More »Blockchain Won’t Save The Metaverse\nThe post Blockchain Won’t Save The Metaverse appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/blockchain-wont-save-the-metaverse/",
          "publishedOn": "2022-04-03T20:31:44.000Z",
          "wordCount": 1065,
          "title": "Blockchain Won’t Save The Metaverse",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_278111994-1.jpeg"
        }
      ]
    },
    {
      "title": "John D. Cook",
      "feedUrl": "https://www.johndcook.com/blog/feed",
      "siteUrl": "https://www.johndcook.com/blog",
      "articles": [
        {
          "id": "https://www.johndcook.com/blog/?p=104738",
          "author": "John",
          "description": "I’m listening to a podcast interviewing Neil Richards, the author of Why Privacy Matters. Richards makes a couple interesting points about the infamous example of Target figuring out which women were pregnant based on their purchase history. First, pregnancy is a point at which women are open to trying new things. So if a company […]\nWhy target ads at pregnant women first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/05/02/pregnant/",
          "publishedOn": "2022-05-02T16:13:18.000Z",
          "wordCount": 342,
          "title": "Why target ads at pregnant women",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=104727",
          "author": "John",
          "description": "As I’ve written about here and elsewhere, the following simple approximations are fairly accurate. log10 x ≈ (x-1)/(x+1) loge x ≈ 2 (x – 1)/(x + 1) log2 x ≈ 3(x – 1)/(x + 1) It’s a little surprising that each is as accurate as it is, but it’s also surprising that the approximations for […]\nCuriously simple approximations first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/05/02/curiously-simple-approximations/",
          "publishedOn": "2022-05-02T13:52:18.000Z",
          "wordCount": 424,
          "title": "Curiously simple approximations",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=104231",
          "author": "John",
          "description": "A couple days ago I wrote about homogeneous coordinates projective planes. I said that the lines y = 5 and y = 6 intersect in a point “at infinity.” In projective geometry any two distinct lines intersect in exactly one point, and you can compute that intersection point the same way, whether the intersection is […]\nCalculating where projective lines intersect first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/27/projective-intersect/",
          "publishedOn": "2022-04-27T11:30:35.000Z",
          "wordCount": 1075,
          "title": "Calculating where projective lines intersect",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=104115",
          "author": "John",
          "description": "A Blaschke product is a function that is the product of Blaschke factors, functions of the form b(z; a) = |a|  (a – z) / a (1 – a*z) where the complex number a lies inside the unit circle and a* is the complex conjugate of a. I wanted to plot Blaschke products with random […]\nRandom Blaschke products and Mathematica binding first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/25/random-blaschke-products/",
          "publishedOn": "2022-04-26T00:02:36.000Z",
          "wordCount": 646,
          "title": "Random Blaschke products and Mathematica binding",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=104104",
          "author": "John",
          "description": "The previous post explained how to define a projective plane over a field F. Now let’s look at how we do geometry in a projective plane. Definitions We have a definition of points from the other post: a point is a triple (a, b, c) of elements of F, with not all elements equal to […]\nProjective duality first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/25/projective-duality/",
          "publishedOn": "2022-04-25T17:24:00.000Z",
          "wordCount": 926,
          "title": "Projective duality",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=104087",
          "author": "John",
          "description": "Given a field F, finite or infinite, you can construct a projective plane over F by starting with pairs of elements of F and adding “points at infinity,” one point for each direction. Motivation: Bézout’s theorem A few days ago I mentioned Bézout’s theorem as an example of a simple theorem that rests on complex […]\nFinite projective planes first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/25/finite-projective-planes/",
          "publishedOn": "2022-04-25T14:49:22.000Z",
          "wordCount": 1343,
          "title": "Finite projective planes",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103782",
          "author": "John",
          "description": "Introduction I was puzzled the first time I saw bilinear transformations, also known as Möbius transformations. I was in a class where everything had been abstract and general, and suddenly thing got very concrete and specific. I wondered why we had changed gears, and I wondered how there could be much to say about something […]\nFixed points of bilinear transformations first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/21/mobius-fixed-points/",
          "publishedOn": "2022-04-21T21:56:00.000Z",
          "wordCount": 524,
          "title": "Fixed points of bilinear transformations",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103774",
          "author": "John",
          "description": "This post looks at how to partition complexity between definitions and theorems, and why it’s useful to be able to partition things more than one way. Quadratic equations Imagine the following dialog in an algebra class. “Quadratic equations always have two roots.” “But what about (x – 5)² = 0. That just has one root, […]\nPartitioning complexity first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/21/partitioning-complexity/",
          "publishedOn": "2022-04-21T14:50:32.000Z",
          "wordCount": 1119,
          "title": "Partitioning complexity",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103710",
          "author": "John",
          "description": "I got an email from a student in France who asked about a French counterpart to my post on Morse code palindromes, and this post is a response to that email. Palindromes A palindrome is a word that remains the same when the letters are reversed, like kayak. A Morse code palindrome is a word […]\nFrench palindromes and Morse code first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/20/french-palindromes-and-morse-code/",
          "publishedOn": "2022-04-20T16:31:53.000Z",
          "wordCount": 731,
          "title": "French palindromes and Morse code",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103703",
          "author": "John",
          "description": "Blaschke factors are complex functions with specified zeros inside the unit disk. Given a complex number a with |a| < 1, the Blaschke factor associated with a is the function Notice the semicolon in b(z; a). This is a convention that a few authors follow, and that I wish more would adopt. From a purely […]\nBlaschke factors first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/20/blaschke-factors/",
          "publishedOn": "2022-04-20T14:45:11.000Z",
          "wordCount": 747,
          "title": "Blaschke factors",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103597",
          "author": "John",
          "description": "Inversion in the unit circle is a way of turning the circle inside-out. Everything that was inside the circle goes outside the circle, and everything that was outside the circle comes in. Not only is the disk turned inside-out, the same thing happens along each ray going out from the origin. Points on that ray […]\nInversion in a circle first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/19/inversion-in-a-circle/",
          "publishedOn": "2022-04-19T16:20:21.000Z",
          "wordCount": 510,
          "title": "Inversion in a circle",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103049",
          "author": "John",
          "description": "Male and female heights both have a standard deviation of about 3 inches, with means of 70 inches and 64 inches. That’s a good first-pass model using round numbers. If you ask what the height of an average adult is, not specifying male or female, you get a mixture of two normal distributions. If we […]\nHow flat is a normal mixture on top? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/13/how-flat-is-a-normal-mixture-on-top/",
          "publishedOn": "2022-04-14T00:38:00.000Z",
          "wordCount": 653,
          "title": "How flat is a normal mixture on top?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=102974",
          "author": "John",
          "description": "A few days ago I wrote about the Hilbert transform and gave as an example that the Hilbert transform of sine is cosine. We’ll bootstrap that example to find the Hilbert transform of any periodic function from its Fourier series. The Hilbert transform of a function f(t) is a function fH(x) defined by where the […]\nHilbert transform and Fourier series first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/13/hilbert-fourier/",
          "publishedOn": "2022-04-13T16:05:15.000Z",
          "wordCount": 719,
          "title": "Hilbert transform and Fourier series",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=102966",
          "author": "John",
          "description": "I got an evaluation copy of The Best Writing on Mathematics 2021 yesterday. One article jumped out as I was skimming the table of contents: A Zeroth Power Is Often a Logarithm Yearning to Be Free by Sanjoy Mahajan. Great title. There are quite a few theorems involving powers that have an exceptional case that […]\nLogarithms yearning to be free first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/13/logarithms-yearning-to-be-free/",
          "publishedOn": "2022-04-13T12:00:22.000Z",
          "wordCount": 476,
          "title": "Logarithms yearning to be free",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=102336",
          "author": "John",
          "description": "I explained the basics of how a slide rule works in the previous post. But how does a circular slide rule work? Apparently the prop Mr. Spock is holding is an E6B aircraft slide rule. It includes a circular slide rule and more functionality. Start with an ordinary straight slide rule, with each bar labeled […]\nCircular slide rule first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/10/circular-slide-rule/",
          "publishedOn": "2022-04-10T22:05:38.000Z",
          "wordCount": 476,
          "title": "Circular slide rule",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=102298",
          "author": "John",
          "description": "Suppose you have two sticks. The length of one is log x, and the length of the other is log y. If you put the two sticks end to end, the combined length is log x + log y = log xy. That’s the basic idea behind a slide rule. The simplest slide rule consists […]\nWhy a slide rule works first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/10/why-a-slide-rule-works/",
          "publishedOn": "2022-04-10T20:49:00.000Z",
          "wordCount": 689,
          "title": "Why a slide rule works",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101985",
          "author": "John",
          "description": "The Hilbert transform of a function f(t) is a function fH(x) defined [1] by The integral must be interpreted in the sense of the Cauchy principal value: The integrand is not absolutely integrable because of the singularity at x and so the value of the integral depends on how you handle the singularity. The Cauchy […]\nHilbert transform and Mathematica first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/08/hilbert-transform-and-mathematica/",
          "publishedOn": "2022-04-08T15:12:50.000Z",
          "wordCount": 675,
          "title": "Hilbert transform and Mathematica",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101943",
          "author": "John",
          "description": "The plot below is of a meromorphic function f(z). That is, the function f(z) is analytic except possibly at poles, and the colors represent the phase angles, the values of θ if you write the function values in polar form. What is the value of the integral where C is the perimeter of the square? […]\nVisual integration first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/08/visual-integration/",
          "publishedOn": "2022-04-08T11:10:02.000Z",
          "wordCount": 514,
          "title": "Visual integration",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101905",
          "author": "John",
          "description": "Regular expressions can do a lot of tasks in practice that they cannot do in theory. That’s because a particular application of regular expressions comes with context and with error tolerance. For example, much has been said about how regular expressions cannot parse HTML. This is strictly true, but it says nothing about how well […]\nRegular expressions and successive approximation first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/07/regex-approximation/",
          "publishedOn": "2022-04-07T14:00:43.000Z",
          "wordCount": 864,
          "title": "Regular expressions and successive approximation",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101812",
          "author": "John",
          "description": "A couple days ago I wrote about how Vieta’s formulas let you sum the zeros of a polynomial without having to first compute the zeros. This is especially handy for high-order polynomials since there is no explicit formula for the zeros. Most functions that arise in applications are not polynomials. How could you find the […]\nSum the zeros of an analytic function without finding them first first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/06/sum-analytic-function-zeros/",
          "publishedOn": "2022-04-06T13:22:57.000Z",
          "wordCount": 790,
          "title": "Sum the zeros of an analytic function without finding them first",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101725",
          "author": "John",
          "description": "The previous post looked at the problem of finding the zeros of a cubic polynomial. Assuming we’re going to use a numerical method to calculate the zero, the hard part is knowing where to tell the numerical method to look. That post showed how to use a change of variables to guarantee that the polynomial […]\nBounding zeros of an analytic function first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/05/analytic-zeros/",
          "publishedOn": "2022-04-05T14:33:39.000Z",
          "wordCount": 748,
          "title": "Bounding zeros of an analytic function",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101681",
          "author": "John",
          "description": "The analog of the quadratic formula for cubic equations is cumbersome. A lot of people naturally say “Forget all that. If I need to find the roots of a cubic, I’ll just use a numerical method like Newton’s method.” Sounds good. Where to start? But how do you know where to look for the roots? […]\nNumerically finding roots of a cubic first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/05/cubic/",
          "publishedOn": "2022-04-05T12:00:16.000Z",
          "wordCount": 903,
          "title": "Numerically finding roots of a cubic",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101654",
          "author": "John",
          "description": "The following is a slightly edited version of a Twitter thread on @AlgebraFact. The lowest C on a piano is called C1 in scientific pitch notation. The C one octave up is C2 and so forth. Middle C is C4. The frequency of Cn is approximately 2n+4 Hz. This would be exact if C0 were […]\nMathematics and piano tuning first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/mathemacs-and-piano-tuning/",
          "publishedOn": "2022-04-04T23:19:24.000Z",
          "wordCount": 478,
          "title": "Mathematics and piano tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101658",
          "author": "John",
          "description": "Once in a while it’s necessary to calculate some function of the roots of a polynomial, and it may be possible to do this without first calculating the roots. Quadratics The quadratic formula gives explicit solutions to the equation The two solutions for x are where The awkward part is taking the square root of […]\nComputing functions of roots without computing roots first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/vieta/",
          "publishedOn": "2022-04-04T14:42:33.000Z",
          "wordCount": 925,
          "title": "Computing functions of roots without computing roots",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101533",
          "author": "John",
          "description": "This post contains a derives a result I needed recently. The derivation is simple but a little tedious, so I wanted to save it in case I need it again. Full width half maximum A common way to measure the width of a function peak in a function f(x) is to find the place x0 […]\nFWHM for a quadratic first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/fwhm-quadratic/",
          "publishedOn": "2022-04-04T12:59:26.000Z",
          "wordCount": 693,
          "title": "FWHM for a quadratic",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101648",
          "author": "John",
          "description": "Here’s a list of five numbers used as slang in various contexts. Location (CB and police radio) End of column (journalism) Best wishes (ham radio) All aircraft in area (US Navy) I love you (text messages) The motivation for this post was an article Those HTML attributes you never use. I wanted to make a […]\nNumber slang and numbered lists first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/number-slang-and-numbered-lists/",
          "publishedOn": "2022-04-04T12:39:43.000Z",
          "wordCount": 242,
          "title": "Number slang and numbered lists",
          "imageUrl": null
        }
      ]
    }
  ],
  "cliVersion": "1.14.4"
}