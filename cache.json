{
  "sources": [
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": [
        {
          "id": "https://mlinproduction.com/?p=936",
          "author": "Luigi",
          "description": "In my previous post, I briefly described how leading companies use experimentation to optimize their products and services and evolve them to the point of feeling elegant, efficient, and magical. These companies have developed mature experimentation programs (ExPrs), including the… Read More \nThe post What is an Experimentation program and Who is Involved? (Experimentation Program Series: Guide 02) appeared first on ML in Production.",
          "link": "https://mlinproduction.com/experimentation-program-stakeholders/?utm_source=rss&utm_medium=rss&utm_campaign=experimentation-program-stakeholders",
          "publishedOn": "2022-04-02T14:03:58.000Z",
          "wordCount": 1691,
          "title": "What is an Experimentation program and Who is Involved? (Experimentation Program Series: Guide 02)",
          "imageUrl": null
        },
        {
          "id": "https://mlinproduction.com/?p=926",
          "author": "Luigi",
          "description": "Seamless. Frictionless. Elegant. Efficient.\nRead More \nThe post Building An Effective Experimentation Program – 01 Introduction appeared first on ML in Production.",
          "link": "https://mlinproduction.com/experimentation-program-introduction/?utm_source=rss&utm_medium=rss&utm_campaign=experimentation-program-introduction",
          "publishedOn": "2022-03-20T14:48:21.000Z",
          "wordCount": 1134,
          "title": "Building An Effective Experimentation Program – 01 Introduction",
          "imageUrl": "https://mlinproduction.com/wp-content/uploads/2022/03/experimentation-beakers.jpeg"
        }
      ]
    },
    {
      "title": "Blog",
      "feedUrl": "http://machinelearningmastery.com/blog/feed",
      "siteUrl": "https://machinelearningmastery.com",
      "articles": [
        {
          "id": "https://machinelearningmastery.com/?p=13373",
          "author": "Adrian Tam",
          "description": "Compared to other programming exercises, a machine learning project is a blend of code and data. You need both to […]\nThe post A Guide to Getting Datasets for Machine Learning in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/a-guide-to-getting-datasets-for-machine-learning-in-python/",
          "publishedOn": "2022-03-31T01:00:09.000Z",
          "wordCount": 3526,
          "title": "A Guide to Getting Datasets for Machine Learning in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/pexels-olha-ruskykh-7166023-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13400",
          "author": "Mitch Bartlett",
          "description": "Sponsored Post Building successful machine learning products requires mastering ML Strategy, including problem formulation, evaluation, and tactics for dealing with […]\nThe post Interactive ML Strategy course with Foster Provost starting April 7 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/interactive-ml-strategy-course-with-foster-provost-starting-april-7/",
          "publishedOn": "2022-03-29T19:41:10.000Z",
          "wordCount": 500,
          "title": "Interactive ML Strategy course with Foster Provost starting April 7",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/Scholarsite.webp"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13355",
          "author": "Mehreen Saeed",
          "description": "Datasets from real-world scenarios are important for building and testing machine learning models. You may just want to have some […]\nThe post A Guide to Obtaining Time Series Datasets in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/a-guide-to-obtaining-time-series-datasets-in-python/",
          "publishedOn": "2022-03-29T02:07:33.000Z",
          "wordCount": 4266,
          "title": "A Guide to Obtaining Time Series Datasets in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/IMG_0628-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13318",
          "author": "Mehreen Saeed",
          "description": "Data visualization is an important aspect of all AI and machine learning applications. You can gain key insights of your […]\nThe post Data Visualization in Python with matplotlib, Seaborn and Bokeh appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/data-visualization-in-python-with-matplotlib-seaborn-and-bokeh/",
          "publishedOn": "2022-03-21T14:00:49.000Z",
          "wordCount": 7616,
          "title": "Data Visualization in Python with matplotlib, Seaborn and Bokeh",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/IMG_0570-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13335",
          "author": "Adrian Tam",
          "description": "Static analyzers are tools that help you check your code without really running your code. The most basic form of […]\nThe post Static Analyzers in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/static-analyzers-in-python/",
          "publishedOn": "2022-03-20T04:09:33.000Z",
          "wordCount": 3659,
          "title": "Static Analyzers in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/pexels-skylar-kang-6044187-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13293",
          "author": "Adrian Tam",
          "description": "Calculus for Machine Learning Crash Course. Get familiar with the calculus techniques in machine learning in 7 days. Calculus is […]\nThe post Calculus for Machine Learning (7-day mini-course) appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/calculus-for-machine-learning-7-day-mini-course/",
          "publishedOn": "2022-03-15T18:26:11.000Z",
          "wordCount": 5435,
          "title": "Calculus for Machine Learning (7-day mini-course)",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/1024px-Mechanical_integrator_CHM.agr_.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13313",
          "author": "Adrian Tam",
          "description": "Python is a neat programming language because its syntax is simple, clear, and concise. But Python will not be so […]\nThe post Exploring the Python Ecosystem appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/exploring-the-python-ecosystem/",
          "publishedOn": "2022-03-15T14:00:00.000Z",
          "wordCount": 2275,
          "title": "Exploring the Python Ecosystem",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/vinit-srivastava-ETTY3Q_ukmk-unsplash-scaled.jpg"
        }
      ]
    },
    {
      "title": "Machine Learning Archives - Uber Engineering Blog",
      "feedUrl": "https://eng.uber.com/tag/machine-learning/feed",
      "siteUrl": "https://eng.uber.com",
      "articles": []
    },
    {
      "title": "AWS Machine Learning Blog",
      "feedUrl": "https://aws.amazon.com/blogs/machine-learning/feed",
      "siteUrl": "https://aws.amazon.com/blogs/machine-learning/",
      "articles": [
        {
          "id": "0d01c636ffdbb651bb76c8c2f8ff1eb0118a73b1",
          "author": "Joshua Levy",
          "description": "In many industries, it’s critical to extract custom entities from documents in a timely manner. This can be challenging. Insurance claims, for example, often contain dozens of important attributes (such as dates, names, locations, and reports) sprinkled across lengthy and dense documents. Manually scanning and extracting such information can be error-prone and time-consuming. Rule-based software […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-custom-entity-recognizer-for-pdf-documents-using-amazon-comprehend/",
          "publishedOn": "2022-04-08T17:32:30.000Z",
          "wordCount": 1954,
          "title": "Build a custom entity recognizer for PDF documents using Amazon Comprehend",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/25/image-46.png"
        },
        {
          "id": "c460ad7425a2142b35a23d87bcece5f7ff3037a6",
          "author": "Bob Strahan",
          "description": "Amazon Kendra is a highly accurate and easy-to-use intelligent search service powered by machine learning (ML). Amazon Kendra offers a suite of data source connectors to simplify the process of ingesting and indexing your content, wherever it resides. For many organizations, Box Content Cloud is a core part of their content storage and lifecycle management […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/getting-started-with-the-amazon-kendra-box-connector/",
          "publishedOn": "2022-04-08T16:10:06.000Z",
          "wordCount": 1853,
          "title": "Getting started with the Amazon Kendra Box connector",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png"
        },
        {
          "id": "9770db1640db4792d317e78fe4a612d13b6f8025",
          "author": "Jay Rao",
          "description": "Amazon Rekognition Custom Labels is a fully managed computer vision service that allows developers to build custom models to classify and identify objects in images that are specific and unique to your business. Rekognition Custom Labels doesn’t require you to have any prior computer vision expertise. You can get started by simply uploading tens of […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/receive-notifications-for-image-analysis-with-amazon-rekognition-custom-labels-and-analyze-predictions/",
          "publishedOn": "2022-04-06T16:46:32.000Z",
          "wordCount": 2176,
          "title": "Receive notifications for image analysis with Amazon Rekognition Custom Labels and analyze predictions",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/01/ML-3899-image031.jpg"
        },
        {
          "id": "0e8423c3b0ca2b8aa2fd2cab118be4196def0bbd",
          "author": "Peyman Razaghi",
          "description": "The built-in Amazon SageMaker XGBoost algorithm provides a managed container to run the popular XGBoost machine learning (ML) framework, with added convenience of supporting advanced training or inference features like distributed training, dataset sharding for large-scale datasets, A/B model testing, or multi-model inference endpoints. You can also extend this powerful algorithm to accommodate different requirements. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/customize-the-amazon-sagemaker-xgboost-algorithm-container/",
          "publishedOn": "2022-04-05T17:24:58.000Z",
          "wordCount": 1535,
          "title": "Customize the Amazon SageMaker XGBoost algorithm container",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/18/ML-2441-archdiag.png"
        },
        {
          "id": "b427fe772702e9e6bb92c140946b1bcd9c5c6dc0",
          "author": "Nathalie Rauschmayr",
          "description": "Research over the past few years has shown that machine learning (ML) models are vulnerable to adversarial inputs, where an adversary can craft inputs to strategically alter the model’s output (in image classification, speech recognition, or fraud detection). For example, imagine you have deployed a model that identifies your employees based on images of their […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/detect-adversarial-inputs-using-amazon-sagemaker-model-monitor-and-amazon-sagemaker-debugger/",
          "publishedOn": "2022-04-05T17:19:32.000Z",
          "wordCount": 3547,
          "title": "Detect adversarial inputs using Amazon SageMaker Model Monitor and Amazon SageMaker Debugger",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/29/ML-7609-image005.jpg"
        },
        {
          "id": "093bc4f91e188e1a2e2f385311b63204025f2c19",
          "author": "Rumi Olsen",
          "description": "As more organizations move to machine learning (ML) to drive deeper insights, two key stumbling blocks they run into are labeling and lifecycle management. Labeling is the identification of data and adding labels to provide context so an ML model can learn from it. Labels might indicate a phrase in an audio file, a car […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-mlops-sentiment-analysis-pipeline-using-amazon-sagemaker-ground-truth-and-databricks-mlflow/",
          "publishedOn": "2022-04-04T19:43:42.000Z",
          "wordCount": 2188,
          "title": "Build an MLOps sentiment analysis pipeline using Amazon SageMaker Ground Truth and Databricks MLflow",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/17/ML-5351-image002-1-657x630.png"
        },
        {
          "id": "44ec1f237a527c498cfe53252dabc3cb1f64d1ce",
          "author": "Sanjay Tiwary",
          "description": "Amazon Kendra is an intelligent search service powered by machine learning (ML). Amazon Kendra reimagines search for your websites and applications so your employees and customers can easily find the content they’re looking for, even when it’s scattered across multiple locations and content repositories within your organization. Amazon Kendra supports a variety of document formats, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/enable-amazon-kendra-search-for-a-scanned-or-image-based-text-document/",
          "publishedOn": "2022-04-04T18:07:45.000Z",
          "wordCount": 1648,
          "title": "Enable Amazon Kendra search for a scanned or image-based text document",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/25/ML-6030-image001-feature-1065x630.png"
        },
        {
          "id": "2aeebc95eb280c09dba0b3c96cc6c229198abe7f",
          "author": "Kai Loreck",
          "description": "Customer service calls require customer agents to have the customer’s account information to process the caller’s request. For example, to provide a status on an insurance claim, the support agent needs policy holder information such as the policy ID and claim number. Such information is often collected in the interactive voice response (IVR) flow at […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/interpret-caller-input-using-grammar-slot-types-in-amazon-lex/",
          "publishedOn": "2022-04-04T16:45:41.000Z",
          "wordCount": 1869,
          "title": "Interpret caller input using grammar slot types in Amazon Lex",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png"
        },
        {
          "id": "9b427ae3ef63dc190c6b7ccb9890b546fe95fc05",
          "author": "Susant Mallick",
          "description": "For customers looking to implement a GxP-compliant environment on AWS for artificial intelligence (AI) and machine learning (ML) systems, we have released a new whitepaper: Machine Learning Best Practices in Healthcare and Life Sciences. This whitepaper provides an overview of security and good ML compliance practices and guidance on building GxP-regulated AI/ML systems using AWS […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/whitepaper-machine-learning-best-practices-in-healthcare-and-life-sciences/",
          "publishedOn": "2022-04-01T18:16:40.000Z",
          "wordCount": 1032,
          "title": "Whitepaper: Machine Learning Best Practices in Healthcare and Life Sciences",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png"
        },
        {
          "id": "8298a7a5db1b264ac6c37c3867417c3928769e17",
          "author": "Roop Bains",
          "description": "Data science and data engineering teams spend a significant portion of their time in the data preparation phase of a machine learning (ML) lifecycle performing data selection, cleaning, and transformation steps. It’s a necessary and important step of any ML workflow in order to generate meaningful insights and predictions, because bad or low-quality data greatly […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/prepare-data-from-databricks-for-machine-learning-using-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2022-03-31T23:07:22.000Z",
          "wordCount": 2668,
          "title": "Prepare data from Databricks for machine learning using Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/24/ML-8541-image001-1232x630.png"
        },
        {
          "id": "baf199adf9d92a5962f4ec20ce81ff5fa0421b0d",
          "author": "Dwayne Browne",
          "description": "Today, customers interact with brands over an increasingly large digital and offline footprint, generating a wealth of interaction data known as behavioral data. As a result, marketers and customer experience teams must work with multiple overlapping tools to engage and target those customers across touchpoints. This increases complexity, creates multiple views of each customer, and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/personalize-cross-channel-customer-experiences-with-amazon-sagemaker-amazon-personalize-and-segment/",
          "publishedOn": "2022-03-29T17:41:54.000Z",
          "wordCount": 3000,
          "title": "Personalize cross-channel customer experiences with Amazon SageMaker, Amazon Personalize, and Twilio Segment",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/21/ML-6845-image001.jpg"
        },
        {
          "id": "e75f3ef671be2d0ce497a26f64eec80bfff4f07b",
          "author": "Dan Iancu",
          "description": "This is blog post is co-written by Theresa Cabrera Menard, an Applied Scientist/Geographic Information Systems Specialist at The Nature Conservancy (TNC) in Hawaii. In recent years, Amazon and AWS have developed a series of sustainability initiatives with the overall goal of helping preserve the natural environment. As part of these efforts, AWS Professional Services establishes […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automated-scalable-and-cost-effective-ml-on-aws-detecting-invasive-australian-tree-ferns-in-hawaiian-forests/",
          "publishedOn": "2022-03-29T16:53:41.000Z",
          "wordCount": 3408,
          "title": "Automated, scalable, and cost-effective ML on AWS: Detecting invasive Australian tree ferns in Hawaiian forests",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/15/blog_pic4.png"
        },
        {
          "id": "97aaf4a45fb3f98dbca55c0fa275d369e8dd1ccf",
          "author": "Peter Chung",
          "description": "Amazon SageMaker Autopilot helps you complete an end-to-end machine learning (ML) workflow by automating the steps of feature engineering, training, tuning, and deploying an ML model for inference. You provide SageMaker Autopilot with a tabular data set and a target attribute to predict. Then, SageMaker Autopilot automatically explores your data, trains, tunes, ranks and finds […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automatically-generate-model-evaluation-metrics-using-sagemaker-autopilot-model-quality-reports/",
          "publishedOn": "2022-03-29T16:47:55.000Z",
          "wordCount": 3055,
          "title": "Automatically generate model evaluation metrics using SageMaker Autopilot Model Quality Reports",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/22/confusion-matrix-638x630.png"
        },
        {
          "id": "dea7590ac337b5e2d649942249f932503c4d46bd",
          "author": "Shibhangi Saha",
          "description": "This post is co-written by Shibangi Saha, Data Scientist, and Graciela Kravtzov, Co-Founder and CTO, of Equilibrium Point. Many individuals are experiencing new symptoms of mental illness, such as stress, anxiety, depression, substance use, and post-traumatic stress disorder (PTSD). According to Kaiser Family Foundation, about half of adults (47%) nationwide have reported negative mental health […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-mental-health-machine-learning-risk-model-using-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2022-03-25T20:37:56.000Z",
          "wordCount": 2529,
          "title": "Build a mental health machine learning risk model using Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/17/ML8274-image010-864x630.png"
        },
        {
          "id": "99ad186f1cc45ebb6c59a41d94d1ffd3662359d5",
          "author": "Matthew Peretick",
          "description": "Amazon Kendra is an intelligent search service powered by machine learning. You can receive spelling suggestions for misspelled terms in your queries by utilizing the Amazon Kendra Spell Checker. Spell Checker helps reduce the frequency of queries returning irrelevant results by providing spelling suggestions for unrecognized terms. In this post, we explore how to use […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/improve-search-accuracy-with-spell-checker-in-amazon-kendra/",
          "publishedOn": "2022-03-25T18:08:51.000Z",
          "wordCount": 1343,
          "title": "Improve search accuracy with Spell Checker in Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/25/ML-8602-image001-resized.jpg"
        },
        {
          "id": "3d6c5da9163112cfa37e93445c4e2b60a26d3c64",
          "author": "Heiko Hotz",
          "description": "This is the second post in a two-part series in which I propose a practical guide for organizations so you can assess the quality of text summarization models for your domain. For an introduction to text summarization, an overview of this tutorial, and the steps to create a baseline for our project (also referred to […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/part-2-set-up-a-text-summarization-project-with-hugging-face-transformers/",
          "publishedOn": "2022-03-23T21:14:03.000Z",
          "wordCount": 3430,
          "title": "Set up a text summarization project with Hugging Face Transformers: Part 2",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png"
        },
        {
          "id": "29be3c5b971aa0ada6bec541c65f04d985b9f9fd",
          "author": "Heiko Hotz",
          "description": "When OpenAI released the third generation of their machine learning (ML) model that specializes in text generation in July 2020, I knew something was different. This model struck a nerve like no one that came before it. Suddenly I heard friends and colleagues, who might be interested in technology but usually don’t care much about […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/part-1-set-up-a-text-summarization-project-with-hugging-face-transformers/",
          "publishedOn": "2022-03-23T21:13:30.000Z",
          "wordCount": 3070,
          "title": "Set up a text summarization project with Hugging Face Transformers: Part 1",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/09/ML-7391-image002.png"
        },
        {
          "id": "a30a1487c091be6a2f19fba15a0ca11760ac910b",
          "author": "Taylor Names",
          "description": "This is a guest post co-authored by Taylor Names, Staff Machine Learning Engineer, Dev Gupta, Machine Learning Manager, and Argie Angeleas, Senior Product Manager at Ibotta. Ibotta is an American technology company that enables users with its desktop and mobile apps to earn cash back on in-store, mobile app, and online purchases with receipt submission, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/optimize-customer-engagement-with-reinforcement-learning/",
          "publishedOn": "2022-03-23T21:07:15.000Z",
          "wordCount": 2153,
          "title": "Optimize customer engagement with reinforcement learning",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/17/ml-7771-image007.png"
        },
        {
          "id": "1eb961f694869c6a2187d10121ba0a13554186d1",
          "author": "John Heater",
          "description": "Amazon Lex is a service for building conversational interfaces into any application using voice and text. With Amazon Lex, you can easily build sophisticated, natural language, conversational bots (chatbots), virtual agents, and interactive voice response (IVR) systems. You can now use industry grammars to accelerate IVR development on Amazon Lex as part of your IVR […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/expedite-ivr-development-with-industry-grammars-on-amazon-lex/",
          "publishedOn": "2022-03-23T01:17:18.000Z",
          "wordCount": 2787,
          "title": "Expedite IVR development with industry grammars on Amazon Lex",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png"
        },
        {
          "id": "229dd128c741e3f461444de5ff03100092aa8119",
          "author": "John Heater",
          "description": "This post was co-written by John Heater, SVP of the Contact Center Practice at NeuraFlash. NeuraFlash is an Advanced AWS Partner with over 40 collective years of experience in the voice and automation space. With a dedicated team of conversation designers, data engineers, and AWS developers, NeuraFlash helps customers take advantage of the power of Amazon […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/easily-migrate-your-ivr-flows-to-amazon-lex-using-the-ivr-migration-tool/",
          "publishedOn": "2022-03-22T22:40:21.000Z",
          "wordCount": 2592,
          "title": "Easily migrate your IVR flows to Amazon Lex using the IVR migration tool",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/22/ML-8542-image001-1099x630.png"
        },
        {
          "id": "32a555920fe3b0dc5224f950b745f309fba00220",
          "author": "RJ",
          "description": "Amazon Search’s vision is to enable customers to search effortlessly. Our spelling correction helps you find what you want even if you don’t know the exact spelling of the intended words. In the past, we used classical machine learning (ML) algorithms with manual feature engineering for spelling correction. To make the next generational leap in […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-amazon-search-achieves-low-latency-high-throughput-t5-inference-with-nvidia-triton-on-aws/",
          "publishedOn": "2022-03-22T16:47:40.000Z",
          "wordCount": 2218,
          "title": "How Amazon Search achieves low-latency, high-throughput T5 inference with NVIDIA Triton on AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/21/ML-8065-image001-feature.png"
        },
        {
          "id": "04611bd8217a125938377ead4fa226180deae472",
          "author": "Greg Herlein",
          "description": "Conversational AI can deliver powerful, automated, interactive experiences through voice and text. Amazon Lex is a service that combines automatic speech recognition and natural language understanding technologies, so you can build these sophisticated conversational experiences. A common application of conversational AI is found in contact centers: self-service virtual agents. We’re excited to announce that you […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/enable-conversational-chatbots-for-telephony-using-amazon-lex-and-the-amazon-chime-sdk/",
          "publishedOn": "2022-03-18T19:20:55.000Z",
          "wordCount": 2658,
          "title": "Enable conversational chatbots for telephony using Amazon Lex and the Amazon Chime SDK",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/17/arch.drawio-1-1.png"
        },
        {
          "id": "0d662d62f2ad7f0ee3b80b73ba595a2756ef4510",
          "author": "Emily Soward",
          "description": "Organizational forms serve as a primary business tool across industries—from financial services, to healthcare, and more. Consider, for example, tax filing forms in the tax management industry, where new forms come out each year with largely the same information. AWS customers across sectors need to process and store information in forms as part of their […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-traceable-custom-multi-format-document-parsing-pipeline-with-amazon-textract/",
          "publishedOn": "2022-03-17T18:28:10.000Z",
          "wordCount": 1796,
          "title": "Build a traceable, custom, multi-format document parsing pipeline with Amazon Textract",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/09/ML-2764-image001-new-630x630.png"
        },
        {
          "id": "36f831377de824a2ca70ae5eb8f237aff18228dc",
          "author": "Vivek Madan",
          "description": "In December 2020, AWS announced the general availability of Amazon SageMaker JumpStart, a capability of Amazon SageMaker that helps you quickly and easily get started with machine learning (ML). JumpStart provides one-click fine-tuning and deployment of a wide variety of pre-trained models across popular ML tasks, as well as a selection of end-to-end solutions that […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-jumpstart-models-and-algorithms-now-available-via-api/",
          "publishedOn": "2022-03-16T19:46:59.000Z",
          "wordCount": 2597,
          "title": "Amazon SageMaker JumpStart models and algorithms now available via API",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/16/image001-1.jpg"
        },
        {
          "id": "0139d82b38bc111704a995fa92d2cae477d8c51e",
          "author": "Abhinav Jawadekar",
          "description": "Organizations use messaging platforms like Slack to bring the right people together to securely communicate with each other and collaborate to get work done. A Slack workspace captures invaluable organizational knowledge in the form of the information that flows through it as the users collaborate. However, making this knowledge easily and securely available to users […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/unravel-the-knowledge-in-slack-workspaces-with-intelligent-search-using-the-amazon-kendra-slack-connector/",
          "publishedOn": "2022-03-15T19:42:51.000Z",
          "wordCount": 1940,
          "title": "Unravel the knowledge in Slack workspaces with intelligent search using the Amazon Kendra Slack connector",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/09/ML-8533-image001-cropped.jpg"
        },
        {
          "id": "4f460408aac16ce5df9b3374c38c7cc5884774fd",
          "author": "Abhinav Jawadekar",
          "description": "Critical information can be scattered across multiple data sources in your organization, including sources such as Windows file systems stored on Amazon FSx for Windows File Server. You can now use the Amazon Kendra connector for FSx for Windows File Server to index documents (HTML, PDF, MS Word, MS PowerPoint, and plain text) stored in […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/securely-search-unstructured-data-on-windows-file-systems-with-amazon-kendra-connector-for-amazon-fsx-for-windows-file-server/",
          "publishedOn": "2022-03-15T19:40:45.000Z",
          "wordCount": 2411,
          "title": "Securely search unstructured data on Windows file systems with the Amazon Kendra connector for Amazon FSx for Windows File Server",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/09/ML-8347-image001.jpg"
        },
        {
          "id": "02a4ebd3b69511b53cd84b4dde966471de28a1ab",
          "author": "Godwin Sahayaraj Vincent",
          "description": "In this post, we demonstrate how to create an automated email response solution using Amazon Comprehend. Organizations spend lots of resources, effort, and money on running their customer care operations to answer customer questions and provide solutions. Your customers may ask questions via various channels, such as email, chat, or phone, and deploying a workforce […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automate-email-responses-using-amazon-comprehend-custom-classification-and-entity-detection/",
          "publishedOn": "2022-03-15T17:17:53.000Z",
          "wordCount": 1605,
          "title": "Automate email responses using Amazon Comprehend custom classification and entity detection",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/03/Automate-Email-Response-Architecture-Diagram-Thumpnail.jpg"
        },
        {
          "id": "a860602f14bda028f19ecff5a466129c7760073c",
          "author": "Woody Borraccino",
          "description": "This is a post co-written with Bernard Paques, CTO of Storm Reply, and Karl Herkt, Senior Strategist at Dassault Systèmes 3DExcite. While computer vision can be crucial to industrial maintenance, manufacturing, logistics, and consumer applications, its adoption is limited by the manual creation of training datasets. The creation of labeled pictures in an industrial context […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/computer-vision-using-synthetic-datasets-with-amazon-rekognition-custom-labels-and-dassault-systemes-3dexcite/",
          "publishedOn": "2022-03-14T21:12:37.000Z",
          "wordCount": 3098,
          "title": "Computer vision using synthetic datasets with Amazon Rekognition Custom Labels and Dassault Systèmes 3DEXCITE",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/08/ML-5808-results-of-the-model-inference.png"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2204.03516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yutong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damani_M/0/1/0/all/0/1\">Mehul Damani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pamela Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuhong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sartoretti_G/0/1/0/all/0/1\">Guillaume Sartoretti</a>",
          "description": "Purpose of review: Recent advances in sensing, actuation, and computation\nhave opened the door to multi-robot systems consisting of hundreds/thousands of\nrobots, with promising applications to automated manufacturing, disaster\nrelief, harvesting, last-mile delivery, port/airport operations, or search and\nrescue. The community has leveraged model-free multi-agent reinforcement\nlearning (MARL) to devise efficient, scalable controllers for multi-robot\nsystems (MRS). This review aims to provide an analysis of the state-of-the-art\nin distributed MARL for multi-robot cooperation.\n\nRecent findings: Decentralized MRS face fundamental challenges, such as\nnon-stationarity and partial observability. Building upon the \"centralized\ntraining, decentralized execution\" paradigm, recent MARL approaches include\nindependent learning, centralized critic, value decomposition, and\ncommunication learning approaches. Cooperative behaviors are demonstrated\nthrough AI benchmarks and fundamental real-world robotic capabilities such as\nmulti-robot motion/path planning.\n\nSummary: This survey reports the challenges surrounding decentralized\nmodel-free MARL for multi-robot cooperation and existing classes of approaches.\nWe present benchmarks and robotic applications along with a discussion on\ncurrent open avenues for research.",
          "link": "http://arxiv.org/abs/2204.03516",
          "publishedOn": "2022-04-09T00:48:55.535Z",
          "wordCount": 615,
          "title": "Distributed Reinforcement Learning for Robot Teams: A Review. (arXiv:2204.03516v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yulun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cashman_M/0/1/0/all/0/1\">Mikaela Cashman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choma_N/0/1/0/all/0/1\">Nicholas Choma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prates_E/0/1/0/all/0/1\">&#xc9;rica T. Prates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vergara_V/0/1/0/all/0/1\">Ver&#xf3;nica G. Melesse Vergara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Andrew Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Manesh Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clyde_A/0/1/0/all/0/1\">Austin Clyde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brettin_T/0/1/0/all/0/1\">Thomas S. Brettin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jong_W/0/1/0/all/0/1\">Wibe A. de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1\">Neeraj Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Head_M/0/1/0/all/0/1\">Martha S. Head</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_R/0/1/0/all/0/1\">Rick L. Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nugent_P/0/1/0/all/0/1\">Peter Nugent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobson_D/0/1/0/all/0/1\">Daniel A. Jacobson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_J/0/1/0/all/0/1\">James B. Brown</a>",
          "description": "We developed Distilled Graph Attention Policy Network (DGAPN), a\nreinforcement learning model to generate novel graph-structured chemical\nrepresentations that optimize user-defined objectives by efficiently navigating\na physically constrained domain. The framework is examined on the task of\ngenerating molecules that are designed to bind, noncovalently, to functional\nsites of SARS-CoV-2 proteins. We present a spatial Graph Attention (sGAT)\nmechanism that leverages self-attention over both node and edge attributes as\nwell as encoding the spatial structure -- this capability is of considerable\ninterest in synthetic biology and drug discovery. An attentional policy network\nis introduced to learn the decision rules for a dynamic, fragment-based\nchemical environment, and state-of-the-art policy gradient techniques are\nemployed to train the network with stability. Exploration is driven by the\nstochasticity of the action space design and the innovation reward bonuses\nlearned and proposed by random network distillation. In experiments, our\nframework achieved outstanding results compared to state-of-the-art algorithms,\nwhile reducing the complexity of paths to chemical synthesis.",
          "link": "http://arxiv.org/abs/2106.02190",
          "publishedOn": "2022-04-09T00:48:55.510Z",
          "wordCount": 745,
          "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery. (arXiv:2106.02190v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05845",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Simpson_I/0/1/0/all/0/1\">Ivor J.A. Simpson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McManamon_A/0/1/0/all/0/1\">Ashley McManamon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Orzsik_B/0/1/0/all/0/1\">Bal&#xe1;zs &#xd6;rzsik</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stone_A/0/1/0/all/0/1\">Alan J. Stone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blockley_N/0/1/0/all/0/1\">Nicholas P. Blockley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asllani_I/0/1/0/all/0/1\">Iris Asllani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Colasanti_A/0/1/0/all/0/1\">Alessandro Colasanti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cercignani_M/0/1/0/all/0/1\">Mara Cercignani</a>",
          "description": "Streamlined qBOLD acquisitions enable experimentally straightforward\nobservations of brain oxygen metabolism. $R_2^\\prime$ maps are easily inferred;\nhowever, the Oxygen extraction fraction (OEF) and deoxygenated blood volume\n(DBV) are more ambiguously determined from the data. As such, existing\ninference methods tend to yield very noisy and underestimated OEF maps, while\noverestimating DBV.\n\nThis work describes a novel probabilistic machine learning approach that can\ninfer plausible distributions of OEF and DBV. Initially, we create a model that\nproduces informative voxelwise prior distribution based on synthetic training\ndata. Contrary to prior work, we model the joint distribution of OEF and DBV\nthrough a scaled multivariate logit-Normal distribution, which enables the\nvalues to be constrained within a plausible range. The prior distribution model\nis used to train an efficient amortized variational Bayesian inference model.\nThis model learns to infer OEF and DBV by predicting real image data, with few\ntraining data required, using the signal equations as a forward model.\n\nWe demonstrate that our approach enables the inference of smooth OEF and DBV\nmaps, with a physiologically plausible distribution that can be adapted through\nspecification of an informative prior distribution. Other benefits include\nmodel comparison (via the evidence lower bound) and uncertainty quantification\nfor identifying image artefacts. Results are demonstrated on a small study\ncomparing subjects undergoing hyperventilation and at rest. We illustrate that\nthe proposed approach allows measurement of gray matter differences in OEF and\nDBV and enables voxelwise comparison between conditions, where we observe\nsignificant increases in OEF and $R_2^\\prime$ during hyperventilation.",
          "link": "http://arxiv.org/abs/2203.05845",
          "publishedOn": "2022-04-09T00:48:55.502Z",
          "wordCount": 733,
          "title": "Flexible Amortized Variational Inference in qBOLD MRI. (arXiv:2203.05845v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03132",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1\">Tianyi Lin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zampetakis_M/0/1/0/all/0/1\">Manolis Zampetakis</a>",
          "description": "We consider the problem of computing an equilibrium in a class of nonlinear\ngeneralized Nash equilibrium problems (NGNEPs) in which the strategy sets for\neach player are defined by equality and inequality constraints that may depend\non the choices of rival players. While the asymptotic global convergence and\nlocal convergence rate of solution procedures have been studied in this\nsetting, the analysis of iteration complexity is still in its infancy. Our\ncontribution is to provide two simple first-order algorithmic frameworks based\non the quadratic penalty method and the augmented Lagrangian method,\nrespectively, with an accelerated mirror-prox algorithm as the inner loop. We\nprovide nonasymptotic theoretical guarantees for these algorithms. More\nspecifically, we establish the global convergence rate of our algorithms for\nsolving (strongly) monotone NGNEPs and we provide iteration complexity bounds\nexpressed in terms of the number of gradient evaluations. Experimental results\ndemonstrate the efficiency of our algorithms.",
          "link": "http://arxiv.org/abs/2204.03132",
          "publishedOn": "2022-04-09T00:48:55.494Z",
          "wordCount": 597,
          "title": "First-Order Algorithms for Nonlinear Generalized Nash Equilibrium Problems. (arXiv:2204.03132v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03219",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tseng_W/0/1/0/all/0/1\">Wei-Cheng Tseng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kao_W/0/1/0/all/0/1\">Wei-Tsung Kao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Mean opinion score (MOS) is a typical subjective evaluation metric for speech\nsynthesis systems. Since collecting MOS is time-consuming, it would be\ndesirable if there are accurate MOS prediction models for automatic evaluation.\nIn this work, we propose DDOS, a novel MOS prediction model. DDOS utilizes\ndomain adaptive pre-training to further pre-train self-supervised learning\nmodels on synthetic speech. And a proposed module is added to model the opinion\nscore distribution of each utterance. With the proposed components, DDOS\noutperforms previous works on BVCC dataset. And the zero shot transfer result\non BC2019 dataset is significantly improved. DDOS also wins second place in\nInterspeech 2022 VoiceMOS challenge in terms of system-level score.",
          "link": "http://arxiv.org/abs/2204.03219",
          "publishedOn": "2022-04-09T00:48:55.487Z",
          "wordCount": 580,
          "title": "DDOS: A MOS Prediction Framework utilizing Domain Adaptive Pre-training and Distribution of Opinion Scores. (arXiv:2204.03219v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>",
          "description": "Unsupervised image-to-image translation aims to learn the translation between\ntwo visual domains without paired data. Despite the recent progress in image\ntranslation models, it remains challenging to build mappings between complex\ndomains with drastic visual discrepancies. In this work, we present a novel\nframework, Generative Prior-guided UNsupervised Image-to-image Translation\n(GP-UNIT), to improve the overall quality and applicability of the translation\nalgorithm. Our key insight is to leverage the generative prior from pre-trained\nclass-conditional GANs (e.g., BigGAN) to learn rich content correspondences\nacross various domains. We propose a novel coarse-to-fine scheme: we first\ndistill the generative prior to capture a robust coarse-level content\nrepresentation that can link objects at an abstract semantic level, based on\nwhich fine-level content features are adaptively learned for more accurate\nmulti-level content correspondences. Extensive experiments demonstrate the\nsuperiority of our versatile framework over state-of-the-art methods in robust,\nhigh-quality and diversified translations, even for challenging and distant\ndomains.",
          "link": "http://arxiv.org/abs/2204.03641",
          "publishedOn": "2022-04-09T00:48:55.479Z",
          "wordCount": 603,
          "title": "Unsupervised Image-to-Image Translation with Generative Prior. (arXiv:2204.03641v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maniati_G/0/1/0/all/0/1\">Georgia Maniati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vioni_A/0/1/0/all/0/1\">Alexandra Vioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellinas_N/0/1/0/all/0/1\">Nikolaos Ellinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikitaras_K/0/1/0/all/0/1\">Karolos Nikitaras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klapsas_K/0/1/0/all/0/1\">Konstantinos Klapsas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_J/0/1/0/all/0/1\">June Sig Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jho_G/0/1/0/all/0/1\">Gunu Jho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalamandaris_A/0/1/0/all/0/1\">Aimilios Chalamandaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsiakoulis_P/0/1/0/all/0/1\">Pirros Tsiakoulis</a>",
          "description": "In this work, we present the SOMOS dataset, the first large-scale mean\nopinion scores (MOS) dataset consisting of solely neural text-to-speech (TTS)\nsamples. It can be employed to train automatic MOS prediction systems focused\non the assessment of modern synthesizers, and can stimulate advancements in\nacoustic model evaluation. It consists of 20K synthetic utterances of the LJ\nSpeech voice, a public domain speech dataset which is a common benchmark for\nbuilding neural acoustic models and vocoders. Utterances are generated from 200\nTTS systems including vanilla neural acoustic models as well as models which\nallow prosodic variations. An LPCNet vocoder is used for all systems, so that\nthe samples' variation depends only on the acoustic models. The synthesized\nutterances provide balanced and adequate domain and length coverage. We collect\nMOS naturalness evaluations on 3 English Amazon Mechanical Turk locales and\nshare practices leading to reliable crowdsourced annotations for this task.\nBaseline results of state-of-the-art MOS prediction models on the SOMOS dataset\nare presented, while we show the challenges that such models face when assigned\nto evaluate synthetic utterances.",
          "link": "http://arxiv.org/abs/2204.03040",
          "publishedOn": "2022-04-09T00:48:55.456Z",
          "wordCount": 650,
          "title": "SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis. (arXiv:2204.03040v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03341",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kieu_T/0/1/0/all/0/1\">Tung Kieu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chenjuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jensen_C/0/1/0/all/0/1\">Christian S. Jensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiteng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kai Zheng</a>",
          "description": "Time series data occurs widely, and outlier detection is a fundamental\nproblem in data mining, which has numerous applications. Existing\nautoencoder-based approaches deliver state-of-the-art performance on\nchallenging real-world data but are vulnerable to outliers and exhibit low\nexplainability. To address these two limitations, we propose robust and\nexplainable unsupervised autoencoder frameworks that decompose an input time\nseries into a clean time series and an outlier time series using autoencoders.\nImproved explainability is achieved because clean time series are better\nexplained with easy-to-understand patterns such as trends and periodicities. We\nprovide insight into this by means of a post-hoc explainability analysis and\nempirical studies. In addition, since outliers are separated from clean time\nseries iteratively, our approach offers improved robustness to outliers, which\nin turn improves accuracy. We evaluate our approach on five real-world datasets\nand report improvements over the state-of-the-art approaches in terms of\nrobustness and explainability.\n\nThis is an extended version of \"Robust and Explainable Autoencoders for\nUnsupervised Time Series Outlier Detection\", to appear in IEEE ICDE 2022.",
          "link": "http://arxiv.org/abs/2204.03341",
          "publishedOn": "2022-04-09T00:48:55.449Z",
          "wordCount": 627,
          "title": "Robust and Explainable Autoencoders for Unsupervised Time Series Outlier Detection---Extended Version. (arXiv:2204.03341v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1906.06717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vasic_M/0/1/0/all/0/1\">Marko Vasic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrovic_A/0/1/0/all/0/1\">Andrija Petrovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kaiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolic_M/0/1/0/all/0/1\">Mladen Nikolic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rishabh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurshid_S/0/1/0/all/0/1\">Sarfraz Khurshid</a>",
          "description": "Rapid advancements in deep learning have led to many recent breakthroughs.\nWhile deep learning models achieve superior performance, often statistically\nbetter than humans, their adoption into safety-critical settings, such as\nhealthcare or self-driving cars is hindered by their inability to provide\nsafety guarantees or to expose the inner workings of the model in a human\nunderstandable form. We present Mo\\\"ET, a novel model based on Mixture of\nExperts, consisting of decision tree experts and a generalized linear model\ngating function. Thanks to such gating function the model is more expressive\nthan the standard decision tree. To support non-differentiable decision trees\nas experts, we formulate a novel training procedure. In addition, we introduce\na hard thresholding version, Mo\\\"ETH, in which predictions are made solely by a\nsingle expert chosen via the gating function. Thanks to that property, Mo\\\"ETH\nallows each prediction to be easily decomposed into a set of logical rules in a\nform which can be easily verified. While Mo\\\"ET is a general use model, we\nillustrate its power in the reinforcement learning setting. By training Mo\\\"ET\nmodels using an imitation learning procedure on deep RL agents we outperform\nthe previous state-of-the-art technique based on decision trees while\npreserving the verifiability of the models. Moreover, we show that Mo\\\"ET can\nalso be used in real-world supervised problems on which it outperforms other\nverifiable machine learning models.",
          "link": "http://arxiv.org/abs/1906.06717",
          "publishedOn": "2022-04-09T00:48:55.442Z",
          "wordCount": 750,
          "title": "Mo\\\"ET: Mixture of Expert Trees and its Application to Verifiable Reinforcement Learning. (arXiv:1906.06717v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.06336",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>",
          "description": "The Shapley value (SV) and Least core (LC) are classic methods in cooperative\ngame theory for cost/profit sharing problems. Both methods have recently been\nproposed as a principled solution for data valuation tasks, i.e., quantifying\nthe contribution of individual datum in machine learning. However, both SV and\nLC suffer computational challenges due to the need for retraining models on\ncombinatorially many data subsets. In this work, we propose to boost the\nefficiency in computing Shapley value or Least core by learning to estimate the\nperformance of a learning algorithm on unseen data combinations. Theoretically,\nwe derive bounds relating the error in the predicted learning performance to\nthe approximation error in SV and LC. Empirically, we show that the proposed\nmethod can significantly improve the accuracy of SV and LC estimation.",
          "link": "http://arxiv.org/abs/2107.06336",
          "publishedOn": "2022-04-09T00:48:55.433Z",
          "wordCount": 593,
          "title": "Improving Cooperative Game Theory-based Data Valuation via Data Utility Learning. (arXiv:2107.06336v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1\">Nan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoxiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Supervised federated learning (FL) enables multiple clients to share the\ntrained model without sharing their labeled data. However, potential clients\nmight even be reluctant to label their own data, which could limit the\napplicability of FL in practice. In this paper, we show the possibility of\nunsupervised FL whose model is still a classifier for predicting class labels,\nif the class-prior probabilities are shifted while the class-conditional\ndistributions are shared among the unlabeled data owned by the clients. We\npropose federation of unsupervised learning (FedUL), where the unlabeled data\nare transformed into surrogate labeled data for each of the clients, a modified\nmodel is trained by supervised FL, and the wanted model is recovered from the\nmodified model. FedUL is a very general solution to unsupervised FL: it is\ncompatible with many supervised FL methods, and the recovery of the wanted\nmodel can be theoretically guaranteed as if the data have been labeled.\nExperiments on benchmark and real-world datasets demonstrate the effectiveness\nof FedUL. Code is available at https://github.com/lunanbit/FedUL.",
          "link": "http://arxiv.org/abs/2204.03304",
          "publishedOn": "2022-04-09T00:48:55.414Z",
          "wordCount": 615,
          "title": "Federated Learning from Only Unlabeled Data with Class-Conditional-Sharing Clients. (arXiv:2204.03304v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Junseok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Yunhak Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+In_Y/0/1/0/all/0/1\">Yeonjun In</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Namkyeong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hyun_D/0/1/0/all/0/1\">Dongmin Hyun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chanyoung Park</a>",
          "description": "Despite the success of Graph Neural Networks (GNNs) on various applications,\nGNNs encounter significant performance degradation when the amount of\nsupervision signals, i.e., number of labeled nodes, is limited, which is\nexpected as GNNs are trained solely based on the supervision obtained from the\nlabeled nodes. On the other hand,recent self-supervised learning paradigm aims\nto train GNNs by solving pretext tasks that do not require any labeled nodes,\nand it has shown to even outperform GNNs trained with few labeled nodes.\nHowever, a major drawback of self-supervised methods is that they fall short of\nlearning class discriminative node representations since no labeled information\nis utilized during training. To this end, we propose a novel semi-supervised\nmethod for graphs, GraFN, that leverages few labeled nodes to ensure nodes that\nbelong to the same class to be grouped together, thereby achieving the best of\nboth worlds of semi-supervised and self-supervised methods. Specifically, GraFN\nrandomly samples support nodes from labeled nodes and anchor nodes from the\nentire graph. Then, it minimizes the difference between two predicted class\ndistributions that are non-parametrically assigned by anchor-supports\nsimilarity from two differently augmented graphs. We experimentally show that\nGraFN surpasses both the semi-supervised and self-supervised methods in terms\nof node classification on real-world graphs. The source code for GraFN is\navailable at https://github.com/Junseok0207/GraFN.",
          "link": "http://arxiv.org/abs/2204.01303",
          "publishedOn": "2022-04-09T00:48:55.406Z",
          "wordCount": 690,
          "title": "GraFN: Semi-Supervised Node Classification on Graph with Few Labels via Non-Parametric Distribution Assignment. (arXiv:2204.01303v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Liang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shubin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jianming Deng</a>",
          "description": "Adopting reinforcement learning (RL) for traffic signal control is\nincreasingly popular. Most RL methods use fixed action interval (denoted as\ntduration) and actuate or maintain a phase every tduration, which makes the\nphase duration less dynamic and flexible. In addition, the actuated phase can\nbe arbitrary, affecting the real-world deployment, which requires a fixed\ncyclical phase structure. To address these challenges, we propose a multi-level\ntraffic signal control framework, DynLight, which uses an optimization method\nMax-QueueLength (M-QL) to determine the phase and uses a deep Q-network to\ndetermine the corresponding duration. Based on DynLight, we further propose\nDynLight-C that adopts a well trained deep Q-network of DynLight and replace\nM-QL by a fixed cyclical control policy that actuate a set of phases in fixed\norder to realize cyclical phase structure. Comprehensive experiments on\nmultiple real-world datasets demonstrate that DynLight achives a new\nstate-of-the-art. Furthermore, the deep Q-network of DynLight can learn well on\ndetermining the phase duration and DynLight-C demonstrates high performance for\ndeployment.",
          "link": "http://arxiv.org/abs/2204.03471",
          "publishedOn": "2022-04-09T00:48:55.399Z",
          "wordCount": 615,
          "title": "DynLight: Realize dynamic phase duration with multi-level traffic signal control. (arXiv:2204.03471v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.03398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Narang_A/0/1/0/all/0/1\">Adhyyan Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faulkner_E/0/1/0/all/0/1\">Evan Faulkner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drusvyatskiy_D/0/1/0/all/0/1\">Dmitriy Drusvyatskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazel_M/0/1/0/all/0/1\">Maryam Fazel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratliff_L/0/1/0/all/0/1\">Lillian J. Ratliff</a>",
          "description": "Learning problems commonly exhibit an interesting feedback mechanism wherein\nthe population data reacts to competing decision makers' actions. This paper\nformulates a new game theoretic framework for this phenomenon, called\n\"multi-player performative prediction\". We focus on two distinct solution\nconcepts, namely (i) performatively stable equilibria and (ii) Nash equilibria\nof the game. The latter equilibria are arguably more informative, but can be\nfound efficiently only when the game is monotone. We show that under mild\nassumptions, the performatively stable equilibria can be found efficiently by a\nvariety of algorithms, including repeated retraining and the repeated\n(stochastic) gradient method. We then establish transparent sufficient\nconditions for strong monotonicity of the game and use them to develop\nalgorithms for finding Nash equilibria. We investigate derivative free methods\nand adaptive gradient algorithms wherein each player alternates between\nlearning a parametric description of their distribution and gradient steps on\nthe empirical risk. Synthetic and semi-synthetic numerical experiments\nillustrate the results.",
          "link": "http://arxiv.org/abs/2201.03398",
          "publishedOn": "2022-04-09T00:48:55.388Z",
          "wordCount": null,
          "title": "Multiplayer Performative Prediction: Learning in Decision-Dependent Games. (arXiv:2201.03398v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03248",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sekimoto_K/0/1/0/all/0/1\">Kaiji Sekimoto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yasuda_M/0/1/0/all/0/1\">Muneki Yasuda</a>",
          "description": "Although evaluation of the expectations on the Ising model is essential in\nvarious applications, this is frequently infeasible because of intractable\nmultiple summations (or integrations). Spatial Monte Carlo integration (SMCI)\nis a sampling-based approximation, and can provide high-accuracy estimations\nfor such intractable expectations. To evaluate the expectation of a function of\nvariables in a specific region (called target region), SMCI considers a larger\nregion containing the target region (called sum region). In SMCI, the multiple\nsummation for the variables in the sum region is precisely executed, and that\nin the outer region is evaluated by the sampling approximation such as the\nstandard Monte Carlo integration. It is guaranteed that the accuracy of the\nSMCI estimator is monotonically improved as the size of the sum region\nincreases. However, a haphazard expansion of the sum region could cause a\ncombinatorial explosion. Therefore, we hope to improve the accuracy without\nsuch region expansion. In this study, based on the theory of generalized least\nsquares, a new effective method is proposed by combining multiple SMCI\nestimators. The validity of the proposed method is demonstrated theoretically\nand numerically. The results indicate that the proposed method can be effective\nin the inverse Ising problem (or Boltzmann machine learning).",
          "link": "http://arxiv.org/abs/2204.03248",
          "publishedOn": "2022-04-09T00:48:55.387Z",
          "wordCount": 660,
          "title": "Composite Spatial Monte Carlo Integration Based on Generalized Least Squares. (arXiv:2204.03248v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.06476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akyon_F/0/1/0/all/0/1\">Fatih Cagatay Akyon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavusoglu_D/0/1/0/all/0/1\">Devrim Cavusoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cengiz_C/0/1/0/all/0/1\">Cemil Cengiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altinuc_S/0/1/0/all/0/1\">Sinan Onur Altinuc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Temizel_A/0/1/0/all/0/1\">Alptekin Temizel</a>",
          "description": "While exam-style questions are a fundamental educational tool serving a\nvariety of purposes, manual construction of questions is a complex process that\nrequires training, experience and resources. Automatic question generation (QG)\ntechniques can be utilized to satisfy the need for a continuous supply of new\nquestions by streamlining their generation. However, compared to automatic\nquestion answering (QA), QG is a more challenging task. In this work, we\nfine-tune a multilingual T5 (mT5) transformer in a multi-task setting for QA,\nQG and answer extraction tasks using Turkish QA datasets. To the best of our\nknowledge, this is the first academic work that performs automated text-to-text\nquestion generation from Turkish texts. Experimental evaluations show that the\nproposed multi-task setting achieves state-of-the-art Turkish question\nanswering and question generation performance on TQuADv1, TQuADv2 datasets and\nXQuAD Turkish split. The source code and the pre-trained models are available\nat https://github.com/obss/turkish-question-generation.",
          "link": "http://arxiv.org/abs/2111.06476",
          "publishedOn": "2022-04-09T00:48:55.387Z",
          "wordCount": null,
          "title": "Automated question generation and question answering from Turkish texts. (arXiv:2111.06476v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03193",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiahao Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Shiqi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1\">Guang Lin</a>",
          "description": "A new data-driven method for operator learning of stochastic differential\nequations(SDE) is proposed in this paper. The central goal is to solve forward\nand inverse stochastic problems more effectively using limited data. Deep\noperator network(DeepONet) has been proposed recently for operator learning.\nCompared to other neural networks to learn functions, it aims at the problem of\nlearning nonlinear operators. However, it can be challenging by using the\noriginal model to learn nonlinear operators for high-dimensional stochastic\nproblems. We propose a new multi-resolution autoencoder DeepONet model referred\nto as MultiAuto-DeepONet to deal with this difficulty with the aid of\nconvolutional autoencoder. The encoder part of the network is designed to\nreduce the dimensionality as well as discover the hidden features of\nhigh-dimensional stochastic inputs. The decoder is designed to have a special\nstructure, i.e. in the form of DeepONet. The first DeepONet in decoder is\ndesigned to reconstruct the input function involving randomness while the\nsecond one is used to approximate the solution of desired equations. Those two\nDeepONets has a common branch net and two independent trunk nets. This\narchitecture enables us to deal with multi-resolution inputs naturally. By\nadding $L_1$ regularization to our network, we found the outputs from the\nbranch net and two trunk nets all have sparse structures. This reduces the\nnumber of trainable parameters in the neural network thus making the model more\nefficient. Finally, we conduct several numerical experiments to illustrate the\neffectiveness of our proposed MultiAuto-DeepONet model with uncertainty\nquantification.",
          "link": "http://arxiv.org/abs/2204.03193",
          "publishedOn": "2022-04-09T00:48:55.379Z",
          "wordCount": 705,
          "title": "MultiAuto-DeepONet: A Multi-resolution Autoencoder DeepONet for Nonlinear Dimension Reduction, Uncertainty Quantification and Operator Learning of Forward and Inverse Stochastic Problems. (arXiv:2204.03193v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.01665",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grelier_C/0/1/0/all/0/1\">Cyril Grelier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goudet_O/0/1/0/all/0/1\">Olivier Goudet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jin-Kao Hao</a>",
          "description": "This work presents the first study of using the popular Monte Carlo Tree\nSearch (MCTS) method combined with dedicated heuristics for solving the\nWeighted Vertex Coloring Problem. Starting with the basic MCTS algorithm, we\ngradually introduce a number of algorithmic variants where MCTS is extended by\nvarious simulation strategies including greedy and local search heuristics. We\nconduct experiments on well-known benchmark instances to assess the value of\neach studied combination. We also provide empirical evidence to shed light on\nthe advantages and limits of each strategy.",
          "link": "http://arxiv.org/abs/2202.01665",
          "publishedOn": "2022-04-09T00:48:55.379Z",
          "wordCount": null,
          "title": "On Monte Carlo Tree Search for Weighted Vertex Coloring. (arXiv:2202.01665v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gustineli_M/0/1/0/all/0/1\">Murilo Gustineli</a>",
          "description": "Artificial neural networks (ANN), typically referred to as neural networks,\nare a class of Machine Learning algorithms and have achieved widespread\nsuccess, having been inspired by the biological structure of the human brain.\nNeural networks are inherently powerful due to their ability to learn complex\nfunction approximations from data. This generalization ability has been able to\nimpact multidisciplinary areas involving image recognition, speech recognition,\nnatural language processing, and others. Activation functions are a crucial\nsub-component of neural networks. They define the output of a node in the\nnetwork given a set of inputs. This survey discusses the main concepts of\nactivation functions in neural networks, including; a brief introduction to\ndeep neural networks, a summary of what are activation functions and how they\nare used in neural networks, their most common properties, the different types\nof activation functions, some of the challenges, limitations, and alternative\nsolutions faced by activation functions, concluding with the final remarks.",
          "link": "http://arxiv.org/abs/2204.02921",
          "publishedOn": "2022-04-09T00:48:55.379Z",
          "wordCount": null,
          "title": "A survey on recently proposed activation functions for Deep Learning. (arXiv:2204.02921v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03495",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Gordon_M/0/1/0/all/0/1\">Max Hunter Gordon</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cerezo_M/0/1/0/all/0/1\">M. Cerezo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>",
          "description": "Principal component analysis (PCA) is a dimensionality reduction method in\ndata analysis that involves diagonalizing the covariance matrix of the dataset.\nRecently, quantum algorithms have been formulated for PCA based on\ndiagonalizing a density matrix. These algorithms assume that the covariance\nmatrix can be encoded in a density matrix, but a concrete protocol for this\nencoding has been lacking. Our work aims to address this gap. Assuming\namplitude encoding of the data, with the data given by the ensemble $\\{p_i,|\n\\psi_i \\rangle\\}$, then one can easily prepare the ensemble average density\nmatrix $\\overline{\\rho} = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i |$. We first\nshow that $\\overline{\\rho}$ is precisely the covariance matrix whenever the\ndataset is centered. For quantum datasets, we exploit global phase symmetry to\nargue that there always exists a centered dataset consistent with\n$\\overline{\\rho}$, and hence $\\overline{\\rho}$ can always be interpreted as a\ncovariance matrix. This provides a simple means for preparing the covariance\nmatrix for arbitrary quantum datasets or centered classical datasets. For\nuncentered classical datasets, our method is so-called \"PCA without centering\",\nwhich we interpret as PCA on a symmetrized dataset. We argue that this closely\ncorresponds to standard PCA, and we derive equations and inequalities that\nbound the deviation of the spectrum obtained with our method from that of\nstandard PCA. We numerically illustrate our method for the MNIST handwritten\ndigit dataset. We also argue that PCA on quantum datasets is natural and\nmeaningful, and we numerically implement our method for molecular ground-state\ndatasets.",
          "link": "http://arxiv.org/abs/2204.03495",
          "publishedOn": "2022-04-09T00:48:55.370Z",
          "wordCount": null,
          "title": "Covariance matrix preparation for quantum principal component analysis. (arXiv:2204.03495v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hadi_M/0/1/0/all/0/1\">Mohammad Abdul Hadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yusuf_I/0/1/0/all/0/1\">Imam Nur Bani Yusuf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thung_F/0/1/0/all/0/1\">Ferdian Thung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luong_K/0/1/0/all/0/1\">Kien Gia Luong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lingxiao_J/0/1/0/all/0/1\">Jiang Lingxiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fard_F/0/1/0/all/0/1\">Fatemeh H. Fard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_D/0/1/0/all/0/1\">David Lo</a>",
          "description": "Developers frequently use APIs to implement certain functionalities, such as\nparsing Excel Files, reading and writing text files line by line, etc.\nDevelopers can greatly benefit from automatic API usage sequence generation\nbased on natural language queries for building applications in a faster and\ncleaner manner. Existing approaches utilize information retrieval models to\nsearch for matching API sequences given a query or use RNN-based\nencoder-decoder to generate API sequences. As it stands, the first approach\ntreats queries and API names as bags of words. It lacks deep comprehension of\nthe semantics of the queries. The latter approach adapts a neural language\nmodel to encode a user query into a fixed-length context vector and generate\nAPI sequences from the context vector.\n\nWe want to understand the effectiveness of recent Pre-trained Transformer\nbased Models (PTMs) for the API learning task. These PTMs are trained on large\nnatural language corpora in an unsupervised manner to retain contextual\nknowledge about the language and have found success in solving similar Natural\nLanguage Processing (NLP) problems. However, the applicability of PTMs has not\nyet been explored for the API sequence generation task. We use a dataset that\ncontains 7 million annotations collected from GitHub to evaluate the PTMs\nempirically. This dataset was also used to assess previous approaches. Based on\nour results, PTMs generate more accurate API sequences and outperform other\nrelated methods by around 11%. We have also identified two different\ntokenization approaches that can contribute to a significant boost in PTMs'\nperformance for the API sequence generation task.",
          "link": "http://arxiv.org/abs/2204.03498",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "On the Effectiveness of Pretrained Models for API Learning. (arXiv:2204.03498v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_W/0/1/0/all/0/1\">Wai Weng Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Layeghy_S/0/1/0/all/0/1\">Siamak Layeghy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarhan_M/0/1/0/all/0/1\">Mohanad Sarhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallagher_M/0/1/0/all/0/1\">Marcus Gallagher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portmann_M/0/1/0/all/0/1\">Marius Portmann</a>",
          "description": "This paper presents a new Android malware detection method based on Graph\nNeural Networks (GNNs) with Jumping-Knowledge (JK). Android function call\ngraphs (FCGs) consist of a set of program functions and their inter-procedural\ncalls. Thus, this paper proposes a GNN-based method for Android malware\ndetection by capturing meaningful intra-procedural call path patterns. In\naddition, a Jumping-Knowledge technique is applied to minimize the effect of\nthe over-smoothing problem, which is common in GNNs. The proposed method has\nbeen extensively evaluated using two benchmark datasets. The results\ndemonstrate the superiority of our approach compared to state-of-the-art\napproaches in terms of key classification metrics, which demonstrates the\npotential of GNNs in Android malware detection and classification.",
          "link": "http://arxiv.org/abs/2201.07537",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "Graph Neural Network-based Android Malware Classification with Jumping Knowledge. (arXiv:2201.07537v5 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.12991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shirvanimoghaddam_M/0/1/0/all/0/1\">Mahyar Shirvanimoghaddam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yifeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guha_A/0/1/0/all/0/1\">Aradhika Guha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salari_A/0/1/0/all/0/1\">Ayoob Salari</a>",
          "description": "In this paper, we consider the federated learning (FL) problem in the\npresence of communication errors. We model the link between the devices and the\ncentral node (CN) by a packet erasure channel, where the local parameters from\ndevices are either erased or received correctly by CN with probability $e$ and\n$1-e$, respectively. We provide mathematical proof for the convergence of the\nFL algorithm in the presence of communication errors, where the CN uses past\nlocal updates when the fresh updates are not received from some devices. We\nshow via simulations that by using the past local updates, the FL algorithm can\nconverge in the presence of communication errors. We also show that when the\ndataset is uniformly distributed among devices, the FL algorithm that only uses\nfresh updates and discards missing updates might converge faster than the FL\nalgorithm that uses past local updates.",
          "link": "http://arxiv.org/abs/2201.12991",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "Federated Learning with Erroneous Communication Links. (arXiv:2201.12991v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Washington_P/0/1/0/all/0/1\">Peter Washington</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutlu_C/0/1/0/all/0/1\">Cezmi Mutlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kline_A/0/1/0/all/0/1\">Aaron Kline</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_C/0/1/0/all/0/1\">Cathy Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunlap_K/0/1/0/all/0/1\">Kaitlyn Dunlap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kent_J/0/1/0/all/0/1\">Jack Kent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Husic_A/0/1/0/all/0/1\">Arman Husic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stockham_N/0/1/0/all/0/1\">Nate Stockham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chrisman_B/0/1/0/all/0/1\">Brianna Chrisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paskov_K/0/1/0/all/0/1\">Kelley Paskov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1\">Jae-Yoon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wall_D/0/1/0/all/0/1\">Dennis P. Wall</a>",
          "description": "Some of the most severe bottlenecks preventing widespread development of\nmachine learning models for human behavior include a dearth of labeled training\ndata and difficulty of acquiring high quality labels. Active learning is a\nparadigm for using algorithms to computationally select a useful subset of data\npoints to label using metrics for model uncertainty and data similarity. We\nexplore active learning for naturalistic computer vision emotion data, a\nparticularly heterogeneous and complex data space due to inherently subjective\nlabels. Using frames collected from gameplay acquired from a therapeutic\nsmartphone game for children with autism, we run a simulation of active\nlearning using gameplay prompts as metadata to aid in the active learning\nprocess. We find that active learning using information generated during\ngameplay slightly outperforms random selection of the same number of labeled\nframes. We next investigate a method to conduct active learning with subjective\ndata, such as in affective computing, and where multiple crowdsourced labels\ncan be acquired for each image. Using the Child Affective Facial Expression\n(CAFE) dataset, we simulate an active learning process for crowdsourcing many\nlabels and find that prioritizing frames using the entropy of the crowdsourced\nlabel distribution results in lower categorical cross-entropy loss compared to\nrandom frame selection. Collectively, these results demonstrate pilot\nevaluations of two novel active learning approaches for subjective affective\ndata collected in noisy settings.",
          "link": "http://arxiv.org/abs/2204.01915",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "An Exploration of Active Learning for Affective Digital Phenotyping. (arXiv:2204.01915v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.02700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shia_E/0/1/0/all/0/1\">Ensheng Shia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hongbin Sun</a>",
          "description": "Commit messages concisely describe the content of code diffs (i.e., code\nchanges) and the intent behind them. Recently, many approaches have been\nproposed to generate commit messages automatically. The information\nretrieval-based methods reuse the commit messages of similar code diffs, while\nthe neural-based methods learn the semantic connection between code diffs and\ncommit messages. However, the reused commit messages might not accurately\ndescribe the content/intent of code diffs and neural-based methods tend to\ngenerate high-frequent and repetitive tokens in the corpus. In this paper, we\ncombine the advantages of the two technical routes and propose a novel\nexemplar-based neural commit message generation model, which treats the similar\ncommit message as an exemplar and leverages it to guide the neural network\nmodel to generate an accurate commit message. We perform extensive experiments\nand the results confirm the effectiveness of our model.",
          "link": "http://arxiv.org/abs/2203.02700",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "ECMG: Exemplar-based Commit Message Generation. (arXiv:2203.02700v2 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naser_M/0/1/0/all/0/1\">M.Z. Naser</a>",
          "description": "Much of our experiments are designed to uncover the cause(s) and effect(s)\nbehind a data generating mechanism (i.e., phenomenon) we happen to be\ninterested in. Uncovering such relationships allows us to identify the true\nworking of a phenomenon and, most importantly, articulate a model that may\nenable us to further explore the phenomenon on hand and/or allow us to predict\nit accurately. Fundamentally, such models are likely to be derived via a causal\napproach (as opposed to an observational or empirical mean). In this approach,\ncausal discovery is required to create a causal model, which can then be\napplied to infer the influence of interventions, and answer any hypothetical\nquestions (i.e., in the form of What ifs? Etc.) that we might have. This paper\nbuilds a case for causal discovery and causal inference and contrasts that\nagainst traditional machine learning approaches; all from a civil and\nstructural engineering perspective. More specifically, this paper outlines the\nkey principles of causality and the most commonly used algorithms and packages\nfor causal discovery and causal inference. Finally, this paper also presents a\nseries of examples and case studies of how causal concepts can be adopted for\nour domain.",
          "link": "http://arxiv.org/abs/2204.01543",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "Causality, Causal Discovery, and Causal Inference in Structural Engineering. (arXiv:2204.01543v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daesoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aune_E/0/1/0/all/0/1\">Erlend Aune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langet_N/0/1/0/all/0/1\">Nad&#xe8;ge Langet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eidsvik_J/0/1/0/all/0/1\">Jo Eidsvik</a>",
          "description": "One of the latest self-supervised learning (SSL) methods, VICReg, showed a\ngreat performance both in the linear evaluation and the fine-tuning evaluation.\nHowever, VICReg is proposed in computer vision and it learns by pulling\nrepresentations of random crops of an image while maintaining the\nrepresentation space by the variance and covariance loss. However, VICReg would\nbe ineffective on non-stationary time series where different parts/crops of\ninput should be differently encoded to consider the non-stationarity. Another\nrecent SSL proposal, Temporal Neighborhood Coding (TNC) is effective for\nencoding non-stationary time series. This study shows that a combination of a\nVICReg-style method and TNC is very effective for SSL on non-stationary time\nseries, where a non-stationary seismic signal time series is used as an\nevaluation dataset.",
          "link": "http://arxiv.org/abs/2204.02697",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance Evaluated on Non-stationary Seismic Signal Time Series. (arXiv:2204.02697v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verdecchia_R/0/1/0/all/0/1\">Roberto Verdecchia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_L/0/1/0/all/0/1\">Lu&#xed;s Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sallou_J/0/1/0/all/0/1\">June Sallou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Michelle Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wickenden_J/0/1/0/all/0/1\">James Wickenden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hotellier_E/0/1/0/all/0/1\">Estelle Hotellier</a>",
          "description": "With the growing availability of large-scale datasets, and the popularization\nof affordable storage and computational capabilities, the energy consumed by AI\nis becoming a growing concern. To address this issue, in recent years, studies\nhave focused on demonstrating how AI energy efficiency can be improved by\ntuning the model training strategy. Nevertheless, how modifications applied to\ndatasets can impact the energy consumption of AI is still an open question. To\nfill this gap, in this exploratory study, we evaluate if data-centric\napproaches can be utilized to improve AI energy efficiency. To achieve our\ngoal, we conduct an empirical experiment, executed by considering 6 different\nAI algorithms, a dataset comprising 5,574 data points, and two dataset\nmodifications (number of data points and number of features). Our results show\nevidence that, by exclusively conducting modifications on datasets, energy\nconsumption can be drastically reduced (up to 92.16%), often at the cost of a\nnegligible or even absent accuracy decline. As additional introductory results,\nwe demonstrate how, by exclusively changing the algorithm used, energy savings\nup to two orders of magnitude can be achieved. In conclusion, this exploratory\ninvestigation empirically demonstrates the importance of applying data-centric\ntechniques to improve AI energy efficiency. Our results call for a research\nagenda that focuses on data-centric techniques, to further enable and\ndemocratize Green AI.",
          "link": "http://arxiv.org/abs/2204.02766",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "Data-Centric Green AI: An Exploratory Empirical Study. (arXiv:2204.02766v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.03706",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ramprasad_P/0/1/0/all/0/1\">Pratik Ramprasad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yuantong Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1\">Guang Cheng</a>",
          "description": "The recent emergence of reinforcement learning has created a demand for\nrobust statistical inference methods for the parameter estimates computed using\nthese algorithms. Existing methods for statistical inference in online learning\nare restricted to settings involving independently sampled observations, while\nexisting statistical inference methods in reinforcement learning (RL) are\nlimited to the batch setting. The online bootstrap is a flexible and efficient\napproach for statistical inference in linear stochastic approximation\nalgorithms, but its efficacy in settings involving Markov noise, such as RL,\nhas yet to be explored. In this paper, we study the use of the online bootstrap\nmethod for statistical inference in RL. In particular, we focus on the temporal\ndifference (TD) learning and Gradient TD (GTD) learning algorithms, which are\nthemselves special instances of linear stochastic approximation under Markov\nnoise. The method is shown to be distributionally consistent for statistical\ninference in policy evaluation, and numerical experiments are included to\ndemonstrate the effectiveness of this algorithm at statistical inference tasks\nacross a range of real RL environments.",
          "link": "http://arxiv.org/abs/2108.03706",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Online Bootstrap Inference For Policy Evaluation in Reinforcement Learning. (arXiv:2108.03706v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.00185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Matthew S. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1\">Animesh Garg</a>",
          "description": "Policy gradient methods have been frequently applied to problems in control\nand reinforcement learning with great success, yet existing convergence\nanalysis still relies on non-intuitive, impractical and often opaque\nconditions. In particular, existing rates are achieved in limited settings,\nunder strict regularity conditions. In this work, we establish explicit\nconvergence rates of policy gradient methods, extending the convergence regime\nto weakly smooth policy classes with $L_2$ integrable gradient. We provide\nintuitive examples to illustrate the insight behind these new conditions.\nNotably, our analysis also shows that convergence rates are achievable for both\nthe standard policy gradient and the natural policy gradient algorithms under\nthese assumptions. Lastly we provide performance guarantees for the converged\npolicies.",
          "link": "http://arxiv.org/abs/2111.00185",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Convergence and Optimality of Policy Gradient Methods in Weakly Smooth Settings. (arXiv:2111.00185v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozumnyi_D/0/1/0/all/0/1\">Denys Rozumnyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oswald_M/0/1/0/all/0/1\">Martin R. Oswald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrari_V/0/1/0/all/0/1\">Vittorio Ferrari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>",
          "description": "We propose a method for jointly estimating the 3D motion, 3D shape, and\nappearance of highly motion-blurred objects from a video. To this end, we model\nthe blurred appearance of a fast moving object in a generative fashion by\nparametrizing its 3D position, rotation, velocity, acceleration, bounces,\nshape, and texture over the duration of a predefined time window spanning\nmultiple frames. Using differentiable rendering, we are able to estimate all\nparameters by minimizing the pixel-wise reprojection error to the input video\nvia backpropagating through a rendering pipeline that accounts for motion blur\nby averaging the graphics output over short time intervals. For that purpose,\nwe also estimate the camera exposure gap time within the same optimization. To\naccount for abrupt motion changes like bounces, we model the motion trajectory\nas a piece-wise polynomial, and we are able to estimate the specific time of\nthe bounce at sub-frame accuracy. Experiments on established benchmark datasets\ndemonstrate that our method outperforms previous methods for fast moving object\ndeblurring and 3D reconstruction.",
          "link": "http://arxiv.org/abs/2111.14465",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Motion-from-Blur: 3D Shape and Motion Estimation of Motion-blurred Objects in Videos. (arXiv:2111.14465v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04175",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Elmas_G/0/1/0/all/0/1\">Gokberk Elmas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dar_S/0/1/0/all/0/1\">Salman UH Dar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korkmaz_Y/0/1/0/all/0/1\">Yilmaz Korkmaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ceyani_E/0/1/0/all/0/1\">Emir Ceyani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Susam_B/0/1/0/all/0/1\">Burak Susam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ozbey_M/0/1/0/all/0/1\">Muzaffer &#xd6;zbey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Avestimehr_S/0/1/0/all/0/1\">Salman Avestimehr</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cukur_T/0/1/0/all/0/1\">Tolga &#xc7;ukur</a>",
          "description": "Multi-institutional efforts can facilitate training of deep MRI\nreconstruction models, albeit privacy risks arise during cross-site sharing of\nimaging data. Federated learning (FL) has recently been introduced to address\nprivacy concerns by enabling distributed training without transfer of imaging\ndata. Existing FL methods for MRI reconstruction employ conditional models to\nmap from undersampled to fully-sampled acquisitions via explicit knowledge of\nthe imaging operator. Since conditional models generalize poorly across\ndifferent acceleration rates or sampling densities, imaging operators must be\nfixed between training and testing, and they are typically matched across\nsites. To improve generalization and flexibility in multi-institutional\ncollaborations, here we introduce a novel method for MRI reconstruction based\non Federated learning of Generative IMage Priors (FedGIMP). FedGIMP leverages a\ntwo-stage approach: cross-site learning of a generative MRI prior, and\nsubject-specific injection of the imaging operator. The global MRI prior is\nlearned via an unconditional adversarial model that synthesizes high-quality MR\nimages based on latent variables. Specificity in the prior is preserved via a\nmapper subnetwork that produces site-specific latents. During inference, the\nprior is combined with subject-specific imaging operators to enable\nreconstruction, and further adapted to individual test samples by minimizing\ndata-consistency loss. Comprehensive experiments on multi-institutional\ndatasets clearly demonstrate enhanced generalization performance of FedGIMP\nagainst site-specific and federated methods based on conditional models, as\nwell as traditional reconstruction methods.",
          "link": "http://arxiv.org/abs/2202.04175",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Federated Learning of Generative Image Priors for MRI Reconstruction. (arXiv:2202.04175v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.12800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Solaiyappan_S/0/1/0/all/0/1\">Siddharth Solaiyappan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuxin Wen</a>",
          "description": "Deep generative networks in recent years have reinforced the need for caution\nwhile consuming various modalities of digital information. One avenue of\ndeepfake creation is aligned with injection and removal of tumors from medical\nscans. Failure to detect medical deepfakes can lead to large setbacks on\nhospital resources or even loss of life. This paper attempts to address the\ndetection of such attacks with a structured case study. Specifically, we\nevaluate eight different machine learning algorithms, which including three\nconventional machine learning methods, support vector machine, random forest,\ndecision tree, and five deep learning models, DenseNet121, DenseNet201,\nResNet50, ResNet101, VGG19, on distinguishing between tampered and untampered\nimages.For deep learning models, the five models are used for feature\nextraction, then fine-tune for each pre-trained model is performed. The\nfindings of this work show near perfect accuracy in detecting instances of\ntumor injections and removals.",
          "link": "http://arxiv.org/abs/2109.12800",
          "publishedOn": "2022-04-09T00:48:55.366Z",
          "wordCount": null,
          "title": "Machine Learning based Medical Image Deepfake Detection: A Comparative Study. (arXiv:2109.12800v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castellano_A/0/1/0/all/0/1\">Agustin Castellano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_H/0/1/0/all/0/1\">Hancheng Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bazerque_J/0/1/0/all/0/1\">Juan Bazerque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallada_E/0/1/0/all/0/1\">Enrique Mallada</a>",
          "description": "In this work we address the problem of finding feasible policies for\nConstrained Markov Decision Processes under probability one constraints. We\nargue that stationary policies are not sufficient for solving this problem, and\nthat a rich class of policies can be found by endowing the controller with a\nscalar quantity, so called budget, that tracks how close the agent is to\nviolating the constraint. We show that the minimal budget required to act\nsafely can be obtained as the smallest fixed point of a Bellman-like operator,\nfor which we analyze its convergence properties. We also show how to learn this\nquantity when the true kernel of the Markov decision process is not known,\nwhile providing sample-complexity bounds. The utility of knowing this minimal\nbudget relies in that it can aid in the search of optimal or near-optimal\npolicies by shrinking down the region of the state space the agent must\nnavigate. Simulations illustrate the different nature of probability one\nconstraints against the typically used constraints in expectation.",
          "link": "http://arxiv.org/abs/2112.05198",
          "publishedOn": "2022-04-09T00:48:55.365Z",
          "wordCount": null,
          "title": "Reinforcement Learning with Almost Sure Constraints. (arXiv:2112.05198v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.11200",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Kwak_Y/0/1/0/all/0/1\">Yunseok Kwak</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Yun_W/0/1/0/all/0/1\">Won Joon Yun</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_J/0/1/0/all/0/1\">Jae Pyoung Kim</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cho_H/0/1/0/all/0/1\">Hyunhee Cho</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Choi_M/0/1/0/all/0/1\">Minseok Choi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jung_S/0/1/0/all/0/1\">Soyi Jung</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_J/0/1/0/all/0/1\">Joongheon Kim</a>",
          "description": "Although deep learning (DL) has already become a state-of-the-art technology\nfor various data processing tasks, data security and computational overload\nproblems often arise due to their high data and computational power dependency.\nTo solve this problem, quantum deep learning (QDL) and distributed deep\nlearning (DDL) has emerged to complement existing DL methods. Furthermore, a\nquantum distributed deep learning (QDDL) technique that combines and maximizes\nthese advantages is getting attention. This paper compares several model\nstructures for QDDL and discusses their possibilities and limitations to\nleverage QDDL for some representative application scenarios.",
          "link": "http://arxiv.org/abs/2202.11200",
          "publishedOn": "2022-04-09T00:48:55.365Z",
          "wordCount": null,
          "title": "Quantum Distributed Deep Learning Architectures: Models, Discussions, and Applications. (arXiv:2202.11200v3 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.15783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polk_S/0/1/0/all/0/1\">Sam L. Polk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_J/0/1/0/all/0/1\">James M. Murphy</a>",
          "description": "Clustering algorithms partition a dataset into groups of similar points. The\nprimary contribution of this article is the Multiscale Spatially-Regularized\nDiffusion Learning (M-SRDL) clustering algorithm, which uses\nspatially-regularized diffusion distances to efficiently and accurately learn\nmultiple scales of latent structure in hyperspectral images. The M-SRDL\nclustering algorithm extracts clusterings at many scales from a hyperspectral\nimage and outputs these clusterings' variation of information-barycenter as an\nexemplar for all underlying cluster structure. We show that incorporating\nspatial regularization into a multiscale clustering framework results in\nsmoother and more coherent clusters when applied to hyperspectral data,\nyielding more accurate clustering labels.",
          "link": "http://arxiv.org/abs/2103.15783",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "Multiscale Clustering of Hyperspectral Images Through Spectral-Spatial Diffusion Geometry. (arXiv:2103.15783v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.02375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Miao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1\">Praveer Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1\">Jayashree Kalpathy-Cramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Federated learning is an emerging research paradigm for enabling\ncollaboratively training deep learning models without sharing patient data.\nHowever, the data from different institutions are usually heterogeneous across\ninstitutions, which may reduce the performance of models trained using\nfederated learning. In this study, we propose a novel heterogeneity-aware\nfederated learning method, SplitAVG, to overcome the performance drops from\ndata heterogeneity in federated learning. Unlike previous federated methods\nthat require complex heuristic training or hyper parameter tuning, our SplitAVG\nleverages the simple network split and feature map concatenation strategies to\nencourage the federated model training an unbiased estimator of the target data\ndistribution. We compare SplitAVG with seven state-of-the-art federated\nlearning methods, using centrally hosted training data as the baseline on a\nsuite of both synthetic and real-world federated datasets. We find that the\nperformance of models trained using all the comparison federated learning\nmethods degraded significantly with the increasing degrees of data\nheterogeneity. In contrast, SplitAVG method achieves comparable results to the\nbaseline method under all heterogeneous settings, that it achieves 96.2% of the\naccuracy and 110.4% of the mean absolute error obtained by the baseline in a\ndiabetic retinopathy binary classification dataset and a bone age prediction\ndataset, respectively, on highly heterogeneous data partitions. We conclude\nthat SplitAVG method can effectively overcome the performance drops from\nvariability in data distributions across institutions. Experimental results\nalso show that SplitAVG can be adapted to different base networks and\ngeneralized to various types of medical imaging tasks.",
          "link": "http://arxiv.org/abs/2107.02375",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "SplitAVG: A heterogeneity-aware federated deep learning method for medical imaging. (arXiv:2107.02375v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_T/0/1/0/all/0/1\">Tristan Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1\">Edward J. Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahlou_S/0/1/0/all/0/1\">Salem Lahlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_M/0/1/0/all/0/1\">Mo Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1\">Emmanuel Bengio</a>",
          "description": "Generative Flow Networks (GFlowNets) have been introduced as a method to\nsample a diverse set of candidates in an active learning context, with a\ntraining objective that makes them approximately sample in proportion to a\ngiven reward function. In this paper, we show a number of additional\ntheoretical properties of GFlowNets. They can be used to estimate joint\nprobability distributions and the corresponding marginal distributions where\nsome variables are unspecified and, of particular interest, can represent\ndistributions over composite objects like sets and graphs. GFlowNets amortize\nthe work typically done by computationally expensive MCMC methods in a single\nbut trained generative pass. They could also be used to estimate partition\nfunctions and free energies, conditional probabilities of supersets\n(supergraphs) given a subset (subgraph), as well as marginal distributions over\nall supersets (supergraphs) of a given set (graph). We introduce variations\nenabling the estimation of entropy and mutual information, sampling from a\nPareto frontier, connections to reward-maximizing policies, and extensions to\nstochastic environments, continuous actions and modular energy functions.",
          "link": "http://arxiv.org/abs/2111.09266",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "GFlowNet Foundations. (arXiv:2111.09266v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zechun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1\">Kwang-Ting Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Dong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhiqiang Shen</a>",
          "description": "The nonuniform quantization strategy for compressing neural networks usually\nachieves better performance than its counterpart, i.e., uniform strategy, due\nto its superior representational capacity. However, many nonuniform\nquantization methods overlook the complicated projection process in\nimplementing the nonuniformly quantized weights/activations, which incurs\nnon-negligible time and space overhead in hardware deployment. In this study,\nwe propose Nonuniform-to-Uniform Quantization (N2UQ), a method that can\nmaintain the strong representation ability of nonuniform methods while being\nhardware-friendly and efficient as the uniform quantization for model\ninference. We achieve this through learning the flexible in-equidistant input\nthresholds to better fit the underlying distribution while quantizing these\nreal-valued inputs into equidistant output levels. To train the quantized\nnetwork with learnable input thresholds, we introduce a generalized\nstraight-through estimator (G-STE) for intractable backward derivative\ncalculation w.r.t. threshold parameters. Additionally, we consider entropy\npreserving regularization to further reduce information loss in weight\nquantization. Even under this adverse constraint of imposing uniformly\nquantized weights and activations, our N2UQ outperforms state-of-the-art\nnonuniform quantization methods by 0.5~1.7 on ImageNet, demonstrating the\ncontribution of N2UQ design. Code and models are available at:\nhttps://github.com/liuzechun/Nonuniform-to-Uniform-Quantization.",
          "link": "http://arxiv.org/abs/2111.14826",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via Generalized Straight-Through Estimation. (arXiv:2111.14826v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bowen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wenxin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shinozaki_T/0/1/0/all/0/1\">Takahiro Shinozaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>",
          "description": "The long-tailed class distribution in visual recognition tasks poses great\nchallenges for neural networks on how to handle the biased predictions between\nhead and tail classes, i.e., the model tends to classify tail classes as head\nclasses. While existing research focused on data resampling and loss function\nengineering, in this paper, we take a different perspective: the classification\nmargins. We study the relationship between the margins and logits\n(classification scores) and empirically observe the biased margins and the\nbiased logits are positively correlated. We propose MARC, a simple yet\neffective MARgin Calibration function to dynamically calibrate the biased\nmargins for unbiased logits. We validate MARC through extensive experiments on\ncommon long-tailed benchmarks including CIFAR-LT, ImageNet-LT, Places-LT, and\niNaturalist-LT. Experimental results demonstrate that our MARC achieves\nfavorable results on these benchmarks. In addition, MARC is extremely easy to\nimplement with just three lines of code. We hope this simple method will\nmotivate people to rethink the biased margins and biased logits in long-tailed\nvisual recognition.",
          "link": "http://arxiv.org/abs/2112.07225",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "Margin Calibration for Long-Tailed Visual Recognition. (arXiv:2112.07225v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.06934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akyon_F/0/1/0/all/0/1\">Fatih Cagatay Akyon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altinuc_S/0/1/0/all/0/1\">Sinan Onur Altinuc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Temizel_A/0/1/0/all/0/1\">Alptekin Temizel</a>",
          "description": "Detection of small objects and objects far away in the scene is a major\nchallenge in surveillance applications. Such objects are represented by small\nnumber of pixels in the image and lack sufficient details, making them\ndifficult to detect using conventional detectors. In this work, an open-source\nframework called Slicing Aided Hyper Inference (SAHI) is proposed that provides\na generic slicing aided inference and fine-tuning pipeline for small object\ndetection. The proposed technique is generic in the sense that it can be\napplied on top of any available object detector without any fine-tuning.\nExperimental evaluations, using object detection baselines on the Visdrone and\nxView aerial object detection datasets show that the proposed inference method\ncan increase object detection AP by 6.8%, 5.1% and 5.3% for FCOS, VFNet and\nTOOD detectors, respectively. Moreover, the detection accuracy can be further\nincreased with a slicing aided fine-tuning, resulting in a cumulative increase\nof 12.7%, 13.4% and 14.5% AP in the same order. Proposed technique has been\nintegrated with Detectron2, MMDetection and YOLOv5 models and it is publicly\navailable at https://github.com/obss/sahi.git .",
          "link": "http://arxiv.org/abs/2202.06934",
          "publishedOn": "2022-04-09T00:48:55.363Z",
          "wordCount": null,
          "title": "Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection. (arXiv:2202.06934v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05774",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1\">Yunhan Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Q/0/1/0/all/0/1\">Quanyan Zhu</a>",
          "description": "In this work, we study the deception of a Linear-Quadratic-Gaussian (LQG)\nagent by manipulating the cost signals. We show that a small falsification of\nthe cost parameters will only lead to a bounded change in the optimal policy.\nThe bound is linear on the amount of falsification the attacker can apply to\nthe cost parameters. We propose an attack model where the attacker aims to\nmislead the agent into learning a `nefarious' policy by intentionally\nfalsifying the cost parameters. We formulate the attack's problem as a convex\noptimization problem and develop necessary and sufficient conditions to check\nthe achievability of the attacker's goal.\n\nWe showcase the adversarial manipulation on two types of LQG learners: the\nbatch RL learner and the other is the adaptive dynamic programming (ADP)\nlearner. Our results demonstrate that with only 2.296% of falsification on the\ncost data, the attacker misleads the batch RL into learning the 'nefarious'\npolicy that leads the vehicle to a dangerous position. The attacker can also\ngradually trick the ADP learner into learning the same `nefarious' policy by\nconsistently feeding the learner a falsified cost signal that stays close to\nthe actual cost signal. The paper aims to raise people's awareness of the\nsecurity threats faced by RL-enabled control systems.",
          "link": "http://arxiv.org/abs/2203.05774",
          "publishedOn": "2022-04-09T00:48:55.363Z",
          "wordCount": null,
          "title": "Reinforcement Learning for Linear Quadratic Control is Vulnerable Under Cost Manipulation. (arXiv:2203.05774v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.05113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tseng_W/0/1/0/all/0/1\">Wei-Cheng Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kao_W/0/1/0/all/0/1\">Wei-Tsung Kao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Recently, adapting the idea of self-supervised learning (SSL) on continuous\nspeech has started gaining attention. SSL models pre-trained on a huge amount\nof unlabeled audio can generate general-purpose representations that benefit a\nwide variety of speech processing tasks. Despite their ubiquitous deployment,\nhowever, the potential privacy risks of these models have not been well\ninvestigated. In this paper, we present the first privacy analysis on several\nSSL speech models using Membership Inference Attacks (MIA) under black-box\naccess. The experiment results show that these pre-trained models are\nvulnerable to MIA and prone to membership information leakage with high Area\nUnder the Curve (AUC) in both utterance-level and speaker-level. Furthermore,\nwe also conduct several ablation studies to understand the factors that\ncontribute to the success of MIA.",
          "link": "http://arxiv.org/abs/2111.05113",
          "publishedOn": "2022-04-09T00:48:55.362Z",
          "wordCount": null,
          "title": "Membership Inference Attacks Against Self-supervised Speech Models. (arXiv:2111.05113v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bellinger_C/0/1/0/all/0/1\">Colin Bellinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drozdyuk_A/0/1/0/all/0/1\">Andriy Drozdyuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowley_M/0/1/0/all/0/1\">Mark Crowley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamblyn_I/0/1/0/all/0/1\">Isaac Tamblyn</a>",
          "description": "The use of reinforcement learning (RL) in scientific applications, such as\nmaterials design and automated chemistry, is increasing. A major challenge,\nhowever, lies in fact that measuring the state of the system is often costly\nand time consuming in scientific applications, whereas policy learning with RL\nrequires a measurement after each time step. In this work, we make the\nmeasurement costs explicit in the form of a costed reward and propose a\nframework that enables off-the-shelf deep RL algorithms to learn a policy for\nboth selecting actions and determining whether or not to measure the current\nstate of the system at each time step. In this way, the agents learn to balance\nthe need for information with the cost of information. Our results show that\nwhen trained under this regime, the Dueling DQN and PPO agents can learn\noptimal action policies whilst making up to 50\\% fewer state measurements, and\nrecurrent neural networks can produce a greater than 50\\% reduction in\nmeasurements. We postulate the these reduction can help to lower the barrier to\napplying RL to real-world scientific applications.",
          "link": "http://arxiv.org/abs/2112.07535",
          "publishedOn": "2022-04-09T00:48:55.362Z",
          "wordCount": null,
          "title": "Scientific Discovery and the Cost of Measurement -- Balancing Information and Cost in Reinforcement Learning. (arXiv:2112.07535v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.14417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Donghwan Lee</a>",
          "description": "The goal of this paper is to investigate a control theoretic analysis of\nlinear stochastic iterative algorithm and temporal difference (TD) learning.\nTD-learning is a linear stochastic iterative algorithm to estimate the value\nfunction of a given policy for a Markov decision process, which is one of the\nmost popular and fundamental reinforcement learning algorithms. While there has\nbeen a series of successful works in theoretical analysis of TD-learning, it\nwas not until recently that researchers found some guarantees on its\nstatistical efficiency. In this paper, we propose a control theoretic\nfinite-time analysis TD-learning, which exploits standard notions in linear\nsystem control communities. Therefore, the proposed work provides additional\ninsights on TD-learning and reinforcement learning with simple concepts and\nanalysis tools in control theory.",
          "link": "http://arxiv.org/abs/2112.14417",
          "publishedOn": "2022-04-09T00:48:55.362Z",
          "wordCount": null,
          "title": "Control Theoretic Analysis of Temporal Difference Learning. (arXiv:2112.14417v4 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_C/0/1/0/all/0/1\">Carl Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1\">Aditya Grover</a>",
          "description": "The goal of imitation learning is to mimic expert behavior from\ndemonstrations, without access to an explicit reward signal. A popular class of\napproach infers the (unknown) reward function via inverse reinforcement\nlearning (IRL) followed by maximizing this reward function via reinforcement\nlearning (RL). The policies learned via these approaches are however very\nbrittle in practice and deteriorate quickly even with small test-time\nperturbations due to compounding errors. We propose Imitation with Planning at\nTest-time (IMPLANT), a new meta-algorithm for imitation learning that utilizes\ndecision-time planning to correct for compounding errors of any base imitation\npolicy. In contrast to existing approaches, we retain both the imitation policy\nand the rewards model at decision-time, thereby benefiting from the learning\nsignal of the two components. Empirically, we demonstrate that IMPLANT\nsignificantly outperforms benchmark imitation learning approaches on standard\ncontrol environments and excels at zero-shot generalization when subject to\nchallenging perturbations in test-time dynamics.",
          "link": "http://arxiv.org/abs/2204.03597",
          "publishedOn": "2022-04-09T00:48:55.361Z",
          "wordCount": null,
          "title": "Imitating, Fast and Slow: Robust learning from demonstrations via decision-time planning. (arXiv:2204.03597v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.14836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhun Deng</a>",
          "description": "Representations of the world environment play a crucial role in artificial\nintelligence. It is often inefficient to conduct reasoning and inference\ndirectly in the space of raw sensory representations, such as pixel values of\nimages. Representation learning allows us to automatically discover suitable\nrepresentations from raw sensory data. For example, given raw sensory data, a\ndeep neural network learns nonlinear representations at its hidden layers,\nwhich are subsequently used for classification at its output layer. This\nhappens implicitly during training through minimizing a supervised or\nunsupervised loss. In this paper, we study the dynamics of such implicit\nnonlinear representation learning. We identify a pair of a new assumption and a\nnovel condition, called the common model structure assumption and the\ndata-architecture alignment condition. Under the common model structure\nassumption, the data-architecture alignment condition is shown to be sufficient\nfor the global convergence and necessary for the global optimality. Moreover,\nour theory explains how and when increasing the network size does and does not\nimprove the training behaviors in the practical regime. Our results provide\npractical guidance for designing a model structure: e.g., the common model\nstructure assumption can be used as a justification for using a particular\nmodel structure instead of others. We also derive a new training framework,\nwhich satisfies the data-architecture alignment condition by automatically\nmodifying any given training algorithm. Given a standard training algorithm,\nthe framework running its modified version is empirically shown to maintain\ncompetitive test performances while providing global convergence guarantees for\ndeep residual neural networks with convolutions, skip connections, and batch\nnormalization with datasets, including MNIST, CIFAR-10, CIFAR-100, Semeion,\nKMNIST and SVHN.",
          "link": "http://arxiv.org/abs/2106.14836",
          "publishedOn": "2022-04-09T00:48:55.361Z",
          "wordCount": null,
          "title": "Understanding Dynamics of Nonlinear Representation Learning and Its Application. (arXiv:2106.14836v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Croitoru_F/0/1/0/all/0/1\">Florinel-Alin Croitoru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grigore_D/0/1/0/all/0/1\">Diana-Nicoleta Grigore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>",
          "description": "During the training process, deep neural networks implicitly learn to\nrepresent the input data samples through a hierarchy of features, where the\nsize of the hierarchy is determined by the number of layers. In this paper, we\nfocus on enforcing the discriminative power of the high-level representations,\nthat are typically learned by the deeper layers (closer to the output). To this\nend, we introduce a new loss term inspired by the Gini impurity, which is aimed\nat minimizing the entropy (increasing the discriminative power) of individual\nhigh-level features with respect to the class labels. Although our Gini loss\ninduces highly-discriminative features, it does not ensure that the\ndistribution of the high-level features matches the distribution of the\nclasses. As such, we introduce another loss term to minimize the\nKullback-Leibler divergence between the two distributions. We conduct\nexperiments on two image classification data sets (CIFAR-100 and Caltech 101),\nconsidering multiple neural architectures ranging from convolutional networks\n(ResNet-17, ResNet-18, ResNet-50) to transformers (CvT). Our empirical results\nshow that integrating our novel loss terms into the training objective\nconsistently outperforms the models trained with cross-entropy alone, without\nincreasing the inference time at all.",
          "link": "http://arxiv.org/abs/2202.07073",
          "publishedOn": "2022-04-09T00:48:55.361Z",
          "wordCount": null,
          "title": "Discriminability-enforcing loss to improve representation learning. (arXiv:2202.07073v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krug_A/0/1/0/all/0/1\">Andreas Krug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratul_R/0/1/0/all/0/1\">Raihan Kabir Ratul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stober_S/0/1/0/all/0/1\">Sebastian Stober</a>",
          "description": "Machine Learning with Deep Neural Networks (DNNs) has become a successful\ntool in solving tasks across various fields of application. The success of DNNs\nis strongly connected to their high complexity in terms of the number of\nnetwork layers or of neurons in each layer, which severely complicates to\nunderstand how DNNs solve their learned task. To improve the explainability of\nDNNs, we adapt methods from neuroscience because this field has a rich\nexperience in analyzing complex and opaque systems. In this work, we draw\ninspiration from how neuroscience uses topographic maps to visualize the\nactivity of the brain when it performs certain tasks. Transferring this\napproach to DNNs can help to visualize and understand their internal processes\nmore intuitively, too. However, the inner structures of brains and DNNs differ\nsubstantially. Therefore, to be able to visualize activations of neurons in\nDNNs as topographic maps, we research techniques to layout the neurons in a\ntwo-dimensional space in which neurons of similar activity are in the vicinity\nof each other. In this work, we introduce and compare different methods to\nobtain a topographic layout of the neurons in a network layer. Moreover, we\ndemonstrate how to use the resulting topographic activation maps to identify\nerrors or encoded biases in DNNs or data sets. Our novel visualization\ntechnique improves the transparency of DNN-based algorithmic decision-making\nsystems and is accessible to a broad audience because topographic maps are\nintuitive to interpret without expert-knowledge in Machine Learning.",
          "link": "http://arxiv.org/abs/2204.03528",
          "publishedOn": "2022-04-09T00:48:55.360Z",
          "wordCount": null,
          "title": "Visualizing Deep Neural Networks with Topographic Activation Maps. (arXiv:2204.03528v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.02072",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Kalashev_O/0/1/0/all/0/1\">O. Kalashev</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kharuk_I/0/1/0/all/0/1\">I. Kharuk</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kuznetsov_M/0/1/0/all/0/1\">M. Kuznetsov</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Rubtsov_G/0/1/0/all/0/1\">G. Rubtsov</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sako_T/0/1/0/all/0/1\">T. Sako</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Tsunesada_Y/0/1/0/all/0/1\">Y. Tsunesada</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Zhezher_Y/0/1/0/all/0/1\">Ya. Zhezher</a>",
          "description": "We introduce a novel method for identifying the mass composition of\nultra-high-energy cosmic rays using deep learning. The key idea of the method\nis to use a chain of two neural networks. The first network predicts the type\nof a primary particle for individual events, while the second infers the mass\ncomposition of an ensemble of events. We apply this method to the Monte-Carlo\ndata for the Telescope Array Surface Detectors readings, on which it yields an\nunprecedented low error of 7% for 4-component approximation. We also discuss\nthe problems of applying the developed method to the experimental data, and the\nway they can be resolved.",
          "link": "http://arxiv.org/abs/2112.02072",
          "publishedOn": "2022-04-09T00:48:55.359Z",
          "wordCount": null,
          "title": "Deep learning method for identifying mass composition of ultra-high-energy cosmic rays. (arXiv:2112.02072v2 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yafei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_J/0/1/0/all/0/1\">John Keller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1\">Sebastian Scherer</a>",
          "description": "In traditional robot exploration methods, the robot usually does not have\nprior biases about the environment it is exploring. Thus the robot assigns\nequal importance to the goals which leads to insufficient exploration\nefficiency. Alternative, often a hand-tuned policy is used to tweak the value\nof goals. In this paper, we present a method to learn how \"good\" some states\nare, measured by the state value function, to provide a hint for the robot to\nmake exploration decisions. We propose to learn state value functions from\nprevious offline collected datasets and then transfer and improve the value\nfunction during testing in a new environment. Moreover, the environments\nusually have very few and even no extrinsic reward or feedback for the robot.\nTherefore in this work, we also tackle the problem of sparse extrinsic rewards\nfrom the environments. We design several intrinsic rewards to encourage the\nrobot to obtain more information during exploration. These reward functions\nthen become the building blocks of the state value functions. We test our\nmethod on challenging subterranean and urban environments. To the best of our\nknowledge, this work for the first time demonstrates value function prediction\nwith previous collected datasets to help exploration in challenging\nsubterranean environments.",
          "link": "http://arxiv.org/abs/2204.03140",
          "publishedOn": "2022-04-09T00:48:55.358Z",
          "wordCount": null,
          "title": "Learning and Transferring Value Function for Robot Exploration in Subterranean Environments. (arXiv:2204.03140v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1\">Satwik Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Swaroop Ghosh</a>",
          "description": "In the last few years, quantum computing has experienced a growth spurt. One\nexciting avenue of quantum computing is quantum machine learning (QML) which\ncan exploit the high dimensional Hilbert space to learn richer representations\nfrom limited data and thus can efficiently solve complex learning tasks.\nDespite the increased interest in QML, there have not been many studies that\ndiscuss the security aspects of QML. In this work, we explored the possible\nfuture applications of QML in the hardware security domain. We also expose the\nsecurity vulnerabilities of QML and emerging attack models, and corresponding\ncountermeasures.",
          "link": "http://arxiv.org/abs/2204.03625",
          "publishedOn": "2022-04-09T00:48:55.345Z",
          "wordCount": null,
          "title": "Security Aspects of Quantum Machine Learning: Opportunities, Threats and Defenses. (arXiv:2204.03625v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tzinis_E/0/1/0/all/0/1\">Efthymios Tzinis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wichern_G/0/1/0/all/0/1\">Gordon Wichern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanian_A/0/1/0/all/0/1\">Aswin Subramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smaragdis_P/0/1/0/all/0/1\">Paris Smaragdis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roux_J/0/1/0/all/0/1\">Jonathan Le Roux</a>",
          "description": "We introduce a new paradigm for single-channel target source separation where\nthe sources of interest can be distinguished using non-mutually exclusive\nconcepts (e.g., loudness, gender, language, spatial location, etc). Our\nproposed heterogeneous separation framework can seamlessly leverage datasets\nwith large distribution shifts and learn cross-domain representations under a\nvariety of concepts used as conditioning. Our experiments show that training\nseparation models with heterogeneous conditions facilitates the generalization\nto new concepts with unseen out-of-domain data while also performing\nsubstantially higher than single-domain specialist models. Notably, such\ntraining leads to more robust learning of new harder source separation\ndiscriminative concepts and can yield improvements over permutation invariant\ntraining with oracle source selection. We analyze the intrinsic behavior of\nsource separation training with heterogeneous metadata and propose ways to\nalleviate emerging problems with challenging separation conditions. We release\nthe collection of preparation recipes for all datasets used to further promote\nresearch towards this challenging task.",
          "link": "http://arxiv.org/abs/2204.03594",
          "publishedOn": "2022-04-09T00:48:55.344Z",
          "wordCount": null,
          "title": "Heterogeneous Target Speech Separation. (arXiv:2204.03594v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.06428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ibriga_H/0/1/0/all/0/1\">Hilda S Ibriga</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>",
          "description": "We aim to provably complete a sparse and highly-missing tensor in the\npresence of covariate information along tensor modes. Our motivation comes from\nonline advertising where users click-through-rates (CTR) on ads over various\ndevices form a CTR tensor that has about 96% missing entries and has many zeros\non non-missing entries, which makes the standalone tensor completion method\nunsatisfactory. Beside the CTR tensor, additional ad features or user\ncharacteristics are often available. In this paper, we propose\nCovariate-assisted Sparse Tensor Completion (COSTCO) to incorporate covariate\ninformation for the recovery of the sparse tensor. The key idea is to jointly\nextract latent components from both the tensor and the covariate matrix to\nlearn a synthetic representation. Theoretically, we derive the error bound for\nthe recovered tensor components and explicitly quantify the improvements on\nboth the reveal probability condition and the tensor recovery accuracy due to\ncovariates. Finally, we apply COSTCO to an advertisement dataset consisting of\na CTR tensor and ad covariate matrix, leading to 23% accuracy improvement over\nthe baseline. An important by-product is that ad latent components from COSTCO\nreveal interesting ad clusters, which are useful for better ad targeting.",
          "link": "http://arxiv.org/abs/2103.06428",
          "publishedOn": "2022-04-09T00:48:55.344Z",
          "wordCount": null,
          "title": "Covariate-assisted Sparse Tensor Completion. (arXiv:2103.06428v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yuxin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neiswanger_W/0/1/0/all/0/1\">Willie Neiswanger</a>",
          "description": "With the surge in the number of hyperparameters and training times of modern\nmachine learning models, hyperparameter tuning is becoming increasingly\nexpensive. However, after assessing 40 tuning methods systematically, we find\nthat each faces certain limitations. In particular, methods that speed up\ntuning via knowledge transfer typically require the final performance of\nhyperparameters and do not focus on low-fidelity information. As we demonstrate\nempirically, this common practice is suboptimal and can incur an unnecessary\nuse of resources. It is more cost-efficient to instead leverage low-fidelity\ntuning observations to measure inter-task similarity and transfer knowledge\nfrom existing to new tasks accordingly. However, performing multi-fidelity\ntuning comes with its own challenges in the transfer setting: the noise in\nadditional observations and the need for performance forecasting. Therefore, we\npropose and conduct a thorough analysis of a multi-task multi-fidelity Bayesian\noptimization framework, which leads to the best instantiation--amortized\nauto-tuning (AT2). We further present an offline-computed 27-task\nhyperparameter recommendation (HyperRec) database to serve the community.\nExtensive experiments on HyperRec and other real-world databases illustrate the\neffectiveness of our AT2 method.",
          "link": "http://arxiv.org/abs/2106.09179",
          "publishedOn": "2022-04-09T00:48:55.344Z",
          "wordCount": null,
          "title": "Amortized Auto-Tuning: Cost-Efficient Bayesian Transfer Optimization for Hyperparameter Recommendation. (arXiv:2106.09179v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.02166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1\">Yushuo Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pengyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_Z/0/1/0/all/0/1\">Zhengping Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_K/0/1/0/all/0/1\">Kaigui Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "The convolutional neural network has achieved great success in fulfilling\ncomputer vision tasks despite large computation overhead against efficient\ndeployment. Structured (channel) pruning is usually applied to reduce the model\nredundancy while preserving the network structure, such that the pruned network\ncan be easily deployed in practice. However, existing structured pruning\nmethods require hand-crafted rules which may lead to tremendous pruning space.\nIn this paper, we introduce Differentiable Annealing Indicator Search (DAIS)\nthat leverages the strength of neural architecture search in the channel\npruning and automatically searches for the effective pruned model with given\nconstraints on computation overhead. Specifically, DAIS relaxes the binarized\nchannel indicators to be continuous and then jointly learns both indicators and\nmodel parameters via bi-level optimization. To bridge the non-negligible\ndiscrepancy between the continuous model and the target binarized model, DAIS\nproposes an annealing-based procedure to steer the indicator convergence\ntowards binarized states. Moreover, DAIS designs various regularizations based\non a priori structural knowledge to control the pruning sparsity and to improve\nmodel performance. Experimental results show that DAIS outperforms\nstate-of-the-art pruning methods on CIFAR-10, CIFAR-100, and ImageNet.",
          "link": "http://arxiv.org/abs/2011.02166",
          "publishedOn": "2022-04-09T00:48:55.343Z",
          "wordCount": null,
          "title": "DAIS: Automatic Channel Pruning via Differentiable Annealing Indicator Search. (arXiv:2011.02166v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.08877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parekh_V/0/1/0/all/0/1\">Vivek Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flore_D/0/1/0/all/0/1\">Dominik Flore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schops_S/0/1/0/all/0/1\">Sebastian Sch&#xf6;ps</a>",
          "description": "Conventional magneto-static finite element analysis of electrical machine\ndesign is time-consuming and computationally expensive. Since each machine\ntopology has a distinct set of parameters, design optimization is commonly\nperformed independently. This paper presents a novel method for predicting Key\nPerformance Indicators (KPIs) of differently parameterized electrical machine\ntopologies at the same time by mapping a high dimensional integrated design\nparameters in a lower dimensional latent space using a variational autoencoder.\nAfter training, via a latent space, the decoder and multi-layer neural network\nwill function as meta-models for sampling new designs and predicting associated\nKPIs, respectively. This enables parameter-based concurrent multi-topology\noptimization.",
          "link": "http://arxiv.org/abs/2201.08877",
          "publishedOn": "2022-04-09T00:48:55.343Z",
          "wordCount": null,
          "title": "Variational Autoencoder based Metamodeling for Multi-Objective Topology Optimization of Electrical Machines. (arXiv:2201.08877v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02978",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lemercier_J/0/1/0/all/0/1\">Jean-Marie Lemercier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thiemann_J/0/1/0/all/0/1\">Joachim Thiemann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Koning_R/0/1/0/all/0/1\">Raphael Koning</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gerkmann_T/0/1/0/all/0/1\">Timo Gerkmann</a>",
          "description": "A two-stage online dereverberation algorithm for hearing devices is presented\nin this paper. The approach combines a multi-channel multi-frame linear\nfiltering approach with a single-channel single-frame post-filter. Both\ncomponents rely on power spectral density (PSD) estimates provided by deep\nneural networks (DNNs). This contribution extends our prior work, which shows\nthat directly optimizing for a criterion at the output of the multi-channel\nlinear filtering stage results in a more efficient dereverberation, as compared\nto placing the criterion at the output of the DNN to optimize the PSD\nestimation. In the present work, we show that the dereverberation performance\nof the proposed first stage particularly improves the early-to-mid\nreverberation ratio if trained end-to-end. We thus argue that it can be\ncombined with a post-filtering stage which benefits from the early-to-mid ratio\nimprovement and is consequently able to efficiently suppress the residual late\nreverberation. This proposed two stage procedure is shown to be both very\neffective in terms of dereverberation performance and computational demands.\nFurthermore, the proposed system can be adapted to the needs of different types\nof hearing-device users by controlling the amount of reduction of early\nreflections. The proposed system outperforms the previously proposed end-to-end\nDNN-supported linear filtering algorithm, as well as other traditional\napproaches, based on an evaluation using the noise-free version of the WHAMR!\ndataset.",
          "link": "http://arxiv.org/abs/2204.02978",
          "publishedOn": "2022-04-09T00:48:55.342Z",
          "wordCount": null,
          "title": "End-To-End Optimization of Online Neural Network-supported Two-Stage Dereverberation for Hearing Devices. (arXiv:2204.02978v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01533",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cuesta_Ramirez_J/0/1/0/all/0/1\">Jhouben Cuesta-Ramirez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Riche_R/0/1/0/all/0/1\">Rodolphe Le Riche</a>, <a href=\"http://arxiv.org/find/math/1/au:+Roustant_O/0/1/0/all/0/1\">Olivier Roustant</a>, <a href=\"http://arxiv.org/find/math/1/au:+Perrin_G/0/1/0/all/0/1\">Guillaume Perrin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Durantin_C/0/1/0/all/0/1\">Cedric Durantin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gliere_A/0/1/0/all/0/1\">Alain Gliere</a>",
          "description": "Most real optimization problems are defined over a mixed search space where\nthe variables are both discrete and continuous. In engineering applications,\nthe objective function is typically calculated with a numerically costly\nblack-box simulation.General mixed and costly optimization problems are\ntherefore of a great practical interest, yet their resolution remains in a\nlarge part an open scientific question. In this article, costly mixed problems\nare approached through Gaussian processes where the discrete variables are\nrelaxed into continuous latent variables. The continuous space is more easily\nharvested by classical Bayesian optimization techniques than a mixed space\nwould. Discrete variables are recovered either subsequently to the continuous\noptimization, or simultaneously with an additional continuous-discrete\ncompatibility constraint that is handled with augmented Lagrangians. Several\npossible implementations of such Bayesian mixed optimizers are compared. In\nparticular, the reformulation of the problem with continuous latent variables\nis put in competition with searches working directly in the mixed space. Among\nthe algorithms involving latent variables and an augmented Lagrangian, a\nparticular attention is devoted to the Lagrange multipliers for which a local\nand a global estimation techniques are studied. The comparisons are based on\nthe repeated optimization of three analytical functions and a beam design\nproblem.",
          "link": "http://arxiv.org/abs/2111.01533",
          "publishedOn": "2022-04-09T00:48:55.341Z",
          "wordCount": null,
          "title": "A comparison of mixed-variables Bayesian optimization approaches. (arXiv:2111.01533v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06416",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1\">Qingxu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_T/0/1/0/all/0/1\">Tenghai Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jianqiang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_Z/0/1/0/all/0/1\">Zhiqiang Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shiguang Wu</a>",
          "description": "When dealing with a series of imminent issues, humans can naturally\nconcentrate on a subset of these concerning issues by prioritizing them\naccording to their contributions to motivational indices, e.g., the probability\nof winning a game. This idea of concentration offers insights into\nreinforcement learning of sophisticated Large-scale Multi-Agent Systems (LMAS)\nparticipated by hundreds of agents. In such an LMAS, each agent receives a long\nseries of entity observations at each step, which can overwhelm existing\naggregation networks such as graph attention networks and cause inefficiency.\nIn this paper, we propose a concentration network called ConcNet. First,\nConcNet scores the observed entities considering several motivational indices,\ne.g., expected survival time and state value of the agents, and then ranks,\nprunes, and aggregates the encodings of observed entities to extract features.\nSecond, distinct from the well-known attention mechanism, ConcNet has a unique\nmotivational subnetwork to explicitly consider the motivational indices when\nscoring the observed entities. Furthermore, we present a concentration policy\ngradient architecture that can learn effective policies in LMAS from scratch.\nExtensive experiments demonstrate that the presented architecture has excellent\nscalability and flexibility, and significantly outperforms existing methods on\nLMAS benchmarks.",
          "link": "http://arxiv.org/abs/2203.06416",
          "publishedOn": "2022-04-09T00:48:55.340Z",
          "wordCount": 655,
          "title": "Concentration Network for Reinforcement Learning of Large-Scale Multi-Agent Systems. (arXiv:2203.06416v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.04121",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daunhawer_I/0/1/0/all/0/1\">Imant Daunhawer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutter_T/0/1/0/all/0/1\">Thomas M. Sutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_Cheong_K/0/1/0/all/0/1\">Kieran Chin-Cheong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palumbo_E/0/1/0/all/0/1\">Emanuele Palumbo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "Multimodal variational autoencoders (VAEs) have shown promise as efficient\ngenerative models for weakly-supervised data. Yet, despite their advantage of\nweak supervision, they exhibit a gap in generative quality compared to unimodal\nVAEs, which are completely unsupervised. In an attempt to explain this gap, we\nuncover a fundamental limitation that applies to a large family of\nmixture-based multimodal VAEs. We prove that the sub-sampling of modalities\nenforces an undesirable upper bound on the multimodal ELBO and thereby limits\nthe generative quality of the respective models. Empirically, we showcase the\ngenerative quality gap on both synthetic and real data and present the\ntradeoffs between different variants of multimodal VAEs. We find that none of\nthe existing approaches fulfills all desired criteria of an effective\nmultimodal generative model when applied on more complex datasets than those\nused in previous benchmarks. In summary, we identify, formalize, and validate\nfundamental limitations of VAE-based approaches for modeling weakly-supervised\ndata and discuss implications for real-world applications.",
          "link": "http://arxiv.org/abs/2110.04121",
          "publishedOn": "2022-04-09T00:48:55.331Z",
          "wordCount": null,
          "title": "On the Limitations of Multimodal VAEs. (arXiv:2110.04121v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.09371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1\">Neeraj Varshney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>",
          "description": "It's better to say \"I can't answer\" than to answer incorrectly. This\nselective prediction ability is crucial for NLP systems to be reliably deployed\nin real-world applications. Prior work has shown that existing selective\nprediction techniques fail to perform well, especially in the out-of-domain\nsetting. In this work, we propose a method that improves probability estimates\nof models by calibrating them using prediction confidence and difficulty score\nof instances. Using these two signals, we first annotate held-out instances and\nthen train a calibrator to predict the likelihood of correctness of the model's\nprediction. We instantiate our method with Natural Language Inference (NLI) and\nDuplicate Detection (DD) tasks and evaluate it in both In-Domain (IID) and\nOut-of-Domain (OOD) settings. In (IID, OOD) settings, we show that the\nrepresentations learned by our calibrator result in an improvement of (15.81%,\n5.64%) and (6.19%, 13.9%) over 'MaxProb' -- a selective prediction baseline --\non NLI and DD tasks respectively.",
          "link": "http://arxiv.org/abs/2008.09371",
          "publishedOn": "2022-04-09T00:48:55.329Z",
          "wordCount": null,
          "title": "Towards Improving Selective Prediction Ability of NLP Systems. (arXiv:2008.09371v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abhishek_K/0/1/0/all/0/1\">Kumar Abhishek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_C/0/1/0/all/0/1\">Colin J. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamarneh_G/0/1/0/all/0/1\">Ghassan Hamarneh</a>",
          "description": "Modern deep learning training procedures rely on model regularization\ntechniques such as data augmentation methods, which generate training samples\nthat increase the diversity of data and richness of label information. A\npopular recent method, mixup, uses convex combinations of pairs of original\nsamples to generate new samples. However, as we show in our experiments, mixup\ncan produce undesirable synthetic samples, where the data is sampled off the\nmanifold and can contain incorrect labels. We propose $\\zeta$-mixup, a\ngeneralization of mixup with provably and demonstrably desirable properties\nthat allows convex combinations of $N \\geq 2$ samples, leading to more\nrealistic and diverse outputs that incorporate information from $N$ original\nsamples by using a $p$-series interpolant. We show that, compared to mixup,\n$\\zeta$-mixup better preserves the intrinsic dimensionality of the original\ndatasets, which is a desirable property for training generalizable models.\nFurthermore, we show that our implementation of $\\zeta$-mixup is faster than\nmixup, and extensive evaluation on controlled synthetic and 24 real-world\nnatural and medical image classification datasets shows that $\\zeta$-mixup\noutperforms mixup and traditional data augmentation techniques.",
          "link": "http://arxiv.org/abs/2204.03323",
          "publishedOn": "2022-04-09T00:48:55.328Z",
          "wordCount": null,
          "title": "Multi-Sample $\\zeta$-mixup: Richer, More Realistic Synthetic Samples from a $p$-Series Interpolant. (arXiv:2204.03323v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Svendsen_D/0/1/0/all/0/1\">Daniel Heestermans Svendsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1\">Daniel Hern&#xe1;ndez-Lobato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martino_L/0/1/0/all/0/1\">Luca Martino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laparra_V/0/1/0/all/0/1\">Valero Laparra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreno_A/0/1/0/all/0/1\">Alvaro Moreno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camps_Valls_G/0/1/0/all/0/1\">Gustau Camps-Valls</a>",
          "description": "Earth observation from satellites offers the possibility to monitor our\nplanet with unprecedented accuracy. Radiative transfer models (RTMs) encode the\nenergy transfer through the atmosphere, and are used to model and understand\nthe Earth system, as well as to estimate the parameters that describe the\nstatus of the Earth from satellite observations by inverse modeling. However,\nperforming inference over such simulators is a challenging problem. RTMs are\nnonlinear, non-differentiable and computationally costly codes, which adds a\nhigh level of difficulty in inference. In this paper, we introduce two\ncomputational techniques to infer not only point estimates of biophysical\nparameters but also their joint distribution. One of them is based on a\nvariational autoencoder approach and the second one is based on a Monte Carlo\nExpectation Maximization (MCEM) scheme. We compare and discuss benefits and\ndrawbacks of each approach. We also provide numerical comparisons in synthetic\nsimulations and the real PROSAIL model, a popular RTM that combines land\nvegetation leaf and canopy modeling. We analyze the performance of the two\napproaches for modeling and inferring the distribution of three key biophysical\nparameters for quantifying the terrestrial biosphere.",
          "link": "http://arxiv.org/abs/2204.03346",
          "publishedOn": "2022-04-09T00:48:55.327Z",
          "wordCount": null,
          "title": "Inference over radiative transfer models using variational and expectation maximization methods. (arXiv:2204.03346v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leslie_D/0/1/0/all/0/1\">David Leslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briggs_M/0/1/0/all/0/1\">Morgan Briggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perini_A/0/1/0/all/0/1\">Antonella Perini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayadeva_S/0/1/0/all/0/1\">Smera Jayadeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rincon_C/0/1/0/all/0/1\">Cami Rinc&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raval_N/0/1/0/all/0/1\">Noopur Raval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birhane_A/0/1/0/all/0/1\">Abeba Birhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Powell_R/0/1/0/all/0/1\">Rosamund Powell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katell_M/0/1/0/all/0/1\">Michael Katell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aitken_M/0/1/0/all/0/1\">Mhairi Aitken</a>",
          "description": "The idea of \"data justice\" is of recent academic vintage. It has arisen over\nthe past decade in Anglo-European research institutions as an attempt to bring\ntogether a critique of the power dynamics that underlie accelerating trends of\ndatafication with a normative commitment to the principles of social justice-a\ncommitment to the achievement of a society that is equitable, fair, and capable\nof confronting the root causes of injustice.However, despite the seeming\nnovelty of such a data justice pedigree, this joining up of the critique of the\npower imbalances that have shaped the digital and \"big data\" revolutions with a\ncommitment to social equity and constructive societal transformation has a\ndeeper historical, and more geographically diverse, provenance. As the stories\nof the data justice initiatives, activism, and advocacy contained in this\nvolume well evidence, practices of data justice across the globe have, in fact,\nlargely preceded the elaboration and crystallisation of the idea of data\njustice in contemporary academic discourse. In telling these data justice\nstories, we hope to provide the reader with two interdependent tools of data\njustice thinking: First, we aim to provide the reader with the critical\nleverage needed to discern those distortions and malformations of data justice\nthat manifest in subtle and explicit forms of power, domination, and coercion.\nSecond, we aim to provide the reader with access to the historically effective\nforms of normativity and ethical insight that have been marshalled by data\njustice activists and advocates as tools of societal transformation-so that\nthese forms of normativity and insight can be drawn on, in turn, as\nconstructive resources to spur future transformative data justice practices.",
          "link": "http://arxiv.org/abs/2204.03100",
          "publishedOn": "2022-04-09T00:48:55.326Z",
          "wordCount": null,
          "title": "Data Justice Stories: A Repository of Case Studies. (arXiv:2204.03100v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03379",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ben_Simon_T/0/1/0/all/0/1\">Talia Ben-Simon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kreuk_F/0/1/0/all/0/1\">Felix Kreuk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Awwad_F/0/1/0/all/0/1\">Faten Awwad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cohen_J/0/1/0/all/0/1\">Jacob T. Cohen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Keshet_J/0/1/0/all/0/1\">Joseph Keshet</a>",
          "description": "Learning a new language involves constantly comparing speech productions with\nreference productions from the environment. Early in speech acquisition,\nchildren make articulatory adjustments to match their caregivers' speech.\nGrownup learners of a language tweak their speech to match the tutor reference.\nThis paper proposes a method to synthetically generate correct pronunciation\nfeedback given incorrect production. Furthermore, our aim is to generate the\ncorrected production while maintaining the speaker's original voice.\n\nThe system prompts the user to pronounce a phrase. The speech is recorded,\nand the samples associated with the inaccurate phoneme are masked with zeros.\nThis waveform serves as an input to a speech generator, implemented as a deep\nlearning inpainting system with a U-net architecture, and trained to output a\nreconstructed speech. The training set is composed of unimpaired proper speech\nexamples, and the generator is trained to reconstruct the original proper\nspeech. We evaluated the performance of our system on phoneme replacement of\nminimal pair words of English as well as on children with pronunciation\ndisorders. Results suggest that human listeners slightly prefer our generated\nspeech over a smoothed replacement of the inaccurate phoneme with a production\nof a different speaker.",
          "link": "http://arxiv.org/abs/2204.03379",
          "publishedOn": "2022-04-09T00:48:55.326Z",
          "wordCount": null,
          "title": "Correcting Misproducted Speech using Spectrogram Inpainting. (arXiv:2204.03379v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenge Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodrati_S/0/1/0/all/0/1\">Soroush Ghodrati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yazdanbakhsh_A/0/1/0/all/0/1\">Amir Yazdanbakhsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmaeilzadeh_H/0/1/0/all/0/1\">Hadi Esmaeilzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Mingu Kang</a>",
          "description": "Self-attention is a key enabler of state-of-art accuracy for various\ntransformer-based Natural Language Processing models. This attention mechanism\ncalculates a correlation score for each word with respect to the other words in\na sentence. Commonly, only a small subset of words highly correlates with the\nword under attention, which is only determined at runtime. As such, a\nsignificant amount of computation is inconsequential due to low attention\nscores and can potentially be pruned. The main challenge is finding the\nthreshold for the scores below which subsequent computation will be\ninconsequential. Although such a threshold is discrete, this paper formulates\nits search through a soft differentiable regularizer integrated into the loss\nfunction of the training. This formulation piggy backs on the back-propagation\ntraining to analytically co-optimize the threshold and the weights\nsimultaneously, striking a formally optimal balance between accuracy and\ncomputation pruning. To best utilize this mathematical innovation, we devise a\nbit-serial architecture, dubbed LeOPArd, for transformer language models with\nbit-level early termination microarchitectural mechanism. We evaluate our\ndesign across 43 back-end tasks for MemN2N, BERT, ALBERT, GPT-2, and Vision\ntransformer models. Post-layout results show that, on average, LeOPArd yields\n1.9x and 3.9x speedup and energy reduction, respectively, while keeping the\naverage accuracy virtually intact (<0.2% degradation)",
          "link": "http://arxiv.org/abs/2204.03227",
          "publishedOn": "2022-04-09T00:48:55.325Z",
          "wordCount": null,
          "title": "Accelerating Attention through Gradient-Based Learned Runtime Pruning. (arXiv:2204.03227v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jiyoung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jungin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_D/0/1/0/all/0/1\">Dongbo Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kwanghoon Sohn</a>",
          "description": "The rise of deep neural networks has led to several breakthroughs for\nsemantic segmentation. In spite of this, a model trained on source domain often\nfails to work properly in new challenging domains, that is directly concerned\nwith the generalization capability of the model. In this paper, we present a\nnovel memory-guided domain generalization method for semantic segmentation\nbased on meta-learning framework. Especially, our method abstracts the\nconceptual knowledge of semantic classes into categorical memory which is\nconstant beyond the domains. Upon the meta-learning concept, we repeatedly\ntrain memory-guided networks and simulate virtual test to 1) learn how to\nmemorize a domain-agnostic and distinct information of classes and 2) offer an\nexternally settled memory as a class-guidance to reduce the ambiguity of\nrepresentation in the test data of arbitrary unseen domain. To this end, we\nalso propose memory divergence and feature cohesion losses, which encourage to\nlearn memory reading and update processes for category-aware domain\ngeneralization. Extensive experiments for semantic segmentation demonstrate the\nsuperior generalization capability of our method over state-of-the-art works on\nvarious benchmarks.",
          "link": "http://arxiv.org/abs/2204.03609",
          "publishedOn": "2022-04-09T00:48:55.321Z",
          "wordCount": null,
          "title": "Pin the Memory: Learning to Generalize Semantic Segmentation. (arXiv:2204.03609v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tz-Ying Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_G/0/1/0/all/0/1\">Gurumurthy Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhizhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1\">Avinash Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_N/0/1/0/all/0/1\">Nuno Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhotika_R/0/1/0/all/0/1\">Rahul Bhotika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Class-incremental learning (CIL) has been widely studied under the setting of\nstarting from a small number of classes (base classes). Instead, we explore an\nunderstudied real-world setting of CIL that starts with a strong model\npre-trained on a large number of base classes. We hypothesize that a strong\nbase model can provide a good representation for novel classes and incremental\nlearning can be done with small adaptations. We propose a 2-stage training\nscheme, i) feature augmentation -- cloning part of the backbone and fine-tuning\nit on the novel data, and ii) fusion -- combining the base and novel\nclassifiers into a unified classifier. Experiments show that the proposed\nmethod significantly outperforms state-of-the-art CIL methods on the\nlarge-scale ImageNet dataset (e.g. +10% overall accuracy than the best). We\nalso propose and analyze understudied practical CIL scenarios, such as\nbase-novel overlap with distribution shift. Our proposed method is robust and\ngeneralizes to all analyzed CIL settings.",
          "link": "http://arxiv.org/abs/2204.03634",
          "publishedOn": "2022-04-09T00:48:55.317Z",
          "wordCount": null,
          "title": "Class-Incremental Learning with Strong Pre-trained Models. (arXiv:2204.03634v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.11048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhihua Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qianwen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1\">Yao Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengfei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>",
          "description": "Graph Neural Networks (GNNs) aim to extend deep learning techniques to graph\ndata and have achieved significant progress in graph analysis tasks (e.g., node\nclassification) in recent years. However, similar to other deep neural networks\nlike Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs),\nGNNs behave like a black box with their details hidden from model developers\nand users. It is therefore difficult to diagnose possible errors of GNNs.\nDespite many visual analytics studies being done on CNNs and RNNs, little\nresearch has addressed the challenges for GNNs. This paper fills the research\ngap with an interactive visual analysis tool, GNNLens, to assist model\ndevelopers and users in understanding and analyzing GNNs. Specifically,\nParallel Sets View and Projection View enable users to quickly identify and\nvalidate error patterns in the set of wrong predictions; Graph View and Feature\nMatrix View offer a detailed analysis of individual nodes to assist users in\nforming hypotheses about the error patterns. Since GNNs jointly model the graph\nstructure and the node features, we reveal the relative influences of the two\ntypes of information by comparing the predictions of three models: GNN,\nMulti-Layer Perceptron (MLP), and GNN Without Using Features (GNNWUF). Two case\nstudies and interviews with domain experts demonstrate the effectiveness of\nGNNLens in facilitating the understanding of GNN models and their errors.",
          "link": "http://arxiv.org/abs/2011.11048",
          "publishedOn": "2022-04-09T00:48:55.317Z",
          "wordCount": null,
          "title": "GNNLens: A Visual Analytics Approach for Prediction Error Diagnosis of Graph Neural Networks. (arXiv:2011.11048v6 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.05454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhenzhen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yuanlong Yu</a>",
          "description": "Feature selection is an important data preprocessing in data mining and\nmachine learning which can be used to reduce the feature dimension without\ndeteriorating model's performance. Since obtaining annotated data is laborious\nor even infeasible in many cases, unsupervised feature selection is more\npractical in reality. Though lots of methods for unsupervised feature selection\nhave been proposed, these methods select features independently, thus it is no\nguarantee that the group of selected features is optimal. What's more, the\nnumber of selected features must be tuned carefully to obtain a satisfactory\nresult. To tackle these problems, we propose a joint adaptive graph and\nstructured sparsity regularization unsupervised feature selection (JASFS)\nmethod in this paper, in which a $l_{2,0}$-norm regularization term with\nrespect to transformation matrix is imposed in the manifold learning for\nfeature selection, and a graph regularization term is incorporated into the\nlearning model to learn the local geometric structure of data adaptively. An\nefficient and simple iterative algorithm is designed to solve the proposed\noptimization problem with the analysis of computational complexity. After\noptimized, a subset of optimal features will be selected in group, and the\nnumber of selected features will be determined automatically. Experimental\nresults on eight benchmarks demonstrate the effectiveness and efficiency of the\nproposed method compared with several state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2010.05454",
          "publishedOn": "2022-04-09T00:48:55.315Z",
          "wordCount": null,
          "title": "Joint Adaptive Graph and Structured Sparsity Regularization for Unsupervised Feature Selection. (arXiv:2010.05454v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.01747",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Narain_S/0/1/0/all/0/1\">Sanjai Narain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mak_E/0/1/0/all/0/1\">Emily Mak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chee_D/0/1/0/all/0/1\">Dana Chee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Englot_B/0/1/0/all/0/1\">Brendan Englot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pochiraju_K/0/1/0/all/0/1\">Kishore Pochiraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1\">Niraj K. Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_K/0/1/0/all/0/1\">Karthik Narayan</a>",
          "description": "System design tools are often only available as input-output blackboxes: for\na given design as input they compute an output representing system behavior.\nBlackboxes are intended to be run in the forward direction. This paper presents\na new method of solving the inverse design problem namely, given requirements\nor constraints on output, find an input that also optimizes an objective\nfunction. This problem is challenging for several reasons. First, blackboxes\nare not designed to be run in reverse. Second, inputs and outputs can be\ndiscrete and continuous. Third, finding designs concurrently satisfying a set\nof requirements is hard because designs satisfying individual requirements may\nconflict with each other. Fourth, blackbox evaluations can be expensive.\nFinally, blackboxes can sometimes fail to produce an output. This paper\npresents CNMA, a new method of solving the inverse problem that overcomes these\nchallenges. CNMA tries to sample only the part of the design space relevant to\nsolving the problem, leveraging the power of neural networks, Mixed Integer\nLinear Programs, and a new learning-from-failure feedback loop. The paper also\npresents a parallel version of CNMA that improves the efficiency and quality of\nsolutions over the sequential version, and tries to steer it away from local\noptima. CNMA's performance is evaluated against conventional optimization\nmethods for seven nonlinear design problems of 8 (two problems), 10, 15, 36 and\n60 real-valued dimensions and one with 186 binary dimensions. Conventional\nmethods evaluated are off-the-shelf implementations of Bayesian Optimization\nwith Gaussian Processes, Nelder Mead and Random Search. The first two do not\nsolve problems that are high-dimensional, have discrete and continuous\nvariables or whose blackboxes can fail to return values. CNMA solves all\nproblems, and surpasses the performance of conventional methods by up to 87%.",
          "link": "http://arxiv.org/abs/2104.01747",
          "publishedOn": "2022-04-09T00:48:55.314Z",
          "wordCount": null,
          "title": "Fast Design Space Exploration of Nonlinear Systems: Part I. (arXiv:2104.01747v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03145",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saragadam_V/0/1/0/all/0/1\">Vishwanath Saragadam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Veeraraghavan_A/0/1/0/all/0/1\">Ashok Veeraraghavan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>",
          "description": "DeepTensor is a computationally efficient framework for low-rank\ndecomposition of matrices and tensors using deep generative networks. We\ndecompose a tensor as the product of low-rank tensor factors (e.g., a matrix as\nthe outer product of two vectors), where each low-rank tensor is generated by a\ndeep network (DN) that is trained in a self-supervised manner to minimize the\nmean-squared approximation error. Our key observation is that the implicit\nregularization inherent in DNs enables them to capture nonlinear signal\nstructures (e.g., manifolds) that are out of the reach of classical linear\nmethods like the singular value decomposition (SVD) and principal component\nanalysis (PCA). Furthermore, in contrast to the SVD and PCA, whose performance\ndeteriorates when the tensor's entries deviate from additive white Gaussian\nnoise, we demonstrate that the performance of DeepTensor is robust to a wide\nrange of distributions. We validate that DeepTensor is a robust and\ncomputationally efficient drop-in replacement for the SVD, PCA, nonnegative\nmatrix factorization (NMF), and similar decompositions by exploring a range of\nreal-world applications, including hyperspectral image denoising, 3D MRI\ntomography, and image classification. In particular, DeepTensor offers a 6dB\nsignal-to-noise ratio improvement over standard denoising methods for signals\ncorrupted by Poisson noise and learns to decompose 3D tensors 60 times faster\nthan a single DN equipped with 3D convolutions.",
          "link": "http://arxiv.org/abs/2204.03145",
          "publishedOn": "2022-04-09T00:48:55.313Z",
          "wordCount": null,
          "title": "DeepTensor: Low-Rank Tensor Decomposition with Deep Network Priors. (arXiv:2204.03145v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03305",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zezario_R/0/1/0/all/0/1\">Ryandhimas E. Zezario</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fuh_C/0/1/0/all/0/1\">Chiou-Shann Fuh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Improving the user's hearing ability to understand speech in noisy\nenvironments is critical to the development of hearing aid (HA) devices. For\nthis, it is important to derive a metric that can fairly predict speech\nintelligibility for HA users. A straightforward approach is to conduct a\nsubjective listening test and use the test results as an evaluation metric.\nHowever, conducting large-scale listening tests is time-consuming and\nexpensive. Therefore, several evaluation metrics were derived as surrogates for\nsubjective listening test results. In this study, we propose a multi-branched\nspeech intelligibility prediction model (MBI-Net), for predicting the\nsubjective intelligibility scores of HA users. MBI-Net consists of two branches\nof models, with each branch consisting of a hearing loss model, a cross-domain\nfeature extraction module, and a speech intelligibility prediction model, to\nprocess speech signals from one channel. The outputs of the two branches are\nfused through a linear layer to obtain predicted speech intelligibility scores.\nExperimental results confirm the effectiveness of MBI-Net, which produces\nhigher prediction scores than the baseline system in Track 1 and Track 2 on the\nClarity Prediction Challenge 2022 dataset.",
          "link": "http://arxiv.org/abs/2204.03305",
          "publishedOn": "2022-04-09T00:48:55.313Z",
          "wordCount": null,
          "title": "MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility Prediction Model for Hearing Aids. (arXiv:2204.03305v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.05861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hadi_M/0/1/0/all/0/1\">Mohammad Abdul Hadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fard_F/0/1/0/all/0/1\">Fatemeh H. Fard</a>",
          "description": "Context: Mobile app reviews written by users on app stores or social media\nare significant resources for app developers.Analyzing app reviews have proved\nto be useful for many areas of software engineering (e.g., requirement\nengineering, testing). Automatic classification of app reviews requires\nextensive efforts to manually curate a labeled dataset. When the classification\npurpose changes (e.g. identifying bugs versus usability issues or sentiment),\nnew datasets should be labeled, which prevents the extensibility of the\ndeveloped models for new desired classes/tasks in practice. Recent pre-trained\nneural language models (PTM) are trained on large corpora in an unsupervised\nmanner and have found success in solving similar Natural Language Processing\nproblems. However, the applicability of PTMs is not explored for app review\nclassification Objective: We investigate the benefits of PTMs for app review\nclassification compared to the existing models, as well as the transferability\nof PTMs in multiple settings. Method: We empirically study the accuracy and\ntime efficiency of PTMs compared to prior approaches using six datasets from\nliterature. In addition, we investigate the performance of the PTMs trained on\napp reviews (i.e. domain-specific PTMs) . We set up different studies to\nevaluate PTMs in multiple settings: binary vs. multi-class classification,\nzero-shot classification (when new labels are introduced to the model),\nmulti-task setting, and classification of reviews from different resources. The\ndatasets are manually labeled app review datasets from Google Play Store, Apple\nApp Store, and Twitter data. In all cases, Micro and Macro Precision, Recall,\nand F1-scores will be used and we will report the time required for training\nand prediction with the models.",
          "link": "http://arxiv.org/abs/2104.05861",
          "publishedOn": "2022-04-09T00:48:55.313Z",
          "wordCount": null,
          "title": "Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews. (arXiv:2104.05861v3 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2004.10888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shangtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "We present a mean-variance policy iteration (MVPI) framework for risk-averse\ncontrol in a discounted infinite horizon MDP optimizing the variance of a\nper-step reward random variable. MVPI enjoys great flexibility in that any\npolicy evaluation method and risk-neutral control method can be dropped in for\nrisk-averse control off the shelf, in both on- and off-policy settings. This\nflexibility reduces the gap between risk-neutral control and risk-averse\ncontrol and is achieved by working on a novel augmented MDP directly. We\npropose risk-averse TD3 as an example instantiating MVPI, which outperforms\nvanilla TD3 and many previous risk-averse control methods in challenging Mujoco\nrobot simulation tasks under a risk-aware performance metric. This risk-averse\nTD3 is the first to introduce deterministic policies and off-policy learning\ninto risk-averse reinforcement learning, both of which are key to the\nperformance boost we show in Mujoco domains.",
          "link": "http://arxiv.org/abs/2004.10888",
          "publishedOn": "2022-04-09T00:48:55.312Z",
          "wordCount": null,
          "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning. (arXiv:2004.10888v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.09745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1\">Sivakanth Gopi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulhane_P/0/1/0/all/0/1\">Pankaj Gulhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1\">Janardhan Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Judy Hanwen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yekhanin_S/0/1/0/all/0/1\">Sergey Yekhanin</a>",
          "description": "We study the basic operation of set union in the global model of differential\nprivacy. In this problem, we are given a universe $U$ of items, possibly of\ninfinite size, and a database $D$ of users. Each user $i$ contributes a subset\n$W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially\nprivate algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the\nsize of $S$ is as large as possible. The problem arises in countless real world\napplications; it is particularly ubiquitous in natural language processing\n(NLP) applications as vocabulary extraction. For example, discovering words,\nsentences, $n$-grams etc., from private text data belonging to users is an\ninstance of the set union problem.\n\nKnown algorithms for this problem proceed by collecting a subset of items\nfrom each user, taking the union of such subsets, and disclosing the items\nwhose noisy counts fall above a certain threshold. Crucially, in the above\nprocess, the contribution of each individual user is always independent of the\nitems held by other users, resulting in a wasteful aggregation process, where\nsome item counts happen to be way above the threshold. We deviate from the\nabove paradigm by allowing users to contribute their items in a\n$\\textit{dependent fashion}$, guided by a $\\textit{policy}$. In this new\nsetting ensuring privacy is significantly delicate. We prove that any policy\nwhich has certain $\\textit{contractive}$ properties would result in a\ndifferentially private algorithm. We design two new algorithms, one using\nLaplace noise and other Gaussian noise, as specific instances of policies\nsatisfying the contractive properties. Our experiments show that the new\nalgorithms significantly outperform previously known mechanisms for the\nproblem.",
          "link": "http://arxiv.org/abs/2002.09745",
          "publishedOn": "2022-04-09T00:48:55.311Z",
          "wordCount": null,
          "title": "Differentially Private Set Union. (arXiv:2002.09745v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jelcicova_Z/0/1/0/all/0/1\">Zuzana Jel&#x10d;icov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verhelst_M/0/1/0/all/0/1\">Marian Verhelst</a>",
          "description": "Multi-head self-attention forms the core of Transformer networks. However,\ntheir quadratically growing complexity with respect to the input sequence\nlength impedes their deployment on resource-constrained edge devices. We\naddress this challenge by proposing a dynamic pruning method, which exploits\nthe temporal stability of data across tokens to reduce inference cost. The\nthreshold-based method only retains significant differences between the\nsubsequent tokens, effectively reducing the number of multiply-accumulates, as\nwell as the internal tensor data sizes. The approach is evaluated on the Google\nSpeech Commands Dataset for keyword spotting, and the performance is compared\nagainst the baseline Keyword Transformer. Our experiments show that we can\nreduce ~80% of operations while maintaining the original 98.4% accuracy.\nMoreover, a reduction of ~87-94% operations can be achieved when only degrading\nthe accuracy by 1-4%, speeding up the multi-head self-attention inference by a\nfactor of ~7.5-16.",
          "link": "http://arxiv.org/abs/2204.03479",
          "publishedOn": "2022-04-09T00:48:55.309Z",
          "wordCount": null,
          "title": "Delta Keyword Transformer: Bringing Transformers to the Edge through Dynamically Pruned Multi-Head Self-Attention. (arXiv:2204.03479v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.08850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zimmermann_R/0/1/0/all/0/1\">Roland S. Zimmermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_S/0/1/0/all/0/1\">Steffen Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1\">Matthias Bethge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>",
          "description": "Contrastive learning has recently seen tremendous success in self-supervised\nlearning. So far, however, it is largely unclear why the learned\nrepresentations generalize so effectively to a large variety of downstream\ntasks. We here prove that feedforward models trained with objectives belonging\nto the commonly used InfoNCE family learn to implicitly invert the underlying\ngenerative model of the observed data. While the proofs make certain\nstatistical assumptions about the generative model, we observe empirically that\nour findings hold even if these assumptions are severely violated. Our theory\nhighlights a fundamental connection between contrastive learning, generative\nmodeling, and nonlinear independent component analysis, thereby furthering our\nunderstanding of the learned representations as well as providing a theoretical\nfoundation to derive more effective contrastive losses.",
          "link": "http://arxiv.org/abs/2102.08850",
          "publishedOn": "2022-04-09T00:48:55.309Z",
          "wordCount": null,
          "title": "Contrastive Learning Inverts the Data Generating Process. (arXiv:2102.08850v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.00135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_G/0/1/0/all/0/1\">Guanghui Lan</a>",
          "description": "We present new policy mirror descent (PMD) methods for solving reinforcement\nlearning (RL) problems with either strongly convex or general convex\nregularizers. By exploring the structural properties of these overall highly\nnonconvex problems we show that the PMD methods exhibit fast linear rate of\nconvergence to the global optimality. We develop stochastic counterparts of\nthese methods, and establish an ${\\cal O}(1/\\epsilon)$ (resp., ${\\cal\nO}(1/\\epsilon^2)$) sampling complexity for solving these RL problems with\nstrongly (resp., general) convex regularizers using different sampling schemes,\nwhere $\\epsilon$ denote the target accuracy. We further show that the\ncomplexity for computing the gradients of these regularizers, if necessary, can\nbe bounded by ${\\cal O}\\{(\\log_\\gamma \\epsilon) [(1-\\gamma)L/\\mu]^{1/2}\\log\n(1/\\epsilon)\\}$ (resp., ${\\cal O} \\{(\\log_\\gamma \\epsilon )\n(L/\\epsilon)^{1/2}\\}$)for problems with strongly (resp., general) convex\nregularizers. Here $\\gamma$ denotes the discounting factor. To the best of our\nknowledge, these complexity bounds, along with our algorithmic developments,\nappear to be new in both optimization and RL literature. The introduction of\nthese convex regularizers also greatly expands the flexibility and\napplicability of RL models.",
          "link": "http://arxiv.org/abs/2102.00135",
          "publishedOn": "2022-04-09T00:48:55.308Z",
          "wordCount": null,
          "title": "Policy Mirror Descent for Reinforcement Learning: Linear Convergence, New Sampling Complexity, and Generalized Problem Classes. (arXiv:2102.00135v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03503",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haller_S/0/1/0/all/0/1\">Stefan Haller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aldea_A/0/1/0/all/0/1\">Adina Aldea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seifert_C/0/1/0/all/0/1\">Christin Seifert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strisciuglio_N/0/1/0/all/0/1\">Nicola Strisciuglio</a>",
          "description": "Automated short answer grading (ASAG) has gained attention in education as a\nmeans to scale educational tasks to the growing number of students. Recent\nprogress in Natural Language Processing and Machine Learning has largely\ninfluenced the field of ASAG, of which we survey the recent research\nadvancements. We complement previous surveys by providing a comprehensive\nanalysis of recently published methods that deploy deep learning approaches. In\nparticular, we focus our analysis on the transition from hand engineered\nfeatures to representation learning approaches, which learn representative\nfeatures for the task at hand automatically from large corpora of data. We\nstructure our analysis of deep learning methods along three categories: word\nembeddings, sequential models, and attention-based methods. Deep learning\nimpacted ASAG differently than other fields of NLP, as we noticed that the\nlearned representations alone do not contribute to achieve the best results,\nbut they rather show to work in a complementary way with hand-engineered\nfeatures. The best performance are indeed achieved by methods that combine the\ncarefully hand-engineered features with the power of the semantic descriptions\nprovided by the latest models, like transformers architectures. We identify\nchallenges and provide an outlook on research direction that can be addressed\nin the future",
          "link": "http://arxiv.org/abs/2204.03503",
          "publishedOn": "2022-04-09T00:48:55.306Z",
          "wordCount": null,
          "title": "Survey on Automated Short Answer Grading with Deep Learning: from Word Embeddings to Transformers. (arXiv:2204.03503v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.03081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadeghi_D/0/1/0/all/0/1\">Delaram Sadeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeibi_A/0/1/0/all/0/1\">Afshin Shoeibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_N/0/1/0/all/0/1\">Navid Ghassemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moridian_P/0/1/0/all/0/1\">Parisa Moridian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadem_A/0/1/0/all/0/1\">Ali Khadem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1\">Roohallah Alizadehsani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teshnehlab_M/0/1/0/all/0/1\">Mohammad Teshnehlab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorriz_J/0/1/0/all/0/1\">J. Manuel Gorriz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khozeimeh_F/0/1/0/all/0/1\">Fahime Khozeimeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu-Dong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1\">Saeid Nahavandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_U/0/1/0/all/0/1\">U Rajendra Acharya</a>",
          "description": "Schizophrenia (SZ) is a mental disorder that typically emerges in late\nadolescence or early adulthood. It reduces the life expectancy of patients by\n15 years. Abnormal behavior, perception of emotions, social relationships, and\nreality perception are among its most significant symptoms. Past studies have\nrevealed the temporal and anterior lobes of hippocampus regions of brain get\naffected by SZ. Also, increased volume of cerebrospinal fluid (CSF) and\ndecreased volume of white and gray matter can be observed due to this disease.\nThe magnetic resonance imaging (MRI) is the popular neuroimaging technique used\nto explore structural/functional brain abnormalities in SZ disorder owing to\nits high spatial resolution. Various artificial intelligence (AI) techniques\nhave been employed with advanced image/signal processing methods to obtain\naccurate diagnosis of SZ. This paper presents a comprehensive overview of\nstudies conducted on automated diagnosis of SZ using MRI modalities. Main\nfindings, various challenges, and future works in developing the automated SZ\ndetection are described in this paper.",
          "link": "http://arxiv.org/abs/2103.03081",
          "publishedOn": "2022-04-09T00:48:55.306Z",
          "wordCount": null,
          "title": "An Overview on Artificial Intelligence Techniques for Diagnosis of Schizophrenia Based on Magnetic Resonance Imaging Modalities: Methods, Challenges, and Future Works. (arXiv:2103.03081v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengchuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Bin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Ce Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "Visual recognition is recently learned via either supervised learning on\nhuman-annotated image-label data or language-image contrastive learning with\nwebly-crawled image-text pairs. While supervised learning may result in a more\ndiscriminative representation, language-image pretraining shows unprecedented\nzero-shot recognition capability, largely due to the different properties of\ndata sources and learning objectives. In this work, we introduce a new\nformulation by combining the two data sources into a common image-text-label\nspace. In this space, we propose a new learning paradigm, called Unified\nContrastive Learning (UniCL) with a single learning objective to seamlessly\nprompt the synergy of two data types. Extensive experiments show that our UniCL\nis an effective way of learning semantically rich yet discriminative\nrepresentations, universally for image recognition in zero-shot, linear-probe,\nfully finetuning and transfer learning scenarios. Particularly, it attains\ngains up to 9.2% and 14.5% in average on zero-shot recognition benchmarks over\nthe language-image contrastive learning and supervised learning methods,\nrespectively. In linear probe setting, it also boosts the performance over the\ntwo methods by 7.3% and 3.4%, respectively. Our study also indicates that UniCL\nstand-alone is a good learner on pure image-label data, rivaling the supervised\nlearning methods across three image classification datasets and two types of\nvision backbones, ResNet and Swin Transformer. Code is available at\nhttps://github.com/microsoft/UniCL.",
          "link": "http://arxiv.org/abs/2204.03610",
          "publishedOn": "2022-04-09T00:48:55.305Z",
          "wordCount": null,
          "title": "Unified Contrastive Learning in Image-Text-Label Space. (arXiv:2204.03610v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03572",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rocha_K/0/1/0/all/0/1\">Karoline da Rocha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bermudez_J/0/1/0/all/0/1\">Jos&#xe9; C. M. Bermudez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rivero_E/0/1/0/all/0/1\">Elena R. C. Rivero</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Costa_M/0/1/0/all/0/1\">M&#xe1;rcio H. Costa</a>",
          "description": "The Epithelial Dysplasia (ED) is a tissue alteration commonly present in\nlesions preceding oral cancer, being its presence one of the most important\nfactors in the progression toward carcinoma. This study proposes a method to\ndesign a low computational cost classification system to support the detection\nof dysplastic epithelia, contributing to reduce the variability of pathologist\nassessments. We employ a multilayer artificial neural network (MLP-ANN) and\ndefining the regions of the epithelium to be assessed based on the knowledge of\nthe pathologist. The performance of the proposed solution was statistically\nevaluated. The implemented MLP-ANN presented an average accuracy of 87%, with a\nvariability much inferior to that obtained from three trained evaluators.\nMoreover, the proposed solution led to results which are very close to those\nobtained using a convolutional neural network (CNN) implemented by transfer\nlearning, with 100 times less computational complexity. In conclusion, our\nresults show that a simple neural network structure can lead to a performance\nequivalent to that of much more complex structures, which are routinely used in\nthe literature.",
          "link": "http://arxiv.org/abs/2204.03572",
          "publishedOn": "2022-04-09T00:48:55.304Z",
          "wordCount": null,
          "title": "A Pathology-Based Machine Learning Method to Assist in Epithelial Dysplasia Diagnosis. (arXiv:2204.03572v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yeh_R/0/1/0/all/0/1\">Raymond A. Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yuan-Ting Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasegawa_Johnson_M/0/1/0/all/0/1\">Mark Hasegawa-Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1\">Alexander G. Schwing</a>",
          "description": "Designing equivariance as an inductive bias into deep-nets has been a\nprominent approach to build effective models, e.g., a convolutional neural\nnetwork incorporates translation equivariance. However, incorporating these\ninductive biases requires knowledge about the equivariance properties of the\ndata, which may not be available, e.g., when encountering a new domain. To\naddress this, we study how to discover interpretable equivariances from data.\nSpecifically, we formulate this discovery process as an optimization problem\nover a model's parameter-sharing schemes. We propose to use the partition\ndistance to empirically quantify the accuracy of the recovered equivariance.\nAlso, we theoretically analyze the method for Gaussian data and provide a bound\non the mean squared gap between the studied discovery scheme and the oracle\nscheme. Empirically, we show that the approach recovers known equivariances,\nsuch as permutations and shifts, on sum of numbers and spatially-invariant\ndata.",
          "link": "http://arxiv.org/abs/2204.03640",
          "publishedOn": "2022-04-09T00:48:55.304Z",
          "wordCount": null,
          "title": "Equivariance Discovery by Learned Parameter-Sharing. (arXiv:2204.03640v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.02601",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lock_E/0/1/0/all/0/1\">Eric F. Lock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_J/0/1/0/all/0/1\">Jun Young Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hoadley_K/0/1/0/all/0/1\">Katherine A. Hoadley</a>",
          "description": "Several modern applications require the integration of multiple large data\nmatrices that have shared rows and/or columns. For example, cancer studies that\nintegrate multiple omics platforms across multiple types of cancer, pan-omics\npan-cancer analysis, have extended our knowledge of molecular heterogenity\nbeyond what was observed in single tumor and single platform studies. However,\nthese studies have been limited by available statistical methodology. We\npropose a flexible approach to the simultaneous factorization and decomposition\nof variation across such bidimensionally linked matrices, BIDIFAC+. This\ndecomposes variation into a series of low-rank components that may be shared\nacross any number of row sets (e.g., omics platforms) or column sets (e.g.,\ncancer types). This builds on a growing literature for the factorization and\ndecomposition of linked matrices, which has primarily focused on multiple\nmatrices that are linked in one dimension (rows or columns) only. Our objective\nfunction extends nuclear norm penalization, is motivated by random matrix\ntheory, gives an identifiable decomposition under relatively mild conditions,\nand can be shown to give the mode of a Bayesian posterior distribution. We\napply BIDIFAC+ to pan-omics pan-cancer data from TCGA, identifying shared and\nspecific modes of variability across 4 different omics platforms and 29\ndifferent cancer types.",
          "link": "http://arxiv.org/abs/2002.02601",
          "publishedOn": "2022-04-09T00:48:55.304Z",
          "wordCount": null,
          "title": "Bidimensional linked matrix factorization for pan-omics pan-cancer analysis. (arXiv:2002.02601v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1\">Shounak Datta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mullick_S/0/1/0/all/0/1\">Sankha Subhra Mullick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Swagatam Das</a>",
          "description": "Few-shot learning aims to transfer the knowledge acquired from training on a\ndiverse set of tasks, from a given task distribution, to generalize to unseen\ntasks, from the same distribution, with a limited amount of labeled data. The\nunderlying requirement for effective few-shot generalization is to learn a good\nrepresentation of the task manifold. One way to encourage this is to preserve\nlocal neighborhoods in the feature space learned by the few-shot learner. To\nthis end, we introduce the notion of interval bounds from the provably robust\ntraining literature to few-shot learning. The interval bounds are used to\ncharacterize neighborhoods around the training tasks. These neighborhoods can\nthen be preserved by minimizing the distance between a task and its respective\nbounds. We further introduce a novel strategy to artificially form new tasks\nfor training by interpolating between the available tasks and their respective\ninterval bounds, to aid in cases with a scarcity of tasks. We apply our\nframework to both model-agnostic meta-learning as well as prototype-based\nmetric-learning paradigms. The efficacy of our proposed approach is evident\nfrom the improved performance on several datasets from diverse domains in\ncomparison to a sizable number of recent competitors.",
          "link": "http://arxiv.org/abs/2204.03511",
          "publishedOn": "2022-04-09T00:48:55.303Z",
          "wordCount": null,
          "title": "Interval Bound Propagation--aided Few-shot Learning. (arXiv:2204.03511v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03573",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tiwari_S/0/1/0/all/0/1\">Sadhana Tiwari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>",
          "description": "Stress, anxiety, and nervousness are all high-risk health states in everyday\nlife. Previously, stress levels were determined by speaking with people and\ngaining insight into what they had experienced recently or in the past.\nTypically, stress is caused by an incidence that occurred a long time ago, but\nsometimes it is triggered by unknown factors. This is a challenging and complex\ntask, but recent research advances have provided numerous opportunities to\nautomate it. The fundamental features of most of these techniques are electro\ndermal activity (EDA) and heart rate values (HRV). We utilized an accelerometer\nto measure body motions to solve this challenge. The proposed novel method\nemploys a test that measures a subject's electrocardiogram (ECG), galvanic skin\nvalues (GSV), HRV values, and body movements in order to provide a low-cost and\ntime-saving solution for detecting stress lifestyle disease in modern times\nusing cyber physical systems. This study provides a new hybrid model for\nlifestyle disease classification that decreases execution time while picking\nthe best collection of characteristics and increases classification accuracy.\nThe developed approach is capable of dealing with the class imbalance problem\nby using WESAD (wearable stress and affect dataset) dataset. The new model uses\nthe Grid search (GS) method to select an optimized set of hyper parameters, and\nit uses a combination of the Correlation coefficient based Recursive feature\nelimination (CoC-RFE) method for optimal feature selection and gradient\nboosting as an estimator to classify the dataset, which achieves high accuracy\nand helps to provide smart, accurate, and high-quality healthcare systems. To\ndemonstrate the validity and utility of the proposed methodology, its\nperformance is compared to those of other well-established machine learning\nmodels.",
          "link": "http://arxiv.org/abs/2204.03573",
          "publishedOn": "2022-04-09T00:48:55.303Z",
          "wordCount": null,
          "title": "An optimized hybrid solution for IoT based lifestyle disease classification using stress data. (arXiv:2204.03573v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.07401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bai Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qiaomin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modiano_E/0/1/0/all/0/1\">Eytan Modiano</a>",
          "description": "With the rapid advance of information technology, network systems have become\nincreasingly complex and hence the underlying system dynamics are often unknown\nor difficult to characterize. Finding a good network control policy is of\nsignificant importance to achieve desirable network performance (e.g., high\nthroughput or low delay). In this work, we consider using model-based\nreinforcement learning (RL) to learn the optimal control policy for queueing\nnetworks so that the average job delay (or equivalently the average queue\nbacklog) is minimized. Traditional approaches in RL, however, cannot handle the\nunbounded state spaces of the network control problem. To overcome this\ndifficulty, we propose a new algorithm, called Reinforcement Learning for\nQueueing Networks (RL-QN), which applies model-based RL methods over a finite\nsubset of the state space, while applying a known stabilizing policy for the\nrest of the states. We establish that the average queue backlog under RL-QN\nwith an appropriately constructed subset can be arbitrarily close to the\noptimal result. We evaluate RL-QN in dynamic server allocation, routing and\nswitching problems. Simulation results show that RL-QN minimizes the average\nqueue backlog effectively.",
          "link": "http://arxiv.org/abs/2011.07401",
          "publishedOn": "2022-04-09T00:48:55.303Z",
          "wordCount": null,
          "title": "RL-QN: A Reinforcement Learning Framework for Optimal Control of Queueing Systems. (arXiv:2011.07401v2 [cs.PF] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abaho_M/0/1/0/all/0/1\">M. Abaho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollegala_D/0/1/0/all/0/1\">D. Bollegala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williamson_P/0/1/0/all/0/1\">P. Williamson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodd_S/0/1/0/all/0/1\">S. Dodd</a>",
          "description": "Probing Pre-trained Language Models (PLMs) using prompts has indirectly\nimplied that language models (LMs) can be treated as knowledge bases. To this\nend, this phenomena has been effective especially when these LMs are fine-tuned\ntowards not just data of a specific domain, but also to the style or linguistic\npattern of the prompts themselves. We observe that, satisfying a particular\nlinguistic pattern in prompts is an unsustainable constraint that unnecessarily\nlengthens the probing task, especially because, they are often manually\ndesigned and the range of possible prompt template patterns can vary depending\non the prompting objective and domain. We therefore explore an idea of using a\nposition-attention mechanism to capture positional information of each word in\na prompt relative to the mask to be filled, hence avoiding the need to\nre-construct prompts when the prompts linguistic pattern changes. Using our\napproach, we demonstrate the ability of eliciting answers to rare prompt\ntemplates (in a case study on health outcome generation) such as Postfix and\nMixed patterns whose missing information is respectively at the start and in\nmultiple random places of the prompt. More so, using various biomedical PLMs,\nour approach consistently outperforms a baseline in which the default mask\nlanguage model (MLM) representation is used to predict masked tokens.",
          "link": "http://arxiv.org/abs/2204.03489",
          "publishedOn": "2022-04-09T00:48:55.302Z",
          "wordCount": null,
          "title": "Position-based Prompting for Health Outcome Generation. (arXiv:2204.03489v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Songlin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "Second-order semantic parsing with end-to-end mean-field inference has been\nshown good performance. In this work we aim to improve this method by modeling\nlabel correlations between adjacent arcs. However, direct modeling leads to\nmemory explosion because second-order score tensors have sizes of $O(n^3L^2)$\n($n$ is the sentence length and $L$ is the number of labels), which is not\naffordable. To tackle this computational challenge, we leverage tensor\ndecomposition techniques, and interestingly, we show that the large\nsecond-order score tensors have no need to be materialized during mean-field\ninference, thereby reducing the computational complexity from cubic to\nquadratic. We conduct experiments on SemEval 2015 Task 18 English datasets,\nshowing the effectiveness of modeling label correlations. Our code is publicly\navailable at https://github.com/sustcsonglin/mean-field-dep-parsing.",
          "link": "http://arxiv.org/abs/2204.03619",
          "publishedOn": "2022-04-09T00:48:55.302Z",
          "wordCount": null,
          "title": "Modeling Label Correlations for Second-Order Semantic Dependency Parsing with Mean-Field Inference. (arXiv:2204.03619v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tingting Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Siyao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jie Liu</a>",
          "description": "As an emerging technology, federated learning (FL) involves training machine\nlearning models over distributed edge devices, which attracts sustained\nattention and has been extensively studied. However, the heterogeneity of\nclient data severely degrades the performance of FL compared with that in\ncentralized training. It causes the locally trained models of clients to move\nin different directions. On the one hand, it slows down or even stalls the\nglobal updates, leading to inefficient communication. On the other hand, it\nenlarges the distances between local models, resulting in an aggregated global\nmodel with poor performance. Fortunately, these shortcomings can be mitigated\nby reducing the angle between the directions that local models move in. Based\non this fact, we propose FedCos, which reduces the directional inconsistency of\nlocal models by introducing a cosine-similarity penalty. It promotes the local\nmodel iterations towards an auxiliary global direction. Moreover, our approach\nis auto-adapt to various non-IID settings without an elaborate selection of\nhyperparameters. The experimental results show that FedCos outperforms the\nwell-known baselines and can enhance them under a variety of FL scenes,\nincluding varying degrees of data heterogeneity, different number of\nparticipants, and cross-silo and cross-device settings. Besides, FedCos\nimproves communication efficiency by 2 to 5 times. With the help of FedCos,\nmultiple FL methods require significantly fewer communication rounds than\nbefore to obtain a model with comparable performance.",
          "link": "http://arxiv.org/abs/2204.03174",
          "publishedOn": "2022-04-09T00:48:55.301Z",
          "wordCount": null,
          "title": "FedCos: A Scene-adaptive Federated Optimization Enhancement for Performance Improvement. (arXiv:2204.03174v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.08676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Yixin Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "We introduce distributed NLI, a new NLU task with a goal to predict the\ndistribution of human judgements for natural language inference. We show that\nby applying additional distribution estimation methods, namely, Monte Carlo\n(MC) Dropout, Deep Ensemble, Re-Calibration, and Distribution Distillation,\nmodels can capture human judgement distribution more effectively than the\nsoftmax baseline. We show that MC Dropout is able to achieve decent performance\nwithout any distribution annotations while Re-Calibration can give further\nimprovements with extra distribution annotations, suggesting the value of\nmultiple annotations for one example in modeling the distribution of human\njudgements. Despite these improvements, the best results are still far below\nthe estimated human upper-bound, indicating that predicting the distribution of\nhuman judgements is still an open, challenging problem with a large room for\nimprovements. We showcase the common errors for MC Dropout and Re-Calibration.\nFinally, we give guidelines on the usage of these methods with different levels\nof data availability and encourage future work on modeling the human opinion\ndistribution for language reasoning. Our code and data are publicly available\nat https://github.com/easonnie/ChaosNLI",
          "link": "http://arxiv.org/abs/2104.08676",
          "publishedOn": "2022-04-09T00:48:55.301Z",
          "wordCount": null,
          "title": "Distributed NLI: Learning to Predict Human Opinion Distributions for Language Reasoning. (arXiv:2104.08676v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barkhof_C/0/1/0/all/0/1\">Claartje Barkhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1\">Wilker Aziz</a>",
          "description": "We propose a framework for the statistical evaluation of variational\nauto-encoders (VAEs) and test two instances of this framework in the context of\nmodelling images of handwritten digits and a corpus of English text. Our take\non evaluation is based on the idea of statistical model criticism, popular in\nBayesian data analysis, whereby a statistical model is evaluated in terms of\nits ability to reproduce statistics of an unknown data generating process from\nwhich we can obtain samples. A VAE learns not one, but two joint distributions\nover a shared sample space, each exploiting a choice of factorisation that\nmakes sampling tractable in one of two directions (latent-to-data,\ndata-to-latent). We evaluate samples from these distributions, assessing their\n(marginal) fit to the observed data and our choice of prior, and we also\nevaluate samples through a pipeline that connects the two distributions\nstarting from a data sample, assessing whether together they exploit and reveal\nlatent factors of variation that are useful to a practitioner. We show that\nthis methodology offers possibilities for model selection qualitatively beyond\nintrinsic evaluation metrics and at a finer granularity than commonly used\nstatistics can offer.",
          "link": "http://arxiv.org/abs/2204.03030",
          "publishedOn": "2022-04-09T00:48:55.300Z",
          "wordCount": null,
          "title": "Statistical Model Criticism of Variational Auto-Encoders. (arXiv:2204.03030v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bazzan_A/0/1/0/all/0/1\">Ana L. C. Bazzan</a>",
          "description": "As the demand for mobility in our society seems to increase, the various\nissues centered on urban mobility are among those that worry most city\ninhabitants in this planet. For instance, how to go from A to B in an efficient\n(but also less stressful) way? These questions and concerns have not changed\neven during the covid-19 pandemic; on the contrary, as the current stand,\npeople who are avoiding public transportation are only contributing to an\nincrease in the vehicular traffic. The are of intelligent transportation\nsystems (ITS) aims at investigating how to employ information and communication\ntechnologies to problems related to transportation. This may mean monitoring\nand managing the infrastructure (e.g., traffic roads, traffic signals, etc.).\nHowever, currently, ITS is also targeting the management of demand. In this\npanorama, artificial intelligence plays an important role, especially with the\nadvances in machine learning that translates in the use of computational\nvision, connected and autonomous vehicles, agent-based simulation, among\nothers. In the present work, a survey of several works developed by our group\nare discussed in a holistic perspective, i.e., they cover not only the supply\nside (as commonly found in ITS works), but also the demand side, and, in an\nnovel perspective, the integration of both.",
          "link": "http://arxiv.org/abs/2204.03570",
          "publishedOn": "2022-04-09T00:48:55.300Z",
          "wordCount": null,
          "title": "Improving Urban Mobility: using artificial intelligence and new technologies to connect supply and demand. (arXiv:2204.03570v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shaowu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunton_S/0/1/0/all/0/1\">Steven L. Brunton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1\">J. Nathan Kutz</a>",
          "description": "High-dimensional spatio-temporal dynamics can often be encoded in a\nlow-dimensional subspace. Engineering applications for modeling,\ncharacterization, design, and control of such large-scale systems often rely on\ndimensionality reduction to make solutions computationally tractable in\nreal-time. Common existing paradigms for dimensionality reduction include\nlinear methods, such as the singular value decomposition (SVD), and nonlinear\nmethods, such as variants of convolutional autoencoders (CAE). However, these\nencoding techniques lack the ability to efficiently represent the complexity\nassociated with spatio-temporal data, which often requires variable geometry,\nnon-uniform grid resolution, adaptive meshing, and/or parametric\ndependencies.To resolve these practical engineering challenges, we propose a\ngeneral framework called Neural Implicit Flow (NIF) that enables a\nmesh-agnostic, low-rank representation of large-scale, parametric,\nspatial-temporal data. NIF consists of two modified multilayer perceptrons\n(MLPs): (i) ShapeNet, which isolates and represents the spatial complexity, and\n(ii) ParameterNet, which accounts for any other input complexity, including\nparametric dependencies, time, and sensor measurements. We demonstrate the\nutility of NIF for parametric surrogate modeling, enabling the interpretable\nrepresentation and compression of complex spatio-temporal dynamics, efficient\nmany-spatial-query tasks, and improved generalization performance for sparse\nreconstruction.",
          "link": "http://arxiv.org/abs/2204.03216",
          "publishedOn": "2022-04-09T00:48:55.299Z",
          "wordCount": null,
          "title": "Neural Implicit Flow: a mesh-agnostic dimensionality reduction paradigm of spatio-temporal data. (arXiv:2204.03216v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1\">Tal Ridnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawen_H/0/1/0/all/0/1\">Hussam Lawen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1\">Emanuel Ben-Baruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1\">Asaf Noy</a>",
          "description": "ImageNet serves as the primary dataset for evaluating the quality of\ncomputer-vision models. The common practice today is training each architecture\nwith a tailor-made scheme, designed and tuned by an expert. In this paper, we\npresent a unified scheme for training any backbone on ImageNet. The scheme,\nnamed USI (Unified Scheme for ImageNet), is based on knowledge distillation and\nmodern tricks. It requires no adjustments or hyper-parameters tuning between\ndifferent models, and is efficient in terms of training times. We test USI on a\nwide variety of architectures, including CNNs, Transformers, Mobile-oriented\nand MLP-only. On all models tested, USI outperforms previous state-of-the-art\nresults. Hence, we are able to transform training on ImageNet from an\nexpert-oriented task to an automatic seamless routine. Since USI accepts any\nbackbone and trains it to top results, it also enables to perform methodical\ncomparisons, and identify the most efficient backbones along the speed-accuracy\nPareto curve. Implementation is available\nat:https://github.com/Alibaba-MIIL/Solving_ImageNet",
          "link": "http://arxiv.org/abs/2204.03475",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results. (arXiv:2204.03475v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chau_R/0/1/0/all/0/1\">Rodrigo Chau</a>",
          "description": "We investigate the \"Visual Pushing for Grasping\" (VPG) system by Zeng et al.\nand the \"Hourglass\" system by Ewerton et al., an evolution of the former. The\nfocus of our work is the investigation of the capabilities of both systems to\nlearn long-term rewards and policies. Zeng et al. original task only needs a\nlimited amount of foresight. Ewerton et al. attain their best performance using\nan agent which only takes the most immediate action under consideration. We are\ninterested in the ability of their models and training algorithms to accurately\npredict long-term Q-Values. To evaluate this ability, we design a new bin\nsorting task and reward function. Our task requires agents to accurately\nestimate future rewards and therefore use high discount factors in their\nQ-Value calculation. We investigate the behaviour of an adaptation of the VPG\ntraining algorithm on our task. We show that this adaptation can not accurately\npredict the required long-term action sequences. In addition to the limitations\nidentified by Ewerton et al., it suffers from the known Deep Q-Learning problem\nof overestimated Q-Values. In an effort to solve our task, we turn to the\nHourglass models and combine them with the Double Q-Learning approach. We show\nthat this approach enables the models to accurately predict long-term action\nsequences when trained with large discount factors. Our results show that the\nDouble Q-Learning technique is essential for training with very high discount\nfactors, as the models Q-Value predictions diverge otherwise. We also\nexperiment with different approaches for discount factor scheduling, loss\ncalculation and exploration procedures. Our results show that the latter\nfactors do not visibly influence the model's performance for our task.",
          "link": "http://arxiv.org/abs/2204.03487",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Optimizing the Long-Term Behaviour of Deep Reinforcement Learning for Pushing and Grasping. (arXiv:2204.03487v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03574",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nayak_N/0/1/0/all/0/1\">Nihal V. Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peilin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1\">Stephen H. Bach</a>",
          "description": "We introduce compositional soft prompting (CSP), a parameter-efficient\nlearning technique to improve the zero-shot compositionality of large-scale\npretrained vision-language models (VLMs) without the overhead of fine-tuning\nthe entire model. VLMs can represent arbitrary classes as natural language\nprompts in their flexible text encoders but they underperform state-of-the-art\nmethods on compositional zero-shot benchmark tasks. To improve VLMs, we propose\na novel form of soft prompting. We treat the attributes and objects that are\ncomposed to define classes as learnable tokens of vocabulary and tune them on\nmultiple prompt compositions. During inference, we recompose the learned\nattribute-object vocabulary in new combinations and show that CSP outperforms\nthe original VLM on benchmark datasets by an average of 14.7 percentage points\nof accuracy. CSP also achieves new state-of-the-art accuracies on two out of\nthree benchmark datasets, while only fine-tuning a small number of parameters.\nFurther, we show that CSP improves generalization to higher-order\nattribute-attribute-object compositions and combinations of pretrained\nattributes and fine-tuned objects.",
          "link": "http://arxiv.org/abs/2204.03574",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Learning to Compose Soft Prompts for Compositional Zero-Shot Learning. (arXiv:2204.03574v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03583",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ribas_C/0/1/0/all/0/1\">Celso H. H. Ribas</a> (1,2), <a href=\"http://arxiv.org/find/cs/1/au:+Bermudez_J/0/1/0/all/0/1\">Jos&#xe9; C. M. Bermudez</a> (1) ((1) Digital Signal Processing Research Laboratory, Federal University of Santa Catarina, Santa Catarina, Brazil, (2) Superintendence of Inspection, National Telecommunications Agency, Amazonas, Brazil)",
          "description": "Access to data and data processing, including the use of machine learning\ntechniques, has become significantly easier and cheaper in recent years.\nNevertheless, solutions that can be widely adopted by regulators for market\nmonitoring and inspection targeting in a data-driven way have not been\nfrequently discussed by the scientific community. This article discusses the\nneed and the difficulties for the development of such solutions, presents an\neffective method to address regulation planning, and illustrates its use to\naccount for the most important and common subject for the majority of\nregulators: the consumer. This article hopes to contribute to increase the\nawareness of the regulatory community to the need for data processing methods\nthat are objective, impartial, transparent, explainable, simple to implement\nand with low computational cost, aiming to the implementation of risk-based\nregulation in the world.",
          "link": "http://arxiv.org/abs/2204.03583",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Risk-based regulation for all: The need and a method for a wide adoption solution for data-driven inspection targeting. (arXiv:2204.03583v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huertas_Tato_J/0/1/0/all/0/1\">Javier Huertas-Tato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_A/0/1/0/all/0/1\">Alejandro Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_D/0/1/0/all/0/1\">David Camacho</a>",
          "description": "The appearance of complex attention-based language models such as BERT,\nRoberta or GPT-3 has allowed to address highly complex tasks in a plethora of\nscenarios. However, when applied to specific domains, these models encounter\nconsiderable difficulties. This is the case of Social Networks such as Twitter,\nan ever-changing stream of information written with informal and complex\nlanguage, where each message requires careful evaluation to be understood even\nby humans given the important role that context plays. Addressing tasks in this\ndomain through Natural Language Processing involves severe challenges. When\npowerful state-of-the-art multilingual language models are applied to this\nscenario, language specific nuances use to get lost in translation. To face\nthese challenges we present \\textbf{BERTuit}, the larger transformer proposed\nso far for Spanish language, pre-trained on a massive dataset of 230M Spanish\ntweets using RoBERTa optimization. Our motivation is to provide a powerful\nresource to better understand Spanish Twitter and to be used on applications\nfocused on this social network, with special emphasis on solutions devoted to\ntackle the spreading of misinformation in this platform. BERTuit is evaluated\non several tasks and compared against M-BERT, XLM-RoBERTa and XLM-T, very\ncompetitive multilingual transformers. The utility of our approach is shown\nwith applications, in this case: a zero-shot methodology to visualize groups of\nhoaxes and profiling authors spreading disinformation.\n\nMisinformation spreads wildly on platforms such as Twitter in languages other\nthan English, meaning performance of transformers may suffer when transferred\noutside English speaking communities.",
          "link": "http://arxiv.org/abs/2204.03465",
          "publishedOn": "2022-04-09T00:48:55.297Z",
          "wordCount": null,
          "title": "BERTuit: Understanding Spanish language in Twitter through a native transformer. (arXiv:2204.03465v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zeyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>",
          "description": "Various neural network models have been proposed to tackle combinatorial\noptimization problems such as the travelling salesman problem (TSP). Existing\nlearning-based TSP methods adopt a simple setting that the training and testing\ndata are independent and identically distributed. However, the existing\nliterature fails to solve TSP instances when training and testing data have\ndifferent distributions. Concretely, we find that different training and\ntesting distribution will result in more difficult TSP instances, i.e., the\nsolution obtained by the model has a large gap from the optimal solution. To\ntackle this problem, in this work, we study learning-based TSP methods when\ntraining and testing data have different distributions using adaptive-hardness,\ni.e., how difficult a TSP instance can be for a solver. This problem is\nchallenging because it is non-trivial to (1) define hardness measurement\nquantitatively; (2) efficiently and continuously generate sufficiently hard TSP\ninstances upon model training; (3) fully utilize instances with different\nlevels of hardness to learn a more powerful TSP solver. To solve these\nchallenges, we first propose a principled hardness measurement to quantify the\nhardness of TSP instances. Then, we propose a hardness-adaptive generator to\ngenerate instances with different hardness. We further propose a curriculum\nlearner fully utilizing these instances to train the TSP solver. Experiments\nshow that our hardness-adaptive generator can generate instances ten times\nharder than the existing methods, and our proposed method achieves significant\nimprovement over state-of-the-art models in terms of the optimality gap.",
          "link": "http://arxiv.org/abs/2204.03236",
          "publishedOn": "2022-04-09T00:48:55.295Z",
          "wordCount": null,
          "title": "Learning to Solve Travelling Salesman Problem with Hardness-adaptive Curriculum. (arXiv:2204.03236v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulynych_B/0/1/0/all/0/1\">Bogdan Kulynych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yao-Yuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1\">Jaros&#x142;aw B&#x142;asiok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1\">Preetum Nakkiran</a>",
          "description": "We investigate and leverage a connection between Differential Privacy (DP)\nand the recently proposed notion of Distributional Generalization (DG).\nApplying this connection, we introduce new conceptual tools for designing\ndeep-learning methods that bypass \"pathologies\" of standard stochastic gradient\ndescent (SGD). First, we prove that differentially private methods satisfy a\n\"What You See Is What You Get (WYSIWYG)\" generalization guarantee: whatever a\nmodel does on its train data is almost exactly what it will do at test time.\nThis guarantee is formally captured by distributional generalization. WYSIWYG\nenables principled algorithm design in deep learning by reducing\n$\\textit{generalization}$ concerns to $\\textit{optimization}$ ones: in order to\nmitigate unwanted behavior at test time, it is provably sufficient to mitigate\nthis behavior on the train data. This is notably false for standard (non-DP)\nmethods, hence this observation has applications even when privacy is not\nrequired. For example, importance sampling is known to fail for standard SGD,\nbut we show that it has exactly the intended effect for DP-trained models.\nThus, with DP-SGD, unlike with SGD, we can influence test-time behavior by\nmaking principled train-time interventions. We use these insights to construct\nsimple algorithms which match or outperform SOTA in several distributional\nrobustness applications, and to significantly improve the privacy vs. disparate\nimpact trade-off of DP-SGD. Finally, we also improve on known theoretical\nbounds relating differential privacy, stability, and distributional\ngeneralization.",
          "link": "http://arxiv.org/abs/2204.03230",
          "publishedOn": "2022-04-09T00:48:55.291Z",
          "wordCount": null,
          "title": "What You See is What You Get: Distributional Generalization for Algorithm Design in Deep Learning. (arXiv:2204.03230v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Sibo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianhua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasiou_C/0/1/0/all/0/1\">Charitos Anastasiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angeli_P/0/1/0/all/0/1\">Panagiota Angeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matar_O/0/1/0/all/0/1\">Omar K. Matar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yi-Ke Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pain_C/0/1/0/all/0/1\">Christopher C. Pain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcucci_R/0/1/0/all/0/1\">Rossella Arcucci</a>",
          "description": "Reduced-order modelling and low-dimensional surrogate models generated using\nmachine learning algorithms have been widely applied in high-dimensional\ndynamical systems to improve the algorithmic efficiency. In this paper, we\ndevelop a system which combines reduced-order surrogate models with a novel\ndata assimilation (DA) technique used to incorporate real-time observations\nfrom different physical spaces. We make use of local smooth surrogate functions\nwhich link the space of encoded system variables and the one of current\nobservations to perform variational DA with a low computational cost. The new\nsystem, named Generalised Latent Assimilation can benefit both the efficiency\nprovided by the reduced-order modelling and the accuracy of data assimilation.\nA theoretical analysis of the difference between surrogate and original\nassimilation cost function is also provided in this paper where an upper bound,\ndepending on the size of the local training set, is given. The new approach is\ntested on a high-dimensional CFD application of a two-phase liquid flow with\nnon-linear observation operators that current Latent Assimilation methods can\nnot handle. Numerical results demonstrate that the proposed assimilation\napproach can significantly improve the reconstruction and prediction accuracy\nof the deep learning surrogate model which is nearly 1000 times faster than the\nCFD simulation.",
          "link": "http://arxiv.org/abs/2204.03497",
          "publishedOn": "2022-04-09T00:48:55.291Z",
          "wordCount": null,
          "title": "Generalised Latent Assimilation in Heterogeneous Reduced Spaces with Machine Learning Surrogate Models. (arXiv:2204.03497v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minkyu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Hyun-Soo Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jinho Kim</a>",
          "description": "Graph neural networks are powerful methods to handle graph-structured data.\nHowever, existing graph neural networks only learn higher-order feature\ninteractions implicitly. Thus, they cannot capture information that occurred in\nlow-order feature interactions. To overcome this problem, we propose Explicit\nFeature Interaction-aware Graph Neural Network (EFI-GNN), which explicitly\nlearns arbitrary-order feature interactions. EFI-GNN can jointly learn with any\nother graph neural network. We demonstrate that the joint learning method\nalways enhances performance on the various node classification tasks.\nFurthermore, since EFI-GNN is inherently a linear model, we can interpret the\nprediction result of EFI-GNN. With the computation rule, we can obtain an\nany-order feature's effect on the decision. By that, we visualize the effects\nof the first-order and second-order features as a form of a heatmap.",
          "link": "http://arxiv.org/abs/2204.03225",
          "publishedOn": "2022-04-09T00:48:55.282Z",
          "wordCount": null,
          "title": "Explicit Feature Interaction-aware Graph Neural Networks. (arXiv:2204.03225v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03439",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Gebhard_T/0/1/0/all/0/1\">Timothy D. Gebhard</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Bonse_M/0/1/0/all/0/1\">Markus J. Bonse</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Quanz_S/0/1/0/all/0/1\">Sascha P. Quanz</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "High-contrast imaging of exoplanets hinges on powerful post-processing\nmethods to denoise the data and separate the signal of a companion from its\nhost star, which is typically orders of magnitude brighter. Existing\npost-processing algorithms do not use all prior domain knowledge that is\navailable about the problem. We propose a new method that builds on our\nunderstanding of the systematic noise and the causal structure of the\ndata-generating process. Our algorithm is based on a modified version of\nhalf-sibling regression (HSR), a flexible denoising framework that combines\nideas from the fields of machine learning and causality. We adapt the method to\naddress the specific requirements of high-contrast exoplanet imaging data\nobtained in pupil tracking mode. The key idea is to estimate the systematic\nnoise in a pixel by regressing the time series of this pixel onto a set of\ncausally independent, signal-free predictor pixels. We use regularized linear\nmodels in this work; however, other (non-linear) models are also possible. In a\nsecond step, we demonstrate how the HSR framework allows us to incorporate\nobserving conditions such as wind speed or air temperature as additional\npredictors. When we apply our method to four data sets from the VLT/NACO\ninstrument, our algorithm provides a better false-positive fraction than\nPCA-based PSF subtraction, a popular baseline method in the field.\nAdditionally, we find that the HSR-based method provides direct and accurate\nestimates for the contrast of the exoplanets without the need to insert\nartificial companions for calibration in the data sets. Finally, we present\nfirst evidence that using the observing conditions as additional predictors can\nimprove the results. Our HSR-based method provides an alternative, flexible and\npromising approach to the challenge of modeling and subtracting the stellar PSF\nand systematic noise in exoplanet imaging data.",
          "link": "http://arxiv.org/abs/2204.03439",
          "publishedOn": "2022-04-09T00:48:55.280Z",
          "wordCount": null,
          "title": "Half-sibling regression meets exoplanet imaging: PSF modeling and subtraction using a flexible, domain knowledge-driven, causal framework. (arXiv:2204.03439v1 [astro-ph.IM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vamsi Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_L/0/1/0/all/0/1\">Likith Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shivam Kumar Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dadi_K/0/1/0/all/0/1\">Kamalakar Dadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yarra_C/0/1/0/all/0/1\">Chiranjeevi Yarra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raju_B/0/1/0/all/0/1\">Bapi S. Raju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajendran_S/0/1/0/all/0/1\">Srijithesh Rajendran</a>",
          "description": "Modeling effective representations using multiple views that positively\ninfluence each other is challenging, and the existing methods perform poorly on\nElectroencephalogram (EEG) signals for sleep-staging tasks. In this paper, we\npropose a novel multi-view self-supervised method (mulEEG) for unsupervised EEG\nrepresentation learning. Our method attempts to effectively utilize the\ncomplementary information available in multiple views to learn better\nrepresentations. We introduce diverse loss that further encourages\ncomplementary information across multiple views. Our method with no access to\nlabels beats the supervised training while outperforming multi-view baseline\nmethods on transfer learning experiments carried out on sleep-staging tasks. We\nposit that our method was able to learn better representations by using\ncomplementary multi-views.",
          "link": "http://arxiv.org/abs/2204.03272",
          "publishedOn": "2022-04-09T00:48:55.279Z",
          "wordCount": null,
          "title": "mulEEG: A Multi-View Representation Learning on EEG Signals. (arXiv:2204.03272v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vital_F/0/1/0/all/0/1\">F&#xe1;bio Vital</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasco_M/0/1/0/all/0/1\">Miguel Vasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sardinha_A/0/1/0/all/0/1\">Alberto Sardinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melo_F/0/1/0/all/0/1\">Francisco Melo</a>",
          "description": "We present Perceive-Represent-Generate (PRG), a novel three-stage framework\nthat maps perceptual information of different modalities (e.g., visual or\nsound), corresponding to a sequence of instructions, to an adequate sequence of\nmovements to be executed by a robot. In the first stage, we perceive and\npre-process the given inputs, isolating individual commands from the complete\ninstruction provided by a human user. In the second stage we encode the\nindividual commands into a multimodal latent space, employing a deep generative\nmodel. Finally, in the third stage we convert the multimodal latent values into\nindividual trajectories and combine them into a single dynamic movement\nprimitive, allowing its execution in a robotic platform. We evaluate our\npipeline in the context of a novel robotic handwriting task, where the robot\nreceives as input a word through different perceptual modalities (e.g., image,\nsound), and generates the corresponding motion trajectory to write it, creating\ncoherent and readable handwritten words.",
          "link": "http://arxiv.org/abs/2204.03051",
          "publishedOn": "2022-04-09T00:48:55.278Z",
          "wordCount": null,
          "title": "Perceive, Represent, Generate: Translating Multimodal Information to Robotic Motion Trajectories. (arXiv:2204.03051v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_P/0/1/0/all/0/1\">Priya Sundaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antonova_R/0/1/0/all/0/1\">Rika Antonova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1\">Jeannette Bohg</a>",
          "description": "Research in manipulation of deformable objects is typically conducted on a\nlimited range of scenarios, because handling each scenario on hardware takes\nsignificant effort. Realistic simulators with support for various types of\ndeformations and interactions have the potential to speed up experimentation\nwith novel tasks and algorithms. However, for highly deformable objects it is\nchallenging to align the output of a simulator with the behavior of real\nobjects. Manual tuning is not intuitive, hence automated methods are needed. We\nview this alignment problem as a joint perception-inference challenge and\ndemonstrate how to use recent neural network architectures to successfully\nperform simulation parameter inference from real point clouds. We analyze the\nperformance of various architectures, comparing their data and training\nrequirements. Furthermore, we propose to leverage differentiable point cloud\nsampling and differentiable simulation to significantly reduce the time to\nachieve the alignment. We employ an efficient way to propagate gradients from\npoint clouds to simulated meshes and further through to the physical simulation\nparameters, such as mass and stiffness. Experiments with highly deformable\nobjects show that our method can achieve comparable or better alignment with\nreal object behavior, while reducing the time needed to achieve this by more\nthan an order of magnitude. Videos and supplementary material are available at\nhttps://tinyurl.com/diffcloud.",
          "link": "http://arxiv.org/abs/2204.03139",
          "publishedOn": "2022-04-09T00:48:55.278Z",
          "wordCount": null,
          "title": "DiffCloud: Real-to-Sim from Point Clouds with Differentiable Simulation and Rendering of Deformable Objects. (arXiv:2204.03139v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simsek_M/0/1/0/all/0/1\">Murat Simsek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantarci_B/0/1/0/all/0/1\">Burak Kantarci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouftah_H/0/1/0/all/0/1\">Hussein T. Mouftah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djukic_P/0/1/0/all/0/1\">Petar Djukic</a>",
          "description": "Despite its technological benefits, Internet of Things (IoT) has cyber\nweaknesses due to the vulnerabilities in the wireless medium. Machine learning\n(ML)-based methods are widely used against cyber threats in IoT networks with\npromising performance. Advanced persistent threat (APT) is prominent for\ncybercriminals to compromise networks, and it is crucial to long-term and\nharmful characteristics. However, it is difficult to apply ML-based approaches\nto identify APT attacks to obtain a promising detection performance due to an\nextremely small percentage among normal traffic. There are limited surveys to\nfully investigate APT attacks in IoT networks due to the lack of public\ndatasets with all types of APT attacks. It is worth to bridge the\nstate-of-the-art in network attack detection with APT attack detection in a\ncomprehensive review article. This survey article reviews the security\nchallenges in IoT networks and presents the well-known attacks, APT attacks,\nand threat models in IoT systems. Meanwhile, signature-based, anomaly-based,\nand hybrid intrusion detection systems are summarized for IoT networks. The\narticle highlights statistical insights regarding frequently applied ML-based\nmethods against network intrusion alongside the number of attacks types\ndetected. Finally, open issues and challenges for common network intrusion and\nAPT attacks are presented for future research.",
          "link": "http://arxiv.org/abs/2204.03433",
          "publishedOn": "2022-04-09T00:48:55.278Z",
          "wordCount": null,
          "title": "Machine Learning-Enabled IoT Security: Open Issues and Challenges Under Advanced Persistent Threats. (arXiv:2204.03433v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03456",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brinkmeyer_L/0/1/0/all/0/1\">Lukas Brinkmeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drumond_R/0/1/0/all/0/1\">Rafael Rego Drumond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burchert_J/0/1/0/all/0/1\">Johannes Burchert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1\">Lars Schmidt-Thieme</a>",
          "description": "Learning complex time series forecasting models usually requires a large\namount of data, as each model is trained from scratch for each task/data set.\nLeveraging learning experience with similar datasets is a well-established\ntechnique for classification problems called few-shot classification. However,\nexisting approaches cannot be applied to time-series forecasting because i)\nmultivariate time-series datasets have different channels and ii) forecasting\nis principally different from classification. In this paper we formalize the\nproblem of few-shot forecasting of time-series with heterogeneous channels for\nthe first time. Extending recent work on heterogeneous attributes in vector\ndata, we develop a model composed of permutation-invariant deep set-blocks\nwhich incorporate a temporal embedding. We assemble the first meta-dataset of\n40 multivariate time-series datasets and show through experiments that our\nmodel provides a good generalization, outperforming baselines carried over from\nsimpler scenarios that either fail to learn across tasks or miss temporal\ninformation.",
          "link": "http://arxiv.org/abs/2204.03456",
          "publishedOn": "2022-04-09T00:48:55.276Z",
          "wordCount": null,
          "title": "Few-Shot Forecasting of Time-Series with Heterogeneous Channels. (arXiv:2204.03456v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ott_F/0/1/0/all/0/1\">Felix Ott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1\">David R&#xfc;gamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heublein_L/0/1/0/all/0/1\">Lucas Heublein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutschler_C/0/1/0/all/0/1\">Christopher Mutschler</a>",
          "description": "The performance of a machine learning model degrades when it is applied to\ndata from a similar but different domain than the data it has initially been\ntrained on. To mitigate this domain shift problem, domain adaptation (DA)\ntechniques search for an optimal transformation that converts the (current)\ninput data from a source domain to a target domain to learn a domain-invariant\nrepresentations that reduces domain discrepancy.\n\nThis paper proposes a novel supervised domain adaptation based on two steps.\nFirst, we search for an optimal class-dependent transformation from the source\nto the target domain from a few samples. We consider optimal transport methods\nsuch as the earth mover distance with Laplacian regularization, Sinkhorn\ntransport and correlation alignment. Second, we use embedding similarity\ntechniques to select the corresponding transformation at inference. We use\ncorrelation metrics and maximum mean discrepancy with higher-order moment\nmatching techniques. We conduct an extensive evaluation on time-series datasets\nwith domain shift including simulated and various online handwriting datasets\nto demonstrate the performance.",
          "link": "http://arxiv.org/abs/2204.03342",
          "publishedOn": "2022-04-09T00:48:55.275Z",
          "wordCount": null,
          "title": "Domain Adaptation for Time-Series Classification to Mitigate Covariate Shift. (arXiv:2204.03342v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daghero_F/0/1/0/all/0/1\">Francesco Daghero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burrello_A/0/1/0/all/0/1\">Alessio Burrello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagliari_D/0/1/0/all/0/1\">Daniele Jahier Pagliari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macii_E/0/1/0/all/0/1\">Enrico Macii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poncino_M/0/1/0/all/0/1\">Massimo Poncino</a>",
          "description": "Energy-efficient machine learning models that can run directly on edge\ndevices are of great interest in IoT applications, as they can reduce network\npressure and response latency, and improve privacy. An effective way to obtain\nenergy-efficiency with small accuracy drops is to sequentially execute a set of\nincreasingly complex models, early-stopping the procedure for \"easy\" inputs\nthat can be confidently classified by the smallest models. As a stopping\ncriterion, current methods employ a single threshold on the output\nprobabilities produced by each model. In this work, we show that such a\ncriterion is sub-optimal for datasets that include classes of different\ncomplexity, and we demonstrate a more general approach based on per-classes\nthresholds. With experiments on a low-power end-node, we show that our method\ncan significantly reduce the energy consumption compared to the\nsingle-threshold approach.",
          "link": "http://arxiv.org/abs/2204.03431",
          "publishedOn": "2022-04-09T00:48:55.274Z",
          "wordCount": null,
          "title": "Energy-Efficient Adaptive Machine Learning on IoT End-Nodes With Class-Dependent Confidence. (arXiv:2204.03431v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balagansky_N/0/1/0/all/0/1\">Nikita Balagansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavrilov_D/0/1/0/all/0/1\">Daniil Gavrilov</a>",
          "description": "Currently, pre-trained models can be considered the default choice for a wide\nrange of NLP tasks. Despite their SoTA results, there is practical evidence\nthat these models may require a different number of computing layers for\ndifferent input sequences, since evaluating all layers leads to overconfidence\non wrong predictions (namely overthinking). This problem can potentially be\nsolved by implementing adaptive computation time approaches, which were first\ndesigned to improve inference speed. Recently proposed PonderNet may be a\npromising solution for performing an early exit by treating the exit layers\nindex as a latent variable. However, the originally proposed exit criterion,\nrelying on sampling from trained posterior distribution on the probability of\nexiting from i-th layer, introduces major variance in model outputs,\nsignificantly reducing the resulting models performance. In this paper, we\npropose Ponder ALBERT (PALBERT): an improvement to PonderNet with a novel\ndeterministic Q-exit criterion and a revisited model architecture. We compared\nPALBERT with recent methods for performing an early exit. We observed that the\nproposed changes can be considered significant improvements on the original\nPonderNet architecture and outperform PABEE on a wide range of GLUE tasks. In\naddition, we also performed an in-depth ablation study of the proposed\narchitecture to further understand Lambda layers and their performance.",
          "link": "http://arxiv.org/abs/2204.03276",
          "publishedOn": "2022-04-09T00:48:55.273Z",
          "wordCount": null,
          "title": "PALBERT: Teaching ALBERT to Ponder. (arXiv:2204.03276v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hedegaard_L/0/1/0/all/0/1\">Lukas Hedegaard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "We present Continual Inference, a Python library for implementing Continual\nInference Networks (CINs) in PyTorch, a class of Neural Networks designed\nspecifically for efficient inference in both online and batch processing\nscenarios. We offer a comprehensive introduction and guide to CINs and their\nimplementation in practice, and provide best-practices and code examples for\ncomposing complex modules for modern Deep Learning. Continual Inference is\nreadily downloadable via the Python Package Index and at\n\\url{www.github.com/lukashedegaard/continual-inference}.",
          "link": "http://arxiv.org/abs/2204.03418",
          "publishedOn": "2022-04-09T00:48:55.272Z",
          "wordCount": null,
          "title": "Continual Inference: A Library for Efficient Online Inference with Deep Neural Networks in PyTorch. (arXiv:2204.03418v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ranjbar_N/0/1/0/all/0/1\">Niloofar Ranjbar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safabakhsh_R/0/1/0/all/0/1\">Reza Safabakhsh</a>",
          "description": "Nowadays, deep neural networks are being used in many domains because of\ntheir high accuracy results. However, they are considered as \"black box\", means\nthat they are not explainable for humans. On the other hand, in some tasks such\nas medical, economic, and self-driving cars, users want the model to be\ninterpretable to decide if they can trust these results or not. In this work,\nwe present a modified version of an autoencoder-based approach for local\ninterpretability called ALIME. The ALIME itself is inspired by a famous method\ncalled Local Interpretable Model-agnostic Explanations (LIME). LIME generates a\nsingle instance level explanation by generating new data around the instance\nand training a local linear interpretable model. ALIME uses an autoencoder to\nweigh the new data around the sample. Nevertheless, the ALIME uses a linear\nmodel as the interpretable model to be trained locally, just like the LIME.\nThis work proposes a new approach, which uses a decision tree instead of the\nlinear model, as the interpretable model. We evaluate the proposed model in\ncase of stability, local fidelity, and interpretability on different datasets.\nCompared to ALIME, the experiments show significant results on stability and\nlocal fidelity and improved results on interpretability.",
          "link": "http://arxiv.org/abs/2204.03321",
          "publishedOn": "2022-04-09T00:48:55.271Z",
          "wordCount": null,
          "title": "Using Decision Tree as Local Interpretable Model in Autoencoder-based LIME. (arXiv:2204.03321v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venezian_E/0/1/0/all/0/1\">Elad Venezian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_Y/0/1/0/all/0/1\">Yoav Katz</a>",
          "description": "Pretrained models are the standard starting point for training. This approach\nconsistently outperforms the use of a random initialization. However,\npretraining is a costly endeavour that few can undertake.\n\nIn this paper, we create better base models at hardly any cost, by fusing\nmultiple existing fine tuned models into one. Specifically, we fuse by\naveraging the weights of these models. We show that the fused model results\nsurpass the pretrained model ones. We also show that fusing is often better\nthan intertraining.\n\nWe find that fusing is less dependent on the target task. Furthermore, weight\ndecay nullifies intertraining effects but not those of fusing.",
          "link": "http://arxiv.org/abs/2204.03044",
          "publishedOn": "2022-04-09T00:48:55.270Z",
          "wordCount": null,
          "title": "Fusing finetuned models for better pretraining. (arXiv:2204.03044v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Chenyan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1\">Payal Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwary_S/0/1/0/all/0/1\">Saurabh Tiwary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1\">Paul Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xia Song</a>",
          "description": "We present a new framework AMOS that pretrains text encoders with an\nAdversarial learning curriculum via a Mixture Of Signals from multiple\nauxiliary generators. Following ELECTRA-style pretraining, the main encoder is\ntrained as a discriminator to detect replaced tokens generated by auxiliary\nmasked language models (MLMs). Different from ELECTRA which trains one MLM as\nthe generator, we jointly train multiple MLMs of different sizes to provide\ntraining signals at various levels of difficulty. To push the discriminator to\nlearn better with challenging replaced tokens, we learn mixture weights over\nthe auxiliary MLMs' outputs to maximize the discriminator loss by\nbackpropagating the gradient from the discriminator via Gumbel-Softmax. For\nbetter pretraining efficiency, we propose a way to assemble multiple MLMs into\none unified auxiliary model. AMOS outperforms ELECTRA and recent\nstate-of-the-art pretrained models by about 1 point on the GLUE benchmark for\nBERT base-sized models.",
          "link": "http://arxiv.org/abs/2204.03243",
          "publishedOn": "2022-04-09T00:48:55.270Z",
          "wordCount": null,
          "title": "Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators. (arXiv:2204.03243v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_J/0/1/0/all/0/1\">Jeffrey Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_R/0/1/0/all/0/1\">Rajat Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tumma_N/0/1/0/all/0/1\">Neehal Tumma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhishek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "Topic models are some of the most popular ways to represent textual data in\nan interpret-able manner. Recently, advances in deep generative models,\nspecifically auto-encoding variational Bayes (AEVB), have led to the\nintroduction of unsupervised neural topic models, which leverage deep\ngenerative models as opposed to traditional statistics-based topic models. We\nextend upon these neural topic models by introducing the Label-Indexed Neural\nTopic Model (LI-NTM), which is, to the extent of our knowledge, the first\neffective upstream semi-supervised neural topic model. We find that LI-NTM\noutperforms existing neural topic models in document reconstruction benchmarks,\nwith the most notable results in low labeled data regimes and for data-sets\nwith informative labels; furthermore, our jointly learned classifier\noutperforms baseline classifiers in ablation studies.",
          "link": "http://arxiv.org/abs/2204.03208",
          "publishedOn": "2022-04-09T00:48:55.269Z",
          "wordCount": null,
          "title": "A Joint Learning Approach for Semi-supervised Neural Topic Modeling. (arXiv:2204.03208v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adibi_A/0/1/0/all/0/1\">Arman Adibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_A/0/1/0/all/0/1\">Aritra Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>",
          "description": "Recent years have witnessed a growing interest in the topic of min-max\noptimization, owing to its relevance in the context of generative adversarial\nnetworks (GANs), robust control and optimization, and reinforcement learning.\nMotivated by this line of work, we consider a multi-agent min-max learning\nproblem, and focus on the emerging challenge of contending with worst-case\nByzantine adversarial agents in such a setup. By drawing on recent results from\nrobust statistics, we design a robust distributed variant of the extra-gradient\nalgorithm - a popular algorithmic approach for min-max optimization. Our main\ncontribution is to provide a crisp analysis of the proposed robust\nextra-gradient algorithm for smooth convex-concave and smooth strongly\nconvex-strongly concave functions. Specifically, we establish statistical rates\nof convergence to approximate saddle points. Our rates are near-optimal, and\nreveal both the effect of adversarial corruption and the benefit of\ncollaboration among the non-faulty agents. Notably, this is the first paper to\nprovide formal theoretical guarantees for large-scale distributed min-max\nlearning in the presence of adversarial agents.",
          "link": "http://arxiv.org/abs/2204.03187",
          "publishedOn": "2022-04-09T00:48:55.268Z",
          "wordCount": null,
          "title": "Distributed Statistical Min-Max Learning in the Presence of Byzantine Agents. (arXiv:2204.03187v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03214",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thapa_C/0/1/0/all/0/1\">Chandra Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1\">Seung Ick Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1\">Muhammad Ejaz Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camtepe_S/0/1/0/all/0/1\">Seyit Camtepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pieprzyk_J/0/1/0/all/0/1\">Josef Pieprzyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nepal_S/0/1/0/all/0/1\">Surya Nepal</a>",
          "description": "The large transformer-based language models demonstrate excellent performance\nin natural language processing. By considering the closeness of natural\nlanguages to the high-level programming language such as C/C++, this work\nstudies how good are the large transformer-based language models detecting\nsoftware vulnerabilities. Our results demonstrate the well performance of these\nmodels on software vulnerability detection. The answer enables extending\ntransformer-based language models to vulnerability detection and leveraging\nsuperior performance beyond the natural language processing domain. Besides, we\nperform the model's security check using Microsoft's Counterfit, a command-line\ntool to assess the model's security. Our results find that these models are\nvulnerable to adversarial examples. In this regard, we present a simple\ncountermeasure and its result. Experimenting with large models is always a\nchallenge due to the requirement of computing resources and platforms/libraries\n& dependencies. Based on the experiences and difficulties we faced during this\nwork, we present our recommendation while choosing the platforms to run these\nlarge models. Moreover, the popular platforms are surveyed thoroughly in this\npaper.",
          "link": "http://arxiv.org/abs/2204.03214",
          "publishedOn": "2022-04-09T00:48:55.266Z",
          "wordCount": null,
          "title": "Transformer-Based Language Models for Software Vulnerability Detection: Performance, Model's Security and Platforms. (arXiv:2204.03214v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Emerson_H/0/1/0/all/0/1\">Harry Emerson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guy_M/0/1/0/all/0/1\">Matt Guy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McConville_R/0/1/0/all/0/1\">Ryan McConville</a>",
          "description": "Hybrid closed loop systems represent the future of care for people with type\n1 diabetes (T1D). These devices usually utilise simple control algorithms to\nselect the optimal insulin dose for maintaining blood glucose levels within a\nhealthy range. Online reinforcement learning (RL) has been utilised as a method\nfor further enhancing glucose control in these devices. Previous approaches\nhave been shown to reduce patient risk and improve time spent in the target\nrange when compared to classical control algorithms, but are prone to\ninstability in the learning process, often resulting in the selection of unsafe\nactions. This work presents an evaluation of offline RL as a means for\ndeveloping clinically effective dosing policies without the need for patient\ninteraction. This paper examines the utility of BCQ, CQL and TD3-BC in managing\nthe blood glucose of nine virtual patients within the UVA/Padova glucose\ndynamics simulator. When trained on less than a tenth of the data required by\nonline RL approaches, this work shows that offline RL can significantly\nincrease time in the healthy blood glucose range when compared to the strongest\nstate-of-art baseline. This is achieved without any associated increase in low\nblood glucose events. Offline RL is also shown to be able to correct for common\nand challenging scenarios such as incorrect bolus dosing, irregular meal\ntimings and sub-optimal training data.",
          "link": "http://arxiv.org/abs/2204.03376",
          "publishedOn": "2022-04-09T00:48:55.265Z",
          "wordCount": null,
          "title": "Offline Reinforcement Learning for Safer Blood Glucose Control in People with Type 1 Diabetes. (arXiv:2204.03376v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thomas_J/0/1/0/all/0/1\">Josephine M. Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moallemy_Oureh_A/0/1/0/all/0/1\">Alice Moallemy-Oureh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beddar_Wiesing_S/0/1/0/all/0/1\">Silvia Beddar-Wiesing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holzhuter_C/0/1/0/all/0/1\">Clara Holzh&#xfc;ter</a>",
          "description": "Graphs are ubiquitous in nature and can therefore serve as models for many\npractical but also theoretical problems. Based on this, the young research\nfield of Graph Neural Networks (GNNs) has emerged. Despite the youth of the\nfield and the speed in which new models are developed, many good surveys have\nbeen published in the last years. Nevertheless, an overview on which graph\ntypes can be modeled by GNNs is missing. In this survey, we give a detailed\noverview of already existing GNNs and, unlike previous surveys, categorize them\naccording to their ability to handle different graph types. We consider GNNs\noperating on static as well as on dynamic graphs of different structural\nconstitutions, with or without node or edge attributes. Moreover in the dynamic\ncase, we separate the models in discrete-time and continuous-time dynamic\ngraphs based on their architecture. According to our findings, there are still\ngraph types, that are not covered by existing GNN models. Specifically, models\nconcerning heterogeneity in attributes are missing and the deletion of nodes\nand edges is only covered rarely.",
          "link": "http://arxiv.org/abs/2204.03080",
          "publishedOn": "2022-04-09T00:48:55.264Z",
          "wordCount": null,
          "title": "Graph Neural Networks Designed for Different Graph Types: A Survey. (arXiv:2204.03080v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weikai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1\">Meng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Songcan Chen</a>",
          "description": "Unsupervised Source (data) Free domain adaptation (USFDA) aims to transfer\nknowledge from a well-trained source model to a related but unlabeled target\ndomain. In such a scenario, all conventional adaptation methods that require\nsource data fail. To combat this challenge, existing USFDAs turn to transfer\nknowledge by aligning the target feature to the latent distribution hidden in\nthe source model. However, such information is naturally limited. Thus, the\nalignment in such a scenario is not only difficult but also insufficient, which\ndegrades the target generalization performance. To relieve this dilemma in\ncurrent USFDAs, we are motivated to explore a new perspective to boost their\nperformance. For this purpose and gaining necessary insight, we look back upon\nthe origin of the domain adaptation and first theoretically derive a new-brand\ntarget generalization error bound based on the model smoothness. Then,\nfollowing the theoretical insight, a general and model-smoothness-guided\nJacobian norm (JN) regularizer is designed and imposed on the target domain to\nmitigate this dilemma. Extensive experiments are conducted to validate its\neffectiveness. In its implementation, just with a few lines of codes added to\nthe existing USFDAs, we achieve superior results on various benchmark datasets.",
          "link": "http://arxiv.org/abs/2204.03467",
          "publishedOn": "2022-04-09T00:48:55.263Z",
          "wordCount": null,
          "title": "Jacobian Norm for Unsupervised Source-Free Domain Adaptation. (arXiv:2204.03467v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangjoon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "The widespread application of artificial intelligence in health research is\ncurrently hampered by limitations in data availability. Distributed learning\nmethods such as federated learning (FL) and shared learning (SL) are introduced\nto solve this problem as well as data management and ownership issues with\ntheir different strengths and weaknesses. The recent proposal of federated\nsplit task-agnostic (FeSTA) learning tries to reconcile the distinct merits of\nFL and SL by enabling the multi-task collaboration between participants through\nVision Transformer (ViT) architecture, but they suffer from higher\ncommunication overhead. To address this, here we present a multi-task\ndistributed learning using ViT with random patch permutation. Instead of using\na CNN based head as in FeSTA, p-FeSTA adopts a randomly permuting simple patch\nembedder, improving the multi-task learning performance without sacrificing\nprivacy. Experimental results confirm that the proposed method significantly\nenhances the benefit of multi-task collaboration, communication efficiency, and\nprivacy preservation, shedding light on practical multi-task distributed\nlearning in the field of medical imaging.",
          "link": "http://arxiv.org/abs/2204.03500",
          "publishedOn": "2022-04-09T00:48:55.247Z",
          "wordCount": null,
          "title": "Multi-Task Distributed Learning using Vision Transformer with Random Patch Permutation. (arXiv:2204.03500v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kommrusch_S/0/1/0/all/0/1\">Steve Kommrusch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monperrus_M/0/1/0/all/0/1\">Martin Monperrus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouchet_L/0/1/0/all/0/1\">Louis-No&#xeb;l Pouchet</a>",
          "description": "We target the problem of automatically synthesizing proofs of semantic\nequivalence between two programs made of sequences of statements. We represent\nprograms using abstract syntax trees (AST), where a given set of\nsemantics-preserving rewrite rules can be applied on a specific AST pattern to\ngenerate a transformed and semantically equivalent program. In our system, two\nprograms are equivalent if there exists a sequence of application of these\nrewrite rules that leads to rewriting one program into the other. We propose a\nneural network architecture based on a transformer model to generate proofs of\nequivalence between program pairs. The system outputs a sequence of rewrites,\nand the validity of the sequence is simply checked by verifying it can be\napplied. If no valid sequence is produced by the neural network, the system\nreports the programs as non-equivalent, ensuring by design no programs may be\nincorrectly reported as equivalent. Our system is fully implemented for a given\ngrammar. To efficiently train the system to generate such sequences, we develop\nan original incremental training technique, named self-supervised sample\nselection. We extensively study the effectiveness of this novel training\napproach on proofs of increasing complexity and length. Our system, S4Eq,\nachieves 97% proof success on a curated dataset of 10,000 pairs of equivalent\nprograms.",
          "link": "http://arxiv.org/abs/2109.10476",
          "publishedOn": "2022-04-09T00:48:55.246Z",
          "wordCount": null,
          "title": "Self-Supervised Learning to Prove Equivalence Between Programs via Semantics-Preserving Rewrite Rules. (arXiv:2109.10476v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03564",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khalid_U/0/1/0/all/0/1\">Umar Khalid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karim_N/0/1/0/all/0/1\">Nazmul Karim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rahnavard_N/0/1/0/all/0/1\">Nazanin Rahnavard</a>",
          "description": "Deep neural networks (DNNs) designed for computer vision and natural language\nprocessing tasks cannot be directly applied to the radio frequency (RF)\ndatasets. To address this challenge, we propose to convert the raw RF data to\ndata types that are suitable for off-the-shelf DNNs by introducing a\nconvolutional transform technique. In addition, we propose a simple 5-layer\nconvolutional neural network architecture (CONV-5) that can operate with raw RF\nI/Q data without any transformation. Further, we put forward an RF dataset,\nreferred to as RF1024, to facilitate future RF research. RF1024 consists of 8\ndifferent RF modulation classes with each class having 1000/200 training/test\nsamples. Each sample of the RF1024 dataset contains 1024 complex I/Q values.\nLastly, the experiments are performed on the RadioML2016 and RF1024 datasets to\ndemonstrate the improved classification performance.",
          "link": "http://arxiv.org/abs/2204.03564",
          "publishedOn": "2022-04-09T00:48:55.190Z",
          "wordCount": null,
          "title": "RF Signal Transformation and Classification using Deep Neural Networks. (arXiv:2204.03564v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiqin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1\">Kangxue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1\">Sanja Fidler</a>",
          "description": "In this paper, we address the problem of texture representation for 3D shapes\nfor the challenging and underexplored tasks of texture transfer and synthesis.\nPrevious works either apply spherical texture maps which may lead to large\ndistortions, or use continuous texture fields that yield smooth outputs lacking\ndetails. We argue that the traditional way of representing textures with images\nand linking them to a 3D mesh via UV mapping is more desirable, since\nsynthesizing 2D images is a well-studied problem. We propose AUV-Net which\nlearns to embed 3D surfaces into a 2D aligned UV space, by mapping the\ncorresponding semantic parts of different 3D shapes to the same location in the\nUV space. As a result, textures are aligned across objects, and can thus be\neasily synthesized by generative models of images. Texture alignment is learned\nin an unsupervised manner by a simple yet effective texture alignment module,\ntaking inspiration from traditional works on linear subspace learning. The\nlearned UV mapping and aligned texture representations enable a variety of\napplications including texture transfer, texture synthesis, and textured single\nview 3D reconstruction. We conduct experiments on multiple datasets to\ndemonstrate the effectiveness of our method. Project page:\nhttps://nv-tlabs.github.io/AUV-NET.",
          "link": "http://arxiv.org/abs/2204.03105",
          "publishedOn": "2022-04-09T00:48:55.189Z",
          "wordCount": null,
          "title": "AUV-Net: Learning Aligned UV Maps for Texture Transfer and Synthesis. (arXiv:2204.03105v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yonghai Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yichuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freris_N/0/1/0/all/0/1\">Nikolaos M. Freris</a>",
          "description": "Federated Learning (FL) is an emerging framework for distributed processing\nof large data volumes by edge devices subject to limited communication\nbandwidths, heterogeneity in data distributions and computational resources, as\nwell as privacy considerations. In this paper, we introduce a new FL protocol\ntermed FedADMM based on primal-dual optimization. The proposed method leverages\ndual variables to tackle statistical heterogeneity, and accommodates system\nheterogeneity by tolerating variable amount of work performed by clients.\nFedADMM maintains identical communication costs per round as FedAvg/Prox, and\ngeneralizes them via the augmented Lagrangian. A convergence proof is\nestablished for nonconvex objectives, under no restrictions in terms of data\ndissimilarity or number of participants per round of the algorithm. We\ndemonstrate the merits through extensive experiments on real datasets, under\nboth IID and non-IID data distributions across clients. FedADMM consistently\noutperforms all baseline methods in terms of communication efficiency, with the\nnumber of rounds needed to reach a prescribed accuracy reduced by up to 87%.\nThe algorithm effectively adapts to heterogeneous data distributions through\nthe use of dual variables, without the need for hyperparameter tuning, and its\nadvantages are more pronounced in large-scale systems.",
          "link": "http://arxiv.org/abs/2204.03529",
          "publishedOn": "2022-04-09T00:48:55.189Z",
          "wordCount": null,
          "title": "FedADMM: A Robust Federated Deep Learning Framework with Adaptivity to System Heterogeneity. (arXiv:2204.03529v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03310",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zezario_R/0/1/0/all/0/1\">Ryandhimas E. Zezario</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_S/0/1/0/all/0/1\">Szu-wei Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fuh_C/0/1/0/all/0/1\">Chiou-Shann Fuh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Recently, deep learning (DL)-based non-intrusive speech assessment models\nhave attracted great attention. Many studies report that these DL-based models\nyield satisfactory assessment performance and good flexibility, but their\nperformance in unseen environments remains a challenge. Furthermore, compared\nto quality scores, fewer studies elaborate deep learning models to estimate\nintelligibility scores. This study proposes a multi-task speech intelligibility\nprediction model, called MTI-Net, for simultaneously predicting human and\nmachine intelligibility measures. Specifically, given a speech utterance,\nMTI-Net is designed to predict subjective listening test results and word error\nrate (WER) scores. We also investigate several methods that can improve the\nprediction performance of MTI-Net. First, we compare different features\n(including low-level features and embeddings from self-supervised learning\n(SSL) models) and prediction targets of MTI-Net. Second, we explore the effect\nof transfer learning and multi-tasking learning on training MTI-Net. Finally,\nwe examine the potential advantages of fine-tuning SSL embeddings. Experimental\nresults demonstrate the effectiveness of using cross-domain features,\nmulti-task learning, and fine-tuning SSL embeddings. Furthermore, it is\nconfirmed that the intelligibility and WER scores predicted by MTI-Net are\nhighly correlated with the ground-truth scores.",
          "link": "http://arxiv.org/abs/2204.03310",
          "publishedOn": "2022-04-09T00:48:55.188Z",
          "wordCount": null,
          "title": "MTI-Net: A Multi-Target Speech Intelligibility Prediction Model. (arXiv:2204.03310v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Minghui Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangnan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_K/0/1/0/all/0/1\">Keping Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leung_V/0/1/0/all/0/1\">Victor C.M.Leung</a>",
          "description": "Due to the rapid growth of data transmissions in internet of vehicles (IoV),\nfinding schemes that can effectively alleviate access congestion has become an\nimportant issue. Recently, many traffic control schemes have been studied.\nNevertheless, the dynamics of traffic and the heterogeneous requirements of\ndifferent IoV applications are not considered in most existing studies, which\nis significant for the random access resource allocation. In this paper, we\nconsider a hybrid traffic control scheme and use proximal policy optimization\n(PPO) method to tackle it. Firstly, IoV devices are divided into various\nclasses based on delay characteristics. The target of maximizing the successful\ntransmission of packets with the success rate constraint is established. Then,\nthe optimization objective is transformed into a markov decision process (MDP)\nmodel. Finally, the access class barring (ACB) factors are obtained based on\nthe PPO method to maximize the number of successful access devices. The\nperformance of the proposal algorithm in respect of successful events and delay\ncompared to existing schemes is verified by simulations.",
          "link": "http://arxiv.org/abs/2204.03504",
          "publishedOn": "2022-04-09T00:48:55.108Z",
          "wordCount": null,
          "title": "AI-aided Traffic Control Scheme for M2M Communications in the Internet of Vehicles. (arXiv:2204.03504v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03326",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joshi_P/0/1/0/all/0/1\">Praveen Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afli_H/0/1/0/all/0/1\">Haithem Afli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasanuzzaman_M/0/1/0/all/0/1\">Mohammed Hasanuzzaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapa_C/0/1/0/all/0/1\">Chandra Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scully_T/0/1/0/all/0/1\">Ted Scully</a>",
          "description": "Deep Learning-based models have been widely investigated, and they have\ndemonstrated significant performance on non-trivial tasks such as speech\nrecognition, image processing, and natural language understanding. However,\nthis is at the cost of substantial data requirements. Considering the\nwidespread proliferation of edge devices (e.g. Internet of Things devices) over\nthe last decade, Deep Learning in the edge paradigm, such as device-cloud\nintegrated platforms, is required to leverage its superior performance.\nMoreover, it is suitable from the data requirements perspective in the edge\nparadigm because the proliferation of edge devices has resulted in an explosion\nin the volume of generated and collected data. However, there are difficulties\ndue to other requirements such as high computation, high latency, and high\nbandwidth caused by Deep Learning applications in real-world scenarios. In this\nregard, this survey paper investigates Deep Learning at the edge, its\narchitecture, enabling technologies, and model adaption techniques, where edge\nservers and edge devices participate in deep learning training and inference.\nFor simplicity, we call this paradigm the All-in EDGE paradigm. Besides, this\npaper presents the key performance metrics for Deep Learning at the All-in EDGE\nparadigm to evaluate various deep learning techniques and choose a suitable\ndesign. Moreover, various open challenges arising from the deployment of Deep\nLearning at the All-in EDGE paradigm are identified and discussed.",
          "link": "http://arxiv.org/abs/2204.03326",
          "publishedOn": "2022-04-09T00:48:55.107Z",
          "wordCount": null,
          "title": "Enabling Deep Learning for All-in EDGE paradigm. (arXiv:2204.03326v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kopacz_A/0/1/0/all/0/1\">Anik&#xf3; Kopacz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mester_A/0/1/0/all/0/1\">&#xc1;gnes Mester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolumban_S/0/1/0/all/0/1\">S&#xe1;ndor Kolumb&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehel_C/0/1/0/all/0/1\">Csat&#xf3; Lehel</a>",
          "description": "We propose a train rescheduling algorithm which applies a standardized\nfeature selection based on pairwise conflicts in order to serve as input for\nthe reinforcement learning framework. We implement an analytical method which\nidentifies and optimally solves every conflict arising between two trains, then\nwe design a corresponding observation space which features the most relevant\ninformation considering these conflicts. The data obtained this way then\ntranslates to actions in the context of the reinforcement learning framework.\nWe test our preliminary model using the evaluation metrics of the Flatland\nChallenge. The empirical results indicate that the suggested feature space\nprovides meaningful observations, from which a sensible scheduling policy can\nbe learned.",
          "link": "http://arxiv.org/abs/2204.03061",
          "publishedOn": "2022-04-09T00:48:55.105Z",
          "wordCount": null,
          "title": "Standardized feature extraction from pairwise conflicts applied to the train rescheduling problem. (arXiv:2204.03061v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Wen Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qingna Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1\">Chunfeng Cui</a>",
          "description": "Adversarial perturbations have drawn great attentions in various deep neural\nnetworks. Most of them are computed by iterations and cannot be interpreted\nvery well. In contrast, little attentions are paid to basic machine learning\nmodels such as support vector machines. In this paper, we investigate the\noptimization models and the interpretations for three types of adversarial\nperturbations against support vector machines, including sample-adversarial\nperturbations (sAP), class-universal adversarial perturbations (cuAP) as well\nas universal adversarial perturbations (uAP). For linear binary/multi\nclassification support vector machines (SVMs), we derive the explicit solutions\nfor sAP, cuAP and uAP (binary case), and approximate solution for uAP of\nmulti-classification. We also obtain the upper bound of fooling rate for uAP.\nSuch results not only increase the interpretability of the three adversarial\nperturbations, but also provide great convenience in computation since\niterative process can be avoided. Numerical results show that our method is\nfast and effective in calculating three types of adversarial perturbations.",
          "link": "http://arxiv.org/abs/2204.03154",
          "publishedOn": "2022-04-09T00:48:55.105Z",
          "wordCount": null,
          "title": "Optimization Models and Interpretations for Three Types of Adversarial Perturbations against Support Vector Machines. (arXiv:2204.03154v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ermolov_A/0/1/0/all/0/1\">Aleksandr Ermolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sangineto_E/0/1/0/all/0/1\">Enver Sangineto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1\">Nicu Sebe</a>",
          "description": "Environments in Reinforcement Learning are usually only partially observable.\nTo address this problem, a possible solution is to provide the agent with\ninformation about the past. However, providing complete observations of\nnumerous steps can be excessive. Inspired by human memory, we propose to\nrepresent history with only important changes in the environment and, in our\napproach, to obtain automatically this representation using self-supervision.\nOur method (TempAl) aligns temporally-close frames, revealing a general, slowly\nvarying state of the environment. This procedure is based on contrastive loss,\nwhich pulls embeddings of nearby observations to each other while pushing away\nother samples from the batch. It can be interpreted as a metric that captures\nthe temporal relations of observations. We propose to combine both common\ninstantaneous and our history representation and we evaluate TempAl on all\navailable Atari games from the Arcade Learning Environment. TempAl surpasses\nthe instantaneous-only baseline in 35 environments out of 49. The source code\nof the method and of all the experiments is available at\nhttps://github.com/htdt/tempal.",
          "link": "http://arxiv.org/abs/2204.03525",
          "publishedOn": "2022-04-09T00:48:55.105Z",
          "wordCount": null,
          "title": "Temporal Alignment for History Representation in Reinforcement Learning. (arXiv:2204.03525v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zongmin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yitian Xu</a>",
          "description": "Direct multi-task twin support vector machine (DMTSVM) explores the shared\ninformation between multiple correlated tasks, then it produces better\ngeneralization performance. However, it contains matrix inversion operation\nwhen solving the dual problems, so it costs much running time. Moreover, kernel\ntrick cannot be directly utilized in the nonlinear case. To effectively avoid\nabove problems, a novel multi-task nonparallel support vector machine (MTNPSVM)\nincluding linear and nonlinear cases is proposed in this paper. By introducing\nepsilon-insensitive loss instead of square loss in DMTSVM, MTNPSVM effectively\navoids matrix inversion operation and takes full advantage of the kernel trick.\nTheoretical implication of the model is further discussed. To further improve\nthe computational efficiency, the alternating direction method of multipliers\n(ADMM) is employed when solving the dual problem. The computational complexity\nand convergence of the algorithm are provided. In addition, the property and\nsensitivity of the parameter in model are further explored. The experimental\nresults on fifteen benchmark datasets and twelve image datasets demonstrate the\nvalidity of MTNPSVM in comparison with the state-of-the-art algorithms.\nFinally, it is applied to real Chinese Wine dataset, and also verifies its\neffectiveness.",
          "link": "http://arxiv.org/abs/2204.02972",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "Multi-task nonparallel support vector machine for classification. (arXiv:2204.02972v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yi Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagduyu_Y/0/1/0/all/0/1\">Yalin E. Sagduyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erpek_T/0/1/0/all/0/1\">Tugba Erpek</a>",
          "description": "NextG networks are intended to provide the flexibility of sharing the\nspectrum with incumbent users and support various spectrum monitoring tasks\nsuch as anomaly detection, fault diagnostics, user equipment identification,\nand authentication. A network of wireless sensors is needed to monitor the\nspectrum for signal transmissions of interest over a large deployment area.\nEach sensor receives signals under a specific channel condition depending on\nits location and trains an individual model of a deep neural network (DNN)\naccordingly to classify signals. To improve the accuracy, individual sensors\nmay exchange sensing data or sensor results with each other or with a fusion\ncenter (such as in cooperative spectrum sensing). In this paper, distributed\nfederated learning over a multi-hop wireless network is considered to\ncollectively train a DNN for signal identification. In distributed federated\nlearning, each sensor broadcasts its trained model to its neighbors, collects\nthe DNN models from its neighbors, and aggregates them to initialize its own\nmodel for the next round of training. Without exchanging any spectrum data,\nthis process is repeated over time such that a common DNN is built across the\nnetwork while preserving the privacy associated with signals collected at\ndifferent locations. Signal classification accuracy and convergence time are\nevaluated for different network topologies (including line, star, ring, grid,\nand random networks) and packet loss events. Then, the reduction of\ncommunication overhead and energy consumption is considered with random\nparticipation of sensors in model updates. The results show the feasibility of\nextending cooperative spectrum sensing over a general multi-hop wireless\nnetwork through federated learning and indicate its robustness to wireless\nnetwork effects, thereby sustaining high accuracy with low communication\noverhead and energy consumption.",
          "link": "http://arxiv.org/abs/2204.03027",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "Federated Learning for Distributed Spectrum Sensing in NextG Communication Networks. (arXiv:2204.03027v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1\">Maria-Florina Balcan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seiler_C/0/1/0/all/0/1\">Christopher Seiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1\">Dravyansh Sharma</a>",
          "description": "Data-driven algorithm configuration is a promising, learning-based approach\nfor beyond worst-case analysis of algorithms with tunable parameters. An\nimportant open problem is the design of efficient data-driven algorithms for\nalgorithm families with more than one parameter. In this work we provide\nalgorithms for efficient (output-polynomial) multidimensional parameter tuning,\ni.e. for families with a small constant number of parameters, for three very\ndifferent combinatorial problems -- linkage-based clustering, dynamic\nprogramming for sequence alignment, and auction design for two-part tariff\nschemes. We extend the single-parameter clustering algorithm of Balcan et al.\n2020 arXiv:1907.00533 to multiple parameters and to the sequence alignment\nproblem by proposing an execution graph which compactly represents all the\nstates the algorithm could attain for all possible parameter values. A key\nproblem-specific challenge is to efficiently compute how the partition of the\nparameter space (into regions with unique algorithmic states) changes with a\nsingle algorithmic step. We give algorithms which improve on the runtime of\npreviously best known results for linkage-based clustering, sequence alignment\nand two-part tariff pricing.",
          "link": "http://arxiv.org/abs/2204.03569",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "Faster algorithms for learning to link, align sequences, and price two-part tariffs. (arXiv:2204.03569v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1\">Leon Bottou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>",
          "description": "Regularization is a fundamental technique to prevent over-fitting and to\nimprove generalization performances by constraining a model's complexity.\nCurrent Deep Networks heavily rely on regularizers such as Data-Augmentation\n(DA) or weight-decay, and employ structural risk minimization, i.e.\ncross-validation, to select the optimal regularization hyper-parameters. In\nthis study, we demonstrate that techniques such as DA or weight decay produce a\nmodel with a reduced complexity that is unfair across classes. The optimal\namount of DA or weight decay found from cross-validation leads to disastrous\nmodel performances on some classes e.g. on Imagenet with a resnet50, the \"barn\nspider\" classification test accuracy falls from $68\\%$ to $46\\%$ only by\nintroducing random crop DA during training. Even more surprising, such\nperformance drop also appears when introducing uninformative regularization\ntechniques such as weight decay. Those results demonstrate that our search for\never increasing generalization performance -- averaged over all classes and\nsamples -- has left us with models and regularizers that silently sacrifice\nperformances on some classes. This scenario can become dangerous when deploying\na model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on\nINaturalist sees its performances fall from $70\\%$ to $30\\%$ on class \\#8889\nwhen introducing random crop DA during the Imagenet pre-training phase. Those\nresults demonstrate that designing novel regularizers without class-dependent\nbias remains an open research question.",
          "link": "http://arxiv.org/abs/2204.03632",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "The Effects of Regularization and Data Augmentation are Class Dependent. (arXiv:2204.03632v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Shashank Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaonkar_R/0/1/0/all/0/1\">Radhika Gaonkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chongyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1\">Soroush Vosoughi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>",
          "description": "Pre-trained language models (LMs) have been shown to memorize a substantial\namount of knowledge from the pre-training corpora; however, they are still\nlimited in recalling factually correct knowledge given a certain context.\nHence, they tend to suffer from counterfactual or hallucinatory generation when\nused in knowledge-intensive natural language generation (NLG) tasks. Recent\nremedies to this problem focus on modifying either the pre-training or task\nfine-tuning objectives to incorporate knowledge, which normally require\nadditional costly training or architecture modification of LMs for practical\napplications. We present Knowledge Infused Decoding (KID) -- a novel decoding\nalgorithm for generative LMs, which dynamically infuses external knowledge into\neach step of the LM decoding. Specifically, we maintain a local knowledge\nmemory based on the current context, interacting with a dynamically created\nexternal knowledge trie, and continuously update the local memory as a\nknowledge-aware constraint to guide decoding via reinforcement learning. On six\ndiverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART)\narmed with KID outperform many task-optimized state-of-the-art models, and show\nparticularly strong performance in few-shot scenarios over seven related\nknowledge-infusion techniques. Human evaluation confirms KID's ability to\ngenerate more relevant and factual language for the input context when compared\nwith multiple baselines. Finally, KID also alleviates exposure bias and\nprovides stable generation quality when generating longer sequences. Code for\nKID is available at https://github.com/microsoft/KID.",
          "link": "http://arxiv.org/abs/2204.03084",
          "publishedOn": "2022-04-09T00:48:55.103Z",
          "wordCount": null,
          "title": "Knowledge Infused Decoding. (arXiv:2204.03084v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Ming Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamura_T/0/1/0/all/0/1\">Toshiyo Tamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ono_N/0/1/0/all/0/1\">Naoaki Ono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altaf_Ul_Amin_M/0/1/0/all/0/1\">MD Altaf-Ul-Amin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanaya_S/0/1/0/all/0/1\">Shigehiko Kanaya</a>",
          "description": "Considering the natural frequency characteristics in sleep medicine, this\npaper first proposes a time-frequency framework for the representation learning\nof the electroencephalogram (EEG) following the definition of the American\nAcademy of Sleep Medicine. To meet the temporal-random and transient nature of\nthe defining characteristics of sleep stages, we further design a\ncontext-sensitive flexible pipeline that automatically adapts to the attributes\nof data itself. That is, the input EEG spectrogram is partitioned into a\nsequence of patches in the time and frequency axes, and then input to a\ndelicate deep learning network for further representation learning to extract\nthe stage-dependent features, which are used in the classification step\nfinally. The proposed pipeline is validated against a large database, i.e., the\nSleep Heart Health Study (SHHS), and the results demonstrate that the\ncompetitive performance for the wake, N2, and N3 stages outperforms the\nstate-of-art works, with the F1 scores being 0.93, 0.88, and 0.87,\nrespectively, and the proposed method has a high inter-rater reliability of\n0.80 kappa. Importantly, we visualize the stage scoring process of the model\ndecision with the Layer-wise Relevance Propagation (LRP) method, which shows\nthat the proposed pipeline is more sensitive and perceivable in the\ndecision-making process than the baseline pipelines. Therefore, the pipeline\ntogether with the LRP method can provide better model interpretability, which\nis important for clinical support.",
          "link": "http://arxiv.org/abs/2204.03173",
          "publishedOn": "2022-04-09T00:48:55.103Z",
          "wordCount": null,
          "title": "Enhancement on Model Interpretability and Sleep Stage Scoring Performance with A Novel Pipeline Based on Deep Neural Network. (arXiv:2204.03173v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1\">Jonathan Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salimans_T/0/1/0/all/0/1\">Tim Salimans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gritsenko_A/0/1/0/all/0/1\">Alexey Gritsenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1\">William Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1\">Mohammad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1\">David J. Fleet</a>",
          "description": "Generating temporally coherent high fidelity video is an important milestone\nin generative modeling research. We make progress towards this milestone by\nproposing a diffusion model for video generation that shows very promising\ninitial results. Our model is a natural extension of the standard image\ndiffusion architecture, and it enables jointly training from image and video\ndata, which we find to reduce the variance of minibatch gradients and speed up\noptimization. To generate long and higher resolution videos we introduce a new\nconditional sampling technique for spatial and temporal video extension that\nperforms better than previously proposed methods. We present the first results\non a large text-conditioned video generation task, as well as state-of-the-art\nresults on an established unconditional video generation benchmark.\nSupplementary material is available at https://video-diffusion.github.io/",
          "link": "http://arxiv.org/abs/2204.03458",
          "publishedOn": "2022-04-09T00:48:55.102Z",
          "wordCount": null,
          "title": "Video Diffusion Models. (arXiv:2204.03458v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yanyong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1\">Kejun Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiuwen Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianrui Li</a>",
          "description": "Multi-view unsupervised feature selection has been proven to be efficient in\nreducing the dimensionality of multi-view unlabeled data with high dimensions.\nThe previous methods assume all of the views are complete. However, in real\napplications, the multi-view data are often incomplete, i.e., some views of\ninstances are missing, which will result in the failure of these methods.\nBesides, while the data arrive in form of streams, these existing methods will\nsuffer the issues of high storage cost and expensive computation time. To\naddress these issues, we propose an Incremental Incomplete Multi-view\nUnsupervised Feature Selection method (I$^2$MUFS) on incomplete multi-view\nstreaming data. By jointly considering the consistent and complementary\ninformation across different views, I$^2$MUFS embeds the unsupervised feature\nselection into an extended weighted non-negative matrix factorization model,\nwhich can learn a consensus clustering indicator matrix and fuse different\nlatent feature matrices with adaptive view weights. Furthermore, we introduce\nthe incremental leaning mechanisms to develop an alternative iterative\nalgorithm, where the feature selection matrix is incrementally updated, rather\nthan recomputing on the entire updated data from scratch. A series of\nexperiments are conducted to verify the effectiveness of the proposed method by\ncomparing with several state-of-the-art methods. The experimental results\ndemonstrate the effectiveness and efficiency of the proposed method in terms of\nthe clustering metrics and the computational cost.",
          "link": "http://arxiv.org/abs/2204.02973",
          "publishedOn": "2022-04-09T00:48:55.002Z",
          "wordCount": null,
          "title": "Incremental Unsupervised Feature Selection for Dynamic Incomplete Multi-view Data. (arXiv:2204.02973v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_E/0/1/0/all/0/1\">Ensheng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gub_W/0/1/0/all/0/1\">Wenchao Gub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hongbin Sun</a>",
          "description": "Code search aims to retrieve the most semantically relevant code snippet for\na given natural language query. Recently, large-scale code pre-trained models\nsuch as CodeBERT and GraphCodeBERT learn generic representations of source code\nand have achieved substantial improvement on code search task. However, the\nhigh-quality sequence-level representations of code snippets have not been\nsufficiently explored. In this paper, we propose a new approach with multimodal\ncontrastive learning and soft data augmentation for code search. Multimodal\ncontrastive learning is used to pull together the representations of code-query\npairs and push apart the unpaired code snippets and queries. Moreover, data\naugmentation is critical in contrastive learning for learning high-quality\nrepresentations. However, only semantic-preserving augmentations for source\ncode are considered in existing work. In this work, we propose to do soft data\naugmentation by dynamically masking and replacing some tokens in code sequences\nto generate code snippets that are similar but not necessarily\nsemantic-preserving as positive samples for paired queries. We conduct\nextensive experiments to evaluate the effectiveness of our approach on a\nlarge-scale dataset with six programming languages. The experimental results\nshow that our approach significantly outperforms the state-of-the-art methods.\nWe also adapt our techniques to several pre-trained models such as RoBERTa and\nCodeBERT, and significantly boost their performance on the code search task.",
          "link": "http://arxiv.org/abs/2204.03293",
          "publishedOn": "2022-04-09T00:48:55.002Z",
          "wordCount": null,
          "title": "Enhancing Semantic Code Search with Multimodal Contrastive Learning and Soft Data Augmentation. (arXiv:2204.03293v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klapsas_K/0/1/0/all/0/1\">Konstantinos Klapsas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellinas_N/0/1/0/all/0/1\">Nikolaos Ellinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikitaras_K/0/1/0/all/0/1\">Karolos Nikitaras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vamvoukakis_G/0/1/0/all/0/1\">Georgios Vamvoukakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakoulidis_P/0/1/0/all/0/1\">Panos Kakoulidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markopoulos_K/0/1/0/all/0/1\">Konstantinos Markopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raptis_S/0/1/0/all/0/1\">Spyros Raptis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_J/0/1/0/all/0/1\">June Sig Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jho_G/0/1/0/all/0/1\">Gunu Jho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalamandaris_A/0/1/0/all/0/1\">Aimilios Chalamandaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsiakoulis_P/0/1/0/all/0/1\">Pirros Tsiakoulis</a>",
          "description": "Voice cloning is a difficult task which requires robust and informative\nfeatures incorporated in a high quality TTS system in order to effectively copy\nan unseen speaker's voice. In our work, we utilize features learned in a\nself-supervised framework via the Bootstrap Your Own Latent (BYOL) method,\nwhich is shown to produce high quality speech representations when specific\naudio augmentations are applied to the vanilla algorithm. We further extend the\naugmentations in the training procedure to aid the resulting features to\ncapture the speaker identity and to make them robust to noise and acoustic\nconditions. The learned features are used as pre-trained utterance-level\nembeddings and as inputs to a Non-Attentive Tacotron based architecture, aiming\nto achieve multispeaker speech synthesis without utilizing additional speaker\nfeatures. This method enables us to train our model in an unlabeled\nmultispeaker dataset as well as use unseen speaker embeddings to copy a\nspeaker's voice. Subjective and objective evaluations are used to validate the\nproposed model, as well as the robustness to the acoustic conditions of the\ntarget utterance.",
          "link": "http://arxiv.org/abs/2204.03421",
          "publishedOn": "2022-04-09T00:48:55.002Z",
          "wordCount": null,
          "title": "Self supervised learning for robust voice cloning. (arXiv:2204.03421v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03565",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhu_L/0/1/0/all/0/1\">Lingwei Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Odani_K/0/1/0/all/0/1\">Koki Odani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Ziwei Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_G/0/1/0/all/0/1\">Guang Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kan_Y/0/1/0/all/0/1\">Yirong Kan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_R/0/1/0/all/0/1\">Renyuan Zhang</a>",
          "description": "Recently there has seen promising results on automatic stage scoring by\nextracting spatio-temporal features from electroencephalogram (EEG). Such\nmethods entail laborious manual feature engineering and domain knowledge. In\nthis study, we propose an adaptive scheme to probabilistically encode, filter\nand accumulate the input signals and weight the resultant features by the\nhalf-Gaussian probabilities of signal intensities. The adaptive representations\nare subsequently fed into a transformer model to automatically mine the\nrelevance between features and corresponding stages. Extensive experiments on\nthe largest public dataset against state-of-the-art methods validate the\neffectiveness of our proposed method and reveal promising future directions.",
          "link": "http://arxiv.org/abs/2204.03565",
          "publishedOn": "2022-04-09T00:48:55.001Z",
          "wordCount": null,
          "title": "Adaptive Spike-Like Representation of EEG Signals for Sleep Stages Scoring. (arXiv:2204.03565v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03125",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Niu_K/0/1/0/all/0/1\">Kaicheng Niu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_M/0/1/0/all/0/1\">Mi Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abdallah_C/0/1/0/all/0/1\">Chaouki T. Abdallah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hayajneh_M/0/1/0/all/0/1\">Mohammad Hayajneh</a>",
          "description": "Recurrent neural networks (RNNs) have many advantages over more traditional\nsystem identification techniques. They may be applied to linear and nonlinear\nsystems, and they require fewer modeling assumptions. However, these neural\nnetwork models may also need larger amounts of data to learn and generalize.\nFurthermore, neural networks training is a time-consuming process. Hence,\nbuilding upon long-short term memory neural networks (LSTM), this paper\nproposes using two types of deep transfer learning, namely parameter\nfine-tuning and freezing, to reduce the data and computation requirements for\nsystem identification. We apply these techniques to identify two dynamical\nsystems, namely a second-order linear system and a Wiener-Hammerstein nonlinear\nsystem. Results show that compared with direct learning, our method accelerates\nlearning by 10% to 50%, which also saves data and computing resources.",
          "link": "http://arxiv.org/abs/2204.03125",
          "publishedOn": "2022-04-09T00:48:54.812Z",
          "wordCount": null,
          "title": "Deep transfer learning for system identification using long short-term memory neural networks. (arXiv:2204.03125v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.00116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciolino_M/0/1/0/all/0/1\">Matthew Ciolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hambrick_D/0/1/0/all/0/1\">Dominick Hambrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1\">David Noever</a>",
          "description": "The sensor to shooter timeline is affected by two main variables: satellite\npositioning and asset positioning. Speeding up satellite positioning by adding\nmore sensors or by decreasing processing time is important only if there is a\nprepared shooter, otherwise the main source of time is getting the shooter into\nposition. However, the intelligence community should work towards the\nexploitation of sensors to the highest speed and effectiveness possible.\nAchieving a high effectiveness while keeping speed high is a tradeoff that must\nbe considered in the sensor to shooter timeline. In this paper we investigate\ntwo main ideas, increasing the effectiveness of satellite imagery through image\nmanipulation and how on-board image manipulation would affect the sensor to\nshooter timeline. We cover these ideas in four scenarios: Discrete Event\nSimulation of onboard processing versus ground station processing, quality of\ninformation with cloud cover removal, information improvement with super\nresolution, and data reduction with image to caption. This paper will show how\nimage manipulation techniques such as Super Resolution, Cloud Removal, and\nImage to Caption will improve the quality of delivered information in addition\nto showing how those processes effect the sensor to shooter timeline.",
          "link": "http://arxiv.org/abs/2203.00116",
          "publishedOn": "2022-04-03T00:52:40.822Z",
          "wordCount": 682,
          "title": "Enhancing Satellite Imagery using Deep Learning for the Sensor To Shooter Timeline. (arXiv:2203.00116v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nitzan_Y/0/1/0/all/0/1\">Yotam Nitzan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aberman_K/0/1/0/all/0/1\">Kfir Aberman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qiurui He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liba_O/0/1/0/all/0/1\">Orly Liba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yarom_M/0/1/0/all/0/1\">Michal Yarom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gandelsman_Y/0/1/0/all/0/1\">Yossi Gandelsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mosseri_I/0/1/0/all/0/1\">Inbar Mosseri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pritch_Y/0/1/0/all/0/1\">Yael Pritch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_or_D/0/1/0/all/0/1\">Daniel Cohen-or</a>",
          "description": "We introduce MyStyle, a personalized deep generative prior trained with a few\nshots of an individual. MyStyle allows to reconstruct, enhance and edit images\nof a specific person, such that the output is faithful to the person's key\nfacial characteristics. Given a small reference set of portrait images of a\nperson (~100), we tune the weights of a pretrained StyleGAN face generator to\nform a local, low-dimensional, personalized manifold in the latent space. We\nshow that this manifold constitutes a personalized region that spans latent\ncodes associated with diverse portrait images of the individual. Moreover, we\ndemonstrate that we obtain a personalized generative prior, and propose a\nunified approach to apply it to various ill-posed image enhancement problems,\nsuch as inpainting and super-resolution, as well as semantic editing. Using the\npersonalized generative prior we obtain outputs that exhibit high-fidelity to\nthe input images and are also faithful to the key facial characteristics of the\nindividual in the reference set. We demonstrate our method with fair-use images\nof numerous widely recognizable individuals for whom we have the prior\nknowledge for a qualitative evaluation of the expected outcome. We evaluate our\napproach against few-shots baselines and show that our personalized prior,\nquantitatively and qualitatively, outperforms state-of-the-art alternatives.",
          "link": "http://arxiv.org/abs/2203.17272",
          "publishedOn": "2022-04-02T00:47:22.631Z",
          "wordCount": 665,
          "title": "MyStyle: A Personalized Generative Prior. (arXiv:2203.17272v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.06159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hessel_M/0/1/0/all/0/1\">Matteo Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danihelka_I/0/1/0/all/0/1\">Ivo Danihelka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viola_F/0/1/0/all/0/1\">Fabio Viola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guez_A/0/1/0/all/0/1\">Arthur Guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmitt_S/0/1/0/all/0/1\">Simon Schmitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sifre_L/0/1/0/all/0/1\">Laurent Sifre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_T/0/1/0/all/0/1\">Theophane Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silver_D/0/1/0/all/0/1\">David Silver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasselt_H/0/1/0/all/0/1\">Hado van Hasselt</a>",
          "description": "We propose a novel policy update that combines regularized policy\noptimization with model learning as an auxiliary loss. The update (henceforth\nMuesli) matches MuZero's state-of-the-art performance on Atari. Notably, Muesli\ndoes so without using deep search: it acts directly with a policy network and\nhas computation speed comparable to model-free baselines. The Atari results are\ncomplemented by extensive ablations, and by additional results on continuous\ncontrol and 9x9 Go.",
          "link": "http://arxiv.org/abs/2104.06159",
          "publishedOn": "2022-04-02T00:47:22.555Z",
          "wordCount": 544,
          "title": "Muesli: Combining Improvements in Policy Optimization. (arXiv:2104.06159v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17218",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chaubey_A/0/1/0/all/0/1\">Ashutosh Chaubey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sinha_S/0/1/0/all/0/1\">Sparsh Sinha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ghose_S/0/1/0/all/0/1\">Susmita Ghose</a>",
          "description": "Speaker identification systems in a real-world scenario are tasked to\nidentify a speaker amongst a set of enrolled speakers given just a few samples\nfor each enrolled speaker. This paper demonstrates the effectiveness of\nmeta-learning and relation networks for this use case. We propose improved\nrelation networks for speaker verification and few-shot (unseen) speaker\nidentification. The use of relation networks facilitates joint training of the\nfrontend speaker encoder and the backend model. Inspired by the use of\nprototypical networks in speaker verification and to increase the\ndiscriminability of the speaker embeddings, we train the model to classify\nsamples in the current episode amongst all speakers present in the training\nset. Furthermore, we propose a new training regime for faster model convergence\nby extracting more information from a given meta-learning episode with\nnegligible extra computation. We evaluate the proposed techniques on VoxCeleb,\nSITW and VCTK datasets on the tasks of speaker verification and unseen speaker\nidentification. The proposed approach outperforms the existing approaches\nconsistently on both tasks.",
          "link": "http://arxiv.org/abs/2203.17218",
          "publishedOn": "2022-04-02T00:47:22.447Z",
          "wordCount": 618,
          "title": "Improved Relation Networks for End-to-End Speaker Verification and Identification. (arXiv:2203.17218v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.04488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nowroozi_E/0/1/0/all/0/1\">Ehsan Nowroozi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mekdad_Y/0/1/0/all/0/1\">Yassine Mekdad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berenjestanaki_M/0/1/0/all/0/1\">Mohammad Hajian Berenjestanaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1\">Mauro Conti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fergougui_A/0/1/0/all/0/1\">Abdeslam EL Fergougui</a>",
          "description": "Convolutional Neural Networks (CNNs) models are one of the most frequently\nused deep learning networks, and extensively used in both academia and\nindustry. Recent studies demonstrated that adversarial attacks against such\nmodels can maintain their effectiveness even when used on models other than the\none targeted by the attacker. This major property is known as transferability,\nand makes CNNs ill-suited for security applications. In this paper, we provide\nthe first comprehensive study which assesses the robustness of CNN-based models\nfor computer networks against adversarial transferability. Furthermore, we\ninvestigate whether the transferability property issue holds in computer\nnetworks applications. In our experiments, we first consider five different\nattacks: the Iterative Fast Gradient Method (I-FGSM), the Jacobian-based\nSaliency Map (JSMA), the Limited-memory Broyden Fletcher Goldfarb Shanno BFGS\n(L- BFGS), the Projected Gradient Descent (PGD), and the DeepFool attack. Then,\nwe perform these attacks against three well- known datasets: the Network-based\nDetection of IoT (N-BaIoT) dataset, the Domain Generating Algorithms (DGA)\ndataset, and the RIPE Atlas dataset. Our experimental results show clearly that\nthe transferability happens in specific use cases for the I- FGSM, the JSMA,\nand the LBFGS attack. In such scenarios, the attack success rate on the target\nnetwork range from 63.00% to 100%. Finally, we suggest two shielding strategies\nto hinder the attack transferability, by considering the Most Powerful Attacks\n(MPAs), and the mismatch LSTM architecture.",
          "link": "http://arxiv.org/abs/2110.04488",
          "publishedOn": "2022-04-02T00:47:22.395Z",
          "wordCount": 726,
          "title": "Demystifying the Transferability of Adversarial Attacks in Computer Networks. (arXiv:2110.04488v3 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.01863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamansavascilar_B/0/1/0/all/0/1\">Baris Yamansavascilar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baktir_A/0/1/0/all/0/1\">Ahmet Cihat Baktir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonmez_C/0/1/0/all/0/1\">Cagatay Sonmez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozgovde_A/0/1/0/all/0/1\">Atay Ozgovde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ersoy_C/0/1/0/all/0/1\">Cem Ersoy</a>",
          "description": "The improvements in the edge computing technology pave the road for\ndiversified applications that demand real-time interaction. However, due to the\nmobility of the end-users and the dynamic edge environment, it becomes\nchallenging to handle the task offloading with high performance. Moreover,\nsince each application in mobile devices has different characteristics, a task\norchestrator must be adaptive and have the ability to learn the dynamics of the\nenvironment. For this purpose, we develop a deep reinforcement learning based\ntask orchestrator, DeepEdge, which learns to meet different task requirements\nwithout needing human interaction even under the heavily-loaded stochastic\nnetwork conditions in terms of mobile users and applications. Given the dynamic\noffloading requests and time-varying communication conditions, we successfully\nmodel the problem as a Markov process and then apply the Double Deep Q-Network\n(DDQN) algorithm to implement DeepEdge. To evaluate the robustness of DeepEdge,\nwe experiment with four different applications including image rendering,\ninfotainment, pervasive health, and augmented reality in the network under\nvarious loads. Furthermore, we compare the performance of our agent with the\nfour different task offloading approaches in the literature. Our results show\nthat DeepEdge outperforms its competitors in terms of the percentage of\nsatisfactorily completed tasks.",
          "link": "http://arxiv.org/abs/2110.01863",
          "publishedOn": "2022-04-02T00:47:22.386Z",
          "wordCount": 692,
          "title": "DeepEdge: A Deep Reinforcement Learning based Task Orchestrator for Edge Computing. (arXiv:2110.01863v2 [cs.NI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.16712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1\">Thomas M. Moerland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broekens_J/0/1/0/all/0/1\">Joost Broekens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>",
          "description": "Sequential decision making, commonly formalized as Markov Decision Process\n(MDP) optimization, is a important challenge in artificial intelligence. Two\nkey approaches to this problem are reinforcement learning (RL) and planning.\nThis paper presents a survey of the integration of both fields, better known as\nmodel-based reinforcement learning. Model-based RL has two main steps. First,\nwe systematically cover approaches to dynamics model learning, including\nchallenges like dealing with stochasticity, uncertainty, partial observability,\nand temporal abstraction. Second, we present a systematic categorization of\nplanning-learning integration, including aspects like: where to start planning,\nwhat budgets to allocate to planning and real data collection, how to plan, and\nhow to integrate planning in the learning and acting loop. After these two\nsections, we also discuss implicit model-based RL as an end-to-end alternative\nfor model learning and planning, and we cover the potential benefits of\nmodel-based RL. Along the way, the survey also draws connections to several\nrelated RL fields, like hierarchical RL and transfer learning. Altogether, the\nsurvey presents a broad conceptual overview of the combination of planning and\nlearning for MDP optimization.",
          "link": "http://arxiv.org/abs/2006.16712",
          "publishedOn": "2022-04-02T00:47:22.362Z",
          "wordCount": 665,
          "title": "Model-based Reinforcement Learning: A Survey. (arXiv:2006.16712v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yanbo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yueqin Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qianyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chengyao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1\">Bo Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wayne Wu</a>",
          "description": "Recent advances like StyleGAN have promoted the growth of controllable facial\nediting. To address its core challenge of attribute decoupling in a single\nlatent space, attempts have been made to adopt dual-space GAN for better\ndisentanglement of style and content representations. Nonetheless, these\nmethods are still incompetent to obtain plausible editing results with high\ncontrollability, especially for complicated attributes. In this study, we\nhighlight the importance of interaction in a dual-space GAN for more\ncontrollable editing. We propose TransEditor, a novel Transformer-based\nframework to enhance such interaction. Besides, we develop a new dual-space\nediting and inversion strategy to provide additional editing flexibility.\nExtensive experiments demonstrate the superiority of the proposed framework in\nimage quality and editing capability, suggesting the effectiveness of\nTransEditor for highly controllable facial editing.",
          "link": "http://arxiv.org/abs/2203.17266",
          "publishedOn": "2022-04-02T00:47:22.354Z",
          "wordCount": 593,
          "title": "TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing. (arXiv:2203.17266v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.15009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1\">Thomas M. Moerland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broekens_J/0/1/0/all/0/1\">Joost Broekens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>",
          "description": "Sequential decision making, commonly formalized as optimization of a Markov\nDecision Process, is a key challenge in artificial intelligence. Two successful\napproaches to MDP optimization are reinforcement learning and planning, which\nboth largely have their own research communities. However, if both research\nfields solve the same problem, then we might be able to disentangle the common\nfactors in their solution approaches. Therefore, this paper presents a unifying\nalgorithmic framework for reinforcement learning and planning (FRAP), which\nidentifies underlying dimensions on which MDP planning and learning algorithms\nhave to decide. At the end of the paper, we compare a variety of well-known\nplanning, model-free and model-based RL algorithms along these dimensions.\nAltogether, the framework may help provide deeper insight in the algorithmic\ndesign space of planning and reinforcement learning.",
          "link": "http://arxiv.org/abs/2006.15009",
          "publishedOn": "2022-04-02T00:47:22.346Z",
          "wordCount": 623,
          "title": "A Unifying Framework for Reinforcement Learning and Planning. (arXiv:2006.15009v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.11821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McLaughlin_N/0/1/0/all/0/1\">Niall McLaughlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rincon_J/0/1/0/all/0/1\">Jesus Martinez del Rincon</a>",
          "description": "In this paper we study data augmentation for opcode sequence based Android\nmalware detection. Data augmentation has been successfully used in many areas\nof deep-learning to significantly improve model performance. Typically, data\naugmentation simulates realistic variations in data to increase the apparent\ndiversity of the training-set. However, for opcode-based malware analysis it is\nnot immediately clear how to apply data augmentation. Hence we first study the\nuse of fixed transformations, then progress to adaptive methods. We propose a\nnovel data augmentation method -- Self-Embedding Language Model Augmentation --\nthat uses a malware detection network's own opcode embedding layer to measure\nopcode similarity for adaptive augmentation. To the best of our knowledge this\nis the first paper to carry out a systematic study of different augmentation\nmethods for opcode sequence based Android malware classification.",
          "link": "http://arxiv.org/abs/2106.11821",
          "publishedOn": "2022-04-02T00:47:22.338Z",
          "wordCount": 605,
          "title": "Data Augmentation for Opcode Sequence Based Malware Detection. (arXiv:2106.11821v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.12558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1\">Constantinos Daskalakis</a>",
          "description": "Machine learning has developed a variety of tools for learning and\nrepresenting high-dimensional distributions with structure. Recent years have\nalso seen big advances in designing multi-item mechanisms. Akin to overfitting,\nhowever, these mechanisms can be extremely sensitive to the Bayesian prior that\nthey target, which becomes problematic when that prior is only approximately\nknown. At the same time, even if access to the exact Bayesian prior is given,\nit is known that optimal or even approximately optimal multi-item mechanisms\nrun into sample, computational, representation and communication intractability\nbarriers.\n\nWe consider a natural class of multi-item mechanism design problems with very\nlarge numbers of items, but where the bidders' value distributions can be\nwell-approximated by a topic model akin to those used in recommendation systems\nwith very large numbers of possible recommendations. We propose a mechanism\ndesign framework for this setting, building on a recent robustification\nframework by Brustle et al., which disentangles the statistical challenge of\nestimating a multi-dimensional prior from the task of designing a good\nmechanism for it, and robustifies the performance of the latter against the\nestimation error of the former. We provide an extension of this framework\nappropriate for our setting, which allows us to exploit the expressive power of\ntopic models to reduce the effective dimensionality of the mechanism design\nproblem and remove the dependence of its computational, communication and\nrepresentation complexity on the number of items.",
          "link": "http://arxiv.org/abs/2110.12558",
          "publishedOn": "2022-04-02T00:47:22.316Z",
          "wordCount": 702,
          "title": "Recommender Systems meet Mechanism Design. (arXiv:2110.12558v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.11956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin-Chun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yunfeng Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bingshuai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shaoming Song</a>",
          "description": "Automatically mining sentiment tendency contained in natural language is a\nfundamental research to some artificial intelligent applications, where\nsolutions alternate with challenges. Transfer learning and multi-task learning\ntechniques have been leveraged to mitigate the supervision sparsity and\ncollaborate multiple heterogeneous domains correspondingly. Recent years, the\nsensitive nature of users' private data raises another challenge for sentiment\nclassification, i.e., data privacy protection. In this paper, we resort to\nfederated learning for multiple domain sentiment classification under the\nconstraint that the corpora must be stored on decentralized devices. In view of\nthe heterogeneous semantics across multiple parties and the peculiarities of\nword embedding, we pertinently provide corresponding solutions. First, we\npropose a Knowledge Transfer Enhanced Private-Shared (KTEPS) framework for\nbetter model aggregation and personalization in federated sentiment\nclassification. Second, we propose KTEPS$^\\star$ with the consideration of the\nrich semantic and huge embedding size properties of word vectors, utilizing\nProjection-based Dimension Reduction (PDR) methods for privacy protection and\nefficient transmission simultaneously. We propose two federated sentiment\nclassification scenes based on public benchmarks, and verify the superiorities\nof our proposed methods with abundant experimental investigations.",
          "link": "http://arxiv.org/abs/2107.11956",
          "publishedOn": "2022-04-02T00:47:22.309Z",
          "wordCount": 646,
          "title": "Preliminary Steps Towards Federated Sentiment Classification. (arXiv:2107.11956v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.06053",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galhotra_S/0/1/0/all/0/1\">Sainyam Galhotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1\">Prasanna Sattigeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1\">Kush R. Varshney</a>",
          "description": "The use of machine learning (ML) in high-stakes societal decisions has\nencouraged the consideration of fairness throughout the ML lifecycle. Although\ndata integration is one of the primary steps to generate high quality training\ndata, most of the fairness literature ignores this stage. In this work, we\nconsider fairness in the integration component of data management, aiming to\nidentify features that improve prediction without adding any bias to the\ndataset. We work under the causal interventional fairness paradigm. Without\nrequiring the underlying structural causal model a priori, we propose an\napproach to identify a sub-collection of features that ensure the fairness of\nthe dataset by performing conditional independence tests between different\nsubsets of features. We use group testing to improve the complexity of the\napproach. We theoretically prove the correctness of the proposed algorithm to\nidentify features that ensure interventional fairness and show that sub-linear\nconditional independence tests are sufficient to identify these variables. A\ndetailed empirical evaluation is performed on real-world datasets to\ndemonstrate the efficacy and efficiency of our technique.",
          "link": "http://arxiv.org/abs/2006.06053",
          "publishedOn": "2022-04-02T00:47:22.302Z",
          "wordCount": 653,
          "title": "Causal Feature Selection for Algorithmic Fairness. (arXiv:2006.06053v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.04184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Ziang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1\">Song Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>",
          "description": "Multi-agent reinforcement learning has made substantial empirical progresses\nin solving games with a large number of players. However, theoretically, the\nbest known sample complexity for finding a Nash equilibrium in general-sum\ngames scales exponentially in the number of players due to the size of the\njoint action space, and there is a matching exponential lower bound. This paper\ninvestigates what learning goals admit better sample complexities in the\nsetting of $m$-player general-sum Markov games with $H$ steps, $S$ states, and\n$A_i$ actions per player. First, we design algorithms for learning an\n$\\epsilon$-Coarse Correlated Equilibrium (CCE) in\n$\\widetilde{\\mathcal{O}}(H^5S\\max_{i\\le m} A_i / \\epsilon^2)$ episodes, and an\n$\\epsilon$-Correlated Equilibrium (CE) in\n$\\widetilde{\\mathcal{O}}(H^6S\\max_{i\\le m} A_i^2 / \\epsilon^2)$ episodes. This\nis the first line of results for learning CCE and CE with sample complexities\npolynomial in $\\max_{i\\le m} A_i$. Our algorithm for learning CE integrates an\nadversarial bandit subroutine which minimizes a weighted swap regret, along\nwith several novel designs in the outer loop. Second, we consider the important\nspecial case of Markov Potential Games, and design an algorithm that learns an\n$\\epsilon$-approximate Nash equilibrium within\n$\\widetilde{\\mathcal{O}}(S\\sum_{i\\le m} A_i / \\epsilon^3)$ episodes (when only\nhighlighting the dependence on $S$, $A_i$, and $\\epsilon$), which only depends\nlinearly in $\\sum_{i\\le m} A_i$ and significantly improves over existing\nefficient algorithm in the $\\epsilon$ dependence. Overall, our results shed\nlight on what equilibria or structural assumptions on the game may enable\nsample-efficient learning with many players.",
          "link": "http://arxiv.org/abs/2110.04184",
          "publishedOn": "2022-04-02T00:47:22.294Z",
          "wordCount": 719,
          "title": "When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?. (arXiv:2110.04184v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.13492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Viet-Anh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh H. T. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khong_A/0/1/0/all/0/1\">Andy W. H. Khong</a>",
          "description": "We introduce a block-online variant of the temporal feature-wise linear\nmodulation (TFiLM) model to achieve bandwidth extension. The proposed\narchitecture simplifies the UNet backbone of the TFiLM to reduce inference time\nand employs an efficient transformer at the bottleneck to alleviate performance\ndegradation. We also utilize self-supervised pretraining and data augmentation\nto enhance the quality of bandwidth extended signals and reduce the sensitivity\nwith respect to downsampling methods. Experiment results on the VCTK dataset\nshow that the proposed method outperforms several recent baselines in both\nintrusive and non-intrusive metrics. Pretraining and filter augmentation also\nhelp stabilize and enhance the overall performance.",
          "link": "http://arxiv.org/abs/2110.13492",
          "publishedOn": "2022-04-02T00:47:22.286Z",
          "wordCount": 607,
          "title": "TUNet: A Block-online Bandwidth Extension Model based on Transformers and Self-supervised Pretraining. (arXiv:2110.13492v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.04605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chunlin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1\">Daoyi Dong</a>",
          "description": "Evolution strategies (ES), as a family of black-box optimization algorithms,\nrecently emerge as a scalable alternative to reinforcement learning (RL)\napproaches such as Q-learning or policy gradient, and are much faster when many\ncentral processing units (CPUs) are available due to better parallelization. In\nthis paper, we propose a systematic incremental learning method for ES in\ndynamic environments. The goal is to adjust previously learned policy to a new\none incrementally whenever the environment changes. We incorporate an instance\nweighting mechanism with ES to facilitate its learning adaptation, while\nretaining scalability of ES. During parameter updating, higher weights are\nassigned to instances that contain more new knowledge, thus encouraging the\nsearch distribution to move towards new promising areas of parameter space. We\npropose two easy-to-implement metrics to calculate the weights: instance\nnovelty and instance quality. Instance novelty measures an instance's\ndifference from the previous optimum in the original environment, while\ninstance quality corresponds to how well an instance performs in the new\nenvironment. The resulting algorithm, Instance Weighted Incremental Evolution\nStrategies (IW-IES), is verified to achieve significantly improved performance\non challenging RL tasks ranging from robot navigation to locomotion. This paper\nthus introduces a family of scalable ES algorithms for RL domains that enables\nrapid learning adaptation to dynamic environments.",
          "link": "http://arxiv.org/abs/2010.04605",
          "publishedOn": "2022-04-02T00:47:22.258Z",
          "wordCount": 711,
          "title": "Instance Weighted Incremental Evolution Strategies for Reinforcement Learning in Dynamic Environments. (arXiv:2010.04605v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.01661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_P/0/1/0/all/0/1\">Pit Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maurer_Y/0/1/0/all/0/1\">Yves Maurer</a>",
          "description": "Iterating with new and improved OCR solutions enforces decision making when\nit comes to targeting the right candidates for reprocessing. This especially\napplies when the underlying data collection is of considerable size and rather\ndiverse in terms of fonts, languages, periods of publication and consequently\nOCR quality. This article captures the efforts of the National Library of\nLuxembourg to support those targeting decisions. They are crucial in order to\nguarantee low computational overhead and reduced quality degradation risks,\ncombined with a more quantifiable OCR improvement. In particular, this work\nexplains the methodology of the library with respect to text block level\nquality assessment. Through extension of this technique, a regression model,\nthat is able to take into account the enhancement potential of a new OCR\nengine, is also presented. They both mark promising approaches, especially for\ncultural institutions dealing with historical data of lower quality.",
          "link": "http://arxiv.org/abs/2110.01661",
          "publishedOn": "2022-04-02T00:47:22.250Z",
          "wordCount": 646,
          "title": "Rerunning OCR: A Machine Learning Approach to Quality Assessment and Enhancement Prediction. (arXiv:2110.01661v4 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.14512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hemati_H/0/1/0/all/0/1\">Hamed Hemati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1\">Damian Borth</a>",
          "description": "Training a multi-speaker Text-to-Speech (TTS) model from scratch is\ncomputationally expensive and adding new speakers to the dataset requires the\nmodel to be re-trained. The naive solution of sequential fine-tuning of a model\nfor new speakers can lead to poor performance of older speakers. This\nphenomenon is known as catastrophic forgetting. In this paper, we look at TTS\nmodeling from a continual learning perspective, where the goal is to add new\nspeakers without forgetting previous speakers. Therefore, we first propose an\nexperimental setup and show that serial fine-tuning for new speakers can cause\nthe forgetting of the earlier speakers. Then we exploit two well-known\ntechniques for continual learning, namely experience replay and weight\nregularization. We reveal how one can mitigate the effect of degradation in\nspeech synthesis diversity in sequential training of new speakers using these\nmethods. Finally, we present a simple extension to experience replay to improve\nthe results in extreme setups where we have access to very small buffers.",
          "link": "http://arxiv.org/abs/2103.14512",
          "publishedOn": "2022-04-02T00:47:22.243Z",
          "wordCount": 629,
          "title": "Continual Speaker Adaptation for Text-to-Speech Synthesis. (arXiv:2103.14512v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montanari_A/0/1/0/all/0/1\">Andrea Montanari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuchen Wu</a>",
          "description": "A substantial body of empirical work documents the lack of robustness in deep\nlearning models to adversarial examples. Recent theoretical work proved that\nadversarial examples are ubiquitous in two-layers networks with sub-exponential\nwidth and ReLU or smooth activations, and multi-layer ReLU networks with\nsub-exponential width. We present a result of the same type, with no\nrestriction on width and for general locally Lipschitz continuous activations.\n\nMore precisely, given a neural network $f(\\,\\cdot\\,;{\\boldsymbol \\theta})$\nwith random weights ${\\boldsymbol \\theta}$, and feature vector ${\\boldsymbol\nx}$, we show that an adversarial example ${\\boldsymbol x}'$ can be found with\nhigh probability along the direction of the gradient $\\nabla_{{\\boldsymbol\nx}}f({\\boldsymbol x};{\\boldsymbol \\theta})$. Our proof is based on a Gaussian\nconditioning technique. Instead of proving that $f$ is approximately linear in\na neighborhood of ${\\boldsymbol x}$, we characterize the joint distribution of\n$f({\\boldsymbol x};{\\boldsymbol \\theta})$ and $f({\\boldsymbol x}';{\\boldsymbol\n\\theta})$ for ${\\boldsymbol x}' = {\\boldsymbol x}-s({\\boldsymbol\nx})\\nabla_{{\\boldsymbol x}}f({\\boldsymbol x};{\\boldsymbol \\theta})$.",
          "link": "http://arxiv.org/abs/2203.17209",
          "publishedOn": "2022-04-02T00:47:22.235Z",
          "wordCount": 600,
          "title": "Adversarial Examples in Random Neural Networks with General Activations. (arXiv:2203.17209v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Albanie_S/0/1/0/all/0/1\">Samuel Albanie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_D/0/1/0/all/0/1\">Dylan Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1\">Jo&#xe3;o F. Henriques</a>",
          "description": "The field of machine learning has achieved striking progress in recent years,\nwitnessing breakthrough results on language modelling, protein folding and\nnitpickingly fine-grained dog breed classification. Some even succeeded at\nplaying computer games and board games, a feat both of engineering and of\nsetting their employers' expectations. The central contribution of this work is\nto carefully examine whether this progress, and technology more broadly, can be\nexpected to continue indefinitely. Through a rigorous application of\nstatistical theory and failure to extrapolate beyond the training data, we\nanswer firmly in the negative and provide details: technology will peak at 3:07\nam (BST) on 20th July, 2032. We then explore the implications of this finding,\ndiscovering that individuals awake at this ungodly hour with access to a\nsufficiently powerful computer possess an opportunity for myriad forms of\nlong-term linguistic 'lock in'. All we need is a large (>> 1W) data centre to\nseize this pivotal moment. By setting our analogue alarm clocks, we propose a\ntractable algorithm to ensure that, for the future of humanity, the British\nspelling of colour becomes the default spelling across more than 80% of the\nglobal word processing software market.",
          "link": "http://arxiv.org/abs/2203.17265",
          "publishedOn": "2022-04-02T00:47:22.214Z",
          "wordCount": 629,
          "title": "A 23 MW data centre is all you need. (arXiv:2203.17265v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mirheidari_B/0/1/0/all/0/1\">Bahman Mirheidari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bittar_A/0/1/0/all/0/1\">Andr&#xe9; Bittar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cummins_N/0/1/0/all/0/1\">Nicholas Cummins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downs_J/0/1/0/all/0/1\">Johnny Downs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisher_H/0/1/0/all/0/1\">Helen L. Fisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christensen_H/0/1/0/all/0/1\">Heidi Christensen</a>",
          "description": "We present a novel feasibility study on the automatic recognition of\nExpressed Emotion (EE), a family environment concept based on caregivers\nspeaking freely about their relative/family member. We describe an automated\napproach for determining the \\textit{degree of warmth}, a key component of EE,\nfrom acoustic and text features acquired from a sample of 37 recorded\ninterviews. These recordings, collected over 20 years ago, are derived from a\nnationally representative birth cohort of 2,232 British twin children and were\nmanually coded for EE. We outline the core steps of extracting usable\ninformation from recordings with highly variable audio quality and assess the\nefficacy of four machine learning approaches trained with different\ncombinations of acoustic and text features. Despite the challenges of working\nwith this legacy data, we demonstrated that the degree of warmth can be\npredicted with an $F_{1}$-score of \\textbf{61.5\\%}. In this paper, we summarise\nour learning and provide recommendations for future work using real-world\nspeech samples.",
          "link": "http://arxiv.org/abs/2203.17242",
          "publishedOn": "2022-04-02T00:47:20.632Z",
          "wordCount": null,
          "title": "Automatic Detection of Expressed Emotion from Five-Minute Speech Samples: Challenges and Opportunities. (arXiv:2203.17242v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aflalo_E/0/1/0/all/0/1\">Estelle Aflalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Meng Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_S/0/1/0/all/0/1\">Shao-Yen Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yongfei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lal_V/0/1/0/all/0/1\">Vasudev Lal</a>",
          "description": "Breakthroughs in transformer-based models have revolutionized not only the\nNLP field, but also vision and multimodal systems. However, although\nvisualization and interpretability tools have become available for NLP models,\ninternal mechanisms of vision and multimodal transformers remain largely\nopaque. With the success of these transformers, it is increasingly critical to\nunderstand their inner workings, as unraveling these black-boxes will lead to\nmore capable and trustworthy models. To contribute to this quest, we propose\nVL-InterpreT, which provides novel interactive visualizations for interpreting\nthe attentions and hidden representations in multimodal transformers.\nVL-InterpreT is a task agnostic and integrated tool that (1) tracks a variety\nof statistics in attention heads throughout all layers for both vision and\nlanguage components, (2) visualizes cross-modal and intra-modal attentions\nthrough easily readable heatmaps, and (3) plots the hidden representations of\nvision and language tokens as they pass through the transformer layers. In this\npaper, we demonstrate the functionalities of VL-InterpreT through the analysis\nof KD-VLP, an end-to-end pretraining vision-language multimodal\ntransformer-based model, in the tasks of Visual Commonsense Reasoning (VCR) and\nWebQA, two visual question answering benchmarks. Furthermore, we also present a\nfew interesting findings about multimodal transformer behaviors that were\nlearned through our tool.",
          "link": "http://arxiv.org/abs/2203.17247",
          "publishedOn": "2022-04-02T00:47:20.632Z",
          "wordCount": null,
          "title": "VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers. (arXiv:2203.17247v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17065",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chugh_T/0/1/0/all/0/1\">Tinkle Chugh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ymeraj_E/0/1/0/all/0/1\">Endi Ymeraj</a>",
          "description": "Wind energy is one of the cleanest renewable electricity sources and can help\nin addressing the challenge of climate change. One of the drawbacks of\nwind-generated energy is the large space necessary to install a wind farm; this\narises from the fact that placing wind turbines in a limited area would hinder\ntheir productivity and therefore not be economically convenient. This naturally\nleads to an optimisation problem, which has three specific challenges: (1)\nmultiple conflicting objectives (2) computationally expensive simulation models\nand (3) optimisation over design sets instead of design vectors. The first and\nsecond challenges can be addressed by using surrogate-assisted e.g.\\ Bayesian\nmulti-objective optimisation. However, the traditional Bayesian optimisation\ncannot be applied as the optimisation function in the problem relies on design\nsets instead of design vectors. This paper extends the applicability of\nBayesian multi-objective optimisation to set based optimisation for solving the\nwind farm layout problem. We use a set-based kernel in Gaussian process to\nquantify the correlation between wind farms (with a different number of\nturbines). The results on the given data set of wind energy and direction\nclearly show the potential of using set-based Bayesian multi-objective\noptimisation.",
          "link": "http://arxiv.org/abs/2203.17065",
          "publishedOn": "2022-04-02T00:47:20.631Z",
          "wordCount": null,
          "title": "Wind Farm Layout Optimisation using Set Based Multi-objective Bayesian Optimisation. (arXiv:2203.17065v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.03721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_N/0/1/0/all/0/1\">Nanyang Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kaican Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoyue Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Runpeng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lanqing Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Fengwei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Deep learning has achieved tremendous success with independent and\nidentically distributed (i.i.d.) data. However, the performance of neural\nnetworks often degenerates drastically when encountering out-of-distribution\n(OoD) data, i.e., when training and test data are sampled from different\ndistributions. While a plethora of algorithms have been proposed for OoD\ngeneralization, our understanding of the data used to train and evaluate these\nalgorithms remains stagnant. In this work, we first identify and measure two\ndistinct kinds of distribution shifts that are ubiquitous in various datasets.\nNext, through extensive experiments, we compare OoD generalization algorithms\nacross two groups of benchmarks, each dominated by one of the distribution\nshifts, revealing their strengths on one shift as well as limitations on the\nother shift. Overall, we position existing datasets and algorithms from\ndifferent research areas seemingly unconnected into the same coherent picture.\nIt may serve as a foothold that can be resorted to by future OoD generalization\nresearch. Our code is available at https://github.com/ynysjtu/ood_bench.",
          "link": "http://arxiv.org/abs/2106.03721",
          "publishedOn": "2022-04-02T00:47:20.388Z",
          "wordCount": null,
          "title": "OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization. (arXiv:2106.03721v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muller_N/0/1/0/all/0/1\">Nicolas M. M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Czempin_P/0/1/0/all/0/1\">Pavel Czempin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dieckmann_F/0/1/0/all/0/1\">Franziska Dieckmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Froghyar_A/0/1/0/all/0/1\">Adam Froghyar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bottinger_K/0/1/0/all/0/1\">Konstantin B&#xf6;ttinger</a>",
          "description": "Current text-to-speech algorithms produce realistic fakes of human voices,\nmaking deepfake detection a much-needed area of research. While researchers\nhave presented various techniques for detecting audio spoofs, it is often\nunclear exactly why these architectures are successful: Preprocessing steps,\nhyperparameter settings, and the degree of fine-tuning are not consistent\nacross related work. Which factors contribute to success, and which are\naccidental? In this work, we address this problem: We systematize audio\nspoofing detection by re-implementing and uniformly evaluating architectures\nfrom related work. We identify overarching features for successful audio\ndeepfake detection, such as using cqtspec or logspec features instead of\nmelspec features, which improves performance by 37% EER on average, all other\nfactors constant. Additionally, we evaluate generalization capabilities: We\ncollect and publish a new dataset consisting of 37.9 hours of found audio\nrecordings of celebrities and politicians, of which 17.2 hours are deepfakes.\nWe find that related work performs poorly on such real-world data (performance\ndegradation of up to one thousand percent). This may suggest that the community\nhas tailored its solutions too closely to the prevailing ASVSpoof benchmark and\nthat deepfakes are much harder to detect outside the lab than previously\nthought.",
          "link": "http://arxiv.org/abs/2203.16263",
          "publishedOn": "2022-04-02T00:47:20.194Z",
          "wordCount": null,
          "title": "Does Audio Deepfake Detection Generalize?. (arXiv:2203.16263v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.14452",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Vargas_Calderon_V/0/1/0/all/0/1\">Vladimir Vargas-Calder&#xf3;n</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gonzalez_F/0/1/0/all/0/1\">Fabio A. Gonz&#xe1;lez</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Vinck_Posada_H/0/1/0/all/0/1\">Herbert Vinck-Posada</a>",
          "description": "We demonstrate the implementation of a novel machine learning framework for\nprobability density estimation and classification using quantum circuits. The\nframework maps a training data set or a single data sample to the quantum state\nof a physical system through quantum feature maps. The quantum state of the\narbitrarily large training data set summarises its probability distribution in\na finite-dimensional quantum wave function. By projecting the quantum state of\na new data sample onto the quantum state of the training data set, one can\nderive statistics to classify or estimate the density of the new data sample.\nRemarkably, the implementation of our framework on a real quantum device does\nnot require any optimisation of quantum circuit parameters. Nonetheless, we\ndiscuss a variational quantum circuit approach that could leverage quantum\nadvantage for our framework.",
          "link": "http://arxiv.org/abs/2203.14452",
          "publishedOn": "2022-04-02T00:47:20.189Z",
          "wordCount": null,
          "title": "Optimisation-free Classification and Density Estimation with Quantum Circuits. (arXiv:2203.14452v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1\">Can Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haichun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaohong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shilin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asad_Z/0/1/0/all/0/1\">Zuhayr Asad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coburn_L/0/1/0/all/0/1\">Lori A. Coburn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_K/0/1/0/all/0/1\">Keith T. Wilson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1\">Bennett A. Landman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1\">Yuankai Huo</a>",
          "description": "The rapid development of diagnostic technologies in healthcare is leading to\nhigher requirements for physicians to handle and integrate the heterogeneous,\nyet complementary data that are produced during routine practice. For instance,\nthe personalized diagnosis and treatment planning for a single cancer patient\nrelies on the various images (e.g., radiological, pathological, and camera\nimages) and non-image data (e.g., clinical data and genomic data). However,\nsuch decision-making procedures can be subjective, qualitative, and have large\ninter-subject variabilities. With the recent advances in multi-modal deep\nlearning technologies, an increasingly large number of efforts have been\ndevoted to a key question: how do we extract and aggregate multi-modal\ninformation to ultimately provide more objective, quantitative computer-aided\nclinical decision making? This paper reviews the recent studies on dealing with\nsuch a question. Briefly, this review will include the (1) overview of current\nmulti-modal learning workflows, (2) summarization of multi-modal fusion\nmethods, (3) discussion of the performance, (4) applications in disease\ndiagnosis and prognosis, and (5) challenges and future directions.",
          "link": "http://arxiv.org/abs/2203.15588",
          "publishedOn": "2022-04-02T00:47:20.170Z",
          "wordCount": null,
          "title": "Deep Multi-modal Fusion of Image and Non-image Data in Disease Diagnosis and Prognosis: A Review. (arXiv:2203.15588v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16336",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zabihi_S/0/1/0/all/0/1\">Soheil Zabihi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rahimian_E/0/1/0/all/0/1\">Elahe Rahimian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asif_A/0/1/0/all/0/1\">Amir Asif</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mohammadi_A/0/1/0/all/0/1\">Arash Mohammadi</a>",
          "description": "Deep learning-based Hand Gesture Recognition (HGR) via surface Electromyogram\n(sEMG) signals has recently shown significant potential for development of\nadvanced myoelectric-controlled prosthesis. Existing deep learning approaches,\ntypically, include only one model as such can hardly maintain acceptable\ngeneralization performance in changing scenarios. In this paper, we aim to\naddress this challenge by capitalizing on the recent advances of hybrid models\nand transformers. In other words, we propose a hybrid framework based on the\ntransformer architecture, which is a relatively new and revolutionizing deep\nlearning model. The proposed hybrid architecture, referred to as the\nTransformer for Hand Gesture Recognition (TraHGR), consists of two parallel\npaths followed by a linear layer that acts as a fusion center to integrate the\nadvantage of each module and provide robustness over different scenarios. We\nevaluated the proposed architecture TraHGR based on the commonly used second\nNinapro dataset, referred to as the DB2. The sEMG signals in the DB2 dataset\nare measured in the real-life conditions from 40 healthy users, each performing\n49 gestures. We have conducted extensive set of experiments to test and\nvalidate the proposed TraHGR architecture, and have compared its achievable\naccuracy with more than five recently proposed HGR classification algorithms\nover the same dataset. We have also compared the results of the proposed TraHGR\narchitecture with each individual path and demonstrated the distinguishing\npower of the proposed hybrid architecture. The recognition accuracies of the\nproposed TraHGR architecture are 86.18%, 88.91%, 81.44%, and 93.84%, which are\n2.48%, 5.12%, 8.82%, and 4.30% higher than the state-ofthe-art performance for\nDB2 (49 gestures), DB2-B (17 gestures), DB2-C (23 gestures), and DB2-D (9\ngestures), respectively.",
          "link": "http://arxiv.org/abs/2203.16336",
          "publishedOn": "2022-04-02T00:47:20.170Z",
          "wordCount": null,
          "title": "TraHGR: Transformer for Hand Gesture Recognition via ElectroMyography. (arXiv:2203.16336v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.03028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Christen_S/0/1/0/all/0/1\">Sammy Christen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocabas_M/0/1/0/all/0/1\">Muhammed Kocabas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aksan_E/0/1/0/all/0/1\">Emre Aksan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwangbo_J/0/1/0/all/0/1\">Jemin Hwangbo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1\">Otmar Hilliges</a>",
          "description": "We introduce the dynamic grasp synthesis task: given an object with a known\n6D pose and a grasp reference, our goal is to generate motions that move the\nobject to a target 6D pose. This is challenging, because it requires reasoning\nabout the complex articulation of the human hand and the intricate physical\ninteraction with the object. We propose a novel method that frames this problem\nin the reinforcement learning framework and leverages a physics simulation,\nboth to learn and to evaluate such dynamic interactions. A hierarchical\napproach decomposes the task into low-level grasping and high-level motion\nsynthesis. It can be used to generate novel hand sequences that approach,\ngrasp, and move an object to a desired location, while retaining\nhuman-likeness. We show that our approach leads to stable grasps and generates\na wide range of motions. Furthermore, even imperfect labels can be corrected by\nour method to generate dynamic interaction sequences.",
          "link": "http://arxiv.org/abs/2112.03028",
          "publishedOn": "2022-04-02T00:47:20.170Z",
          "wordCount": null,
          "title": "D-Grasp: Physically Plausible Dynamic Grasp Synthesis for Hand-Object Interactions. (arXiv:2112.03028v2 [cs.RO] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15937",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yang_M/0/1/0/all/0/1\">Mu Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hirschi_K/0/1/0/all/0/1\">Kevin Hirschi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Looney_S/0/1/0/all/0/1\">Stephen D. Looney</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kang_O/0/1/0/all/0/1\">Okim Kang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hansen_J/0/1/0/all/0/1\">John H. L. Hansen</a>",
          "description": "Current leading mispronunciation detection and diagnosis (MDD) systems\nachieve promising performance via end-to-end phoneme recognition. One challenge\nof such end-to-end solutions is the scarcity of human-annotated phonemes on\nnatural L2 speech. In this work, we leverage unlabeled L2 speech via a\npseudo-labeling (PL) procedure and extend the fine-tuning approach based on\npre-trained self-supervised learning (SSL) models. Specifically, we use Wav2vec\n2.0 as our SSL model, and fine-tune it using original labeled L2 speech samples\nplus the created pseudo-labeled L2 speech samples. Our pseudo labels are\ndynamic and are produced by an ensemble of the online model on-the-fly, which\nensures that our model is robust to pseudo label noise. We show that\nfine-tuning with pseudo labels gains a 5.35% phoneme error rate reduction and\n2.48% MDD F1 score improvement over a labeled-samples-only fine-tuning\nbaseline. The proposed PL method is also shown to outperform conventional\noffline PL methods. Compared to the state-of-the-art MDD systems, our MDD\nsolution achieves a more accurate and consistent phonetic error diagnosis. In\naddition, we conduct an open test on a separate UTD-4Accents dataset, where our\nsystem recognition outputs show a strong correlation with human perception,\nbased on accentedness and intelligibility.",
          "link": "http://arxiv.org/abs/2203.15937",
          "publishedOn": "2022-04-02T00:47:20.169Z",
          "wordCount": null,
          "title": "Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness and Intelligibility Assessment. (arXiv:2203.15937v1 [eess.AS] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.14542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karim_N/0/1/0/all/0/1\">Nazmul Karim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizve_M/0/1/0/all/0/1\">Mamshad Nayeem Rizve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahnavard_N/0/1/0/all/0/1\">Nazanin Rahnavard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1\">Ajmal Mian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>",
          "description": "Supervised deep learning methods require a large repository of annotated\ndata; hence, label noise is inevitable. Training with such noisy data\nnegatively impacts the generalization performance of deep neural networks. To\ncombat label noise, recent state-of-the-art methods employ some sort of sample\nselection mechanism to select a possibly clean subset of data. Next, an\noff-the-shelf semi-supervised learning method is used for training where\nrejected samples are treated as unlabeled data. Our comprehensive analysis\nshows that current selection methods disproportionately select samples from\neasy (fast learnable) classes while rejecting those from relatively harder\nones. This creates class imbalance in the selected clean set and in turn,\ndeteriorates performance under high label noise. In this work, we propose\nUNICON, a simple yet effective sample selection method which is robust to high\nlabel noise. To address the disproportionate selection of easy and hard\nsamples, we introduce a Jensen-Shannon divergence based uniform selection\nmechanism which does not require any probabilistic modeling and hyperparameter\ntuning. We complement our selection method with contrastive learning to further\ncombat the memorization of noisy labels. Extensive experimentation on multiple\nbenchmark datasets demonstrates the effectiveness of UNICON; we obtain an 11.4%\nimprovement over the current state-of-the-art on CIFAR100 dataset with a 90%\nnoise rate. Our code is publicly available",
          "link": "http://arxiv.org/abs/2203.14542",
          "publishedOn": "2022-04-02T00:47:20.167Z",
          "wordCount": null,
          "title": "UNICON: Combating Label Noise Through Uniform Selection and Contrastive Learning. (arXiv:2203.14542v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.06537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guangxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenkai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xuancheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yunfang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>",
          "description": "The conventional wisdom behind learning deep classification models is to\nfocus on bad-classified examples and ignore well-classified examples that are\nfar from the decision boundary. For instance, when training with cross-entropy\nloss, examples with higher likelihoods (i.e., well-classified examples)\ncontribute smaller gradients in back-propagation. However, we theoretically\nshow that this common practice hinders representation learning, energy\noptimization, and margin growth. To counteract this deficiency, we propose to\nreward well-classified examples with additive bonuses to revive their\ncontribution to the learning process. This counterexample theoretically\naddresses these three issues. We empirically support this claim by directly\nverifying the theoretical results or significant performance improvement with\nour counterexample on diverse tasks, including image classification, graph\nclassification, and machine translation. Furthermore, this paper shows that we\ncan deal with complex scenarios, such as imbalanced classification, OOD\ndetection, and applications under adversarial attacks because our idea can\nsolve these three issues. Code is available at:\nhttps://github.com/lancopku/well-classified-examples-are-underestimated.",
          "link": "http://arxiv.org/abs/2110.06537",
          "publishedOn": "2022-04-02T00:47:20.159Z",
          "wordCount": null,
          "title": "Well-classified Examples are Underestimated in Classification with Deep Neural Networks. (arXiv:2110.06537v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.08377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Girdhar_R/0/1/0/all/0/1\">Rohit Girdhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Mannat Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravi_N/0/1/0/all/0/1\">Nikhila Ravi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maaten_L/0/1/0/all/0/1\">Laurens van der Maaten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1\">Armand Joulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_I/0/1/0/all/0/1\">Ishan Misra</a>",
          "description": "Prior work has studied different visual modalities in isolation and developed\nseparate architectures for recognition of images, videos, and 3D data. Instead,\nin this paper, we propose a single model which excels at classifying images,\nvideos, and single-view 3D data using exactly the same model parameters. Our\n'Omnivore' model leverages the flexibility of transformer-based architectures\nand is trained jointly on classification tasks from different modalities.\nOmnivore is simple to train, uses off-the-shelf standard datasets, and performs\nat-par or better than modality-specific models of the same size. A single\nOmnivore model obtains 86.0% on ImageNet, 84.1% on Kinetics, and 67.1% on SUN\nRGB-D. After finetuning, our models outperform prior work on a variety of\nvision tasks and generalize across modalities. Omnivore's shared visual\nrepresentation naturally enables cross-modal recognition without access to\ncorrespondences between modalities. We hope our results motivate researchers to\nmodel visual modalities together.",
          "link": "http://arxiv.org/abs/2201.08377",
          "publishedOn": "2022-04-02T00:47:20.158Z",
          "wordCount": null,
          "title": "Omnivore: A Single Model for Many Visual Modalities. (arXiv:2201.08377v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1\">Zhihao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Siqi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhijie Yan</a>",
          "description": "Overlapping speech diarization has been traditionally treated as a\nmulti-label classification problem. In this paper, we reformulate this task as\na single-label prediction problem by encoding multiple binary labels into a\nsingle label with the power set, which represents the possible combinations of\ntarget speakers. This formulation has two benefits. First, the overlaps of\ntarget speakers are explicitly modeled. Second, threshold selection is no\nlonger needed. Through this formulation, we propose the speaker embedding-aware\nneural diarization (SEND) framework, where a speech encoder, a speaker encoder,\ntwo similarity scorers, and a post-processing network are jointly optimized to\npredict the encoded labels according to the similarities between speech\nfeatures and speaker embeddings. Experimental results show that SEND has a\nstable learning process and can be trained on highly overlapped data without\nextra initialization. More importantly, our method achieves the\nstate-of-the-art performance in real meeting scenarios with fewer model\nparameters and lower computational complexity.",
          "link": "http://arxiv.org/abs/2203.09767",
          "publishedOn": "2022-04-02T00:47:20.157Z",
          "wordCount": null,
          "title": "Speaker Embedding-aware Neural Diarization: an Efficient Framework for Overlapping Speech Diarization in Meeting Scenarios. (arXiv:2203.09767v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peri_N/0/1/0/all/0/1\">Neehar Peri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luiten_J/0/1/0/all/0/1\">Jonathon Luiten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mengtian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osep_A/0/1/0/all/0/1\">Aljo&#x161;a O&#x161;ep</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1\">Laura Leal-Taix&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1\">Deva Ramanan</a>",
          "description": "Object detection and forecasting are fundamental components of embodied\nperception. These two problems, however, are largely studied in isolation by\nthe community. In this paper, we propose an end-to-end approach for detection\nand motion forecasting based on raw sensor measurement as opposed to ground\ntruth tracks. Instead of predicting the current frame locations and forecasting\nforward in time, we directly predict future object locations and backcast to\ndetermine where each trajectory began. Our approach not only improves overall\naccuracy compared to other modular or end-to-end baselines, it also prompts us\nto rethink the role of explicit tracking for embodied perception. Additionally,\nby linking future and current locations in a many-to-one manner, our approach\nis able to reason about multiple futures, a capability that was previously\nconsidered difficult for end-to-end approaches. We conduct extensive\nexperiments on the popular nuScenes dataset and demonstrate the empirical\neffectiveness of our approach. In addition, we investigate the appropriateness\nof reusing standard forecasting metrics for an end-to-end setup, and find a\nnumber of limitations which allow us to build simple baselines to game these\nmetrics. We address this issue with a novel set of joint forecasting and\ndetection metrics that extend the commonly used AP metrics from the detection\ncommunity to measuring forecasting accuracy. Our code is available at\nhttps://github.com/neeharperi/FutureDet",
          "link": "http://arxiv.org/abs/2203.16297",
          "publishedOn": "2022-04-02T00:47:20.155Z",
          "wordCount": null,
          "title": "Forecasting from LiDAR via Future Object Detection. (arXiv:2203.16297v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_G/0/1/0/all/0/1\">Guimin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Mingyue Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jiechao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Sikun Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1\">Lihua Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_R/0/1/0/all/0/1\">Robert Gutierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_B/0/1/0/all/0/1\">Bradford Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_L/0/1/0/all/0/1\">Laura E. Barnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boukhechba_M/0/1/0/all/0/1\">Mehdi Boukhechba</a>",
          "description": "The Internet of Things (IoT) boom has revolutionized almost every corner of\npeople's daily lives: healthcare, home, transportation, manufacturing, supply\nchain, and so on. With the recent development of sensor and communication\ntechnologies, IoT devices including smart wearables, cameras, smartwatches, and\nautonomous vehicles can accurately measure and perceive their surrounding\nenvironment. Continuous sensing generates massive amounts of data and presents\nchallenges for machine learning. Deep learning models (e.g., convolution neural\nnetworks and recurrent neural networks) have been extensively employed in\nsolving IoT tasks by learning patterns from multi-modal sensory data. Graph\nNeural Networks (GNNs), an emerging and fast-growing family of neural network\nmodels, can capture complex interactions within sensor topology and have been\ndemonstrated to achieve state-of-the-art results in numerous IoT learning\ntasks. In this survey, we present a comprehensive review of recent advances in\nthe application of GNNs to the IoT field, including a deep dive analysis of GNN\ndesign in various IoT sensing environments, an overarching list of public data\nand source code from the collected publications, and future research\ndirections. To keep track of newly published works, we collect representative\npapers and their open-source implementations and create a Github repository at\nhttps://github.com/GuiminDong/GNN4IoT.",
          "link": "http://arxiv.org/abs/2203.15935",
          "publishedOn": "2022-04-02T00:47:20.154Z",
          "wordCount": null,
          "title": "Graph Neural Networks in IoT: A Survey. (arXiv:2203.15935v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenbin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_J/0/1/0/all/0/1\">Jeremy C. Weiss</a>",
          "description": "Recent works in artificial intelligence fairness attempt to mitigate\ndiscrimination by proposing constrained optimization programs that achieve\nparity for some fairness statistic. Most assume availability of the class\nlabel, which is impractical in many real-world applications such as precision\nmedicine, actuarial analysis and recidivism prediction. Here we consider\nfairness in longitudinal right-censored environments, where the time to event\nmight be unknown, resulting in censorship of the class label and\ninapplicability of existing fairness studies. We devise applicable fairness\nmeasures, propose a debiasing algorithm, and provide necessary theoretical\nconstructs to bridge fairness with and without censorship for these important\nand socially-sensitive tasks. Our experiments on four censored datasets confirm\nthe utility of our approach.",
          "link": "http://arxiv.org/abs/2203.16024",
          "publishedOn": "2022-04-02T00:47:20.144Z",
          "wordCount": null,
          "title": "Longitudinal Fairness with Censorship. (arXiv:2203.16024v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chun-Hsien Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pu-Jen Cheng</a>",
          "description": "Word embedding is a modern distributed word representations approach widely\nused in many natural language processing tasks. Converting the vocabulary in a\nlegal document into a word embedding model facilitates subjecting legal\ndocuments to machine learning, deep learning, and other algorithms and\nsubsequently performing the downstream tasks of natural language processing\nvis-\\`a-vis, for instance, document classification, contract review, and\nmachine translation. The most common and practical approach of accuracy\nevaluation with the word embedding model uses a benchmark set with linguistic\nrules or the relationship between words to perform analogy reasoning via\nalgebraic calculation. This paper proposes establishing a 1,134 Legal\nAnalogical Reasoning Questions Set (LARQS) from the 2,388 Chinese Codex corpus\nusing five kinds of legal relations, which are then used to evaluate the\naccuracy of the Chinese word embedding model. Moreover, we discovered that\nlegal relations might be ubiquitous in the word embedding model.",
          "link": "http://arxiv.org/abs/2203.15173",
          "publishedOn": "2022-04-02T00:47:20.144Z",
          "wordCount": null,
          "title": "An Evaluation Dataset for Legal Word Embedding: A Case Study On Chinese Codex. (arXiv:2203.15173v1 [cs.CL] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.12438",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gupta_V/0/1/0/all/0/1\">Vishal Gupta</a>, <a href=\"http://arxiv.org/find/math/1/au:+Huang_M/0/1/0/all/0/1\">Michael Huang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rusmevichientong_P/0/1/0/all/0/1\">Paat Rusmevichientong</a>",
          "description": "Motivated by the poor performance of cross-validation in settings where data\nare scarce, we propose a novel estimator of the out-of-sample performance of a\npolicy in data-driven optimization.Our approach exploits the optimization\nproblem's sensitivity analysis to estimate the gradient of the optimal\nobjective value with respect to the amount of noise in the data and uses the\nestimated gradient to debias the policy's in-sample performance. Unlike\ncross-validation techniques, our approach avoids sacrificing data for a test\nset, utilizes all data when training and, hence, is well-suited to settings\nwhere data are scarce. We prove bounds on the bias and variance of our\nestimator for optimization problems with uncertain linear objectives but known,\npotentially non-convex, feasible regions. For more specialized optimization\nproblems where the feasible region is \"weakly-coupled\" in a certain sense, we\nprove stronger results. Specifically, we provide explicit high-probability\nbounds on the error of our estimator that hold uniformly over a policy class\nand depends on the problem's dimension and policy class's complexity. Our\nbounds show that under mild conditions, the error of our estimator vanishes as\nthe dimension of the optimization problem grows, even if the amount of\navailable data remains small and constant. Said differently, we prove our\nestimator performs well in the small-data, large-scale regime. Finally, we\nnumerically compare our proposed method to state-of-the-art approaches through\na case-study on dispatching emergency medical response services using real\ndata. Our method provides more accurate estimates of out-of-sample performance\nand learns better-performing policies.",
          "link": "http://arxiv.org/abs/2107.12438",
          "publishedOn": "2022-04-02T00:47:20.143Z",
          "wordCount": null,
          "title": "Debiasing In-Sample Policy Performance for Small-Data, Large-Scale Optimization. (arXiv:2107.12438v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yuhao Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kunlin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Song Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_I/0/1/0/all/0/1\">Ignavier Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1\">Jinmeng Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1\">Shan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_T/0/1/0/all/0/1\">Teng Fei</a>",
          "description": "Spatial clustering has been widely used for spatial data mining and knowledge\ndiscovery. An ideal multivariate spatial clustering should consider both\nspatial contiguity and aspatial attributes. Existing spatial clustering\napproaches may face challenges for discovering repeated geographic patterns\nwith spatial contiguity maintained. In this paper, we propose a Spatial\nToeplitz Inverse Covariance-Based Clustering (STICC) method that considers both\nattributes and spatial relationships of geographic objects for multivariate\nspatial clustering. A subregion is created for each geographic object serving\nas the basic unit when performing clustering. A Markov random field is then\nconstructed to characterize the attribute dependencies of subregions. Using a\nspatial consistency strategy, nearby objects are encouraged to belong to the\nsame cluster. To test the performance of the proposed STICC algorithm, we apply\nit in two use cases. The comparison results with several baseline methods show\nthat the STICC outperforms others significantly in terms of adjusted rand index\nand macro-F1 score. Join count statistics is also calculated and shows that the\nspatial contiguity is well preserved by STICC. Such a spatial clustering method\nmay benefit various applications in the fields of geography, remote sensing,\ntransportation, and urban planning, etc.",
          "link": "http://arxiv.org/abs/2203.09611",
          "publishedOn": "2022-04-02T00:47:20.143Z",
          "wordCount": null,
          "title": "STICC: A multivariate spatial clustering method for repeated geographic pattern discovery with consideration of spatial contiguity. (arXiv:2203.09611v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciolino_M/0/1/0/all/0/1\">Matthew Ciolino</a>",
          "description": "If a unit cannot receive intelligence from a source due to external factors,\nwe consider them disadvantaged users. We categorize this as a preoccupied unit\nworking on a low connectivity device on the edge. This case requires that we\nuse a different approach to deliver intelligence, particularly satellite\nimagery information, than normally employed. To address this, we propose a\nsurvey of information reduction techniques to deliver the information from a\nsatellite image in a smaller package. We investigate four techniques to aid in\nthe reduction of delivered information: traditional image compression, neural\nnetwork image compression, object detection image cutout, and image to caption.\nEach of these mechanisms have their benefits and tradeoffs when considered for\na disadvantaged user.",
          "link": "http://arxiv.org/abs/2203.13686",
          "publishedOn": "2022-04-02T00:47:20.143Z",
          "wordCount": null,
          "title": "Image Compression and Actionable Intelligence With Deep Neural Networks. (arXiv:2203.13686v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hemati_H/0/1/0/all/0/1\">Hamed Hemati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schreyer_M/0/1/0/all/0/1\">Marco Schreyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1\">Damian Borth</a>",
          "description": "International audit standards require the direct assessment of a financial\nstatement's underlying accounting journal entries. Driven by advances in\nartificial intelligence, deep-learning inspired audit techniques emerged to\nexamine vast quantities of journal entry data. However, in regular audits, most\nof the proposed methods are applied to learn from a comparably stationary\njournal entry population, e.g., of a financial quarter or year. Ignoring\nsituations where audit relevant distribution changes are not evident in the\ntraining data or become incrementally available over time. In contrast, in\ncontinuous auditing, deep-learning models are continually trained on a stream\nof recorded journal entries, e.g., of the last hour. Resulting in situations\nwhere previous knowledge interferes with new information and will be entirely\noverwritten. This work proposes a continual anomaly detection framework to\novercome both challenges and designed to learn from a stream of journal entry\ndata experiences. The framework is evaluated based on deliberately designed\naudit scenarios and two real-world datasets. Our experimental results provide\ninitial evidence that such a learning scheme offers the ability to reduce\nfalse-positive alerts and false-negative decisions.",
          "link": "http://arxiv.org/abs/2112.13215",
          "publishedOn": "2022-04-02T00:47:20.142Z",
          "wordCount": null,
          "title": "Continual Learning for Unsupervised Anomaly Detection in Continuous Auditing of Financial Accounting Data. (arXiv:2112.13215v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15884",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Augustin_M/0/1/0/all/0/1\">Mihai-Cezar Augustin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonvin_V/0/1/0/all/0/1\">Vivien Bonvin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houssou_R/0/1/0/all/0/1\">Regis Houssou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rappos_E/0/1/0/all/0/1\">Efstratios Rappos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robert_Nicoud_S/0/1/0/all/0/1\">Stephan Robert-Nicoud</a>",
          "description": "In classification problems, supervised machine-learning methods outperform\ntraditional algorithms, thanks to the ability of neural networks to learn\ncomplex patterns. However, in two-class classification tasks like anomaly or\nfraud detection, unsupervised methods could do even better, because their\nprediction is not limited to previously learned types of anomalies. An\nintuitive approach of anomaly detection can be based on the distances from the\ncenters of mass of the two respective classes. Autoencoders, although trained\nwithout supervision, can also detect anomalies: considering the center of mass\nof the normal points, reconstructions have now radii, with largest radii most\nlikely indicating anomalous points. Of course, radii-based classification were\nalready possible without interposing an autoencoder. In any space, radial\nclassification can be operated, to some extent. In order to outperform it, we\nproceed to radial deformations of data (i.e. centric compression or expansions\nof axes) and autoencoder training. Any autoencoder that makes use of a data\ncenter is here baptized a centric autoencoder (cAE). A special type is the cAE\ntrained with a uniformly compressed dataset, named the centripetal autoencoder\n(cpAE). The new concept is studied here in relation with a schematic artificial\ndataset, and the derived methods show consistent score improvements. But tested\non real banking data, our radial deformation supervised algorithms alone still\nperform better that cAEs, as expected from most supervised methods;\nnonetheless, in hybrid approaches, cAEs can be combined with a radial\ndeformation of space, improving its classification score. We expect that\ncentric autoencoders will become irreplaceable objects in anomaly live\ndetection based on geometry, thanks to their ability to stem naturally on\ngeometrical algorithms and to their native capability of detecting unknown\nanomaly types.",
          "link": "http://arxiv.org/abs/2203.15884",
          "publishedOn": "2022-04-02T00:47:20.142Z",
          "wordCount": null,
          "title": "Radial Autoencoders for Enhanced Anomaly Detection. (arXiv:2203.15884v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.13634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avranas_A/0/1/0/all/0/1\">Apostolos Avranas</a> (EURECOM), <a href=\"http://arxiv.org/find/cs/1/au:+Kountouris_M/0/1/0/all/0/1\">Marios Kountouris</a> (EURECOM), <a href=\"http://arxiv.org/find/cs/1/au:+Ciblat_P/0/1/0/all/0/1\">Philippe Ciblat</a> (T&#xe9;l&#xe9;com Paris)",
          "description": "The problem of resource constrained scheduling in a dynamic and heterogeneous\nwireless setting is considered here. In our setup, the available limited\nbandwidth resources are allocated in order to serve randomly arriving service\ndemands, which in turn belong to different classes in terms of payload data\nrequirement, delay tolerance, and importance/priority. In addition to\nheterogeneous traffic, another major challenge stems from random service rates\ndue to time-varying wireless communication channels. Various approaches for\nscheduling and resource allocation can be used, ranging from simple greedy\nheuristics and constrained optimization to combinatorics. Those methods are\ntailored to specific network or application configuration and are usually\nsuboptimal. To this purpose, we resort to deep reinforcement learning (DRL) and\npropose a distributional Deep Deterministic Policy Gradient (DDPG) algorithm\ncombined with Deep Sets to tackle the aforementioned problem. Furthermore, we\npresent a novel way to use a Dueling Network, which leads to further\nperformance improvement. Our proposed algorithm is tested on both synthetic and\nreal data, showing consistent gains against state-of-the-art conventional\nmethods from combinatorics, optimization, and scheduling metrics.",
          "link": "http://arxiv.org/abs/2011.13634",
          "publishedOn": "2022-04-02T00:47:20.141Z",
          "wordCount": null,
          "title": "Deep Reinforcement Learning for Resource Constrained Multiclass Scheduling in Wireless Networks. (arXiv:2011.13634v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15547",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bright_J/0/1/0/all/0/1\">Jerrin Bright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajkumar_S/0/1/0/all/0/1\">Suryaprakash Rajkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doss_A/0/1/0/all/0/1\">Arockia Selvakumar Arockia Doss</a>",
          "description": "Convolutional Neural Networks need the construction of informative features,\nwhich are determined by channel-wise and spatial-wise information at the\nnetwork's layers. In this research, we focus on bringing in a novel solution\nthat uses sophisticated optimization for enhancing both the spatial and channel\ncomponents inside each layer's receptive field. Capsule Networks were used to\nunderstand the spatial association between features in the feature map.\nStandalone capsule networks have shown good results on comparatively simple\ndatasets than on complex datasets as a result of the inordinate amount of\nfeature information. Thus, to tackle this issue, we have proposed ME-CapsNet by\nintroducing deeper convolutional layers to extract important features before\npassing through modules of capsule layers strategically to improve the\nperformance of the network significantly. The deeper convolutional layer\nincludes blocks of Squeeze-Excitation networks which use a stochastic sampling\napproach for progressively reducing the spatial size thereby dynamically\nrecalibrating the channels by reconstructing their interdependencies without\nmuch loss of important feature information. Extensive experimentation was done\nusing commonly used datasets demonstrating the efficiency of the proposed\nME-CapsNet, which clearly outperforms various research works by achieving\nhigher accuracy with minimal model complexity in complex datasets.",
          "link": "http://arxiv.org/abs/2203.15547",
          "publishedOn": "2022-04-02T00:47:20.141Z",
          "wordCount": null,
          "title": "ME-CapsNet: A Multi-Enhanced Capsule Networks with Routing Mechanism. (arXiv:2203.15547v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.01522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1\">Zhi Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Baosheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Despite the success of deep neural networks, there are still many challenges\nin deep representation learning due to the data scarcity issues such as data\nimbalance, unseen distribution, and domain shift. To address the\nabove-mentioned issues, a variety of methods have been devised to explore the\nsample relationships in a vanilla way (i.e., from the perspectives of either\nthe input or the loss function), failing to explore the internal structure of\ndeep neural networks for learning with sample relationships. Inspired by this,\nwe propose to enable deep neural networks themselves with the ability to learn\nthe sample relationships from each mini-batch. Specifically, we introduce a\nbatch transformer module or BatchFormer, which is then applied into the batch\ndimension of each mini-batch to implicitly explore sample relationships during\ntraining. By doing this, the proposed method enables the collaboration of\ndifferent samples, e.g., the head-class samples can also contribute to the\nlearning of the tail classes for long-tailed recognition. Furthermore, to\nmitigate the gap between training and testing, we share the classifier between\nwith or without the BatchFormer during training, which can thus be removed\nduring testing. We perform extensive experiments on over ten datasets and the\nproposed method achieves significant improvements on different data scarcity\napplications without any bells and whistles, including the tasks of long-tailed\nrecognition, compositional zero-shot learning, domain generalization, and\ncontrastive learning. Code will be made publicly available at\nhttps://github.com/zhihou7/BatchFormer.",
          "link": "http://arxiv.org/abs/2203.01522",
          "publishedOn": "2022-04-02T00:47:20.141Z",
          "wordCount": null,
          "title": "BatchFormer: Learning to Explore Sample Relationships for Robust Representation Learning. (arXiv:2203.01522v2 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Karren Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markovic_D/0/1/0/all/0/1\">Dejan Markovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krenn_S/0/1/0/all/0/1\">Steven Krenn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_V/0/1/0/all/0/1\">Vasu Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_A/0/1/0/all/0/1\">Alexander Richard</a>",
          "description": "Since facial actions such as lip movements contain significant information\nabout speech content, it is not surprising that audio-visual speech enhancement\nmethods are more accurate than their audio-only counterparts. Yet,\nstate-of-the-art approaches still struggle to generate clean, realistic speech\nwithout noise artifacts and unnatural distortions in challenging acoustic\nenvironments. In this paper, we propose a novel audio-visual speech enhancement\nframework for high-fidelity telecommunications in AR/VR. Our approach leverages\naudio-visual speech cues to generate the codes of a neural speech codec,\nenabling efficient synthesis of clean, realistic speech from noisy signals.\nGiven the importance of speaker-specific cues in speech, we focus on developing\npersonalized models that work well for individual speakers. We demonstrate the\nefficacy of our approach on a new audio-visual speech dataset collected in an\nunconstrained, large vocabulary setting, as well as existing audio-visual\ndatasets, outperforming speech enhancement baselines on both quantitative\nmetrics and human evaluation studies. Please see the supplemental video for\nqualitative results at\nhttps://github.com/facebookresearch/facestar/releases/download/paper_materials/video.mp4.",
          "link": "http://arxiv.org/abs/2203.17263",
          "publishedOn": "2022-04-02T00:47:20.131Z",
          "wordCount": null,
          "title": "Audio-Visual Speech Codecs: Rethinking Audio-Visual Speech Enhancement by Re-Synthesis. (arXiv:2203.17263v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17023",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chengxin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengyuan Zhang</a>",
          "description": "Previous research has looked into ways to improve speech emotion recognition\n(SER) by utilizing both acoustic and linguistic cues of speech. However, the\npotential association between state-of-the-art ASR models and the SER task has\nyet to be investigated. In this paper, we propose a novel channel and\ntemporal-wise attention RNN (CTA-RNN) architecture based on the intermediate\nrepresentations of pre-trained ASR models. Specifically, the embeddings of a\nlarge-scale pre-trained end-to-end ASR encoder contain both acoustic and\nlinguistic information, as well as the ability to generalize to different\nspeakers, making them well suited for downstream SER task. To further exploit\nthe embeddings from different layers of the ASR encoder, we propose a novel\nCTA-RNN architecture to capture the emotional salient parts of embeddings in\nboth the channel and temporal directions. We evaluate our approach on two\npopular benchmark datasets, IEMOCAP and MSP-IMPROV, using both within-corpus\nand cross-corpus settings. Experimental results show that our proposed method\ncan achieve excellent performance in terms of accuracy and robustness.",
          "link": "http://arxiv.org/abs/2203.17023",
          "publishedOn": "2022-04-02T00:47:20.119Z",
          "wordCount": null,
          "title": "CTA-RNN: Channel and Temporal-wise Attention RNN Leveraging Pre-trained ASR Embeddings for Speech Emotion Recognition. (arXiv:2203.17023v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.06392",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hemati_H/0/1/0/all/0/1\">Hamed Hemati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1\">Damian Borth</a>",
          "description": "Recent neural Text-to-Speech (TTS) models have been shown to perform very\nwell when enough data is available. However, fine-tuning them for new speakers\nor languages is not straightforward in a low-resource setup. In this paper, we\nshow that by applying minor modifications to a Tacotron model, one can transfer\nan existing TTS model for new speakers from the same or a different language\nusing only 20 minutes of data. For this purpose, we first introduce a base\nmulti-lingual Tacotron with language-agnostic input, then demonstrate how\ntransfer learning is done for different scenarios of speaker adaptation without\nexploiting any pre-trained speaker encoder or code-switching technique. We\nevaluate the transferred model in both subjective and objective ways.",
          "link": "http://arxiv.org/abs/2011.06392",
          "publishedOn": "2022-04-02T00:47:20.118Z",
          "wordCount": null,
          "title": "Using IPA-Based Tacotron for Data Efficient Cross-Lingual Speaker Adaptation and Pronunciation Enhancement. (arXiv:2011.06392v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.05885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dankers_V/0/1/0/all/0/1\">Verna Dankers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1\">Elia Bruni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1\">Dieuwke Hupkes</a>",
          "description": "Obtaining human-like performance in NLP is often argued to require\ncompositional generalisation. Whether neural networks exhibit this ability is\nusually studied by training models on highly compositional synthetic data.\nHowever, compositionality in natural language is much more complex than the\nrigid, arithmetic-like version such data adheres to, and artificial\ncompositionality tests thus do not allow us to determine how neural models deal\nwith more realistic forms of compositionality. In this work, we re-instantiate\nthree compositionality tests from the literature and reformulate them for\nneural machine translation (NMT). Our results highlight that: i) unfavourably,\nmodels trained on more data are more compositional; ii) models are sometimes\nless compositional than expected, but sometimes more, exemplifying that\ndifferent levels of compositionality are required, and models are not always\nable to modulate between them correctly; iii) some of the non-compositional\nbehaviours are mistakes, whereas others reflect the natural variation in data.\nApart from an empirical study, our work is a call to action: we should rethink\nthe evaluation of compositionality in neural networks and develop benchmarks\nusing real data to evaluate compositionality on natural language, where\ncomposing meaning is not as straightforward as doing the math.",
          "link": "http://arxiv.org/abs/2108.05885",
          "publishedOn": "2022-04-02T00:47:20.118Z",
          "wordCount": null,
          "title": "The paradox of the compositionality of natural language: a neural machine translation case study. (arXiv:2108.05885v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Shijie Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zuohui Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "For a long period, different recommendation tasks typically require designing\ntask-specific architectures and training objectives. As a result, it is hard to\ntransfer the learned knowledge and representations from one task to another,\nthus restricting the generalization ability of existing recommendation\napproaches, e.g., a sequential recommendation model can hardly be applied or\ntransferred to a review generation method. To deal with such issues,\nconsidering that language grounding is a powerful medium to describe and\nrepresent various problems or tasks, we present a flexible and unified\ntext-to-text paradigm called \"Pretrain, Personalized Prompt, and Predict\nParadigm\" (P5) for recommendation, which unifies various recommendation tasks\nin a shared framework. In P5, all data such as user-item interactions, item\nmetadata, and user reviews are converted to a common format -- natural language\nsequences. The rich information from natural language assist P5 to capture\ndeeper semantics for recommendation. P5 learns different tasks with the same\nlanguage modeling objective during pretraining. Thus, it possesses the\npotential to serve as the foundation model for downstream recommendation tasks,\nallows easy integration with other modalities, and enables instruction-based\nrecommendation, which will revolutionize the technical form of recommender\nsystem towards universal recommendation engine. With adaptive personalized\nprompt for different users, P5 is able to make predictions in a zero-shot or\nfew-shot manner and largely reduces the necessity for extensive fine-tuning. On\nseveral recommendation benchmarks, we conduct experiments to show the\neffectiveness of our generative approach. We will release our prompts and\npretrained P5 language model to help advance future research on Recommendation\nas Language Processing (RLP) and Personalized Foundation Models.",
          "link": "http://arxiv.org/abs/2203.13366",
          "publishedOn": "2022-04-02T00:47:20.118Z",
          "wordCount": null,
          "title": "Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5). (arXiv:2203.13366v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.10811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ben_Shabat_Y/0/1/0/all/0/1\">Yizhak Ben-Shabat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koneputugodage_C/0/1/0/all/0/1\">Chamin Hewa Koneputugodage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1\">Stephen Gould</a>",
          "description": "Shape implicit neural representations (INRs) have recently shown to be\neffective in shape analysis and reconstruction tasks. Existing INRs require\npoint coordinates to learn the implicit level sets of the shape. When a normal\nvector is available for each point, a higher fidelity representation can be\nlearned, however normal vectors are often not provided as raw data.\nFurthermore, the method's initialization has been shown to play a crucial role\nfor surface reconstruction. In this paper, we propose a divergence guided shape\nrepresentation learning approach that does not require normal vectors as input.\nWe show that incorporating a soft constraint on the divergence of the distance\nfunction favours smooth solutions that reliably orients gradients to match the\nunknown normal at each point, in some cases even better than approaches that\nuse ground truth normal vectors directly. Additionally, we introduce a novel\ngeometric initialization method for sinusoidal INRs that further improves\nconvergence to the desired solution. We evaluate the effectiveness of our\napproach on the task of surface reconstruction and shape space learning and\nshow SOTA performance compared to other unoriented methods. Code and model\nparameters available at our project page https://chumbyte.github.io/DiGS-Site/.",
          "link": "http://arxiv.org/abs/2106.10811",
          "publishedOn": "2022-04-02T00:47:20.117Z",
          "wordCount": null,
          "title": "DiGS : Divergence guided shape implicit neural representation for unoriented point clouds. (arXiv:2106.10811v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Przyborowski_M/0/1/0/all/0/1\">Mateusz Przyborowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pabis_M/0/1/0/all/0/1\">Mateusz Pabi&#x15b;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janusz_A/0/1/0/all/0/1\">Andrzej Janusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slezak_D/0/1/0/all/0/1\">Dominik &#x15a;l&#x119;zak</a>",
          "description": "Gaussian mixture models find their place as a powerful tool, mostly in the\nclustering problem, but with proper preparation also in feature extraction,\npattern recognition, image segmentation and in general machine learning. When\nfaced with the problem of schema matching, different mixture models computed on\ndifferent pieces of data can maintain crucial information about the structure\nof the dataset. In order to measure or compare results from mixture models, the\nWasserstein distance can be very useful, however it is not easy to calculate\nfor mixture distributions. In this paper we derive one of possible\napproximations for the Wasserstein distance between Gaussian mixture models and\nreduce it to linear problem. Furthermore, application examples concerning real\nworld data are shown.",
          "link": "http://arxiv.org/abs/2111.14244",
          "publishedOn": "2022-04-02T00:47:20.117Z",
          "wordCount": null,
          "title": "Schema matching using Gaussian mixture models with Wasserstein distance. (arXiv:2111.14244v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17275",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xingyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunzhu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1\">David Held</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>",
          "description": "We consider the problem of sequential robotic manipulation of deformable\nobjects using tools. Previous works have shown that differentiable physics\nsimulators provide gradients to the environment state and help trajectory\noptimization to converge orders of magnitude faster than model-free\nreinforcement learning algorithms for deformable object manipulation. However,\nsuch gradient-based trajectory optimization typically requires access to the\nfull simulator states and can only solve short-horizon, single-skill tasks due\nto local optima. In this work, we propose a novel framework, named DiffSkill,\nthat uses a differentiable physics simulator for skill abstraction to solve\nlong-horizon deformable object manipulation tasks from sensory observations. In\nparticular, we first obtain short-horizon skills using individual tools from a\ngradient-based optimizer, using the full state information in a differentiable\nsimulator; we then learn a neural skill abstractor from the demonstration\ntrajectories which takes RGBD images as input. Finally, we plan over the skills\nby finding the intermediate goals and then solve long-horizon tasks. We show\nthe advantages of our method in a new set of sequential deformable object\nmanipulation tasks compared to previous reinforcement learning algorithms and\ncompared to the trajectory optimizer.",
          "link": "http://arxiv.org/abs/2203.17275",
          "publishedOn": "2022-04-02T00:47:20.110Z",
          "wordCount": null,
          "title": "DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with Tools. (arXiv:2203.17275v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.12967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haroush_M/0/1/0/all/0/1\">Matan Haroush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frostig_T/0/1/0/all/0/1\">Tzviel Frostig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_R/0/1/0/all/0/1\">Ruth Heller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soudry_D/0/1/0/all/0/1\">Daniel Soudry</a>",
          "description": "Background. Commonly, Deep Neural Networks (DNNs) generalize well on samples\ndrawn from a distribution similar to that of the training set. However, DNNs'\npredictions are brittle and unreliable when the test samples are drawn from a\ndissimilar distribution. This is a major concern for deployment in real-world\napplications, where such behavior may come at a considerable cost, such as\nindustrial production lines, autonomous vehicles, or healthcare applications.\nContributions. We frame Out Of Distribution (OOD) detection in DNNs as a\nstatistical hypothesis testing problem. Tests generated within our proposed\nframework combine evidence from the entire network. Unlike previous OOD\ndetection heuristics, this framework returns a $p$-value for each test sample.\nIt is guaranteed to maintain the Type I Error (T1E - incorrectly predicting OOD\nfor an actual in-distribution sample) for test data. Moreover, this allows to\ncombine several detectors while maintaining the T1E. Building on this\nframework, we suggest a novel OOD procedure based on low-order statistics. Our\nmethod achieves comparable or better results than state-of-the-art methods on\nwell-accepted OOD benchmarks, without retraining the network parameters or\nassuming prior knowledge on the test distribution -- and at a fraction of the\ncomputational cost.",
          "link": "http://arxiv.org/abs/2102.12967",
          "publishedOn": "2022-04-02T00:47:20.110Z",
          "wordCount": null,
          "title": "A statistical framework for efficient out of distribution detection in deep neural networks. (arXiv:2102.12967v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Batz_K/0/1/0/all/0/1\">Kevin Batz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallus_A/0/1/0/all/0/1\">Adrian Gallus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaminski_B/0/1/0/all/0/1\">Benjamin Lucien Kaminski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katoen_J/0/1/0/all/0/1\">Joost-Pieter Katoen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winkler_T/0/1/0/all/0/1\">Tobias Winkler</a>",
          "description": "We study weighted programming, a programming paradigm for specifying\nmathematical models. More specifically, the weighted programs we investigate\nare like usual imperative programs with two additional features: (1)\nnondeterministic branching and (2) weighting execution traces. Weights can be\nnumbers but also other objects like words from an alphabet, polynomials, formal\npower series, or cardinal numbers. We argue that weighted programming as a\nparadigm can be used to specify mathematical models beyond probability\ndistributions (as is done in probabilistic programming).\n\nWe develop weakest-precondition- and weakest-liberal-precondition-style\ncalculi \\`{a} la Dijkstra for reasoning about mathematical models specified by\nweighted programs. We present several case studies. For instance, we use\nweighted programming to model the ski rental problem - an optimization problem.\nWe model not only the optimization problem itself, but also the best\ndeterministic online algorithm for solving this problem as weighted programs.\nBy means of weakest-precondition-style reasoning, we can determine the\ncompetitive ratio of the online algorithm on source code level.",
          "link": "http://arxiv.org/abs/2202.07577",
          "publishedOn": "2022-04-02T00:47:20.110Z",
          "wordCount": null,
          "title": "Weighted Programming. (arXiv:2202.07577v2 [cs.PL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fuyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xi Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tingyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1\">Yu Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Junzhou Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_Y/0/1/0/all/0/1\">Yatao Bian</a>",
          "description": "As a powerful tool for modeling complex relationships, hypergraphs are\ngaining popularity from the graph learning community. However, commonly used\nframeworks in deep hypergraph learning focus on hypergraphs with\n\\textit{edge-independent vertex weights}(EIVWs), without considering\nhypergraphs with \\textit{edge-dependent vertex weights} (EDVWs) that have more\nmodeling power. To compensate for this, in this paper, we present General\nHypergraph Spectral Convolution(GHSC), a general learning framework that not\nonly can handle EDVW and EIVW hypergraphs, but more importantly, enables\ntheoretically explicitly utilizing the existing powerful Graph Convolutional\nNeural Networks (GCNNs) such that largely ease the design of Hypergraph Neural\nNetworks. In this framework, the graph Laplacian of the given undirected GCNNs\nis replaced with a unified hypergraph Laplacian that incorporates vertex weight\ninformation from a random walk perspective by equating our defined generalized\nhypergraphs with simple undirected graphs. Extensive experiments from various\ndomains including social network analysis, visual objective classification,\nprotein learning demonstrate that the proposed framework can achieve\nstate-of-the-art performance.",
          "link": "http://arxiv.org/abs/2203.16939",
          "publishedOn": "2022-04-02T00:47:20.109Z",
          "wordCount": null,
          "title": "Hypergraph Convolutional Networks via Equivalency between Hypergraphs and Undirected Graphs. (arXiv:2203.16939v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1908.02203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Udeshi_S/0/1/0/all/0/1\">Sakshi Udeshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shanshan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_G/0/1/0/all/0/1\">Gerald Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loh_L/0/1/0/all/0/1\">Lionell Loh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawshan_L/0/1/0/all/0/1\">Louth Rawshan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chattopadhyay_S/0/1/0/all/0/1\">Sudipta Chattopadhyay</a>",
          "description": "Machine Learning (ML) has automated a multitude of our day-to-day decision\nmaking domains such as education, employment and driving automation. The\ncontinued success of ML largely depends on our ability to trust the model we\nare using. Recently, a new class of attacks called Backdoor Attacks have been\ndeveloped. These attacks undermine the user's trust in ML models. In this work,\nwe present NEO, a model agnostic framework to detect and mitigate such backdoor\nattacks in image classification ML models. For a given image classification\nmodel, our approach analyses the inputs it receives and determines if the model\nis backdoored. In addition to this feature, we also mitigate these attacks by\ndetermining the correct predictions of the poisoned images. An appealing\nfeature of NEO is that it can, for the first time, isolate and reconstruct the\nbackdoor trigger. NEO is also the first defence methodology, to the best of our\nknowledge that is completely blackbox.\n\nWe have implemented NEO and evaluated it against three state of the art\npoisoned models. These models include highly critical applications such as\ntraffic sign detection (USTS) and facial detection. In our evaluation, we show\nthat NEO can detect $\\approx$88% of the poisoned inputs on average and it is as\nfast as 4.4 ms per input image. We also reconstruct the poisoned input for the\nuser to effectively test their systems.",
          "link": "http://arxiv.org/abs/1908.02203",
          "publishedOn": "2022-04-02T00:47:20.106Z",
          "wordCount": null,
          "title": "Model Agnostic Defence against Backdoor Attacks in Machine Learning. (arXiv:1908.02203v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16822",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zuluaga_Gomez_J/0/1/0/all/0/1\">Juan Zuluaga-Gomez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prasad_A/0/1/0/all/0/1\">Amrutha Prasad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nigmatulina_I/0/1/0/all/0/1\">Iuliia Nigmatulina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sarfjoo_S/0/1/0/all/0/1\">Saeed Sarfjoo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Motlicek_P/0/1/0/all/0/1\">Petr Motlicek</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kleinert_M/0/1/0/all/0/1\">Matthias Kleinert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Helmke_H/0/1/0/all/0/1\">Hartmut Helmke</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ohneiser_O/0/1/0/all/0/1\">Oliver Ohneiser</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhan_Q/0/1/0/all/0/1\">Qingran Zhan</a>",
          "description": "Recent work on self-supervised pre-training focus on leveraging large-scale\nunlabeled speech data to build robust end-to-end (E2E) acoustic models (AM)\nthat can be later fine-tuned on downstream tasks e.g., automatic speech\nrecognition (ASR). Yet, few works investigated the impact on performance when\nthe data substantially differs between the pre-training and downstream\nfine-tuning phases (i.e., domain shift). We target this scenario by analyzing\nthe robustness of Wav2Vec2.0 and XLS-R models on downstream ASR for a\ncompletely unseen domain, i.e., air traffic control (ATC) communications. We\nbenchmark the proposed models on four challenging ATC test sets\n(signal-to-noise ratio varies between 5 to 20 dB). Relative word error rate\n(WER) reduction between 20% to 40% are obtained in comparison to hybrid-based\nstate-of-the-art ASR baselines by fine-tuning E2E acoustic models with a small\nfraction of labeled data. We also study the impact of fine-tuning data size on\nWERs, going from 5 minutes (few-shot) to 15 hours.",
          "link": "http://arxiv.org/abs/2203.16822",
          "publishedOn": "2022-04-02T00:47:20.105Z",
          "wordCount": null,
          "title": "How Does Pre-trained Wav2Vec2.0 Perform on Domain Shifted ASR? An Extensive Benchmark on Air Traffic Control Communications. (arXiv:2203.16822v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.14785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1\">Tianyu Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huishuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yinpeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Correctly classifying adversarial examples is an essential but challenging\nrequirement for safely deploying machine learning models. As reported in\nRobustBench, even the state-of-the-art adversarially trained models struggle to\nexceed 67% robust test accuracy on CIFAR-10, which is far from practical. A\ncomplementary way towards robustness is to introduce a rejection option,\nallowing the model to not return predictions on uncertain inputs, where\nconfidence is a commonly used certainty proxy. Along with this routine, we find\nthat confidence and a rectified confidence (R-Con) can form two coupled\nrejection metrics, which could provably distinguish wrongly classified inputs\nfrom correctly classified ones. This intriguing property sheds light on using\ncoupling strategies to better detect and reject adversarial examples. We\nevaluate our rectified rejection (RR) module on CIFAR-10, CIFAR-10-C, and\nCIFAR-100 under several attacks including adaptive ones, and demonstrate that\nthe RR module is compatible with different adversarial training frameworks on\nimproving robustness, with little extra computation. The code is available at\nhttps://github.com/P2333/Rectified-Rejection.",
          "link": "http://arxiv.org/abs/2105.14785",
          "publishedOn": "2022-04-02T00:47:20.105Z",
          "wordCount": null,
          "title": "Two Coupled Rejection Metrics Can Tell Adversarial Examples Apart. (arXiv:2105.14785v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.04671",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_T/0/1/0/all/0/1\">Tianyi Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1\">Yuejiao Sun</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xiao_Q/0/1/0/all/0/1\">Quan Xiao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1\">Wotao Yin</a>",
          "description": "Stochastic bilevel optimization generalizes the classic stochastic\noptimization from the minimization of a single objective to the minimization of\nan objective function that depends the solution of another optimization\nproblem. Recently, stochastic bilevel optimization is regaining popularity in\nemerging machine learning applications such as hyper-parameter optimization and\nmodel-agnostic meta learning. To solve this class of stochastic optimization\nproblems, existing methods require either double-loop or two-timescale updates,\nwhich are sometimes less efficient. This paper develops a new optimization\nmethod for a class of stochastic bilevel problems that we term Single-Timescale\nstochAstic BiLevEl optimization (STABLE) method. STABLE runs in a single loop\nfashion, and uses a single-timescale update with a fixed batch size. To achieve\nan $\\epsilon$-stationary point of the bilevel problem, STABLE requires ${\\cal\nO}(\\epsilon^{-2})$ samples in total; and to achieve an $\\epsilon$-optimal\nsolution in the strongly convex case, STABLE requires ${\\cal O}(\\epsilon^{-1})$\nsamples. To the best of our knowledge, this is the first bilevel optimization\nalgorithm achieving the same order of sample complexity as the stochastic\ngradient descent method for the single-level stochastic optimization.",
          "link": "http://arxiv.org/abs/2102.04671",
          "publishedOn": "2022-04-02T00:47:20.103Z",
          "wordCount": null,
          "title": "A Single-Timescale Method for Stochastic Bilevel Optimization. (arXiv:2102.04671v4 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17019",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chernyak_B/0/1/0/all/0/1\">Bronya R. Chernyak</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Simon_T/0/1/0/all/0/1\">Talia Ben Simon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Segal_Y/0/1/0/all/0/1\">Yael Segal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Steffman_J/0/1/0/all/0/1\">Jeremy Steffman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chodroff_E/0/1/0/all/0/1\">Eleanor Chodroff</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cole_J/0/1/0/all/0/1\">Jennifer S. Cole</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Keshet_J/0/1/0/all/0/1\">Joseph Keshet</a>",
          "description": "Vocal fry or creaky voice refers to a voice quality characterized by\nirregular glottal opening and low pitch. It occurs in diverse languages and is\nprevalent in American English, where it is used not only to mark phrase\nfinality, but also sociolinguistic factors and affect. Due to its irregular\nperiodicity, creaky voice challenges automatic speech processing and\nrecognition systems, particularly for languages where creak is frequently used.\n\nThis paper proposes a deep learning model to detect creaky voice in fluent\nspeech. The model is composed of an encoder and a classifier trained together.\nThe encoder takes the raw waveform and learns a representation using a\nconvolutional neural network. The classifier is implemented as a multi-headed\nfully-connected network trained to detect creaky voice, voicing, and pitch,\nwhere the last two are used to refine creak prediction. The model is trained\nand tested on speech of American English speakers, annotated for creak by\ntrained phoneticians.\n\nWe evaluated the performance of our system using two encoders: one is\ntailored for the task, and the other is based on a state-of-the-art\nunsupervised representation. Results suggest our best-performing system has\nimproved recall and F1 scores compared to previous methods on unseen data.",
          "link": "http://arxiv.org/abs/2203.17019",
          "publishedOn": "2022-04-02T00:47:20.102Z",
          "wordCount": null,
          "title": "DeepFry: Identifying Vocal Fry Using Deep Neural Networks. (arXiv:2203.17019v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17004",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Welker_S/0/1/0/all/0/1\">Simon Welker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Richter_J/0/1/0/all/0/1\">Julius Richter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gerkmann_T/0/1/0/all/0/1\">Timo Gerkmann</a>",
          "description": "Score-based generative models (SGMs) have recently shown impressive results\nfor difficult generative tasks such as the unconditional and conditional\ngeneration of natural images and audio signals. In this work, we extend these\nmodels to the complex short-time Fourier transform (STFT) domain, proposing a\nnovel training task for speech enhancement using a complex-valued deep neural\nnetwork. We derive this training task within the formalism of stochastic\ndifferential equations, thereby enabling the use of predictor-corrector\nsamplers. We provide alternative formulations inspired by previous publications\non using SGMs for speech enhancement, avoiding the need for any prior\nassumptions on the noise distribution and making the training task purely\ngenerative which, as we show, results in improved enhancement performance.",
          "link": "http://arxiv.org/abs/2203.17004",
          "publishedOn": "2022-04-02T00:47:20.085Z",
          "wordCount": null,
          "title": "Speech Enhancement with Score-Based Generative Models in the Complex STFT Domain. (arXiv:2203.17004v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Houssou_R/0/1/0/all/0/1\">Regis Houssou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augustin_M/0/1/0/all/0/1\">Mihai-Cezar Augustin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rappos_E/0/1/0/all/0/1\">Efstratios Rappos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonvin_V/0/1/0/all/0/1\">Vivien Bonvin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robert_Nicoud_S/0/1/0/all/0/1\">Stephan Robert-Nicoud</a>",
          "description": "This paper proposes a new method to generate synthetic data sets based on\ncopula models. Our goal is to produce surrogate data resembling real data in\nterms of marginal and joint distributions. We present a complete and reliable\nalgorithm for generating a synthetic data set comprising numeric or categorical\nvariables. Applying our methodology to two datasets shows better performance\ncompared to other methods such as SMOTE and autoencoders.",
          "link": "http://arxiv.org/abs/2203.17250",
          "publishedOn": "2022-04-02T00:47:20.085Z",
          "wordCount": null,
          "title": "Generation and Simulation of Synthetic Datasets with Copulas. (arXiv:2203.17250v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gadre_S/0/1/0/all/0/1\">Samir Yitzhak Gadre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ehsani_K/0/1/0/all/0/1\">Kiana Ehsani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuran Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mottaghi_R/0/1/0/all/0/1\">Roozbeh Mottaghi</a>",
          "description": "We propose Continuous Scene Representations (CSR), a scene representation\nconstructed by an embodied agent navigating within a space, where objects and\ntheir relationships are modeled by continuous valued embeddings. Our method\ncaptures feature relationships between objects, composes them into a graph\nstructure on-the-fly, and situates an embodied agent within the representation.\nOur key insight is to embed pair-wise relationships between objects in a latent\nspace. This allows for a richer representation compared to discrete relations\n(e.g., [support], [next-to]) commonly used for building scene representations.\nCSR can track objects as the agent moves in a scene, update the representation\naccordingly, and detect changes in room configurations. Using CSR, we\noutperform state-of-the-art approaches for the challenging downstream task of\nvisual room rearrangement, without any task specific training. Moreover, we\nshow the learned embeddings capture salient spatial details of the scene and\nshow applicability to real world data. A summery video and code is available at\nhttps://prior.allenai.org/projects/csr.",
          "link": "http://arxiv.org/abs/2203.17251",
          "publishedOn": "2022-04-02T00:47:20.084Z",
          "wordCount": null,
          "title": "Continuous Scene Representations for Embodied AI. (arXiv:2203.17251v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gulati_M/0/1/0/all/0/1\">Manoj Gulati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arjunan_P/0/1/0/all/0/1\">Pandarasamy Arjunan</a>",
          "description": "Modern buildings are densely equipped with smart energy meters, which\nperiodically generate a massive amount of time-series data yielding few million\ndata points every day. This data can be leveraged to discover the underlying\nloads, infer their energy consumption patterns, inter-dependencies on\nenvironmental factors, and the building's operational properties. Furthermore,\nit allows us to simultaneously identify anomalies present in the electricity\nconsumption profiles, which is a big step towards saving energy and achieving\nglobal sustainability. However, to date, the lack of large-scale annotated\nenergy consumption datasets hinders the ongoing research in anomaly detection.\nWe contribute to this effort by releasing a well-annotated version of a\npublicly available ASHRAE Great Energy Predictor III data set containing 1,413\nsmart electricity meter time series spanning over one year. In addition, we\nbenchmark the performance of eight state-of-the-art anomaly detection methods\non our dataset and compare their performance.",
          "link": "http://arxiv.org/abs/2203.17256",
          "publishedOn": "2022-04-02T00:47:20.082Z",
          "wordCount": null,
          "title": "LEAD1.0: A Large-scale Annotated Dataset for Energy Anomaly Detection in Commercial Buildings. (arXiv:2203.17256v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1\">Stephen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frostig_R/0/1/0/all/0/1\">Roy Frostig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1\">Mahdi Soltanolkotabi</a>",
          "description": "We initiate a study of supervised learning from many independent sequences\n(\"trajectories\") of non-independent covariates, reflecting tasks in sequence\nmodeling, control, and reinforcement learning. Conceptually, our\nmulti-trajectory setup sits between two traditional settings in statistical\nlearning theory: learning from independent examples and learning from a single\nauto-correlated sequence. Our conditions for efficient learning generalize the\nformer setting--trajectories must be non-degenerate in ways that extend\nstandard requirements for independent examples. They do not require that\ntrajectories be ergodic, long, nor strictly stable.\n\nFor linear least-squares regression, given $n$-dimensional examples produced\nby $m$ trajectories, each of length $T$, we observe a notable change in\nstatistical efficiency as the number of trajectories increases from a few\n(namely $m \\lesssim n$) to many (namely $m \\gtrsim n$). Specifically, we\nestablish that the worst-case error rate this problem is $\\Theta(n / m T)$\nwhenever $m \\gtrsim n$. Meanwhile, when $m \\lesssim n$, we establish a (sharp)\nlower bound of $\\Omega(n^2 / m^2 T)$ on the worst-case error rate, realized by\na simple, marginally unstable linear dynamical system. A key upshot is that, in\ndomains where trajectories regularly reset, the error rate eventually behaves\nas if all of the examples were independent altogether, drawn from their\nmarginals. As a corollary of our analysis, we also improve guarantees for the\nlinear system identification problem.",
          "link": "http://arxiv.org/abs/2203.17193",
          "publishedOn": "2022-04-02T00:47:20.077Z",
          "wordCount": null,
          "title": "Learning from many trajectories. (arXiv:2203.17193v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yen-Lun Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanjun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chung-Che Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Jyh-Shing Roger Jang</a>",
          "description": "The countermeasure (CM) model is developed to protect Automatic Speaker\nVerification (ASV) systems from spoof attacks and prevent resulting personal\ninformation leakage. Based on practicality and security considerations, the CM\nmodel is usually deployed on edge devices, which have more limited computing\nresources and storage space than cloud- based systems. This work proposes\ntraining strategies for a lightweight CM model for ASV, using generalized end-\nto-end (GE2E) pre-training and adversarial fine-tuning to improve performance,\nand applying knowledge distillation (KD) to reduce the size of the CM model. In\nthe evalua- tion phase of the ASVspoof 2021 Logical Access task, the\nlightweight ResNetSE model reaches min t-DCF 0.2695 and EER 3.54%. Compared to\nthe teacher model, the lightweight student model only uses 22.5% of parameters\nand 21.1% of multiply and accumulate operands of the teacher model.",
          "link": "http://arxiv.org/abs/2203.17031",
          "publishedOn": "2022-04-02T00:47:20.076Z",
          "wordCount": null,
          "title": "Training strategy for a lightweight countermeasure model for automatic speaker verification. (arXiv:2203.17031v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Izadi_M/0/1/0/all/0/1\">Maliheh Izadi</a>",
          "description": "Users use Issue Tracking Systems to keep track and manage issue reports in\ntheir repositories. An issue is a rich source of software information that\ncontains different reports including a problem, a request for new features, or\nmerely a question about the software product. As the number of these issues\nincreases, it becomes harder to manage them manually. Thus, automatic\napproaches are proposed to help facilitate the management of issue reports.\n\nThis paper describes CatIss, an automatic CATegorizer of ISSue reports which\nis built upon the Transformer-based pre-trained RoBERTa model. CatIss\nclassifies issue reports into three main categories of Bug reports,\nEnhancement/feature requests, and Questions. First, the datasets provided for\nthe NLBSE tool competition are cleaned and preprocessed. Then, the pre-trained\nRoBERTa model is fine-tuned on the preprocessed dataset. Evaluating CatIss on\nabout 80 thousand issue reports from GitHub, indicates that it performs very\nwell surpassing the competition baseline, TicketTagger, and achieving 87.2%\nF1-score (micro average). Additionally, as CatIss is trained on a wide set of\nrepositories, it is a generic prediction model, hence applicable for any unseen\nsoftware project or projects with little historical data. Scripts for cleaning\nthe datasets, training CatIss, and evaluating the model are publicly available.",
          "link": "http://arxiv.org/abs/2203.17196",
          "publishedOn": "2022-04-02T00:47:20.076Z",
          "wordCount": null,
          "title": "CatIss: An Intelligent Tool for Categorizing Issues Reports using Transformers. (arXiv:2203.17196v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.01539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dapeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ran He</a>",
          "description": "To ease the burden of labeling, unsupervised domain adaptation (UDA) aims to\ntransfer knowledge in previous and related labeled datasets (sources) to a new\nunlabeled dataset (target). Despite impressive progress, prior methods always\nneed to access the raw source data and develop data-dependent alignment\napproaches to recognize the target samples in a transductive learning manner,\nwhich may raise privacy concerns from source individuals. Several recent\nstudies resort to an alternative solution by exploiting the well-trained\nwhite-box model from the source domain, yet, it may still leak the raw data\nthrough generative adversarial learning. This paper studies a practical and\ninteresting setting for UDA, where only black-box source models (i.e., only\nnetwork predictions are available) are provided during adaptation in the target\ndomain. To solve this problem, we propose a new two-step knowledge adaptation\nframework called DIstill and fine-tuNE (DINE). Taking into consideration the\ntarget data structure, DINE first distills the knowledge from the source\npredictor to a customized target model, then fine-tunes the distilled model to\nfurther fit the target domain. Besides, neural networks are not required to be\nidentical across domains in DINE, even allowing effective adaptation on a\nlow-resource device. Empirical results on three UDA scenarios (i.e.,\nsingle-source, multi-source, and partial-set) confirm that DINE achieves highly\ncompetitive performance compared to state-of-the-art data-dependent approaches.\nCode is available at \\url{https://github.com/tim-learn/DINE/}.",
          "link": "http://arxiv.org/abs/2104.01539",
          "publishedOn": "2022-04-02T00:47:20.076Z",
          "wordCount": null,
          "title": "DINE: Domain Adaptation from Single and Multiple Black-box Predictors. (arXiv:2104.01539v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17128",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cohen_S/0/1/0/all/0/1\">Samuel N. Cohen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jiang_D/0/1/0/all/0/1\">Deqing Jiang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sirignano_J/0/1/0/all/0/1\">Justin Sirignano</a>",
          "description": "Solving high-dimensional partial differential equations (PDEs) is a major\nchallenge in scientific computing. We develop a new numerical method for\nsolving elliptic-type PDEs by adapting the Q-learning algorithm in\nreinforcement learning. Our \"Q-PDE\" algorithm is mesh-free and therefore has\nthe potential to overcome the curse of dimensionality. Using a neural tangent\nkernel (NTK) approach, we prove that the neural network approximator for the\nPDE solution, trained with the Q-PDE algorithm, converges to the trajectory of\nan infinite-dimensional ordinary differential equation (ODE) as the number of\nhidden units $\\rightarrow \\infty$. For monotone PDE (i.e. those given by\nmonotone operators, which may be nonlinear), despite the lack of a spectral gap\nin the NTK, we then prove that the limit neural network, which satisfies the\ninfinite-dimensional ODE, converges in $L^2$ to the PDE solution as the\ntraining time $\\rightarrow \\infty$. More generally, we can prove that any fixed\npoint of the wide-network limit for the Q-PDE algorithm is a solution of the\nPDE (not necessarily under the monotone condition). The numerical performance\nof the Q-PDE algorithm is studied for several elliptic PDEs.",
          "link": "http://arxiv.org/abs/2203.17128",
          "publishedOn": "2022-04-02T00:47:20.075Z",
          "wordCount": null,
          "title": "Neural Q-learning for solving elliptic PDEs. (arXiv:2203.17128v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Weizhi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingrui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1\">Kai Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weiyu Li</a>",
          "description": "Dimension reduction and data quantization are two important methods for\nreducing data complexity. In the paper, we study the methodology of first\nreducing data dimension by random projection and then quantizing the\nprojections to ternary or binary codes, which has been widely applied in\nclassification. Usually, the quantization will seriously degrade the accuracy\nof classification due to high quantization errors. Interestingly, however, we\nobserve that the quantization could provide comparable and often superior\naccuracy, as the data to be quantized are sparse features generated with common\nfilters. Furthermore, this quantization property could be maintained in the\nrandom projections of sparse features, if both the features and random\nprojection matrices are sufficiently sparse. By conducting extensive\nexperiments, we validate and analyze this intriguing property.",
          "link": "http://arxiv.org/abs/2203.16798",
          "publishedOn": "2022-04-02T00:47:20.074Z",
          "wordCount": null,
          "title": "Ternary and Binary Quantization for Improved Classification. (arXiv:2203.16798v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hardt_M/0/1/0/all/0/1\">Moritz Hardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagadeesan_M/0/1/0/all/0/1\">Meena Jagadeesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendler_Dunner_C/0/1/0/all/0/1\">Celestine Mendler-D&#xfc;nner</a>",
          "description": "We introduce the notion of performative power, which measures the ability of\na firm operating an algorithmic system, such as a digital content\nrecommendation platform, to steer a population. We relate performative power to\nthe economic theory of market power. Traditional economic concepts are well\nknown to struggle with identifying anti-competitive patterns in digital\nplatforms--a core challenge is the difficulty of defining the market, its\nparticipants, products, and prices. Performative power sidesteps the problem of\nmarket definition by focusing on a directly observable statistical measure\ninstead. High performative power enables a platform to profit from steering\nparticipant behavior, whereas low performative power ensures that learning from\nhistorical data is close to optimal.\n\nOur first general result shows that under low performative power, a firm\ncannot do better than standard supervised learning on observed data. We draw an\nanalogy with a firm being a price-taker, an economic condition that arises\nunder perfect competition in classical market models. We then contrast this\nwith a market where performative power is concentrated and show that the\nequilibrium state can differ significantly. We go on to study performative\npower in a concrete setting of strategic classification where participants can\nswitch between competing firms. We show that monopolies maximize performative\npower and disutility for the participant, while competition and outside options\ndecrease performative power. We end on a discussion of connections to measures\nof market power in economics and of the relationship with ongoing antitrust\ndebates.",
          "link": "http://arxiv.org/abs/2203.17232",
          "publishedOn": "2022-04-02T00:47:20.074Z",
          "wordCount": null,
          "title": "Performative Power. (arXiv:2203.17232v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16582",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1\">Biwei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magliacane_S/0/1/0/all/0/1\">Sara Magliacane</a>",
          "description": "Dealing with non-stationarity in environments (i.e., transition dynamics) and\nobjectives (i.e., reward functions) is a challenging problem that is crucial in\nreal-world applications of reinforcement learning (RL). Most existing\napproaches only focus on families of stationary MDPs, in which the\nnon-stationarity is episodic, i.e., the change is only possible across\nepisodes. The few works that do consider non-stationarity without a specific\nboundary, i.e., also allow for changes within an episode, model the changes\nmonolithically in a single shared embedding vector. In this paper, we propose\nFactored Adaptation for Non-Stationary RL (FANS-RL), a factored adaption\napproach that explicitly learns the individual latent change factors affecting\nthe transition dynamics and reward functions. FANS-RL learns jointly the\nstructure of a factored MDP and a factored representation of the time-varying\nchange factors, as well as the specific state components that they affect, via\na factored non-stationary variational autoencoder. Through this general\nframework, we can consider general non-stationary scenarios with different\nchanging function types and changing frequency. Experimental results\ndemonstrate that FANS-RL outperforms existing approaches in terms of rewards,\ncompactness of the latent state representation and robustness to varying\ndegrees of non-stationarity.",
          "link": "http://arxiv.org/abs/2203.16582",
          "publishedOn": "2022-04-02T00:47:20.073Z",
          "wordCount": null,
          "title": "Factored Adaptation for Non-Stationary Reinforcement Learning. (arXiv:2203.16582v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1\">James Seale Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1\">Junjiao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_Y/0/1/0/all/0/1\">Yen-Chang Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1\">Zsolt Kira</a>",
          "description": "Continual learning describes a setting where machine learning models learn\nnovel concepts from continuously shifting training data, while simultaneously\navoiding degradation of knowledge on previously seen classes (a phenomenon\nknown as the catastrophic forgetting problem) which may disappear from the\ntraining data for extended periods of time. Current approaches for continual\nlearning of a single expanding task (aka class-incremental continual learning)\nrequire extensive rehearsal of previously seen data to avoid this degradation\nof knowledge. Unfortunately, rehearsal comes at a sharp cost to memory and\ncomputation, and it may also violate data-privacy. Instead, we explore\ncombining knowledge distillation and parameter regularization in new ways to\nachieve strong continual learning performance without rehearsal. Specifically,\nwe take a deep dive into common continual learning techniques: prediction\ndistillation, feature distillation, L2 parameter regularization, and EWC\nparameter regularization. We first disprove the common assumption that\nparameter regularization techniques fail for rehearsal-free continual learning\nof a single, expanding task. Next, we explore how to leverage knowledge from a\npre-trained model in rehearsal-free continual learning and find that vanilla L2\nparameter regularization outperforms EWC parameter regularization and feature\ndistillation. We then highlight the impact of the rehearsal-free continual\nlearning settings with a classifier expansion benchmark, showing that a\nstrategy based on our findings combined with a positive/negative label\nbalancing heuristic can close the performance gap between the upper bound and\nthe existing strategies by up to roughly 50%. Finally, we show that a simple\nmethod consisting of pre-training, L2 regularization, and prediction\ndistillation can even outperform rehearsal-based methods on the common\nCIFAR-100 benchmark.",
          "link": "http://arxiv.org/abs/2203.17269",
          "publishedOn": "2022-04-02T00:47:20.070Z",
          "wordCount": null,
          "title": "A Closer Look at Rehearsal-Free Continual Learning. (arXiv:2203.17269v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Organisciak_D/0/1/0/all/0/1\">Daniel Organisciak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1\">Hubert P. H. Shum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nwoye_E/0/1/0/all/0/1\">Ephraim Nwoye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_W/0/1/0/all/0/1\">Wai Lok Woo</a>",
          "description": "Schizophrenia is a severe mental health condition that requires a long and\ncomplicated diagnostic process. However, early diagnosis is vital to control\nsymptoms. Deep learning has recently become a popular way to analyse and\ninterpret medical data. Past attempts to use deep learning for schizophrenia\ndiagnosis from brain-imaging data have shown promise but suffer from a large\ntraining-application gap - it is difficult to apply lab research to the real\nworld. We propose to reduce this training-application gap by focusing on\nreadily accessible data. We collect a data set of psychiatric observations of\npatients based on DSM-5 criteria. Because similar data is already recorded in\nall mental health clinics that diagnose schizophrenia using DSM-5, our method\ncould be easily integrated into current processes as a tool to assist\nclinicians, whilst abiding by formal diagnostic criteria. To facilitate\nreal-world usage of our system, we show that it is interpretable and robust.\nUnderstanding how a machine learning tool reaches its diagnosis is essential to\nallow clinicians to trust that diagnosis. To interpret the framework, we fuse\ntwo complementary attention mechanisms, 'squeeze and excitation' and\n'self-attention', to determine global attribute importance and attribute\ninteractivity, respectively. The model uses these importance scores to make\ndecisions. This allows clinicians to understand how a diagnosis was reached,\nimproving trust in the model. Because machine learning models often struggle to\ngeneralise to data from different sources, we perform experiments with\naugmented test data to evaluate the model's applicability to the real world. We\nfind that our model is more robust to perturbations, and should therefore\nperform better in a clinical setting. It achieves 98% accuracy with 10-fold\ncross-validation.",
          "link": "http://arxiv.org/abs/2203.17085",
          "publishedOn": "2022-04-02T00:47:20.069Z",
          "wordCount": null,
          "title": "RobIn: A Robust Interpretable Deep Network for Schizophrenia Diagnosis. (arXiv:2203.17085v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17066",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hazra_S/0/1/0/all/0/1\">Souvik Hazra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feng_H/0/1/0/all/0/1\">Hao Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiprit_G/0/1/0/all/0/1\">Gamze Naz Kiprit</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stephan_M/0/1/0/all/0/1\">Michael Stephan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Servadei_L/0/1/0/all/0/1\">Lorenzo Servadei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wille_R/0/1/0/all/0/1\">Robert Wille</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Weigel_R/0/1/0/all/0/1\">Robert Weigel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Santra_A/0/1/0/all/0/1\">Avik Santra</a>",
          "description": "Gesture recognition is one of the most intuitive ways of interaction and has\ngathered particular attention for human computer interaction. Radar sensors\npossess multiple intrinsic properties, such as their ability to work in low\nillumination, harsh weather conditions, and being low-cost and compact, making\nthem highly preferable for a gesture recognition solution. However, most\nliterature work focuses on solutions with a limited range that is lower than a\nmeter. We propose a novel architecture for a long-range (1m - 2m) gesture\nrecognition solution that leverages a point cloud-based cross-learning approach\nfrom camera point cloud to 60-GHz FMCW radar point cloud, which allows learning\nbetter representations while suppressing noise. We use a variant of Dynamic\nGraph CNN (DGCNN) for the cross-learning, enabling us to model relationships\nbetween the points at a local and global level and to model the temporal\ndynamics a Bi-LSTM network is employed. In the experimental results section, we\ndemonstrate our model's overall accuracy of 98.4% for five gestures and its\ngeneralization capability.",
          "link": "http://arxiv.org/abs/2203.17066",
          "publishedOn": "2022-04-02T00:47:20.067Z",
          "wordCount": null,
          "title": "Cross-modal Learning of Graph Representations using Radar Point Cloud for Long-Range Gesture Recognition. (arXiv:2203.17066v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prasad_L/0/1/0/all/0/1\">Lodagala V S V Durga Prasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sreyan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Umesh_S/0/1/0/all/0/1\">S. Umesh</a>",
          "description": "While self-supervised speech representation learning (SSL) models serve a\nvariety of downstream tasks, these models have been observed to overfit to the\ndomain from which the unlabelled data originates. To alleviate this issue, we\npropose PADA (Pruning Assisted Domain Adaptation) and zero out redundant\nweights from models pre-trained on large amounts of out-of-domain (OOD) data.\nIntuitively, this helps to make space for the target-domain ASR finetuning. The\nredundant weights can be identified through various pruning strategies which\nhave been discussed in detail as a part of this work. Specifically, we\ninvestigate the effect of the recently discovered Task-Agnostic and Task-Aware\npruning on PADA and propose a new pruning paradigm based on the latter, which\nwe call Cross-Domain Task-Aware Pruning (CD-TAW). CD-TAW obtains the initial\npruning mask from a well fine-tuned OOD model, which makes it starkly different\nfrom the rest of the pruning strategies discussed in the paper. Our proposed\nCD-TAW methodology achieves up to 20.6% relative WER improvement over our\nbaseline when fine-tuned on a 2-hour subset of Switchboard data without\nlanguage model (LM) decoding. Furthermore, we conduct a detailed analysis to\nhighlight the key design choices of our proposed method.",
          "link": "http://arxiv.org/abs/2203.16965",
          "publishedOn": "2022-04-02T00:47:20.064Z",
          "wordCount": null,
          "title": "PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations. (arXiv:2203.16965v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Landverk_M/0/1/0/all/0/1\">Marius C. Landverk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riemer_Sorensen_S/0/1/0/all/0/1\">Signe Riemer-S&#xf8;rensen</a>",
          "description": "Measuring model performance is a key issue for deep learning practitioners.\nHowever, we often lack the ability to explain why a specific architecture\nattains superior predictive accuracy for a given data set. Often, validation\naccuracy is used as a performance heuristic quantifying how well a network\ngeneralizes to unseen data, but it does not capture anything about the\ninformation flow in the model. Mutual information can be used as a measure of\nthe quality of internal representations in deep learning models, and the\ninformation plane may provide insights into whether the model exploits the\navailable information in the data. The information plane has previously been\nexplored for fully connected neural networks and convolutional architectures.\nWe present an architecture-agnostic method for tracking a network's internal\nrepresentations during training, which are then used to create the mutual\ninformation plane. The method is exemplified for graph-based neural networks\nfitted on citation data. We compare how the inductive bias introduced in\ngraph-based architectures changes the mutual information plane relative to a\nfully connected neural network.",
          "link": "http://arxiv.org/abs/2203.16887",
          "publishedOn": "2022-04-02T00:47:20.019Z",
          "wordCount": null,
          "title": "Mutual information estimation for graph convolutional neural networks. (arXiv:2203.16887v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oosterhuis_H/0/1/0/all/0/1\">Harrie Oosterhuis</a>",
          "description": "Clicks on rankings suffer from position bias: generally items on lower ranks\nare less likely to be examined - and thus clicked - by users, in spite of their\nactual preferences between items. The prevalent approach to unbiased\nclick-based Learning-to-Rank (LTR) is based on counterfactual\nInverse-Propensity-Scoring (IPS) estimation. Unique about LTR is the fact that\nstandard Doubly-Robust (DR) estimation - which combines IPS with regression\npredictions - is inapplicable since the treatment variable - indicating whether\na user examined an item - cannot be observed in the data. In this paper, we\nintroduce a novel DR estimator that uses the expectation of treatment per rank\ninstead. Our novel DR estimator has more robust unbiasedness conditions than\nthe existing IPS approach, and in addition, provides enormous decreases in\nvariance: our experimental results indicate it requires several orders of\nmagnitude fewer datapoints to converge at optimal performance. For the unbiased\nLTR field, our DR estimator contributes both increases in state-of-the-art\nperformance and the most robust theoretical guarantees of all known LTR\nestimators.",
          "link": "http://arxiv.org/abs/2203.17118",
          "publishedOn": "2022-04-02T00:47:20.019Z",
          "wordCount": null,
          "title": "Doubly-Robust Estimation for Unbiased Learning-to-Rank from Position-Biased Click Feedback. (arXiv:2203.17118v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Heming Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>",
          "description": "In this paper, we propose Generalized Aggressive Decoding (GAD) -- a novel\napproach to accelerating autoregressive translation with no quality loss,\nthrough the collaboration of autoregressive and non-autoregressive translation\n(NAT) of the Transformer. At each decoding iteration, GAD aggressively decodes\na number of tokens in parallel as a draft through NAT and then verifies them in\nthe autoregressive manner, where only the tokens that pass the verification are\nkept as decoded tokens. GAD can achieve the same performance as autoregressive\ntranslation but much more efficiently because both NAT drafting and\nautoregressive verification are fast due to parallel computing. We conduct\nexperiments in the WMT14 English-German translation task and confirm that the\nvanilla GAD yields exactly the same results as greedy decoding with an around\n3x speedup, and that its variant (GAD++) with an advanced verification strategy\nnot only outperforms the greedy translation and even achieves the comparable\ntranslation quality with the beam search result, but also further improves the\ndecoding speed, resulting in an around 5x speedup over autoregressive\ntranslation. Our models and codes are available at\nhttps://github.com/hemingkx/Generalized-Aggressive-Decoding.",
          "link": "http://arxiv.org/abs/2203.16487",
          "publishedOn": "2022-04-02T00:47:20.019Z",
          "wordCount": null,
          "title": "Lossless Speedup of Autoregressive Translation with Generalized Aggressive Decoding. (arXiv:2203.16487v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roberts_A/0/1/0/all/0/1\">Adam Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1\">Hyung Won Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levskaya_A/0/1/0/all/0/1\">Anselm Levskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_G/0/1/0/all/0/1\">Gaurav Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bradbury_J/0/1/0/all/0/1\">James Bradbury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andor_D/0/1/0/all/0/1\">Daniel Andor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narang_S/0/1/0/all/0/1\">Sharan Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lester_B/0/1/0/all/0/1\">Brian Lester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaffney_C/0/1/0/all/0/1\">Colin Gaffney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohiuddin_A/0/1/0/all/0/1\">Afroz Mohiuddin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hawthorne_C/0/1/0/all/0/1\">Curtis Hawthorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewkowycz_A/0/1/0/all/0/1\">Aitor Lewkowycz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salcianu_A/0/1/0/all/0/1\">Alex Salcianu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zee_M/0/1/0/all/0/1\">Marc van Zee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1\">Jacob Austin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_S/0/1/0/all/0/1\">Sebastian Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soares_L/0/1/0/all/0/1\">Livio Baldini Soares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Haitang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvyashchenko_S/0/1/0/all/0/1\">Sasha Tsvyashchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhery_A/0/1/0/all/0/1\">Aakanksha Chowdhery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastings_J/0/1/0/all/0/1\">Jasmijn Bastings</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulian_J/0/1/0/all/0/1\">Jannis Bulian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_X/0/1/0/all/0/1\">Xavier Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jianmo Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Andrew Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenealy_K/0/1/0/all/0/1\">Kathleen Kenealy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1\">Jonathan H. Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Stephan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrette_D/0/1/0/all/0/1\">Dan Garrette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Thorp_J/0/1/0/all/0/1\">James Lee-Thorp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shazeer_N/0/1/0/all/0/1\">Noam Shazeer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_M/0/1/0/all/0/1\">Marvin Ritter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosma_M/0/1/0/all/0/1\">Maarten Bosma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passos_A/0/1/0/all/0/1\">Alexandre Passos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maitin_Shepard_J/0/1/0/all/0/1\">Jeremy Maitin-Shepard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fiedel_N/0/1/0/all/0/1\">Noah Fiedel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omernick_M/0/1/0/all/0/1\">Mark Omernick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saeta_B/0/1/0/all/0/1\">Brennan Saeta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sepassi_R/0/1/0/all/0/1\">Ryan Sepassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spiridonov_A/0/1/0/all/0/1\">Alexander Spiridonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newlan_J/0/1/0/all/0/1\">Joshua Newlan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gesmundo_A/0/1/0/all/0/1\">Andrea Gesmundo</a>",
          "description": "Recent neural network-based language models have benefited greatly from\nscaling up the size of training datasets and the number of parameters in the\nmodels themselves. Scaling can be complicated due to various factors including\nthe need to distribute computation on supercomputer clusters (e.g., TPUs),\nprevent bottlenecks when infeeding data, and ensure reproducible results. In\nthis work, we present two software libraries that ease these issues:\n$\\texttt{t5x}$ simplifies the process of building and training large language\nmodels at scale while maintaining ease of use, and $\\texttt{seqio}$ provides a\ntask-based API for simple creation of fast and reproducible training data and\nevaluation pipelines. These open-source libraries have been used to train\nmodels with hundreds of billions of parameters on datasets with multiple\nterabytes of training data.\n\nAlong with the libraries, we release configurations and instructions for\nT5-like encoder-decoder models as well as GPT-like decoder-only architectures.\n\n$\\texttt{t5x}$ and $\\texttt{seqio}$ are open source and available at\nhttps://github.com/google-research/t5x and https://github.com/google/seqio,\nrespectively.",
          "link": "http://arxiv.org/abs/2203.17189",
          "publishedOn": "2022-04-02T00:47:20.018Z",
          "wordCount": null,
          "title": "Scaling Up Models and Data with $\\texttt{t5x}$ and $\\texttt{seqio}$. (arXiv:2203.17189v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ao_J/0/1/0/all/0/1\">Junyi Ao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziqiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Long Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_T/0/1/0/all/0/1\">Tom Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_L/0/1/0/all/0/1\">Lirong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yao Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "This paper studies a novel pre-training technique with unpaired speech data,\nSpeech2C, for encoder-decoder based automatic speech recognition (ASR). Within\na multi-task learning framework, we introduce two pre-training tasks for the\nencoder-decoder network using acoustic units, i.e., pseudo codes, derived from\nan offline clustering model. One is to predict the pseudo codes via masked\nlanguage modeling in encoder output, like HuBERT model, while the other lets\nthe decoder learn to reconstruct pseudo codes autoregressively instead of\ngenerating textual scripts. In this way, the decoder learns to reconstruct\noriginal speech information with codes before learning to generate correct\ntext. Comprehensive experiments on the LibriSpeech corpus show that the\nproposed Speech2C can relatively reduce the word error rate (WER) by 19.2% over\nthe method without decoder pre-training, and also outperforms significantly the\nstate-of-the-art wav2vec 2.0 and HuBERT on fine-tuning subsets of 10h and 100h.",
          "link": "http://arxiv.org/abs/2203.17113",
          "publishedOn": "2022-04-02T00:47:20.004Z",
          "wordCount": null,
          "title": "Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data. (arXiv:2203.17113v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17138",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bohez_S/0/1/0/all/0/1\">Steven Bohez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tunyasuvunakool_S/0/1/0/all/0/1\">Saran Tunyasuvunakool</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brakel_P/0/1/0/all/0/1\">Philemon Brakel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadeghi_F/0/1/0/all/0/1\">Fereshteh Sadeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasenclever_L/0/1/0/all/0/1\">Leonard Hasenclever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tassa_Y/0/1/0/all/0/1\">Yuval Tassa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parisotto_E/0/1/0/all/0/1\">Emilio Parisotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Humplik_J/0/1/0/all/0/1\">Jan Humplik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haarnoja_T/0/1/0/all/0/1\">Tuomas Haarnoja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hafner_R/0/1/0/all/0/1\">Roland Hafner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulfmeier_M/0/1/0/all/0/1\">Markus Wulfmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neunert_M/0/1/0/all/0/1\">Michael Neunert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moran_B/0/1/0/all/0/1\">Ben Moran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siegel_N/0/1/0/all/0/1\">Noah Siegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huber_A/0/1/0/all/0/1\">Andrea Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romano_F/0/1/0/all/0/1\">Francesco Romano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batchelor_N/0/1/0/all/0/1\">Nathan Batchelor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casarini_F/0/1/0/all/0/1\">Federico Casarini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merel_J/0/1/0/all/0/1\">Josh Merel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadsell_R/0/1/0/all/0/1\">Raia Hadsell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1\">Nicolas Heess</a>",
          "description": "We investigate the use of prior knowledge of human and animal movement to\nlearn reusable locomotion skills for real legged robots. Our approach builds\nupon previous work on imitating human or dog Motion Capture (MoCap) data to\nlearn a movement skill module. Once learned, this skill module can be reused\nfor complex downstream tasks. Importantly, due to the prior imposed by the\nMoCap data, our approach does not require extensive reward engineering to\nproduce sensible and natural looking behavior at the time of reuse. This makes\nit easy to create well-regularized, task-oriented controllers that are suitable\nfor deployment on real robots. We demonstrate how our skill module can be used\nfor imitation, and train controllable walking and ball dribbling policies for\nboth the ANYmal quadruped and OP3 humanoid. These policies are then deployed on\nhardware via zero-shot simulation-to-reality transfer. Accompanying videos are\navailable at https://bit.ly/robot-npmp.",
          "link": "http://arxiv.org/abs/2203.17138",
          "publishedOn": "2022-04-02T00:47:20.004Z",
          "wordCount": null,
          "title": "Imitate and Repurpose: Learning Reusable Robot Movement Skills From Human and Animal Behaviors. (arXiv:2203.17138v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17089",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Nikoloska_I/0/1/0/all/0/1\">Ivana Nikoloska</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Simeone_O/0/1/0/all/0/1\">Osvaldo Simeone</a>",
          "description": "Near-term noisy intermediate-scale quantum circuits can efficiently implement\nimplicit probabilistic models in discrete spaces, supporting distributions that\nare practically infeasible to sample from using classical means. One of the\npossible applications of such models, also known as Born machines, is\nprobabilistic inference, which is at the core of Bayesian methods. This paper\nstudies the use of Born machines for the problem of training binary Bayesian\nneural networks. In the proposed approach, a Born machine is used to model the\nvariational distribution of the binary weights of the neural network, and data\nfrom multiple tasks is used to reduce training data requirements on new tasks.\nThe method combines gradient-based meta-learning and variational inference via\nBorn machines, and is shown in a prototypical regression problem to outperform\nconventional joint learning strategies.",
          "link": "http://arxiv.org/abs/2203.17089",
          "publishedOn": "2022-04-02T00:47:20.003Z",
          "wordCount": null,
          "title": "Quantum-Aided Meta-Learning for Bayesian Binary Neural Networks via Born Machines. (arXiv:2203.17089v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eichenberger_C/0/1/0/all/0/1\">Christian Eichenberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neun_M/0/1/0/all/0/1\">Moritz Neun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_H/0/1/0/all/0/1\">Henry Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herruzo_P/0/1/0/all/0/1\">Pedro Herruzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spanring_M/0/1/0/all/0/1\">Markus Spanring</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yichao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Sungbin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konyakhin_V/0/1/0/all/0/1\">Vsevolod Konyakhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukashina_N/0/1/0/all/0/1\">Nina Lukashina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shpilman_A/0/1/0/all/0/1\">Aleksei Shpilman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiedemann_N/0/1/0/all/0/1\">Nina Wiedemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raubal_M/0/1/0/all/0/1\">Martin Raubal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_H/0/1/0/all/0/1\">Hai L. Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohajerpoor_R/0/1/0/all/0/1\">Reza Mohajerpoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1\">Chen Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1\">Inhi Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hermes_L/0/1/0/all/0/1\">Luca Hermes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melnik_A/0/1/0/all/0/1\">Andrew Melnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velioglu_R/0/1/0/all/0/1\">Riza Velioglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieth_M/0/1/0/all/0/1\">Markus Vieth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schilling_M/0/1/0/all/0/1\">Malte Schilling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bojesomo_A/0/1/0/all/0/1\">Alabi Bojesomo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marzouqi_H/0/1/0/all/0/1\">Hasan Al Marzouqi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liatsis_P/0/1/0/all/0/1\">Panos Liatsis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santokhi_J/0/1/0/all/0/1\">Jay Santokhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hillier_D/0/1/0/all/0/1\">Dylan Hillier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yiming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarwar_J/0/1/0/all/0/1\">Joned Sarwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_A/0/1/0/all/0/1\">Anna Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hewage_E/0/1/0/all/0/1\">Emil Hewage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonietz_D/0/1/0/all/0/1\">David Jonietz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_F/0/1/0/all/0/1\">Fei Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruca_A/0/1/0/all/0/1\">Aleksandra Gruca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kopp_M/0/1/0/all/0/1\">Michael Kopp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreil_D/0/1/0/all/0/1\">David Kreil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>",
          "description": "The IARAI Traffic4cast competitions at NeurIPS 2019 and 2020 showed that\nneural networks can successfully predict future traffic conditions 1 hour into\nthe future on simply aggregated GPS probe data in time and space bins. We thus\nreinterpreted the challenge of forecasting traffic conditions as a movie\ncompletion task. U-Nets proved to be the winning architecture, demonstrating an\nability to extract relevant features in this complex real-world geo-spatial\nprocess. Building on the previous competitions, Traffic4cast 2021 now focuses\non the question of model robustness and generalizability across time and space.\nMoving from one city to an entirely different city, or moving from pre-COVID\ntimes to times after COVID hit the world thus introduces a clear domain shift.\nWe thus, for the first time, release data featuring such domain shifts. The\ncompetition now covers ten cities over 2 years, providing data compiled from\nover 10^12 GPS probe data. Winning solutions captured traffic dynamics\nsufficiently well to even cope with these complex domain shifts. Surprisingly,\nthis seemed to require only the previous 1h traffic dynamic history and static\nroad graph as input.",
          "link": "http://arxiv.org/abs/2203.17070",
          "publishedOn": "2022-04-02T00:47:20.002Z",
          "wordCount": null,
          "title": "Traffic4cast at NeurIPS 2021 - Temporal and Spatial Few-Shot Transfer Learning in Gridded Geo-Spatial Processes. (arXiv:2203.17070v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17001",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Guo_S/0/1/0/all/0/1\">Shuai Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_J/0/1/0/all/0/1\">Jiatong Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qian_T/0/1/0/all/0/1\">Tao Qian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jin_Q/0/1/0/all/0/1\">Qin Jin</a>",
          "description": "Deep learning based singing voice synthesis (SVS) systems have been\ndemonstrated to flexibly generate singing with better qualities, compared to\nconventional statistical parametric based methods. However, neural systems are\ngenerally data-hungry and have difficulty to reach reasonable singing quality\nwith limited public available training data. In this work, we explore different\ndata augmentation methods to boost the training of SVS systems, including\nseveral strategies customized to SVS based on pitch augmentation and mix-up\naugmentation. To further stabilize the training, we introduce the\ncycle-consistent training strategy. Extensive experiments on two public singing\ndatabases demonstrate that our proposed augmentation methods and the\nstabilizing training strategy can significantly improve the performance on both\nobjective and subjective evaluations.",
          "link": "http://arxiv.org/abs/2203.17001",
          "publishedOn": "2022-04-02T00:47:20.000Z",
          "wordCount": null,
          "title": "SingAug: Data Augmentation for Singing Voice Synthesis with Cycle-consistent Training Strategy. (arXiv:2203.17001v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siuzdak_H/0/1/0/all/0/1\">Hubert Siuzdak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dura_P/0/1/0/all/0/1\">Piotr Dura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijn_P/0/1/0/all/0/1\">Pol van Rijn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacoby_N/0/1/0/all/0/1\">Nori Jacoby</a>",
          "description": "Recent advances in neural text-to-speech research have been dominated by\ntwo-stage pipelines utilizing low-level intermediate speech representation such\nas mel-spectrograms. However, such predetermined features are fundamentally\nlimited, because they do not allow to exploit the full potential of a\ndata-driven approach through learning hidden representations. For this reason,\nseveral end-to-end methods have been proposed. However, such models are harder\nto train and require a large number of high-quality recordings with\ntranscriptions. Here, we propose WavThruVec - a two-stage architecture that\nresolves the bottleneck by using high-dimensional Wav2Vec 2.0 embeddings as\nintermediate speech representation. Since these hidden activations provide\nhigh-level linguistic features, they are more robust to noise. That allows us\nto utilize annotated speech datasets of a lower quality to train the\nfirst-stage module. At the same time, the second-stage component can be trained\non large-scale untranscribed audio corpora, as Wav2Vec 2.0 embeddings are\ntime-aligned and speaker-independent. This results in an increased\ngeneralization capability to out-of-vocabulary words, as well as to a better\ngeneralization to unseen speakers. We show that the proposed model not only\nmatches the quality of state-of-the-art neural models, but also presents useful\nproperties enabling tasks like voice conversion or zero-shot synthesis.",
          "link": "http://arxiv.org/abs/2203.16930",
          "publishedOn": "2022-04-02T00:47:19.999Z",
          "wordCount": null,
          "title": "WavThruVec: Latent speech representation as intermediate features for neural speech synthesis. (arXiv:2203.16930v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yiran Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_P/0/1/0/all/0/1\">Pratyay Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokhale_T/0/1/0/all/0/1\">Tejas Gokhale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yezhou Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>",
          "description": "We present a debiased dataset for the Person-centric Visual Grounding (PCVG)\ntask first proposed by Cui et al. (2021) in the Who's Waldo dataset. Given an\nimage and a caption, PCVG requires pairing up a person's name mentioned in a\ncaption with a bounding box that points to the person in the image. We find\nthat the original Who's Waldo dataset compiled for this task contains a large\nnumber of biased samples that are solvable simply by heuristic methods; for\ninstance, in many cases the first name in the sentence corresponds to the\nlargest bounding box, or the sequence of names in the sentence corresponds to\nan exact left-to-right order in the image. Naturally, models trained on these\nbiased data lead to over-estimation of performance on the benchmark. To enforce\nmodels being correct for the correct reasons, we design automated tools to\nfilter and debias the original dataset by ruling out all examples of\ninsufficient context, such as those with no verb or with a long chain of\nconjunct names in their captions. Our experiments show that our new sub-sampled\ndataset contains less bias with much lowered heuristic performances and widened\ngaps between heuristic and supervised methods. We also demonstrate the same\nbenchmark model trained on our debiased training set outperforms that trained\non the original biased (and larger) training set on our debiased test set. We\nargue our debiased dataset offers the PCVG task a more practical baseline for\nreliable benchmarking and future improvements.",
          "link": "http://arxiv.org/abs/2203.16682",
          "publishedOn": "2022-04-02T00:47:19.996Z",
          "wordCount": null,
          "title": "To Find Waldo You Need Contextual Cues: Debiasing Who's Waldo. (arXiv:2203.16682v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mehra_S/0/1/0/all/0/1\">Srishti Mehra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louka_R/0/1/0/all/0/1\">Robert Louka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixun Zhang</a>",
          "description": "Environmental, Social, and Governance (ESG) are non-financial factors that\nare garnering attention from investors as they increasingly look to apply these\nas part of their analysis to identify material risks and growth opportunities.\nSome of this attention is also driven by clients who, now more aware than ever,\nare demanding for their money to be managed and invested responsibly. As the\ninterest in ESG grows, so does the need for investors to have access to\nconsumable ESG information. Since most of it is in text form in reports,\ndisclosures, press releases, and 10-Q filings, we see a need for sophisticated\nNLP techniques for classification tasks for ESG text. We hypothesize that an\nESG domain-specific pre-trained model will help with such and study building of\nthe same in this paper. We explored doing this by fine-tuning BERTs pre-trained\nweights using ESG specific text and then further fine-tuning the model for a\nclassification task. We were able to achieve accuracy better than the original\nBERT and baseline models in environment-specific classification tasks.",
          "link": "http://arxiv.org/abs/2203.16788",
          "publishedOn": "2022-04-02T00:47:19.995Z",
          "wordCount": null,
          "title": "ESGBERT: Language Model to Help with Classification Tasks Related to Companies Environmental, Social, and Governance Practices. (arXiv:2203.16788v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujita_O/0/1/0/all/0/1\">Osamu Fujita</a>",
          "description": "This paper investigates probability density functions (PDFs) that are\ncontinuous everywhere, nearly uniform around the mode of distribution, and\nadaptable to a variety of distribution shapes ranging from bell-shaped to\nrectangular. From the viewpoint of computational tractability, the PDF based on\nthe Fermi-Dirac or logistic function is advantageous in estimating its shape\nparameters. The most appropriate PDF for $n$-variate distribution is of the\nform:\n$p\\left(\\mathbf{x}\\right)\\propto\\left[\\cosh\\left(\\left[\\left(\\mathbf{x}-\\mathbf{m}\\right)^{\\mathsf{T}}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{x}-\\mathbf{m}\\right)\\right]^{n/2}\\right)+\\cosh\\left(r^{n}\\right)\\right]^{-1}$\nwhere $\\mathbf{x},\\mathbf{m}\\in\\mathbb{R}^{n}$, $\\boldsymbol{\\Sigma}$ is an\n$n\\times n$ positive definite matrix, and $r>0$ is a shape parameter. The\nflat-topped PDFs can be used as a component of mixture models in machine\nlearning to improve goodness of fit and make a model as simple as possible.",
          "link": "http://arxiv.org/abs/2203.17027",
          "publishedOn": "2022-04-02T00:47:19.988Z",
          "wordCount": null,
          "title": "Flat-topped Probability Density Functions for Mixture Models. (arXiv:2203.17027v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16952",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Swalpa Kumar Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deria_A/0/1/0/all/0/1\">Ankur Deria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1\">Danfeng Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasti_B/0/1/0/all/0/1\">Behnood Rasti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaza_A/0/1/0/all/0/1\">Antonio Plaza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chanussot_J/0/1/0/all/0/1\">Jocelyn Chanussot</a>",
          "description": "Vision transformer (ViT) has been trending in image classification tasks due\nto its promising performance when compared to convolutional neural networks\n(CNNs). As a result, many researchers have tried to incorporate ViT models in\nhyperspectral image (HSI) classification tasks, but without achieving\nsatisfactory performance. To this paper, we introduce a new multimodal fusion\ntransformer (MFT) network for HSI land-cover classification, which utilizes\nother sources of multimodal data in addition to HSI. Instead of using\nconventional feature fusion techniques, other multimodal data are used as an\nexternal classification (CLS) token in the transformer encoder, which helps\nachieving better generalization. ViT and other similar transformer models use a\nrandomly initialized external classification token {and fail to generalize\nwell}. However, the use of a feature embedding derived from other sources of\nmultimodal data, such as light detection and ranging (LiDAR), offers the\npotential to improve those models by means of a CLS. The concept of\ntokenization is used in our work to generate CLS and HSI patch tokens, helping\nto learn key features in a reduced feature space. We also introduce a new\nattention mechanism for improving the exchange of information between HSI\ntokens and the CLS (e.g., LiDAR) token. Extensive experiments are carried out\non widely used and benchmark datasets i.e., the University of Houston, Trento,\nUniversity of Southern Mississippi Gulfpark (MUUFL), and Augsburg. In the\nresults section, we compare the proposed MFT model with other state-of-the-art\ntransformer models, classical CNN models, as well as conventional classifiers.\nThe superior performance achieved by the proposed model is due to the use of\nmultimodal information as external classification tokens.",
          "link": "http://arxiv.org/abs/2203.16952",
          "publishedOn": "2022-04-02T00:47:19.987Z",
          "wordCount": null,
          "title": "Multimodal Fusion Transformer for Remote Sensing Image Classification. (arXiv:2203.16952v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kashkin_A/0/1/0/all/0/1\">A. Kashkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karpukhin_I/0/1/0/all/0/1\">I. Karpukhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shishkin_S/0/1/0/all/0/1\">S. Shishkin</a>",
          "description": "The goal of voice conversion (VC) is to convert input voice to match the\ntarget speaker's voice while keeping text and prosody intact. VC is usually\nused in entertainment and speaking-aid systems, as well as applied for speech\ndata generation and augmentation. The development of any-to-any VC systems,\nwhich are capable of generating voices unseen during model training, is of\nparticular interest to both researchers and the industry. Despite recent\nprogress, any-to-any conversion quality is still inferior to natural speech.\n\nIn this work, we propose a new any-to-any voice conversion pipeline. Our\napproach uses automated speech recognition (ASR) features, pitch tracking, and\na state-of-the-art waveform prediction model. According to multiple subjective\nand objective evaluations, our method outperforms modern baselines in terms of\nvoice quality, similarity and consistency.",
          "link": "http://arxiv.org/abs/2203.16937",
          "publishedOn": "2022-04-02T00:47:19.985Z",
          "wordCount": null,
          "title": "HiFi-VC: High Quality ASR-Based Voice Conversion. (arXiv:2203.16937v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17008",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1\">Kanghyun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hye Yoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1\">Deokki Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Joonsang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1\">Noseong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Youngsok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jinho Lee</a>",
          "description": "Model quantization is considered as a promising method to greatly reduce the\nresource requirements of deep neural networks. To deal with the performance\ndrop induced by quantization errors, a popular method is to use training data\nto fine-tune quantized networks. In real-world environments, however, such a\nmethod is frequently infeasible because training data is unavailable due to\nsecurity, privacy, or confidentiality concerns. Zero-shot quantization\naddresses such problems, usually by taking information from the weights of a\nfull-precision teacher network to compensate the performance drop of the\nquantized networks. In this paper, we first analyze the loss surface of\nstate-of-the-art zero-shot quantization techniques and provide several\nfindings. In contrast to usual knowledge distillation problems, zero-shot\nquantization often suffers from 1) the difficulty of optimizing multiple loss\nterms together, and 2) the poor generalization capability due to the use of\nsynthetic samples. Furthermore, we observe that many weights fail to cross the\nrounding threshold during training the quantized networks even when it is\nnecessary to do so for better performance. Based on the observations, we\npropose AIT, a simple yet powerful technique for zero-shot quantization, which\naddresses the aforementioned two problems in the following way: AIT i) uses a\nKL distance loss only without a cross-entropy loss, and ii) manipulates\ngradients to guarantee that a certain portion of weights are properly updated\nafter crossing the rounding thresholds. Experiments show that AIT outperforms\nthe performance of many existing methods by a great margin, taking over the\noverall state-of-the-art position in the field.",
          "link": "http://arxiv.org/abs/2203.17008",
          "publishedOn": "2022-04-02T00:47:19.984Z",
          "wordCount": null,
          "title": "It's All In the Teacher: Zero-Shot Quantization Brought Closer to the Teacher. (arXiv:2203.17008v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16687",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qinghua Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorban_A/0/1/0/all/0/1\">Alexander N. Gorban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirkes_E/0/1/0/all/0/1\">Evgeny M. Mirkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bac_J/0/1/0/all/0/1\">Jonathan Bac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zinovyev_A/0/1/0/all/0/1\">Andrei Zinovyev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyukin_I/0/1/0/all/0/1\">Ivan Y. Tyukin</a>",
          "description": "Finding best architectures of learning machines, such as deep neural\nnetworks, is a well-known technical and theoretical challenge. Recent work by\nMellor et al (2021) showed that there may exist correlations between the\naccuracies of trained networks and the values of some easily computable\nmeasures defined on randomly initialised networks which may enable to search\ntens of thousands of neural architectures without training. Mellor et al used\nthe Hamming distance evaluated over all ReLU neurons as such a measure.\nMotivated by these findings, in our work, we ask the question of the existence\nof other and perhaps more principled measures which could be used as\ndeterminants of success of a given neural architecture. In particular, we\nexamine, if the dimensionality and quasi-orthogonality of neural networks'\nfeature space could be correlated with the network's performance after\ntraining. We showed, using the setup as in Mellor et al, that dimensionality\nand quasi-orthogonality may jointly serve as network's performance\ndiscriminants. In addition to offering new opportunities to accelerate neural\narchitecture search, our findings suggest important relationships between the\nnetworks' final performance and properties of their randomly initialised\nfeature spaces: data dimension and quasi-orthogonality.",
          "link": "http://arxiv.org/abs/2203.16687",
          "publishedOn": "2022-04-02T00:47:19.983Z",
          "wordCount": null,
          "title": "Quasi-orthogonality and intrinsic dimensions as measures of learning and generalisation. (arXiv:2203.16687v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Katayose_T/0/1/0/all/0/1\">Taisuke Katayose</a>",
          "description": "Recently machine learning using neural networks has been developed, and many\nnew methods have been suggested. On the other hand, a system that has true\nversatility has not been developed, and there remain many fields in which the\nhuman brain has advantages over machine learning. We considered how the human\nbrain recognizes events and memorizes them and succeeded to reproduce the\nsystem of the human brain on a machine learning model with a new autoencoder\nneural network (NN). The previous autoencoders have the problem that they\ncannot define well what is the features of the input data, and we need to\nrestrict the middle layer of the autoencoder artificially. We solve this\nproblem by defining a new loss function that reflects the information entropy,\nand it enables the NN to compress the input data ideally and automatically\ndiscover the hidden law behind the input data set. The loss function used in\nour NN is based on the free-energy principle which is known as the unified\nbrain theory, and our study is the first concrete formularization of this\nprinciple. The result of this study can be applied to any kind of data analysis\nand also to cognitive science.",
          "link": "http://arxiv.org/abs/2203.16941",
          "publishedOn": "2022-04-02T00:47:19.982Z",
          "wordCount": null,
          "title": "The ideal data compression and automatic discovery of hidden law using neural network. (arXiv:2203.16941v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16773",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tseng_W/0/1/0/all/0/1\">Wei-Cheng Tseng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Speech representations learned from Self-supervised learning (SSL) models\nhave been found beneficial for various speech processing tasks. However,\nutilizing SSL representations usually requires fine-tuning the pre-trained\nmodels or designing task-specific downstream models and loss functions, causing\nmuch memory usage and human labor. On the other hand, prompting in Natural\nLanguage Processing (NLP) is an efficient and widely used technique to leverage\npre-trained language models (LMs). Nevertheless, such a paradigm is little\nstudied in the speech community. We report in this paper the first exploration\nof the prompt tuning paradigm for speech processing tasks based on Generative\nSpoken Language Model (GSLM). Experiment results show that the prompt tuning\ntechnique achieves competitive performance in speech classification tasks with\nfewer trainable parameters than fine-tuning specialized downstream models. We\nfurther study the technique in challenging sequence generation tasks. Prompt\ntuning also demonstrates its potential, while the limitation and possible\nresearch directions are discussed in this paper.",
          "link": "http://arxiv.org/abs/2203.16773",
          "publishedOn": "2022-04-02T00:47:19.981Z",
          "wordCount": null,
          "title": "An Exploration of Prompt Tuning on Generative Spoken Language Model for Speech Processing Tasks. (arXiv:2203.16773v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17055",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hillebrecht_B/0/1/0/all/0/1\">Birgit Hillebrecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unger_B/0/1/0/all/0/1\">Benjamin Unger</a>",
          "description": "Physics-informed neural networks (PINNs) are one popular approach to\nintroduce a priori knowledge about physical systems into the learning\nframework. PINNs are known to be robust for smaller training sets, derive\nbetter generalization problems, and are faster to train. In this paper, we show\nthat using PINNs in comparison with purely data-driven neural networks is not\nonly favorable for training performance but allows us to extract significant\ninformation on the quality of the approximated solution. Assuming that the\nunderlying differential equation for the PINN training is an ordinary\ndifferential equation, we derive a rigorous upper limit on the PINN prediction\nerror. This bound is applicable even for input data not included in the\ntraining phase and without any prior knowledge about the true solution.\nTherefore, our a posteriori error estimation is an essential step to certify\nthe PINN. We apply our error estimator exemplarily to two academic toy\nproblems, whereof one falls in the category of model-predictive control and\nthereby shows the practical use of the derived results.",
          "link": "http://arxiv.org/abs/2203.17055",
          "publishedOn": "2022-04-02T00:47:19.981Z",
          "wordCount": null,
          "title": "Certified machine learning: A posteriori error estimation for physics-informed neural networks. (arXiv:2203.17055v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1\">Mahdi S. Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuli_M/0/1/0/all/0/1\">Mathieu Tuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1\">Konstantinos N. Plataniotis</a>",
          "description": "Explaining the generalization characteristics of deep learning is an emerging\ntopic in advanced machine learning. There are several unanswered questions\nabout how learning under stochastic optimization really works and why certain\nstrategies are better than others. In this paper, we address the following\nquestion: \\textit{can we probe intermediate layers of a deep neural network to\nidentify and quantify the learning quality of each layer?} With this question\nin mind, we propose new explainability metrics that measure the redundant\ninformation in a network's layers using a low-rank factorization framework and\nquantify a complexity measure that is highly correlated with the generalization\nperformance of a given optimizer, network, and dataset. We subsequently exploit\nthese metrics to augment the Stochastic Gradient Descent (SGD) optimizer by\nadaptively adjusting the learning rate in each layer to improve in\ngeneralization performance. Our augmented SGD -- dubbed RMSGD -- introduces\nminimal computational overhead compared to SOTA methods and outperforms them by\nexhibiting strong generalization characteristics across application,\narchitecture, and dataset.",
          "link": "http://arxiv.org/abs/2203.16723",
          "publishedOn": "2022-04-02T00:47:19.978Z",
          "wordCount": null,
          "title": "Exploiting Explainable Metrics for Augmented SGD. (arXiv:2203.16723v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antoniou_A/0/1/0/all/0/1\">Anna Antoniou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dossena_G/0/1/0/all/0/1\">Giacomo Dossena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacMillan_J/0/1/0/all/0/1\">Julia MacMillan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamblin_S/0/1/0/all/0/1\">Steven Hamblin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David Clifton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrone_P/0/1/0/all/0/1\">Paula Petrone</a>",
          "description": "Objective: The use of routinely-acquired medical data for research purposes\nrequires the protection of patient confidentiality via data anonymisation. The\nobjective of this work is to calculate the risk of re-identification arising\nfrom a malicious attack to an anonymised dataset, as described below. Methods:\nWe first present an analytical means of estimating the probability of\nre-identification of a single patient in a k-anonymised dataset of Electronic\nHealth Record (EHR) data. Second, we generalize this solution to obtain the\nprobability of multiple patients being re-identified. We provide synthetic\nvalidation via Monte Carlo simulations to illustrate the accuracy of the\nestimates obtained. Results: The proposed analytical framework for risk\nestimation provides re-identification probabilities that are in agreement with\nthose provided by simulation in a number of scenarios. Our work is limited by\nconservative assumptions which inflate the re-identification probability.\nDiscussion: Our estimates show that the re-identification probability increases\nwith the proportion of the dataset maliciously obtained and that it has an\ninverse relationship with the equivalence class size. Our recursive approach\nextends the applicability domain to the general case of a multi-patient\nre-identification attack in an arbitrary k-anonymisation scheme. Conclusion: We\nprescribe a systematic way to parametrize the k-anonymisation process based on\na pre-determined re-identification probability. We observed that the benefits\nof a reduced re-identification risk that come with increasing k-size may not be\nworth the reduction in data granularity when one is considering benchmarking\nthe re-identification probability on the size of the portion of the dataset\nmaliciously obtained by the adversary.",
          "link": "http://arxiv.org/abs/2203.16921",
          "publishedOn": "2022-04-02T00:47:19.951Z",
          "wordCount": null,
          "title": "Assessing the risk of re-identification arising from an attack on anonymised data. (arXiv:2203.16921v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1\">Emiel Hoogeboom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satorras_V/0/1/0/all/0/1\">Victor Garcia Satorras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vignac_C/0/1/0/all/0/1\">Cl&#xe9;ment Vignac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "This work introduces a diffusion model for molecule generation in 3D that is\nequivariant to Euclidean transformations. Our E(3) Equivariant Diffusion Model\n(EDM) learns to denoise a diffusion process with an equivariant network that\njointly operates on both continuous (atom coordinates) and categorical features\n(atom types). In addition, we provide a probabilistic analysis which admits\nlikelihood computation of molecules using our model. Experimentally, the\nproposed method significantly outperforms previous 3D molecular generative\nmethods regarding the quality of generated samples and efficiency at training\ntime.",
          "link": "http://arxiv.org/abs/2203.17003",
          "publishedOn": "2022-04-02T00:47:19.950Z",
          "wordCount": null,
          "title": "Equivariant Diffusion for Molecule Generation in 3D. (arXiv:2203.17003v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wallingford_M/0/1/0/all/0/1\">Matthew Wallingford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1\">Alessandro Achille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1\">Avinash Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fowlkes_C/0/1/0/all/0/1\">Charless Fowlkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhotika_R/0/1/0/all/0/1\">Rahul Bhotika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Adapting pre-trained models with broad capabilities has become standard\npractice for learning a wide range of downstream tasks. The typical approach of\nfine-tuning different models for each task is performant, but incurs a\nsubstantial memory cost. To efficiently learn multiple downstream tasks we\nintroduce Task Adaptive Parameter Sharing (TAPS), a general method for tuning a\nbase model to a new task by adaptively modifying a small, task-specific subset\nof layers. This enables multi-task learning while minimizing resources used and\ncompetition between tasks. TAPS solves a joint optimization problem which\ndetermines which layers to share with the base model and the value of the\ntask-specific weights. Further, a sparsity penalty on the number of active\nlayers encourages weight sharing with the base model. Compared to other\nmethods, TAPS retains high accuracy on downstream tasks while introducing few\ntask-specific parameters. Moreover, TAPS is agnostic to the model architecture\nand requires only minor changes to the training scheme. We evaluate our method\non a suite of fine-tuning tasks and architectures (ResNet, DenseNet, ViT) and\nshow that it achieves state-of-the-art performance while being simple to\nimplement.",
          "link": "http://arxiv.org/abs/2203.16708",
          "publishedOn": "2022-04-02T00:47:19.937Z",
          "wordCount": null,
          "title": "Task Adaptive Parameter Sharing for Multi-Task Learning. (arXiv:2203.16708v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sen_D/0/1/0/all/0/1\">Dipayan Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+A%2E_P/0/1/0/all/0/1\">Prashanth L.A.</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalan_A/0/1/0/all/0/1\">Aditya Gopalan</a>",
          "description": "We consider the problem of sequentially learning to estimate, in the mean\nsquared error (MSE) sense, a Gaussian $K$-vector of unknown covariance by\nobserving only $m < K$ of its entries in each round. This reduces to learning\nan optimal subset for estimating the entire vector. Towards this, we first\nestablish an exponential concentration bound for an estimate of the MSE for\neach observable subset. We then frame the estimation problem with bandit\nfeedback in the best-subset identification setting. We propose a variant of the\nsuccessive elimination algorithm to cater to the adaptive estimation problem,\nand we derive an upper bound on the sample complexity of this algorithm. In\naddition, to understand the fundamental limit on the sample complexity of this\nadaptive estimation bandit problem, we derive a minimax lower bound.",
          "link": "http://arxiv.org/abs/2203.16810",
          "publishedOn": "2022-04-02T00:47:19.937Z",
          "wordCount": null,
          "title": "Adaptive Estimation of Random Vectors with Bandit Feedback. (arXiv:2203.16810v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sehwag_V/0/1/0/all/0/1\">Vikash Sehwag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazirbas_C/0/1/0/all/0/1\">Caner Hazirbas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordo_A/0/1/0/all/0/1\">Albert Gordo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozgenel_F/0/1/0/all/0/1\">Firat Ozgenel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1\">Cristian Canton Ferrer</a>",
          "description": "Our work focuses on addressing sample deficiency from low-density regions of\ndata manifold in common image datasets. We leverage diffusion process based\ngenerative models to synthesize novel images from low-density regions. We\nobserve that uniform sampling from diffusion models predominantly samples from\nhigh-density regions of the data manifold. Therefore, we modify the sampling\nprocess to guide it towards low-density regions while simultaneously\nmaintaining the fidelity of synthetic data. We rigorously demonstrate that our\nprocess successfully generates novel high fidelity samples from low-density\nregions. We further examine generated samples and show that the model does not\nmemorize low-density data and indeed learns to generate novel samples from\nlow-density regions.",
          "link": "http://arxiv.org/abs/2203.17260",
          "publishedOn": "2022-04-02T00:47:19.934Z",
          "wordCount": null,
          "title": "Generating High Fidelity Data from Low-density Regions using Diffusion Models. (arXiv:2203.17260v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16776",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zheng_H/0/1/0/all/0/1\">Huahuan Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+An_K/0/1/0/all/0/1\">Keyu An</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ou_Z/0/1/0/all/0/1\">Zhijian Ou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_C/0/1/0/all/0/1\">Chen Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ding_K/0/1/0/all/0/1\">Ke Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wan_G/0/1/0/all/0/1\">Guanglu Wan</a>",
          "description": "Utilizing text-only data with an external language model (LM) in end-to-end\nRNN-Transducer (RNN-T) for speech recognition is challenging. Recently, a class\nof methods such as density ratio (DR) and ILM estimation (ILME) have been\ndeveloped, outperforming the classic shallow fusion (SF) method. The basic idea\nbehind these methods is that RNN-T posterior should first subtract the\nimplicitly learned ILM prior, in order to integrate the external LM. While\nrecent studies suggest that RNN-T only learns some low-order language model\ninformation, the DR method uses a well-trained ILM. We hypothesize that this\nsetting is appropriate and may deteriorate the performance of the DR method,\nand propose a low-order density ratio method (LODR) by training a low-order\nweak ILM for DR. Extensive empirical experiments are conducted on both\nin-domain and cross-domain scenarios on English LibriSpeech & Tedlium-2 and\nChinese WenetSpeech & AISHELL-1 datasets. It is shown that LODR consistently\noutperforms SF in all tasks, while performing generally close to ILME and\nbetter than DR in most tests.",
          "link": "http://arxiv.org/abs/2203.16776",
          "publishedOn": "2022-04-02T00:47:19.927Z",
          "wordCount": null,
          "title": "An Empirical Study of Language Model Integration for Transducer based Speech Recognition. (arXiv:2203.16776v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sato_T/0/1/0/all/0/1\">Takami Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qi Alfred Chen</a>",
          "description": "After the 2017 TuSimple Lane Detection Challenge, its dataset and evaluation\nbased on accuracy and F1 score have become the de facto standard to measure the\nperformance of lane detection methods. While they have played a major role in\nimproving the performance of lane detection methods, the validity of this\nevaluation method in downstream tasks has not been adequately researched. In\nthis study, we design 2 new driving-oriented metrics for lane detection:\nEnd-to-End Lateral Deviation metric (E2E-LD) is directly formulated based on\nthe requirements of autonomous driving, a core downstream task of lane\ndetection; Per-frame Simulated Lateral Deviation metric (PSLD) is a lightweight\nsurrogate metric of E2E-LD. To evaluate the validity of the metrics, we conduct\na large-scale empirical study with 4 major types of lane detection approaches\non the TuSimple dataset and our newly constructed dataset Comma2k19-LD. Our\nresults show that the conventional metrics have strongly negative correlations\n($\\leq$-0.55) with E2E-LD, meaning that some recent improvements purely\ntargeting the conventional metrics may not have led to meaningful improvements\nin autonomous driving, but rather may actually have made it worse by\noverfitting to the conventional metrics. As autonomous driving is a\nsecurity/safety-critical system, the underestimation of robustness hinders the\nsound development of practical lane detection models. We hope that our study\nwill help the community achieve more downstream task-aware evaluations for lane\ndetection.",
          "link": "http://arxiv.org/abs/2203.16851",
          "publishedOn": "2022-04-02T00:47:19.926Z",
          "wordCount": null,
          "title": "Towards Driving-Oriented Metric for Lane Detection Models. (arXiv:2203.16851v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16673",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yue Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oymak_S/0/1/0/all/0/1\">Samet Oymak</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fazel_M/0/1/0/all/0/1\">Maryam Fazel</a>",
          "description": "This paper studies the problem of identifying low-order linear systems via\nHankel nuclear norm regularization. Hankel regularization encourages the\nlow-rankness of the Hankel matrix, which maps to the low-orderness of the\nsystem. We provide novel statistical analysis for this regularization and\ncarefully contrast it with the unregularized ordinary least-squares (OLS)\nestimator. Our analysis leads to new bounds on estimating the impulse response\nand the Hankel matrix associated with the linear system. We first design an\ninput excitation and show that Hankel regularization enables one to recover the\nsystem using optimal number of observations in the true system order and\nachieve strong statistical estimation rates. Surprisingly, we demonstrate that\nthe input design indeed matters, by showing that intuitive choices such as\ni.i.d. Gaussian input leads to provably sub-optimal sample complexity. To\nbetter understand the benefits of regularization, we also revisit the OLS\nestimator. Besides refining existing bounds, we experimentally identify when\nregularized approach improves over OLS: (1) For low-order systems with slow\nimpulse-response decay, OLS method performs poorly in terms of sample\ncomplexity, (2) Hankel matrix returned by regularization has a more clear\nsingular value gap that ease identification of the system order, (3) Hankel\nregularization is less sensitive to hyperparameter choice. Finally, we\nestablish model selection guarantees through a joint train-validation procedure\nwhere we tune the regularization parameter for near-optimal estimation.",
          "link": "http://arxiv.org/abs/2203.16673",
          "publishedOn": "2022-04-02T00:47:19.925Z",
          "wordCount": null,
          "title": "System Identification via Nuclear Norm Regularization. (arXiv:2203.16673v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17155",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Junjie Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zi-Gang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grebogi_C/0/1/0/all/0/1\">Celso Grebogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1\">Ying-Cheng Lai</a>",
          "description": "We develop a deep convolutional neural network (DCNN) based framework for\nmodel-free prediction of the occurrence of extreme events both in time (\"when\")\nand in space (\"where\") in nonlinear physical systems of spatial dimension two.\nThe measurements or data are a set of two-dimensional snapshots or images. For\na desired time horizon of prediction, a proper labeling scheme can be\ndesignated to enable successful training of the DCNN and subsequent prediction\nof extreme events in time. Given that an extreme event has been predicted to\noccur within the time horizon, a space-based labeling scheme can be applied to\npredict, within certain resolution, the location at which the event will occur.\nWe use synthetic data from the 2D complex Ginzburg-Landau equation and\nempirical wind speed data of the North Atlantic ocean to demonstrate and\nvalidate our machine-learning based prediction framework. The trade-offs among\nthe prediction horizon, spatial resolution, and accuracy are illustrated, and\nthe detrimental effect of spatially biased occurrence of extreme event on\nprediction accuracy is discussed. The deep learning framework is viable for\npredicting extreme events in the real world.",
          "link": "http://arxiv.org/abs/2203.17155",
          "publishedOn": "2022-04-02T00:47:19.924Z",
          "wordCount": null,
          "title": "Predicting extreme events from data using deep machine learning: when and where. (arXiv:2203.17155v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elazar_N/0/1/0/all/0/1\">Nathan Elazar</a>",
          "description": "We explore the use of class-conditional autoregressive (CA) models to perform\nimage classification on MNIST-10. Autoregressive models assign probability to\nan entire input by combining probabilities from each individual feature; hence\nclassification decisions made by a CA can be readily decomposed into\ncontributions from each each input feature. That is to say, CA are inherently\nlocally interpretable. Our experiments show that naively training a CA achieves\nmuch worse accuracy compared to a standard classifier, however this is due to\nover-fitting and not a lack of expressive power. Using knowledge distillation\nfrom a standard classifier, a student CA can be trained to match the\nperformance of the teacher while still being interpretable.",
          "link": "http://arxiv.org/abs/2203.17002",
          "publishedOn": "2022-04-02T00:47:19.923Z",
          "wordCount": null,
          "title": "Conditional Autoregressors are Interpretable Classifiers. (arXiv:2203.17002v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ayache_E/0/1/0/all/0/1\">Eliot H. Ayache</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omand_C/0/1/0/all/0/1\">Conor M.B. Omand</a>",
          "description": "In recent years, the field of machine learning has seen rapid growth, with\napplications in a variety of domains, including image recognition, natural\nlanguage processing, and predictive modeling. In this paper, we explore the\napplication of machine learning to the generation of scientific articles. We\npresent a method for using machine learning to generate scientific articles\nbased on a data set of scientific papers. The method uses a machine-learning\nalgorithm to learn the structure of a scientific article and a set of training\ndata consisting of scientific papers. The machine-learning algorithm is used to\ngenerate a scientific article based on the data set of scientific papers. We\nevaluate the performance of the method by comparing the generated article to a\nset of manually written articles. The results show that the machine-generated\narticle is of similar quality to the manually written articles.",
          "link": "http://arxiv.org/abs/2203.16569",
          "publishedOn": "2022-04-02T00:47:19.911Z",
          "wordCount": null,
          "title": "Generating Scientific Articles with Machine Learning. (arXiv:2203.16569v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16587",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chatterjee_S/0/1/0/all/0/1\">Sabyasachi Chatterjee</a>, <a href=\"http://arxiv.org/find/math/1/au:+Goswami_S/0/1/0/all/0/1\">Subhajit Goswami</a>",
          "description": "We consider the problem of estimating piecewise regular functions in an\nonline setting, i.e., the data arrive sequentially and at any round our task is\nto predict the value of the true function at the next revealed point using the\navailable data from past predictions. We propose a suitably modified version of\na recently developed online learning algorithm called the sleeping experts\naggregation algorithm. We show that this estimator satisfies oracle risk bounds\nsimultaneously for all local regions of the domain. As concrete instantiations\nof the expert aggregation algorithm proposed here, we study an online mean\naggregation and an online linear regression aggregation algorithm where experts\ncorrespond to the set of dyadic subrectangles of the domain. The resulting\nalgorithms are near linear time computable in the sample size. We specifically\nfocus on the performance of these online algorithms in the context of\nestimating piecewise polynomial and bounded variation function classes in the\nfixed design setup. The simultaneous oracle risk bounds we obtain for these\nestimators in this context provide new and improved (in certain aspects)\nguarantees even in the batch setting and are not available for the state of the\nart batch learning estimators.",
          "link": "http://arxiv.org/abs/2203.16587",
          "publishedOn": "2022-04-02T00:47:19.910Z",
          "wordCount": null,
          "title": "Spatially Adaptive Online Prediction of Piecewise Regular Functions. (arXiv:2203.16587v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_M/0/1/0/all/0/1\">Morio Matsumoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuba_H/0/1/0/all/0/1\">Hiroya Matsuba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kujirai_T/0/1/0/all/0/1\">Toshihiro Kujirai</a>",
          "description": "Meta-reinforcement learning (meta-RL) acquires meta-policies that show good\nperformance for tasks in a wide task distribution. However, conventional\nmeta-RL, which learns meta-policies by randomly sampling tasks, has been\nreported to show meta-overfitting for certain tasks, especially for easy tasks\nwhere an agent can easily get high scores. To reduce effects of the\nmeta-overfitting, we considered meta-RL with curriculum-based task sampling.\nOur method is Robust Meta Reinforcement Learning with Guided Task Sampling\n(RMRL-GTS), which is an effective method that restricts task sampling based on\nscores and epochs. We show that in order to achieve robust meta-RL, it is\nnecessary not only to intensively sample tasks with poor scores, but also to\nrestrict and expand the task regions of the tasks to be sampled.",
          "link": "http://arxiv.org/abs/2203.16801",
          "publishedOn": "2022-04-02T00:47:19.910Z",
          "wordCount": null,
          "title": "Robust Meta-Reinforcement Learning with Curriculum-Based Task Sampling. (arXiv:2203.16801v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yang Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1\">Quan Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsumura_T/0/1/0/all/0/1\">Tadayuki Matsumura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuji_T/0/1/0/all/0/1\">Taiki Fuji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ito_K/0/1/0/all/0/1\">Kiyoto Ito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mizuno_H/0/1/0/all/0/1\">Hiroyuki Mizuno</a>",
          "description": "We present Mask Atari, a new benchmark to help solve partially observable\nMarkov decision process (POMDP) problems with Deep Reinforcement Learning\n(DRL)-based approaches. To achieve a simulation environment for the POMDP\nproblems, Mask Atari is constructed based on Atari 2600 games with\ncontrollable, moveable, and learnable masks as the observation area for the\ntarget agent, especially with the active information gathering (AIG) setting in\nPOMDPs. Given that one does not yet exist, Mask Atari provides a challenging,\nefficient benchmark for evaluating the methods that focus on the above problem.\nMoreover, the mask operation is a trial for introducing the receptive field in\nthe human vision system into a simulation environment for an agent, which means\nthe evaluations are not biased from the sensing ability and purely focus on the\ncognitive performance of the methods when compared with the human baseline. We\ndescribe the challenges and features of our benchmark and evaluate several\nbaselines with Mask Atari.",
          "link": "http://arxiv.org/abs/2203.16777",
          "publishedOn": "2022-04-02T00:47:19.908Z",
          "wordCount": null,
          "title": "Mask Atari for Deep Reinforcement Learning as POMDP Benchmarks. (arXiv:2203.16777v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoopes_A/0/1/0/all/0/1\">Andrew Hoopes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffmann_M/0/1/0/all/0/1\">Malte Hoffmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greve_D/0/1/0/all/0/1\">Douglas N. Greve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischl_B/0/1/0/all/0/1\">Bruce Fischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guttag_J/0/1/0/all/0/1\">John Guttag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalca_A/0/1/0/all/0/1\">Adrian V. Dalca</a>",
          "description": "We introduce HyperMorph, a framework that facilitates efficient\nhyperparameter tuning in learning-based deformable image registration.\nClassical registration algorithms perform an iterative pair-wise optimization\nto compute a deformation field that aligns two images. Recent learning-based\napproaches leverage large image datasets to learn a function that rapidly\nestimates a deformation for a given image pair. In both strategies, the\naccuracy of the resulting spatial correspondences is strongly influenced by the\nchoice of certain hyperparameter values. However, an effective hyperparameter\nsearch consumes substantial time and human effort as it often involves training\nmultiple models for different fixed hyperparameter values and may lead to\nsuboptimal registration. We propose an amortized hyperparameter learning\nstrategy to alleviate this burden by learning the impact of hyperparameters on\ndeformation fields. We design a meta network, or hypernetwork, that predicts\nthe parameters of a registration network for input hyperparameters, thereby\ncomprising a single model that generates the optimal deformation field\ncorresponding to given hyperparameter values. This strategy enables fast,\nhigh-resolution hyperparameter search at test-time, reducing the inefficiency\nof traditional approaches while increasing flexibility. We also demonstrate\nadditional benefits of HyperMorph, including enhanced robustness to model\ninitialization and the ability to rapidly identify optimal hyperparameter\nvalues specific to a dataset, image contrast, task, or even anatomical region,\nall without the need to retrain models. We make our code publicly available at\nthis http URL",
          "link": "http://arxiv.org/abs/2203.16680",
          "publishedOn": "2022-04-02T00:47:19.906Z",
          "wordCount": null,
          "title": "Learning the Effect of Registration Hyperparameters with HyperMorph. (arXiv:2203.16680v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16691",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Baade_A/0/1/0/all/0/1\">Alan Baade</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_P/0/1/0/all/0/1\">Puyuan Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Harwath_D/0/1/0/all/0/1\">David Harwath</a>",
          "description": "In this paper, we propose a simple yet powerful improvement over the recent\nSelf-Supervised Audio Spectrogram Transformer (SSAST) model for speech and\naudio classification. Specifically, we leverage the insight that the SSAST uses\na very high masking ratio (75%) during pretraining, meaning that the vast\nmajority of self-attention compute is performed on mask tokens. We address this\nby integrating the encoder-decoder architecture from Masked Autoencoders are\nScalable Vision Learners (MAE) into the SSAST, where a deep encoder operates on\nonly unmasked input, and a shallow decoder operates on encoder outputs and mask\ntokens. We find that MAE-like pretraining can provide a 3x speedup and 2x\nmemory usage reduction over the vanilla SSAST using current audio pretraining\nstrategies with ordinary model and input sizes. When fine-tuning on downstream\ntasks, which only uses the encoder, we find that our approach outperforms the\nSSAST on a variety of downstream tasks. We further conduct comprehensive\nevaluations into different strategies of pretraining and explore differences in\nMAE-style pretraining between the visual and audio domains.",
          "link": "http://arxiv.org/abs/2203.16691",
          "publishedOn": "2022-04-02T00:47:19.904Z",
          "wordCount": null,
          "title": "MAE-AST: Masked Autoencoding Audio Spectrogram Transformer. (arXiv:2203.16691v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16940",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Diaz_Guerra_D/0/1/0/all/0/1\">David Diaz-Guerra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Miguel_A/0/1/0/all/0/1\">Antonio Miguel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beltran_J/0/1/0/all/0/1\">Jose R. Beltran</a>",
          "description": "In this paper, we present a new model for Direction of Arrival (DOA)\nestimation of sound sources based on an Icosahedral Convolutional Neural\nNetwork (CNN) applied over SRP-PHAT power maps computed from the signals\nreceived by a microphone array. This icosahedral CNN is equivariant to the 60\nrotational symmetries of the icosahedron, which represent a good approximation\nof the continuous space of spherical rotations, and can be implemented using\nstandard 2D convolutional layers, having a lower computational cost than most\nof the spherical CNNs. In addition, instead of using fully connected layers\nafter the icosahedral convolutions, we propose a new soft-argmax function that\ncan be seen as a differentiable version of the argmax function and allows us to\nsolve the DOA estimation as a regression problem interpreting the output of the\nconvolutional layers as a probability distribution. We prove that using models\nthat fit the equivariances of the problem allows us to outperform other\nstate-of-the-art models with a lower computational cost and more robustness,\nobtaining root mean square localization errors lower than 10{\\deg} even in\nscenarios with a reverberation time $T_{60}$ of 1.5 s.",
          "link": "http://arxiv.org/abs/2203.16940",
          "publishedOn": "2022-04-02T00:47:19.904Z",
          "wordCount": null,
          "title": "Direction of Arrival Estimation of Sound Sources Using Icosahedral CNNs. (arXiv:2203.16940v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17028",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1\">Yuhan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1\">Yong Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1\">Youlong Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1\">Yuanming Shi</a>",
          "description": "Federated learning (FL), as a disruptive machine learning paradigm, enables\nthe collaborative training of a global model over decentralized local datasets\nwithout sharing them. It spans a wide scope of applications from\nInternet-of-Things (IoT) to biomedical engineering and drug discovery. To\nsupport low-latency and high-privacy FL over wireless networks, in this paper,\nwe propose a reconfigurable intelligent surface (RIS) empowered over-the-air FL\nsystem to alleviate the dilemma between learning accuracy and privacy. This is\nachieved by simultaneously exploiting the channel propagation reconfigurability\nwith RIS for boosting the receive signal power, as well as waveform\nsuperposition property with over-the-air computation (AirComp) for fast model\naggregation. By considering a practical scenario where high-dimensional local\nmodel updates are transmitted across multiple communication blocks, we\ncharacterize the convergence behaviors of the differentially private federated\noptimization algorithm. We further formulate a system optimization problem to\noptimize the learning accuracy while satisfying privacy and power constraints\nvia the joint design of transmit power, artificial noise, and phase shifts at\nRIS, for which a two-step alternating minimization framework is developed.\nSimulation results validate our systematic, theoretical, and algorithmic\nachievements and demonstrate that RIS can achieve a better trade-off between\nprivacy and accuracy for over-the-air FL systems.",
          "link": "http://arxiv.org/abs/2203.17028",
          "publishedOn": "2022-04-02T00:47:19.901Z",
          "wordCount": null,
          "title": "Differentially Private Federated Learning via Reconfigurable Intelligent Surface. (arXiv:2203.17028v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heydari_S/0/1/0/all/0/1\">Sajjad Heydari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Livi_L/0/1/0/all/0/1\">Lorenzo Livi</a>",
          "description": "Hypergraph representations are both more efficient and better suited to\ndescribe data characterized by relations between two or more objects. In this\nwork, we present the first graph neural network based on message passing\ncapable of processing hypergraph-structured data. We show that the proposed\nmodel defines a design space for neural network models for hypergraphs, thus\ngeneralizing existing models for hypergraphs. We report experiments on a\nbenchmark dataset for node classification, highlighting the effectiveness of\nthe proposed model with respect to other state-of-the-art methods for graphs\nand hypergraphs. We also discuss the benefits of using hypergraph\nrepresentations and, at the same time, highlight the limitation of using\nequivalent graph representations when the underlying problem has relations\namong more than two objects.",
          "link": "http://arxiv.org/abs/2203.16995",
          "publishedOn": "2022-04-02T00:47:19.900Z",
          "wordCount": null,
          "title": "Message Passing Neural Networks for Hypergraphs. (arXiv:2203.16995v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16775",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amit Kumar Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asif_A/0/1/0/all/0/1\">Abdullah Al Asif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1\">Anik Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1\">Md. Nur Hossain</a>",
          "description": "Hate speech has spread more rapidly through the daily use of technology and,\nmost notably, by sharing your opinions or feelings on social media in a\nnegative aspect. Although numerous works have been carried out in detecting\nhate speeches in English, German, and other languages, very few works have been\ncarried out in the context of the Bengali language. In contrast, millions of\npeople communicate on social media in Bengali. The few existing works that have\nbeen carried out need improvements in both accuracy and interpretability. This\narticle proposed encoder decoder based machine learning model, a popular tool\nin NLP, to classify user's Bengali comments on Facebook pages. A dataset of\n7,425 Bengali comments, consisting of seven distinct categories of hate\nspeeches, was used to train and evaluate our model. For extracting and encoding\nlocal features from the comments, 1D convolutional layers were used. Finally,\nthe attention mechanism, LSTM, and GRU based decoders have been used for\npredicting hate speech categories. Among the three encoder decoder algorithms,\nthe attention-based decoder obtained the best accuracy (77%).",
          "link": "http://arxiv.org/abs/2203.16775",
          "publishedOn": "2022-04-02T00:47:19.899Z",
          "wordCount": null,
          "title": "Bangla hate speech detection on social media using attention-based recurrent neural network. (arXiv:2203.16775v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaoning Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1\">Trung X. Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_A/0/1/0/all/0/1\">Axi Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1\">Zhinan Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1\">Chang D. Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1\">In So Kweon</a>",
          "description": "Contrastive learning (CL) is widely known to require many negative samples,\n65536 in MoCo for instance, for which the performance of a dictionary-free\nframework is often inferior because the negative sample size (NSS) is limited\nby its mini-batch size (MBS). To decouple the NSS from the MBS, a dynamic\ndictionary has been adopted in a large volume of CL frameworks, among which\narguably the most popular one is MoCo family. In essence, MoCo adopts a\nmomentum-based queue dictionary, for which we perform a fine-grained analysis\nof its size and consistency. We point out that InfoNCE loss used in MoCo\nimplicitly attract anchors to their corresponding positive sample with various\nstrength of penalties and identify such inter-anchor hardness-awareness\nproperty as a major reason for the necessity of a large dictionary. Our\nfindings motivate us to simplify MoCo v2 via the removal of its dictionary as\nwell as momentum. Based on an InfoNCE with the proposed dual temperature, our\nsimplified frameworks, SimMoCo and SimCo, outperform MoCo v2 by a visible\nmargin. Moreover, our work bridges the gap between CL and non-CL frameworks,\ncontributing to a more unified understanding of these two mainstream frameworks\nin SSL. Code is available at: https://bit.ly/3LkQbaT.",
          "link": "http://arxiv.org/abs/2203.17248",
          "publishedOn": "2022-04-02T00:47:19.898Z",
          "wordCount": null,
          "title": "Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo. (arXiv:2203.17248v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.07914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Wenqian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Junyang Jin</a>",
          "description": "Diagnosis of ice accretion on wind turbine blades is all the time a hard nut\nto crack in condition monitoring of wind farms. Existing methods focus on\nmechanism analysis of icing process, deviation degree analysis of feature\nengineering. However, there have not been deep researches of neural networks\napplied in this field at present. Supervisory control and data acquisition\n(SCADA) makes it possible to train networks through continuously providing not\nonly operation parameters and performance parameters of wind turbines but also\nenvironmental parameters and operation modes. This paper explores the\npossibility that using convolutional neural networks (CNNs), generative\nadversarial networks (GANs) and domain adaption learning to establish\nintelligent diagnosis frameworks under different training scenarios.\nSpecifically, PGANC and PGANT are proposed for sufficient and non-sufficient\ntarget wind turbine labeled data, respectively. The basic idea is that we\nconsider a two-stage training with parallel GANs, which are aimed at capturing\nintrinsic features for normal and icing samples, followed by classification CNN\nor domain adaption module in various training cases. Model validation on three\nwind turbine SCADA data shows that two-stage training can effectively improve\nthe model performance. Besides, if there is no sufficient labeled data for a\ntarget turbine, which is an extremely common phenomenon in real industrial\npractices, the addition of domain adaption learning makes the trained model\nshow better performance. Overall, our proposed intelligent diagnosis frameworks\ncan achieve more accurate detection on the same wind turbine and more\ngeneralized capability on a new wind turbine, compared with other machine\nlearning models and conventional CNNs.",
          "link": "http://arxiv.org/abs/2101.07914",
          "publishedOn": "2022-04-02T00:47:19.898Z",
          "wordCount": null,
          "title": "Intelligent Icing Detection Model of Wind Turbine Blades Based on SCADA data. (arXiv:2101.07914v1 [cs.LG] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16944",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Berrone_S/0/1/0/all/0/1\">Stefano Berrone</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Oberto_D/0/1/0/all/0/1\">Davide Oberto</a>",
          "description": "In the present paper a new data-driven model to close and increase accuracy\nof RANS equations is proposed. It is based on the direct approximation of the\ndivergence of the Reynolds Stress Tensor (RST) through a Neural Network (NN).\nThis choice is driven by the presence of the divergence of RST in the RANS\nequations. Furthermore, once this data-driven approach is trained, there is no\nneed to run any turbulence model to close the equations. Finally, it is well\nknown that a good approximation of a function it is not necessarily a good\napproximation of its derivative. The architecture and inputs choices of the\nproposed network guarantee both Galilean and coordinates-frame rotation\ninvariances by looking to a vector basis expansion of the divergence of the\nRST. Two well-known test cases are used to show advantages of the proposed\nmethod compared to classic turbulence models.",
          "link": "http://arxiv.org/abs/2203.16944",
          "publishedOn": "2022-04-02T00:47:19.895Z",
          "wordCount": null,
          "title": "A data-driven approach for the closure of RANS models by the divergence of the Reynolds Stress Tensor. (arXiv:2203.16944v1 [physics.flu-dyn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1812.00086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Heda Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Haiping Lu</a>",
          "description": "Graph convolutional network (GCN) is an emerging neural network approach. It\nlearns new representation of a node by aggregating feature vectors of all\nneighbors in the aggregation process without considering whether the neighbors\nor features are useful or not. Recent methods have improved solutions by\nsampling a fixed size set of neighbors, or assigning different weights to\ndifferent neighbors in the aggregation process, but features within a feature\nvector are still treated equally in the aggregation process. In this paper, we\nintroduce a new convolution operation on regular size feature maps constructed\nfrom features of a fixed node bandwidth via sampling to get the first-level\nnode representation, which is then passed to a standard GCN to learn the\nsecond-level node representation. Experiments show that our method outperforms\ncompeting methods in semi-supervised node classification tasks. Furthermore,\nour method opens new doors for exploring new GCN architectures, particularly\ndeeper GCN models.",
          "link": "http://arxiv.org/abs/1812.00086",
          "publishedOn": "2022-04-02T00:47:19.893Z",
          "wordCount": null,
          "title": "Graph Node-Feature Convolution for Representation Learning. (arXiv:1812.00086v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.04704",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Alanwar_A/0/1/0/all/0/1\">Amr Alanwar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Niazi_M/0/1/0/all/0/1\">Muhammad Umar B. Niazi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Johansson_K/0/1/0/all/0/1\">Karl H. Johansson</a>",
          "description": "This paper proposes a data-driven set-based estimation algorithm for a class\nof nonlinear systems with polynomial nonlinearities. Using the system's\ninput-output data, the proposed method computes a set that guarantees the\ninclusion of the system's state in real-time. Although the system is assumed to\nbe a polynomial type, the exact polynomial functions, and their coefficients\nare assumed to be unknown. To this end, the estimator relies on offline and\nonline phases. The offline phase utilizes past input-output data to estimate a\nset of possible coefficients of the polynomial system. Then, using this\nestimated set of coefficients and the side information about the system, the\nonline phase provides a set estimate of the state. Finally, the proposed\nmethodology is evaluated through its application on SIR (Susceptible, Infected,\nRecovered) epidemic model.",
          "link": "http://arxiv.org/abs/2111.04704",
          "publishedOn": "2022-04-02T00:47:19.892Z",
          "wordCount": null,
          "title": "Data-driven Set-based Estimation of Polynomial Systems with Application to SIR Epidemics. (arXiv:2111.04704v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.11251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hanchen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Lu Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xuemin Lin</a>",
          "description": "Subgraph matching is a fundamental problem in various fields that use graph\nstructured data. Subgraph matching algorithms enumerate all isomorphic\nembeddings of a query graph q in a data graph G. An important branch of\nmatching algorithms exploit the backtracking search approach which recursively\nextends intermediate results following a matching order of query vertices. It\nhas been shown that the matching order plays a critical role in time efficiency\nof these backtracking based subgraph matching algorithms. In recent years, many\nadvanced techniques for query vertex ordering (i.e., matching order generation)\nhave been proposed to reduce the unpromising intermediate results according to\nthe preset heuristic rules. In this paper, for the first time we apply the\nReinforcement Learning (RL) and Graph Neural Networks (GNNs) techniques to\ngenerate the high-quality matching order for subgraph matching algorithms.\nInstead of using the fixed heuristics to generate the matching order, our model\ncould capture and make full use of the graph information, and thus determine\nthe query vertex order with the adaptive learning-based rule that could\nsignificantly reduces the number of redundant enumerations. With the help of\nthe reinforcement learning framework, our model is able to consider the\nlong-term benefits rather than only consider the local information at current\nordering step.Extensive experiments on six real-life data graphs demonstrate\nthat our proposed matching order generation technique could reduce up to two\norders of magnitude of query processing time compared to the state-of-the-art\nalgorithms.",
          "link": "http://arxiv.org/abs/2201.11251",
          "publishedOn": "2022-04-02T00:47:19.869Z",
          "wordCount": null,
          "title": "Reinforcement Learning Based Query Vertex Ordering Model for Subgraph Matching. (arXiv:2201.11251v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1\">Shivani Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_N/0/1/0/all/0/1\">Niladri Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Subir Kumar Saha</a>",
          "description": "An increasing number of machine learning models have been deployed in domains\nwith high stakes such as finance and healthcare. Despite their superior\nperformances, many models are black boxes in nature which are hard to explain.\nThere are growing efforts for researchers to develop methods to interpret these\nblack-box models. Post hoc explanations based on perturbations, such as LIME,\nare widely used approaches to interpret a machine learning model after it has\nbeen built. This class of methods has been shown to exhibit large instability,\nposing serious challenges to the effectiveness of the method itself and harming\nuser trust. In this paper, we propose S-LIME, which utilizes a hypothesis\ntesting framework based on central limit theorem for determining the number of\nperturbation points needed to guarantee stability of the resulting explanation.\nExperiments on both simulated and real world data sets are provided to\ndemonstrate the effectiveness of our method.",
          "link": "http://arxiv.org/abs/2203.17081",
          "publishedOn": "2022-04-02T00:47:19.836Z",
          "wordCount": null,
          "title": "Interpretation of Black Box NLP Models: A Survey. (arXiv:2203.17081v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.00645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maskey_S/0/1/0/all/0/1\">Sohir Maskey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levie_R/0/1/0/all/0/1\">Ron Levie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yunseok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1\">Gitta Kutyniok</a>",
          "description": "Message passing neural networks (MPNN) have seen a steep rise in popularity\nsince their introduction as generalizations of convolutional neural networks to\ngraph structured data, and are now considered state-of-the-art tools for\nsolving a large variety of graph-focused problems. We study the generalization\ncapabilities of MPNNs in graph classification. We assume that graphs of\ndifferent classes are sampled from different random graph models. Based on this\ndata distribution, we derive a non-asymptotic bound on the generalization gap\nbetween the empirical and statistical loss, that decreases to zero as the\ngraphs become larger. This is proven by showing that a MPNN, applied on a\ngraph, approximates the MPNN applied on the geometric model that the graph\ndiscretizes.",
          "link": "http://arxiv.org/abs/2202.00645",
          "publishedOn": "2022-04-02T00:47:19.836Z",
          "wordCount": null,
          "title": "Stability and Generalization Capabilities of Message Passing Graph Neural Networks. (arXiv:2202.00645v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.05781",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zuluaga_Gomez_J/0/1/0/all/0/1\">Juan Zuluaga-Gomez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sarfjoo_S/0/1/0/all/0/1\">Seyyed Saeed Sarfjoo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prasad_A/0/1/0/all/0/1\">Amrutha Prasad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nigmatulina_I/0/1/0/all/0/1\">Iuliia Nigmatulina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Motlicek_P/0/1/0/all/0/1\">Petr Motlicek</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ondrej_K/0/1/0/all/0/1\">Karel Ondrej</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ohneiser_O/0/1/0/all/0/1\">Oliver Ohneiser</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Helmke_H/0/1/0/all/0/1\">Hartmut Helmke</a>",
          "description": "Automatic speech recognition (ASR) allows transcribing the communications\nbetween air traffic controllers (ATCOs) and aircraft pilots. The transcriptions\nare used later to extract ATC named entities e.g., aircraft callsigns, command\ntypes, or values. One common challenge is Speech Activity Detection (SAD) and\ndiarization system. If one of them fails then two or more single speaker\nsegments remain in the same recording, jeopardizing the overall system's\nperformance. We propose a system that combines the segmentation of a SAD module\nwith a BERT model that performs speaker change detection (SCD) and speaker role\ndetection (SRD) by chunking ASR transcripts i.e., diarization with a defined\nnumber of speakers together with SRD. The proposed model is evaluated on\nreal-life ATC test sets. It reaches up to 0.90/0.95 F1-score on ATCO/pilot SRD,\nwhich means a 27% relative improvement on diarization error rate (DER) compared\nto standard acoustic-based diarization. Results are measured on ASR transcripts\nof challenging ATC test sets with $\\sim$13\\% word error rate, and the\nrobustness of the system is even validated on noisy ASR transcripts.",
          "link": "http://arxiv.org/abs/2110.05781",
          "publishedOn": "2022-04-02T00:47:19.834Z",
          "wordCount": null,
          "title": "BERTraffic: BERT-based Joint Speaker Role and Speaker Change Detection for Air Traffic Control Communications. (arXiv:2110.05781v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moritz_N/0/1/0/all/0/1\">Niko Moritz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hori_T/0/1/0/all/0/1\">Takaaki Hori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roux_J/0/1/0/all/0/1\">Jonathan Le Roux</a>",
          "description": "The recurrent neural network transducer (RNN-T) objective plays a major role\nin building today's best automatic speech recognition (ASR) systems for\nproduction. Similarly to the connectionist temporal classification (CTC)\nobjective, the RNN-T loss uses specific rules that define how a set of\nalignments is generated to form a lattice for the full-sum training. However,\nit is yet largely unknown if these rules are optimal and do lead to the best\npossible ASR results. In this work, we present a new transducer objective\nfunction that generalizes the RNN-T loss to accept a graph representation of\nthe labels, thus providing a flexible and efficient framework to manipulate\ntraining lattices, e.g., for studying different transition rules, implementing\ndifferent transducer losses, or restricting alignments. We demonstrate that\ntransducer-based ASR with CTC-like lattice achieves better results compared to\nstandard RNN-T, while also ensuring a strictly monotonic alignment, which will\nallow better optimization of the decoding procedure. For example, the proposed\nCTC-like transducer achieves an improvement of 4.8% on the test-other condition\nof LibriSpeech relative to an equivalent RNN-T based system.",
          "link": "http://arxiv.org/abs/2111.01272",
          "publishedOn": "2022-04-02T00:47:19.827Z",
          "wordCount": null,
          "title": "Sequence Transduction with Graph-based Supervision. (arXiv:2111.01272v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.06484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tsung-Han Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liou_Y/0/1/0/all/0/1\">Yi-Syuan Liou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Shao-Ji Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hsin-Ying Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tung-I Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuan-Chih Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Winston H. Hsu</a>",
          "description": "In the field of domain adaptation, a trade-off exists between the model\nperformance and the number of target domain annotations. Active learning,\nmaximizing model performance with few informative labeled data, comes in handy\nfor such a scenario. In this work, we present D2ADA, a general active domain\nadaptation framework for semantic segmentation. To adapt the model to the\ntarget domain with minimum queried labels, we propose acquiring labels of the\nsamples with high probability density in the target domain yet with low\nprobability density in the source domain, complementary to the existing source\ndomain labeled data. To further facilitate labeling efficiency, we design a\ndynamic scheduling policy to adjust the labeling budgets between domain\nexploration and model uncertainty over time. Extensive experiments show that\nour method outperforms existing active learning and domain adaptation baselines\non two benchmarks, GTA5 -> Cityscapes and SYNTHIA -> Cityscapes. With less than\n5% target domain annotations, our method reaches comparable results with that\nof full supervision.",
          "link": "http://arxiv.org/abs/2202.06484",
          "publishedOn": "2022-04-02T00:47:19.827Z",
          "wordCount": null,
          "title": "D2ADA: Dynamic Density-aware Active Domain Adaptation for Semantic Segmentation. (arXiv:2202.06484v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17241",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hickman_R/0/1/0/all/0/1\">Riley J. Hickman</a>, <a href=\"http://arxiv.org/find/math/1/au:+Aldeghi_M/0/1/0/all/0/1\">Matteo Aldeghi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hase_F/0/1/0/all/0/1\">Florian H&#xe4;se</a>, <a href=\"http://arxiv.org/find/math/1/au:+Aspuru_Guzik_A/0/1/0/all/0/1\">Al&#xe1;n Aspuru-Guzik</a>",
          "description": "Optimization strategies driven by machine learning, such as Bayesian\noptimization, are being explored across experimental sciences as an efficient\nalternative to traditional design of experiment. When combined with automated\nlaboratory hardware and high-performance computing, these strategies enable\nnext-generation platforms for autonomous experimentation. However, the\npractical application of these approaches is hampered by a lack of flexible\nsoftware and algorithms tailored to the unique requirements of chemical\nresearch. One such aspect is the pervasive presence of constraints in the\nexperimental conditions when optimizing chemical processes or protocols, and in\nthe chemical space that is accessible when designing functional molecules or\nmaterials. Although many of these constraints are known a priori, they can be\ninterdependent, non-linear, and result in non-compact optimization domains. In\nthis work, we extend our experiment planning algorithms Phoenics and Gryffin\nsuch that they can handle arbitrary known constraints via an intuitive and\nflexible interface. We benchmark these extended algorithms on continuous and\ndiscrete test functions with a diverse set of constraints, demonstrating their\nflexibility and robustness. In addition, we illustrate their practical utility\nin two simulated chemical research scenarios: the optimization of the synthesis\nof o-xylenyl Buckminsterfullerene adducts under constrained flow conditions,\nand the design of redox active molecules for flow batteries under synthetic\naccessibility constraints. The tools developed constitute a simple, yet\nversatile strategy to enable model-based optimization with known experimental\nconstraints, contributing to its applicability as a core component of\nautonomous platforms for scientific discovery.",
          "link": "http://arxiv.org/abs/2203.17241",
          "publishedOn": "2022-04-02T00:47:19.825Z",
          "wordCount": null,
          "title": "Bayesian optimization with known experimental and design constraints for chemistry applications. (arXiv:2203.17241v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.09562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukhija_B/0/1/0/all/0/1\">Bhavya Sukhija</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turchetta_M/0/1/0/all/0/1\">Matteo Turchetta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindner_D/0/1/0/all/0/1\">David Lindner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trimpe_S/0/1/0/all/0/1\">Sebastian Trimpe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baumann_D/0/1/0/all/0/1\">Dominik Baumann</a>",
          "description": "Learning optimal control policies directly on physical systems is challenging\nsince even a single failure can lead to costly hardware damage. Most existing\nmodel-free learning methods that guarantee safety, i.e., no failures, during\nexploration are limited to local optima. A notable exception is the GoSafe\nalgorithm, which, unfortunately, cannot handle high-dimensional systems and\nhence cannot be applied to most real-world dynamical systems. This work\nproposes GoSafeOpt as the first algorithm that can safely discover globally\noptimal policies for high-dimensional systems while giving safety and\noptimality guarantees. We demonstrate the superiority of GoSafeOpt over\ncompeting model-free safe learning methods on a robot arm that would be\nprohibitive for GoSafe.",
          "link": "http://arxiv.org/abs/2201.09562",
          "publishedOn": "2022-04-02T00:47:19.824Z",
          "wordCount": null,
          "title": "GoSafeOpt: Scalable Safe Exploration for Global Optimization of Dynamical Systems. (arXiv:2201.09562v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rueegg_N/0/1/0/all/0/1\">Nadine Rueegg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuffi_S/0/1/0/all/0/1\">Silvia Zuffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1\">Konrad Schindler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1\">Michael J. Black</a>",
          "description": "Our goal is to recover the 3D shape and pose of dogs from a single image.\nThis is a challenging task because dogs exhibit a wide range of shapes and\nappearances, and are highly articulated. Recent work has proposed to directly\nregress the SMAL animal model, with additional limb scale parameters, from\nimages. Our method, called BARC (Breed-Augmented Regression using\nClassification), goes beyond prior work in several important ways. First, we\nmodify the SMAL shape space to be more appropriate for representing dog shape.\nBut, even with a better shape model, the problem of regressing dog shape from\nan image is still challenging because we lack paired images with 3D ground\ntruth. To compensate for the lack of paired data, we formulate novel losses\nthat exploit information about dog breeds. In particular, we exploit the fact\nthat dogs of the same breed have similar body shapes. We formulate a novel\nbreed similarity loss consisting of two parts: One term encourages the shape of\ndogs from the same breed to be more similar than dogs of different breeds. The\nsecond one, a breed classification loss, helps to produce recognizable\nbreed-specific shapes. Through ablation studies, we find that our breed losses\nsignificantly improve shape accuracy over a baseline without them. We also\ncompare BARC qualitatively to WLDO with a perceptual study and find that our\napproach produces dogs that are significantly more realistic. This work shows\nthat a-priori information about genetic similarity can help to compensate for\nthe lack of 3D training data. This concept may be applicable to other animal\nspecies or groups of species. Our code is publicly available for research\npurposes at https://barc.is.tue.mpg.de/.",
          "link": "http://arxiv.org/abs/2203.15536",
          "publishedOn": "2022-04-02T00:47:19.824Z",
          "wordCount": null,
          "title": "BARC: Learning to Regress 3D Dog Shape from Images by Exploiting Breed Information. (arXiv:2203.15536v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.12970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Rongjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuming He</a>",
          "description": "Scene Graph Generation (SGG) remains a challenging visual understanding task\ndue to its compositional property. Most previous works adopt a bottom-up\ntwo-stage or a point-based one-stage approach, which often suffers from high\ntime complexity or sub-optimal designs. In this work, we propose a novel SGG\nmethod to address the aforementioned issues, formulating the task as a\nbipartite graph construction problem. To solve the problem, we develop a\ntransformer-based end-to-end framework that first generates the entity and\npredicate proposal set, followed by inferring directed edges to form the\nrelation triplets. In particular, we develop a new entity-aware predicate\nrepresentation based on a structural predicate generator that leverages the\ncompositional property of relationships. Moreover, we design a graph assembling\nmodule to infer the connectivity of the bipartite scene graph based on our\nentity-aware structure, enabling us to generate the scene graph in an\nend-to-end manner. Extensive experimental results show that our design is able\nto achieve the state-of-the-art or comparable performance on two challenging\nbenchmarks, surpassing most of the existing approaches and enjoying higher\nefficiency in inference. We hope our model can serve as a strong baseline for\nthe Transformer-based scene graph generation. Code is available:\nhttps://github.com/Scarecrow0/SGTR",
          "link": "http://arxiv.org/abs/2112.12970",
          "publishedOn": "2022-04-02T00:47:19.823Z",
          "wordCount": null,
          "title": "SGTR: End-to-end Scene Graph Generation with Transformer. (arXiv:2112.12970v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.11594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1\">Haoran You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_T/0/1/0/all/0/1\">Tong Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yingyan Lin</a>",
          "description": "Graph Convolutional Networks (GCNs) have emerged as the state-of-the-art\ngraph learning model. However, it can be notoriously challenging to inference\nGCNs over large graph datasets, limiting their application to large real-world\ngraphs and hindering the exploration of deeper and more sophisticated GCN\ngraphs. This is because real-world graphs can be extremely large and sparse.\nFurthermore, the node degree of GCNs tends to follow the power-law distribution\nand therefore have highly irregular adjacency matrices, resulting in\nprohibitive inefficiencies in both data processing and movement and thus\nsubstantially limiting the achievable GCN acceleration efficiency. To this end,\nthis paper proposes a GCN algorithm and accelerator Co-Design framework dubbed\nGCoD which can largely alleviate the aforementioned GCN irregularity and boost\nGCNs' inference efficiency. Specifically, on the algorithm level, GCoD\nintegrates a split and conquer GCN training strategy that polarizes the graphs\nto be either denser or sparser in local neighborhoods without compromising the\nmodel accuracy, resulting in graph adjacency matrices that (mostly) have merely\ntwo levels of workload and enjoys largely enhanced regularity and thus ease of\nacceleration. On the hardware level, we further develop a dedicated two-pronged\naccelerator with a separated engine to process each of the aforementioned\ndenser and sparser workloads, further boosting the overall utilization and\nacceleration efficiency. Extensive experiments and ablation studies validate\nthat our GCoD consistently reduces the number of off-chip accesses, leading to\nspeedups of 15286x, 294x, 7.8x, and 2.5x as compared to CPUs, GPUs, and\nprior-art GCN accelerators including HyGCN and AWB-GCN, respectively, while\nmaintaining or even improving the task accuracy. Codes are available at\nhttps://github.com/RICE-EIC/GCoD.",
          "link": "http://arxiv.org/abs/2112.11594",
          "publishedOn": "2022-04-02T00:47:19.818Z",
          "wordCount": null,
          "title": "GCoD: Graph Convolutional Network Acceleration via Dedicated Algorithm and Accelerator Co-Design. (arXiv:2112.11594v2 [cs.AR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jian Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olszewski_K/0/1/0/all/0/1\">Kyle Olszewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_M/0/1/0/all/0/1\">Menglei Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yun Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tulyakov_S/0/1/0/all/0/1\">Sergey Tulyakov</a>",
          "description": "Recent research explosion on Neural Radiance Field (NeRF) shows the\nencouraging potential to represent complex scenes with neural networks. One\nmajor drawback of NeRF is its prohibitive inference time: Rendering a single\npixel requires querying the NeRF network hundreds of times. To resolve it,\nexisting efforts mainly attempt to reduce the number of required sampled\npoints. However, the problem of iterative sampling still exists. On the other\nhand, Neural Light Field (NeLF) presents a more straightforward representation\nover NeRF in novel view synthesis -- the rendering of a pixel amounts to one\nsingle forward pass without ray-marching. In this work, we present a deep\nresidual MLP network (88 layers) to effectively learn the light field. We show\nthe key to successfully learning such a deep NeLF network is to have sufficient\ndata, for which we transfer the knowledge from a pre-trained NeRF model via\ndata distillation. Extensive experiments on both synthetic and real-world\nscenes show the merits of our method over other counterpart algorithms. On the\nsynthetic scenes, we achieve 26-35x FLOPs reduction (per camera ray) and 28-31x\nruntime speedup, meanwhile delivering significantly better (1.4-2.8 dB average\nPSNR improvement) rendering quality than NeRF without any customized\nimplementation tricks.",
          "link": "http://arxiv.org/abs/2203.17261",
          "publishedOn": "2022-04-02T00:47:19.817Z",
          "wordCount": null,
          "title": "R2L: Distilling Neural Radiance Field to Neural Light Field for Efficient Novel View Synthesis. (arXiv:2203.17261v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.02165",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bassi_P/0/1/0/all/0/1\">Pedro R. A. S. Bassi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Attux_R/0/1/0/all/0/1\">Romis Attux</a>",
          "description": "Objective: To propose novel SSVEP classification methodologies using deep\nneural networks (DNNs) and improve performances in single-channel and\nuser-independent brain-computer interfaces (BCIs) with small data lengths.\nApproach: We propose the utilization of filter banks (creating sub-band\ncomponents of the EEG signal) in conjunction with DNNs. In this context, we\ncreated three different models: a recurrent neural network (FBRNN) analyzing\nthe time domain, a 2D convolutional neural network (FBCNN-2D) processing\ncomplex spectrum features and a 3D convolutional neural network (FBCNN-3D)\nanalyzing complex spectrograms, which we introduce in this study as possible\ninput for SSVEP classification. We tested our neural networks on three open\ndatasets and conceived them so as not to require calibration from the final\nuser, simulating a user-independent BCI. Results: The DNNs with the filter\nbanks surpassed the accuracy of similar networks without this preprocessing\nstep by considerable margins, and they outperformed common SSVEP classification\nmethods (SVM and FBCCA) by even higher margins. Conclusion and significance:\nFilter banks allow different types of deep neural networks to more efficiently\nanalyze the harmonic components of SSVEP. Complex spectrograms carry more\ninformation than complex spectrum features and the magnitude spectrum, allowing\nthe FBCNN-3D to surpass the other CNNs. The performances obtained in the\nchallenging classification problems indicates a strong potential for the\nconstruction of portable, economical, fast and low-latency BCIs.",
          "link": "http://arxiv.org/abs/2109.02165",
          "publishedOn": "2022-04-02T00:47:19.760Z",
          "wordCount": null,
          "title": "FBDNN: Filter Banks and Deep Neural Networks for Portable and Fast Brain-Computer Interfaces. (arXiv:2109.02165v4 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mendieta_M/0/1/0/all/0/1\">Matias Mendieta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Taojiannan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Minwoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zhengming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>",
          "description": "Federated learning (FL) is a promising strategy for performing\nprivacy-preserving, distributed learning with a network of clients (i.e., edge\ndevices). However, the data distribution among clients is often non-IID in\nnature, making efficient optimization difficult. To alleviate this issue, many\nFL algorithms focus on mitigating the effects of data heterogeneity across\nclients by introducing a variety of proximal terms, some incurring considerable\ncompute and/or memory overheads, to restrain local updates with respect to the\nglobal model. Instead, we consider rethinking solutions to data heterogeneity\nin FL with a focus on local learning generality rather than proximal\nrestriction. To this end, we first present a systematic study informed by\nsecond-order indicators to better understand algorithm effectiveness in FL.\nInterestingly, we find that standard regularization methods are surprisingly\nstrong performers in mitigating data heterogeneity effects. Based on our\nfindings, we further propose a simple and effective method, FedAlign, to\novercome data heterogeneity and the pitfalls of previous methods. FedAlign\nachieves competitive accuracy with state-of-the-art FL methods across a variety\nof settings while minimizing computation and memory overhead. Code is available\nat https://github.com/mmendiet/FedAlign",
          "link": "http://arxiv.org/abs/2111.14213",
          "publishedOn": "2022-04-02T00:47:19.748Z",
          "wordCount": null,
          "title": "Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning. (arXiv:2111.14213v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16912",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ath_G/0/1/0/all/0/1\">George De Ath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chugh_T/0/1/0/all/0/1\">Tinkle Chugh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahat_A/0/1/0/all/0/1\">Alma A. M. Rahat</a>",
          "description": "Optimisation problems often have multiple conflicting objectives that can be\ncomputationally and/or financially expensive. Mono-surrogate Bayesian\noptimisation (BO) is a popular model-based approach for optimising such\nblack-box functions. It combines objective values via scalarisation and builds\na Gaussian process (GP) surrogate of the scalarised values. The location which\nmaximises a cheap-to-query acquisition function is chosen as the next location\nto expensively evaluate. While BO is an effective strategy, the use of GPs is\nlimiting. Their performance decreases as the problem input dimensionality\nincreases, and their computational complexity scales cubically with the amount\nof data. To address these limitations, we extend previous work on BO by\ndensity-ratio estimation (BORE) to the multi-objective setting. BORE links the\ncomputation of the probability of improvement acquisition function to that of\nprobabilistic classification. This enables the use of state-of-the-art\nclassifiers in a BO-like framework. In this work we present MBORE:\nmulti-objective Bayesian optimisation by density-ratio estimation, and compare\nit to BO across a range of synthetic and real-world benchmarks. We find that\nMBORE performs as well as or better than BO on a wide variety of problems, and\nthat it outperforms BO on high-dimensional and real-world problems.",
          "link": "http://arxiv.org/abs/2203.16912",
          "publishedOn": "2022-04-02T00:47:19.737Z",
          "wordCount": null,
          "title": "MBORE: Multi-objective Bayesian Optimisation by Density-Ratio Estimation. (arXiv:2203.16912v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jing_X/0/1/0/all/0/1\">Xin Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parada_Cabaleiro_E/0/1/0/all/0/1\">Emilia Parada-Cabaleiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Triantafyllopoulos_A/0/1/0/all/0/1\">Andreas Triantafyllopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Meishu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zijiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1\">Bj&#xf6;rn W. Schuller</a>",
          "description": "Detecting COVID-19 from audio signals, such as breathing and coughing, can be\nused as a fast and efficient pre-testing method to reduce the virus\ntransmission. Due to the promising results of deep learning networks in\nmodelling time sequences, and since applications to rapidly identify COVID\nin-the-wild should require low computational effort, we present a\ntemporal-oriented broadcasting residual learning method that achieves efficient\ncomputation and high accuracy with a small model size. Based on the\nEfficientNet architecture, our novel network, named Temporal-oriented\nResNet~(TorNet), constitutes of a broadcasting learning block, i.e. the\nAlternating Broadcast (AB) Block, which contains several Broadcast Residual\nBlocks (BC ResBlocks) and a convolution layer. With the AB Block, the network\nobtains useful audio-temporal features and higher level embeddings effectively\nwith much less computation than Recurrent Neural Networks~(RNNs), typically\nused to model temporal information. TorNet achieves 72.2% Unweighted Average\nRecall (UAR) on the INTERPSEECH 2021 Computational Paralinguistics Challenge\nCOVID-19 cough Sub-Challenge, by this showing competitive results with a higher\ncomputational efficiency than other state-of-the-art alternatives.",
          "link": "http://arxiv.org/abs/2203.17012",
          "publishedOn": "2022-04-02T00:47:19.737Z",
          "wordCount": null,
          "title": "A Temporal-oriented Broadcast ResNet for COVID-19 Detection. (arXiv:2203.17012v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jalota_D/0/1/0/all/0/1\">Devansh Jalota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1\">Karthik Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizan_N/0/1/0/all/0/1\">Navid Azizan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johari_R/0/1/0/all/0/1\">Ramesh Johari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>",
          "description": "In transportation networks, users typically choose routes in a decentralized\nand self-interested manner to minimize their individual travel costs, which, in\npractice, often results in inefficient overall outcomes for society. As a\nresult, there has been a growing interest in designing road tolling schemes to\ncope with these efficiency losses and steer users toward a system-efficient\ntraffic pattern. However, the efficacy of road tolling schemes often relies on\nhaving access to complete information on users' trip attributes, such as their\norigin-destination (O-D) travel information and their values of time, which may\nnot be available in practice.\n\nMotivated by this practical consideration, we propose an online learning\napproach to set tolls in a traffic network to drive heterogeneous users with\ndifferent values of time toward a system-efficient traffic pattern. In\nparticular, we develop a simple yet effective algorithm that adjusts tolls at\neach time period solely based on the observed aggregate flows on the roads of\nthe network without relying on any additional trip attributes of users, thereby\npreserving user privacy. In the setting where the O-D pairs and values of time\nof users are drawn i.i.d. at each period, we show that our approach obtains an\nexpected regret and road capacity violation of $O(\\sqrt{T})$, where $T$ is the\nnumber of periods over which tolls are updated. Our regret guarantee is\nrelative to an offline oracle that has complete information on users' trip\nattributes. We further establish a $\\Omega(\\sqrt{T})$ lower bound on the regret\nof any algorithm, which establishes that our algorithm is optimal up to\nconstants. Finally, we demonstrate the superior performance of our approach\nrelative to several benchmarks on a real-world transportation network, thereby\nhighlighting its practical applicability.",
          "link": "http://arxiv.org/abs/2203.17150",
          "publishedOn": "2022-04-02T00:47:19.736Z",
          "wordCount": null,
          "title": "Online Learning for Traffic Routing under Unknown Preferences. (arXiv:2203.17150v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.03959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1\">Rhea Sanjay Sukthanker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiwu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Suryansh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1\">Radu Timofte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Flow-based generative models have shown an excellent ability to explicitly\nlearn the probability density function of data via a sequence of invertible\ntransformations. Yet, learning attentions in generative flows remains\nunderstudied, while it has made breakthroughs in other domains. To fill the\ngap, this paper introduces two types of invertible attention mechanisms, i.e.,\nmap-based and transformer-based attentions, for both unconditional and\nconditional generative flows. The key idea is to exploit a masked scheme of\nthese two attentions to learn long-range data dependencies in the context of\ngenerative flows. The masked scheme allows for invertible attention modules\nwith tractable Jacobian determinants, enabling its seamless integration at any\npositions of the flow-based models. The proposed attention mechanisms lead to\nmore efficient generative flows, due to their capability of modeling the\nlong-term data dependencies. Evaluation on multiple image synthesis tasks shows\nthat the proposed attention flows result in efficient models and compare\nfavorably against the state-of-the-art unconditional and conditional generative\nflows.",
          "link": "http://arxiv.org/abs/2106.03959",
          "publishedOn": "2022-04-02T00:47:19.732Z",
          "wordCount": null,
          "title": "Generative Flows with Invertible Attentions. (arXiv:2106.03959v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Da-Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>",
          "description": "New classes arise frequently in our ever-changing world, e.g., emerging\ntopics in social media and new types of products in e-commerce. A model should\nrecognize new classes and meanwhile maintain discriminability over old classes.\nUnder severe circumstances, only limited novel instances are available to\nincrementally update the model. The task of recognizing few-shot new classes\nwithout forgetting old classes is called few-shot class-incremental learning\n(FSCIL). In this work, we propose a new paradigm for FSCIL based on\nmeta-learning by LearnIng Multi-phase Incremental Tasks (LIMIT), which\nsynthesizes fake FSCIL tasks from the base dataset. The data format of fake\ntasks is consistent with the `real' incremental tasks, and we can build a\ngeneralizable feature space for the unseen tasks through meta-learning.\nBesides, LIMIT also constructs a calibration module based on transformer, which\ncalibrates the old class classifiers and new class prototypes into the same\nscale and fills in the semantic gap. The calibration module also adaptively\ncontextualizes the instance-specific embedding with a set-to-set function.\nLIMIT efficiently adapts to new classes and meanwhile resists forgetting over\nold classes. Experiments on three benchmark datasets (CIFAR100, miniImageNet,\nand CUB200) and large-scale dataset, i.e., ImageNet ILSVRC2012 validate that\nLIMIT achieves state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2203.17030",
          "publishedOn": "2022-04-02T00:47:19.731Z",
          "wordCount": null,
          "title": "Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks. (arXiv:2203.17030v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1\">Abigail J. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chesmore_G/0/1/0/all/0/1\">Grace E. Chesmore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocha_K/0/1/0/all/0/1\">Kyle A. Rocha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farah_A/0/1/0/all/0/1\">Amanda Farah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sayeed_M/0/1/0/all/0/1\">Maryum Sayeed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myles_J/0/1/0/all/0/1\">Justin Myles</a>",
          "description": "$\\textit{The Bachelor}$ is a reality TV dating show in which a single\nbachelor selects his wife from a pool of approximately 30 female contestants\nover eight weeks of filming (American Broadcasting Company 2002). We collected\nthe following data on all 422 contestants that participated in seasons 11\nthrough 25: their Age, Hometown, Career, Race, Week they got their first 1-on-1\ndate, whether they got the first impression rose, and what \"place\" they ended\nup getting. We then trained three machine learning models to predict the ideal\ncharacteristics of a successful contestant on $\\textit{The Bachelor}$. The\nthree algorithms that we tested were: random forest classification, neural\nnetworks, and linear regression. We found consistency across all three models,\nalthough the neural network performed the best overall. Our models found that a\nwoman has the highest probability of progressing far on $\\textit{The Bachelor}$\nif she is: 26 years old, white, from the Northwest, works as an dancer,\nreceived a 1-on-1 in week 6, and did not receive the First Impression Rose. Our\nmethodology is broadly applicable to all romantic reality television, and our\nresults will inform future $\\textit{The Bachelor}$ production and contestant\nstrategies. While our models were relatively successful, we still encountered\nhigh misclassification rates. This may be because: (1) Our training dataset had\nfewer than 400 points or (2) Our models were too simple to parameterize the\ncomplex romantic connections contestants forge over the course of a season.",
          "link": "http://arxiv.org/abs/2203.16648",
          "publishedOn": "2022-04-02T00:47:19.728Z",
          "wordCount": null,
          "title": "Predicting Winners of the Reality TV Dating Show $\\textit{The Bachelor}$ Using Machine Learning Algorithms. (arXiv:2203.16648v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chuizheng Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Sungyong Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griesemer_S/0/1/0/all/0/1\">Sam Griesemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "Physics-informed machine learning (PIML), referring to the combination of\nprior knowledge of physics, which is the high level abstraction of natural\nphenomenons and human behaviours in the long history, with data-driven machine\nlearning models, has emerged as an effective way to mitigate the shortage of\ntraining data, to increase models' generalizability and to ensure the physical\nplausibility of results. In this paper, we survey an abundant number of recent\nworks in PIML and summarize them from three aspects: (1) motivations of PIML,\n(2) physics knowledge in PIML, (3) methods of physics knowledge integration in\nPIML. We also discuss current challenges and corresponding research\nopportunities in PIML.",
          "link": "http://arxiv.org/abs/2203.16797",
          "publishedOn": "2022-04-02T00:47:19.728Z",
          "wordCount": null,
          "title": "When Physics Meets Machine Learning: A Survey of Physics-Informed Machine Learning. (arXiv:2203.16797v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17226",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ross_I/0/1/0/all/0/1\">I. M. Ross</a>",
          "description": "Nesterov's accelerated gradient algorithm is derived from first principles.\nThe first principles are founded on the recently-developed optimal control\ntheory for optimization. This theory frames an optimization problem as an\noptimal control problem whose trajectories generate various continuous-time\nalgorithms. The algorithmic trajectories satisfy the necessary conditions for\noptimal control. The necessary conditions produce a controllable dynamical\nsystem for accelerated optimization. Stabilizing this system via a quadratic\ncontrol Lyapunov function generates an ordinary differential equation. An Euler\ndiscretization of the resulting differential equation produces Nesterov's\nalgorithm. In this context, this result solves the purported mystery\nsurrounding the algorithm.",
          "link": "http://arxiv.org/abs/2203.17226",
          "publishedOn": "2022-04-02T00:47:19.727Z",
          "wordCount": null,
          "title": "A Derivation of Nesterov's Accelerated Gradient Algorithm from Optimal Control Theory. (arXiv:2203.17226v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elbanna_G/0/1/0/all/0/1\">Gasser Elbanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biryukov_A/0/1/0/all/0/1\">Alice Biryukov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheidwasser_Clow_N/0/1/0/all/0/1\">Neil Scheidwasser-Clow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orlandic_L/0/1/0/all/0/1\">Lara Orlandic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mainar_P/0/1/0/all/0/1\">Pablo Mainar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kegler_M/0/1/0/all/0/1\">Mikolaj Kegler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beckmann_P/0/1/0/all/0/1\">Pierre Beckmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cernak_M/0/1/0/all/0/1\">Milos Cernak</a>",
          "description": "As a neurophysiological response to threat or adverse conditions, stress can\naffect cognition, emotion and behaviour with potentially detrimental effects on\nhealth in the case of sustained exposure. Since the affective content of speech\nis inherently modulated by an individual's physical and mental state, a\nsubstantial body of research has been devoted to the study of paralinguistic\ncorrelates of stress-inducing task load. Historically, voice stress analysis\n(VSA) has been conducted using conventional digital signal processing (DSP)\ntechniques. Despite the development of modern methods based on deep neural\nnetworks (DNNs), accurately detecting stress in speech remains difficult due to\nthe wide variety of stressors and considerable variability in the individual\nstress perception. To that end, we introduce a set of five datasets for task\nload detection in speech. The voice recordings were collected as either\ncognitive or physical stress was induced in the cohort of volunteers, with a\ncumulative number of more than a hundred speakers. We used the datasets to\ndesign and evaluate a novel self-supervised audio representation that leverages\nthe effectiveness of handcrafted features (DSP-based) and the complexity of\ndata-driven DNN representations. Notably, the proposed approach outperformed\nboth extensive handcrafted feature sets and novel DNN-based audio\nrepresentation learning approaches.",
          "link": "http://arxiv.org/abs/2203.16637",
          "publishedOn": "2022-04-02T00:47:19.726Z",
          "wordCount": null,
          "title": "Hybrid Handcrafted and Learnable Audio Representation for Analysis of Speech Under Cognitive and Physical Load. (arXiv:2203.16637v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_M/0/1/0/all/0/1\">Meiyu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zhe Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Junping Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feifei_K/0/1/0/all/0/1\">Kou Feifei</a>",
          "description": "Learning knowledge representation of scientific paper data is a problem to be\nsolved, and how to learn the representation of paper nodes in scientific paper\nheterogeneous network is the core to solve this problem. This paper proposes an\nunsupervised cluster-level scientific paper heterogeneous graph node\nrepresentation learning method (UCHL), aiming at obtaining the representation\nof nodes (authors, institutions, papers, etc.) in the heterogeneous graph of\nscientific papers. Based on the heterogeneous graph representation, this paper\nperforms link prediction on the entire heterogeneous graph and obtains the\nrelationship between the edges of the nodes, that is, the relationship between\npapers and papers. Experiments results show that the proposed method achieves\nexcellent performance on multiple evaluation metrics on real scientific paper\ndatasets.",
          "link": "http://arxiv.org/abs/2203.16751",
          "publishedOn": "2022-04-02T00:47:19.720Z",
          "wordCount": null,
          "title": "An unsupervised cluster-level based method for learning node representations of heterogeneous graphs in scientific papers. (arXiv:2203.16751v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xixin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shoukang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xunying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>",
          "description": "Deep neural networks have brought significant advancements to speech emotion\nrecognition (SER). However, the architecture design in SER is mainly based on\nexpert knowledge and empirical (trial-and-error) evaluations, which is\ntime-consuming and resource intensive. In this paper, we propose to apply\nneural architecture search (NAS) techniques to automatically configure the SER\nmodels. To accelerate the candidate architecture optimization, we propose a\nuniform path dropout strategy to encourage all candidate architecture\noperations to be equally optimized. Experimental results of two different\nneural structures on IEMOCAP show that NAS can improve SER performance (54.89\\%\nto 56.28\\%) while maintaining model parameter sizes. The proposed dropout\nstrategy also shows superiority over the previous approaches.",
          "link": "http://arxiv.org/abs/2203.16928",
          "publishedOn": "2022-04-02T00:47:19.716Z",
          "wordCount": null,
          "title": "Neural Architecture Search for Speech Emotion Recognition. (arXiv:2203.16928v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1\">Guanxing Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Hao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xinghao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_X/0/1/0/all/0/1\">Xiaotong Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbas_S/0/1/0/all/0/1\">Saqlain Abbas</a>",
          "description": "Acoustic source localization has been applied in different fields, such as\naeronautics and ocean science, generally using multiple microphones array data\nto reconstruct the source location. However, the model-based beamforming\nmethods fail to achieve the high-resolution of conventional beamforming maps.\nDeep neural networks are also appropriate to locate the sound source, but in\ngeneral, these methods with complex network structures are hard to be\nrecognized by hardware. In this paper, a novel neural network, termed the\nAcoustic-Net, is proposed to locate and quantify the sound source simply using\nthe original signals. The experiments demonstrate that the proposed method\nsignificantly improves the accuracy of sound source prediction and the\ncomputing speed, which may generalize well to real data. The code and trained\nmodels are available at https://github.com/JoaquinChou/Acoustic-Net.",
          "link": "http://arxiv.org/abs/2203.16988",
          "publishedOn": "2022-04-02T00:47:19.716Z",
          "wordCount": null,
          "title": "Acoustic-Net: A Novel Neural Network for Sound Localization and Quantification. (arXiv:2203.16988v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clavel_C/0/1/0/all/0/1\">Chlo&#xe9; Clavel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labeau_M/0/1/0/all/0/1\">Matthieu Labeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cassell_J/0/1/0/all/0/1\">Justine Cassell</a>",
          "description": "Some exciting new approaches to neural architectures for the analysis of\nconversation have been introduced over the past couple of years. These include\nneural architectures for detecting emotion, dialogue acts, and sentiment\npolarity. They take advantage of some of the key attributes of contemporary\nmachine learning, such as recurrent neural networks with attention mechanisms\nand transformer-based approaches. However, while the architectures themselves\nare extremely promising, the phenomena they have been applied to to date are\nbut a small part of what makes conversation engaging. In this paper we survey\nthese neural architectures and what they have been applied to. On the basis of\nthe social science literature, we then describe what we believe to be the most\nfundamental and definitional feature of conversation, which is its\nco-construction over time by two or more interlocutors. We discuss how neural\narchitectures of the sort surveyed could profitably be applied to these more\nfundamental aspects of conversation, and what this buys us in terms of a better\nanalysis of conversation and even, in the longer term, a better way of\ngenerating conversation for a conversational system.",
          "link": "http://arxiv.org/abs/2203.16891",
          "publishedOn": "2022-04-02T00:47:19.714Z",
          "wordCount": null,
          "title": "A survey of neural models for the automatic analysis of conversation: Towards a better integration of the social sciences. (arXiv:2203.16891v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guanzi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiying Zhang</a>",
          "description": "In recent years, hypergraph learning has attracted great attention due to its\ncapacity in representing complex and high-order relationships. However, current\nneural network approaches designed for hypergraphs are mostly shallow, thus\nlimiting their ability to extract information from high-order neighbors. In\nthis paper, we show both theoretically and empirically, that the performance of\nhypergraph neural networks does not improve as the number of layers increases,\nwhich is known as the over-smoothing problem. To tackle this issue, we develop\na new deep hypergraph convolutional network called Deep-HGCN, which can\nmaintain the heterogeneity of node representation in deep layers. Specifically,\nwe prove that a $k$-layer Deep-HGCN simulates a polynomial filter of order $k$\nwith arbitrary coefficients, which can relieve the problem of over-smoothing.\nExperimental results on various datasets demonstrate the superior performance\nof the proposed model comparing to the state-of-the-art hypergraph learning\napproaches.",
          "link": "http://arxiv.org/abs/2203.17159",
          "publishedOn": "2022-04-02T00:47:19.714Z",
          "wordCount": null,
          "title": "Preventing Over-Smoothing for Hypergraph Neural Networks. (arXiv:2203.17159v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tyukin_I/0/1/0/all/0/1\">Ivan Y. Tyukin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_O/0/1/0/all/0/1\">Oliver Sutton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorban_A/0/1/0/all/0/1\">Alexander N. Gorban</a>",
          "description": "In this work we consider the problem of data classification in post-classical\nsettings were the number of training examples consists of mere few data points.\nWe explore the phenomenon and reveal key relationships between dimensionality\nof AI model's feature space, non-degeneracy of data distributions, and the\nmodel's generalisation capabilities. The main thrust of our present analysis is\non the influence of nonlinear feature transformations mapping original data\ninto higher- and possibly infinite-dimensional spaces on the resulting model's\ngeneralisation capabilities. Subject to appropriate assumptions, we establish\nnew relationships between intrinsic dimensions of the transformed data and the\nprobabilities to learn successfully from few presentations.",
          "link": "http://arxiv.org/abs/2203.16935",
          "publishedOn": "2022-04-02T00:47:19.694Z",
          "wordCount": null,
          "title": "Learning from few examples with nonlinear feature maps. (arXiv:2203.16935v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Avinash Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikuesan_R/0/1/0/all/0/1\">Richard Adeyemi Ikuesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venter_H/0/1/0/all/0/1\">Hein Venter</a>",
          "description": "Ransomware attacks have increased significantly in recent years, causing\ngreat destruction and damage to critical systems and business operations.\nAttackers are unfailingly finding innovative ways to bypass detection\nmechanisms, whichencouraged the adoption of artificial intelligence. However,\nmost research summarizes the general features of AI and induces many false\npositives, as the behavior of ransomware constantly differs to bypass\ndetection. Focusing on the key indicating features of ransomware becomes vital\nas this guides the investigator to the inner workings and main function of\nransomware itself. By utilizing access privileges in process memory, the main\nfunction of the ransomware can be detected more easily and accurately.\nFurthermore, new signatures and fingerprints of ransomware families can be\nidentified to classify novel ransomware attacks correctly. The current research\nused the process memory access privileges of the different memory regions of\nthe behavior of an executable to quickly determine its intent before serious\nharm can occur. To achieve this aim, several well-known machine learning\nalgorithms were explored with an accuracy range of 81.38 to 96.28 percents. The\nstudy thus confirms the feasibility of utilizing process memory as a detection\nmechanism for ransomware.",
          "link": "http://arxiv.org/abs/2203.16871",
          "publishedOn": "2022-04-02T00:47:19.684Z",
          "wordCount": null,
          "title": "Ransomware Detection using Process Memory. (arXiv:2203.16871v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16874",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoli Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gao_T/0/1/0/all/0/1\">Ting Gao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Duan_J/0/1/0/all/0/1\">Jinqiao Duan</a>",
          "description": "Many complex real world phenomena exhibit abrupt, intermittent or jumping\nbehaviors, which are more suitable to be described by stochastic differential\nequations under non-Gaussian L\\'evy noise. Among these complex phenomena, the\nmost likely transition paths between metastable states are important since\nthese rare events may have high impact in certain scenarios. Based on the large\ndeviation principle, the most likely transition path could be treated as the\nminimizer of the rate function upon paths that connect two points. One of the\nchallenges to calculate the most likely transition path for stochastic\ndynamical systems under non-Gaussian L\\'evy noise is that the associated rate\nfunction can not be explicitly expressed by paths. For this reason, we\nformulate an optimal control problem to obtain the optimal state as the most\nlikely transition path. We then develop a neural network method to solve this\nissue. Several experiments are investigated for both Gaussian and non-Gaussian\ncases.",
          "link": "http://arxiv.org/abs/2203.16874",
          "publishedOn": "2022-04-02T00:47:19.675Z",
          "wordCount": null,
          "title": "An Optimal Control Method to Compute the Most Likely Transition Path for Stochastic Dynamical Systems with Jumps. (arXiv:2203.16874v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16711",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1\">Junyu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Najafi_K/0/1/0/all/0/1\">Khadijeh Najafi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sharma_K/0/1/0/all/0/1\">Kunal Sharma</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tacchino_F/0/1/0/all/0/1\">Francesco Tacchino</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jiang_L/0/1/0/all/0/1\">Liang Jiang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Mezzacapo_A/0/1/0/all/0/1\">Antonio Mezzacapo</a>",
          "description": "Parametrized quantum circuits can be used as quantum neural networks and have\nthe potential to outperform their classical counterparts when trained for\naddressing learning problems. To date, much of the results on their performance\non practical problems are heuristic in nature. In particular, the convergence\nrate for the training of quantum neural networks is not fully understood. Here,\nwe analyze the dynamics of gradient descent for the training error of a class\nof variational quantum machine learning models. We define wide quantum neural\nnetworks as parameterized quantum circuits in the limit of a large number of\nqubits and variational parameters. We then find a simple analytic formula that\ncaptures the average behavior of their loss function and discuss the\nconsequences of our findings. For example, for random quantum circuits, we\npredict and characterize an exponential decay of the residual training error as\na function of the parameters of the system. We finally validate our analytic\nresults with numerical experiments.",
          "link": "http://arxiv.org/abs/2203.16711",
          "publishedOn": "2022-04-02T00:47:19.645Z",
          "wordCount": null,
          "title": "An analytic theory for the dynamics of wide quantum neural networks. (arXiv:2203.16711v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16852",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lim_D/0/1/0/all/0/1\">Dan Lim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jung_S/0/1/0/all/0/1\">Sunghee Jung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_E/0/1/0/all/0/1\">Eesung Kim</a>",
          "description": "In neural text-to-speech (TTS), two-stage system or a cascade of separately\nlearned models have shown synthesis quality close to human speech. For example,\nFastSpeech2 transforms an input text to a mel-spectrogram and then HiFi-GAN\ngenerates a raw waveform from a mel-spectogram where they are called an\nacoustic feature generator and a neural vocoder respectively. However, their\ntraining pipeline is somewhat cumbersome in that it requires a fine-tuning and\nan accurate speech-text alignment for optimal performance. In this work, we\npresent end-to-end text-to-speech (E2E-TTS) model which has a simplified\ntraining pipeline and outperforms a cascade of separately learned models.\nSpecifically, our proposed model is jointly trained FastSpeech2 and HiFi-GAN\nwith an alignment module. Since there is no acoustic feature mismatch between\ntraining and inference, it does not requires fine-tuning. Furthermore, we\nremove dependency on an external speech-text alignment tool by adopting an\nalignment learning objective in our joint training framework. Experiments on\nLJSpeech corpus shows that the proposed model outperforms publicly available,\nstate-of-the-art implementations of ESPNet2-TTS on subjective evaluation (MOS)\nand some objective evaluations.",
          "link": "http://arxiv.org/abs/2203.16852",
          "publishedOn": "2022-04-02T00:47:19.632Z",
          "wordCount": null,
          "title": "JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to Speech. (arXiv:2203.16852v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16642",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Goerigk_M/0/1/0/all/0/1\">Marc Goerigk</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kurtz_J/0/1/0/all/0/1\">Jannis Kurtz</a>",
          "description": "In this work we study robust one- and two-stage problems with discrete\nuncertainty sets which are known to be hard to solve even if the underlying\ndeterministic problem is easy. Popular solution methods iteratively generate\nscenario constraints and possibly second-stage variables. This way, by solving\na sequence of smaller problems, it is often possible to avoid the complexity of\nconsidering all scenarios simultaneously. A key ingredient for the performance\nof the iterative methods is a good selection of start scenarios. In this paper\nwe propose a data-driven heuristic to seed the iterative solution method with a\nset of starting scenarios that provide a strong lower bound early in the\nprocess, and result in considerably smaller overall solution times compared to\nother benchmark methods. Our heuristic learns the relevance of a scenario by\nextracting information from training data based on a combined similarity\nmeasure between robust problem instances and single scenarios. Our experiments\nshow that predicting even a small number of good start scenarios by our method\ncan considerably reduce the computation time of the iterative methods.",
          "link": "http://arxiv.org/abs/2203.16642",
          "publishedOn": "2022-04-02T00:47:19.618Z",
          "wordCount": null,
          "title": "Data-driven Prediction of Relevant Scenarios for Robust Optimization. (arXiv:2203.16642v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17164",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Bondar_D/0/1/0/all/0/1\">Denys I. Bondar</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Popovych_Z/0/1/0/all/0/1\">Zakhar Popovych</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jacobs_K/0/1/0/all/0/1\">Kurt Jacobs</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Korpas_G/0/1/0/all/0/1\">Georgios Korpas</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Marecek_J/0/1/0/all/0/1\">Jakub Marecek</a>",
          "description": "Current quantum devices suffer imperfections as a result of fabrication, as\nwell as noise and dissipation as a result of coupling to their immediate\nenvironments. Because of this, it is often difficult to obtain accurate models\nof their dynamics from first principles. An alternative is to extract such\nmodels from time-series measurements of their behavior. Here, we formulate this\nsystem-identification problem as a polynomial optimization problem. Recent\nadvances in optimization have provided globally convergent solvers for this\nclass of problems, which using our formulation prove estimates of the Kraus map\nor the Lindblad equation. We include an overview of the state-of-the-art\nalgorithms, bounds, and convergence rates, and illustrate the use of this\napproach to modeling open quantum systems.",
          "link": "http://arxiv.org/abs/2203.17164",
          "publishedOn": "2022-04-02T00:47:19.521Z",
          "wordCount": null,
          "title": "Recovering models of open quantum systems from data via polynomial optimization: Towards globally convergent quantum system identification. (arXiv:2203.17164v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16749",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Koizumi_Y/0/1/0/all/0/1\">Yuma Koizumi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zen_H/0/1/0/all/0/1\">Heiga Zen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yatabe_K/0/1/0/all/0/1\">Kohei Yatabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_N/0/1/0/all/0/1\">Nanxin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bacchiani_M/0/1/0/all/0/1\">Michiel Bacchiani</a>",
          "description": "Neural vocoder using denoising diffusion probabilistic model (DDPM) has been\nimproved by adaptation of the diffusion noise distribution to given acoustic\nfeatures. In this study, we propose SpecGrad that adapts the diffusion noise so\nthat its time-varying spectral envelope becomes close to the conditioning\nlog-mel spectrogram. This adaptation by time-varying filtering improves the\nsound quality especially in the high-frequency bands. It is processed in the\ntime-frequency domain to keep the computational cost almost the same as the\nconventional DDPM-based neural vocoders. Experimental results showed that\nSpecGrad generates higher-fidelity speech waveform than conventional DDPM-based\nneural vocoders in both analysis-synthesis and speech enhancement scenarios.\nAudio demos are available at wavegrad.github.io/specgrad/.",
          "link": "http://arxiv.org/abs/2203.16749",
          "publishedOn": "2022-04-02T00:47:19.470Z",
          "wordCount": null,
          "title": "SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with Adaptive Noise Spectral Shaping. (arXiv:2203.16749v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.05630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_N/0/1/0/all/0/1\">Nian Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhengyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanchet_J/0/1/0/all/0/1\">Jose Blanchet</a>",
          "description": "Policy learning using historical observational data is an important problem\nthat has found widespread applications. Examples include selecting offers,\nprices, advertisements to send to customers, as well as selecting which\nmedication to prescribe to a patient. However, existing literature rests on the\ncrucial assumption that the future environment where the learned policy will be\ndeployed is the same as the past environment that has generated the data -- an\nassumption that is often false or too coarse an approximation. In this paper,\nwe lift this assumption and aim to learn a distributionally robust policy with\nincomplete observational data. We first present a policy evaluation procedure\nthat allows us to assess how well the policy does under the worst-case\nenvironment shift. We then establish a central limit theorem type guarantee for\nthis proposed policy evaluation scheme. Leveraging this evaluation scheme, we\nfurther propose a novel learning algorithm that is able to learn a policy that\nis robust to adversarial perturbations and unknown covariate shifts with a\nperformance guarantee based on the theory of uniform convergence. Finally, we\nempirically test the effectiveness of our proposed algorithm in synthetic\ndatasets and demonstrate that it provides the robustness that is missing using\nstandard policy learning algorithms. We conclude the paper by providing a\ncomprehensive application of our methods in the context of a real-world voting\ndataset.",
          "link": "http://arxiv.org/abs/2006.05630",
          "publishedOn": "2022-04-02T00:47:19.450Z",
          "wordCount": null,
          "title": "Distributional Robust Batch Contextual Bandits. (arXiv:2006.05630v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamel_C/0/1/0/all/0/1\">Craig M. Hamel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_K/0/1/0/all/0/1\">Kevin N. Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kramer_S/0/1/0/all/0/1\">Sharlotte L.B. Kramer</a>",
          "description": "The calibration of solid constitutive models with full-field experimental\ndata is a long-standing challenge, especially in materials which undergo large\ndeformation. In this paper, we propose a physics-informed deep-learning\nframework for the discovery of constitutive model parameterizations given\nfull-field displacement data and global force-displacement data. Contrary to\nthe majority of recent literature in this field, we work with the weak form of\nthe governing equations rather than the strong form to impose physical\nconstraints upon the neural network predictions. The approach presented in this\npaper is computationally efficient, suitable for irregular geometric domains,\nand readily ingests displacement data without the need for interpolation onto a\ncomputational grid. A selection of canonical hyperelastic materials models\nsuitable for different material classes is considered including the\nNeo-Hookean, Gent, and Blatz-Ko constitutive models as exemplars for general\nhyperelastic behavior, polymer behavior with lock-up, and compressible foam\nbehavior respectively. We demonstrate that physics informed machine learning is\nan enabling technology and may shift the paradigm of how full-field\nexperimental data is utilized to calibrate constitutive models under finite\ndeformations.",
          "link": "http://arxiv.org/abs/2203.16577",
          "publishedOn": "2022-04-02T00:47:18.841Z",
          "wordCount": 614,
          "title": "Calibrating constitutive models with full-field data via physics informed neural networks. (arXiv:2203.16577v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aru_J/0/1/0/all/0/1\">Jaan Aru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labash_A/0/1/0/all/0/1\">Aqeel Labash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corcoll_O/0/1/0/all/0/1\">Oriol Corcoll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vicente_R/0/1/0/all/0/1\">Raul Vicente</a>",
          "description": "Theory of Mind is an essential ability of humans to infer the mental states\nof others. Here we provide a coherent summary of the potential, current\nprogress, and problems of deep learning approaches to Theory of Mind. We\nhighlight that many current findings can be explained through shortcuts. These\nshortcuts arise because the tasks used to investigate Theory of Mind in deep\nlearning systems have been too narrow. Thus, we encourage researchers to\ninvestigate Theory of Mind in complex open-ended environments. Furthermore, to\ninspire future deep learning systems we provide a concise overview of prior\nwork done in humans. We further argue that when studying Theory of Mind with\ndeep learning, the research's main focus and contribution ought to be opening\nup the network's representations. We recommend researchers use tools from the\nfield of interpretability of AI to study the relationship between different\nnetwork components and aspects of Theory of Mind.",
          "link": "http://arxiv.org/abs/2203.16540",
          "publishedOn": "2022-04-02T00:47:18.834Z",
          "wordCount": 602,
          "title": "Mind the gap: Challenges of deep learning approaches to Theory of Mind. (arXiv:2203.16540v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ziyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1\">Bhavya Kailkhura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>",
          "description": "Many important machine learning applications involve regularized nonconvex\nbi-level optimization. However, the existing gradient-based bi-level\noptimization algorithms cannot handle nonconvex or nonsmooth regularizers, and\nthey suffer from a high computation complexity in nonconvex bi-level\noptimization. In this work, we study a proximal gradient-type algorithm that\nadopts the approximate implicit differentiation (AID) scheme for nonconvex\nbi-level optimization with possibly nonconvex and nonsmooth regularizers. In\nparticular, the algorithm applies the Nesterov's momentum to accelerate the\ncomputation of the implicit gradient involved in AID. We provide a\ncomprehensive analysis of the global convergence properties of this algorithm\nthrough identifying its intrinsic potential function. In particular, we\nformally establish the convergence of the model parameters to a critical point\nof the bi-level problem, and obtain an improved computation complexity\n$\\mathcal{O}(\\kappa^{3.5}\\epsilon^{-2})$ over the state-of-the-art result.\nMoreover, we analyze the asymptotic convergence rates of this algorithm under a\nclass of local nonconvex geometries characterized by a {\\L}ojasiewicz-type\ngradient inequality. Experiment on hyper-parameter optimization demonstrates\nthe effectiveness of our algorithm.",
          "link": "http://arxiv.org/abs/2203.16615",
          "publishedOn": "2022-04-02T00:47:18.783Z",
          "wordCount": 617,
          "title": "A Fast and Convergent Proximal Algorithm for Regularized Nonconvex and Nonsmooth Bi-level Optimization. (arXiv:2203.16615v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bombari_S/0/1/0/all/0/1\">Simone Bombari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1\">Alessandro Achille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yusheng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1\">Kunwar Yashraj Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Appalaraju_S/0/1/0/all/0/1\">Srikar Appalaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadevan_V/0/1/0/all/0/1\">Vijay Mahadevan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Memorization of the relation between entities in a dataset can lead to\nprivacy issues when using a trained model for question answering. We introduce\nRelational Memorization (RM) to understand, quantify and control this\nphenomenon. While bounding general memorization can have detrimental effects on\nthe performance of a trained model, bounding RM does not prevent effective\nlearning. The difference is most pronounced when the data distribution is\nlong-tailed, with many queries having only few training examples: Impeding\ngeneral memorization prevents effective learning, while impeding only\nrelational memorization still allows learning general properties of the\nunderlying concepts. We formalize the notion of Relational Privacy (RP) and,\ninspired by Differential Privacy (DP), we provide a possible definition of\nDifferential Relational Privacy (DrP). These notions can be used to describe\nand compute bounds on the amount of RM in a trained model. We illustrate\nRelational Privacy concepts in experiments with large-scale models for Question\nAnswering.",
          "link": "http://arxiv.org/abs/2203.16701",
          "publishedOn": "2022-04-02T00:47:18.726Z",
          "wordCount": 609,
          "title": "Towards Differential Relational Privacy and its use in Question Answering. (arXiv:2203.16701v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carranza_A/0/1/0/all/0/1\">Aldo Gael Carranza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "Many popular contextual bandit algorithms estimate reward models to inform\ndecision making. However, true rewards can contain action-independent\nredundancies that are not relevant for decision making and only increase the\nstatistical complexity of accurate estimation. It is sufficient and more\ndata-efficient to estimate the simplest function that explains the reward\ndifferences between actions, that is, the heterogeneous treatment effect,\ncommonly understood to be more structured and simpler than the reward.\nMotivated by this observation, building on recent work on oracle-based\nalgorithms, we design a statistically optimal and computationally efficient\nalgorithm using heterogeneous treatment effect estimation oracles. Our results\nprovide the first universal reduction of contextual bandits to a\ngeneral-purpose heterogeneous treatment effect estimation method. We show that\nour approach is more robust to model misspecification than reward estimation\nmethods based on squared error regression oracles. Experimentally, we show the\nbenefits of heterogeneous treatment effect estimation in contextual bandits\nover reward estimation.",
          "link": "http://arxiv.org/abs/2203.16668",
          "publishedOn": "2022-04-02T00:47:18.378Z",
          "wordCount": 601,
          "title": "Flexible and Efficient Contextual Bandits with Heterogeneous Treatment Effect Oracle. (arXiv:2203.16668v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16707",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Yao_J/0/1/0/all/0/1\">Jiahao Yao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_H/0/1/0/all/0/1\">Haoya Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Bukov_M/0/1/0/all/0/1\">Marin Bukov</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lin_L/0/1/0/all/0/1\">Lin Lin</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ying_L/0/1/0/all/0/1\">Lexing Ying</a>",
          "description": "Variational quantum algorithms stand at the forefront of simulations on\nnear-term and future fault-tolerant quantum devices. While most variational\nquantum algorithms involve only continuous optimization variables, the\nrepresentational power of the variational ansatz can sometimes be significantly\nenhanced by adding certain discrete optimization variables, as is exemplified\nby the generalized quantum approximate optimization algorithm (QAOA). However,\nthe hybrid discrete-continuous optimization problem in the generalized QAOA\nposes a challenge to the optimization. We propose a new algorithm called\nMCTS-QAOA, which combines a Monte Carlo tree search method with an improved\nnatural policy gradient solver to optimize the discrete and continuous\nvariables in the quantum circuit, respectively. We find that MCTS-QAOA has\nexcellent noise-resilience properties and outperforms prior algorithms in\nchallenging instances of the generalized QAOA.",
          "link": "http://arxiv.org/abs/2203.16707",
          "publishedOn": "2022-04-02T00:47:18.372Z",
          "wordCount": 577,
          "title": "Monte Carlo Tree Search based Hybrid Optimization of Variational Quantum Circuits. (arXiv:2203.16707v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Olivier_R/0/1/0/all/0/1\">Raphael Olivier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1\">Bhiksha Raj</a>",
          "description": "Like many other tasks involving neural networks, Speech Recognition models\nare vulnerable to adversarial attacks. However recent research has pointed out\ndifferences between attacks and defenses on ASR models compared to image\nmodels. Improving the robustness of ASR models requires a paradigm shift from\nevaluating attacks on one or a few models to a systemic approach in evaluation.\nWe lay the ground for such research by evaluating on various architectures a\nrepresentative set of adversarial attacks: targeted and untargeted,\noptimization and speech processing-based, white-box, black-box and targeted\nattacks. Our results show that the relative strengths of different attack\nalgorithms vary considerably when changing the model architecture, and that the\nresults of some attacks are not to be blindly trusted. They also indicate that\ntraining choices such as self-supervised pretraining can significantly impact\nrobustness by enabling transferable perturbations. We release our source code\nas a package that should help future research in evaluating their attacks and\ndefenses.",
          "link": "http://arxiv.org/abs/2203.16536",
          "publishedOn": "2022-04-02T00:47:18.330Z",
          "wordCount": 616,
          "title": "Recent improvements of ASR models in the face of adversarial attacks. (arXiv:2203.16536v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cacciapuoti_R/0/1/0/all/0/1\">Rosalba Cacciapuoti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAmore_L/0/1/0/all/0/1\">Luisa D&#x27;Amore</a>",
          "description": "We focus on Partial Differential Equation (PDE) based Data Assimilatio\nproblems (DA) solved by means of variational approaches and Kalman filter\nalgorithm. Recently, we presented a Domain Decomposition framework (we call it\nDD-DA, for short) performing a decomposition of the whole physical domain along\nspace and time directions, and joining the idea of Schwarz' methods and\nparallel in time approaches. For effective parallelization of DD-DA algorithms,\nthe computational load assigned to subdomains must be equally distributed.\nUsually computational cost is proportional to the amount of data entities\nassigned to partitions. Good quality partitioning also requires the volume of\ncommunication during calculation to be kept at its minimum. In order to deal\nwith DD-DA problems where the observations are nonuniformly distributed and\ngeneral sparse, in the present work we employ a parallel load balancing\nalgorithm based on adaptive and dynamic defining of boundaries of DD -- which\nis aimed to balance workload according to data location. We call it DyDD. As\nthe numerical model underlying DA problems arising from the so-called\ndiscretize-then-optimize approach is the constrained least square model (CLS),\nwe will use CLS as a reference state estimation problem and we validate DyDD on\ndifferent scenarios.",
          "link": "http://arxiv.org/abs/2203.16535",
          "publishedOn": "2022-04-02T00:47:18.324Z",
          "wordCount": 669,
          "title": "Parallel framework for Dynamic Domain Decomposition of Data Assimilation problems a case study on Kalman Filter algorithm. (arXiv:2203.16535v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16683",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Rocha_K/0/1/0/all/0/1\">Kyle Akira Rocha</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Andrews_J/0/1/0/all/0/1\">Jeff J. Andrews</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Berry_C/0/1/0/all/0/1\">Christopher P. L. Berry</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Doctor_Z/0/1/0/all/0/1\">Zoheyr Doctor</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Marchant_P/0/1/0/all/0/1\">Pablo Marchant</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kalogera_V/0/1/0/all/0/1\">Vicky Kalogera</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Coughlin_S/0/1/0/all/0/1\">Scott Coughlin</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Bavera_S/0/1/0/all/0/1\">Simone S. Bavera</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Dotter_A/0/1/0/all/0/1\">Aaron Dotter</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Fragos_T/0/1/0/all/0/1\">Tassos Fragos</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kovlakas_K/0/1/0/all/0/1\">Konstantinos Kovlakas</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Misra_D/0/1/0/all/0/1\">Devina Misra</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Xing_Z/0/1/0/all/0/1\">Zepei Xing</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Zapartas_E/0/1/0/all/0/1\">Emmanouil Zapartas</a>",
          "description": "Binary stars undergo a variety of interactions and evolutionary phases,\ncritical for predicting and explaining observed properties. Binary population\nsynthesis with full stellar-structure and evolution simulations are\ncomputationally expensive requiring a large number of mass-transfer sequences.\nThe recently developed binary population synthesis code POSYDON incorporates\ngrids of MESA binary star simulations which are then interpolated to model\nlarge-scale populations of massive binaries. The traditional method of\ncomputing a high-density rectilinear grid of simulations is not scalable for\nhigher-dimension grids, accounting for a range of metallicities, rotation, and\neccentricity. We present a new active learning algorithm, psy-cris, which uses\nmachine learning in the data-gathering process to adaptively and iteratively\nselect targeted simulations to run, resulting in a custom, high-performance\ntraining set. We test psy-cris on a toy problem and find the resulting training\nsets require fewer simulations for accurate classification and regression than\neither regular or randomly sampled grids. We further apply psy-cris to the\ntarget problem of building a dynamic grid of MESA simulations, and we\ndemonstrate that, even without fine tuning, a simulation set of only $\\sim 1/4$\nthe size of a rectilinear grid is sufficient to achieve the same classification\naccuracy. We anticipate further gains when algorithmic parameters are optimized\nfor the targeted application. We find that optimizing for classification only\nmay lead to performance losses in regression, and vice versa. Lowering the\ncomputational cost of producing grids will enable future versions of POSYDON to\ncover more input parameters while preserving interpolation accuracies.",
          "link": "http://arxiv.org/abs/2203.16683",
          "publishedOn": "2022-04-02T00:47:18.317Z",
          "wordCount": 726,
          "title": "Active Learning for Computationally Efficient Distribution of Binary Evolution Simulations. (arXiv:2203.16683v1 [astro-ph.SR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michelis_M/0/1/0/all/0/1\">Mike Y. Michelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katzschmann_R/0/1/0/all/0/1\">Robert K. Katzschmann</a>",
          "description": "Enhancing neural networks with knowledge of physical equations has become an\nefficient way of solving various physics problems, from fluid flow to\nelectromagnetism. Graph neural networks show promise in accurately representing\nirregularly meshed objects and learning their dynamics, but have so far\nrequired supervision through large datasets. In this work, we represent meshes\nnaturally as graphs, process these using Graph Networks, and formulate our\nphysics-based loss to provide an unsupervised learning framework for partial\ndifferential equations (PDE). We quantitatively compare our results to a\nclassical numerical PDE solver, and show that our computationally efficient\napproach can be used as an interactive PDE solver that is adjusting boundary\nconditions in real-time and remains sufficiently close to the baseline\nsolution. Our inherently differentiable framework will enable the application\nof PDE solvers in interactive settings, such as model-based control of\nsoft-body deformations, or in gradient-based optimization methods that require\na fully differentiable pipeline.",
          "link": "http://arxiv.org/abs/2203.16628",
          "publishedOn": "2022-04-02T00:47:18.309Z",
          "wordCount": 583,
          "title": "Physics-constrained Unsupervised Learning of Partial Differential Equations using Meshes. (arXiv:2203.16628v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16622",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Baid_U/0/1/0/all/0/1\">Ujjwal Baid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pati_S/0/1/0/all/0/1\">Sarthak Pati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kurc_T/0/1/0/all/0/1\">Tahsin M. Kurc</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gupta_R/0/1/0/all/0/1\">Rajarsi Gupta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bremer_E/0/1/0/all/0/1\">Erich Bremer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abousamra_S/0/1/0/all/0/1\">Shahira Abousamra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thakur_S/0/1/0/all/0/1\">Siddhesh P. Thakur</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Saltz_J/0/1/0/all/0/1\">Joel H. Saltz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bakas_S/0/1/0/all/0/1\">Spyridon Bakas</a>",
          "description": "We evaluate the performance of federated learning (FL) in developing deep\nlearning models for analysis of digitized tissue sections. A classification\napplication was considered as the example use case, on quantifiying the\ndistribution of tumor infiltrating lymphocytes within whole slide images\n(WSIs). A deep learning classification model was trained using 50*50 square\nmicron patches extracted from the WSIs. We simulated a FL environment in which\na dataset, generated from WSIs of cancer from numerous anatomical sites\navailable by The Cancer Genome Atlas repository, is partitioned in 8 different\nnodes. Our results show that the model trained with the federated training\napproach achieves similar performance, both quantitatively and qualitatively,\nto that of a model trained with all the training data pooled at a centralized\nlocation. Our study shows that FL has tremendous potential for enabling\ndevelopment of more robust and accurate models for histopathology image\nanalysis without having to collect large and diverse training data at a single\nlocation.",
          "link": "http://arxiv.org/abs/2203.16622",
          "publishedOn": "2022-04-02T00:47:18.291Z",
          "wordCount": 624,
          "title": "Federated Learning for the Classification of Tumor Infiltrating Lymphocytes. (arXiv:2203.16622v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1\">Zhenrui Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Huimin Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kou_Z/0/1/0/all/0/1\">Ziyi Kou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1\">Lanyu Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>",
          "description": "Modern smart sensor-based energy management systems leverage non-intrusive\nload monitoring (NILM) to predict and optimize appliance load distribution in\nreal-time. NILM, or energy disaggregation, refers to the decomposition of\nelectricity usage conditioned on the aggregated power signals (i.e., smart\nsensor on the main channel). Based on real-time appliance power prediction\nusing sensory technology, energy disaggregation has great potential to increase\nelectricity efficiency and reduce energy expenditure. With the introduction of\ntransformer models, NILM has achieved significant improvements in predicting\ndevice power readings. Nevertheless, transformers are less efficient due to\nO(l^2) complexity w.r.t. sequence length l. Moreover, transformers can fail to\ncapture local signal patterns in sequence-to-point settings due to the lack of\ninductive bias in local context. In this work, we propose an efficient\nlocalness transformer for non-intrusive load monitoring (ELTransformer).\nSpecifically, we leverage normalization functions and switch the order of\nmatrix multiplication to approximate self-attention and reduce computational\ncomplexity. Additionally, we introduce localness modeling with sparse local\nattention heads and relative position encodings to enhance the model capacity\nin extracting short-term local patterns. To the best of our knowledge,\nELTransformer is the first NILM model that addresses computational complexity\nand localness modeling in NILM. With extensive experiments and quantitative\nanalyses, we demonstrate the efficiency and effectiveness of the the proposed\nELTransformer with considerable improvements compared to state-of-the-art\nbaselines.",
          "link": "http://arxiv.org/abs/2203.16537",
          "publishedOn": "2022-04-02T00:47:18.284Z",
          "wordCount": 668,
          "title": "Efficient Localness Transformer for Smart Sensor-Based Energy Disaggregation. (arXiv:2203.16537v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yu-Huai Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-Shin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1\">Pin-Tuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>",
          "description": "In traditional speaker diarization systems, a well-trained speaker model is a\nkey component to extract representations from consecutive and partially\noverlapping segments in a long speech session. To be more consistent with the\nback-end segmentation and clustering, we propose a new CNN-based speaker\nmodeling scheme, which takes into account the heterogeneity of the speakers in\neach training segment and batch. We randomly and synthetically augment the\ntraining data into a set of segments, each of which contains more than one\nspeaker and some overlapping parts. A soft label is imposed on each segment\nbased on its speaker occupation ratio, and the standard cross entropy loss is\nimplemented in model training. In this way, the speaker model should have the\nability to generate a geometrically meaningful embedding for each multi-speaker\nsegment. Experimental results show that our system is superior to the baseline\nsystem using x-vectors in two speaker diarization tasks. In the CALLHOME task\ntrained on the NIST SRE and Switchboard datasets, our system achieves a\nrelative reduction of 12.93% in DER. In Track 2 of CHiME-6, our system provides\n13.24%, 12.60%, and 5.65% relative reductions in DER, JER, and WER,\nrespectively.",
          "link": "http://arxiv.org/abs/2203.16646",
          "publishedOn": "2022-04-02T00:47:18.278Z",
          "wordCount": 652,
          "title": "Generation of Speaker Representations Using Heterogeneous Training Batch Assembly. (arXiv:2203.16646v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16574",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miculicich_L/0/1/0/all/0/1\">Lesly Miculicich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>",
          "description": "The state-of-the-art models for coreference resolution are based on\nindependent mention pair-wise decisions. We propose a modelling approach that\nlearns coreference at the document-level and takes global decisions. For this\npurpose, we model coreference links in a graph structure where the nodes are\ntokens in the text, and the edges represent the relationship between them. Our\nmodel predicts the graph in a non-autoregressive manner, then iteratively\nrefines it based on previous predictions, allowing global dependencies between\ndecisions. The experimental results show improvements over various baselines,\nreinforcing the hypothesis that document-level information improves conference\nresolution.",
          "link": "http://arxiv.org/abs/2203.16574",
          "publishedOn": "2022-04-02T00:47:18.269Z",
          "wordCount": 523,
          "title": "Graph Refinement for Coreference Resolution. (arXiv:2203.16574v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16662",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Beckham_C/0/1/0/all/0/1\">Christopher Beckham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Laradji_I/0/1/0/all/0/1\">Issam Laradji</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rodriguez_P/0/1/0/all/0/1\">Pau Rodriguez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vazquez_D/0/1/0/all/0/1\">David Vazquez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nowrouzezahrai_D/0/1/0/all/0/1\">Derek Nowrouzezahrai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "In this paper, we explore the use of GAN-based few-shot data augmentation as\na method to improve few-shot classification performance. We perform an\nexploration into how a GAN can be fine-tuned for such a task (one of which is\nin a class-incremental manner), as well as a rigorous empirical investigation\ninto how well these models can perform to improve few-shot classification. We\nidentify issues related to the difficulty of training such generative models\nunder a purely supervised regime with very few examples, as well as issues\nregarding the evaluation protocols of existing works. We also find that in this\nregime, classification accuracy is highly sensitive to how the classes of the\ndataset are randomly split. Therefore, we propose a semi-supervised fine-tuning\napproach as a more pragmatic way forward to address these problems.",
          "link": "http://arxiv.org/abs/2203.16662",
          "publishedOn": "2022-04-02T00:47:18.263Z",
          "wordCount": 572,
          "title": "Challenges in leveraging GANs for few-shot data augmentation. (arXiv:2203.16662v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hersche_M/0/1/0/all/0/1\">Michael Hersche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karunaratne_G/0/1/0/all/0/1\">Geethan Karunaratne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cherubini_G/0/1/0/all/0/1\">Giovanni Cherubini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebastian_A/0/1/0/all/0/1\">Abu Sebastian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahimi_A/0/1/0/all/0/1\">Abbas Rahimi</a>",
          "description": "Continually learning new classes from fresh data without forgetting previous\nknowledge of old classes is a very challenging research problem. Moreover, it\nis imperative that such learning must respect certain memory and computational\nconstraints such as (i) training samples are limited to only a few per class,\n(ii) the computational cost of learning a novel class remains constant, and\n(iii) the memory footprint of the model grows at most linearly with the number\nof classes observed. To meet the above constraints, we propose C-FSCIL, which\nis architecturally composed of a frozen meta-learned feature extractor, a\ntrainable fixed-size fully connected layer, and a rewritable dynamically\ngrowing memory that stores as many vectors as the number of encountered\nclasses. C-FSCIL provides three update modes that offer a trade-off between\naccuracy and compute-memory cost of learning novel classes. C-FSCIL exploits\nhyperdimensional embedding that allows to continually express many more classes\nthan the fixed dimensions in the vector space, with minimal interference. The\nquality of class vector representations is further improved by aligning them\nquasi-orthogonally to each other by means of novel loss functions. Experiments\non the CIFAR100, miniImageNet, and Omniglot datasets show that C-FSCIL\noutperforms the baselines with remarkable accuracy and compression. It also\nscales up to the largest problem size ever tried in this few-shot setting by\nlearning 423 novel classes on top of 1200 base classes with less than 1.6%\naccuracy drop. Our code is available at\nhttps://github.com/IBM/constrained-FSCIL.",
          "link": "http://arxiv.org/abs/2203.16588",
          "publishedOn": "2022-04-02T00:47:18.256Z",
          "wordCount": 682,
          "title": "Constrained Few-shot Class-incremental Learning. (arXiv:2203.16588v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lv_H/0/1/0/all/0/1\">Heng Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zi-Xiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Chunling Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1\">Wu-Hao Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenglong You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1\">Rui-Bo Jin</a>",
          "description": "Orbital angular momentum of light is regarded as a valuable resource in\nquantum technology, especially in quantum communication and quantum sensing and\nranging. However, the OAM state of light is susceptible to undesirable\nexperimental conditions such as propagation distance and phase distortions,\nwhich hinders the potential for the realistic implementation of relevant\ntechnologies. In this article, we exploit an enhanced deep learning neural\nnetwork to identify different OAM modes of light at multiple propagation\ndistances with phase distortions. Specifically, our trained deep learning\nneural network can efficiently identify the vortex beam's topological charge\nand propagation distance with 97% accuracy. Our technique has important\nimplications for OAM based communication and sensing protocols.",
          "link": "http://arxiv.org/abs/2203.16539",
          "publishedOn": "2022-04-02T00:47:18.225Z",
          "wordCount": 591,
          "title": "Identification of diffracted vortex beams at different propagation distances using deep learning. (arXiv:2203.16539v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mei_L/0/1/0/all/0/1\">Lingjie Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>",
          "description": "We present a meta-learning framework for learning new visual concepts\nquickly, from just one or a few examples, guided by multiple naturally\noccurring data streams: simultaneously looking at images, reading sentences\nthat describe the objects in the scene, and interpreting supplemental sentences\nthat relate the novel concept with other concepts. The learned concepts support\ndownstream applications, such as answering questions by reasoning about unseen\nimages. Our model, namely FALCON, represents individual visual concepts, such\nas colors and shapes, as axis-aligned boxes in a high-dimensional space (the\n\"box embedding space\"). Given an input image and its paired sentence, our model\nfirst resolves the referential expression in the sentence and associates the\nnovel concept with particular objects in the scene. Next, our model interprets\nsupplemental sentences to relate the novel concept with other known concepts,\nsuch as \"X has property Y\" or \"X is a kind of Y\". Finally, it infers an optimal\nbox embedding for the novel concept that jointly 1) maximizes the likelihood of\nthe observed instances in the image, and 2) satisfies the relationships between\nthe novel concepts and the known ones. We demonstrate the effectiveness of our\nmodel on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2203.16639",
          "publishedOn": "2022-04-02T00:47:18.216Z",
          "wordCount": 672,
          "title": "FALCON: Fast Visual Concept Learning by Integrating Images, Linguistic descriptions, and Conceptual Relations. (arXiv:2203.16639v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haviv_A/0/1/0/all/0/1\">Adi Haviv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_O/0/1/0/all/0/1\">Ori Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Press_O/0/1/0/all/0/1\">Ofir Press</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izsak_P/0/1/0/all/0/1\">Peter Izsak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1\">Omer Levy</a>",
          "description": "Transformers typically require some form of positional encoding, such as\npositional embeddings, to process natural language sequences. Surprisingly, we\nfind that transformer language models without any explicit positional encoding\nare still competitive with standard models, and that this phenomenon is robust\nacross different datasets, model sizes, and sequence lengths. Probing\nexperiments reveal that such models acquire an implicit notion of absolute\npositions throughout the network, effectively compensating for the missing\ninformation. We conjecture that causal attention enables the model to infer the\nnumber of predecessors that each token can attend to, thereby approximating its\nabsolute position.",
          "link": "http://arxiv.org/abs/2203.16634",
          "publishedOn": "2022-04-02T00:47:18.191Z",
          "wordCount": 545,
          "title": "Transformer Language Models without Positional Encodings Still Learn Positional Information. (arXiv:2203.16634v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lentzas_A/0/1/0/all/0/1\">Athanasios Lentzas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vrakas_D/0/1/0/all/0/1\">Dimitris Vrakas</a>",
          "description": "Home absence detection is an emerging field on smart home installations.\nIdentifying whether or not the residents of the house are present, is important\nin numerous scenarios. Possible scenarios include but are not limited to:\nelderly people living alone, people suffering from dementia, home quarantine.\nThe majority of published papers focus on either pressure / door sensors or\ncameras in order to detect outing events. Although the aforementioned\napproaches provide solid results, they are intrusive and require modifications\nfor sensor placement. In our work, appliance electrical use is investigated as\na means for detecting the presence or absence of residents. The energy use is\nthe result of power disaggregation, a non intrusive / non invasive sensing\nmethod. Since a dataset providing energy data and ground truth for home absence\nis not available, artificial outing events were introduced on the UK-DALE\ndataset, a well known dataset for Non Intrusive Load Monitoring (NILM). Several\nmachine learning algorithms were evaluated using the generated dataset.\nBenchmark results have shown that home absence detection using appliance power\nconsumption is feasible.",
          "link": "http://arxiv.org/abs/2203.16538",
          "publishedOn": "2022-04-02T00:47:18.184Z",
          "wordCount": 637,
          "title": "Machine Learning Approaches for Non-Intrusive Home Absence Detection Based on Appliance Electrical Use. (arXiv:2203.16538v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.04420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1\">Harshavardhan Kamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Alexander Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1\">B. Aditya Prakash</a>",
          "description": "In real-time forecasting in public health, data collection is a non-trivial\nand demanding task. Often after initially released, it undergoes several\nrevisions later (maybe due to human or technical constraints) - as a result, it\nmay take weeks until the data reaches to a stable value. This so-called\n'backfill' phenomenon and its effect on model performance has been barely\nstudied in the prior literature. In this paper, we introduce the multi-variate\nbackfill problem using COVID-19 as the motivating example. We construct a\ndetailed dataset composed of relevant signals over the past year of the\npandemic. We then systematically characterize several patterns in backfill\ndynamics and leverage our observations for formulating a novel problem and\nneural framework Back2Future that aims to refines a given model's predictions\nin real-time. Our extensive experiments demonstrate that our method refines the\nperformance of top models for COVID-19 forecasting, in contrast to non-trivial\nbaselines, yielding 18% improvement over baselines, enabling us obtain a new\nSOTA performance. In addition, we show that our model improves model evaluation\ntoo; hence policy-makers can better understand the true accuracy of forecasting\nmodels in real-time.",
          "link": "http://arxiv.org/abs/2106.04420",
          "publishedOn": "2022-03-27T00:51:42.565Z",
          "wordCount": 756,
          "title": "Back2Future: Leveraging Backfill Dynamics for Improving Real-time Predictions in Future. (arXiv:2106.04420v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1\">Pengzhen Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Changlin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guangrun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yun Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Q/0/1/0/all/0/1\">Qing Du Xiaodan Liang Xiaojun Chang</a>",
          "description": "Recently, a surge of interest in visual transformers is to reduce the\ncomputational cost by limiting the calculation of self-attention to a local\nwindow. Most current work uses a fixed single-scale window for modeling by\ndefault, ignoring the impact of window size on model performance. However, this\nmay limit the modeling potential of these window-based models for multi-scale\ninformation. In this paper, we propose a novel method, named Dynamic Window\nVision Transformer (DW-ViT). The dynamic window strategy proposed by DW-ViT\ngoes beyond the model that employs a fixed single window setting. To the best\nof our knowledge, we are the first to use dynamic multi-scale windows to\nexplore the upper limit of the effect of window settings on model performance.\nIn DW-ViT, multi-scale information is obtained by assigning windows of\ndifferent sizes to different head groups of window multi-head self-attention.\nThen, the information is dynamically fused by assigning different weights to\nthe multi-scale window branches. We conducted a detailed performance evaluation\non three datasets, ImageNet-1K, ADE20K, and COCO. Compared with related\nstate-of-the-art (SoTA) methods, DW-ViT obtains the best performance.\nSpecifically, compared with the current SoTA Swin Transformers\n\\cite{liu2021swin}, DW-ViT has achieved consistent and substantial improvements\non all three datasets with similar parameters and computational costs. In\naddition, DW-ViT exhibits good scalability and can be easily inserted into any\nwindow-based visual transformers.",
          "link": "http://arxiv.org/abs/2203.12856",
          "publishedOn": "2022-03-26T00:46:08.023Z",
          "wordCount": 668,
          "title": "Beyond Fixation: Dynamic Window Visual Transformer. (arXiv:2203.12856v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brekelmans_R/0/1/0/all/0/1\">Rob Brekelmans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Genewein_T/0/1/0/all/0/1\">Tim Genewein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grau_Moya_J/0/1/0/all/0/1\">Jordi Grau-Moya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deletang_G/0/1/0/all/0/1\">Gr&#xe9;goire Del&#xe9;tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunesch_M/0/1/0/all/0/1\">Markus Kunesch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Legg_S/0/1/0/all/0/1\">Shane Legg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortega_P/0/1/0/all/0/1\">Pedro Ortega</a>",
          "description": "Policy regularization methods such as maximum entropy regularization are\nwidely used in reinforcement learning to improve the robustness of a learned\npolicy. In this paper, we show how this robustness arises from hedging against\nworst-case perturbations of the reward function, which are chosen from a\nlimited set by an imagined adversary. Using convex duality, we characterize\nthis robust set of adversarial reward perturbations under KL and\nalpha-divergence regularization, which includes Shannon and Tsallis entropy\nregularization as special cases. Importantly, generalization guarantees can be\ngiven within this robust set. We provide detailed discussion of the worst-case\nreward perturbations, and present intuitive empirical examples to illustrate\nthis robustness and its relationship with generalization. Finally, we discuss\nhow our analysis complements and extends previous results on adversarial reward\nrobustness and path consistency optimality conditions.",
          "link": "http://arxiv.org/abs/2203.12592",
          "publishedOn": "2022-03-26T00:46:08.017Z",
          "wordCount": 592,
          "title": "Your Policy Regularizer is Secretly an Adversary. (arXiv:2203.12592v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kefalas_M/0/1/0/all/0/1\">Marios Kefalas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rojo_J/0/1/0/all/0/1\">Juan de Santiago Rojo Jr.</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apostolidis_A/0/1/0/all/0/1\">Asteris Apostolidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herik_D/0/1/0/all/0/1\">Dirk van den Herik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stein_B/0/1/0/all/0/1\">Bas van Stein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Back_T/0/1/0/all/0/1\">Thomas B&#xe4;ck</a>",
          "description": "Data-driven modeling is an imperative tool in various industrial\napplications, including many applications in the sectors of aeronautics and\ncommercial aviation. These models are in charge of providing key insights, such\nas which parameters are important on a specific measured outcome or which\nparameter values we should expect to observe given a set of input parameters.\nAt the same time, however, these models rely heavily on assumptions (e.g.,\nstationarity) or are \"black box\" (e.g., deep neural networks), meaning that\nthey lack interpretability of their internal working and can be viewed only in\nterms of their inputs and outputs. An interpretable alternative to the \"black\nbox\" models and with considerably less assumptions is symbolic regression (SR).\nSR searches for the optimal model structure while simultaneously optimizing the\nmodel's parameters without relying on an a-priori model structure. In this\nwork, we apply SR on real-life exhaust gas temperature (EGT) data, collected at\nhigh frequencies through the entire flight, in order to uncover meaningful\nalgebraic relationships between the EGT and other measurable engine parameters.\nThe experimental results exhibit promising model accuracy, as well as\nexplainability returning an absolute difference of 3{\\deg}C compared to the\nground truth and demonstrating consistency from an engineering perspective.",
          "link": "http://arxiv.org/abs/2203.13108",
          "publishedOn": "2022-03-26T00:46:07.924Z",
          "wordCount": 687,
          "title": "Explainable Artificial Intelligence for Exhaust Gas Temperature of Turbofan Engines. (arXiv:2203.13108v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_T/0/1/0/all/0/1\">Taeyeong Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Would_O/0/1/0/all/0/1\">Owen Would</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salazar_Gomez_A/0/1/0/all/0/1\">Adrian Salazar-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cielniak_G/0/1/0/all/0/1\">Grzegorz Cielniak</a>",
          "description": "Data augmentation can be a simple yet powerful tool for autonomous robots to\nfully utilise available data for selfsupervised identification of atypical\nscenes or objects. State-of-the-art augmentation methods arbitrarily embed\n\"structural\" peculiarity on typical images so that classifying these artefacts\ncan provide guidance for learning representations for the detection of\nanomalous visual signals. In this paper, however, we argue that learning such\nstructure-sensitive representations can be a suboptimal approach to some\nclasses of anomaly (e.g., unhealthy fruits) which could be better recognised by\na different type of visual element such as \"colour\". We thus propose Channel\nRandomisation as a novel data augmentation method for restricting neural\nnetworks to learn encoding of \"colour irregularity\" whilst predicting\nchannel-randomised images to ultimately build reliable fruit-monitoring robots\nidentifying atypical fruit qualities. Our experiments show that (1) this\ncolour-based alternative can better learn representations for consistently\naccurate identification of fruit anomalies in various fruit species, and also,\n(2) unlike other methods, the validation accuracy can be utilised as a\ncriterion for early stopping of training in practice due to positive\ncorrelation between the performance in the self-supervised\ncolour-differentiation task and the subsequent detection rate of actual\nanomalous fruits. Also, the proposed approach is evaluated on a new\nagricultural dataset, Riseholme-2021, consisting of 3.5K strawberry images\ngathered by a mobile robot, which we share online to encourage active\nagri-robotics research.",
          "link": "http://arxiv.org/abs/2109.10135",
          "publishedOn": "2022-03-26T00:46:07.917Z",
          "wordCount": 707,
          "title": "Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies. (arXiv:2109.10135v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.07508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tong_G/0/1/0/all/0/1\">Guangmo Tong</a>",
          "description": "Real-world decision-making systems are often subject to uncertainties that\nhave to be resolved through observational data. Therefore, we are frequently\nconfronted with combinatorial optimization problems of which the objective\nfunction is unknown and thus has to be debunked using empirical evidence. In\ncontrast to the common practice that relies on a learning-and-optimization\nstrategy, we consider the regression between combinatorial spaces, aiming to\ninfer high-quality optimization solutions from samples of input-solution pairs\n-- without the need to learn the objective function. Our main deliverable is a\nuniversal solver that is able to handle abstract undetermined stochastic\ncombinatorial optimization problems. For learning foundations, we present\nlearning-error analysis under the PAC-Bayesian framework using a new\nmargin-based analysis. In empirical studies, we demonstrate our design using\nproof-of-concept experiments, and compare it with other methods that are\npotentially applicable. Overall, we obtain highly encouraging experimental\nresults for several classic combinatorial problems on both synthetic and\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2107.07508",
          "publishedOn": "2022-03-26T00:46:07.897Z",
          "wordCount": 606,
          "title": "USCO-Solver: Solving Undetermined Stochastic Combinatorial Optimization Problems. (arXiv:2107.07508v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.10982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Myers_Dean_J/0/1/0/all/0/1\">Josh Myers-Dean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yinan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Price_B/0/1/0/all/0/1\">Brian Price</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Scott Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurari_D/0/1/0/all/0/1\">Danna Gurari</a>",
          "description": "Generalized few-shot semantic segmentation was introduced to move beyond only\nevaluating few-shot segmentation models on novel classes to include testing\ntheir ability to remember base classes. While the current state-of-the-art\napproach is based on meta-learning, it performs poorly and saturates in\nlearning after observing only a few shots. We propose the first fine-tuning\nsolution, and demonstrate that it addresses the saturation problem while\nachieving state-of-the-art results on two datasets, PASCAL-5i and COCO-20i. We\nalso show that it outperforms existing methods, whether fine-tuning multiple\nfinal layers or only the final layer. Finally, we present a triplet loss\nregularization that shows how to redistribute the balance of performance\nbetween novel and base categories so that there is a smaller gap between them.",
          "link": "http://arxiv.org/abs/2112.10982",
          "publishedOn": "2022-03-26T00:46:07.847Z",
          "wordCount": 609,
          "title": "Generalized Few-Shot Semantic Segmentation: All You Need is Fine-Tuning. (arXiv:2112.10982v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.02234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Dong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daum_M/0/1/0/all/0/1\">Maureen Daum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1\">Walter Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balazinska_M/0/1/0/all/0/1\">Magdalena Balazinska</a>",
          "description": "We design, implement, and evaluate DeepEverest, a system for the efficient\nexecution of interpretation by example queries over the activation values of a\ndeep neural network. DeepEverest consists of an efficient indexing technique\nand a query execution algorithm with various optimizations. We prove that the\nproposed query execution algorithm is instance optimal. Experiments with our\nprototype show that DeepEverest, using less than 20% of the storage of full\nmaterialization, significantly accelerates individual queries by up to 63x and\nconsistently outperforms other methods on multi-query workloads that simulate\nDNN interpretation processes.",
          "link": "http://arxiv.org/abs/2104.02234",
          "publishedOn": "2022-03-26T00:46:07.841Z",
          "wordCount": 633,
          "title": "DeepEverest: Accelerating Declarative Top-K Queries for Deep Neural Network Interpretation [Technical Report]. (arXiv:2104.02234v7 [cs.DB] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12088",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weir_J/0/1/0/all/0/1\">Joshua Weir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junhong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalmers_A/0/1/0/all/0/1\">Andrew Chalmers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhee_T/0/1/0/all/0/1\">Taehyun Rhee</a>",
          "description": "We present a deep neural network for removing undesirable shading features\nfrom an unconstrained portrait image, recovering the underlying texture. Our\ntraining scheme incorporates three regularization strategies: masked loss, to\nemphasize high-frequency shading features; soft-shadow loss, which improves\nsensitivity to subtle changes in lighting; and shading-offset estimation, to\nsupervise separation of shading and texture. Our method demonstrates improved\ndelighting quality and generalization when compared with the state-of-the-art.\nWe further demonstrate how our delighting method can enhance the performance of\nlight-sensitive computer vision tasks such as face relighting and semantic\nparsing, allowing them to handle extreme lighting conditions.",
          "link": "http://arxiv.org/abs/2203.12088",
          "publishedOn": "2022-03-26T00:46:07.818Z",
          "wordCount": 551,
          "title": "Deep Portrait Delighting. (arXiv:2203.12088v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suliman_M/0/1/0/all/0/1\">Mohamed A. Suliman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_L/0/1/0/all/0/1\">Logan Z. J. Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fawaz_A/0/1/0/all/0/1\">Abdulah Fawaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robinson_E/0/1/0/all/0/1\">Emma C. Robinson</a>",
          "description": "Cortical surface registration is a fundamental tool for neuroimaging analysis\nthat has been shown to improve the alignment of functional regions relative to\nvolumetric approaches. Classically, image registration is performed by\noptimizing a complex objective similarity function, leading to long run times.\nThis contributes to a convention for aligning all data to a global average\nreference frame that poorly reflects the underlying cortical heterogeneity. In\nthis paper, we propose a novel unsupervised learning-based framework that\nconverts registration to a multi-label classification problem, where each point\nin a low-resolution control grid deforms to one of fixed, finite number of\nendpoints. This is learned using a spherical geometric deep learning\narchitecture, in an end-to-end unsupervised way, with regularization imposed\nusing a deep Conditional Random Field (CRF). Experiments show that our proposed\nframework performs competitively, in terms of similarity and areal distortion,\nrelative to the most popular classical surface registration algorithms and\ngenerates smoother deformations than other learning-based surface registration\nmethods, even in subjects with atypical cortical morphology.",
          "link": "http://arxiv.org/abs/2203.12999",
          "publishedOn": "2022-03-26T00:46:07.813Z",
          "wordCount": 615,
          "title": "A Deep-Discrete Learning Framework for Spherical Surface Registration. (arXiv:2203.12999v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12932",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Burrello_A/0/1/0/all/0/1\">Alessio Burrello</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Morghet_F/0/1/0/all/0/1\">Francesco Bianco Morghet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scherer_M/0/1/0/all/0/1\">Moritz Scherer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Benatti_S/0/1/0/all/0/1\">Simone Benatti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Macii_E/0/1/0/all/0/1\">Enrico Macii</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Poncino_M/0/1/0/all/0/1\">Massimo Poncino</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pagliari_D/0/1/0/all/0/1\">Daniele Jahier Pagliari</a>",
          "description": "Human-machine interaction is gaining traction in rehabilitation tasks, such\nas controlling prosthetic hands or robotic arms. Gesture recognition exploiting\nsurface electromyographic (sEMG) signals is one of the most promising\napproaches, given that sEMG signal acquisition is non-invasive and is directly\nrelated to muscle contraction. However, the analysis of these signals still\npresents many challenges since similar gestures result in similar muscle\ncontractions. Thus the resulting signal shapes are almost identical, leading to\nlow classification accuracy. To tackle this challenge, complex neural networks\nare employed, which require large memory footprints, consume relatively high\nenergy and limit the maximum battery life of devices used for classification.\nThis work addresses this problem with the introduction of the Bioformers. This\nnew family of ultra-small attention-based architectures approaches\nstate-of-the-art performance while reducing the number of parameters and\noperations of 4.9X. Additionally, by introducing a new inter-subjects\npre-training, we improve the accuracy of our best Bioformer by 3.39%, matching\nstate-of-the-art accuracy without any additional inference cost. Deploying our\nbest performing Bioformer on a Parallel, Ultra-Low Power (PULP) microcontroller\nunit (MCU), the GreenWaves GAP8, we achieve an inference latency and energy of\n2.72 ms and 0.14 mJ, respectively, 8.0X lower than the previous\nstate-of-the-art neural network, while occupying just 94.2 kB of memory.",
          "link": "http://arxiv.org/abs/2203.12932",
          "publishedOn": "2022-03-26T00:46:07.807Z",
          "wordCount": 658,
          "title": "Bioformers: Embedding Transformers for Ultra-Low Power sEMG-based Gesture Recognition. (arXiv:2203.12932v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13110",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kram_S/0/1/0/all/0/1\">Sebastian Kram</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kraus_C/0/1/0/all/0/1\">Christopher Kraus</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feigl_T/0/1/0/all/0/1\">Tobias Feigl</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stahlke_M/0/1/0/all/0/1\">Maximilian Stahlke</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Robert_J/0/1/0/all/0/1\">J&#xf6;rg Robert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mutschler_C/0/1/0/all/0/1\">Christopher Mutschler</a>",
          "description": "Recent localization frameworks exploit spatial information of complex channel\nmeasurements (CMs) to estimate accurate positions even in multipath propagation\nscenarios. State-of-the art CM fingerprinting(FP)-based methods employ\nconvolutional neural networks (CNN) to extract the spatial information.\nHowever, they need spatially dense data sets (associated with high acquisition\nand maintenance efforts) to work well -- which is rarely the case in practical\napplications. If such data is not available (or its quality is low), we cannot\ncompensate the performance degradation of CNN-based FP as they do not provide\nstatistical position estimates, which prevents a fusion with other sources of\ninformation on the observation level.\n\nWe propose a novel localization framework that adapts well to sparse datasets\nthat only contain CMs of specific areas within the environment with strong\nmultipath propagation. Our framework compresses CMs into informative features\nto unravel spatial information. It then regresses Gaussian processes (GPs) for\neach of them, which imply statistical observation models based on\ndistance-dependent covariance kernels. Our framework combines the trained GPs\nwith line-of-sight ranges and a dynamics model in a particle filter. Our\nmeasurements show that our approach outperforms state-of-the-art CNN\nfingerprinting (0.52 m vs. 1.3 m MAE) on spatially sparse data collected in a\nrealistic industrial indoor environment.",
          "link": "http://arxiv.org/abs/2203.13110",
          "publishedOn": "2022-03-26T00:46:07.792Z",
          "wordCount": 659,
          "title": "Position Tracking using Likelihood Modeling of Channel Features with Gaussian Processes. (arXiv:2203.13110v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.06825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yi-Lin Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1\">Jaemin Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Recently, fine-tuning language models pre-trained on large text corpora have\nprovided huge improvements on vision-and-language (V&L) tasks as well as on\npure language tasks. However, fine-tuning the entire parameter set of\npre-trained models becomes impractical since the model size is growing rapidly.\nHence, in this paper, we introduce adapter-based parameter-efficient transfer\nlearning techniques to V&L models such as VL-BART and VLT5. We evaluate our\nmethods in a unified multi-task setup on both image-text and video-text\nbenchmarks. For the image-text tasks, we use four diverse V&L datasets: VQAv2,\nGQA, NLVR2 , and MSCOCO image captioning. For video-text tasks, we use TVQA,\nHow2QA, TVC, and YC2C. With careful training and thorough experiments, we\nbenchmark three popular adapter-based methods (Adapter, Hyperformer, Compacter)\nagainst the standard full fine-tuning and the recently proposed prompt-tuning\napproach. We also enhance the efficiency and performance of adapters by sharing\ntheir weights to attain knowledge across tasks. Our results demonstrate that\ntraining the adapter with the weight-sharing technique (4.18% of total\nparameters for image-text tasks and 3.39% for video-text tasks) can match the\nperformance of fine-tuning the entire model. Lastly, we present a comprehensive\nanalysis including the combination of adapter and task-specific prompts and the\nimpact of V&L pre-training on adapters. Our code is available at:\nhttps://github.com/ylsung/VL_adapter.",
          "link": "http://arxiv.org/abs/2112.06825",
          "publishedOn": "2022-03-26T00:46:07.769Z",
          "wordCount": 696,
          "title": "VL-Adapter: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks. (arXiv:2112.06825v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13186",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Andreas_P/0/1/0/all/0/1\">Pastor Andr&#xe9;as</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Krasula_L/0/1/0/all/0/1\">Luk&#xe1;&#x161; Krasula</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoqing Zhu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_Z/0/1/0/all/0/1\">Zhi Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Callet_P/0/1/0/all/0/1\">Patrick Le Callet</a>",
          "description": "The goal of most subjective studies is to place a set of stimuli on a\nperceptual scale. This is mostly done directly by rating, e.g. using single or\ndouble stimulus methodologies, or indirectly by ranking or pairwise comparison.\nAll these methods estimate the perceptual magnitudes of the stimuli on a scale.\nHowever, procedures such as Maximum Likelihood Difference Scaling (MLDS) have\nshown that considering perceptual distances can bring benefits in terms of\ndiscriminatory power, observers' cognitive load, and the number of trials\nrequired. One of the disadvantages of the MLDS method is that the perceptual\nscales obtained for stimuli created from different source content are generally\nnot comparable. In this paper, we propose an extension of the MLDS method that\nensures inter-content comparability of the results and shows its usefulness\nespecially in the presence of observer errors.",
          "link": "http://arxiv.org/abs/2203.13186",
          "publishedOn": "2022-03-26T00:46:07.750Z",
          "wordCount": 594,
          "title": "Improving Maximum Likelihood Difference Scaling method to measure inter content scale. (arXiv:2203.13186v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avidor_T/0/1/0/all/0/1\">Tomer Avidor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Israel_N/0/1/0/all/0/1\">Nadav Tal Israel</a>",
          "description": "Distributed training algorithms of deep neural networks show impressive\nconvergence speedup properties on very large problems. However, they inherently\nsuffer from communication related slowdowns and communication topology becomes\na crucial design choice. Common approaches supported by most machine learning\nframeworks are: 1) Synchronous decentralized algorithms relying on a\npeer-to-peer All Reduce topology that is sensitive to stragglers and\ncommunication delays. 2) Asynchronous centralised algorithms with a server\nbased topology that is prone to communication bottleneck. Researchers also\nsuggested asynchronous decentralized algorithms designed to avoid the\nbottleneck and speedup training, however, those commonly use inexact sparse\naveraging that may lead to a degradation in accuracy. In this paper, we propose\nLocal Asynchronous SGD (LASGD), an asynchronous decentralized algorithm that\nrelies on All Reduce for model synchronization.\n\nWe empirically validate LASGD's performance on image classification tasks on\nthe ImageNet dataset. Our experiments demonstrate that LASGD accelerates\ntraining compared to SGD and state of the art gossip based approaches.",
          "link": "http://arxiv.org/abs/2203.13085",
          "publishedOn": "2022-03-26T00:46:07.743Z",
          "wordCount": 592,
          "title": "Locally Asynchronous Stochastic Gradient Descent for Decentralised Deep Learning. (arXiv:2203.13085v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bijl_E/0/1/0/all/0/1\">Etienne van de Bijl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_J/0/1/0/all/0/1\">Jan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pries_J/0/1/0/all/0/1\">Joris Pries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhulai_S/0/1/0/all/0/1\">Sandjai Bhulai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoogendoorn_M/0/1/0/all/0/1\">Mark Hoogendoorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_R/0/1/0/all/0/1\">Rob van der Mei</a>",
          "description": "Novel prediction methods should always be compared to a baseline to know how\nwell they perform. Without this frame of reference, the performance score of a\nmodel is basically meaningless. What does it mean when a model achieves an\n$F_1$ of 0.8 on a test set? A proper baseline is needed to evaluate the\n`goodness' of a performance score. Comparing with the latest state-of-the-art\nmodel is usually insightful. However, being state-of-the-art can change rapidly\nwhen newer models are developed. Contrary to an advanced model, a simple dummy\nclassifier could be used. However, the latter could be beaten too easily,\nmaking the comparison less valuable. This paper presents a universal baseline\nmethod for all binary classification models, named the Dutch Draw (DD). This\napproach weighs simple classifiers and determines the best classifier to use as\na baseline. We theoretically derive the DD baseline for many commonly used\nevaluation measures and show that in most situations it reduces to (almost)\nalways predicting either zero or one. Summarizing, the DD baseline is: (1)\ngeneral, as it is applicable to all binary classification problems; (2) simple,\nas it is quickly determined without training or parameter-tuning; (3)\ninformative, as insightful conclusions can be drawn from the results. The DD\nbaseline serves two purposes. First, to enable comparisons across research\npapers by this robust and universal baseline. Secondly, to provide a sanity\ncheck during the development process of a prediction model. It is a major\nwarning sign when a model is outperformed by the DD baseline.",
          "link": "http://arxiv.org/abs/2203.13084",
          "publishedOn": "2022-03-26T00:46:07.727Z",
          "wordCount": 714,
          "title": "The Dutch Draw: Constructing a Universal Baseline for Binary Prediction Models. (arXiv:2203.13084v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pelosin_F/0/1/0/all/0/1\">Francesco Pelosin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Saurav Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torsello_A/0/1/0/all/0/1\">Andrea Torsello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raducanu_B/0/1/0/all/0/1\">Bogdan Raducanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weijer_J/0/1/0/all/0/1\">Joost van de Weijer</a>",
          "description": "In this paper, we investigate the continual learning of Vision Transformers\n(ViT) for the challenging exemplar-free scenario, with special focus on how to\nefficiently distill the knowledge of its crucial self-attention mechanism\n(SAM). Our work takes an initial step towards a surgical investigation of SAM\nfor designing coherent continual learning methods in ViTs. We first carry out\nan evaluation of established continual learning regularization techniques. We\nthen examine the effect of regularization when applied to two key enablers of\nSAM: (a) the contextualized embedding layers, for their ability to capture\nwell-scaled representations with respect to the values, and (b) the prescaled\nattention maps, for carrying value-independent global contextual information.\nWe depict the perks of each distilling strategy on two image recognition\nbenchmarks (CIFAR100 and ImageNet-32) -- while (a) leads to a better overall\naccuracy, (b) helps enhance the rigidity by maintaining competitive\nperformances. Furthermore, we identify the limitation imposed by the symmetric\nnature of regularization losses. To alleviate this, we propose an asymmetric\nvariant and apply it to the pooled output distillation (POD) loss adapted for\nViTs. Our experiments confirm that introducing asymmetry to POD boosts its\nplasticity while retaining stability across (a) and (b). Moreover, we\nacknowledge low forgetting measures for all the compared methods, indicating\nthat ViTs might be naturally inclined continual learner",
          "link": "http://arxiv.org/abs/2203.13167",
          "publishedOn": "2022-03-26T00:46:07.713Z",
          "wordCount": 675,
          "title": "Towards Exemplar-Free Continual Learning in Vision Transformers: an Account of Attention, Functional and Weight Regularization. (arXiv:2203.13167v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1\">Subhabrata Dutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Juneja_J/0/1/0/all/0/1\">Jeevesh Juneja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Dipankar Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>",
          "description": "Identifying argument components from unstructured texts and predicting the\nrelationships expressed among them are two primary steps of argument mining.\nThe intrinsic complexity of these tasks demands powerful learning models. While\npretrained Transformer-based Language Models (LM) have been shown to provide\nstate-of-the-art results over different NLP tasks, the scarcity of manually\nannotated data and the highly domain-dependent nature of argumentation restrict\nthe capabilities of such models. In this work, we propose a novel transfer\nlearning strategy to overcome these challenges. We utilize argumentation-rich\nsocial discussions from the ChangeMyView subreddit as a source of unsupervised,\nargumentative discourse-aware knowledge by finetuning pretrained LMs on a\nselectively masked language modeling task. Furthermore, we introduce a novel\nprompt-based strategy for inter-component relation prediction that compliments\nour proposed finetuning method while leveraging on the discourse context.\nExhaustive experiments show the generalization capability of our method on\nthese two tasks over within-domain as well as out-of-domain datasets,\noutperforming several existing and employed strong baselines.",
          "link": "http://arxiv.org/abs/2203.12881",
          "publishedOn": "2022-03-26T00:46:07.706Z",
          "wordCount": 605,
          "title": "Can Unsupervised Knowledge Transfer from Social Discussions Help Argument Mining?. (arXiv:2203.12881v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.04462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zong_Z/0/1/0/all/0/1\">Zefang Zong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_T/0/1/0/all/0/1\">Tao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1\">Tong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Depeng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong Li</a>",
          "description": "Recent technology development brings the booming of numerous new\nDemand-Driven Services (DDS) into urban lives, including ridesharing, on-demand\ndelivery, express systems and warehousing. In DDS, a service loop is an\nelemental structure, including its service worker, the service providers and\ncorresponding service targets. The service workers should transport either\nhumans or parcels from the providers to the target locations. Various planning\ntasks within DDS can thus be classified into two individual stages: 1)\nDispatching, which is to form service loops from demand/supply distributions,\nand 2)Routing, which is to decide specific serving orders within the\nconstructed loops. Generating high-quality strategies in both stages is\nimportant to develop DDS but faces several challenging. Meanwhile, deep\nreinforcement learning (DRL) has been developed rapidly in recent years. It is\na powerful tool to solve these problems since DRL can learn a parametric model\nwithout relying on too many problem-based assumptions and optimize long-term\neffect by learning sequential decisions. In this survey, we first define DDS,\nthen highlight common applications and important decision/control problems\nwithin. For each problem, we comprehensively introduce the existing DRL\nsolutions. We also introduce open simulation environments for development and\nevaluation of DDS applications. Finally, we analyze remaining challenges and\ndiscuss further research opportunities in DRL solutions for DDS.",
          "link": "http://arxiv.org/abs/2108.04462",
          "publishedOn": "2022-03-26T00:46:07.686Z",
          "wordCount": 692,
          "title": "Deep Reinforcement Learning for Demand Driven Services in Logistics and Transportation Systems: A Survey. (arXiv:2108.04462v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.09916",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Laperre_B/0/1/0/all/0/1\">Brecht Laperre</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Amaya_J/0/1/0/all/0/1\">Jorge Amaya</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Jamal_S/0/1/0/all/0/1\">Sara Jamal</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lapenta_G/0/1/0/all/0/1\">Giovanni Lapenta</a>",
          "description": "Simulations of large-scale plasma systems are typically based on a fluid\napproximation approach. These models construct a moment-based system of\nequations that approximate the particle-based physics as a fluid, but as a\nresult lack the small-scale physical processes available to fully kinetic\nmodels. Traditionally, empirical closure relations are used to close the\nmoment-based system of equations, which typically approximate the pressure\ntensor or heat flux. The more accurate the closure relation, the stronger the\nsimulation approaches kinetic-based results. In this paper, new closure terms\nare constructed using machine learning techniques. Two different machine\nlearning models, a multi-layer perceptron and a gradient boosting regressor,\nsynthesize a local closure relation for the pressure tensor and heat flux\nvector from fully kinetic simulations of a 2D magnetic reconnection problem.\nThe models are compared to an existing closure relation for the pressure\ntensor, and the applicability of the models is discussed. The initial results\nshow that the models can capture the diagonal components of the pressure tensor\naccurately, and show promising results for the heat flux, opening the way for\nnew experiments in multi-scale modeling. We find that the sampling of the\npoints used to train both models play a capital role in their accuracy.",
          "link": "http://arxiv.org/abs/2110.09916",
          "publishedOn": "2022-03-26T00:46:07.679Z",
          "wordCount": 695,
          "title": "Identification of high order closure terms from fully kinetic simulations using machine learning. (arXiv:2110.09916v2 [physics.plasm-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shome_A/0/1/0/all/0/1\">Arumoy Shome</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_L/0/1/0/all/0/1\">Luis Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deursen_A/0/1/0/all/0/1\">Arie van Deursen</a>",
          "description": "The adoption of Artificial Intelligence (AI) in high-stakes domains such as\nhealthcare, wildlife preservation, autonomous driving and criminal justice\nsystem calls for a data-centric approach to AI. Data scientists spend the\nmajority of their time studying and wrangling the data, yet tools to aid them\nwith data analysis are lacking. This study identifies the recurrent data\nquality issues in public datasets. Analogous to code smells, we introduce a\nnovel catalogue of data smells that can be used to indicate early signs of\nproblems or technical debt in machine learning systems. To understand the\nprevalence of data quality issues in datasets, we analyse 25 public datasets\nand identify 14 data smells.",
          "link": "http://arxiv.org/abs/2203.08007",
          "publishedOn": "2022-03-26T00:46:07.673Z",
          "wordCount": 557,
          "title": "Data Smells in Public Datasets. (arXiv:2203.08007v2 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caldarola_D/0/1/0/all/0/1\">Debora Caldarola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caputo_B/0/1/0/all/0/1\">Barbara Caputo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciccone_M/0/1/0/all/0/1\">Marco Ciccone</a>",
          "description": "Models trained in federated settings often suffer from degraded performances\nand fail at generalizing, especially when facing heterogeneous scenarios. In\nthis work, we investigate such behavior through the lens of geometry of the\nloss and Hessian eigenspectrum, linking the model's lack of generalization\ncapacity to the sharpness of the solution. Motivated by prior studies\nconnecting the sharpness of the loss surface and the generalization gap, we\nshow that i) training clients locally with Sharpness-Aware Minimization (SAM)\nor its adaptive version (ASAM) and ii) averaging stochastic weights (SWA) on\nthe server-side can substantially improve generalization in Federated Learning\nand help bridging the gap with centralized models. By seeking parameters in\nneighborhoods having uniform low loss, the model converges towards flatter\nminima and its generalization significantly improves in both homogeneous and\nheterogeneous scenarios. Empirical results demonstrate the effectiveness of\nthose optimizers across a variety of benchmark vision datasets (e.g.\nCIFAR10/100, Landmarks-User-160k, IDDA) and tasks (large scale classification,\nsemantic segmentation, domain generalization).",
          "link": "http://arxiv.org/abs/2203.11834",
          "publishedOn": "2022-03-26T00:46:07.667Z",
          "wordCount": 624,
          "title": "Improving Generalization in Federated Learning by Seeking Flat Minima. (arXiv:2203.11834v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12865",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+K_K/0/1/0/all/0/1\">Karthikeyan K</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatt_S/0/1/0/all/0/1\">Shaily Bhatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1\">Pankaj Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aditya_S/0/1/0/all/0/1\">Somak Aditya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dandapat_S/0/1/0/all/0/1\">Sandipan Dandapat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitaram_S/0/1/0/all/0/1\">Sunayana Sitaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_M/0/1/0/all/0/1\">Monojit Choudhary</a>",
          "description": "The recently proposed CheckList (Riberio et al,. 2020) approach to evaluation\nof NLP systems has revealed high failure rates for basic capabilities for\nmultiple state-of-the-art and commercial models. However, the CheckList\ncreation process is manual which creates a bottleneck towards creation of\nmultilingual CheckLists catering 100s of languages. In this work, we explore\nmultiple approaches to generate and evaluate the quality of Multilingual\nCheckList. We device an algorithm -- Automated Multilingual Checklist\nGeneration (AMCG) for automatically transferring a CheckList from a source to a\ntarget language that relies on a reasonable machine translation system. We then\ncompare the CheckList generated by AMCG with CheckLists generated with\ndifferent levels of human intervention. Through in-depth crosslingual\nexperiments between English and Hindi, and broad multilingual experiments\nspanning 11 languages, we show that the automatic approach can provide accurate\nestimates of failure rates of a model across capabilities, as would a\nhuman-verified CheckList, and better than CheckLists generated by humans from\nscratch.",
          "link": "http://arxiv.org/abs/2203.12865",
          "publishedOn": "2022-03-26T00:46:07.661Z",
          "wordCount": 597,
          "title": "Multilingual CheckList: Generation and Evaluation. (arXiv:2203.12865v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hatamizadeh_A/0/1/0/all/0/1\">Ali Hatamizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongxu Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_H/0/1/0/all/0/1\">Holger Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1\">Jan Kautz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Daguang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molchanov_P/0/1/0/all/0/1\">Pavlo Molchanov</a>",
          "description": "In this work we demonstrate the vulnerability of vision transformers (ViTs)\nto gradient-based inversion attacks. During this attack, the original data\nbatch is reconstructed given model weights and the corresponding gradients. We\nintroduce a method, named GradViT, that optimizes random noise into naturally\nlooking images via an iterative process. The optimization objective consists of\n(i) a loss on matching the gradients, (ii) image prior in the form of distance\nto batch-normalization statistics of a pretrained CNN model, and (iii) a total\nvariation regularization on patches to guide correct recovery locations. We\npropose a unique loss scheduling function to overcome local minima during\noptimization. We evaluate GadViT on ImageNet1K and MS-Celeb-1M datasets, and\nobserve unprecedentedly high fidelity and closeness to the original (hidden)\ndata. During the analysis we find that vision transformers are significantly\nmore vulnerable than previously studied CNNs due to the presence of the\nattention mechanism. Our method demonstrates new state-of-the-art results for\ngradient inversion in both qualitative and quantitative metrics. Project page\nat https://gradvit.github.io/.",
          "link": "http://arxiv.org/abs/2203.11894",
          "publishedOn": "2022-03-26T00:46:07.641Z",
          "wordCount": 649,
          "title": "GradViT: Gradient Inversion of Vision Transformers. (arXiv:2203.11894v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kluvanec_D/0/1/0/all/0/1\">Daniel Kluvanec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_T/0/1/0/all/0/1\">Thomas B. Phillips</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCaffrey_K/0/1/0/all/0/1\">Kenneth J. W. McCaffrey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moubayed_N/0/1/0/all/0/1\">Noura Al Moubayed</a>",
          "description": "A difficult step in the process of karyotyping is segmenting chromosomes that\ntouch or overlap. In an attempt to automate the process, previous studies\nturned to Deep Learning methods, with some formulating the task as a semantic\nsegmentation problem. These models treat separate chromosome instances as\nsemantic classes, which we show to be problematic, since it is uncertain which\nchromosome should be classed as #1 and #2. Assigning class labels based on\ncomparison rules, such as the shorter/longer chromosome alleviates, but does\nnot fully resolve the issue. Instead, we separate the chromosome instances in a\nsecond stage, predicting the orientation of the chromosomes by the model and\nuse it as one of the key distinguishing factors of the chromosomes. We\ndemonstrate this method to be effective. Furthermore, we introduce a novel\nDouble-Angle representation that a neural network can use to predict the\norientation. The representation maps any direction and its reverse to the same\npoint. Lastly, we present a new expanded synthetic dataset, which is based on\nPommier's dataset, but addresses its issues with insufficient separation\nbetween its training and testing sets.",
          "link": "http://arxiv.org/abs/2203.13004",
          "publishedOn": "2022-03-26T00:46:07.630Z",
          "wordCount": 628,
          "title": "Using Orientation to Distinguish Overlapping Chromosomes. (arXiv:2203.13004v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Litake_O/0/1/0/all/0/1\">Onkar Litake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabane_M/0/1/0/all/0/1\">Maithili Sabane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_P/0/1/0/all/0/1\">Parth Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranade_A/0/1/0/all/0/1\">Aparna Ranade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>",
          "description": "Named entity recognition (NER) is the process of recognising and classifying\nimportant information (entities) in text. Proper nouns, such as a person's\nname, an organization's name, or a location's name, are examples of entities.\nThe NER is one of the important modules in applications like human resources,\ncustomer support, search engines, content classification, and academia. In this\nwork, we consider NER for low-resource Indian languages like Hindi and Marathi.\nThe transformer-based models have been widely used for NER tasks. We consider\ndifferent variations of BERT like base-BERT, RoBERTa, and AlBERT and benchmark\nthem on publicly available Hindi and Marathi NER datasets. We provide an\nexhaustive comparison of different monolingual and multilingual\ntransformer-based models and establish simple baselines currently missing in\nthe literature. We show that the monolingual MahaRoBERTa model performs the\nbest for Marathi NER whereas the multilingual XLM-RoBERTa performs the best for\nHindi NER. We also perform cross-language evaluation and present mixed\nobservations.",
          "link": "http://arxiv.org/abs/2203.12907",
          "publishedOn": "2022-03-26T00:46:07.599Z",
          "wordCount": 612,
          "title": "Mono vs Multilingual BERT: A Case Study in Hindi and Marathi Named Entity Recognition. (arXiv:2203.12907v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lorenzana_M/0/1/0/all/0/1\">Marlon Bran Lorenzana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Engstrom_C/0/1/0/all/0/1\">Craig Engstrom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_S/0/1/0/all/0/1\">Shekhar S. Chandra</a>",
          "description": "Convolutional neural networks (CNN) have demonstrated outstanding Compressed\nSensing (CS) performance compared to traditional, hand-crafted methods.\nHowever, they are broadly limited in terms of generalisability, inductive bias\nand difficulty to model long distance relationships. Transformer neural\nnetworks (TNN) overcome such issues by implementing an attention mechanism\ndesigned to capture dependencies between inputs. However, high-resolution tasks\ntypically require vision Transformers (ViT) to decompose an image into\npatch-based tokens, limiting inputs to inherently local contexts. We propose a\nnovel image decomposition that naturally embeds images into low-resolution\ninputs. These Kaleidoscope tokens (KD) provide a mechanism for global\nattention, at the same computational cost as a patch-based approach. To\nshowcase this development, we replace CNN components in a well-known CS-MRI\nneural network with TNN blocks and demonstrate the improvements afforded by KD.\nWe also propose an ensemble of image tokens, which enhance overall image\nquality and reduces model size. Supplementary material is available:\nhttps://github.com/uqmarlonbran/TCS.git}{https://github.com/uqmarlonbran/TCS.git",
          "link": "http://arxiv.org/abs/2203.12861",
          "publishedOn": "2022-03-26T00:46:07.593Z",
          "wordCount": 612,
          "title": "Transformer Compressed Sensing via Global Image Tokens. (arXiv:2203.12861v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12948",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Fabiani_F/0/1/0/all/0/1\">Filippo Fabiani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Simonetto_A/0/1/0/all/0/1\">Andrea Simonetto</a>, <a href=\"http://arxiv.org/find/math/1/au:+Goulart_P/0/1/0/all/0/1\">Paul J. Goulart</a>",
          "description": "We investigate both stationary and time-varying, nonmonotone generalized Nash\nequilibrium problems that exhibit symmetric interactions among the agents,\nwhich are known to be potential. As may happen in practical cases, however, we\nenvision a scenario in which the formal expression of the underlying potential\nfunction is not available, and we design a semi-decentralized Nash equilibrium\nseeking algorithm. In the proposed two-layer scheme, a coordinator iteratively\nintegrates the (possibly noisy and sporadic) agents' feedback to learn the\npseudo-gradients of the agents, and then design personalized incentives for\nthem. On their side, the agents receive those personalized incentives, compute\na solution to an extended game, and then return feedback measurements to the\ncoordinator. In the stationary setting, our algorithm returns a Nash\nequilibrium in case the coordinator is endowed with standard learning policies,\nwhile it returns a Nash equilibrium up to a constant, yet adjustable, error in\nthe time-varying case. As a motivating application, we consider the ridehailing\nservice provided by several companies with mobility as a service orchestration,\nnecessary to both handle competition among firms and avoid traffic congestion,\nwhich is also adopted to run numerical experiments verifying our results.",
          "link": "http://arxiv.org/abs/2203.12948",
          "publishedOn": "2022-03-26T00:46:07.573Z",
          "wordCount": 653,
          "title": "Personalized incentives as feedback design in generalized Nash equilibrium problems. (arXiv:2203.12948v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13225",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Carmon_Y/0/1/0/all/0/1\">Yair Carmon</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hausler_D/0/1/0/all/0/1\">Danielle Hausler</a>",
          "description": "We develop and analyze algorithms for distributionally robust optimization\n(DRO) of convex losses. In particular, we consider group-structured and bounded\n$f$-divergence uncertainty sets. Our approach relies on an accelerated method\nthat queries a ball optimization oracle, i.e., a subroutine that minimizes the\nobjective within a small ball around the query point. Our main contribution is\nefficient implementations of this oracle for DRO objectives. For DRO with $N$\nnon-smooth loss functions, the resulting algorithms find an $\\epsilon$-accurate\nsolution with $\\widetilde{O}\\left(N\\epsilon^{-2/3} + \\epsilon^{-2}\\right)$\nfirst-order oracle queries to individual loss functions. Compared to existing\nalgorithms for this problem, we improve complexity by a factor of up to\n$\\epsilon^{-4/3}$.",
          "link": "http://arxiv.org/abs/2203.13225",
          "publishedOn": "2022-03-26T00:46:07.561Z",
          "wordCount": 544,
          "title": "Distributionally Robust Optimization via Ball Oracle Acceleration. (arXiv:2203.13225v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.11906",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Goto_K/0/1/0/all/0/1\">Kiichi Goto</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Suehara_T/0/1/0/all/0/1\">Taikan Suehara</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yoshioka_T/0/1/0/all/0/1\">Tamaki Yoshioka</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kurata_M/0/1/0/all/0/1\">Masakazu Kurata</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nagahara_H/0/1/0/all/0/1\">Hajime Nagahara</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nakashima_Y/0/1/0/all/0/1\">Yuta Nakashima</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Takemura_N/0/1/0/all/0/1\">Noriko Takemura</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Iwasaki_M/0/1/0/all/0/1\">Masako Iwasaki</a>",
          "description": "Deep learning is a rapidly-evolving technology with possibility to\nsignificantly improve physics reach of collider experiments. In this study we\ndeveloped a novel algorithm of vertex finding for future lepton colliders such\nas the International Linear Collider. We deploy two networks; one is simple\nfully-connected layers to look for vertex seeds from track pairs, and the other\nis a customized Recurrent Neural Network with an attention mechanism and an\nencoder-decoder structure to associate tracks to the vertex seeds. The\nperformance of the vertex finder is compared with the standard ILC\nreconstruction algorithm.",
          "link": "http://arxiv.org/abs/2101.11906",
          "publishedOn": "2022-03-26T00:46:07.555Z",
          "wordCount": null,
          "title": "Development of a Vertex Finding Algorithm using Recurrent Neural Network. (arXiv:2101.11906v4 [physics.data-an] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.00798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McTavish_H/0/1/0/all/0/1\">Hayden McTavish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_C/0/1/0/all/0/1\">Chudi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achermann_R/0/1/0/all/0/1\">Reto Achermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karimalis_I/0/1/0/all/0/1\">Ilias Karimalis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jacques Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudin_C/0/1/0/all/0/1\">Cynthia Rudin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seltzer_M/0/1/0/all/0/1\">Margo Seltzer</a>",
          "description": "Sparse decision tree optimization has been one of the most fundamental\nproblems in AI since its inception and is a challenge at the core of\ninterpretable machine learning. Sparse decision tree optimization is\ncomputationally hard, and despite steady effort since the 1960's, breakthroughs\nhave only been made on the problem within the past few years, primarily on the\nproblem of finding optimal sparse decision trees. However, current\nstate-of-the-art algorithms often require impractical amounts of computation\ntime and memory to find optimal or near-optimal trees for some real-world\ndatasets, particularly those having several continuous-valued features. Given\nthat the search spaces of these decision tree optimization problems are\nmassive, can we practically hope to find a sparse decision tree that competes\nin accuracy with a black box machine learning model? We address this problem\nvia smart guessing strategies that can be applied to any optimal\nbranch-and-bound-based decision tree algorithm. We show that by using these\nguesses, we can reduce the run time by multiple orders of magnitude, while\nproviding bounds on how far the resulting trees can deviate from the black\nbox's accuracy and expressive power. Our approach enables guesses about how to\nbin continuous features, the size of the tree, and lower bounds on the error\nfor the optimal decision tree. Our experiments show that in many cases we can\nrapidly construct sparse decision trees that match the accuracy of black box\nmodels. To summarize: when you are having trouble optimizing, just guess.",
          "link": "http://arxiv.org/abs/2112.00798",
          "publishedOn": "2022-03-26T00:46:07.553Z",
          "wordCount": 727,
          "title": "Fast Sparse Decision Tree Optimization via Reference Ensembles. (arXiv:2112.00798v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13131",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gafni_O/0/1/0/all/0/1\">Oran Gafni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polyak_A/0/1/0/all/0/1\">Adam Polyak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashual_O/0/1/0/all/0/1\">Oron Ashual</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheynin_S/0/1/0/all/0/1\">Shelly Sheynin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1\">Devi Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taigman_Y/0/1/0/all/0/1\">Yaniv Taigman</a>",
          "description": "Recent text-to-image generation methods provide a simple yet exciting\nconversion capability between text and image domains. While these methods have\nincrementally improved the generated image fidelity and text relevancy, several\npivotal gaps remain unanswered, limiting applicability and quality. We propose\na novel text-to-image method that addresses these gaps by (i) enabling a simple\ncontrol mechanism complementary to text in the form of a scene, (ii)\nintroducing elements that substantially improve the tokenization process by\nemploying domain-specific knowledge over key image regions (faces and salient\nobjects), and (iii) adapting classifier-free guidance for the transformer use\ncase. Our model achieves state-of-the-art FID and human evaluation results,\nunlocking the ability to generate high fidelity images in a resolution of\n512x512 pixels, significantly improving visual quality. Through scene\ncontrollability, we introduce several new capabilities: (i) Scene editing, (ii)\ntext editing with anchor scenes, (iii) overcoming out-of-distribution text\nprompts, and (iv) story illustration generation, as demonstrated in the story\nwe wrote.",
          "link": "http://arxiv.org/abs/2203.13131",
          "publishedOn": "2022-03-26T00:46:07.535Z",
          "wordCount": null,
          "title": "Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors. (arXiv:2203.13131v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.13822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Minxue Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_X/0/1/0/all/0/1\">Xuefei Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yitu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jingwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiran Chen</a>",
          "description": "Client-wise data heterogeneity is one of the major issues that hinder\neffective training in federated learning (FL). Since the data distribution on\neach client may vary dramatically, the client selection strategy can\nsignificantly influence the convergence rate of the FL process. Active client\nselection strategies are popularly proposed in recent studies. However, they\nneglect the loss correlations between the clients and achieve only marginal\nimprovement compared to the uniform selection strategy. In this work, we\npropose FedCor -- an FL framework built on a correlation-based client selection\nstrategy, to boost the convergence rate of FL. Specifically, we first model the\nloss correlations between the clients with a Gaussian Process (GP). Based on\nthe GP model, we derive a client selection strategy with a significant\nreduction of expected global loss in each round. Besides, we develop an\nefficient GP training method with a low communication overhead in the FL\nscenario by utilizing the covariance stationarity. Our experimental results\nshow that compared to the state-of-the-art method, FedCorr can improve the\nconvergence rates by $34\\%\\sim 99\\%$ and $26\\%\\sim 51\\%$ on FMNIST and\nCIFAR-10, respectively.",
          "link": "http://arxiv.org/abs/2103.13822",
          "publishedOn": "2022-03-26T00:46:07.532Z",
          "wordCount": null,
          "title": "FedCor: Correlation-Based Active Client Selection Strategy for Heterogeneous Federated Learning. (arXiv:2103.13822v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galanti_T/0/1/0/all/0/1\">Tomer Galanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galanti_L/0/1/0/all/0/1\">Liane Galanti</a>",
          "description": "We study the implicit bias of gradient based training methods to favor\nlow-depth solutions when training deep neural networks. Recent results in the\nliterature suggest that penultimate layer representations learned by a\nclassifier over multiple classes exhibit a clustering property, called neural\ncollapse. We demonstrate empirically that the neural collapse property extends\nbeyond the penultimate layer and tends to emerge in intermediate layers as\nwell. In this regards, we hypothesize that gradient based methods are\nimplicitly biased towards selecting neural networks of minimal depth for\nachieving this clustering property.",
          "link": "http://arxiv.org/abs/2202.09028",
          "publishedOn": "2022-03-26T00:46:07.531Z",
          "wordCount": null,
          "title": "On the Implicit Bias Towards Minimal Depth of Deep Neural Networks. (arXiv:2202.09028v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_G/0/1/0/all/0/1\">Guibao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jianye Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wulong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hongzhong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yibo Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guangyong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1\">Pheng Ann Heng</a>",
          "description": "Precise congestion prediction from a placement solution plays a crucial role\nin circuit placement. This work proposes the lattice hypergraph (LH-graph), a\nnovel graph formulation for circuits, which preserves netlist data during the\nwhole learning process, and enables the congestion information propagated\ngeometrically and topologically. Based on the formulation, we further developed\na heterogeneous graph neural network architecture LHNN, jointing the routing\ndemand regression to support the congestion spot classification. LHNN\nconstantly achieves more than 35% improvements compared with U-nets and Pix2Pix\non the F1 score. We expect our work shall highlight essential procedures using\nmachine learning for congestion prediction.",
          "link": "http://arxiv.org/abs/2203.12831",
          "publishedOn": "2022-03-26T00:46:07.530Z",
          "wordCount": null,
          "title": "LHNN: Lattice Hypergraph Neural Network for VLSI Congestion Prediction. (arXiv:2203.12831v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.06476",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Behanova_A/0/1/0/all/0/1\">Andrea Behanova</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abdollahzadeh_A/0/1/0/all/0/1\">Ali Abdollahzadeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Belevich_I/0/1/0/all/0/1\">Ilya Belevich</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jokitalo_E/0/1/0/all/0/1\">Eija Jokitalo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sierra_A/0/1/0/all/0/1\">Alejandra Sierra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tohka_J/0/1/0/all/0/1\">Jussi Tohka</a>",
          "description": "Background and Objective: Advances in electron microscopy (EM) now allow\nthree-dimensional (3D) imaging of hundreds of micrometers of tissue with\nnanometer-scale resolution, providing new opportunities to study the\nultrastructure of the brain. In this work, we introduce a freely available\nMatlab-based gACSON software for visualization, segmentation, assessment, and\nmorphology analysis of myelinated axons in 3D-EM volumes of brain tissue\nsamples. Methods: The software is equipped with a graphical user interface\n(GUI). It automatically segments the intra-axonal space of myelinated axons and\ntheir corresponding myelin sheaths and allows manual segmentation,\nproofreading, and interactive correction of the segmented components. gACSON\nanalyzes the morphology of myelinated axons, such as axonal diameter, axonal\neccentricity, myelin thickness, or g-ratio. Results: We illustrate the use of\nthe software by segmenting and analyzing myelinated axons in six 3D-EM volumes\nof rat somatosensory cortex after sham surgery or traumatic brain injury (TBI).\nOur results suggest that the equivalent diameter of myelinated axons in\nsomatosensory cortex was decreased in TBI animals five months after the injury.\nConclusions: Our results indicate that gACSON is a valuable tool for\nvisualization, segmentation, assessment, and morphology analysis of myelinated\naxons in 3D-EM volumes. It is freely available at\nhttps://github.com/AndreaBehan/g-ACSON under the MIT license.",
          "link": "http://arxiv.org/abs/2112.06476",
          "publishedOn": "2022-03-26T00:46:07.528Z",
          "wordCount": null,
          "title": "gACSON software for automated segmentation and morphology analyses of myelinated axons in 3D electron microscopy. (arXiv:2112.06476v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pabian_M/0/1/0/all/0/1\">Mateusz Pabian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rzepka_D/0/1/0/all/0/1\">Dominik Rzepka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pawlak_M/0/1/0/all/0/1\">Miros&#x142;aw Pawlak</a>",
          "description": "This study adapts the highly-versatile siamese neural network model to the\nevent data domain. We introduce a supervised training framework for optimizing\nEarth's Mover Distance (EMD) between spike trains with spiking neural networks\n(SNN). We train this model on images of the MNIST dataset converted into\nspiking domain with novel conversion schemes. The quality of the siamese\nembeddings of input images was evaluated by measuring the classifier\nperformance for different dataset coding types. The models achieved performance\nsimilar to existing SNN-based approaches (F1-score of up to 0.9386) while using\nonly about 15% of hidden layer neurons to classify each example. Furthermore,\nmodels which did not employ a sparse neural code were about 45% slower than\ntheir sparse counterparts. These properties make the model suitable for low\nenergy consumption and low prediction latency applications.",
          "link": "http://arxiv.org/abs/2203.13207",
          "publishedOn": "2022-03-26T00:46:07.527Z",
          "wordCount": null,
          "title": "Supervised Training of Siamese Spiking Neural Networks with Earth's Mover Distance. (arXiv:2203.13207v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.11099",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Tirelli_A/0/1/0/all/0/1\">Andrea Tirelli</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Tenti_G/0/1/0/all/0/1\">Giacomo Tenti</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Nakano_K/0/1/0/all/0/1\">Kousuke Nakano</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sorella_S/0/1/0/all/0/1\">Sandro Sorella</a>",
          "description": "We have developed a technique combining the accuracy of quantum Monte Carlo\nin describing the electron correlation with the efficiency of a Machine\nLearning Potential (MLP). We use kernel regression in combination with SOAP\n(Smooth Overlap of Atomic Position) features, implemented here in a very\nefficient way. The key ingredients are: i) a sparsification technique, based on\nfarthest point sampling, ensuring generality and transferability of our MLPs\nand ii) the so called $\\Delta$-learning, allowing a small training data set, a\nfundamental property for highly accurate but computationally demanding\ncalculations, such as the ones based on quantum Monte Carlo. As the first\napplication we present a benchmark study of the liquid-liquid transition of\nhigh-pressure hydrogen and show the quality of our MLP, by emphasizing the\nimportance of high accuracy for this very debated subject, where experiments\nare difficult in the lab, and theory is still far from being conclusive.",
          "link": "http://arxiv.org/abs/2112.11099",
          "publishedOn": "2022-03-26T00:46:07.525Z",
          "wordCount": null,
          "title": "High pressure hydrogen by machine learning and quantum Monte Carlo. (arXiv:2112.11099v2 [cond-mat.str-el] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13154",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kehrenberg_T/0/1/0/all/0/1\">Thomas Kehrenberg</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bartlett_M/0/1/0/all/0/1\">Myles Bartlett</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sharmanska_V/0/1/0/all/0/1\">Viktoriia Sharmanska</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Quadrianto_N/0/1/0/all/0/1\">Novi Quadrianto</a>",
          "description": "When trained on diverse labeled data, machine learning models have proven\nthemselves to be a powerful tool in all facets of society. However, due to\nbudget limitations, deliberate or non-deliberate censorship, and other problems\nduring data collection and curation, the labeled training set might exhibit a\nsystematic shortage of data for certain groups. We investigate a scenario in\nwhich the absence of certain data is linked to the second level of a two-level\nhierarchy in the data. Inspired by the idea of protected groups from\nalgorithmic fairness, we refer to the partitions carved by this second level as\n\"subgroups\"; we refer to combinations of subgroups and classes, or leaves of\nthe hierarchy, as \"sources\". To characterize the problem, we introduce the\nconcept of classes with incomplete subgroup support. The representational bias\nin the training set can give rise to spurious correlations between the classes\nand the subgroups which render standard classification models ungeneralizable\nto unseen sources. To overcome this bias, we make use of an additional, diverse\nbut unlabeled dataset, called the \"deployment set\", to learn a representation\nthat is invariant to subgroup. This is done by adversarially matching the\nsupport of the training and deployment sets in representation space. In order\nto learn the desired invariance, it is paramount that the sets of samples\nobserved by the discriminator are balanced by class; this is easily achieved\nfor the training set, but requires using semi-supervised clustering for the\ndeployment set. We demonstrate the effectiveness of our method with experiments\non several datasets and variants of the problem.",
          "link": "http://arxiv.org/abs/2203.13154",
          "publishedOn": "2022-03-26T00:46:07.524Z",
          "wordCount": null,
          "title": "Addressing Missing Sources with Adversarial Support-Matching. (arXiv:2203.13154v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.04386",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biswas_K/0/1/0/all/0/1\">Koushik Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sandeep Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1\">Shilpak Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1\">Ashish Kumar Pandey</a>",
          "description": "An activation function is a crucial component of a neural network that\nintroduces non-linearity in the network. The state-of-the-art performance of a\nneural network depends also on the perfect choice of an activation function. We\npropose two novel non-monotonic smooth trainable activation functions, called\nErfAct and Pserf. Experiments suggest that the proposed functions improve the\nnetwork performance significantly compared to the widely used activations like\nReLU, Swish, and Mish. Replacing ReLU by ErfAct and Pserf, we have 5.68% and\n5.42% improvement for top-1 accuracy on Shufflenet V2 (2.0x) network in\nCIFAR100 dataset, 2.11% and 1.96% improvement for top-1 accuracy on Shufflenet\nV2 (2.0x) network in CIFAR10 dataset, 1.0%, and 1.0% improvement on mean\naverage precision (mAP) on SSD300 model in Pascal VOC dataset.",
          "link": "http://arxiv.org/abs/2109.04386",
          "publishedOn": "2022-03-26T00:46:07.522Z",
          "wordCount": 622,
          "title": "ErfAct and Pserf: Non-monotonic Smooth Trainable Activation Functions. (arXiv:2109.04386v4 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.13207",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Heese_R/0/1/0/all/0/1\">Raoul Heese</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Bickert_P/0/1/0/all/0/1\">Patricia Bickert</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Niederle_A/0/1/0/all/0/1\">Astrid Elisa Niederle</a>",
          "description": "We propose a quantum representation of binary classification trees with\nbinary features based on a probabilistic approach. By using the quantum\ncomputer as a processor for probability distributions, a probabilistic\ntraversal of the decision tree can be realized via measurements of a quantum\ncircuit. We describe how tree inductions and the prediction of class labels of\nquery data can be integrated into this framework. An on-demand sampling method\nenables predictions with a constant number of classical memory slots,\nindependent of the tree depth. We experimentally study our approach using both\na quantum computing simulator and actual IBM quantum hardware. To our\nknowledge, this is the first realization of a decision tree classifier on a\nquantum device.",
          "link": "http://arxiv.org/abs/2108.13207",
          "publishedOn": "2022-03-26T00:46:07.514Z",
          "wordCount": null,
          "title": "Representation of binary classification trees with binary features by quantum circuits. (arXiv:2108.13207v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Urteaga_I/0/1/0/all/0/1\">I&#xf1;igo Urteaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Draidia_M/0/1/0/all/0/1\">Moulay-Za&#xef;dane Dra&#xef;dia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lancewicki_T/0/1/0/all/0/1\">Tomer Lancewicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_S/0/1/0/all/0/1\">Shahram Khadivi</a>",
          "description": "Transformer-based language models (TLMs) provide state-of-the-art performance\nin many modern natural language processing applications. TLM training is\nconducted in two phases. First, the model is pre-trained over large volumes of\ntext to minimize a generic objective function, such as the Masked Language\nModel (MLM). Second, the model is fine-tuned in specific downstream tasks.\nPre-training requires large volumes of data and high computational resources,\nwhile introducing many still unresolved design choices. For instance, selecting\nhyperparameters for language model pre-training is often carried out based on\nheuristics or grid-based searches. In this work, we propose a multi-armed\nbandit-based online optimization framework for the sequential selection of\npre-training hyperparameters to optimize language model performance. We pose\nthe pre-training procedure as a sequential decision-making task, where at each\npre-training step, an agent must determine what hyperparameters to use towards\noptimizing the pre-training objective. We propose a Thompson sampling bandit\nalgorithm, based on a surrogate Gaussian process reward model of the MLM\npre-training objective, for its sequential minimization. We empirically show\nhow the proposed Gaussian process based Thompson sampling pre-trains robust and\nwell-performing language models. Namely, by sequentially selecting masking\nhyperparameters of the TLM, we achieve satisfactory performance in less epochs,\nnot only in terms of the pre-training MLM objective, but in diverse downstream\nfine-tuning tasks. The proposed bandit-based technique provides an automated\nhyperparameter selection method for pre-training TLMs of interest to\npractitioners. In addition, our results indicate that, instead of MLM\npre-training with fixed masking probabilities, sequentially adapting the\nmasking hyperparameters improves both pre-training loss and downstream task\nmetrics.",
          "link": "http://arxiv.org/abs/2203.13151",
          "publishedOn": "2022-03-26T00:46:07.513Z",
          "wordCount": null,
          "title": "Multi-armed bandits for online optimization of language model pre-training: the use case of dynamic masking. (arXiv:2203.13151v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11528",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_R/0/1/0/all/0/1\">Ruoyu Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yi_M/0/1/0/all/0/1\">Mingyang Yi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1\">Zhitang Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_S/0/1/0/all/0/1\">Shengyu Zhu</a>",
          "description": "In real-world applications, it is important and desirable to learn a model\nthat performs well on out-of-distribution (OOD) data. Recently, causality has\nbecome a powerful tool to tackle the OOD generalization problem, with the idea\nresting on the causal mechanism that is invariant across domains of interest.\nTo leverage the generally unknown causal mechanism, existing works assume a\nlinear form of causal feature or require sufficiently many and diverse training\ndomains, which are usually restrictive in practice. In this work, we obviate\nthese assumptions and tackle the OOD problem without explicitly recovering the\ncausal feature. Our approach is based on transformations that modify the\nnon-causal feature but leave the causal part unchanged, which can be either\nobtained from prior knowledge or learned from the training data in the\nmulti-domain scenario. Under the setting of invariant causal mechanism, we\ntheoretically show that if all such transformations are available, then we can\nlearn a minimax optimal model across the domains using only single domain data.\nNoticing that knowing a complete set of these causal invariant transformations\nmay be impractical, we further show that it suffices to know only a subset of\nthese transformations. Based on the theoretical findings, a regularized\ntraining procedure is proposed to improve the OOD generalization capability.\nExtensive experimental results on both synthetic and real datasets verify the\neffectiveness of the proposed algorithm, even with only a few causal invariant\ntransformations.",
          "link": "http://arxiv.org/abs/2203.11528",
          "publishedOn": "2022-03-26T00:46:07.512Z",
          "wordCount": null,
          "title": "Out-of-distribution Generalization with Causal Invariant Transformations. (arXiv:2203.11528v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.08781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Birrell_J/0/1/0/all/0/1\">Jeremiah Birrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katsoulakis_M/0/1/0/all/0/1\">Markos A. Katsoulakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pantazis_Y/0/1/0/all/0/1\">Yannis Pantazis</a>",
          "description": "Variational representations of divergences and distances between\nhigh-dimensional probability distributions offer significant theoretical\ninsights and practical advantages in numerous research areas. Recently, they\nhave gained popularity in machine learning as a tractable and scalable approach\nfor training probabilistic models and for statistically differentiating between\ndata distributions. Their advantages include: 1) They can be estimated from\ndata as statistical averages. 2) Such representations can leverage the ability\nof neural networks to efficiently approximate optimal solutions in function\nspaces. However, a systematic and practical approach to improving the tightness\nof such variational formulas, and accordingly accelerate statistical learning\nand estimation from data, is currently lacking. Here we develop such a\nmethodology for building new, tighter variational representations of\ndivergences. Our approach relies on improved objective functionals constructed\nvia an auxiliary optimization problem. Furthermore, the calculation of the\nfunctional Hessian of objective functionals unveils the local curvature\ndifferences around the common optimal variational solution; this quantifies and\norders the tightness gains between different variational representations.\nFinally, numerical simulations utilizing neural network optimization\ndemonstrate that tighter representations can result in significantly faster\nlearning and more accurate estimation of divergences in both synthetic and real\ndatasets (of more than 1000 dimensions), often accelerated by nearly an order\nof magnitude.",
          "link": "http://arxiv.org/abs/2006.08781",
          "publishedOn": "2022-03-26T00:46:07.508Z",
          "wordCount": null,
          "title": "Optimizing Variational Representations of Divergences and Accelerating their Statistical Estimation. (arXiv:2006.08781v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.08393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mossel_E/0/1/0/all/0/1\">Elchanan Mossel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandon_C/0/1/0/all/0/1\">Colin Sandon</a>",
          "description": "In this work, we study the computational complexity of determining whether a\nmachine learning model that perfectly fits the training data will generalizes\nto unseen data. In particular, we study the power of a malicious agent whose\ngoal is to construct a model g that fits its training data and nothing else,\nbut is indistinguishable from an accurate model f. We say that g strongly\nspoofs f if no polynomial-time algorithm can tell them apart. If instead we\nrestrict to algorithms that run in $n^c$ time for some fixed $c$, we say that g\nc-weakly spoofs f. Our main results are\n\n1. Under cryptographic assumptions, strong spoofing is possible and\n\n2. For any c> 0, c-weak spoofing is possible unconditionally\n\nWhile the assumption of a malicious agent is an extreme scenario (hopefully\ncompanies training large models are not malicious), we believe that it sheds\nlight on the inherent difficulties of blindly trusting large proprietary models\nor data.",
          "link": "http://arxiv.org/abs/2106.08393",
          "publishedOn": "2022-03-26T00:46:07.508Z",
          "wordCount": null,
          "title": "Spoofing Generalization: When Can't You Trust Proprietary Models?. (arXiv:2106.08393v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arunachalam_S/0/1/0/all/0/1\">Sridhar Pandian Arunachalam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1\">Sneha Silwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_B/0/1/0/all/0/1\">Ben Evans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinto_L/0/1/0/all/0/1\">Lerrel Pinto</a>",
          "description": "Optimizing behaviors for dexterous manipulation has been a longstanding\nchallenge in robotics, with a variety of methods from model-based control to\nmodel-free reinforcement learning having been previously explored in\nliterature. Perhaps one of the most powerful techniques to learn complex\nmanipulation strategies is imitation learning. However, collecting and learning\nfrom demonstrations in dexterous manipulation is quite challenging. The\ncomplex, high-dimensional action-space involved with multi-finger control often\nleads to poor sample efficiency of learning-based methods. In this work, we\npropose 'Dexterous Imitation Made Easy' (DIME) a new imitation learning\nframework for dexterous manipulation. DIME only requires a single RGB camera to\nobserve a human operator and teleoperate our robotic hand. Once demonstrations\nare collected, DIME employs standard imitation learning methods to train\ndexterous manipulation policies. On both simulation and real robot benchmarks\nwe demonstrate that DIME can be used to solve complex, in-hand manipulation\ntasks such as 'flipping', 'spinning', and 'rotating' objects with the Allegro\nhand. Our framework along with pre-collected demonstrations is publicly\navailable at https://nyu-robot-learning.github.io/dime.",
          "link": "http://arxiv.org/abs/2203.13251",
          "publishedOn": "2022-03-26T00:46:07.490Z",
          "wordCount": null,
          "title": "Dexterous Imitation Made Easy: A Learning-Based Framework for Efficient Dexterous Manipulation. (arXiv:2203.13251v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13132",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Yang_Y/0/1/0/all/0/1\">Yan Yang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hossain_Z/0/1/0/all/0/1\">Zakir Hossain</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Asif_K/0/1/0/all/0/1\">Khandaker Asif</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Pan_L/0/1/0/all/0/1\">Liyuan Pan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Rahman_S/0/1/0/all/0/1\">Shafin Rahman</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Stone_E/0/1/0/all/0/1\">Eric Stone</a>",
          "description": "De novo peptide sequencing aims to recover amino acid sequences of a peptide\nfrom tandem mass spectrometry (MS) data. Existing approaches for de novo\nanalysis enumerate MS evidence for all amino acid classes during inference. It\nleads to over-trimming on receptive fields of MS data and restricts MS evidence\nassociated with following undecoded amino acids. Our approach, DPST,\ncircumvents these limitations with two key components: (1) A confidence value\naggregation encoder to sketch spectrum representations according to\namino-acid-based connectivity among MS; (2) A global-local fusion decoder to\nprogressively assimilate contextualized spectrum representations with a\npredefined preconception of localized MS evidence and amino acid priors. Our\ncomponents originate from a closed-form solution and selectively attend to\ninformative amino-acid-aware MS representations. Through extensive empirical\nstudies, we demonstrate the superiority of DPST, showing that it outperforms\nstate-of-the-art approaches by a margin of 12% - 19% peptide accuracy.",
          "link": "http://arxiv.org/abs/2203.13132",
          "publishedOn": "2022-03-26T00:46:07.255Z",
          "wordCount": null,
          "title": "DPST: De Novo Peptide Sequencing with Amino-Acid-Aware Transformers. (arXiv:2203.13132v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Luoxiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zijun Zhang</a>",
          "description": "The convolutional neural network (CNN) has been widely applied to process the\nindustrial data based tensor input, which integrates data records of\ndistributed industrial systems from the spatial, temporal, and system dynamics\naspects. However, unlike images, information in the industrial data based\ntensor is not necessarily spatially ordered. Thus, directly applying CNN is\nineffective. To tackle such issue, we propose a plug and play module, the\nRubik's Cube Operator (RCO), to adaptively permutate the data organization of\nthe industrial data based tensor to an optimal or suboptimal order of\nattributes before being processed by CNNs, which can be updated with subsequent\nCNNs together via the gradient-based optimizer. The proposed RCO maintains K\nbinary and right stochastic permutation matrices to permutate attributes of K\naxes of the input industrial data based tensor. A novel learning process is\nproposed to enable learning permutation matrices from data, where the\nGumbel-Softmax is employed to reparameterize elements of permutation matrices,\nand the soft regularization loss is proposed and added to the task-specific\nloss to ensure the feature diversity of the permuted data. We verify the\neffectiveness of the proposed RCO via considering two representative learning\ntasks processing industrial data via CNNs, the wind power prediction (WPP) and\nthe wind speed prediction (WSP) from the renewable energy domain. Computational\nexperiments are conducted based on four datasets collected from different wind\nfarms and the results demonstrate that the proposed RCO can improve the\nperformance of CNN based networks significantly.",
          "link": "http://arxiv.org/abs/2203.12921",
          "publishedOn": "2022-03-26T00:46:07.252Z",
          "wordCount": null,
          "title": "Rubik's Cube Operator: A Plug And Play Permutation Module for Better Arranging High Dimensional Industrial Data in Deep Convolutional Processes. (arXiv:2203.12921v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.05078",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Domingues_O/0/1/0/all/0/1\">Omar Darwiche Domingues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menard_P/0/1/0/all/0/1\">Pierre M&#xe9;nard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pirotta_M/0/1/0/all/0/1\">Matteo Pirotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufmann_E/0/1/0/all/0/1\">Emilie Kaufmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>",
          "description": "In this work, we propose KeRNS: an algorithm for episodic reinforcement\nlearning in non-stationary Markov Decision Processes (MDPs) whose state-action\nset is endowed with a metric. Using a non-parametric model of the MDP built\nwith time-dependent kernels, we prove a regret bound that scales with the\ncovering dimension of the state-action space and the total variation of the MDP\nwith time, which quantifies its level of non-stationarity. Our method\ngeneralizes previous approaches based on sliding windows and exponential\ndiscounting used to handle changing environments. We further propose a\npractical implementation of KeRNS, we analyze its regret and validate it\nexperimentally.",
          "link": "http://arxiv.org/abs/2007.05078",
          "publishedOn": "2022-03-26T00:46:07.248Z",
          "wordCount": null,
          "title": "A Kernel-Based Approach to Non-Stationary Reinforcement Learning in Metric Spaces. (arXiv:2007.05078v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zihan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1\">Xiangyang Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon S. Du</a>",
          "description": "This paper gives the first polynomial-time algorithm for tabular Markov\nDecision Processes (MDP) that enjoys a regret bound \\emph{independent on the\nplanning horizon}. Specifically, we consider tabular MDP with $S$ states, $A$\nactions, a planning horizon $H$, total reward bounded by $1$, and the agent\nplays for $K$ episodes. We design an algorithm that achieves an\n$O\\left(\\mathrm{poly}(S,A,\\log K)\\sqrt{K}\\right)$ regret in contrast to\nexisting bounds which either has an additional $\\mathrm{polylog}(H)$\ndependency~\\citep{zhang2020reinforcement} or has an exponential dependency on\n$S$~\\citep{li2021settling}. Our result relies on a sequence of new structural\nlemmas establishing the approximation power, stability, and concentration\nproperty of stationary policies, which can have applications in other problems\nrelated to Markov chains.",
          "link": "http://arxiv.org/abs/2203.12922",
          "publishedOn": "2022-03-26T00:46:07.246Z",
          "wordCount": null,
          "title": "Horizon-Free Reinforcement Learning in Polynomial Time: the Power of Stationary Policies. (arXiv:2203.12922v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.13792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yufan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruiyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tensmeyer_C/0/1/0/all/0/1\">Chris Tensmeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiuxiang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinhui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tong Sun</a>",
          "description": "One of the major challenges in training text-to-image generation models is\nthe need of a large number of high-quality image-text pairs. While image\nsamples are often easily accessible, the associated text descriptions typically\nrequire careful human captioning, which is particularly time- and\ncost-consuming. In this paper, we propose the first work to train text-to-image\ngeneration models without any text data. Our method leverages the well-aligned\nmulti-modal semantic space of the powerful pre-trained CLIP model: the\nrequirement of text-conditioning is seamlessly alleviated via generating text\nfeatures from image features. Extensive experiments are conducted to illustrate\nthe effectiveness of the proposed method. We obtain state-of-the-art results in\nthe standard text-to-image generation tasks. Importantly, the proposed\nlanguage-free model outperforms most existing models trained with full\nimage-text pairs. Furthermore, our method can be applied in fine-tuning\npre-trained models, which saves both training time and cost in training\ntext-to-image generation models. Our pre-trained model obtains competitive\nresults in zero-shot text-to-image generation on the MS-COCO dataset, yet with\naround only 1% of the model size and training data size relative to the\nrecently proposed large DALL-E model.",
          "link": "http://arxiv.org/abs/2111.13792",
          "publishedOn": "2022-03-26T00:46:07.245Z",
          "wordCount": null,
          "title": "LAFITE: Towards Language-Free Training for Text-to-Image Generation. (arXiv:2111.13792v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.13657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lucchesi_N/0/1/0/all/0/1\">Nicol&#xf2; Lucchesi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carta_A/0/1/0/all/0/1\">Antonio Carta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lomonaco_V/0/1/0/all/0/1\">Vincenzo Lomonaco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1\">Davide Bacciu</a>",
          "description": "Continual Reinforcement Learning (CRL) is a challenging setting where an\nagent learns to interact with an environment that is constantly changing over\ntime (the stream of experiences). In this paper, we describe Avalanche RL, a\nlibrary for Continual Reinforcement Learning which allows to easily train\nagents on a continuous stream of tasks. Avalanche RL is based on PyTorch and\nsupports any OpenAI Gym environment. Its design is based on Avalanche, one of\nthe more popular continual learning libraries, which allow us to reuse a large\nnumber of continual learning strategies and improve the interaction between\nreinforcement learning and continual learning researchers. Additionally, we\npropose Continual Habitat-Lab, a novel benchmark and a high-level library which\nenables the usage of the photorealistic simulator Habitat-Sim for CRL research.\nOverall, Avalanche RL attempts to unify under a common framework continual\nreinforcement learning applications, which we hope will foster the growth of\nthe field.",
          "link": "http://arxiv.org/abs/2202.13657",
          "publishedOn": "2022-03-26T00:46:07.245Z",
          "wordCount": null,
          "title": "Avalanche RL: a Continual Reinforcement Learning Library. (arXiv:2202.13657v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teofili_T/0/1/0/all/0/1\">Tommaso Teofili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firmani_D/0/1/0/all/0/1\">Donatella Firmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koudas_N/0/1/0/all/0/1\">Nick Koudas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martello_V/0/1/0/all/0/1\">Vincenzo Martello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merialdo_P/0/1/0/all/0/1\">Paolo Merialdo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_D/0/1/0/all/0/1\">Divesh Srivastava</a>",
          "description": "Entity resolution (ER) aims at matching records that refer to the same\nreal-world entity. Although widely studied for the last 50 years, ER still\nrepresents a challenging data management problem, and several recent works have\nstarted to investigate the opportunity of applying deep learning (DL)\ntechniques to solve this problem. In this paper, we study the fundamental\nproblem of explainability of the DL solution for ER. Understanding the matching\npredictions of an ER solution is indeed crucial to assess the trustworthiness\nof the DL model and to discover its biases. We treat the DL model as a black\nbox classifier and - while previous approaches to provide explanations for DL\npredictions are agnostic to the classification task. we propose the CERTA\napproach that is aware of the semantics of the ER problem. Our approach\nproduces both saliency explanations, which associate each attribute with a\nsaliency score, and counterfactual explanations, which provide examples of\nvalues that can flip the prediction. CERTA builds on a probabilistic framework\nthat aims at computing the explanations evaluating the outcomes produced by\nusing perturbed copies of the input records. We experimentally evaluate CERTA's\nexplanations of state-of-the-art ER solutions based on DL models using publicly\navailable datasets, and demonstrate the effectiveness of CERTA over recently\nproposed methods for this problem.",
          "link": "http://arxiv.org/abs/2203.12978",
          "publishedOn": "2022-03-26T00:46:07.244Z",
          "wordCount": null,
          "title": "Effective Explanations for Entity Resolution Models. (arXiv:2203.12978v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.04307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bozkurt_A/0/1/0/all/0/1\">Alper Kamil Bozkurt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zavlanos_M/0/1/0/all/0/1\">Michael M. Zavlanos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajic_M/0/1/0/all/0/1\">Miroslav Pajic</a>",
          "description": "Synthesis from linear temporal logic (LTL) specifications provides assured\ncontrollers for autonomous systems operating in stochastic and potentially\nadversarial environments. Automatic synthesis tools, however, require a model\nof the environment to construct controllers. In this work, we introduce a\nmodel-free reinforcement learning (RL) approach that derives controllers from\ngiven LTL specifications even when the environment is completely unknown. We\nmodel the problem of satisfying the LTL specifications as a stochastic game\n(SG) between the controller and the adversarial environment; we then learn\noptimal controller strategies that maximize the probability of satisfying the\nLTL specifications against the worst-case environment behavior. We first\nconstruct a product game using the deterministic parity automaton (DPA)\ntranslated from the given LTL specification. By deriving distinct rewards and\ndiscount factors from the acceptance condition of the DPA, we reduce the\nmaximization of the worst-case probability of satisfying the LTL specification\ninto the maximization of a discounted reward objective in the product game;\nthis allows for the use of model-free RL algorithms to learn an optimal\ncontroller strategy. To deal with the common scalability problems when the\nnumber of colors defining the acceptance condition of the DPA is large, we\npropose a lazy color generation method where distinct rewards and discount\nfactors are utilized only when needed, and an approximate method where the\ncontroller eventually focuses on only one color. In several case studies, we\nshow that our approach is scalable to a wide range of LTL formulas,\nsignificantly outperforming existing methods for learning controllers from LTL\nspecifications in SGs.",
          "link": "http://arxiv.org/abs/2102.04307",
          "publishedOn": "2022-03-26T00:46:07.244Z",
          "wordCount": null,
          "title": "Learning Optimal Strategies for Temporal Tasks in Stochastic Games. (arXiv:2102.04307v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jahani_Nezhad_T/0/1/0/all/0/1\">Tayyebeh Jahani-Nezhad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddah_Ali_M/0/1/0/all/0/1\">Mohammad Ali Maddah-Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Songze Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caire_G/0/1/0/all/0/1\">Giuseppe Caire</a>",
          "description": "We propose SwiftAgg+, a novel secure aggregation protocol for federated\nlearning systems, where a central server aggregates local models of\n$N\\in\\mathbb{N}$ distributed users, each of size $L \\in \\mathbb{N}$, trained on\ntheir local data, in a privacy-preserving manner. SwiftAgg+ can significantly\nreduce the communication overheads without any compromise on security, and\nachieve the optimum communication load within a diminishing gap. Specifically,\nin presence of at most $D$ dropout users, SwiftAgg+ achieves average per-user\ncommunication load of $(1+\\mathcal{O}(\\frac{1}{N}))L$ and the server\ncommunication load of $(1+\\mathcal{O}(\\frac{1}{N}))L$, with a worst-case\ninformation-theoretic security guarantee, against any subset of up to $T$\nsemi-honest users who may also collude with the curious server. The proposed\nSwiftAgg+ has also a flexibility to reduce the number of active communication\nlinks at the cost of increasing the the communication load between the users\nand the server. In particular, for any $K\\in\\mathbb{N}$, SwiftAgg+ can achieve\nthe uplink communication load of $(1+\\frac{T}{K})L$, and per-user communication\nload of up to $(1-\\frac{1}{N})(1+\\frac{T+D}{K})L$, where the number of\npair-wise active connections in the network is $\\frac{N}{2}(K+T+D+1)$.",
          "link": "http://arxiv.org/abs/2203.13060",
          "publishedOn": "2022-03-26T00:46:07.238Z",
          "wordCount": null,
          "title": "SwiftAgg+: Achieving Asymptotically Optimal Communication Load in Secure Aggregation for Federated Learning. (arXiv:2203.13060v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.00603",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Richard J. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tiffany Y. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipkova_J/0/1/0/all/0/1\">Jana Lipkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Judy J. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williamson_D/0/1/0/all/0/1\">Drew F.K. Williamson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1\">Ming Y. Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahai_S/0/1/0/all/0/1\">Sharifa Sahai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_F/0/1/0/all/0/1\">Faisal Mahmood</a>",
          "description": "In the current development and deployment of many artificial intelligence\n(AI) systems in healthcare, algorithm fairness is a challenging problem in\ndelivering equitable care. Recent evaluation of AI models stratified across\nrace sub-populations have revealed inequalities in how patients are diagnosed,\ngiven treatments, and billed for healthcare costs. In this perspective article,\nwe summarize the intersectional field of fairness in machine learning through\nthe context of current issues in healthcare, outline how algorithmic biases\n(e.g. - image acquisition, genetic variation, intra-observer labeling\nvariability) arise in current clinical workflows and their resulting healthcare\ndisparities. Lastly, we also review emerging technology for mitigating bias via\nfederated learning, disentanglement, and model explainability, and their role\nin AI-SaMD development.",
          "link": "http://arxiv.org/abs/2110.00603",
          "publishedOn": "2022-03-26T00:46:07.238Z",
          "wordCount": null,
          "title": "Algorithm Fairness in AI for Medicine and Healthcare. (arXiv:2110.00603v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.04260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiao-Ming Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_Y/0/1/0/all/0/1\">Yu-Wei Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Chen-Lu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhen-Duo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xin-Shun Xu</a>",
          "description": "With the vigorous development of multimedia equipment and applications,\nefficient retrieval of large-scale multi-modal data has become a trendy\nresearch topic. Thereinto, hashing has become a prevalent choice due to its\nretrieval efficiency and low storage cost. Although multi-modal hashing has\ndrawn lots of attention in recent years, there still remain some problems. The\nfirst point is that existing methods are mainly designed in batch mode and not\nable to efficiently handle streaming multi-modal data. The second point is that\nall existing online multi-modal hashing methods fail to effectively handle\nunseen new classes which come continuously with streaming data chunks. In this\npaper, we propose a new model, termed Online enhAnced SemantIc haShing (OASIS).\nWe design novel semantic-enhanced representation for data, which could help\nhandle the new coming classes, and thereby construct the enhanced semantic\nobjective function. An efficient and effective discrete online optimization\nalgorithm is further proposed for OASIS. Extensive experiments show that our\nmethod can exceed the state-of-the-art models. For good reproducibility and\nbenefiting the community, our code and data are already available in\nsupplementary material and will be made publicly available.",
          "link": "http://arxiv.org/abs/2109.04260",
          "publishedOn": "2022-03-26T00:46:07.237Z",
          "wordCount": null,
          "title": "Online Enhanced Semantic Hashing: Towards Effective and Efficient Retrieval for Streaming Multi-Modal Data. (arXiv:2109.04260v2 [cs.MM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Burrello_A/0/1/0/all/0/1\">Alessio Burrello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dequino_A/0/1/0/all/0/1\">Alberto Dequino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagliari_D/0/1/0/all/0/1\">Daniele Jahier Pagliari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conti_F/0/1/0/all/0/1\">Francesco Conti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanghieri_M/0/1/0/all/0/1\">Marcello Zanghieri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macii_E/0/1/0/all/0/1\">Enrico Macii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poncino_M/0/1/0/all/0/1\">Massimo Poncino</a>",
          "description": "Temporal Convolutional Networks (TCNs) are emerging lightweight Deep Learning\nmodels for Time Series analysis. We introduce an automated exploration approach\nand a library of optimized kernels to map TCNs on Parallel Ultra-Low Power\n(PULP) microcontrollers. Our approach minimizes latency and energy by\nexploiting a layer tiling optimizer to jointly find the tiling dimensions and\nselect among alternative implementations of the causal and dilated\n1D-convolution operations at the core of TCNs. We benchmark our approach on a\ncommercial PULP device, achieving up to 103X lower latency and 20.3X lower\nenergy than the Cube-AI toolkit executed on the STM32L4 and from 2.9X to 26.6X\nlower energy compared to commercial closed-source and academic open-source\napproaches on the same hardware target.",
          "link": "http://arxiv.org/abs/2203.12925",
          "publishedOn": "2022-03-26T00:46:07.236Z",
          "wordCount": null,
          "title": "TCN Mapping Optimization for Ultra-Low Power Time-Series Edge Inference. (arXiv:2203.12925v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Abhishek Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garza_E/0/1/0/all/0/1\">Ethan Garza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chopra_A/0/1/0/all/0/1\">Ayush Chopra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vepakomma_P/0/1/0/all/0/1\">Praneeth Vepakomma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1\">Vivek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raskar_R/0/1/0/all/0/1\">Ramesh Raskar</a>",
          "description": "We propose sanitizer, a framework for secure and task-agnostic data release.\nWhile releasing datasets continues to make a big impact in various applications\nof computer vision, its impact is mostly realized when data sharing is not\ninhibited by privacy concerns. We alleviate these concerns by sanitizing\ndatasets in a two-stage process. First, we introduce a global decoupling stage\nfor decomposing raw data into sensitive and non-sensitive latent\nrepresentations. Secondly, we design a local sampling stage to synthetically\ngenerate sensitive information with differential privacy and merge it with\nnon-sensitive latent features to create a useful representation while\npreserving the privacy. This newly formed latent information is a task-agnostic\nrepresentation of the original dataset with anonymized sensitive information.\nWhile most algorithms sanitize data in a task-dependent manner, a few\ntask-agnostic sanitization techniques sanitize data by censoring sensitive\ninformation. In this work, we show that a better privacy-utility trade-off is\nachieved if sensitive information can be synthesized privately. We validate the\neffectiveness of the sanitizer by outperforming state-of-the-art baselines on\nthe existing benchmark tasks and demonstrating tasks that are not possible\nusing existing techniques.",
          "link": "http://arxiv.org/abs/2203.13204",
          "publishedOn": "2022-03-26T00:46:07.235Z",
          "wordCount": null,
          "title": "Decouple-and-Sample: Protecting sensitive information in task agnostic data release. (arXiv:2203.13204v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08368",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_K/0/1/0/all/0/1\">Kai Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yifei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaowei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wen Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>",
          "description": "The exponentially large discrete search space in mixed-precision quantization\n(MPQ) makes it hard to determine the optimal bit-width for each layer. Previous\nworks usually resort to iterative search methods on the training set, which\nconsume hundreds or even thousands of GPU-hours. In this study, we reveal that\nsome unique learnable parameters in quantization, namely the scale factors in\nthe quantizer, can serve as importance indicators of a layer, reflecting the\ncontribution of that layer to the final accuracy at certain bit-widths. These\nimportance indicators naturally perceive the numerical transformation during\nquantization-aware training, which can precisely and correctly provide\nquantization sensitivity metrics of layers. However, a deep network always\ncontains hundreds of such indicators, and training them one by one would lead\nto an excessive time cost. To overcome this issue, we propose a joint training\nscheme that can obtain all indicators at once. It considerably speeds up the\nindicators training process by parallelizing the original sequential training\nprocesses. With these learned importance indicators, we formulate the MPQ\nsearch problem as a one-time integer linear programming (ILP) problem. That\navoids the iterative search and significantly reduces search time without\nlimiting the bit-width search space. For example, MPQ search on ResNet18 with\nour indicators takes only 0.06 seconds. Also, extensive experiments show our\napproach can achieve SOTA accuracy on ImageNet for far-ranging models with\nvarious constraints (e.g., BitOps, compress rate).",
          "link": "http://arxiv.org/abs/2203.08368",
          "publishedOn": "2022-03-26T00:46:07.234Z",
          "wordCount": null,
          "title": "Mixed-Precision Neural Network Quantization via Learned Layer-wise Importance. (arXiv:2203.08368v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>",
          "description": "Recent studies on StyleGAN show high performance on artistic portrait\ngeneration by transfer learning with limited data. In this paper, we explore\nmore challenging exemplar-based high-resolution portrait style transfer by\nintroducing a novel DualStyleGAN with flexible control of dual styles of the\noriginal face domain and the extended artistic portrait domain. Different from\nStyleGAN, DualStyleGAN provides a natural way of style transfer by\ncharacterizing the content and style of a portrait with an intrinsic style path\nand a new extrinsic style path, respectively. The delicately designed extrinsic\nstyle path enables our model to modulate both the color and complex structural\nstyles hierarchically to precisely pastiche the style example. Furthermore, a\nnovel progressive fine-tuning scheme is introduced to smoothly transform the\ngenerative space of the model to the target domain, even with the above\nmodifications on the network architecture. Experiments demonstrate the\nsuperiority of DualStyleGAN over state-of-the-art methods in high-quality\nportrait style transfer and flexible style control.",
          "link": "http://arxiv.org/abs/2203.13248",
          "publishedOn": "2022-03-26T00:46:07.215Z",
          "wordCount": null,
          "title": "Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer. (arXiv:2203.13248v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04302",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Karlik_E/0/1/0/all/0/1\">Edo Cohen-Karlik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1\">Avichai Ben David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1\">Nadav Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1\">Amir Globerson</a>",
          "description": "When using recurrent neural networks (RNNs) it is common practice to apply\ntrained models to sequences longer than those seen in training. This\n\"extrapolating\" usage deviates from the traditional statistical learning setup\nwhere guarantees are provided under the assumption that train and test\ndistributions are identical. Here we set out to understand when RNNs can\nextrapolate, focusing on a simple case where the data generating distribution\nis memoryless. We first show that even with infinite training data, there exist\nRNN models that interpolate perfectly (i.e., they fit the training data) yet\nextrapolate poorly to longer sequences. We then show that if gradient descent\nis used for training, learning will converge to perfect extrapolation under\ncertain assumptions on initialization. Our results complement recent studies on\nthe implicit bias of gradient descent, showing that it plays a key role in\nextrapolation when learning temporal prediction models.",
          "link": "http://arxiv.org/abs/2202.04302",
          "publishedOn": "2022-03-26T00:46:07.195Z",
          "wordCount": null,
          "title": "On the Implicit Bias of Gradient Descent for Temporal Extrapolation. (arXiv:2202.04302v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12864",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ito_K/0/1/0/all/0/1\">Kaito Ito</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kashima_K/0/1/0/all/0/1\">Kenji Kashima</a>",
          "description": "Kullback-Leibler (KL) control enables efficient numerical methods for\nnonlinear optimal control problems. The crucial assumption of KL control is the\nfull controllability of the transition distribution. However, this assumption\nis often violated when the dynamics evolves in a continuous space.\nConsequently, applying KL control to problems with continuous spaces requires\nsome approximation, which leads to the lost of the optimality. To avoid such\napproximation, in this paper, we reformulate the KL control problem for\ncontinuous spaces so that it does not require unrealistic assumptions. The key\ndifference between the original and reformulated KL control is that the former\nmeasures the control effort by KL divergence between controlled and\nuncontrolled transition distributions while the latter replaces the\nuncontrolled transition by a noise-driven transition. We show that the\nreformulated KL control admits efficient numerical algorithms like the original\none without unreasonable assumptions. Specifically, the associated value\nfunction can be computed by using a Monte Carlo method based on its path\nintegral representation.",
          "link": "http://arxiv.org/abs/2203.12864",
          "publishedOn": "2022-03-26T00:46:07.192Z",
          "wordCount": null,
          "title": "Kullback-Leibler control for discrete-time nonlinear systems on continuous spaces. (arXiv:2203.12864v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.09490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karaderi_T/0/1/0/all/0/1\">Tayfun Karaderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burghardt_T/0/1/0/all/0/1\">Tilo Burghardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsiang_A/0/1/0/all/0/1\">Allison Y. Hsiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramaer_J/0/1/0/all/0/1\">Jacob Ramaer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_D/0/1/0/all/0/1\">Daniela N. Schmidt</a>",
          "description": "We apply deep metric learning for the first time to the problem of\nclassifying planktic foraminifer shells on microscopic images. This species\nrecognition task is an important information source and scientific pillar for\nreconstructing past climates. All foraminifer CNN recognition pipelines in the\nliterature produce black-box classifiers that lack visualization options for\nhuman experts and cannot be applied to open-set problems. Here, we benchmark\nmetric learning against these pipelines, produce the first scientific\nvisualization of the phenotypic planktic foraminifer morphology space, and\ndemonstrate that metric learning can be used to cluster species unseen during\ntraining. We show that metric learning outperforms all published CNN-based\nstate-of-the-art benchmarks in this domain. We evaluate our approach on the\n34,640 expert-annotated images of the Endless Forams public library of 35\nmodern planktic foraminifera species. Our results on this data show leading 92%\naccuracy (at 0.84 F1-score) in reproducing expert labels on withheld test data,\nand 66.5% accuracy (at 0.70 F1-score) when clustering species never encountered\nin training. We conclude that metric learning is highly effective for this\ndomain and serves as an important tool towards expert-in-the-loop automation of\nmicrofossil identification. Keycode, network weights, and data splits are\npublished with this paper for full reproducibility.",
          "link": "http://arxiv.org/abs/2112.09490",
          "publishedOn": "2022-03-26T00:46:07.172Z",
          "wordCount": null,
          "title": "Visual Microfossil Identification via Deep Metric Learning. (arXiv:2112.09490v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_C/0/1/0/all/0/1\">Cheng Kevin Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wardak_A/0/1/0/all/0/1\">Asem Wardak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_P/0/1/0/all/0/1\">Pulin Gong</a>",
          "description": "Deep neural networks (DNNs) have been successfully applied to many real-world\nproblems, but a complete understanding of their dynamical and computational\nprinciples is still lacking. Conventional theoretical frameworks for analysing\nDNNs often assume random networks with coupling weights obeying Gaussian\nstatistics. However, non-Gaussian, heavy-tailed coupling is a ubiquitous\nphenomenon in DNNs. Here, by weaving together theories of heavy-tailed random\nmatrices and non-equilibrium statistical physics, we develop a new type of mean\nfield theory for DNNs which predicts that heavy-tailed weights enable the\nemergence of an extended critical regime without fine-tuning parameters. In\nthis extended critical regime, DNNs exhibit rich and complex propagation\ndynamics across layers. We further elucidate that the extended criticality\nendows DNNs with profound computational advantages: balancing the contraction\nas well as expansion of internal neural representations and speeding up\ntraining processes, hence providing a theoretical guide for the design of\nefficient neural architectures.",
          "link": "http://arxiv.org/abs/2203.12967",
          "publishedOn": "2022-03-26T00:46:07.163Z",
          "wordCount": null,
          "title": "Extended critical regimes of deep neural networks. (arXiv:2203.12967v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andreev_P/0/1/0/all/0/1\">Pavel Andreev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alanov_A/0/1/0/all/0/1\">Aibek Alanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivanov_O/0/1/0/all/0/1\">Oleg Ivanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>",
          "description": "Generative adversarial networks have recently demonstrated outstanding\nperformance in neural vocoding outperforming best autoregressive and flow-based\nmodels. In this paper, we show that this success can be extended to other tasks\nof conditional audio generation. In particular, building upon HiFi vocoders, we\npropose a novel HiFi++ general framework for neural vocoding, bandwidth\nextension, and speech enhancement. We show that with the improved generator\narchitecture and simplified multi-discriminator training, HiFi++ performs on\npar with the state-of-the-art in these tasks while spending significantly less\nmemory and computational resources. The effectiveness of our approach is\nvalidated through a series of extensive experiments.",
          "link": "http://arxiv.org/abs/2203.13086",
          "publishedOn": "2022-03-26T00:46:07.163Z",
          "wordCount": null,
          "title": "HiFi++: a Unified Framework for Neural Vocoding, Bandwidth Extension and Speech Enhancement. (arXiv:2203.13086v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Le Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1\">Richard Yuanzhe Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuexin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xinying Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiaodan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Denny Zhou</a>",
          "description": "Transformer-based models generally allocate the same amount of computation\nfor each token in a given sequence. We develop a simple but effective \"token\ndropping\" method to accelerate the pretraining of transformer models, such as\nBERT, without degrading its performance on downstream tasks. In short, we drop\nunimportant tokens starting from an intermediate layer in the model to make the\nmodel focus on important tokens; the dropped tokens are later picked up by the\nlast layer of the model so that the model still produces full-length sequences.\nWe leverage the already built-in masked language modeling (MLM) loss to\nidentify unimportant tokens with practically no computational overhead. In our\nexperiments, this simple approach reduces the pretraining cost of BERT by 25%\nwhile achieving similar overall fine-tuning performance on standard downstream\ntasks.",
          "link": "http://arxiv.org/abs/2203.13240",
          "publishedOn": "2022-03-26T00:46:07.163Z",
          "wordCount": null,
          "title": "Token Dropping for Efficient BERT Pretraining. (arXiv:2203.13240v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Hung T. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1\">H. Vincent Poor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_M/0/1/0/all/0/1\">Mung Chiang</a>",
          "description": "Federated learning is a prime candidate for distributed machine learning at\nthe network edge due to the low communication complexity and privacy protection\namong other attractive properties. However, existing algorithms face issues\nwith slow convergence and/or robustness of performance due to the considerable\nheterogeneity of data distribution, computation and communication capability at\nthe edge. In this work, we tackle both of these issues by focusing on the key\ncomponent of model aggregation in federated learning systems and studying\noptimal algorithms to perform this task. Particularly, we propose a contextual\naggregation scheme that achieves the optimal context-dependent bound on loss\nreduction in each round of optimization. The aforementioned context-dependent\nbound is derived from the particular participating devices in that round and an\nassumption on smoothness of the overall loss function. We show that this\naggregation leads to a definite reduction of loss function at every round.\nFurthermore, we can integrate our aggregation with many existing algorithms to\nobtain the contextual versions. Our experimental results demonstrate\nsignificant improvements in convergence speed and robustness of the contextual\nversions compared to the original algorithms. We also consider different\nvariants of the contextual aggregation and show robust performance even in the\nmost extreme settings.",
          "link": "http://arxiv.org/abs/2203.12738",
          "publishedOn": "2022-03-26T00:46:07.135Z",
          "wordCount": null,
          "title": "Contextual Model Aggregation for Fast and Robust Federated Learning in Edge Computing. (arXiv:2203.12738v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12659",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Debnath_S/0/1/0/all/0/1\">Soumyadeep Debnath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mollah_A/0/1/0/all/0/1\">Ayatullah Faruk Mollah</a>",
          "description": "Computational protein-protein interaction (PPI) prediction techniques can\ncontribute greatly in reducing time, cost and false-positive interactions\ncompared to experimental approaches. Sequence is one of the key and primary\ninformation of proteins that plays a crucial role in PPI prediction. Several\nmachine learning approaches have been applied to exploit the characteristics of\nPPI datasets. However, these datasets greatly influence the performance of\npredicting models. So, care should be taken on both dataset curation as well as\ndesign of predictive models. Here, we have described our submitted solution\nwith the results of the SeqPIP competition whose objective was to develop\ncomprehensive PPI predictive models from sequence information with high-quality\nbias-free interaction datasets. A training set of 2000 positive and 2000\nnegative interactions with sequences was given to us. Our method was evaluated\nwith three independent high-quality interaction test datasets and with other\ncompetitors solutions.",
          "link": "http://arxiv.org/abs/2203.12659",
          "publishedOn": "2022-03-26T00:46:07.132Z",
          "wordCount": 595,
          "title": "A Supervised Machine Learning Approach for Sequence Based Protein-protein Interaction (PPI) Prediction. (arXiv:2203.12659v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12658",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zach_M/0/1/0/all/0/1\">Martin Zach</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kobler_E/0/1/0/all/0/1\">Erich Kobler</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pock_T/0/1/0/all/0/1\">Thomas Pock</a>",
          "description": "In the past decades, Computed Tomography (CT) has established itself as one\nof the most important imaging techniques in medicine. Today, the applicability\nof CT is only limited by the deposited radiation dose, reduction of which\nmanifests in noisy or incomplete measurements. Thus, the need for robust\nreconstruction algorithms arises. In this work, we learn a parametric\nregularizer with a global receptive field by maximizing it's likelihood on\nreference CT data. Due to this unsupervised learning strategy, our trained\nregularizer truly represents higher-level domain statistics, which we\nempirically demonstrate by synthesizing CT images. Moreover, this regularizer\ncan easily be applied to different CT reconstruction problems by embedding it\nin a variational framework, which increases flexibility and interpretability\ncompared to feed-forward learning-based approaches. In addition, the\naccompanying probabilistic perspective enables experts to explore the full\nposterior distribution and may quantify uncertainty of the reconstruction\napproach. We apply the regularizer to limited-angle and few-view CT\nreconstruction problems, where it outperforms traditional reconstruction\nalgorithms by a large margin.",
          "link": "http://arxiv.org/abs/2203.12658",
          "publishedOn": "2022-03-26T00:46:07.123Z",
          "wordCount": null,
          "title": "Computed Tomography Reconstruction using Generative Energy-Based Priors. (arXiv:2203.12658v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Low_S/0/1/0/all/0/1\">Siow Meng Low</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Akshat Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanner_S/0/1/0/all/0/1\">Scott Sanner</a>",
          "description": "Recent advances in deep learning have enabled optimization of deep reactive\npolicies (DRPs) for continuous MDP planning by encoding a parametric policy as\na deep neural network and exploiting automatic differentiation in an end-to-end\nmodel-based gradient descent framework. This approach has proven effective for\noptimizing DRPs in nonlinear continuous MDPs, but it requires a large number of\nsampled trajectories to learn effectively and can suffer from high variance in\nsolution quality. In this work, we revisit the overall model-based DRP\nobjective and instead take a minorization-maximization perspective to\niteratively optimize the DRP w.r.t. a locally tight lower-bounded objective.\nThis novel formulation of DRP learning as iterative lower bound optimization\n(ILBO) is particularly appealing because (i) each step is structurally easier\nto optimize than the overall objective, (ii) it guarantees a monotonically\nimproving objective under certain theoretical conditions, and (iii) it reuses\nsamples between iterations thus lowering sample complexity. Empirical\nevaluation confirms that ILBO is significantly more sample-efficient than the\nstate-of-the-art DRP planner and consistently produces better solution quality\nwith lower variance. We additionally demonstrate that ILBO generalizes well to\nnew problem instances (i.e., different initial states) without requiring\nretraining.",
          "link": "http://arxiv.org/abs/2203.12679",
          "publishedOn": "2022-03-26T00:46:07.121Z",
          "wordCount": null,
          "title": "Sample-efficient Iterative Lower Bound Optimization of Deep Reactive Policies for Planning in Continuous MDPs. (arXiv:2203.12679v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Youngmin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allmendinger_R/0/1/0/all/0/1\">Richard Allmendinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_Ibanez_M/0/1/0/all/0/1\">Manuel L&#xf3;pez-Ib&#xe1;&#xf1;ez</a>",
          "description": "We consider a type of constrained optimization problem, where the violation\nof a constraint leads to an irrevocable loss, such as breakage of a valuable\nexperimental resource/platform or loss of human life. Such problems are\nreferred to as safe optimization problems (SafeOPs). While SafeOPs have\nreceived attention in the machine learning community in recent years, there was\nlittle interest in the evolutionary computation (EC) community despite some\nearly attempts between 2009 and 2011. Moreover, there is a lack of acceptable\nguidelines on how to benchmark different algorithms for SafeOPs, an area where\nthe EC community has significant experience in. Driven by the need for more\nefficient algorithms and benchmark guidelines for SafeOPs, the objective of\nthis paper is to reignite the interest of this problem class in the EC\ncommunity. To achieve this we (i) provide a formal definition of SafeOPs and\ncontrast it to other types of optimization problems that the EC community is\nfamiliar with, (ii) investigate the impact of key SafeOP parameters on the\nperformance of selected safe optimization algorithms, (iii) benchmark EC\nagainst state-of-the-art safe optimization algorithms from the machine learning\ncommunity, and (iv) provide an open-source Python framework to replicate and\nextend our work.",
          "link": "http://arxiv.org/abs/2203.12622",
          "publishedOn": "2022-03-26T00:46:07.120Z",
          "wordCount": null,
          "title": "Are Evolutionary Algorithms Safe Optimizers?. (arXiv:2203.12622v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12774",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_M/0/1/0/all/0/1\">Max Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schick_L/0/1/0/all/0/1\">Logan Schick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gombolay_M/0/1/0/all/0/1\">Matthew Gombolay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalan_N/0/1/0/all/0/1\">Nakul Gopalan</a>",
          "description": "Modern day computer games have extremely large state and action spaces. To\ndetect bugs in these games' models, human testers play the games repeatedly to\nexplore the game and find errors in the games. Such game play is exhaustive and\ntime consuming. Moreover, since robotics simulators depend on similar methods\nof model specification and debugging, the problem of finding errors in the\nmodel is of interest for the robotics community to ensure robot behaviors and\ninteractions are consistent in simulators. Previous methods have used\nreinforcement learning and search based methods including Rapidly-exploring\nRandom Trees (RRT) to explore a game's state-action space to find bugs.\nHowever, such search and exploration based methods are not efficient at\nexploring the state-action space without a pre-defined heuristic. In this work\nwe attempt to combine a human-tester's expertise in solving games, and the\nexhaustiveness of RRT to search a game's state space efficiently with high\ncoverage. This paper introduces human-seeded RRT (HS-RRT) and\nbehavior-cloning-assisted RRT (CA-RRT) in testing the number of game states\nsearched and the time taken to explore those game states. We compare our\nmethods to an existing weighted RRT baseline for game exploration testing\nstudied. We find HS-RRT and CA-RRT both explore more game states in fewer tree\nexpansions/iterations when compared to the existing baseline. In each test,\nCA-RRT reached more states on average in the same number of iterations as RRT.\nIn our tested environments, CA-RRT was able to reach the same number of states\nas RRT by more than 5000 fewer iterations on average, almost a 50% reduction.",
          "link": "http://arxiv.org/abs/2203.12774",
          "publishedOn": "2022-03-26T00:46:07.120Z",
          "wordCount": null,
          "title": "Learning Efficient Exploration through Human Seeded Rapidly-exploring Random Trees. (arXiv:2203.12774v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12633",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yurtsever_A/0/1/0/all/0/1\">Alp Yurtsever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1\">Tolga Birdal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1\">Vladislav Golyanik</a>",
          "description": "We present a hybrid classical-quantum framework based on the Frank-Wolfe\nalgorithm, Q-FW, for solving quadratic, linearly-constrained, binary\noptimization problems on quantum annealers (QA). The computational premise of\nquantum computers has cultivated the re-design of various existing vision\nproblems into quantum-friendly forms. Experimental QA realizations can solve a\nparticular non-convex problem known as the quadratic unconstrained binary\noptimization (QUBO). Yet a naive-QUBO cannot take into account the restrictions\non the parameters. To introduce additional structure in the parameter space,\nresearchers have crafted ad-hoc solutions incorporating (linear) constraints in\nthe form of regularizers. However, this comes at the expense of a\nhyper-parameter, balancing the impact of regularization. To date, a true\nconstrained solver of quadratic binary optimization (QBO) problems has lacked.\nQ-FW first reformulates constrained-QBO as a copositive program (CP), then\nemploys Frank-Wolfe iterations to solve CP while satisfying linear (in)equality\nconstraints. This procedure unrolls the original constrained-QBO into a set of\nunconstrained QUBOs all of which are solved, in a sequel, on a QA. We use\nD-Wave Advantage QA to conduct synthetic and real experiments on two important\ncomputer vision problems, graph matching and permutation synchronization, which\ndemonstrate that our approach is effective in alleviating the need for an\nexplicit regularization coefficient.",
          "link": "http://arxiv.org/abs/2203.12633",
          "publishedOn": "2022-03-26T00:46:07.119Z",
          "wordCount": null,
          "title": "Q-FW: A Hybrid Classical-Quantum Frank-Wolfe for Quadratic Binary Optimization. (arXiv:2203.12633v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zanette_A/0/1/0/all/0/1\">Andrea Zanette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wainwright_M/0/1/0/all/0/1\">Martin J. Wainwright</a>",
          "description": "We introduce a new reinforcement learning principle that approximates the\nBellman equations by enforcing their validity only along an user-defined space\nof test functions. Focusing on applications to model-free offline RL with\nfunction approximation, we exploit this principle to derive confidence\nintervals for off-policy evaluation, as well as to optimize over policies\nwithin a prescribed policy class. We prove an oracle inequality on our policy\noptimization procedure in terms of a trade-off between the value and\nuncertainty of an arbitrary comparator policy. Different choices of test\nfunction spaces allow us to tackle different problems within a common\nframework. We characterize the loss of efficiency in moving from on-policy to\noff-policy data using our procedures, and establish connections to\nconcentrability coefficients studied in past work. We examine in depth the\nimplementation of our methods with linear function approximation, and provide\ntheoretical guarantees with polynomial-time implementations even when Bellman\nclosure does not hold.",
          "link": "http://arxiv.org/abs/2203.12786",
          "publishedOn": "2022-03-26T00:46:07.119Z",
          "wordCount": null,
          "title": "Bellman Residual Orthogonalization for Offline Reinforcement Learning. (arXiv:2203.12786v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Costales_R/0/1/0/all/0/1\">Robby Costales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_S/0/1/0/all/0/1\">Shariq Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_F/0/1/0/all/0/1\">Fei Sha</a>",
          "description": "Reinforcement learning algorithms struggle on tasks with complex hierarchical\ndependency structures. Humans and other intelligent agents do not waste time\nassessing the utility of every high-level action in existence, but instead only\nconsider ones they deem possible in the first place. By focusing only on what\nis feasible, or \"afforded\", at the present moment, an agent can spend more time\nboth evaluating the utility of and acting on what matters. To this end, we\npresent Hierarchical Affordance Learning (HAL), a method that learns a model of\nhierarchical affordances in order to prune impossible subtasks for more\neffective learning. Existing works in hierarchical reinforcement learning\nprovide agents with structural representations of subtasks but are not\naffordance-aware, and by grounding our definition of hierarchical affordances\nin the present state, our approach is more flexible than the multitude of\napproaches that ground their subtask dependencies in a symbolic history. While\nthese logic-based methods often require complete knowledge of the subtask\nhierarchy, our approach is able to utilize incomplete and varying symbolic\nspecifications. Furthermore, we demonstrate that relative to\nnon-affordance-aware methods, HAL agents are better able to efficiently learn\ncomplex tasks, navigate environment stochasticity, and acquire diverse skills\nin the absence of extrinsic supervision -- all of which are hallmarks of human\nlearning.",
          "link": "http://arxiv.org/abs/2203.12686",
          "publishedOn": "2022-03-26T00:46:07.118Z",
          "wordCount": null,
          "title": "Possibility Before Utility: Learning And Using Hierarchical Affordances. (arXiv:2203.12686v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuor_T/0/1/0/all/0/1\">Tiffany Tuor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lockhart_J/0/1/0/all/0/1\">Joshua Lockhart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1\">Daniele Magazzeni</a>",
          "description": "Machine learning algorithms can perform well when trained on large datasets.\nWhile large organisations often have considerable data assets, it can be\ndifficult for these assets to be unified in a manner that makes training\npossible. Data is very often 'siloed' in different parts of the organisation,\nwith little to no access between silos. This fragmentation of data assets is\nespecially prevalent in heavily regulated industries like financial services or\nhealthcare. In this paper we propose a framework to enable asynchronous\ncollaborative training of machine learning models across data silos. This\nallows data science teams to collaboratively train a machine learning model,\nwithout sharing data with one another. Our proposed approach enhances\nconventional federated learning techniques to make them suitable for this\nasynchronous training in this intra-organisation, cross-silo setting. We\nvalidate our proposed approach via extensive experiments.",
          "link": "http://arxiv.org/abs/2203.12637",
          "publishedOn": "2022-03-26T00:46:07.117Z",
          "wordCount": null,
          "title": "Asynchronous Collaborative Learning Across Data Silos. (arXiv:2203.12637v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Benato_L/0/1/0/all/0/1\">Lisa Benato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buhmann_E/0/1/0/all/0/1\">Erik Buhmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdmann_M/0/1/0/all/0/1\">Martin Erdmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fackeldey_P/0/1/0/all/0/1\">Peter Fackeldey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glombitza_J/0/1/0/all/0/1\">Jonas Glombitza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartmann_N/0/1/0/all/0/1\">Nikolai Hartmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasieczka_G/0/1/0/all/0/1\">Gregor Kasieczka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korcari_W/0/1/0/all/0/1\">William Korcari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhr_T/0/1/0/all/0/1\">Thomas Kuhr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinheimer_J/0/1/0/all/0/1\">Jan Steinheimer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stocker_H/0/1/0/all/0/1\">Horst St&#xf6;cker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plehn_T/0/1/0/all/0/1\">Tilman Plehn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kai Zhou</a>",
          "description": "We introduce a Python package that provides simply and unified access to a\ncollection of datasets from fundamental physics research - including particle\nphysics, astroparticle physics, and hadron- and nuclear physics - for\nsupervised machine learning studies. The datasets contain hadronic top quarks,\ncosmic-ray induced air showers, phase transitions in hadronic matter, and\ngenerator-level histories. While public datasets from multiple fundamental\nphysics disciplines already exist, the common interface and provided reference\nmodels simplify future work on cross-disciplinary machine learning and transfer\nlearning in fundamental physics. We discuss the design and structure and line\nout how additional datasets can be submitted for inclusion.\n\nAs showcase application, we present a simple yet flexible graph-based neural\nnetwork architecture that can easily be applied to a wide range of supervised\nlearning tasks. We show that our approach reaches performance close to\ndedicated methods on all datasets. To simplify adaptation for various problems,\nwe provide easy-to-follow instructions on how graph-based representations of\ndata structures, relevant for fundamental physics, can be constructed and\nprovide code implementations for several of them. Implementations are also\nprovided for our proposed method and all reference algorithms.",
          "link": "http://arxiv.org/abs/2107.00656",
          "publishedOn": "2022-03-26T00:46:07.116Z",
          "wordCount": null,
          "title": "Shared Data and Algorithms for Deep Learning in Fundamental Physics. (arXiv:2107.00656v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Friedlander_T/0/1/0/all/0/1\">Tomer Friedlander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>",
          "description": "Canonical Correlation Analysis (CCA) is a method for feature extraction of\ntwo views by finding maximally correlated linear projections of them. Several\nvariants of CCA have been introduced in the literature, in particular, variants\nbased on deep neural networks for learning highly correlated nonlinear\ntransformations of two views. As these models are parameterized conventionally,\ntheir learnable parameters remain independent of the inputs after the training\nprocess, which may limit their capacity for learning highly correlated\nrepresentations. We introduce a novel dynamic scaling method for training an\ninput-dependent canonical correlation model. In our deep-CCA models, the\nparameters of the last layer are scaled by a second neural network that is\nconditioned on the model's input, resulting in a parameterization that is\ndependent on the input samples. We evaluate our model on multiple datasets and\ndemonstrate that the learned representations are more correlated in comparison\nto the conventionally-parameterized CCA-based models and also obtain preferable\nretrieval results. Our code is available at\nhttps://github.com/tomerfr/DynamicallyScaledDeepCCA.",
          "link": "http://arxiv.org/abs/2203.12377",
          "publishedOn": "2022-03-26T00:46:07.115Z",
          "wordCount": null,
          "title": "Dynamically-Scaled Deep Canonical Correlation Analysis. (arXiv:2203.12377v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kovvuri_V/0/1/0/all/0/1\">Veera Raghava Reddy Kovvuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seisenberger_M/0/1/0/all/0/1\">Monika Seisenberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_B/0/1/0/all/0/1\">Berndt M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiuyi Fan</a>",
          "description": "Feature attribution XAI algorithms enable their users to gain insight into\nthe underlying patterns of large datasets through their feature importance\ncalculation. Existing feature attribution algorithms treat all features in a\ndataset homogeneously, which may lead to misinterpretation of consequences of\nchanging feature values. In this work, we consider partitioning features into\ncontrollable and uncontrollable parts and propose the Controllable fActor\nFeature Attribution (CAFA) approach to compute the relative importance of\ncontrollable features. We carried out experiments applying CAFA to two existing\ndatasets and our own COVID-19 non-pharmaceutical control measures dataset.\nExperimental results show that with CAFA, we are able to exclude influences\nfrom uncontrollable features in our explanation while keeping the full dataset\nfor prediction.",
          "link": "http://arxiv.org/abs/2203.12701",
          "publishedOn": "2022-03-26T00:46:07.109Z",
          "wordCount": null,
          "title": "On Understanding the Influence of Controllable Factors with a Feature Attribution Algorithm: a Medical Case Study. (arXiv:2203.12701v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10919",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Collins_J/0/1/0/all/0/1\">Jack H. Collins</a>",
          "description": "I present a Variational Autoencoder (VAE) trained on collider physics data\n(specifically boosted $W$ jets), with reconstruction error given by an\napproximation to the Earth Movers Distance (EMD) between input and output jets.\nThis VAE learns a concrete representation of the data manifold, with\nsemantically meaningful and interpretable latent space directions which are\nhierarchically organized in terms of their relation to physical EMD scales in\nthe underlying physical generative process. A hyperparameter $\\beta$ controls\nthe resolution at which the VAE is sensitive to structures in the data\nmanifold. The variation of the latent space structure with $\\beta$, and the\nscaling of some VAE properties, provide insight into scale dependent structure\nof the dataset and its information complexity. I introduce two measures of the\ndimensionality of the learnt representation that are calculated from this\nscaling.",
          "link": "http://arxiv.org/abs/2109.10919",
          "publishedOn": "2022-03-26T00:46:07.108Z",
          "wordCount": null,
          "title": "An Exploration of Learnt Representations of W Jets. (arXiv:2109.10919v2 [hep-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.16745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Makhlouf_K/0/1/0/all/0/1\">Karima Makhlouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhioua_S/0/1/0/all/0/1\">Sami Zhioua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1\">Catuscia Palamidessi</a>",
          "description": "Fairness emerged as an important requirement to guarantee that Machine\nLearning (ML) predictive systems do not discriminate against specific\nindividuals or entire sub-populations, in particular, minorities. Given the\ninherent subjectivity of viewing the concept of fairness, several notions of\nfairness have been introduced in the literature. This paper is a survey that\nillustrates the subtleties between fairness notions through a large number of\nexamples and scenarios. In addition, unlike other surveys in the literature, it\naddresses the question of: which notion of fairness is most suited to a given\nreal-world scenario and why? Our attempt to answer this question consists in\n(1) identifying the set of fairness-related characteristics of the real-world\nscenario at hand, (2) analyzing the behavior of each fairness notion, and then\n(3) fitting these two elements to recommend the most suitable fairness notion\nin every specific setup. The results are summarized in a decision diagram that\ncan be used by practitioners and policymakers to navigate the relatively large\ncatalog of ML.",
          "link": "http://arxiv.org/abs/2006.16745",
          "publishedOn": "2022-03-26T00:46:07.091Z",
          "wordCount": null,
          "title": "On the Applicability of ML Fairness Notions. (arXiv:2006.16745v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13038",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ragnarsdottir_H/0/1/0/all/0/1\">Hanna Ragnarsdottir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Manduchi_L/0/1/0/all/0/1\">Laura Manduchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Michel_H/0/1/0/all/0/1\">Holger Michel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Laumer_F/0/1/0/all/0/1\">Fabian Laumer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wellmann_S/0/1/0/all/0/1\">Sven Wellmann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ozkan_E/0/1/0/all/0/1\">Ece Ozkan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vogt_J/0/1/0/all/0/1\">Julia Vogt</a>",
          "description": "Pulmonary hypertension (PH) in newborns and infants is a complex condition\nassociated with several pulmonary, cardiac, and systemic diseases contributing\nto morbidity and mortality. Therefore, accurate and early detection of PH is\ncrucial for successful management. Using echocardiography, the primary\ndiagnostic tool in pediatrics, human assessment is both time-consuming and\nexpertise-demanding, raising the need for an automated approach. In this work,\nwe present an interpretable multi-view video-based deep learning approach to\npredict PH for a cohort of 194 newborns using echocardiograms. We use\nspatio-temporal convolutional architectures for the prediction of PH from each\nview, and aggregate the predictions of the different views using majority\nvoting. To the best of our knowledge, this is the first work for an automated\nassessment of PH in newborns using echocardiograms. Our results show a mean\nF1-score of 0.84 for severity prediction and 0.92 for binary detection using\n10-fold cross-validation. We complement our predictions with saliency maps and\nshow that the learned model focuses on clinically relevant cardiac structures,\nmotivating its usage in clinical practice.",
          "link": "http://arxiv.org/abs/2203.13038",
          "publishedOn": "2022-03-26T00:46:07.089Z",
          "wordCount": null,
          "title": "Interpretable Prediction of Pulmonary Hypertension in Newborns using Echocardiograms. (arXiv:2203.13038v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_N/0/1/0/all/0/1\">Nasir Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schrader_E/0/1/0/all/0/1\">Ellen Schrader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerven_M/0/1/0/all/0/1\">Marcel van Gerven</a>",
          "description": "Learning in biological and artificial neural networks is often framed as a\nproblem in which targeted error signals guide parameter updating for more\noptimal network behaviour. Backpropagation of error (BP) is an example of such\nan approach and has proven to be a highly successful application of stochastic\ngradient descent to deep neural networks. However, BP relies on the global\ntransmission of gradient information and has therefore been criticised for its\nbiological implausibility. We propose constrained parameter inference (COPI) as\na new principle for learning. COPI allows for the estimation of network\nparameters under the constraints of decorrelated neural inputs and top-down\nperturbations of neural states. We show that COPI not only is more biologically\nplausible but also provides distinct advantages for fast learning, compared\nwith standard backpropagation of error.",
          "link": "http://arxiv.org/abs/2203.13203",
          "publishedOn": "2022-03-26T00:46:07.085Z",
          "wordCount": null,
          "title": "Constrained Parameter Inference as a Principle for Learning. (arXiv:2203.13203v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Tao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Shan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bohan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yuxuan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>",
          "description": "Structural re-parameterization (Rep) methods achieve noticeable improvements\non simple VGG-style networks. Despite the prevalence, current Rep methods\nsimply re-parameterize all operations into an augmented network, including\nthose that rarely contribute to the model's performance. As such, the price to\npay is an expensive computational overhead to manipulate these unnecessary\nbehaviors. To eliminate the above caveats, we aim to bootstrap the training\nwith minimal cost by devising a dynamic re-parameterization (DyRep) method,\nwhich encodes Rep technique into the training process that dynamically evolves\nthe network structures. Concretely, our proposal adaptively finds the\noperations which contribute most to the loss in the network, and applies Rep to\nenhance their representational capacity. Besides, to suppress the noisy and\nredundant operations introduced by Rep, we devise a de-parameterization\ntechnique for a more compact re-parameterization. With this regard, DyRep is\nmore efficient than Rep since it smoothly evolves the given network instead of\nconstructing an over-parameterized network. Experimental results demonstrate\nour effectiveness, e.g., DyRep improves the accuracy of ResNet-18 by $2.04\\%$\non ImageNet and reduces $22\\%$ runtime over the baseline. Code is available at:\nhttps://github.com/hunto/DyRep.",
          "link": "http://arxiv.org/abs/2203.12868",
          "publishedOn": "2022-03-26T00:46:07.080Z",
          "wordCount": null,
          "title": "DyRep: Bootstrapping Training with Dynamic Re-parameterization. (arXiv:2203.12868v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.00567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1\">Kai Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1\">Wentong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Michael Ying Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1\">Bodo Rosenhahn</a>",
          "description": "Text-to-image synthesis (T2I) aims to generate photo-realistic images which\nare semantically consistent with the text descriptions. Existing methods are\nusually built upon conditional generative adversarial networks (GANs) and\ninitialize an image from noise with sentence embedding, and then refine the\nfeatures with fine-grained word embedding iteratively. A close inspection of\ntheir generated images reveals a major limitation: even though the generated\nimage holistically matches the description, individual image regions or parts\nof somethings are often not recognizable or consistent with words in the\nsentence, e.g. \"a white crown\". To address this problem, we propose a novel\nframework Semantic-Spatial Aware GAN for synthesizing images from input text.\nConcretely, we introduce a simple and effective Semantic-Spatial Aware block,\nwhich (1) learns semantic-adaptive transformation conditioned on text to\neffectively fuse text features and image features, and (2) learns a semantic\nmask in a weakly-supervised way that depends on the current text-image fusion\nprocess in order to guide the transformation spatially. Experiments on the\nchallenging COCO and CUB bird datasets demonstrate the advantage of our method\nover the recent state-of-the-art approaches, regarding both visual fidelity and\nalignment with input text description.",
          "link": "http://arxiv.org/abs/2104.00567",
          "publishedOn": "2022-03-26T00:46:07.015Z",
          "wordCount": 708,
          "title": "Text to Image Generation with Semantic-Spatial Aware GAN. (arXiv:2104.00567v6 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12852",
          "author": "<a href=\"http://arxiv.org/find/hep-ex/1/au:+Thais_S/0/1/0/all/0/1\">Savannah Thais</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Calafiura_P/0/1/0/all/0/1\">Paolo Calafiura</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Chachamis_G/0/1/0/all/0/1\">Grigorios Chachamis</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+DeZoort_G/0/1/0/all/0/1\">Gage DeZoort</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Duarte_J/0/1/0/all/0/1\">Javier Duarte</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Ganguly_S/0/1/0/all/0/1\">Sanmay Ganguly</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Kagan_M/0/1/0/all/0/1\">Michael Kagan</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Murnane_D/0/1/0/all/0/1\">Daniel Murnane</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Neubauer_M/0/1/0/all/0/1\">Mark S. Neubauer</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Terao_K/0/1/0/all/0/1\">Kazuhiro Terao</a>",
          "description": "Many physical systems can be best understood as sets of discrete data with\nassociated relationships. Where previously these sets of data have been\nformulated as series or image data to match the available machine learning\narchitectures, with the advent of graph neural networks (GNNs), these systems\ncan be learned natively as graphs. This allows a wide variety of high- and\nlow-level physical features to be attached to measurements and, by the same\ntoken, a wide variety of HEP tasks to be accomplished by the same GNN\narchitectures. GNNs have found powerful use-cases in reconstruction, tagging,\ngeneration and end-to-end analysis. With the wide-spread adoption of GNNs in\nindustry, the HEP community is well-placed to benefit from rapid improvements\nin GNN latency and memory usage. However, industry use-cases are not perfectly\naligned with HEP and much work needs to be done to best match unique GNN\ncapabilities to unique HEP obstacles. We present here a range of these\ncapabilities, predictions of which are currently being well-adopted in HEP\ncommunities, and which are still immature. We hope to capture the landscape of\ngraph techniques in machine learning as well as point out the most significant\ngaps that are inhibiting potentially large leaps in research.",
          "link": "http://arxiv.org/abs/2203.12852",
          "publishedOn": "2022-03-26T00:46:07.005Z",
          "wordCount": 671,
          "title": "Graph Neural Networks in Particle Physics: Implementations, Innovations, and Challenges. (arXiv:2203.12852v1 [hep-ex])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Close_G/0/1/0/all/0/1\">George Close</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hain_T/0/1/0/all/0/1\">Thomas Hain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goetze_S/0/1/0/all/0/1\">Stefan Goetze</a>",
          "description": "Training of speech enhancement systems often does not incorporate knowledge\nof human perception and thus can lead to unnatural sounding results.\nIncorporating psychoacoustically motivated speech perception metrics as part of\nmodel training via a predictor network has recently gained interest. However,\nthe performance of such predictors is limited by the distribution of metric\nscores that appear in the training data. In this work, we propose MetricGAN+/-\n(an extension of MetricGAN+, one such metric-motivated system) which introduces\nan additional network - a \"de-generator\" which attempts to improve the\nrobustness of the prediction network (and by extension of the generator) by\nensuring observation of a wider range of metric scores in training.\nExperimental results on the VoiceBank-DEMAND dataset show relative improvement\nin PESQ score of 3.8% (3.05 vs 3.22 PESQ score), as well as better\ngeneralisation to unseen noise and speech.",
          "link": "http://arxiv.org/abs/2203.12369",
          "publishedOn": "2022-03-26T00:46:06.996Z",
          "wordCount": null,
          "title": "MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data. (arXiv:2203.12369v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08411",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chen-Yu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chun-Liang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dozat_T/0/1/0/all/0/1\">Timothy Dozat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perot_V/0/1/0/all/0/1\">Vincent Perot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_G/0/1/0/all/0/1\">Guolong Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_N/0/1/0/all/0/1\">Nan Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1\">Joshua Ainslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Renshen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujii_Y/0/1/0/all/0/1\">Yasuhisa Fujii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>",
          "description": "Sequence modeling has demonstrated state-of-the-art performance on natural\nlanguage and document understanding tasks. However, it is challenging to\ncorrectly serialize tokens in form-like documents in practice due to their\nvariety of layout patterns. We propose FormNet, a structure-aware sequence\nmodel to mitigate the suboptimal serialization of forms. First, we design Rich\nAttention that leverages the spatial relationship between tokens in a form for\nmore precise attention score calculation. Second, we construct Super-Tokens for\neach word by embedding representations from their neighboring tokens through\ngraph convolutions. FormNet therefore explicitly recovers local syntactic\ninformation that may have been lost during serialization. In experiments,\nFormNet outperforms existing methods with a more compact model size and less\npre-training data, establishing new state-of-the-art performance on CORD, FUNSD\nand Payment benchmarks.",
          "link": "http://arxiv.org/abs/2203.08411",
          "publishedOn": "2022-03-26T00:46:06.982Z",
          "wordCount": 610,
          "title": "FormNet: Structural Encoding beyond Sequential Modeling in Form Document Information Extraction. (arXiv:2203.08411v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stember_J/0/1/0/all/0/1\">Joseph Stember</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Young_R/0/1/0/all/0/1\">Robert Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalu_H/0/1/0/all/0/1\">Hrithwik Shalu</a>",
          "description": "Purpose: A core component of advancing cancer treatment research is assessing\nresponse to therapy. Doing so by hand, for example as per RECIST or RANO\ncriteria, is tedious, time-consuming, and can miss important tumor response\ninformation; most notably, they exclude non-target lesions. We wish to assess\nchange in a holistic fashion that includes all lesions, obtaining simple,\ninformative, and automated assessments of tumor progression or regression. Due\nto often low patient enrolments in clinical trials, we wish to make response\nassessments with small training sets. Deep neuroevolution (DNE) can produce\nradiology artificial intelligence (AI) that performs well on small training\nsets. Here we use DNE for function approximation that predicts progression\nversus regression of metastatic brain disease.\n\nMethods: We analyzed 50 pairs of MRI contrast-enhanced images as our training\nset. Half of these pairs, separated in time, qualified as disease progression,\nwhile the other 25 images constituted regression. We trained the parameters of\na relatively small CNN via mutations that consisted of random CNN weight\nadjustments and mutation fitness. We then incorporated the best mutations into\nthe next generations CNN, repeating this process for approximately 50,000\ngenerations. We applied the CNNs to our training set, as well as a separate\ntesting set with the same class balance of 25 progression and 25 regression\nimages.\n\nResults: DNE achieved monotonic convergence to 100% training set accuracy.\nDNE also converged monotonically to 100% testing set accuracy.\n\nConclusion: DNE can accurately classify brain-metastatic disease progression\nversus regression. Future work will extend the input from 2D image slices to\nfull 3D volumes, and include the category of no change. We believe that an\napproach such as our could ultimately provide a useful adjunct to RANO/RECIST\nassessment.",
          "link": "http://arxiv.org/abs/2203.12853",
          "publishedOn": "2022-03-26T00:46:06.970Z",
          "wordCount": null,
          "title": "Direct evaluation of progression or regression of disease burden in brain metastatic disease with Deep Neuroevolution. (arXiv:2203.12853v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stanton_S/0/1/0/all/0/1\">Samuel Stanton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddox_W/0/1/0/all/0/1\">Wesley Maddox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruver_N/0/1/0/all/0/1\">Nate Gruver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maffettone_P/0/1/0/all/0/1\">Phillip Maffettone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delaney_E/0/1/0/all/0/1\">Emily Delaney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenside_P/0/1/0/all/0/1\">Peyton Greenside</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>",
          "description": "Bayesian optimization is a gold standard for query-efficient continuous\noptimization. However, its adoption for drug and antibody sequence design has\nbeen hindered by the discrete, high-dimensional nature of the decision\nvariables. We develop a new approach (LaMBO) which jointly trains a denoising\nautoencoder with a discriminative multi-task Gaussian process head, enabling\ngradient-based optimization of multi-objective acquisition functions in the\nlatent space of the autoencoder. These acquisition functions allow LaMBO to\nbalance the explore-exploit trade-off over multiple design rounds, and to\nbalance objective tradeoffs by optimizing sequences at many different points on\nthe Pareto frontier. We evaluate LaMBO on a small-molecule task based on the\nZINC dataset and introduce a new large-molecule task targeting fluorescent\nproteins. In our experiments, LaMBO outperforms genetic optimizers and does not\nrequire a large pretraining corpus, demonstrating that Bayesian optimization is\npractical and effective for biological sequence design.",
          "link": "http://arxiv.org/abs/2203.12742",
          "publishedOn": "2022-03-26T00:46:06.946Z",
          "wordCount": null,
          "title": "Accelerating Bayesian Optimization for Biological Sequence Design with Denoising Autoencoders. (arXiv:2203.12742v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiawei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chentao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yue Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Ruoxin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xinyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jie Li</a>",
          "description": "Graph Contrastive Learning (GCL) has shown promising performance in graph\nrepresentation learning (GRL) without the supervision of manual annotations.\nGCL can generate graph-level embeddings by maximizing the Mutual Information\n(MI) between different augmented views of the same graph (positive pairs).\nHowever, we identify an obstacle that the optimization of InfoNCE loss only\nconcentrates on a few embeddings dimensions, limiting the distinguishability of\nembeddings in downstream graph classification tasks. This paper proposes an\neffective graph complementary contrastive learning approach named GraphCoCo to\ntackle the above issue. Specifically, we set the embedding of the first\naugmented view as the anchor embedding to localize \"highlighted\" dimensions\n(i.e., the dimensions contribute most in similarity measurement). Then remove\nthese dimensions in the embeddings of the second augmented view to discover\nneglected complementary representations. Therefore, the combination of anchor\nand complementary embeddings significantly improves the performance in\ndownstream tasks. Comprehensive experiments on various benchmark datasets are\nconducted to demonstrate the effectiveness of GraphCoCo, and the results show\nthat our model outperforms the state-of-the-art methods. Source code will be\nmade publicly available.",
          "link": "http://arxiv.org/abs/2203.12821",
          "publishedOn": "2022-03-26T00:46:06.946Z",
          "wordCount": null,
          "title": "GraphCoCo: Graph Complementary Contrastive Learning. (arXiv:2203.12821v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_S/0/1/0/all/0/1\">Shaopeng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_F/0/1/0/all/0/1\">Fengxiang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "The right to be forgotten has been legislated in many countries, but its\nenforcement in the AI industry would cause unbearable costs. When single data\ndeletion requests come, companies may need to delete the whole models learned\nwith massive resources. Existing works propose methods to remove knowledge\nlearned from data for explicitly parameterized models, which however are not\nappliable to the sampling-based Bayesian inference, i.e., Markov chain Monte\nCarlo (MCMC), as MCMC can only infer implicit distributions. In this paper, we\npropose the first machine unlearning algorithm for MCMC. We first convert the\nMCMC unlearning problem into an explicit optimization problem. Based on this\nproblem conversion, an {\\it MCMC influence function} is designed to provably\ncharacterize the learned knowledge from data, which then delivers the MCMC\nunlearning algorithm. Theoretical analysis shows that MCMC unlearning would not\ncompromise the generalizability of the MCMC models. Experiments on Gaussian\nmixture models and Bayesian neural networks confirm the effectiveness of the\nproposed algorithm. The code is available at\n\\url{https://github.com/fshp971/mcmc-unlearning}.",
          "link": "http://arxiv.org/abs/2203.12964",
          "publishedOn": "2022-03-26T00:46:06.945Z",
          "wordCount": null,
          "title": "Knowledge Removal in Sampling-based Bayesian Inference. (arXiv:2203.12964v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lal_M/0/1/0/all/0/1\">Mithun Lal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paproki_A/0/1/0/all/0/1\">Anthony Paproki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habili_N/0/1/0/all/0/1\">Nariman Habili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petersson_L/0/1/0/all/0/1\">Lars Petersson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvado_O/0/1/0/all/0/1\">Olivier Salvado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1\">Clinton Fookes</a>",
          "description": "Estimation of human shape and pose from a single image is a challenging task.\nIt is an even more difficult problem to map the identified human shape onto a\n3D human model. Existing methods map manually labelled human pixels in real 2D\nimages onto the 3D surface, which is prone to human error, and the sparsity of\navailable annotated data often leads to sub-optimal results. We propose to\nsolve the problem of data scarcity by training 2D-3D human mapping algorithms\nusing automatically generated synthetic data for which exact and dense 2D-3D\ncorrespondence is known. Such a learning strategy using synthetic environments\nhas a high generalisation potential towards real-world data. Using different\ncamera parameter variations, background and lighting settings, we created\nprecise ground truth data that constitutes a wider distribution. We evaluate\nthe performance of models trained on synthetic using the COCO dataset and\nvalidation framework. Results show that training 2D-3D mapping network models\non synthetic data is a viable alternative to using real data.",
          "link": "http://arxiv.org/abs/2203.12919",
          "publishedOn": "2022-03-26T00:46:06.944Z",
          "wordCount": 614,
          "title": "Learning Dense Correspondence from Synthetic Environments. (arXiv:2203.12919v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1\">Md Rubel Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hao Zheng</a>",
          "description": "High-quality system-level message flow specifications can lead to\ncomprehensive validation of system-on-chip (SoC) designs. We propose a\ndisruptive method that utilizes an attention mechanism to produce accurate flow\nspecifications from SoC IP communication traces. The proposed method can\novercome the inherent complexity of SoC traces induced by the concurrency and\nparallelism of multicore designs that existing flow specification mining tools\noften find extremely challenging. Experiments on highly interleaved traces show\npromising flow reconstruction compared to several tools dedicated to the flow\nspecification mining problem.",
          "link": "http://arxiv.org/abs/2203.13182",
          "publishedOn": "2022-03-26T00:46:06.935Z",
          "wordCount": 523,
          "title": "Deep Bidirectional Transformers for SoC Flow Specification Mining. (arXiv:2203.13182v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.10973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ko_T/0/1/0/all/0/1\">Taehee Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiantao Li</a>",
          "description": "Non-convex loss functions arise frequently in modern machine learning, and\nfor the theoretical analysis of stochastic optimization methods, the presence\nof non-isolated minima presents a unique challenge that has remained\nunder-explored. In this paper, we study the local convergence of the stochastic\ngradient descent method to non-isolated global minima. Under mild assumptions,\nwe estimate the probability for the iterations to stay near the minima by\nadopting the notion of stochastic stability. After establishing such stability,\nwe present the lower bound complexity in terms of various error criteria for a\ngiven error tolerance $\\epsilon$ and a failure probability $\\gamma$.",
          "link": "http://arxiv.org/abs/2203.10973",
          "publishedOn": "2022-03-26T00:46:06.928Z",
          "wordCount": 574,
          "title": "A Local Convergence Theory for the Stochastic Gradient Descent Method in Non-Convex Optimization With Non-isolated Local Minima. (arXiv:2203.10973v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loog_M/0/1/0/all/0/1\">Marco Loog</a>",
          "description": "We illustrate the detrimental effect, such as overconfident decisions, that\nexponential behavior can have in methods like classical LDA and logistic\nregression. We then show how polynomiality can remedy the situation. This,\namong others, leads purposefully to random-level performance in the tails, away\nfrom the bulk of the training data. A directly related, simple, yet important\ntechnical novelty we subsequently present is softRmax: a reasoned alternative\nto the standard softmax function employed in contemporary (deep) neural\nnetworks. It is derived through linking the standard softmax to Gaussian\nclass-conditional models, as employed in LDA, and replacing those by a\npolynomial alternative. We show that two aspects of softRmax, conservativeness\nand inherent gradient regularization, lead to robustness against adversarial\nattacks without gradient obfuscation.",
          "link": "http://arxiv.org/abs/2203.12693",
          "publishedOn": "2022-03-26T00:46:06.919Z",
          "wordCount": null,
          "title": "Enhancing Classifier Conservativeness and Robustness by Polynomiality. (arXiv:2203.12693v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12621",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chung_H/0/1/0/all/0/1\">Hyungjin Chung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_E/0/1/0/all/0/1\">Eun Sun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Patient scans from MRI often suffer from noise, which hampers the diagnostic\ncapability of such images. As a method to mitigate such artifact, denoising is\nlargely studied both within the medical imaging community and beyond the\ncommunity as a general subject. However, recent deep neural network-based\napproaches mostly rely on the minimum mean squared error (MMSE) estimates,\nwhich tend to produce a blurred output. Moreover, such models suffer when\ndeployed in real-world sitautions: out-of-distribution data, and complex noise\ndistributions that deviate from the usual parametric noise models. In this\nwork, we propose a new denoising method based on score-based reverse diffusion\nsampling, which overcomes all the aforementioned drawbacks. Our network,\ntrained only with coronal knee scans, excels even on out-of-distribution in\nvivo liver MRI data, contaminated with complex mixture of noise. Even more, we\npropose a method to enhance the resolution of the denoised image with the same\nnetwork. With extensive experiments, we show that our method establishes\nstate-of-the-art performance, while having desirable properties which prior\nMMSE denoisers did not have: flexibly choosing the extent of denoising, and\nquantifying uncertainty.",
          "link": "http://arxiv.org/abs/2203.12621",
          "publishedOn": "2022-03-26T00:46:06.916Z",
          "wordCount": null,
          "title": "MR Image Denoising and Super-Resolution Using Regularized Reverse Diffusion. (arXiv:2203.12621v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12677",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hsu_K/0/1/0/all/0/1\">Kyle Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Moo Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rafailov_R/0/1/0/all/0/1\">Rafael Rafailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>",
          "description": "We study how the choice of visual perspective affects learning and\ngeneralization in the context of physical manipulation from raw sensor\nobservations. Compared with the more commonly used global third-person\nperspective, a hand-centric (eye-in-hand) perspective affords reduced\nobservability, but we find that it consistently improves training efficiency\nand out-of-distribution generalization. These benefits hold across a variety of\nlearning algorithms, experimental settings, and distribution shifts, and for\nboth simulated and real robot apparatuses. However, this is only the case when\nhand-centric observability is sufficient; otherwise, including a third-person\nperspective is necessary for learning, but also harms out-of-distribution\ngeneralization. To mitigate this, we propose to regularize the third-person\ninformation stream via a variational information bottleneck. On six\nrepresentative manipulation tasks with varying hand-centric observability\nadapted from the Meta-World benchmark, this results in a state-of-the-art\nreinforcement learning agent operating from both perspectives improving its\nout-of-distribution generalization on every task. While some practitioners have\nlong put cameras in the hands of robots, our work systematically analyzes the\nbenefits of doing so and provides simple and broadly applicable insights for\nimproving end-to-end learned vision-based robotic manipulation.",
          "link": "http://arxiv.org/abs/2203.12677",
          "publishedOn": "2022-03-26T00:46:06.900Z",
          "wordCount": 646,
          "title": "Vision-Based Manipulators Need to Also See from Their Hands. (arXiv:2203.12677v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12620",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dedhiya_R/0/1/0/all/0/1\">Ronak Dedhiya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kakileti_S/0/1/0/all/0/1\">Siva Teja Kakileti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deepu_G/0/1/0/all/0/1\">Goutham Deepu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gopinath_K/0/1/0/all/0/1\">Kanchana Gopinath</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Opoku_N/0/1/0/all/0/1\">Nicholas Opoku</a>, <a href=\"http://arxiv.org/find/eess/1/au:+King_C/0/1/0/all/0/1\">Christopher King</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Manjunath_G/0/1/0/all/0/1\">Geetha Manjunath</a>",
          "description": "Onchocerciasis is causing blindness in over half a million people in the\nworld today. Drug development for the disease is crippled as there is no way of\nmeasuring effectiveness of the drug without an invasive procedure. Drug\nefficacy measurement through assessment of viability of onchocerca worms\nrequires the patients to undergo nodulectomy which is invasive, expensive,\ntime-consuming, skill-dependent, infrastructure dependent and lengthy process.\nIn this paper, we discuss the first-ever study that proposes use of machine\nlearning over thermal imaging to non-invasively and accurately predict the\nviability of worms. The key contributions of the paper are (i) a unique thermal\nimaging protocol along with pre-processing steps such as alignment,\nregistration and segmentation to extract interpretable features (ii) extraction\nof relevant semantic features (iii) development of accurate classifiers for\ndetecting the existence of viable worms in a nodule. When tested on a\nprospective test data of 30 participants with 48 palpable nodules, we achieved\nan Area Under the Curve (AUC) of 0.85.",
          "link": "http://arxiv.org/abs/2203.12620",
          "publishedOn": "2022-03-26T00:46:06.894Z",
          "wordCount": null,
          "title": "Evaluation of Non-Invasive Thermal Imaging for detection of Viability of Onchocerciasis worms. (arXiv:2203.12620v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xiaofei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianlin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qing Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Juefei_Xu_F/0/1/0/all/0/1\">Felix Juefei-Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "Deep learning has recently been widely applied to many applications across\ndifferent domains, e.g., image classification and audio recognition. However,\nthe quality of Deep Neural Networks (DNNs) still raises concerns in the\npractical operational environment, which calls for systematic testing,\nespecially in safety-critical scenarios. Inspired by software testing, a number\nof structural coverage criteria are designed and proposed to measure the test\nadequacy of DNNs. However, due to the blackbox nature of DNN, the existing\nstructural coverage criteria are difficult to interpret, making it hard to\nunderstand the underlying principles of these criteria. The relationship\nbetween the structural coverage and the decision logic of DNNs is unknown.\nMoreover, recent studies have further revealed the non-existence of correlation\nbetween the structural coverage and DNN defect detection, which further posts\nconcerns on what a suitable DNN testing criterion should be.\n\nIn this paper, we propose the interpretable coverage criteria through\nconstructing the decision structure of a DNN. Mirroring the control flow graph\nof the traditional program, we first extract a decision graph from a DNN based\non its interpretation, where a path of the decision graph represents a decision\nlogic of the DNN. Based on the control flow and data flow of the decision\ngraph, we propose two variants of path coverage to measure the adequacy of the\ntest cases in exercising the decision logic. The higher the path coverage, the\nmore diverse decision logic the DNN is expected to be explored. Our large-scale\nevaluation results demonstrate that: the path in the decision graph is\neffective in characterizing the decision of the DNN, and the proposed coverage\ncriteria are also sensitive with errors including natural errors and\nadversarial examples, and strongly correlated with the output impartiality.",
          "link": "http://arxiv.org/abs/2203.12915",
          "publishedOn": "2022-03-26T00:46:06.892Z",
          "wordCount": 756,
          "title": "NPC: Neuron Path Coverage via Characterizing Decision Logic of Deep Neural Networks. (arXiv:2203.12915v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Tejedor_A/0/1/0/all/0/1\">Alvaro J. Garcia-Tejedor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nogales_A/0/1/0/all/0/1\">Alberto Nogales</a>",
          "description": "Organizations have realized the importance of data analysis and its benefits.\nThis in combination with Machine Learning algorithms has allowed to solve\nproblems more easily, making these processes less time-consuming. Neural\nnetworks are the Machine Learning technique that is recently obtaining very\ngood best results. This paper describes an open-source Python library called\nGEMA developed to work with a type of neural network model called\nSelf-Organizing-Maps. GEMA is freely available under GNU General Public License\nat GitHub (https://github.com/ufvceiec/GEMA). The library has been evaluated in\ndifferent a particular use case obtaining accurate results.",
          "link": "http://arxiv.org/abs/2203.13190",
          "publishedOn": "2022-03-26T00:46:06.885Z",
          "wordCount": 532,
          "title": "GEMA: An open-source Python library for self-organizing-maps. (arXiv:2203.13190v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2004.05599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Domingues_O/0/1/0/all/0/1\">Omar Darwiche Domingues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menard_P/0/1/0/all/0/1\">Pierre M&#xe9;nard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pirotta_M/0/1/0/all/0/1\">Matteo Pirotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufmann_E/0/1/0/all/0/1\">Emilie Kaufmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>",
          "description": "We consider the exploration-exploitation dilemma in finite-horizon\nreinforcement learning problems whose state-action space is endowed with a\nmetric. We introduce Kernel-UCBVI, a model-based optimistic algorithm that\nleverages the smoothness of the MDP and a non-parametric kernel estimator of\nthe rewards and transitions to efficiently balance exploration and\nexploitation. For problems with $K$ episodes and horizon $H$, we provide a\nregret bound of $\\widetilde{O}\\left( H^3 K^{\\frac{2d}{2d+1}}\\right)$, where $d$\nis the covering dimension of the joint state-action space. This is the first\nregret bound for kernel-based RL using smoothing kernels, which requires very\nweak assumptions on the MDP and has been previously applied to a wide range of\ntasks. We empirically validate our approach in continuous MDPs with sparse\nrewards.",
          "link": "http://arxiv.org/abs/2004.05599",
          "publishedOn": "2022-03-26T00:46:06.879Z",
          "wordCount": 605,
          "title": "Kernel-Based Reinforcement Learning: A Finite-Time Analysis. (arXiv:2004.05599v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1\">Youming Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yulian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Peng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>",
          "description": "In this paper we investigate the problem of stochastic multi-armed bandits\n(MAB) in the (local) differential privacy (DP/LDP) model. Unlike previous\nresults that assume bounded/sub-Gaussian reward distributions, we focus on the\nsetting where each arm's reward distribution only has $(1+v)$-th moment with\nsome $v\\in (0, 1]$. In the first part, we study the problem in the central\n$\\epsilon$-DP model. We first provide a near-optimal result by developing a\nprivate and robust Upper Confidence Bound (UCB) algorithm. Then, we improve the\nresult via a private and robust version of the Successive Elimination (SE)\nalgorithm. Finally, we establish the lower bound to show that the\ninstance-dependent regret of our improved algorithm is optimal. In the second\npart, we study the problem in the $\\epsilon$-LDP model. We propose an algorithm\nthat can be seen as locally private and robust version of SE algorithm, which\nprovably achieves (near) optimal rates for both instance-dependent and\ninstance-independent regret. Our results reveal differences between the problem\nof private MAB with bounded/sub-Gaussian rewards and heavy-tailed rewards. To\nachieve these (near) optimal rates, we develop several new hard instances and\nprivate robust estimators as byproducts, which might be used to other related\nproblems. Finally, experiments also support our theoretical findings and show\nthe effectiveness of our algorithms.",
          "link": "http://arxiv.org/abs/2106.02575",
          "publishedOn": "2022-03-26T00:46:06.871Z",
          "wordCount": 730,
          "title": "Optimal Rates of (Locally) Differentially Private Heavy-tailed Multi-Armed Bandits. (arXiv:2106.02575v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13088",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1\">Sebastian Hofst&#xe4;tter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khattab_O/0/1/0/all/0/1\">Omar Khattab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Althammer_S/0/1/0/all/0/1\">Sophia Althammer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sertkan_M/0/1/0/all/0/1\">Mete Sertkan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1\">Allan Hanbury</a>",
          "description": "Recent progress in neural information retrieval has demonstrated large gains\nin effectiveness, while often sacrificing the efficiency and interpretability\nof the neural model compared to classical approaches. This paper proposes\nColBERTer, a neural retrieval model using contextualized late interaction\n(ColBERT) with enhanced reduction. Along the effectiveness Pareto frontier,\nColBERTer's reductions dramatically lower ColBERT's storage requirements while\nsimultaneously improving the interpretability of its token-matching scores. To\nthis end, ColBERTer fuses single-vector retrieval, multi-vector refinement, and\noptional lexical matching components into one model. For its multi-vector\ncomponent, ColBERTer reduces the number of stored vectors per document by\nlearning unique whole-word representations for the terms in each document and\nlearning to identify and remove word representations that are not essential to\neffective scoring. We employ an explicit multi-task, multi-stage training to\nfacilitate using very small vector dimensions. Results on the MS MARCO and\nTREC-DL collection show that ColBERTer can reduce the storage footprint by up\nto 2.5x, while maintaining effectiveness. With just one dimension per token in\nits smallest setting, ColBERTer achieves index storage parity with the\nplaintext size, with very strong effectiveness results. Finally, we demonstrate\nColBERTer's robustness on seven high-quality out-of-domain collections,\nyielding statistically significant gains over traditional retrieval baselines.",
          "link": "http://arxiv.org/abs/2203.13088",
          "publishedOn": "2022-03-26T00:46:06.850Z",
          "wordCount": 657,
          "title": "Introducing Neural Bag of Whole-Words with ColBERTer: Contextualized Late Interactions using Enhanced Reduction. (arXiv:2203.13088v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.03820",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Amoukou_S/0/1/0/all/0/1\">Salim I. Amoukou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brunel_N/0/1/0/all/0/1\">Nicolas J-B. Brunel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Salaun_T/0/1/0/all/0/1\">Tangi Sala&#xfc;n</a>",
          "description": "Although Shapley Values (SV) are widely used in explainable AI, they can be\npoorly understood and estimated, implying that their analysis may lead to\nspurious inferences and explanations. As a starting point, we remind an\ninvariance principle for SV and derive the correct approach for computing the\nSV of categorical variables that are particularly sensitive to the encoding\nused. In the case of tree-based models, we introduce two estimators of Shapley\nValues that exploit the tree structure efficiently and are more accurate than\nstate-of-the-art methods. Simulations and comparisons are performed with\nstate-of-the-art algorithms and show the practical gain of our approach.\nFinally, we discuss the ability of SV to provide reliable local explanations.\nWe also provide a Python package that computes our estimators at\nhttps://github.com/salimamoukou/acv00.",
          "link": "http://arxiv.org/abs/2106.03820",
          "publishedOn": "2022-03-26T00:46:06.839Z",
          "wordCount": 611,
          "title": "Accurate Shapley Values for explaining tree-based models. (arXiv:2106.03820v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.09855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_G/0/1/0/all/0/1\">Guojun Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rahul Singh</a>",
          "description": "We study a finite-horizon restless multi-armed bandit problem with multiple\nactions, dubbed R(MA)^2B. The state of each arm evolves according to a\ncontrolled Markov decision process (MDP), and the reward of pulling an arm\ndepends on both the current state of the corresponding MDP and the action\ntaken. The goal is to sequentially choose actions for arms so as to maximize\nthe expected value of the cumulative rewards collected. Since finding the\noptimal policy is typically intractable, we propose a computationally appealing\nindex policy which we call Occupancy-Measured-Reward Index Policy. Our policy\nis well-defined even if the underlying MDPs are not indexable. We prove that it\nis asymptotically optimal when the activation budget and number of arms are\nscaled up, while keeping their ratio as a constant. For the case when the\nsystem parameters are unknown, we develop a learning algorithm. Our learning\nalgorithm uses the principle of optimism in the face of uncertainty and further\nuses a generative model in order to fully exploit the structure of\nOccupancy-Measured-Reward Index Policy. We call it the R(MA)^2B-UCB algorithm.\nAs compared with the existing algorithms, R(MA)^2B-UCB performs close to an\noffline optimum policy, and also achieves a sub-linear regret with a low\ncomputational complexity. Experimental results show that R(MA)^2B-UCB\noutperforms the existing algorithms in both regret and run time.",
          "link": "http://arxiv.org/abs/2109.09855",
          "publishedOn": "2022-03-26T00:46:06.830Z",
          "wordCount": 704,
          "title": "Reinforcement Learning for Finite-Horizon Restless Multi-Armed Multi-Action Bandits. (arXiv:2109.09855v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.00998",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aoudia_F/0/1/0/all/0/1\">Fay&#xe7;al Ait Aoudia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoydis_J/0/1/0/all/0/1\">Jakob Hoydis</a>",
          "description": "We propose a learning-based method for the joint design of a transmit and\nreceive filter, the constellation geometry and associated bit labeling, as well\nas a neural network (NN)-based detector. The method maximizes an achievable\ninformation rate, while simultaneously satisfying constraints on the adjacent\nchannel leakage ratio (ACLR) and peak-to-average power ratio (PAPR). This\nallows control of the tradeoff between spectral containment, peak power, and\ncommunication rate. Evaluation on an additive white Gaussian noise (AWGN)\nchannel shows significant reduction of ACLR and PAPR compared to a conventional\nbaseline relying on quadrature amplitude modulation (QAM) and\nroot-raised-cosine (RRC), without significant loss of information rate. When\nconsidering a 3rd Generation Partnership Project (3GPP) multipath channel, the\nlearned waveform and neural receiver enable competitive or higher rates than an\northogonal frequency division multiplexing (OFDM) baseline, while reducing the\nACLR by 10 dB and the PAPR by 2 dB. The proposed method incurs no additional\ncomplexity on the transmitter side and might be an attractive tool for waveform\ndesign of beyond-5G systems.",
          "link": "http://arxiv.org/abs/2109.00998",
          "publishedOn": "2022-03-26T00:46:06.823Z",
          "wordCount": 646,
          "title": "Waveform Learning for Next-Generation Wireless Communication Systems. (arXiv:2109.00998v3 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_D/0/1/0/all/0/1\">Dongseong Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sim_K/0/1/0/all/0/1\">Khe Chai Sim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Z/0/1/0/all/0/1\">Zhouyuan Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strohman_T/0/1/0/all/0/1\">Trevor Strohman</a>",
          "description": "State-of-the-art automatic speech recognition (ASR) systems are trained with\ntens of thousands of hours of labeled speech data. Human transcription is\nexpensive and time consuming. Factors such as the quality and consistency of\nthe transcription can greatly affect the performance of the ASR models trained\nwith these data. In this paper, we show that we can train a strong teacher\nmodel to produce high quality pseudo labels by utilizing recent self-supervised\nand semi-supervised learning techniques. Specifically, we use JUST (Joint\nUnsupervised/Supervised Training) and iterative noisy student teacher training\nto train a 600 million parameter bi-directional teacher model. This model\nachieved 4.0% word error rate (WER) on a voice search task, 11.1% relatively\nbetter than a baseline. We further show that by using this strong teacher model\nto generate high-quality pseudo labels for training, we can achieve 13.6%\nrelative WER reduction (5.9% to 5.1%) for a streaming model compared to using\nhuman labels.",
          "link": "http://arxiv.org/abs/2203.12668",
          "publishedOn": "2022-03-26T00:46:06.797Z",
          "wordCount": 598,
          "title": "Pseudo Label Is Better Than Human Label. (arXiv:2203.12668v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kobayashi_R/0/1/0/all/0/1\">Ryoma Kobayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukuta_Y/0/1/0/all/0/1\">Yusuke Mukuta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harada_T/0/1/0/all/0/1\">Tatsuya Harada</a>",
          "description": "This study addresses a multiclass learning from label proportions (MCLLP)\nsetting in which training instances are provided in bags and only the\nproportion of each class within the bags is provided. Most existing MCLLP\nmethods impose bag-wise constraints on the prediction of instances or assign\nthem pseudo-labels; however, none of these methods have a theoretical\nconsistency. To solve this problem, a risk-consistent method is proposed for\ninstance classification using the empirical risk minimization framework, and\nits estimation error bound is derived. An approximation method is proposed for\nthe proposed risk estimator, to apply it to large bags, by diverting the\nconstraints on bags in existing research. The proposed method can be applied to\nany deep model or loss and is compatible with stochastic optimization.\nExperiments are conducted on benchmarks to verify the effectiveness of the\nproposed method.",
          "link": "http://arxiv.org/abs/2203.12836",
          "publishedOn": "2022-03-26T00:46:06.787Z",
          "wordCount": 571,
          "title": "Risk Consistent Multi-Class Learning from Label Proportions. (arXiv:2203.12836v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12803",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_A/0/1/0/all/0/1\">Alexandros Shikun Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_N/0/1/0/all/0/1\">Naomi Fengqi Li</a>",
          "description": "COVID-19 pandemic has spread rapidly and caused a shortage of global medical\nresources. The efficiency of COVID-19 diagnosis has become highly significant.\nAs deep learning and convolutional neural network (CNN) has been widely\nutilized and been verified in analyzing medical images, it has become a\npowerful tool for computer-assisted diagnosis. However, there are two most\nsignificant challenges in medical image classification with the help of deep\nlearning and neural networks, one of them is the difficulty of acquiring enough\nsamples, which may lead to model overfitting. Privacy concerns mainly bring the\nother challenge since medical-related records are often deemed patients'\nprivate information and protected by laws such as GDPR and HIPPA. Federated\nlearning can ensure the model training is decentralized on different devices\nand no data is shared among them, which guarantees privacy. However, with data\nlocated on different devices, the accessible data of each device could be\nlimited. Since transfer learning has been verified in dealing with limited data\nwith good performance, therefore, in this paper, We made a trial to implement\nfederated learning and transfer learning techniques using CNNs to classify\nCOVID-19 using lung CT scans. We also explored the impact of dataset\ndistribution at the client-side in federated learning and the number of\ntraining epochs a model is trained. Finally, we obtained very high performance\nwith federated learning, demonstrating our success in leveraging accuracy and\nprivacy.",
          "link": "http://arxiv.org/abs/2203.12803",
          "publishedOn": "2022-03-26T00:46:06.781Z",
          "wordCount": 761,
          "title": "When Accuracy Meets Privacy: Two-Stage Federated Transfer Learning Framework in Classification of Medical Images on Limited Data: A COVID-19 Case Study. (arXiv:2203.12803v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yizhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>",
          "description": "Transformer has brought great success to a wide range of natural language\nprocessing tasks. Nevertheless, the computational overhead of the vanilla\ntransformer scales quadratically with sequence length. Many efforts have been\nmade to develop more efficient transformer variants. A line of work (e.g.,\nLinformer) projects the input sequence into a low-rank space, achieving linear\ntime complexity. However, Linformer does not suit well for text generation\ntasks as the sequence length must be pre-specified. We propose MemSizer, an\napproach also projects the source sequence into lower dimension representation\nbut can take input with dynamic length, with a different perspective of the\nattention mechanism. MemSizer not only achieves the same linear time complexity\nbut also enjoys efficient recurrent-style autoregressive generation, which\nyields constant memory complexity and reduced computation at inference. We\ndemonstrate that MemSizer provides an improved tradeoff between efficiency and\naccuracy over the vanilla transformer and other linear variants in language\nmodeling and machine translation tasks, revealing a viable direction towards\nfurther inference efficiency improvement.",
          "link": "http://arxiv.org/abs/2203.12644",
          "publishedOn": "2022-03-26T00:46:06.774Z",
          "wordCount": 599,
          "title": "Linearizing Transformer with Key-Value Memory Bank. (arXiv:2203.12644v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Jun-Gi Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_U/0/1/0/all/0/1\">U Kang</a>",
          "description": "Given an irregular dense tensor, how can we efficiently analyze it? An\nirregular tensor is a collection of matrices whose columns have the same size\nand rows have different sizes from each other. PARAFAC2 decomposition is a\nfundamental tool to deal with an irregular tensor in applications including\nphenotype discovery and trend analysis. Although several PARAFAC2 decomposition\nmethods exist, their efficiency is limited for irregular dense tensors due to\nthe expensive computations involved with the tensor. In this paper, we propose\nDPar2, a fast and scalable PARAFAC2 decomposition method for irregular dense\ntensors. DPar2 achieves high efficiency by effectively compressing each slice\nmatrix of a given irregular tensor, careful reordering of computations with the\ncompression results, and exploiting the irregularity of the tensor. Extensive\nexperiments show that DPar2 is up to 6.0x faster than competitors on real-world\nirregular tensors while achieving comparable accuracy. In addition, DPar2 is\nscalable with respect to the tensor size and target rank.",
          "link": "http://arxiv.org/abs/2203.12798",
          "publishedOn": "2022-03-26T00:46:06.768Z",
          "wordCount": 615,
          "title": "DPar2: Fast and Scalable PARAFAC2 Decomposition for Irregular Dense Tensors. (arXiv:2203.12798v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1\">Aastha Acharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_R/0/1/0/all/0/1\">Rebecca Russell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1\">Nisar R. Ahmed</a>",
          "description": "For autonomous agents to act as trustworthy partners to human users, they\nmust be able to reliably communicate their competency for the tasks they are\nasked to perform. Towards this objective, we develop probabilistic world models\nbased on deep generative modelling that allow for the simulation of agent\ntrajectories and accurate calculation of tasking outcome probabilities. By\ncombining the strengths of conditional variational autoencoders with recurrent\nneural networks, the deep generative world model can probabilistically forecast\ntrajectories over long horizons to task completion. We show how these\nforecasted trajectories can be used to calculate outcome probability\ndistributions, which enable the precise assessment of agent competency for\nspecific tasks and initial settings.",
          "link": "http://arxiv.org/abs/2203.12670",
          "publishedOn": "2022-03-26T00:46:06.748Z",
          "wordCount": 562,
          "title": "Competency Assessment for Autonomous Agents using Deep Generative Models. (arXiv:2203.12670v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12634",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Rosofsky_S/0/1/0/all/0/1\">Shawn G. Rosofsky</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Huerta_E/0/1/0/all/0/1\">E. A. Huerta</a>",
          "description": "We present an end-to-end framework to learn partial differential equations\nthat brings together initial data production, selection of boundary conditions,\nand the use of physics-informed neural operators to solve partial differential\nequations that are ubiquitous in the study and modeling of physics phenomena.\nWe first demonstrate that our methods reproduce the accuracy and performance of\nother neural operators published elsewhere in the literature to learn the 1D\nwave equation and the 1D Burgers equation. Thereafter, we apply our\nphysics-informed neural operators to learn new types of equations, including\nthe 2D Burgers equation in the scalar, inviscid and vector types. Finally, we\nshow that our approach is also applicable to learn the physics of the 2D linear\nand nonlinear shallow water equations, which involve three coupled partial\ndifferential equations. We release our artificial intelligence surrogates and\nscientific software to produce initial data and boundary conditions to study a\nbroad range of physically motivated scenarios. We provide the source code, an\ninteractive website to visualize the predictions of our physics informed neural\noperators, and a tutorial for their use at the Data and Learning Hub for\nScience.",
          "link": "http://arxiv.org/abs/2203.12634",
          "publishedOn": "2022-03-26T00:46:06.741Z",
          "wordCount": 641,
          "title": "Applications of physics informed neural operators. (arXiv:2203.12634v1 [physics.comp-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12674",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hongda Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasehzadeh_A/0/1/0/all/0/1\">Ali Nasehzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Ping Wang</a>",
          "description": "The Internet of Things (IoT) has been continuously rising in the past few\nyears, and its potentials are now more apparent. However, transient data\ngeneration and limited energy resources are the major bottlenecks of these\nnetworks. Besides, minimum delay and other conventional quality of service\nmeasurements are still valid requirements to meet. An efficient caching policy\ncan help meet the standard quality of service requirements while bypassing IoT\nnetworks' specific limitations. Adopting deep reinforcement learning (DRL)\nalgorithms enables us to develop an effective caching scheme without the need\nfor any prior knowledge or contextual information. In this work, we propose a\nDRL-based caching scheme that improves the cache hit rate and reduces energy\nconsumption of the IoT networks, in the meanwhile, taking data freshness and\nlimited lifetime of IoT data into account. To better capture the\nregional-different popularity distribution, we propose a hierarchical\narchitecture to deploy edge caching nodes in IoT networks. The results of\ncomprehensive experiments show that our proposed method outperforms the\nwell-known conventional caching policies and an existing DRL-based solution in\nterms of cache hit rate and energy consumption of the IoT networks by\nconsiderable margins.",
          "link": "http://arxiv.org/abs/2203.12674",
          "publishedOn": "2022-03-26T00:46:06.726Z",
          "wordCount": 635,
          "title": "A Deep Reinforcement Learning-Based Caching Strategy for IoT Networks with Transient Data. (arXiv:2203.12674v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12720",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+McCarter_C/0/1/0/all/0/1\">Calvin McCarter</a>",
          "description": "Current domain adaptation methods address the problems of covariate shift or\nlabel shift, but are not applicable to the setting where they occur\nsimultaneously and interact with each other. In this paper, we propose an\nassumption, confounded shift, to begin to address this problem. We also propose\na framework for this task, based on minimizing the expected divergence between\nthe source and target conditional distributions. Within this framework, we\npropose using the reverse KL divergence, demonstrating the use of both\nparametric linear Gaussian and nonparametric nonlinear Gaussian Process\nestimators of the conditional distribution. We also propose using the Maximum\nMean Discrepancy (MMD) within our framework. To make confounded domain\nadaptation with the MMD effective, we propose an intelligent dynamic strategy\nfor choosing the kernel bandwidth, which may be of independent interest even\noutside of the confounded shift context. Finally, we show that our approach is\nadvantageous on a variety of synthetic and real datasets.",
          "link": "http://arxiv.org/abs/2203.12720",
          "publishedOn": "2022-03-26T00:46:06.705Z",
          "wordCount": 580,
          "title": "Towards All-Purpose Domain Adaptation Under Confounding. (arXiv:2203.12720v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12715",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1\">Sangwoo Park</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Simeone_O/0/1/0/all/0/1\">Osvaldo Simeone</a>",
          "description": "An efficient data-driven prediction strategy for multi-antenna\nfrequency-selective channels must operate based on a small number of pilot\nsymbols. This paper proposes novel channel prediction algorithms that address\nthis goal by integrating transfer and meta-learning with a reduced-rank\nparametrization of the channel. The proposed methods optimize linear predictors\nby utilizing data from previous frames, which are generally characterized by\ndistinct propagation characteristics, in order to enable fast training on the\ntime slots of the current frame. The proposed predictors rely on a novel\nlong-short-term decomposition (LSTD) of the linear prediction model that\nleverages the disaggregation of the channel into long-term space-time\nsignatures and fading amplitudes. We first develop predictors for\nsingle-antenna frequency-flat channels based on transfer/meta-learned quadratic\nregularization. Then, we introduce transfer and meta-learning algorithms for\nLSTD-based prediction models that build on equilibrium propagation (EP) and\nalternating least squares (ALS). Numerical results under the 3GPP 5G standard\nchannel model demonstrate the impact of transfer and meta-learning on reducing\nthe number of pilots for channel prediction, as well as the merits of the\nproposed LSTD parametrization.",
          "link": "http://arxiv.org/abs/2203.12715",
          "publishedOn": "2022-03-26T00:46:06.686Z",
          "wordCount": 637,
          "title": "Predicting Multi-Antenna Frequency-Selective Channels via Meta-Learned Linear Filters based on Long-Short Term Channel Decomposition. (arXiv:2203.12715v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12758",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zadeh_A/0/1/0/all/0/1\">Ali Hadi Zadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmoud_M/0/1/0/all/0/1\">Mostafa Mahmoud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelhadi_A/0/1/0/all/0/1\">Ameer Abdelhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moshovos_A/0/1/0/all/0/1\">Andreas Moshovos</a>",
          "description": "Increasingly larger and better Transformer models keep advancing\nstate-of-the-art accuracy and capability for Natural Language Processing\napplications. These models demand more computational power, storage, and\nenergy. Mokey reduces the footprint of state-of-the-art 32-bit or 16-bit\nfloating-point transformer models by quantizing all values to 4-bit indexes\ninto dictionaries of representative 16-bit fixed-point centroids. Mokey does\nnot need fine-tuning, an essential feature as often the training resources or\ndatasets are not available to many. Exploiting the range of values that\nnaturally occur in transformer models, Mokey selects centroid values to also\nfit an exponential curve. This unique feature enables Mokey to replace the bulk\nof the original multiply-accumulate operations with narrow 3b fixed-point\nadditions resulting in an area- and energy-efficient hardware accelerator\ndesign. Over a set of state-of-the-art transformer models, the Mokey\naccelerator delivers an order of magnitude improvements in energy efficiency\nover a Tensor Cores-based accelerator while improving performance by at least\n$4\\times$ and as much as $15\\times$ depending on the model and on-chip\nbuffering capacity. Optionally, Mokey can be used as a memory compression\nassist for any other accelerator, transparently stashing wide floating-point or\nfixed-point activations or weights into narrow 4-bit indexes. Mokey proves\nsuperior to prior state-of-the-art quantization methods for Transformers.",
          "link": "http://arxiv.org/abs/2203.12758",
          "publishedOn": "2022-03-26T00:46:06.677Z",
          "wordCount": 670,
          "title": "Mokey: Enabling Narrow Fixed-Point Inference for Out-of-the-Box Floating-Point Transformer Models. (arXiv:2203.12758v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jing Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefani_E/0/1/0/all/0/1\">Eliana Stefani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomason_J/0/1/0/all/0/1\">Jesse Thomason</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>",
          "description": "A long-term goal of AI research is to build intelligent agents that can\ncommunicate with humans in natural language, perceive the environment, and\nperform real-world tasks. Vision-and-Language Navigation (VLN) is a fundamental\nand interdisciplinary research topic towards this goal, and receives increasing\nattention from natural language processing, computer vision, robotics, and\nmachine learning communities. In this paper, we review contemporary studies in\nthe emerging field of VLN, covering tasks, evaluation metrics, methods, etc.\nThrough structured analysis of current progress and challenges, we highlight\nthe limitations of current VLN and opportunities for future work. This paper\nserves as a thorough reference for the VLN research community.",
          "link": "http://arxiv.org/abs/2203.12667",
          "publishedOn": "2022-03-26T00:46:06.664Z",
          "wordCount": 571,
          "title": "Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions. (arXiv:2203.12667v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Purushwalkam_S/0/1/0/all/0/1\">Senthil Purushwalkam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morgado_P/0/1/0/all/0/1\">Pedro Morgado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhinav Gupta</a>",
          "description": "Self-supervised learning (SSL) aims to eliminate one of the major bottlenecks\nin representation learning - the need for human annotations. As a result, SSL\nholds the promise to learn representations from data in-the-wild, i.e., without\nthe need for finite and static datasets. Instead, true SSL algorithms should be\nable to exploit the continuous stream of data being generated on the internet\nor by agents exploring their environments. But do traditional self-supervised\nlearning approaches work in this setup? In this work, we investigate this\nquestion by conducting experiments on the continuous self-supervised learning\nproblem. While learning in the wild, we expect to see a continuous (infinite)\nnon-IID data stream that follows a non-stationary distribution of visual\nconcepts. The goal is to learn a representation that can be robust, adaptive\nyet not forgetful of concepts seen in the past. We show that a direct\napplication of current methods to such continuous setup is 1) inefficient both\ncomputationally and in the amount of data required, 2) leads to inferior\nrepresentations due to temporal correlations (non-IID data) in some sources of\nstreaming data and 3) exhibits signs of catastrophic forgetting when trained on\nsources with non-stationary data distributions. We propose the use of replay\nbuffers as an approach to alleviate the issues of inefficiency and temporal\ncorrelations. We further propose a novel method to enhance the replay buffer by\nmaintaining the least redundant samples. Minimum redundancy (MinRed) buffers\nallow us to learn effective representations even in the most challenging\nstreaming scenarios composed of sequential visual data obtained from a single\nembodied agent, and alleviates the problem of catastrophic forgetting when\nlearning from data with non-stationary semantic distributions.",
          "link": "http://arxiv.org/abs/2203.12710",
          "publishedOn": "2022-03-26T00:46:06.657Z",
          "wordCount": 709,
          "title": "The Challenges of Continuous Self-Supervised Learning. (arXiv:2203.12710v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.09478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parunandi_K/0/1/0/all/0/1\">Karthikeya S. Parunandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Aayushman Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_R/0/1/0/all/0/1\">Raman Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravorty_S/0/1/0/all/0/1\">Suman Chakravorty</a>",
          "description": "The problem of Reinforcement Learning (RL) in an unknown nonlinear dynamical\nsystem is equivalent to the search for an optimal feedback law utilizing the\nsimulations/ rollouts of the dynamical system. Most RL techniques search over a\ncomplex global nonlinear feedback parametrization making them suffer from high\ntraining times as well as variance. Instead, we advocate searching over a local\nfeedback representation consisting of an open-loop sequence, and an associated\noptimal linear feedback law completely determined by the open-loop. We show\nthat this alternate approach results in highly efficient training, the answers\nobtained are repeatable and hence reliable, and the resulting closed\nperformance is superior to global state-of-the-art RL techniques. Finally, if\nwe replan, whenever required, which is feasible due to the fast and reliable\nlocal solution, it allows us to recover global optimality of the resulting\nfeedback law.",
          "link": "http://arxiv.org/abs/2002.09478",
          "publishedOn": "2022-03-26T00:46:06.644Z",
          "wordCount": null,
          "title": "On the Search for Feedback in Reinforcement Learning. (arXiv:2002.09478v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dullerud_N/0/1/0/all/0/1\">Natalie Dullerud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Karsten Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamidieh_K/0/1/0/all/0/1\">Kimia Hamidieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1\">Nicolas Papernot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Marzyeh Ghassemi</a>",
          "description": "Deep metric learning (DML) enables learning with less supervision through its\nemphasis on the similarity structure of representations. There has been much\nwork on improving generalization of DML in settings like zero-shot retrieval,\nbut little is known about its implications for fairness. In this paper, we are\nthe first to evaluate state-of-the-art DML methods trained on imbalanced data,\nand to show the negative impact these representations have on minority subgroup\nperformance when used for downstream tasks. In this work, we first define\nfairness in DML through an analysis of three properties of the representation\nspace -- inter-class alignment, intra-class alignment, and uniformity -- and\npropose finDML, the fairness in non-balanced DML benchmark to characterize\nrepresentation fairness. Utilizing finDML, we find bias in DML representations\nto propagate to common downstream classification tasks. Surprisingly, this bias\nis propagated even when training data in the downstream task is re-balanced. To\naddress this problem, we present Partial Attribute De-correlation (PARADE) to\nde-correlate feature representations from sensitive attributes and reduce\nperformance gaps between subgroups in both embedding space and downstream\nmetrics.",
          "link": "http://arxiv.org/abs/2203.12748",
          "publishedOn": "2022-03-26T00:46:06.642Z",
          "wordCount": 646,
          "title": "Is Fairness Only Metric Deep? Evaluating and Addressing Subgroup Gaps in Deep Metric Learning. (arXiv:2203.12748v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heo_S/0/1/0/all/0/1\">Seong-Hwan Heo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1\">WonKee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jong-Hyeok Lee</a>",
          "description": "Zero-shot slot filling has received considerable attention to cope with the\nproblem of limited available data for the target domain. One of the important\nfactors in zero-shot learning is to make the model learn generalized and\nreliable representations. For this purpose, we present mcBERT, which stands for\nmomentum contrastive learning with BERT, to develop a robust zero-shot slot\nfilling model. mcBERT uses BERT to initialize the two encoders, the query\nencoder and key encoder, and is trained by applying momentum contrastive\nlearning. Our experimental results on the SNIPS benchmark show that mcBERT\nsubstantially outperforms the previous models, recording a new\nstate-of-the-art. Besides, we also show that each component composing mcBERT\ncontributes to the performance improvement.",
          "link": "http://arxiv.org/abs/2203.12940",
          "publishedOn": "2022-03-26T00:46:06.624Z",
          "wordCount": null,
          "title": "mcBERT: Momentum Contrastive Learning with BERT for Zero-Shot Slot Filling. (arXiv:2203.12940v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07191",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yejia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingjing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_X/0/1/0/all/0/1\">Xiaomin Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yiru Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yunxia Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danny Z. Chen</a>",
          "description": "With rising male infertility, sperm head morphology classification becomes\ncritical for accurate and timely clinical diagnosis. Recent deep learning (DL)\nmorphology analysis methods achieve promising benchmark results, but leave\nperformance and robustness on the table by relying on limited and possibly\nnoisy class labels. To address this, we introduce a new DL training framework\nthat leverages anatomical and image priors from human sperm microscopy crops to\nextract useful features without additional labeling cost. Our core idea is to\ndistill sperm head information with reliably-generated pseudo-masks and\nunsupervised spatial prediction tasks. The predicted foreground masks from this\ndistillation step are then leveraged to regularize and reduce image and label\nnoise in the tuning stage. We evaluate our new approach on two public sperm\ndatasets and achieve state-of-the-art performances (e.g. 65.9% SCIAN accuracy\nand 96.5% HuSHeM accuracy).",
          "link": "http://arxiv.org/abs/2202.07191",
          "publishedOn": "2022-03-20T00:45:06.506Z",
          "wordCount": 620,
          "title": "Improving Human Sperm Head Morphology Classification with Unsupervised Anatomical Feature Distillation. (arXiv:2202.07191v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.07933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zuoguang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yimo Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongsong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Limin Sun</a>",
          "description": "This paper explores the threat detection for general Social Engineering (SE)\nattack using Machine Learning (ML) techniques, rather than focusing on or\nlimited to a specific SE attack type, e.g. email phishing. Firstly, this paper\nprocesses and obtains more SE threat data from the previous Knowledge Graph\n(KG), and then extracts different threat features and generates new datasets\ncorresponding with three different feature combinations. Finally, 9 types of ML\nmodels are created and trained using the three datasets, respectively, and\ntheir performance are compared and analyzed with 27 threat detectors and 270\ntimes of experiments. The experimental results and analyses show that: 1) the\nML techniques are feasible in detecting general SE attacks and some ML models\nare quite effective; ML-based SE threat detection is complementary with\nKG-based approaches; 2) the generated datasets are usable and the SE domain\nontology proposed in previous work can dissect SE attacks and deliver the SE\nthreat features, allowing it to be used as a data model for future research.\nBesides, more conclusions and analyses about the characteristics of different\nML detectors and the datasets are discussed.",
          "link": "http://arxiv.org/abs/2203.07933",
          "publishedOn": "2022-03-19T00:42:49.469Z",
          "wordCount": 643,
          "title": "Threat Detection for General Social Engineering Attack Using Machine Learning Techniques. (arXiv:2203.07933v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumder_S/0/1/0/all/0/1\">Sahisnu Mazumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robertson_E/0/1/0/all/0/1\">Eric Robertson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grigsby_S/0/1/0/all/0/1\">Scott Grigsby</a>",
          "description": "As more and more AI agents are used in practice, it is time to think about\nhow to make these agents fully autonomous so that they can (1) learn by\nthemselves continually in a self-motivated and self-initiated manner rather\nthan being retrained offline periodically on the initiation of human engineers\nand (2) accommodate or adapt to unexpected or novel circumstances. As the\nreal-world is an open environment that is full of unknowns or novelties,\ndetecting novelties, characterizing them, accommodating or adapting to them,\nand gathering ground-truth training data and incrementally learning the\nunknowns/novelties are critical to making the AI agent more and more\nknowledgeable and powerful over time. The key challenge is how to automate the\nprocess so that it is carried out continually on the agent's own initiative and\nthrough its own interactions with humans, other agents and the environment just\nlike human on-the-job learning. This paper proposes a framework (called SOLA)\nfor this learning paradigm to promote the research of building autonomous and\ncontinual learning enabled AI agents. To show feasibility, an implemented agent\nis also described.",
          "link": "http://arxiv.org/abs/2203.08994",
          "publishedOn": "2022-03-19T00:42:49.462Z",
          "wordCount": 623,
          "title": "AI Autonomy: Self-Initiation, Adaptation and Continual Learning. (arXiv:2203.08994v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.04706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balunovic_M/0/1/0/all/0/1\">Mislav Balunovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitrov_D/0/1/0/all/0/1\">Dimitar I. Dimitrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staab_R/0/1/0/all/0/1\">Robin Staab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Federated learning is an established method for training machine learning\nmodels without sharing training data. However, recent work has shown that it\ncannot guarantee data privacy as shared gradients can still leak sensitive\ninformation. To formalize the problem of gradient leakage, we propose a\ntheoretical framework that enables, for the first time, analysis of the Bayes\noptimal adversary phrased as an optimization problem. We demonstrate that\nexisting leakage attacks can be seen as approximations of this optimal\nadversary with different assumptions on the probability distributions of the\ninput data and gradients. Our experiments confirm the effectiveness of the\nBayes optimal adversary when it has knowledge of the underlying distribution.\nFurther, our experimental evaluation shows that several existing heuristic\ndefenses are not effective against stronger attacks, especially early in the\ntraining process. Thus, our findings indicate that the construction of more\neffective defenses and their evaluation remains an open problem.",
          "link": "http://arxiv.org/abs/2111.04706",
          "publishedOn": "2022-03-19T00:42:49.456Z",
          "wordCount": 608,
          "title": "Bayesian Framework for Gradient Leakage. (arXiv:2111.04706v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.05146",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Stark_H/0/1/0/all/0/1\">Hannes St&#xe4;rk</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ganea_O/0/1/0/all/0/1\">Octavian-Eugen Ganea</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Pattanaik_L/0/1/0/all/0/1\">Lagnajit Pattanaik</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Barzilay_R/0/1/0/all/0/1\">Regina Barzilay</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi Jaakkola</a>",
          "description": "Predicting how a drug-like molecule binds to a specific protein target is a\ncore problem in drug discovery. An extremely fast computational binding method\nwould enable key applications such as fast virtual screening or drug\nengineering. Existing methods are computationally expensive as they rely on\nheavy candidate sampling coupled with scoring, ranking, and fine-tuning steps.\nWe challenge this paradigm with EquiBind, an SE(3)-equivariant geometric deep\nlearning model performing direct-shot prediction of both i) the receptor\nbinding location (blind docking) and ii) the ligand's bound pose and\norientation. EquiBind achieves significant speed-ups and better quality\ncompared to traditional and recent baselines. Further, we show extra\nimprovements when coupling it with existing fine-tuning techniques at the cost\nof increased running time. Finally, we propose a novel and fast fine-tuning\nmodel that adjusts torsion angles of a ligand's rotatable bonds based on\nclosed-form global minima of the von Mises angular distance to a given input\natomic point cloud, avoiding previous expensive differential evolution\nstrategies for energy minimization.",
          "link": "http://arxiv.org/abs/2202.05146",
          "publishedOn": "2022-03-19T00:42:49.438Z",
          "wordCount": 628,
          "title": "EquiBind: Geometric Deep Learning for Drug Binding Structure Prediction. (arXiv:2202.05146v2 [q-bio.BM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.07138",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shulei Wang</a>",
          "description": "Self-supervised metric learning has been a successful approach for learning a\ndistance from an unlabeled dataset. The resulting distance is broadly useful\nfor improving various distance-based downstream tasks, even when no information\nfrom downstream tasks is utilized in the metric learning stage. To gain\ninsights into this approach, we develop a statistical framework to\ntheoretically study how self-supervised metric learning can benefit downstream\ntasks in the context of multi-view data. Under this framework, we show that the\ntarget distance of metric learning satisfies several desired properties for the\ndownstream tasks. On the other hand, our investigation suggests the target\ndistance can be further improved by moderating each direction's weights. In\naddition, our analysis precisely characterizes the improvement by\nself-supervised metric learning on four commonly used downstream tasks: sample\nidentification, two-sample testing, $k$-means clustering, and $k$-nearest\nneighbor classification. When the distance is estimated from an unlabeled\ndataset, we establish the upper bound on distance estimation's accuracy and the\nnumber of samples sufficient for downstream task improvement. Finally,\nnumerical experiments are presented to support the theoretical results in the\npaper.",
          "link": "http://arxiv.org/abs/2106.07138",
          "publishedOn": "2022-03-19T00:42:49.431Z",
          "wordCount": 657,
          "title": "Self-Supervised Metric Learning in Multi-View Data: A Downstream Task Perspective. (arXiv:2106.07138v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Way_E/0/1/0/all/0/1\">Elliot Way</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapilivai_D/0/1/0/all/0/1\">Dheeraj S.K. Kapilivai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yiwei Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lei Yu</a>",
          "description": "We introduce Backpropagation Through Time and Space (BPTTS), a method for\ntraining a recurrent spatio-temporal neural network, that is used in a\nhomogeneous multi-agent reinforcement learning (MARL) setting to learn\nnumerical methods for hyperbolic conservation laws. We treat the numerical\nschemes underlying partial differential equations (PDEs) as a Partially\nObservable Markov Game (POMG) in Reinforcement Learning (RL). Similar to\nnumerical solvers, our agent acts at each discrete location of a computational\nspace for efficient and generalizable learning. To learn higher-order spatial\nmethods by acting on local states, the agent must discern how its actions at a\ngiven spatiotemporal location affect the future evolution of the state. The\nmanifestation of this non-stationarity is addressed by BPTTS, which allows for\nthe flow of gradients across both space and time. The learned numerical\npolicies are comparable to the SOTA numerics in two settings, the Burgers'\nEquation and the Euler Equations, and generalize well to other simulation\nset-ups.",
          "link": "http://arxiv.org/abs/2203.08937",
          "publishedOn": "2022-03-19T00:42:49.424Z",
          "wordCount": 605,
          "title": "Backpropagation through Time and Space: Learning Numerical Methods with Multi-Agent Reinforcement Learning. (arXiv:2203.08937v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09410",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Holzmuller_D/0/1/0/all/0/1\">David Holzm&#xfc;ller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zaverkin_V/0/1/0/all/0/1\">Viktor Zaverkin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kastner_J/0/1/0/all/0/1\">Johannes K&#xe4;stner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steinwart_I/0/1/0/all/0/1\">Ingo Steinwart</a>",
          "description": "We study the performance of different pool-based Batch Mode Deep Active\nLearning (BMDAL) methods for regression on tabular data, focusing on methods\nthat do not require to modify the network architecture and training. Our\ncontributions are three-fold: First, we present a framework for constructing\nBMDAL methods out of kernels, kernel transformations and selection methods,\nshowing that many of the most popular BMDAL methods fit into our framework.\nSecond, we propose new components, leading to a new BMDAL method. Third, we\nintroduce an open-source benchmark with 15 large tabular data sets, which we\nuse to compare different BMDAL methods. Our benchmark results show that a\ncombination of our novel components yields new state-of-the-art results in\nterms of RMSE and is computationally efficient. We provide open-source code\nthat includes efficient implementations of all kernels, kernel transformations,\nand selection methods, and can be used for reproducing our results.",
          "link": "http://arxiv.org/abs/2203.09410",
          "publishedOn": "2022-03-19T00:42:49.418Z",
          "wordCount": 604,
          "title": "A Framework and Benchmark for Deep Batch Active Learning for Regression. (arXiv:2203.09410v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tirinzoni_A/0/1/0/all/0/1\">Andrea Tirinzoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Marjani_A/0/1/0/all/0/1\">Aymen Al-Marjani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufmann_E/0/1/0/all/0/1\">Emilie Kaufmann</a>",
          "description": "In probably approximately correct (PAC) reinforcement learning (RL), an agent\nis required to identify an $\\epsilon$-optimal policy with probability\n$1-\\delta$. While minimax optimal algorithms exist for this problem, its\ninstance-dependent complexity remains elusive in episodic Markov decision\nprocesses (MDPs). In this paper, we propose the first (nearly) matching upper\nand lower bounds on the sample complexity of PAC RL in deterministic episodic\nMDPs with finite state and action spaces. In particular, our bounds feature a\nnew notion of sub-optimality gap for state-action pairs that we call the\ndeterministic return gap. While our instance-dependent lower bound is written\nas a linear program, our algorithms are very simple and do not require solving\nsuch an optimization problem during learning. Their design and analyses employ\nnovel ideas, including graph-theoretical concepts such as minimum flows and\nmaximum cuts, which we believe to shed new light on this problem.",
          "link": "http://arxiv.org/abs/2203.09251",
          "publishedOn": "2022-03-19T00:42:49.412Z",
          "wordCount": 580,
          "title": "Near Instance-Optimal PAC Reinforcement Learning for Deterministic MDPs. (arXiv:2203.09251v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09324",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mo_S/0/1/0/all/0/1\">Shentong Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morgado_P/0/1/0/all/0/1\">Pedro Morgado</a>",
          "description": "Unsupervised audio-visual source localization aims at localizing visible\nsound sources in a video without relying on ground-truth localization for\ntraining. Previous works often seek high audio-visual similarities for likely\npositive (sounding) regions and low similarities for likely negative regions.\nHowever, accurately distinguishing between sounding and non-sounding regions is\nchallenging without manual annotations. In this work, we propose a simple yet\neffective approach for Easy Visual Sound Localization, namely EZ-VSL, without\nrelying on the construction of positive and/or negative regions during\ntraining. Instead, we align audio and visual spaces by seeking audio-visual\nrepresentations that are aligned in, at least, one location of the associated\nimage, while not matching other images, at any location. We also introduce a\nnovel object guided localization scheme at inference time for improved\nprecision. Our simple and effective framework achieves state-of-the-art\nperformance on two popular benchmarks, Flickr SoundNet and VGG-Sound Source. In\nparticular, we improve the CIoU of the Flickr SoundNet test set from 76.80% to\n83.94%, and on the VGG-Sound Source dataset from 34.60% to 38.85%. The code is\navailable at https://github.com/stoneMo/EZ-VSL.",
          "link": "http://arxiv.org/abs/2203.09324",
          "publishedOn": "2022-03-19T00:42:49.404Z",
          "wordCount": 626,
          "title": "Localizing Visual Sounds the Easy Way. (arXiv:2203.09324v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhong-Jing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_E/0/1/0/all/0/1\">Eduin E. Hernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu-Chih Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rini_S/0/1/0/all/0/1\">Stefano Rini</a>",
          "description": "In this paper, we introduce a novel algorithm, $\\mathsf{CO}_3$, for\ncommunication-efficiency distributed Deep Neural Network (DNN) training.\n$\\mathsf{CO}_3$ is a joint training/communication protocol, which encompasses\nthree processing steps for the network gradients: (i) quantization through\nfloating-point conversion, (ii) lossless compression, and (iii) error\ncorrection. These three components are crucial in the implementation of\ndistributed DNN training over rate-constrained links. The interplay of these\nthree steps in processing the DNN gradients is carefully balanced to yield a\nrobust and high-performance scheme. The performance of the proposed scheme is\ninvestigated through numerical evaluations over CIFAR-10.",
          "link": "http://arxiv.org/abs/2203.09044",
          "publishedOn": "2022-03-19T00:42:49.396Z",
          "wordCount": 530,
          "title": "Convert, compress, correct: Three steps toward communication-efficient DNN training. (arXiv:2203.09044v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.13485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhizhou Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruihan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jian Peng</a>",
          "description": "Many practical applications of reinforcement learning require agents to learn\nfrom sparse and delayed rewards. It challenges the ability of agents to\nattribute their actions to future outcomes. In this paper, we consider the\nproblem formulation of episodic reinforcement learning with trajectory\nfeedback. It refers to an extreme delay of reward signals, in which the agent\ncan only obtain one reward signal at the end of each trajectory. A popular\nparadigm for this problem setting is learning with a designed auxiliary dense\nreward function, namely proxy reward, instead of sparse environmental signals.\nBased on this framework, this paper proposes a novel reward redistribution\nalgorithm, randomized return decomposition (RRD), to learn a proxy reward\nfunction for episodic reinforcement learning. We establish a surrogate problem\nby Monte-Carlo sampling that scales up least-squares-based reward\nredistribution to long-horizon problems. We analyze our surrogate loss function\nby connection with existing methods in the literature, which illustrates the\nalgorithmic properties of our approach. In experiments, we extensively evaluate\nour proposed method on a variety of benchmark tasks with episodic rewards and\ndemonstrate substantial improvement over baseline algorithms.",
          "link": "http://arxiv.org/abs/2111.13485",
          "publishedOn": "2022-03-19T00:42:49.378Z",
          "wordCount": 661,
          "title": "Learning Long-Term Reward Redistribution via Randomized Return Decomposition. (arXiv:2111.13485v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Achaji_L/0/1/0/all/0/1\">Lina Achaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barry_T/0/1/0/all/0/1\">Thierno Barry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fouqueray_T/0/1/0/all/0/1\">Thibault Fouqueray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreau_J/0/1/0/all/0/1\">Julien Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aioun_F/0/1/0/all/0/1\">Francois Aioun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charpillet_F/0/1/0/all/0/1\">Francois Charpillet</a>",
          "description": "Nowadays, our mobility systems are evolving into the era of intelligent\nvehicles that aim to improve road safety. Due to their vulnerability,\npedestrians are the users who will benefit the most from these developments.\nHowever, predicting their trajectory is one of the most challenging concerns.\nIndeed, accurate prediction requires a good understanding of multi-agent\ninteractions that can be complex. Learning the underlying spatial and temporal\npatterns caused by these interactions is even more of a competitive and open\nproblem that many researchers are tackling. In this paper, we introduce a model\ncalled PRediction Transformer (PReTR) that extracts features from the\nmulti-agent scenes by employing a factorized spatio-temporal attention module.\nIt shows less computational needs than previously studied models with\nempirically better results. Besides, previous works in motion prediction suffer\nfrom the exposure bias problem caused by generating future sequences\nconditioned on model prediction samples rather than ground-truth samples. In\norder to go beyond the proposed solutions, we leverage encoder-decoder\nTransformer networks for parallel decoding a set of learned object queries.\nThis non-autoregressive solution avoids the need for iterative conditioning and\narguably decreases training and testing computational time. We evaluate our\nmodel on the ETH/UCY datasets, a publicly available benchmark for pedestrian\ntrajectory prediction. Finally, we justify our usage of the parallel decoding\ntechnique by showing that the trajectory prediction task can be better solved\nas a non-autoregressive task.",
          "link": "http://arxiv.org/abs/2203.09293",
          "publishedOn": "2022-03-19T00:42:49.365Z",
          "wordCount": 675,
          "title": "PreTR: Spatio-Temporal Non-Autoregressive Trajectory Prediction Transformer. (arXiv:2203.09293v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.10360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1\">Zhengxiao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yujie Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1\">Jiezhong Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhilin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "There have been various types of pretraining architectures including\nautoencoding models (e.g., BERT), autoregressive models (e.g., GPT), and\nencoder-decoder models (e.g., T5). However, none of the pretraining frameworks\nperforms the best for all tasks of three main categories including natural\nlanguage understanding (NLU), unconditional generation, and conditional\ngeneration. We propose a General Language Model (GLM) based on autoregressive\nblank infilling to address this challenge. GLM improves blank filling\npretraining by adding 2D positional encodings and allowing an arbitrary order\nto predict spans, which results in performance gains over BERT and T5 on NLU\ntasks. Meanwhile, GLM can be pretrained for different types of tasks by varying\nthe number and lengths of blanks. On a wide range of tasks across NLU,\nconditional and unconditional generation, GLM outperforms BERT, T5, and GPT\ngiven the same model sizes and data, and achieves the best performance from a\nsingle pretrained model with 1.25x parameters of BERT Large , demonstrating its\ngeneralizability to different downstream tasks.",
          "link": "http://arxiv.org/abs/2103.10360",
          "publishedOn": "2022-03-19T00:42:49.358Z",
          "wordCount": 659,
          "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling. (arXiv:2103.10360v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lienen_M/0/1/0/all/0/1\">Marten Lienen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>",
          "description": "We propose a new method for spatio-temporal forecasting on arbitrarily\ndistributed points. Assuming that the observed system follows an unknown\npartial differential equation, we derive a continuous-time model for the\ndynamics of the data via the finite element method. The resulting graph neural\nnetwork estimates the instantaneous effects of the unknown dynamics on each\ncell in a meshing of the spatial domain. Our model can incorporate prior\nknowledge via assumptions on the form of the unknown PDE, which induce a\nstructural bias towards learning specific processes. Through this mechanism, we\nderive a transport variant of our model from the convection equation and show\nthat it improves the transfer performance to higher-resolution meshes on sea\nsurface temperature and gas flow forecasting against baseline models\nrepresenting a selection of spatio-temporal forecasting methods. A qualitative\nanalysis shows that our model disentangles the data dynamics into their\nconstituent parts, which makes it uniquely interpretable.",
          "link": "http://arxiv.org/abs/2203.08852",
          "publishedOn": "2022-03-19T00:42:49.351Z",
          "wordCount": 595,
          "title": "Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks. (arXiv:2203.08852v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhiqiao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jie Hu</a>",
          "description": "As deep learning becomes the mainstream in the field of natural language\nprocessing, the need for suitable active learning method are becoming\nunprecedented urgent. Active Learning (AL) methods based on nearest neighbor\nclassifier are proposed and demonstrated superior results. However, existing\nnearest neighbor classifier are not suitable for classifying mutual exclusive\nclasses because inter-class discrepancy cannot be assured by nearest neighbor\nclassifiers. As a result, informative samples in the margin area can not be\ndiscovered and AL performance are damaged. To this end, we propose a novel\nNearest neighbor Classifier with Margin penalty for Active Learning(NCMAL).\nFirstly, mandatory margin penalty are added between classes, therefore both\ninter-class discrepancy and intra-class compactness are both assured. Secondly,\na novel sample selection strategy are proposed to discover informative samples\nwithin the margin area. To demonstrate the effectiveness of the methods, we\nconduct extensive experiments on for datasets with other state-of-the-art\nmethods. The experimental results demonstrate that our method achieves better\nresults with fewer annotated samples than all baseline methods.",
          "link": "http://arxiv.org/abs/2203.09174",
          "publishedOn": "2022-03-19T00:42:49.331Z",
          "wordCount": 603,
          "title": "Nearest Neighbor Classifier with Margin Penalty for Active Learning. (arXiv:2203.09174v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seitzer_M/0/1/0/all/0/1\">Maximilian Seitzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavakoli_A/0/1/0/all/0/1\">Arash Tavakoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antic_D/0/1/0/all/0/1\">Dimitrije Antic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martius_G/0/1/0/all/0/1\">Georg Martius</a>",
          "description": "Capturing aleatoric uncertainty is a critical part of many machine learning\nsystems. In deep learning, a common approach to this end is to train a neural\nnetwork to estimate the parameters of a heteroscedastic Gaussian distribution\nby maximizing the logarithm of the likelihood function under the observed data.\nIn this work, we examine this approach and identify potential hazards\nassociated with the use of log-likelihood in conjunction with gradient-based\noptimizers. First, we present a synthetic example illustrating how this\napproach can lead to very poor but stable parameter estimates. Second, we\nidentify the culprit to be the log-likelihood loss, along with certain\nconditions that exacerbate the issue. Third, we present an alternative\nformulation, termed $\\beta$-NLL, in which each data point's contribution to the\nloss is weighted by the $\\beta$-exponentiated variance estimate. We show that\nusing an appropriate $\\beta$ largely mitigates the issue in our illustrative\nexample. Fourth, we evaluate this approach on a range of domains and tasks and\nshow that it achieves considerable improvements and performs more robustly\nconcerning hyperparameters, both in predictive RMSE and log-likelihood\ncriteria.",
          "link": "http://arxiv.org/abs/2203.09168",
          "publishedOn": "2022-03-19T00:42:49.321Z",
          "wordCount": 633,
          "title": "On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks. (arXiv:2203.09168v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.05131",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1\">Yinglun Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Katz_Samuels_J/0/1/0/all/0/1\">Julian Katz-Samuels</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nowak_R/0/1/0/all/0/1\">Robert Nowak</a>",
          "description": "We introduce the model selection problem in pure exploration linear bandits,\nwhere the learner needs to adapt to the instance-dependent complexity measure\nof the smallest hypothesis class containing the true model. We design\nalgorithms in both fixed confidence and fixed budget settings with near\ninstance optimal guarantees. The core of our algorithms is a new optimization\nproblem based on experimental design that leverages the geometry of the action\nset to identify a near-optimal hypothesis class. Our fixed budget algorithm is\ndeveloped based on a novel selection-validation procedure, which provides a new\nway to study the understudied fixed budget setting (even without the added\nchallenge of model selection). We adapt our algorithms, in both fixed\nconfidence and fixed budget settings, to problems with model misspecification.",
          "link": "http://arxiv.org/abs/2109.05131",
          "publishedOn": "2022-03-19T00:42:49.314Z",
          "wordCount": 580,
          "title": "Near Instance Optimal Model Selection for Pure Exploration Linear Bandits. (arXiv:2109.05131v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_L/0/1/0/all/0/1\">Ling-Yu Duan</a>",
          "description": "Federated Learning (FL) is an emerging distributed learning paradigm under\nprivacy constraint. Data heterogeneity is one of the main challenges in FL,\nwhich results in slow convergence and degraded performance. Most existing\napproaches only tackle the heterogeneity challenge by restricting the local\nmodel update in client, ignoring the performance drop caused by direct global\nmodel aggregation. Instead, we propose a data-free knowledge distillation\nmethod to fine-tune the global model in the server (FedFTG), which relieves the\nissue of direct model aggregation. Concretely, FedFTG explores the input space\nof local models through a generator, and uses it to transfer the knowledge from\nlocal models to the global model. Besides, we propose a hard sample mining\nscheme to achieve effective knowledge distillation throughout the training. In\naddition, we develop customized label sampling and class-level ensemble to\nderive maximum utilization of knowledge, which implicitly mitigates the\ndistribution discrepancy across clients. Extensive experiments show that our\nFedFTG significantly outperforms the state-of-the-art (SOTA) FL algorithms and\ncan serve as a strong plugin for enhancing FedAvg, FedProx, FedDyn, and\nSCAFFOLD.",
          "link": "http://arxiv.org/abs/2203.09249",
          "publishedOn": "2022-03-19T00:42:49.308Z",
          "wordCount": 629,
          "title": "Fine-tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning. (arXiv:2203.09249v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Valavi_E/0/1/0/all/0/1\">Ehsan Valavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hestness_J/0/1/0/all/0/1\">Joel Hestness</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ardalani_N/0/1/0/all/0/1\">Newsha Ardalani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iansiti_M/0/1/0/all/0/1\">Marco Iansiti</a>",
          "description": "Managers often believe that collecting more data will continually improve the\naccuracy of their machine learning models. However, we argue in this paper that\nwhen data lose relevance over time, it may be optimal to collect a limited\namount of recent data instead of keeping around an infinite supply of older\n(less relevant) data. In addition, we argue that increasing the stock of data\nby including older datasets may, in fact, damage the model's accuracy.\nExpectedly, the model's accuracy improves by increasing the flow of data\n(defined as data collection rate); however, it requires other tradeoffs in\nterms of refreshing or retraining machine learning models more frequently.\n\nUsing these results, we investigate how the business value created by machine\nlearning models scales with data and when the stock of data establishes a\nsustainable competitive advantage. We argue that data's time-dependency weakens\nthe barrier to entry that the stock of data creates. As a result, a competing\nfirm equipped with a limited (yet sufficient) amount of recent data can develop\nmore accurate models. This result, coupled with the fact that older datasets\nmay deteriorate models' accuracy, suggests that created business value doesn't\nscale with the stock of available data unless the firm offloads less relevant\ndata from its data repository. Consequently, a firm's growth policy should\nincorporate a balance between the stock of historical data and the flow of new\ndata.\n\nWe complement our theoretical results with an experiment. In the experiment,\nwe empirically measure the loss in the accuracy of a next word prediction model\ntrained on datasets from various time periods. Our empirical measurements\nconfirm the economic significance of the value decline over time. For example,\n100MB of text data, after seven years, becomes as valuable as 50MB of current\ndata for the next word prediction task.",
          "link": "http://arxiv.org/abs/2203.09118",
          "publishedOn": "2022-03-19T00:42:49.289Z",
          "wordCount": 749,
          "title": "Time and the Value of Data. (arXiv:2203.09118v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.05446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eastwood_C/0/1/0/all/0/1\">Cian Eastwood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mason_I/0/1/0/all/0/1\">Ian Mason</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_C/0/1/0/all/0/1\">Christopher K. I. Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "Source-free domain adaptation (SFDA) aims to adapt a model trained on\nlabelled data in a source domain to unlabelled data in a target domain without\naccess to the source-domain data during adaptation. Existing methods for SFDA\nleverage entropy-minimization techniques which: (i) apply only to\nclassification; (ii) destroy model calibration; and (iii) rely on the source\nmodel achieving a good level of feature-space class-separation in the target\ndomain. We address these issues for a particularly pervasive type of domain\nshift called measurement shift which can be resolved by restoring the source\nfeatures rather than extracting new ones. In particular, we propose Feature\nRestoration (FR) wherein we: (i) store a lightweight and flexible approximation\nof the feature distribution under the source data; and (ii) adapt the\nfeature-extractor such that the approximate feature distribution under the\ntarget data realigns with that saved on the source. We additionally propose a\nbottom-up training scheme which boosts performance, which we call Bottom-Up\nFeature Restoration (BUFR). On real and synthetic data, we demonstrate that\nBUFR outperforms existing SFDA methods in terms of accuracy, calibration, and\ndata efficiency, while being less reliant on the performance of the source\nmodel in the target domain.",
          "link": "http://arxiv.org/abs/2107.05446",
          "publishedOn": "2022-03-19T00:42:49.282Z",
          "wordCount": 689,
          "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration. (arXiv:2107.05446v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08893",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yucong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Keming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Sheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianxi Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1\">Marinka Zitnik</a>",
          "description": "Objective: Disease knowledge graphs are a way to connect, organize, and\naccess disparate information about diseases with numerous benefits for\nartificial intelligence (AI). To create knowledge graphs, it is necessary to\nextract knowledge from multimodal datasets in the form of relationships between\ndisease concepts and normalize both concepts and relationship types. Methods:\nWe introduce REMAP, a multimodal approach for disease relation extraction and\nclassification. The REMAP machine learning approach jointly embeds a partial,\nincomplete knowledge graph and a medical language dataset into a compact latent\nvector space, followed by aligning the multimodal embeddings for optimal\ndisease relation extraction. Results: We apply REMAP approach to a disease\nknowledge graph with 96,913 relations and a text dataset of 1.24 million\nsentences. On a dataset annotated by human experts, REMAP improves text-based\ndisease relation extraction by 10.0% (accuracy) and 17.2% (F1-score) by fusing\ndisease knowledge graphs with text information. Further, REMAP leverages text\ninformation to recommend new relationships in the knowledge graph,\noutperforming graph-based methods by 8.4% (accuracy) and 10.4% (F1-score).\nDiscussion: Systematized knowledge is becoming the backbone of AI, creating\nopportunities to inject semantics into AI and fully integrate it into machine\nlearning algorithms. While prior semantic knowledge can assist in extracting\ndisease relationships from text, existing methods can not fully leverage\nmultimodal datasets. Conclusion: REMAP is a multimodal approach for extracting\nand classifying disease relationships by fusing structured knowledge and text\ninformation. REMAP provides a flexible neural architecture to easily find,\naccess, and validate AI-driven relationships between disease concepts.",
          "link": "http://arxiv.org/abs/2203.08893",
          "publishedOn": "2022-03-19T00:42:49.275Z",
          "wordCount": 698,
          "title": "Multimodal Learning on Graphs for Disease Relation Extraction. (arXiv:2203.08893v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1\">Xiaotong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuchen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suehiro_D/0/1/0/all/0/1\">Daiki Suehiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1\">Seiichi Uchida</a>",
          "description": "In this paper, we propose an optimal rejection method for rejecting ambiguous\nsamples by a rejection function. This rejection function is trained together\nwith a classification function under the framework of Learning-with-Rejection\n(LwR). The highlights of LwR are: (1) the rejection strategy is not heuristic\nbut has a strong background from a machine learning theory, and (2) the\nrejection function can be trained on an arbitrary feature space which is\ndifferent from the feature space for classification. The latter suggests we can\nchoose a feature space that is more suitable for rejection. Although the past\nresearch on LwR focused only on its theoretical aspect, we propose to utilize\nLwR for practical pattern classification tasks. Moreover, we propose to use\nfeatures from different CNN layers for classification and rejection. Our\nextensive experiments of notMNIST classification and character/non-character\nclassification demonstrate that the proposed method achieves better performance\nthan traditional rejection strategies.",
          "link": "http://arxiv.org/abs/2203.09151",
          "publishedOn": "2022-03-19T00:42:49.268Z",
          "wordCount": 589,
          "title": "Optimal Rejection Function Meets Character Recognition Tasks. (arXiv:2203.09151v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09376",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhang_K/0/1/0/all/0/1\">Kaining Zhang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Hsieh_M/0/1/0/all/0/1\">Min-Hsiu Hsieh</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_L/0/1/0/all/0/1\">Liu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Variational quantum circuits have been widely employed in quantum simulation\nand quantum machine learning in recent years. However, quantum circuits with\nrandom structures have poor trainability due to the exponentially vanishing\ngradient with respect to the circuit depth and the qubit number. This result\nleads to a general belief that deep quantum circuits will not be feasible for\npractical tasks. In this work, we propose an initialization strategy with\ntheoretical guarantees for the vanishing gradient problem in general deep\ncircuits. Specifically, we prove that under proper Gaussian initialized\nparameters, the norm of the gradient decays at most polynomially when the qubit\nnumber and the circuit depth increase. Our theoretical results hold for both\nthe local and the global observable cases, where the latter was believed to\nhave vanishing gradients even for shallow circuits. Experimental results verify\nour theoretical findings in the quantum simulation and quantum chemistry.",
          "link": "http://arxiv.org/abs/2203.09376",
          "publishedOn": "2022-03-19T00:42:49.262Z",
          "wordCount": 592,
          "title": "Gaussian initializations help deep variational quantum circuits escape from the barren plateau. (arXiv:2203.09376v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamalloo_E/0/1/0/all/0/1\">Ehsan Kamalloo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezagholizadeh_M/0/1/0/all/0/1\">Mehdi Rezagholizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodsi_A/0/1/0/all/0/1\">Ali Ghodsi</a>",
          "description": "Data Augmentation (DA) is known to improve the generalizability of deep\nneural networks. Most existing DA techniques naively add a certain number of\naugmented samples without considering the quality and the added computational\ncost of these samples. To tackle this problem, a common strategy, adopted by\nseveral state-of-the-art DA methods, is to adaptively generate or re-weight\naugmented samples with respect to the task objective during training. However,\nthese adaptive DA methods: (1) are computationally expensive and not\nsample-efficient, and (2) are designed merely for a specific setting. In this\nwork, we present a universal DA technique, called Glitter, to overcome both\nissues. Glitter can be plugged into any DA method, making training\nsample-efficient without sacrificing performance. From a pre-generated pool of\naugmented samples, Glitter adaptively selects a subset of worst-case samples\nwith maximal loss, analogous to adversarial DA. Without altering the training\nstrategy, the task objective can be optimized on the selected subset. Our\nthorough experiments on the GLUE benchmark, SQuAD, and HellaSwag in three\nwidely used training setups including consistency training, self-distillation\nand knowledge distillation reveal that Glitter is substantially faster to train\nand achieves a competitive performance, compared to strong baselines.",
          "link": "http://arxiv.org/abs/2203.09391",
          "publishedOn": "2022-03-19T00:42:49.244Z",
          "wordCount": 649,
          "title": "When Chosen Wisely, More Data Is What You Need: A Universal Sample-Efficient Strategy For Data Augmentation. (arXiv:2203.09391v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09205",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mueller_T/0/1/0/all/0/1\">Tamara T. Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usynin_D/0/1/0/all/0/1\">Dmitrii Usynin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paetzold_J/0/1/0/all/0/1\">Johannes C. Paetzold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1\">Daniel Rueckert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaissis_G/0/1/0/all/0/1\">Georgios Kaissis</a>",
          "description": "In this work, we study the applications of differential privacy (DP) in the\ncontext of graph-structured data. We discuss the formulations of DP applicable\nto the publication of graphs and their associated statistics as well as machine\nlearning on graph-based data, including graph neural networks (GNNs). The\nformulation of DP in the context of graph-structured data is difficult, as\nindividual data points are interconnected (often non-linearly or sparsely).\nThis connectivity complicates the computation of individual privacy loss in\ndifferentially private learning. The problem is exacerbated by an absence of a\nsingle, well-established formulation of DP in graph settings. This issue\nextends to the domain of GNNs, rendering private machine learning on\ngraph-structured data a challenging task. A lack of prior systematisation work\nmotivated us to study graph-based learning from a privacy perspective. In this\nwork, we systematise different formulations of DP on graphs, discuss challenges\nand promising applications, including the GNN domain. We compare and separate\nworks into graph analysis tasks and graph learning tasks with GNNs. Finally, we\nconclude our work with a discussion of open questions and potential directions\nfor further research in this area.",
          "link": "http://arxiv.org/abs/2203.09205",
          "publishedOn": "2022-03-19T00:42:49.237Z",
          "wordCount": 629,
          "title": "SoK: Differential Privacy on Graph-Structured Data. (arXiv:2203.09205v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09098",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruiteng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jianguo Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xugang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wenhuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Di Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Junhai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yantao Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_J/0/1/0/all/0/1\">Jianwu Dang</a>",
          "description": "Speaker embedding is an important front-end module to explore discriminative\nspeaker features for many speech applications where speaker information is\nneeded. Current SOTA backbone networks for speaker embedding are designed to\naggregate multi-scale features from an utterance with multi-branch network\narchitectures for speaker representation. However, naively adding many branches\nof multi-scale features with the simple fully convolutional operation could not\nefficiently improve the performance due to the rapid increase of model\nparameters and computational complexity. Therefore, in the most current\nstate-of-the-art network architectures, only a few branches corresponding to a\nlimited number of temporal scales could be designed for speaker embeddings. To\naddress this problem, in this paper, we propose an effective temporal\nmulti-scale (TMS) model where multi-scale branches could be efficiently\ndesigned in a speaker embedding network almost without increasing computational\ncosts. The new model is based on the conventional TDNN, where the network\narchitecture is smartly separated into two modeling operators: a\nchannel-modeling operator and a temporal multi-branch modeling operator. Adding\ntemporal multi-scale in the temporal multi-branch operator needs only a little\nbit increase of the number of parameters, and thus save more computational\nbudget for adding more branches with large temporal scales. Moreover, in the\ninference stage, we further developed a systemic re-parameterization method to\nconvert the TMS-based model into a single-path-based topology in order to\nincrease inference speed. We investigated the performance of the new TMS method\nfor automatic speaker verification (ASV) on in-domain and out-of-domain\nconditions. Results show that the TMS-based model obtained a significant\nincrease in the performance over the SOTA ASV models, meanwhile, had a faster\ninference speed.",
          "link": "http://arxiv.org/abs/2203.09098",
          "publishedOn": "2022-03-19T00:42:49.225Z",
          "wordCount": 744,
          "title": "TMS: A Temporal Multi-scale Backbone Design for Speaker Embedding. (arXiv:2203.09098v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chuxu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1\">Kaize Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yanfang Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chawla_N/0/1/0/all/0/1\">Nitesh V. Chawla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>",
          "description": "Graph representation learning has attracted tremendous attention due to its\nremarkable performance in many real-world applications. However, prevailing\n(semi-)supervised graph representation learning models for specific tasks often\nsuffer from label sparsity issue as data labeling is always time and resource\nconsuming. In light of this, few-shot learning on graphs (FSLG), which combines\nthe strengths of graph representation learning and few-shot learning together,\nhas been proposed to tackle the performance degradation in face of limited\nannotated data challenge. There have been many studies working on FSLG\nrecently. In this paper, we comprehensively survey these work in the form of a\nseries of methods and applications. Specifically, we first introduce FSLG\nchallenges and bases, then categorize and summarize existing work of FSLG in\nterms of three major graph mining tasks at different granularity levels, i.e.,\nnode, edge, and graph. Finally, we share our thoughts on some future research\ndirections of FSLG. The authors of this survey have contributed significantly\nto the AI literature on FSLG over the last few years.",
          "link": "http://arxiv.org/abs/2203.09308",
          "publishedOn": "2022-03-19T00:42:48.923Z",
          "wordCount": 604,
          "title": "Few-Shot Learning on Graphs: A Survey. (arXiv:2203.09308v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shuo Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Huafei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dao_M/0/1/0/all/0/1\">Minh N. Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1\">Feng Xia</a>",
          "description": "Graph Augmentation Learning (GAL) provides outstanding solutions for graph\nlearning in handling incomplete data, noise data, etc. Numerous GAL methods\nhave been proposed for graph-based applications such as social network analysis\nand traffic flow forecasting. However, the underlying reasons for the\neffectiveness of these GAL methods are still unclear. As a consequence, how to\nchoose optimal graph augmentation strategy for a certain application scenario\nis still in black box. There is a lack of systematic, comprehensive, and\nexperimentally validated guideline of GAL for scholars. Therefore, in this\nsurvey, we in-depth review GAL techniques from macro (graph), meso (subgraph),\nand micro (node/edge) levels. We further detailedly illustrate how GAL enhance\nthe data quality and the model performance. The aggregation mechanism of\naugmentation strategies and graph learning models are also discussed by\ndifferent application scenarios, i.e., data-specific, model-specific, and\nhybrid scenarios. To better show the outperformance of GAL, we experimentally\nvalidate the effectiveness and adaptability of different GAL strategies in\ndifferent downstream tasks. Finally, we share our insights on several open\nissues of GAL, including heterogeneity, spatio-temporal dynamics, scalability,\nand generalization.",
          "link": "http://arxiv.org/abs/2203.09020",
          "publishedOn": "2022-03-19T00:42:48.916Z",
          "wordCount": 623,
          "title": "Graph Augmentation Learning. (arXiv:2203.09020v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_B/0/1/0/all/0/1\">Binh-Son Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngan Le</a>",
          "description": "Medical image segmentation has been so far achieving promising results with\nConvolutional Neural Networks (CNNs). However, it is arguable that in\ntraditional CNNs, its pooling layer tends to discard important information such\nas positions. Moreover, CNNs are sensitive to rotation and affine\ntransformation. Capsule network is a data-efficient network design proposed to\novercome such limitations by replacing pooling layers with dynamic routing and\nconvolutional strides, which aims to preserve the part-whole relationships.\nCapsule network has shown a great performance in image recognition and natural\nlanguage processing, but applications for medical image segmentation,\nparticularly volumetric image segmentation, has been limited. In this work, we\npropose 3D-UCaps, a 3D voxel-based Capsule network for medical volumetric image\nsegmentation. We build the concept of capsules into a CNN by designing a\nnetwork with two pathways: the first pathway is encoded by 3D Capsule blocks,\nwhereas the second pathway is decoded by 3D CNNs blocks. 3D-UCaps, therefore\ninherits the merits from both Capsule network to preserve the spatial\nrelationship and CNNs to learn visual representation. We conducted experiments\non various datasets to demonstrate the robustness of 3D-UCaps including\niSeg-2017, LUNA16, Hippocampus, and Cardiac, where our method outperforms\nprevious Capsule networks and 3D-Unets.",
          "link": "http://arxiv.org/abs/2203.08965",
          "publishedOn": "2022-03-19T00:42:48.650Z",
          "wordCount": 643,
          "title": "3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation. (arXiv:2203.08965v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">So Yeon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaplot_D/0/1/0/all/0/1\">Devendra Singh Chaplot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1\">Pradeep Ravikumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1\">Yonatan Bisk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>",
          "description": "Recent methods for embodied instruction following are typically trained\nend-to-end using imitation learning. This often requires the use of expert\ntrajectories and low-level language instructions. Such approaches assume that\nneural states will integrate multimodal semantics to perform state tracking,\nbuilding spatial memory, exploration, and long-term planning. In contrast, we\npropose a modular method with structured representations that (1) builds a\nsemantic map of the scene and (2) performs exploration with a semantic search\npolicy, to achieve the natural language goal. Our modular method achieves SOTA\nperformance (24.46 %) with a substantial (8.17 % absolute) gap from previous\nwork while using less data by eschewing both expert trajectories and low-level\ninstructions. Leveraging low-level language, however, can further increase our\nperformance (26.49 %). Our findings suggest that an explicit spatial memory and\na semantic search policy can provide a stronger and more general representation\nfor state-tracking and guidance, even in the absence of expert trajectories or\nlow-level instructions.",
          "link": "http://arxiv.org/abs/2110.07342",
          "publishedOn": "2022-03-19T00:42:48.631Z",
          "wordCount": 652,
          "title": "FILM: Following Instructions in Language with Modular Methods. (arXiv:2110.07342v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenqing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_E/0/1/0/all/0/1\">Esha Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1\">Muhammad Shafique</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maniatakos_M/0/1/0/all/0/1\">Michail Maniatakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jabari_S/0/1/0/all/0/1\">Saif Eddin Jabari</a>",
          "description": "Backdoor attacks impose a new threat in Deep Neural Networks (DNNs), where a\nbackdoor is inserted into the neural network by poisoning the training dataset,\nmisclassifying inputs that contain the adversary trigger. The major challenge\nfor defending against these attacks is that only the attacker knows the secret\ntrigger and the target class. The problem is further exacerbated by the recent\nintroduction of \"Hidden Triggers\", where the triggers are carefully fused into\nthe input, bypassing detection by human inspection and causing backdoor\nidentification through anomaly detection to fail. To defend against such\nimperceptible attacks, in this work we systematically analyze how\nrepresentations, i.e., the set of neuron activations for a given DNN when using\nthe training data as inputs, are affected by backdoor attacks. We propose\nPiDAn, an algorithm based on coherence optimization purifying the poisoned\ndata. Our analysis shows that representations of poisoned data and authentic\ndata in the target class are still embedded in different linear subspaces,\nwhich implies that they show different coherence with some latent spaces. Based\non this observation, the proposed PiDAn algorithm learns a sample-wise weight\nvector to maximize the projected coherence of weighted samples, where we\ndemonstrate that the learned weight vector has a natural \"grouping effect\" and\nis distinguishable between authentic data and poisoned data. This enables the\nsystematic detection and mitigation of backdoor attacks. Based on our\ntheoretical analysis and experimental results, we demonstrate the effectiveness\nof PiDAn in defending against backdoor attacks that use different settings of\npoisoned samples on GTSRB and ILSVRC2012 datasets. Our PiDAn algorithm can\ndetect more than 90% infected classes and identify 95% poisoned samples.",
          "link": "http://arxiv.org/abs/2203.09289",
          "publishedOn": "2022-03-19T00:42:48.621Z",
          "wordCount": 726,
          "title": "PiDAn: A Coherence Optimization Approach for Backdoor Attack Detection and Mitigation in Deep Neural Networks. (arXiv:2203.09289v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.01971",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Jin_H/0/1/0/all/0/1\">Hanxun Jin</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Jiao_T/0/1/0/all/0/1\">Tong Jiao</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Clifton_R/0/1/0/all/0/1\">Rodney J. Clifton</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kim_K/0/1/0/all/0/1\">Kyung-Suk Kim</a>",
          "description": "Here, we report measurements of detailed dynamic cohesive properties (DCPs)\nbeyond the dynamic fracture toughness of a bicontinuously nanostructured\ncopolymer, polyurea, under an extremely loading rate, from deep-learning\nanalyses of a dynamic big-data-generating experiment. We first describe a new\nDynamic Line-Image Shearing Interferometer (DL-ISI), which uses a streak camera\nto record optical fringes of displacement-gradient vs time profile along a line\non sample's rear surface. This system enables us to detect crack initiation and\ngrowth processes in plate-impact experiments. Then, we present a convolutional\nneural network (CNN) based deep-learning framework, trained by extensive\nfinite-element simulations, that inversely determines the accurate DCPs from\nthe DL-ISI fringe images. For the measurements, plate-impact experiments were\nperformed on a set of samples with a mid-plane crack. A Conditional Generative\nAdversarial Networks (cGAN) was employed first to reconstruct missing DL-ISI\nfringes with recorded partial DL-ISI fringes. Then, the CNN and a correlation\nmethod were applied to the fully reconstructed fringes to get the dynamic\nfracture toughness, 12.1kJ/m^2, cohesive strength, 302 MPa, and maximum\ncohesive separation, 80.5 um, within 0.4%, 2.7%, and 2.2% differences,\nrespectively. For the first time, the DCPs of polyurea have been successfully\nobtained by the DL-ISI with the pre-trained CNN and correlation analyses of\ncGAN-reconstructed data sets. The dynamic cohesive strength is found to be\nnearly three times higher than the dynamic-failure-initiation strength. The\nhigh dynamic fracture toughness is found to stem from both high dynamic\ncohesive strength and high ductility of the dynamic cohesive separation.",
          "link": "http://arxiv.org/abs/2112.01971",
          "publishedOn": "2022-03-19T00:42:48.614Z",
          "wordCount": 728,
          "title": "Dynamic fracture of a bicontinuously nanostructured copolymer: A deep-learning analysis of big-data-generating experiment. (arXiv:2112.01971v2 [cond-mat.mtrl-sci] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.07171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fatemi_M/0/1/0/all/0/1\">Mehdi Fatemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavakoli_A/0/1/0/all/0/1\">Arash Tavakoli</a>",
          "description": "We present a general convergent class of reinforcement learning algorithms\nthat is founded on two distinct principles: (1) mapping value estimates to a\ndifferent space using arbitrary functions from a broad class, and (2) linearly\ndecomposing the reward signal into multiple channels. The first principle\nenables incorporating specific properties into the value estimator that can\nenhance learning. The second principle, on the other hand, allows for the value\nfunction to be represented as a composition of multiple utility functions. This\ncan be leveraged for various purposes, e.g. dealing with highly varying reward\nscales, incorporating a priori knowledge about the sources of reward, and\nensemble learning. Combining the two principles yields a general blueprint for\ninstantiating convergent algorithms by orchestrating diverse mapping functions\nover multiple reward channels. This blueprint generalizes and subsumes\nalgorithms such as Q-Learning, Log Q-Learning, and Q-Decomposition. In\naddition, our convergence proof for this general class relaxes certain required\nassumptions in some of these algorithms. Based on our theory, we discuss\nseveral interesting configurations as special cases. Finally, to illustrate the\npotential of the design space that our theory opens up, we instantiate a\nparticular algorithm and evaluate its performance on the Atari suite.",
          "link": "http://arxiv.org/abs/2203.07171",
          "publishedOn": "2022-03-19T00:42:48.607Z",
          "wordCount": 646,
          "title": "Orchestrated Value Mapping for Reinforcement Learning. (arXiv:2203.07171v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carletti_M/0/1/0/all/0/1\">Mattia Carletti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Terzi_M/0/1/0/all/0/1\">Matteo Terzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susto_G/0/1/0/all/0/1\">Gian Antonio Susto</a>",
          "description": "Adversarial Training has proved to be an effective training paradigm to\nenforce robustness against adversarial examples in modern neural network\narchitectures. Despite many efforts, explanations of the foundational\nprinciples underpinning the effectiveness of Adversarial Training are limited\nand far from being widely accepted by the Deep Learning community. In this\npaper, we describe surprising properties of adversarially-trained models,\nshedding light on mechanisms through which robustness against adversarial\nattacks is implemented. Moreover, we highlight limitations and failure modes\naffecting these models that were not discussed by prior works. We conduct\nextensive analyses on a wide range of architectures and datasets, performing a\ndeep comparison between robust and natural models.",
          "link": "http://arxiv.org/abs/2203.09243",
          "publishedOn": "2022-03-19T00:42:48.600Z",
          "wordCount": 545,
          "title": "On the Properties of Adversarially-Trained CNNs. (arXiv:2203.09243v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heger_P/0/1/0/all/0/1\">Philip Heger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Full_M/0/1/0/all/0/1\">Markus Full</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilger_D/0/1/0/all/0/1\">Daniel Hilger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosters_N/0/1/0/all/0/1\">Norbert Hosters</a>",
          "description": "The placement of temperature sensitive and safety-critical components is\ncrucial in the automotive industry. It is therefore inevitable, even at the\ndesign stage of new vehicles that these components are assessed for potential\nsafety issues. However, with increasing number of design proposals, risk\nassessment quickly becomes expensive. We therefore present a parameterized\nsurrogate model for the prediction of three-dimensional flow fields in\naerothermal vehicle simulations. The proposed physics-informed neural network\n(PINN) design is aimed at learning families of flow solutions according to a\ngeometric variation. In scope of this work, we could show that our\nnondimensional, multivariate scheme can be efficiently trained to predict the\nvelocity and pressure distribution for different design scenarios and geometric\nscales. The proposed algorithm is based on a parametric minibatch training\nwhich enables the utilization of large datasets necessary for the\nthree-dimensional flow modeling. Further, we introduce a continuous resampling\nalgorithm that allows to operate on one static dataset. Every feature of our\nmethodology is tested individually and verified against conventional CFD\nsimulations. Finally, we apply our proposed method in context of an exemplary\nreal-world automotive application.",
          "link": "http://arxiv.org/abs/2203.09204",
          "publishedOn": "2022-03-19T00:42:48.583Z",
          "wordCount": 682,
          "title": "Investigation of Physics-Informed Deep Learning for the Prediction of Parametric, Three-Dimensional Flow Based on Boundary Data. (arXiv:2203.09204v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08161",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Bazarov_A/0/1/0/all/0/1\">Abdullah Bazarov</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Benito_M/0/1/0/all/0/1\">Mar&#xed;a Benito</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Hutsi_G/0/1/0/all/0/1\">Gert H&#xfc;tsi</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kipper_R/0/1/0/all/0/1\">Rain Kipper</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Pata_J/0/1/0/all/0/1\">Joosep Pata</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Poder_S/0/1/0/all/0/1\">Sven P&#xf5;der</a>",
          "description": "The abundance of dark matter subhalos orbiting a host galaxy is a generic\nprediction of the cosmological framework. It is a promising way to constrain\nthe nature of dark matter. Here we describe the challenges of detecting stars\nwhose phase-space distribution may be perturbed by the passage of dark matter\nsubhalos using a machine learning approach. The training data are three Milky\nWay-like galaxies and nine synthetic Gaia DR2 surveys derived from these. We\nfirst quantify the magnitude of the perturbations in the simulated galaxies\nusing an anomaly detection algorithm. We also estimate the feasibility of this\napproach in the Gaia DR2-like catalogues by comparing the anomaly detection\nbased approach with a supervised classification. We find that a classification\nalgorithm optimized on about half a billion synthetic star observables exhibits\nmild but nonzero sensitivity. This classification-based approach is not\nsufficiently sensitive to pinpoint the exact locations of subhalos in the\nsimulation, as would be expected from the very limited number of subhalos in\nthe detectable region. The enormous size of the Gaia dataset motivates the\nfurther development of scalable and accurate computational methods that could\nbe used to select potential regions of interest for dark matter searches to\nultimately constrain the Milky Way's subhalo mass function.",
          "link": "http://arxiv.org/abs/2203.08161",
          "publishedOn": "2022-03-19T00:42:48.577Z",
          "wordCount": 691,
          "title": "Sensitivity Estimation for Dark Matter Subhalos in Synthetic Gaia DR2 using Deep Learning. (arXiv:2203.08161v1 [astro-ph.GA] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.08207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sanh_V/0/1/0/all/0/1\">Victor Sanh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webson_A/0/1/0/all/0/1\">Albert Webson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1\">Stephen H. Bach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutawika_L/0/1/0/all/0/1\">Lintang Sutawika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alyafeai_Z/0/1/0/all/0/1\">Zaid Alyafeai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaffin_A/0/1/0/all/0/1\">Antoine Chaffin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stiegler_A/0/1/0/all/0/1\">Arnaud Stiegler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scao_T/0/1/0/all/0/1\">Teven Le Scao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raja_A/0/1/0/all/0/1\">Arun Raja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dey_M/0/1/0/all/0/1\">Manan Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bari_M/0/1/0/all/0/1\">M Saiful Bari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thakker_U/0/1/0/all/0/1\">Urmish Thakker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shanya Sharma Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szczechla_E/0/1/0/all/0/1\">Eliza Szczechla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taewoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhablani_G/0/1/0/all/0/1\">Gunjan Chhablani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayak_N/0/1/0/all/0/1\">Nihal Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Datta_D/0/1/0/all/0/1\">Debajyoti Datta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Jonathan Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Mike Tian-Jian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Han Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manica_M/0/1/0/all/0/1\">Matteo Manica</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1\">Sheng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yong_Z/0/1/0/all/0/1\">Zheng Xin Yong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_H/0/1/0/all/0/1\">Harshit Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bawden_R/0/1/0/all/0/1\">Rachel Bawden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Thomas Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neeraj_T/0/1/0/all/0/1\">Trishala Neeraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rozen_J/0/1/0/all/0/1\">Jos Rozen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abheesht Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santilli_A/0/1/0/all/0/1\">Andrea Santilli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fevry_T/0/1/0/all/0/1\">Thibault Fevry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fries_J/0/1/0/all/0/1\">Jason Alan Fries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teehan_R/0/1/0/all/0/1\">Ryan Teehan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bers_T/0/1/0/all/0/1\">Tali Bers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1\">Stella Biderman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Leo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_T/0/1/0/all/0/1\">Thomas Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>",
          "description": "Large language models have recently been shown to attain reasonable zero-shot\ngeneralization on a diverse set of tasks (Brown et al., 2020). It has been\nhypothesized that this is a consequence of implicit multitask learning in\nlanguage models' pretraining (Radford et al., 2019). Can zero-shot\ngeneralization instead be directly induced by explicit multitask learning? To\ntest this question at scale, we develop a system for easily mapping any natural\nlanguage tasks into a human-readable prompted form. We convert a large set of\nsupervised datasets, each with multiple prompts with diverse wording. These\nprompted datasets allow for benchmarking the ability of a model to perform\ncompletely held-out tasks. We fine-tune a pretrained encoder-decoder model\n(Raffel et al., 2020; Lester et al., 2021) on this multitask mixture covering a\nwide variety of tasks. The model attains strong zero-shot performance on\nseveral standard datasets, often outperforming models up to 16x its size.\nFurther, our approach attains strong performance on a subset of tasks from the\nBIG-bench benchmark, outperforming models up to 6x its size. All trained models\nare available at https://github.com/bigscience-workshop/t-zero and all prompts\nare available at https://github.com/bigscience-workshop/promptsource.",
          "link": "http://arxiv.org/abs/2110.08207",
          "publishedOn": "2022-03-19T00:42:48.570Z",
          "wordCount": 754,
          "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization. (arXiv:2110.08207v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.12837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bradberry_T/0/1/0/all/0/1\">Trent J. Bradberry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hase_C/0/1/0/all/0/1\">Christopher H. Hase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kent_L/0/1/0/all/0/1\">LeAnna Kent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gongora_J/0/1/0/all/0/1\">Joel A. G&#xf3;ngora</a>",
          "description": "The laborious process of labeling data often bottlenecks projects that aim to\nleverage the power of supervised machine learning. Active Learning (AL) has\nbeen established as a technique to ameliorate this condition through an\niterative framework that queries a human annotator for labels of instances with\nthe most uncertain class assignment. Via this mechanism, AL produces a binary\nclassifier trained on less labeled data but with little, if any, loss in\npredictive performance. Despite its advantages, AL can have difficulty with\nclass-imbalanced datasets and results in an inefficient labeling process. To\naddress these drawbacks, we investigate our unsupervised instance selection\n(UNISEL) technique followed by a Random Forest (RF) classifier on 10 outlier\ndetection datasets under low-label conditions. These results are compared to AL\nperformed on the same datasets. Further, we investigate the combination of\nUNISEL and AL. Results indicate that UNISEL followed by an RF performs\ncomparably to AL with an RF and that the combination of UNISEL and AL\ndemonstrates superior performance. The practical implications of these findings\nin terms of time savings and generalizability afforded by UNISEL are discussed.",
          "link": "http://arxiv.org/abs/2104.12837",
          "publishedOn": "2022-03-19T00:42:48.562Z",
          "wordCount": 657,
          "title": "Unsupervised Instance Selection with Low-Label, Supervised Learning for Outlier Detection. (arXiv:2104.12837v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fatemi_M/0/1/0/all/0/1\">Mehdi Fatemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Mary Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petch_J/0/1/0/all/0/1\">Jeremy Petch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nelson_W/0/1/0/all/0/1\">Walter Nelson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Connolly_S/0/1/0/all/0/1\">Stuart J. Connolly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benz_A/0/1/0/all/0/1\">Alexander Benz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carnicelli_A/0/1/0/all/0/1\">Anthony Carnicelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Marzyeh Ghassemi</a>",
          "description": "Reinforcement learning (RL) tasks are typically framed as Markov Decision\nProcesses (MDPs), assuming that decisions are made at fixed time intervals.\nHowever, many applications of great importance, including healthcare, do not\nsatisfy this assumption, yet they are commonly modelled as MDPs after an\nartificial reshaping of the data. In addition, most healthcare (and similar)\nproblems are offline by nature, allowing for only retrospective studies. To\naddress both challenges, we begin by discussing the Semi-MDP (SMDP) framework,\nwhich formally handles actions of variable timings. We next present a formal\nway to apply SMDP modifications to nearly any given value-based offline RL\nmethod. We use this theory to introduce three SMDP-based offline RL algorithms,\nnamely, SDQN, SDDQN, and SBCQ. We then experimentally demonstrate that these\nSMDP-based algorithms learn the optimal policy in these variable-time\nenvironments, whereas un-directed modifications of MDP modelling lead to\nsub-optimal policies. Finally, we apply our new algorithms to a real-world\noffline dataset pertaining to warfarin dosing for stroke prevention and\ndemonstrate similar results.",
          "link": "http://arxiv.org/abs/2203.09365",
          "publishedOn": "2022-03-19T00:42:48.544Z",
          "wordCount": 613,
          "title": "Semi-Markov Offline Reinforcement Learning for Healthcare. (arXiv:2203.09365v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09268",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Blumberg_S/0/1/0/all/0/1\">Stefano B. Blumberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_H/0/1/0/all/0/1\">Hongxiang Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Grussu_F/0/1/0/all/0/1\">Francesco Grussu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1\">Yukun Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Figini_M/0/1/0/all/0/1\">Matteo Figini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alexander_D/0/1/0/all/0/1\">Daniel C. Alexander</a>",
          "description": "We present PROSUB: PROgressive SUBsampling, a deep learning based, automated\nmethodology that subsamples an oversampled data set (e.g. multi-channeled 3D\nimages) with minimal loss of information. We build upon a recent dual-network\napproach that won the MICCAI MUlti-DIffusion (MUDI) quantitative MRI\nmeasurement sampling-reconstruction challenge, but suffers from deep learning\ntraining instability, by subsampling with a hard decision boundary. PROSUB uses\nthe paradigm of recursive feature elimination (RFE) and progressively\nsubsamples measurements during deep learning training, improving optimization\nstability. PROSUB also integrates a neural architecture search (NAS) paradigm,\nallowing the network architecture hyperparameters to respond to the subsampling\nprocess. We show PROSUB outperforms the winner of the MUDI MICCAI challenge,\nproducing large improvements >18% MSE on the MUDI challenge sub-tasks and\nqualitative improvements on downstream processes useful for clinical\napplications. We also show the benefits of incorporating NAS and analyze the\neffect of PROSUB's components. As our method generalizes to other problems\nbeyond MRI measurement selection-reconstruction, our code is\nhttps://github.com/sbb-gh/PROSUB",
          "link": "http://arxiv.org/abs/2203.09268",
          "publishedOn": "2022-03-19T00:42:48.535Z",
          "wordCount": 630,
          "title": "Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI. (arXiv:2203.09268v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giammarino_V/0/1/0/all/0/1\">Vittorio Giammarino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunne_M/0/1/0/all/0/1\">Matthew F Dunne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moore_K/0/1/0/all/0/1\">Kylie N Moore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasselmo_M/0/1/0/all/0/1\">Michael E Hasselmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stern_C/0/1/0/all/0/1\">Chantal E Stern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "We develop a method to learn bio-inspired foraging policies using human data.\nWe conduct an experiment where humans are virtually immersed in an open field\nforaging environment and are trained to collect the highest amount of rewards.\nA Markov Decision Process (MDP) framework is introduced to model the human\ndecision dynamics. Then, Imitation Learning (IL) based on maximum likelihood\nestimation is used to train Neural Networks (NN) that map human decisions to\nobserved states. The results show that passive imitation substantially\nunderperforms humans. We further refine the human-inspired policies via\nReinforcement Learning (RL), using on-policy algorithms that are more suitable\nto learn from pre-trained networks. We show that the combination of IL and RL\ncan match human results and that good performance strongly depends on an\negocentric representation of the environment. The developed methodology can be\nused to efficiently learn policies for unmanned vehicles which have to solve\nmissions in an open field environment.",
          "link": "http://arxiv.org/abs/2203.06250",
          "publishedOn": "2022-03-19T00:42:48.529Z",
          "wordCount": 644,
          "title": "Learning from humans: combining imitation and deep reinforcement learning to accomplish human-level performance on a virtual foraging task. (arXiv:2203.06250v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.08465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1\">Gen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yifan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wenjin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuesong Li</a>",
          "description": "Here, we present a Heterogeneous Graph neural network for Multimodal\nneuroimaging fusion learning (HGM). Traditional GNN-based models usually assume\nthe brain network is a homogeneous graph with single type of nodes and edges.\nHowever, vast literatures have shown the heterogeneity of the human brain\nespecially between the two hemispheres. Homogeneous brain network is\ninsufficient to model the complicated brain state. Therefore, in this work we\nfirstly model the brain network as heterogeneous graph with multi-type nodes\n(i.e., left and right hemispheric nodes) and multi-type edges (i.e., intra- and\ninter-hemispheric edges). Besides, we also propose a self-supervised\npre-training strategy based on heterogeneou brain network to address the\noverfitting problem due to the complex model and small sample size. Our results\non two datasets show the superiority of proposed model over other multimodal\nmethods for disease prediction task. Besides, ablation experiments show that\nour model with pre-training strategy can alleviate the problem of limited\ntraining sample size.",
          "link": "http://arxiv.org/abs/2110.08465",
          "publishedOn": "2022-03-19T00:42:48.522Z",
          "wordCount": 639,
          "title": "A Heterogeneous Graph Based Framework for Multimodal Neuroimaging Fusion Learning. (arXiv:2110.08465v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dupty_M/0/1/0/all/0/1\">Mohammed Haroon Dupty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1\">Wee Sun Lee</a>",
          "description": "Graph Neural Networks (GNNs) have emerged as prominent models for\nrepresentation learning on graph structured data. GNNs follow an approach of\nmessage passing analogous to 1-dimensional Weisfeiler Lehman (1-WL) test for\ngraph isomorphism and consequently are limited by the distinguishing power of\n1-WL. More expressive higher-order GNNs which operate on k-tuples of nodes need\nincreased computational resources in order to process higher-order tensors.\nInstead of the WL approach, in this work, we follow the classical approach of\nIndividualization and Refinement (IR), a technique followed by most practical\nisomorphism solvers. Individualization refers to artificially distinguishing a\nnode in the graph and refinement is the propagation of this information to\nother nodes through message passing. We learn to adaptively select nodes to\nindividualize and to aggregate the resulting graphs after refinement to help\nhandle the complexity. Our technique lets us learn richer node embeddings while\nkeeping the computational complexity manageable. Theoretically, we show that\nour procedure is more expressive than the 1-WL test. Experiments show that our\nmethod outperforms prominent 1-WL GNN models as well as competitive\nhigher-order baselines on several benchmark synthetic and real datasets.\nFurthermore, our method opens new doors for exploring the paradigm of learning\non graph structures with individualization and refinement.",
          "link": "http://arxiv.org/abs/2203.09141",
          "publishedOn": "2022-03-19T00:42:48.514Z",
          "wordCount": 633,
          "title": "Graph Representation Learning with Individualization and Refinement. (arXiv:2203.09141v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhouxing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>",
          "description": "Interval Bound Propagation (IBP) is so far the base of state-of-the-art\nmethods for training neural networks with certifiable robustness guarantees\nwhen potential adversarial perturbations present, while the convergence of IBP\ntraining remains unknown in existing literature. In this paper, we present a\ntheoretical analysis on the convergence of IBP training. With an\noverparameterized assumption, we analyze the convergence of IBP robust\ntraining. We show that when using IBP training to train a randomly initialized\ntwo-layer ReLU neural network with logistic loss, gradient descent can linearly\nconverge to zero robust training error with a high probability if we have\nsufficiently small perturbation radius and large network width.",
          "link": "http://arxiv.org/abs/2203.08961",
          "publishedOn": "2022-03-19T00:42:48.497Z",
          "wordCount": null,
          "title": "On the Convergence of Certified Robust Training with Interval Bound Propagation. (arXiv:2203.08961v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.02611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Romero_D/0/1/0/all/0/1\">David W. Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuzina_A/0/1/0/all/0/1\">Anna Kuzina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bekkers_E/0/1/0/all/0/1\">Erik J. Bekkers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1\">Jakub M. Tomczak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoogendoorn_M/0/1/0/all/0/1\">Mark Hoogendoorn</a>",
          "description": "Conventional neural architectures for sequential data present important\nlimitations. Recurrent networks suffer from exploding and vanishing gradients,\nsmall effective memory horizons, and must be trained sequentially.\nConvolutional networks are unable to handle sequences of unknown size and their\nmemory horizon must be defined a priori. In this work, we show that all these\nproblems can be solved by formulating convolutional kernels in CNNs as\ncontinuous functions. The resulting Continuous Kernel Convolution (CKConv)\nallows us to model arbitrarily long sequences in a parallel manner, within a\nsingle operation, and without relying on any form of recurrence. We show that\nContinuous Kernel Convolutional Networks (CKCNNs) obtain state-of-the-art\nresults in multiple datasets, e.g., permuted MNIST, and, thanks to their\ncontinuous nature, are able to handle non-uniformly sampled datasets and\nirregularly-sampled data natively. CKCNNs match or perform better than neural\nODEs designed for these purposes in a faster and simpler manner.",
          "link": "http://arxiv.org/abs/2102.02611",
          "publishedOn": "2022-03-19T00:42:48.496Z",
          "wordCount": 624,
          "title": "CKConv: Continuous Kernel Convolution For Sequential Data. (arXiv:2102.02611v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muller_D/0/1/0/all/0/1\">Dennis M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marz_M/0/1/0/all/0/1\">Michael M&#xe4;rz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheele_S/0/1/0/all/0/1\">Stephan Scheele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_U/0/1/0/all/0/1\">Ute Schmid</a>",
          "description": "Machine learning based image classification algorithms, such as deep neural\nnetwork approaches, will be increasingly employed in critical settings such as\nquality control in industry, where transparency and comprehensibility of\ndecisions are crucial. Therefore, we aim to extend the defect detection task\ntowards an interactive human-in-the-loop approach that allows us to integrate\nrich background knowledge and the inference of complex relationships going\nbeyond traditional purely data-driven approaches. We propose an approach for an\ninteractive support system for classifications in an industrial quality control\nsetting that combines the advantages of both (explainable) knowledge-driven and\ndata-driven machine learning methods, in particular inductive logic programming\nand convolutional neural networks, with human expertise and control. The\nresulting system can assist domain experts with decisions, provide transparent\nexplanations for results, and integrate feedback from users; thus reducing\nworkload for humans while both respecting their expertise and without removing\ntheir agency or accountability.",
          "link": "http://arxiv.org/abs/2203.09181",
          "publishedOn": "2022-03-19T00:42:48.489Z",
          "wordCount": 600,
          "title": "An Interactive Explanatory AI System for Industrial Quality Control. (arXiv:2203.09181v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09281",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Wilsenach_J/0/1/0/all/0/1\">James B. Wilsenach</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Warnaby_C/0/1/0/all/0/1\">Catherine E. Warnaby</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deane_C/0/1/0/all/0/1\">Charlotte M. Deane</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Reinert_G/0/1/0/all/0/1\">Gesine D. Reinert</a>",
          "description": "As a relatively new field, network neuroscience has tended to focus on\naggregate behaviours of the brain averaged over many successive experiments or\nover long recordings in order to construct robust brain models. These models\nare limited in their ability to explain dynamic state changes in the brain\nwhich occurs spontaneously as a result of normal brain function. Hidden Markov\nModels (HMMs) trained on neuroimaging time series data have since arisen as a\nmethod to produce dynamical models that are easy to train but can be difficult\nto fully parametrise or analyse. We propose an interpretation of these neural\nHMMs as multiplex brain state graph models we term Hidden Markov Graph Models\n(HMGMs). This interpretation allows for dynamic brain activity to be analysed\nusing the full repertoire of network analysis techniques. Furthermore, we\npropose a general method for selecting HMM hyperparameters in the absence of\nexternal data, based on the principle of maximum entropy, and use this to\nselect the number of layers in the multiplex model. We produce a new tool for\ndetermining important communities of brain regions using a spatiotemporal\nrandom walk-based procedure that takes advantage of the underlying Markov\nstructure of the model. Our analysis of real multi-subject fMRI data provides\nnew results that corroborate the modular processing hypothesis of the brain at\nrest as well as contributing new evidence of functional overlap between and\nwithin dynamic brain state communities. Our analysis pipeline provides a way to\ncharacterise dynamic network activity of the brain under novel behaviours or\nconditions.",
          "link": "http://arxiv.org/abs/2203.09281",
          "publishedOn": "2022-03-19T00:42:48.483Z",
          "wordCount": 758,
          "title": "Ranking of Communities in Multiplex Spatiotemporal Models of Brain Dynamics. (arXiv:2203.09281v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1\">Grzegorz Dudek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smyl_S/0/1/0/all/0/1\">Slawek Smyl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelka_P/0/1/0/all/0/1\">Pawe&#x142; Pe&#x142;ka</a>",
          "description": "This paper compares recurrent neural networks (RNNs) with different types of\ngated cells for forecasting time series with multiple seasonality. The cells we\ncompare include classical long short term memory (LSTM), gated recurrent unit\n(GRU), modified LSTM with dilation, and two new cells we proposed recently,\nwhich are equipped with dilation and attention mechanisms. To model the\ntemporal dependencies of different scales, our RNN architecture has multiple\ndilated recurrent layers stacked with hierarchical dilations. The proposed RNN\nproduces both point forecasts and predictive intervals (PIs) for them. An\nempirical study concerning short-term electrical load forecasting for 35\nEuropean countries confirmed that the new gated cells with dilation and\nattention performed best.",
          "link": "http://arxiv.org/abs/2203.09170",
          "publishedOn": "2022-03-19T00:42:48.475Z",
          "wordCount": 552,
          "title": "Recurrent Neural Networks for Forecasting Time Series with Multiple Seasonality: A Comparative Study. (arXiv:2203.09170v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09510",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jinhyung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chenfeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yiyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1\">Masayoshi Tomizuka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1\">Wei Zhan</a>",
          "description": "While numerous 3D detection works leverage the complementary relationship\nbetween RGB images and point clouds, developments in the broader framework of\nsemi-supervised object recognition remain uninfluenced by multi-modal fusion.\nCurrent methods develop independent pipelines for 2D and 3D semi-supervised\nlearning despite the availability of paired image and point cloud frames.\nObserving that the distinct characteristics of each sensor cause them to be\nbiased towards detecting different objects, we propose DetMatch, a flexible\nframework for joint semi-supervised learning on 2D and 3D modalities. By\nidentifying objects detected in both sensors, our pipeline generates a cleaner,\nmore robust set of pseudo-labels that both demonstrates stronger performance\nand stymies single-modality error propagation. Further, we leverage the richer\nsemantics of RGB images to rectify incorrect 3D class predictions and improve\nlocalization of 3D boxes. Evaluating on the challenging KITTI and Waymo\ndatasets, we improve upon strong semi-supervised learning methods and observe\nhigher quality pseudo-labels. Code will be released at\nhttps://github.com/Divadi/DetMatch",
          "link": "http://arxiv.org/abs/2203.09510",
          "publishedOn": "2022-03-19T00:42:48.458Z",
          "wordCount": 628,
          "title": "DetMatch: Two Teachers are Better Than One for Joint 2D and 3D Semi-Supervised Object Detection. (arXiv:2203.09510v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.07683",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Meyer_P/0/1/0/all/0/1\">Pierre-Jean Meyer</a>",
          "description": "This paper presents a new reachability analysis approach to compute interval\nover-approximations of the output set of feedforward neural networks with input\nuncertainty. We adapt to neural networks an existing mixed-monotonicity method\nfor the reachability analysis of dynamical systems and apply it to each partial\nnetwork within the main network. This ensures that the intersection of the\nobtained results is the tightest interval over-approximation of the output of\neach layer that can be obtained using mixed-monotonicity on any partial network\ndecomposition. Unlike other tools in the literature focusing on small classes\nof piecewise-affine or monotone activation functions, the main strength of our\napproach is its generality: it can handle neural networks with any\nLipschitz-continuous activation function. In addition, the simplicity of our\nframework allows users to very easily add unimplemented activation functions,\nby simply providing the function, its derivative and the global argmin and\nargmax of the derivative. Our algorithm is compared to five other\ninterval-based tools (Interval Bound Propagation, ReluVal, Neurify, VeriNet,\nCROWN) on both existing benchmarks and two sets of small and large randomly\ngenerated networks for four activation functions (ReLU, TanH, ELU, SiLU).",
          "link": "http://arxiv.org/abs/2111.07683",
          "publishedOn": "2022-03-19T00:42:48.451Z",
          "wordCount": 641,
          "title": "Reachability analysis of neural networks using mixed monotonicity. (arXiv:2111.07683v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.00100",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tygert_M/0/1/0/all/0/1\">Mark Tygert</a>",
          "description": "The author's recent research papers, \"Cumulative deviation of a subpopulation\nfrom the full population\" and \"A graphical method of cumulative differences\nbetween two subpopulations\" (both published in volume 8 of Springer's\nopen-access \"Journal of Big Data\" during 2021), propose graphical methods and\nsummary statistics, without extensively calibrating formal significance tests.\nThe summary metrics and methods can measure the calibration of probabilistic\npredictions and can assess differences in responses between a subpopulation and\nthe full population while controlling for a covariate or score via conditioning\non it. These recently published papers construct significance tests based on\nthe scalar summary statistics, but only sketch how to calibrate the attained\nsignificance levels (also known as \"P-values\") for the tests. The present\narticle reviews and synthesizes work spanning many decades in order to detail\nhow to calibrate the P-values. The present paper presents computationally\nefficient, easily implemented numerical methods for evaluating properly\ncalibrated P-values, together with rigorous mathematical proofs guaranteeing\ntheir accuracy, and illustrates and validates the methods with open-source\nsoftware and numerical examples.",
          "link": "http://arxiv.org/abs/2202.00100",
          "publishedOn": "2022-03-19T00:42:48.427Z",
          "wordCount": 647,
          "title": "Calibration of P-values for calibration and for deviation of a subpopulation from the full population. (arXiv:2202.00100v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08951",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vo_Ho_V/0/1/0/all/0/1\">Viet-Khoa Vo-Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamazaki_K/0/1/0/all/0/1\">Kashu Yamazaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_H/0/1/0/all/0/1\">Hieu Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1\">Minh-Triet Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngan Le</a>",
          "description": "Deep learning methods have been successful in solving tasks in machine\nlearning and have made breakthroughs in many sectors owing to their ability to\nautomatically extract features from unstructured data. However, their\nperformance relies on manual trial-and-error processes for selecting an\nappropriate network architecture, hyperparameters for training, and\npre-/post-procedures. Even though it has been shown that network architecture\nplays a critical role in learning feature representation feature from data and\nthe final performance, searching for the best network architecture is\ncomputationally intensive and heavily relies on researchers' experience.\nAutomated machine learning (AutoML) and its advanced techniques i.e. Neural\nArchitecture Search (NAS) have been promoted to address those limitations. Not\nonly in general computer vision tasks, but NAS has also motivated various\napplications in multiple areas including medical imaging. In medical imaging,\nNAS has significant progress in improving the accuracy of image classification,\nsegmentation, reconstruction, and more. However, NAS requires the availability\nof large annotated data, considerable computation resources, and pre-defined\ntasks. To address such limitations, meta-learning has been adopted in the\nscenarios of few-shot learning and multiple tasks. In this book chapter, we\nfirst present a brief review of NAS by discussing well-known approaches in\nsearch space, search strategy, and evaluation strategy. We then introduce\nvarious NAS approaches in medical imaging with different applications such as\nclassification, segmentation, detection, reconstruction, etc. Meta-learning in\nNAS for few-shot learning and multiple tasks is then explained. Finally, we\ndescribe several open problems in NAS.",
          "link": "http://arxiv.org/abs/2203.08951",
          "publishedOn": "2022-03-19T00:42:48.421Z",
          "wordCount": 708,
          "title": "Meta-Learning of NAS for Few-shot Learning in Medical Image Applications. (arXiv:2203.08951v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09270",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wickstrom_K/0/1/0/all/0/1\">Kristoffer Wickstr&#xf8;m</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kampffmeyer_M/0/1/0/all/0/1\">Michael Kampffmeyer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mikalsen_K/0/1/0/all/0/1\">Karl &#xd8;yvind Mikalsen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jenssen_R/0/1/0/all/0/1\">Robert Jenssen</a>",
          "description": "The lack of labeled data is a key challenge for learning useful\nrepresentation from time series data. However, an unsupervised representation\nframework that is capable of producing high quality representations could be of\ngreat value. It is key to enabling transfer learning, which is especially\nbeneficial for medical applications, where there is an abundance of data but\nlabeling is costly and time consuming. We propose an unsupervised contrastive\nlearning framework that is motivated from the perspective of label smoothing.\nThe proposed approach uses a novel contrastive loss that naturally exploits a\ndata augmentation scheme in which new samples are generated by mixing two data\nsamples with a mixing component. The task in the proposed framework is to\npredict the mixing component, which is utilized as soft targets in the loss\nfunction. Experiments demonstrate the framework's superior performance compared\nto other representation learning approaches on both univariate and multivariate\ntime series and illustrate its benefits for transfer learning for clinical time\nseries.",
          "link": "http://arxiv.org/abs/2203.09270",
          "publishedOn": "2022-03-19T00:42:48.414Z",
          "wordCount": 635,
          "title": "Mixing Up Contrastive Learning: Self-Supervised Representation Learning for Time Series. (arXiv:2203.09270v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.07835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horn_M/0/1/0/all/0/1\">Max Horn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brouwer_E/0/1/0/all/0/1\">Edward De Brouwer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moor_M/0/1/0/all/0/1\">Michael Moor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreau_Y/0/1/0/all/0/1\">Yves Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1\">Bastian Rieck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgwardt_K/0/1/0/all/0/1\">Karsten Borgwardt</a>",
          "description": "Graph neural networks (GNNs) are a powerful architecture for tackling graph\nlearning tasks, yet have been shown to be oblivious to eminent substructures\nsuch as cycles. We present TOGL, a novel layer that incorporates global\ntopological information of a graph using persistent homology. TOGL can be\neasily integrated into any type of GNN and is strictly more expressive (in\nterms the Weisfeiler--Lehman graph isomorphism test) than message-passing GNNs.\nAugmenting GNNs with TOGL leads to improved predictive performance for graph\nand node classification tasks, both on synthetic data sets, which can be\nclassified by humans using their topology but not by ordinary GNNs, and on\nreal-world data.",
          "link": "http://arxiv.org/abs/2102.07835",
          "publishedOn": "2022-03-19T00:42:48.398Z",
          "wordCount": 606,
          "title": "Topological Graph Neural Networks. (arXiv:2102.07835v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tong_S/0/1/0/all/0/1\">Shangyuan Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garipov_T/0/1/0/all/0/1\">Timur Garipov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi S. Jaakkola</a>",
          "description": "We study the problem of aligning the supports of distributions. Compared to\nthe existing work on distribution alignment, support alignment does not require\nthe densities to be matched. We propose symmetric support difference as a\ndivergence measure to quantify the mismatch between supports. We show that\nselect discriminators (e.g. discriminator trained for Jensen-Shannon\ndivergence) are able to map support differences as support differences in their\none-dimensional output space. Following this result, our method aligns supports\nby minimizing a symmetrized relaxed optimal transport cost in the discriminator\n1D space via an adversarial process. Furthermore, we show that our approach can\nbe viewed as a limit of existing notions of alignment by increasing\ntransportation assignment tolerance. We quantitatively evaluate the method\nacross domain adaptation tasks with shifts in label distributions. Our\nexperiments show that the proposed method is more robust against these shifts\nthan other alignment-based baselines.",
          "link": "http://arxiv.org/abs/2203.08908",
          "publishedOn": "2022-03-19T00:42:48.388Z",
          "wordCount": null,
          "title": "Adversarial Support Alignment. (arXiv:2203.08908v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.12034",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1\">Yinglun Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_D/0/1/0/all/0/1\">Dongruo Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jiang_R/0/1/0/all/0/1\">Ruoxi Jiang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Willett_R/0/1/0/all/0/1\">Rebecca Willett</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nowak_R/0/1/0/all/0/1\">Robert Nowak</a>",
          "description": "We study pure exploration in bandits, where the dimension of the feature\nrepresentation can be much larger than the number of arms. To overcome the\ncurse of dimensionality, we propose to adaptively embed the feature\nrepresentation of each arm into a lower-dimensional space and carefully deal\nwith the induced model misspecification. Our approach is conceptually very\ndifferent from existing works that can either only handle low-dimensional\nlinear bandits or passively deal with model misspecification. We showcase the\napplication of our approach to two pure exploration settings that were\npreviously under-studied: (1) the reward function belongs to a possibly\ninfinite-dimensional Reproducing Kernel Hilbert Space, and (2) the reward\nfunction is nonlinear and can be approximated by neural networks. Our main\nresults provide sample complexity guarantees that only depend on the effective\ndimension of the feature spaces in the kernel or neural representations.\nExtensive experiments conducted on both synthetic and real-world datasets\ndemonstrate the efficacy of our methods.",
          "link": "http://arxiv.org/abs/2106.12034",
          "publishedOn": "2022-03-19T00:42:48.384Z",
          "wordCount": 612,
          "title": "Pure Exploration in Kernel and Neural Bandits. (arXiv:2106.12034v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Martinez_A/0/1/0/all/0/1\">Angel Mario Castro Martinez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spille_C/0/1/0/all/0/1\">Constantin Spille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossbach_J/0/1/0/all/0/1\">Jana Ro&#xdf;bach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kollmeier_B/0/1/0/all/0/1\">Birger Kollmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meyer_B/0/1/0/all/0/1\">Bernd T. Meyer</a>",
          "description": "This paper presents a speech intelligibility model based on automatic speech\nrecognition (ASR), combining phoneme probabilities from deep neural networks\n(DNN) and a performance measure that estimates the word error rate from these\nprobabilities. This model does not require the clean speech reference nor the\nword labels during testing as the ASR decoding step, which finds the most\nlikely sequence of words given phoneme posterior probabilities, is omitted. The\nmodel is evaluated via the root-mean-squared error between the predicted and\nobserved speech reception thresholds from eight normal-hearing listeners. The\nrecognition task consists of identifying noisy words from a German matrix\nsentence test. The speech material was mixed with eight noise maskers covering\ndifferent modulation types, from speech-shaped stationary noise to a\nsingle-talker masker. The prediction performance is compared to five\nestablished models and an ASR-model using word labels. Two combinations of\nfeatures and networks were tested. Both include temporal information either at\nthe feature level (amplitude modulation filterbanks and a feed-forward network)\nor captured by the architecture (mel-spectrograms and a time-delay deep neural\nnetwork, TDNN). The TDNN model is on par with the DNN while reducing the number\nof parameters by a factor of 37; this optimization allows parallel streams on\ndedicated hearing aid hardware as a forward-pass can be computed within the\n10ms of each frame. The proposed model performs almost as well as the\nlabel-based model and produces more accurate predictions than the baseline\nmodels.",
          "link": "http://arxiv.org/abs/2203.09148",
          "publishedOn": "2022-03-19T00:42:48.344Z",
          "wordCount": 714,
          "title": "Prediction of speech intelligibility with DNN-based performance measures. (arXiv:2203.09148v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.07967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koestler_L/0/1/0/all/0/1\">Lukas Koestler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grittner_D/0/1/0/all/0/1\">Daniel Grittner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moeller_M/0/1/0/all/0/1\">Michael Moeller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1\">Daniel Cremers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahner_Z/0/1/0/all/0/1\">Zorah L&#xe4;hner</a>",
          "description": "Neural fields have gained significant attention in the computer vision\ncommunity due to their excellent performance in novel view synthesis, geometry\nreconstruction, and generative modeling. Some of their advantages are a sound\ntheoretic foundation and an easy implementation in current deep learning\nframeworks. While neural fields have been applied to signals on manifolds,\ne.g., for texture reconstruction, their representation has been limited to\nextrinsically embedding the shape into Euclidean space. The extrinsic embedding\nignores known intrinsic manifold properties and is inflexible wrt. transfer of\nthe learned function. To overcome these limitations, this work introduces\nintrinsic neural fields, a novel and versatile representation for neural fields\non manifolds. Intrinsic neural fields combine the advantages of neural fields\nwith the spectral properties of the Laplace-Beltrami operator. We show\ntheoretically that intrinsic neural fields inherit many desirable properties of\nthe extrinsic neural field framework but exhibit additional intrinsic\nqualities, like isometry invariance. In experiments, we show intrinsic neural\nfields can reconstruct high-fidelity textures from images with state-of-the-art\nquality and are robust to the discretization of the underlying manifold. We\ndemonstrate the versatility of intrinsic neural fields by tackling various\napplications: texture transfer between deformed shapes & different shapes,\ntexture reconstruction from real-world images with view dependence, and\ndiscretization-agnostic learning on meshes and point clouds.",
          "link": "http://arxiv.org/abs/2203.07967",
          "publishedOn": "2022-03-19T00:42:48.337Z",
          "wordCount": 671,
          "title": "Intrinsic Neural Fields: Learning Functions on Manifolds. (arXiv:2203.07967v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.07561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koch_L/0/1/0/all/0/1\">Luke Koch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oesch_S/0/1/0/all/0/1\">Sean Oesch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adkisson_M/0/1/0/all/0/1\">Mary Adkisson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erwin_S/0/1/0/all/0/1\">Sam Erwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_B/0/1/0/all/0/1\">Brian Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaulagain_A/0/1/0/all/0/1\">Amul Chaulagain</a>",
          "description": "Standardized file formats play a key role in the development and use of\ncomputer software. However, it is possible to abuse standardized file formats\nby creating a file that is valid in multiple file formats. The resulting\npolyglot (many languages) file can confound file format identification,\nallowing elements of the file to evade analysis.This is especially problematic\nfor malware detection systems that rely on file format identification for\nfeature extraction. File format identification processes that depend on file\nsignatures can be easily evaded thanks to flexibility in the format\nspecifications of certain file formats. Although work has been done to identify\nfile formats using more comprehensive methods than file signatures, accurate\nidentification of polyglot files remains an open problem. Since malware\ndetection systems routinely perform file format-specific feature extraction,\npolyglot files need to be filtered out prior to ingestion by these systems.\nOtherwise, malicious content could pass through undetected. To address the\nproblem of polyglot detection we assembled a data set using the mitra tool. We\nthen evaluated the performance of the most commonly used file identification\ntool, file. Finally, we demonstrated the accuracy, precision, recall and F1\nscore of a range of machine and deep learning models. Malconv2 and Catboost\ndemonstrated the highest recall on our data set with 95.16% and 95.34%,\nrespectively. These models can be incorporated into a malware detector's file\nprocessing pipeline to filter out potentially malicious polyglots before file\nformat-dependent feature extraction takes place.",
          "link": "http://arxiv.org/abs/2203.07561",
          "publishedOn": "2022-03-19T00:42:48.320Z",
          "wordCount": 694,
          "title": "Toward the Detection of Polyglot Files. (arXiv:2203.07561v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruihan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_P/0/1/0/all/0/1\">Prakhar Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Denoising diffusion probabilistic models are a promising new class of\ngenerative models that are competitive with GANs on perceptual metrics. In this\npaper, we explore their potential for sequentially generating video. Inspired\nby recent advances in neural video compression, we use denoising diffusion\nmodels to stochastically generate a residual to a deterministic next-frame\nprediction. We compare this approach to two sequential VAE and two GAN\nbaselines on four datasets, where we test the generated frames for perceptual\nquality and forecasting accuracy against ground truth frames. We find\nsignificant improvements in terms of perceptual quality on all data and\nimprovements in terms of frame forecasting for complex high-resolution videos.",
          "link": "http://arxiv.org/abs/2203.09481",
          "publishedOn": "2022-03-19T00:42:48.287Z",
          "wordCount": 562,
          "title": "Diffusion Probabilistic Modeling for Video Generation. (arXiv:2203.09481v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vaska_N/0/1/0/all/0/1\">Nathan Vaska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helus_V/0/1/0/all/0/1\">Victoria Helus</a>",
          "description": "Increasing the semantic understanding and contextual awareness of machine\nlearning models is important for improving robustness and reducing\nsusceptibility to data shifts. In this work, we leverage contextual awareness\nfor the anomaly detection problem. Although graphed-based anomaly detection has\nbeen widely studied, context-dependent anomaly detection is an open problem and\nwithout much current research. We develop a general framework for converting a\ncontext-dependent anomaly detection problem to a link prediction problem,\nallowing well-established techniques from this domain to be applied. We\nimplement a system based on our framework that utilizes knowledge graph\nembedding models and demonstrates the ability to detect outliers using context\nprovided by a semantic knowledge base. We show that our method can detect\ncontext-dependent anomalies with a high degree of accuracy and show that\ncurrent object detectors can detect enough classes to provide the needed\ncontext for good performance within our example domain.",
          "link": "http://arxiv.org/abs/2203.09354",
          "publishedOn": "2022-03-19T00:42:48.202Z",
          "wordCount": 579,
          "title": "Context-Dependent Anomaly Detection with Knowledge Graph Embedding Models. (arXiv:2203.09354v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09346",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ryck_T/0/1/0/all/0/1\">Tim De Ryck</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jagtap_A/0/1/0/all/0/1\">Ameya D. Jagtap</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mishra_S/0/1/0/all/0/1\">Siddhartha Mishra</a>",
          "description": "We prove rigorous bounds on the errors resulting from the approximation of\nthe incompressible Navier-Stokes equations with (extended) physics informed\nneural networks. We show that the underlying PDE residual can be made\narbitrarily small for tanh neural networks with two hidden layers. Moreover,\nthe total error can be estimated in terms of the training error, network size\nand number of quadrature points. The theory is illustrated with numerical\nexperiments.",
          "link": "http://arxiv.org/abs/2203.09346",
          "publishedOn": "2022-03-19T00:42:48.194Z",
          "wordCount": 514,
          "title": "Error estimates for physics informed neural networks approximating the Navier-Stokes equations. (arXiv:2203.09346v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09477",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Li_R/0/1/0/all/0/1\">Ruilin Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_R/0/1/0/all/0/1\">Ruobin Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Suganthan_P/0/1/0/all/0/1\">P. N. Suganthan</a>",
          "description": "Electroencephalogram (EEG) signals are complex, non-linear, and\nnon-stationary in nature. However, previous studies that applied decomposition\nto minimize the complexity mainly exploited the hand-engineering features,\nlimiting the information learned in EEG decoding. Therefore, extracting\nadditional primary features from different disassembled components to improve\nthe EEG-based recognition performance remains challenging. On the other hand,\nattempts have been made to use a single model to learn the hand-engineering\nfeatures. Less work has been done to improve the generalization ability through\nensemble learning. In this work, we propose a novel decomposition-based hybrid\nensemble convolutional neural network (CNN) framework to enhance the capability\nof decoding EEG signals. CNNs, in particular, automatically learn the primary\nfeatures from raw disassembled components but not handcraft features. The first\noption is to fuse the obtained score before the Softmax layer and execute\nback-propagation on the entire ensemble network, whereas the other is to fuse\nthe probability output of the Softmax layer. Moreover, a component-specific\nbatch normalization (CSBN) layer is employed to reduce subject variability.\nAgainst the challenging cross-subject driver fatigue-related situation\nawareness (SA) recognition task, eight models are proposed under the framework,\nwhich all showed superior performance than the strong baselines. The\nperformance of different decomposition methods and ensemble modes were further\ncompared. Results indicated that discrete wavelet transform (DWT)-based\nensemble CNN achieves the best 82.11% among the proposed models. Our framework\ncan be simply extended to any CNN architecture and applied in any EEG-related\nsectors, opening the possibility of extracting more preliminary information\nfrom complex EEG data.",
          "link": "http://arxiv.org/abs/2203.09477",
          "publishedOn": "2022-03-19T00:42:48.177Z",
          "wordCount": 702,
          "title": "A Decomposition-Based Hybrid Ensemble CNN Framework for Improving Cross-Subject EEG Decoding Performance. (arXiv:2203.09477v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marfoq_O/0/1/0/all/0/1\">Othmane Marfoq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neglia_G/0/1/0/all/0/1\">Giovanni Neglia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kameni_L/0/1/0/all/0/1\">Laetitia Kameni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Richard Vidal</a>",
          "description": "Federated learning allows clients to collaboratively learn statistical models\nwhile keeping their data local. Federated learning was originally used to train\na unique global model to be served to all clients, but this approach might be\nsub-optimal when clients' local data distributions are heterogeneous. In order\nto tackle this limitation, recent personalized federated learning methods train\na separate model for each client while still leveraging the knowledge available\nat other clients. In this work, we exploit the ability of deep neural networks\nto extract high quality vectorial representations (embeddings) from non-tabular\ndata, e.g., images and text, to propose a personalization mechanism based on\nlocal memorization. Personalization is obtained interpolating a pre-trained\nglobal model with a $k$-nearest neighbors (kNN) model based on the shared\nrepresentation provided by the global model. We provide generalization bounds\nfor the proposed approach and we show on a suite of federated datasets that\nthis approach achieves significantly higher accuracy and fairness than\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2111.09360",
          "publishedOn": "2022-03-19T00:42:48.171Z",
          "wordCount": 621,
          "title": "Personalized Federated Learning through Local Memorization. (arXiv:2111.09360v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Benz_N/0/1/0/all/0/1\">Nina Corvelo Benz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_M/0/1/0/all/0/1\">Manuel Gomez Rodriguez</a>",
          "description": "Automated decision support systems that are able to infer second opinions\nfrom experts can potentially facilitate a more efficient allocation of\nresources; they can help decide when and from whom to seek a second opinion. In\nthis paper, we look at the design of this type of support systems from the\nperspective of counterfactual inference. We focus on a multiclass\nclassification setting and first show that, if experts make predictions on\ntheir own, the underlying causal mechanism generating their predictions needs\nto satisfy a desirable set invariant property. Further, we show that, for any\ncausal mechanism satisfying this property, there exists an equivalent mechanism\nwhere the predictions by each expert are generated by independent\nsub-mechanisms governed by a common noise. This motivates the design of a set\ninvariant Gumbel-Max structural causal model where the structure of the noise\ngoverning the sub-mechanisms underpinning the model depends on an intuitive\nnotion of similarity between experts which can be estimated from data.\nExperiments on both synthetic and real data show that our model can be used to\ninfer second opinions more accurately than its non-causal counterpart.",
          "link": "http://arxiv.org/abs/2203.08653",
          "publishedOn": "2022-03-19T00:42:48.164Z",
          "wordCount": 626,
          "title": "Counterfactual Inference of Second Opinions. (arXiv:2203.08653v1 [cs.LG] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00520",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Puli_A/0/1/0/all/0/1\">Aahlad Puli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lily H. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oermann_E/0/1/0/all/0/1\">Eric K. Oermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>",
          "description": "In many prediction problems, spurious correlations are induced by a changing\nrelationship between the label and a nuisance variable that is also correlated\nwith the covariates. For example, in classifying animals in natural images, the\nbackground, which is a nuisance, can predict the type of animal. This\nnuisance-label relationship does not always hold, and the performance of a\nmodel trained under one such relationship may be poor on data with a different\nnuisance-label relationship. To build predictive models that perform well\nregardless of the nuisance-label relationship, we develop Nuisance-Randomized\nDistillation (NURD). We introduce the nuisance-randomized distribution, a\ndistribution where the nuisance and the label are independent. Under this\ndistribution, we define the set of representations such that conditioning on\nany member, the nuisance and the label remain independent. We prove that the\nrepresentations in this set always perform better than chance, while\nrepresentations outside of this set may not. NURD finds a representation from\nthis set that is most informative of the label under the nuisance-randomized\ndistribution, and we prove that this representation achieves the highest\nperformance regardless of the nuisance-label relationship. We evaluate NURD on\nseveral tasks including chest X-ray classification where, using non-lung\npatches as the nuisance, NURD produces models that predict pneumonia under\nstrong spurious correlations.",
          "link": "http://arxiv.org/abs/2107.00520",
          "publishedOn": "2022-03-19T00:42:48.158Z",
          "wordCount": 700,
          "title": "Out-of-distribution Generalization in the Presence of Nuisance-Induced Spurious Correlations. (arXiv:2107.00520v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.08812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiongjie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yongxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunpeng Li</a>",
          "description": "While theoretically appealing, the application of the Wasserstein distance to\nlarge-scale machine learning problems has been hampered by its prohibitive\ncomputational cost. The sliced Wasserstein distance and its variants improve\nthe computational efficiency through the random projection, yet they suffer\nfrom low accuracy if the number of projections is not sufficiently large,\nbecause the majority of projections result in trivially small values. In this\nwork, we propose a new family of distance metrics, called augmented sliced\nWasserstein distances (ASWDs), constructed by first mapping samples to\nhigher-dimensional hypersurfaces parameterized by neural networks. It is\nderived from a key observation that (random) linear projections of samples\nresiding on these hypersurfaces would translate to much more flexible nonlinear\nprojections in the original sample space, so they can capture complex\nstructures of the data distribution. We show that the hypersurfaces can be\noptimized by gradient ascent efficiently. We provide the condition under which\nthe ASWD is a valid metric and show that this can be obtained by an injective\nneural network architecture. Numerical results demonstrate that the ASWD\nsignificantly outperforms other Wasserstein variants for both synthetic and\nreal-world problems.",
          "link": "http://arxiv.org/abs/2006.08812",
          "publishedOn": "2022-03-19T00:42:48.149Z",
          "wordCount": 698,
          "title": "Augmented Sliced Wasserstein Distances. (arXiv:2006.08812v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yi Liu</a>",
          "description": "For marketing, we sometimes need to recommend content for multiple pages in\nsequence. Different from general sequential decision making process, the use\ncases have a simpler flow where customers per seeing recommended content on\neach page can only return feedback as moving forward in the process or dropping\nfrom it until a termination state. We refer to this type of problems as\nsequential decision making in linear--flow. We propose to formulate the problem\nas an MDP with Bandits where Bandits are employed to model the transition\nprobability matrix. At recommendation time, we use Thompson sampling (TS) to\nsample the transition probabilities and allocate the best series of actions\nwith analytical solution through exact dynamic programming. The way that we\nformulate the problem allows us to leverage TS's efficiency in balancing\nexploration and exploitation and Bandit's convenience in modeling actions'\nincompatibility. In the simulation study, we observe the proposed MDP with\nBandits algorithm outperforms Q-learning with $\\epsilon$-greedy and decreasing\n$\\epsilon$, independent Bandits, and interaction Bandits. We also find the\nproposed algorithm's performance is the most robust to changes in the\nacross-page interdependence strength.",
          "link": "http://arxiv.org/abs/2107.00204",
          "publishedOn": "2022-03-19T00:42:48.132Z",
          "wordCount": 664,
          "title": "Markov Decision Process modeled with Bandits for Sequential Decision Making in Linear-flow. (arXiv:2107.00204v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pilarski_P/0/1/0/all/0/1\">Patrick M. Pilarski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Butcher_A/0/1/0/all/0/1\">Andrew Butcher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davoodi_E/0/1/0/all/0/1\">Elnaz Davoodi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johanson_M/0/1/0/all/0/1\">Michael Bradley Johanson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brenneis_D/0/1/0/all/0/1\">Dylan J. A. Brenneis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parker_A/0/1/0/all/0/1\">Adam S. R. Parker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acker_L/0/1/0/all/0/1\">Leslie Acker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1\">Matthew M. Botvinick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modayil_J/0/1/0/all/0/1\">Joseph Modayil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1\">Adam White</a>",
          "description": "Learned communication between agents is a powerful tool when approaching\ndecision-making problems that are hard to overcome by any single agent in\nisolation. However, continual coordination and communication learning between\nmachine agents or human-machine partnerships remains a challenging open\nproblem. As a stepping stone toward solving the continual communication\nlearning problem, in this paper we contribute a multi-faceted study into what\nwe term Pavlovian signalling -- a process by which learned, temporally extended\npredictions made by one agent inform decision-making by another agent with\ndifferent perceptual access to their shared environment. We seek to establish\nhow different temporal processes and representational choices impact Pavlovian\nsignalling between learning agents. To do so, we introduce a partially\nobservable decision-making domain we call the Frost Hollow. In this domain a\nprediction learning agent and a reinforcement learning agent are coupled into a\ntwo-part decision-making system that seeks to acquire sparse reward while\navoiding time-conditional hazards. We evaluate two domain variations: 1)\nmachine prediction and control learning in a linear walk, and 2) a prediction\nlearning machine interacting with a human participant in a virtual reality\nenvironment. Our results showcase the speed of learning for Pavlovian\nsignalling, the impact that different temporal representations do (and do not)\nhave on agent-agent coordination, and how temporal aliasing impacts agent-agent\nand human-agent interactions differently. As a main contribution, we establish\nPavlovian signalling as a natural bridge between fixed signalling paradigms and\nfully adaptive communication learning. Our results therefore point to an\nactionable, constructivist path towards continual communication learning\nbetween reinforcement learning agents, with potential impact in a range of\nreal-world settings.",
          "link": "http://arxiv.org/abs/2203.09498",
          "publishedOn": "2022-03-19T00:42:48.126Z",
          "wordCount": 750,
          "title": "The Frost Hollow Experiments: Pavlovian Signalling as a Path to Coordination and Communication Between Agents. (arXiv:2203.09498v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinay_M/0/1/0/all/0/1\">Mor Sinay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agmon_N/0/1/0/all/0/1\">Noa Agmon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maksimov_O/0/1/0/all/0/1\">Oleg Maksimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fux_A/0/1/0/all/0/1\">Aviad Fux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraus_S/0/1/0/all/0/1\">Sarit Kraus</a>",
          "description": "This paper considers the complex problem of a team of UAVs searching targets\nunder uncertainty. The goal of the UAV team is to find all of the moving\ntargets as quickly as possible before they arrive at their selected goal. The\nuncertainty considered is threefold: First, the UAVs do not know the targets'\nlocations and destinations. Second, the sensing capabilities of the UAVs are\nnot perfect. Third, the targets' movement model is unknown. We suggest a\nreal-time algorithmic framework for the UAVs, combining entropy and\nstochastic-temporal belief, that aims at optimizing the probability of a quick\nand successful detection of all of the targets. We have empirically evaluated\nthe algorithmic framework, and have shown its efficiency and significant\nperformance improvement compared to other solutions. Furthermore, we have\nevaluated our framework using Peer Designed Agents (PDAs), which are computer\nagents that simulate targets and show that our algorithmic framework\noutperforms other solutions in this scenario.",
          "link": "http://arxiv.org/abs/2203.09476",
          "publishedOn": "2022-03-19T00:42:48.119Z",
          "wordCount": 595,
          "title": "Uncertainty with UAV Search of Multiple Goal-oriented Targets. (arXiv:2203.09476v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.08648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuelong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>",
          "description": "Graph-based clustering plays an important role in the clustering area. Recent\nstudies about graph convolution neural networks have achieved impressive\nsuccess on graph type data. However, in general clustering tasks, the graph\nstructure of data does not exist such that the strategy to construct a graph is\ncrucial for performance. Therefore, how to extend graph convolution networks\ninto general clustering tasks is an attractive problem. In this paper, we\npropose a graph auto-encoder for general data clustering, which constructs the\ngraph adaptively according to the generative perspective of graphs. The\nadaptive process is designed to induce the model to exploit the high-level\ninformation behind data and utilize the non-Euclidean structure sufficiently.\nWe further design a novel mechanism with rigorous analysis to avoid the\ncollapse caused by the adaptive construction. Via combining the generative\nmodel for network embedding and graph-based clustering, a graph auto-encoder\nwith a novel decoder is developed such that it performs well in weighted graph\nused scenarios. Extensive experiments prove the superiority of our model.",
          "link": "http://arxiv.org/abs/2002.08648",
          "publishedOn": "2022-03-19T00:42:48.112Z",
          "wordCount": 667,
          "title": "Adaptive Graph Auto-Encoder for General Data Clustering. (arXiv:2002.08648v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.12535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Riaz_H/0/1/0/all/0/1\">Hamd ul Moqeet Riaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benbarka_N/0/1/0/all/0/1\">Nuri Benbarka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoefer_T/0/1/0/all/0/1\">Timon Hoefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zell_A/0/1/0/all/0/1\">Andreas Zell</a>",
          "description": "We present FourierMask, which employs Fourier series combined with implicit\nneural representations to generate instance segmentation masks. We apply a\nFourier mapping (FM) to the coordinate locations and utilize the mapped\nfeatures as inputs to an implicit representation (coordinate-based multi-layer\nperceptron (MLP)). FourierMask learns to predict the coefficients of the FM for\na particular instance, and therefore adapts the FM to a specific object. This\nallows FourierMask to be generalized to predict instance segmentation masks\nfrom natural images. Since implicit functions are continuous in the domain of\ninput coordinates, we illustrate that by sub-sampling the input pixel\ncoordinates, we can generate higher resolution masks during inference.\nFurthermore, we train a renderer MLP (FourierRend) on the uncertain predictions\nof FourierMask and illustrate that it significantly improves the quality of the\nmasks. FourierMask shows competitive results on the MS COCO dataset compared to\nthe baseline Mask R-CNN at the same output resolution and surpasses it on\nhigher resolution.",
          "link": "http://arxiv.org/abs/2112.12535",
          "publishedOn": "2022-03-19T00:42:48.105Z",
          "wordCount": 632,
          "title": "FourierMask: Instance Segmentation using Fourier Mapping in Implicit Neural Networks. (arXiv:2112.12535v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Liang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaofeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoxiao Li</a>",
          "description": "In this work, we focus on the challenging task, neuro-disease classification,\nusing functional magnetic resonance imaging (fMRI). In population graph-based\ndisease analysis, graph convolutional neural networks (GCNs) have achieved\nremarkable success. However, these achievements are inseparable from abundant\nlabeled data and sensitive to spurious signals. To improve fMRI representation\nlearning and classification under a label-efficient setting, we propose a novel\nand theory-driven self-supervised learning (SSL) framework on GCNs, namely\nGraph CCA for Temporal self-supervised learning on fMRI analysis GATE.\nConcretely, it is demanding to design a suitable and effective SSL strategy to\nextract formation and robust features for fMRI. To this end, we investigate\nseveral new graph augmentation strategies from fMRI dynamic functional\nconnectives (FC) for SSL training. Further, we leverage canonical-correlation\nanalysis (CCA) on different temporal embeddings and present the theoretical\nimplications. Consequently, this yields a novel two-step GCN learning procedure\ncomprised of (i) SSL on an unlabeled fMRI population graph and (ii) fine-tuning\non a small labeled fMRI dataset for a classification task. Our method is tested\non two independent fMRI datasets, demonstrating superior performance on autism\nand dementia diagnosis.",
          "link": "http://arxiv.org/abs/2203.09034",
          "publishedOn": "2022-03-19T00:42:48.090Z",
          "wordCount": 630,
          "title": "GATE: Graph CCA for Temporal SElf-supervised Learning for Label-efficient fMRI Analysis. (arXiv:2203.09034v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.15511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Han Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Mingyi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianyi Chen</a>",
          "description": "Asynchronous and parallel implementation of standard reinforcement learning\n(RL) algorithms is a key enabler of the tremendous success of modern RL. Among\nmany asynchronous RL algorithms, arguably the most popular and effective one is\nthe asynchronous advantage actor-critic (A3C) algorithm. Although A3C is\nbecoming the workhorse of RL, its theoretical properties are still not\nwell-understood, including its non-asymptotic analysis and the performance gain\nof parallelism (a.k.a. linear speedup). This paper revisits the A3C algorithm\nand establishes its non-asymptotic convergence guarantees. Under both i.i.d.\nand Markovian sampling, we establish the local convergence guarantee for A3C in\nthe general policy approximation case and the global convergence guarantee in\nsoftmax policy parameterization. Under i.i.d. sampling, A3C obtains sample\ncomplexity of $\\mathcal{O}(\\epsilon^{-2.5}/N)$ per worker to achieve $\\epsilon$\naccuracy, where $N$ is the number of workers. Compared to the best-known sample\ncomplexity of $\\mathcal{O}(\\epsilon^{-2.5})$ for two-timescale AC, A3C achieves\n\\emph{linear speedup}, which justifies the advantage of parallelism and\nasynchrony in AC algorithms theoretically for the first time. Numerical tests\non synthetic environment, OpenAI Gym environments and Atari games have been\nprovided to verify our theoretical analysis.",
          "link": "http://arxiv.org/abs/2012.15511",
          "publishedOn": "2022-03-19T00:42:48.082Z",
          "wordCount": 651,
          "title": "Towards Understanding Asynchronous Advantage Actor-critic: Convergence and Linear Speedup. (arXiv:2012.15511v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.06853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozbay_E/0/1/0/all/0/1\">Eren Ozbay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamble_V/0/1/0/all/0/1\">Vijay Kamble</a>",
          "description": "On-demand labor platforms aim to train a skilled workforce to serve its\nincoming demand for jobs. Since limited jobs are available for training, and it\nis usually not necessary to train all workers, efficient matching of training\njobs requires prioritizing fast learners over slow ones. However, the learning\nrates of novice workers are unknown, resulting in a tradeoff between\nexploration (learning the learning rates) and exploitation (training the best\nworkers). Motivated to study this tradeoff, we analyze a novel objective within\nthe stochastic multi-armed bandit framework. Given $K$ arms, instead of\nmaximizing the expected total reward from $T$ pulls (the traditional \"sum\"\nobjective), we consider the vector of cumulative rewards earned from the $K$\narms at the end of $T$ pulls and aim to maximize the expected highest\ncumulative reward (the \"max\" objective). When rewards represent skill\nincrements, this corresponds to the objective of training a single highly\nskilled worker from a set of novice workers, using a limited supply of training\njobs. For this objective, we show that any policy must incur an\ninstance-dependent asymptotic regret of $\\Omega(\\log T)$ (with a higher\ninstance-dependent constant) and a worst-case regret of\n$\\Omega(K^{1/3}T^{2/3})$. We then design an explore-then-commit policy\nfeaturing exploration based on appropriately tuned confidence bounds on the\nmean reward and an adaptive stopping criterion, which adapts to the problem\ndifficulty and achieves these bounds (up to logarithmic factors). We generalize\nour algorithmic insights to the problem of maximizing the expected value of the\naverage cumulative reward of the top $m$ arms with the highest cumulative\nrewards, corresponding to the case where multiple workers must be trained. Our\nnumerical experiments demonstrate the efficacy of our policies compared to\nseveral natural alternatives in practical parameter regimes.",
          "link": "http://arxiv.org/abs/2006.06853",
          "publishedOn": "2022-03-19T00:42:48.075Z",
          "wordCount": 769,
          "title": "Bandit Labor Training. (arXiv:2006.06853v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chira_D/0/1/0/all/0/1\">Darius Chira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haralampiev_I/0/1/0/all/0/1\">Ilian Haralampiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winther_O/0/1/0/all/0/1\">Ole Winther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dittadi_A/0/1/0/all/0/1\">Andrea Dittadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lievin_V/0/1/0/all/0/1\">Valentin Li&#xe9;vin</a>",
          "description": "Image super-resolution (SR) techniques are used to generate a high-resolution\nimage from a low-resolution image. Until now, deep generative models such as\nautoregressive models and Generative Adversarial Networks (GANs) have proven to\nbe effective at modelling high-resolution images. Models based on Variational\nAutoencoders (VAEs) have often been criticized for their feeble generative\nperformance, but with new advancements such as VDVAE (very deep VAE), there is\nnow strong evidence that deep VAEs have the potential to outperform current\nstate-of-the-art models for high-resolution image generation. In this paper, we\nintroduce VDVAE-SR, a new model that aims to exploit the most recent deep VAE\nmethodologies to improve upon image super-resolution using transfer learning on\npretrained VDVAEs. Through qualitative and quantitative evaluations, we show\nthat the proposed model is competitive with other state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2203.09445",
          "publishedOn": "2022-03-19T00:42:48.067Z",
          "wordCount": 578,
          "title": "Image Super-Resolution With Deep Variational Autoencoders. (arXiv:2203.09445v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Finocchiaro_J/0/1/0/all/0/1\">Jessie Finocchiaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frongillo_R/0/1/0/all/0/1\">Rafael Frongillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nueve_E/0/1/0/all/0/1\">Enrique Nueve</a>",
          "description": "The Lov\\'asz hinge is a convex surrogate recently proposed for structured\nbinary classification, in which $k$ binary predictions are made simultaneously\nand the error is judged by a submodular set function. Despite its wide usage in\nimage segmentation and related problems, its consistency has remained open. We\nresolve this open question, showing that the Lov\\'asz hinge is inconsistent for\nits desired target unless the set function is modular. Leveraging a recent\nembedding framework, we instead derive the target loss for which the Lov\\'asz\nhinge is consistent. This target, which we call the structured abstain problem,\nallows one to abstain on any subset of the $k$ predictions. We derive two link\nfunctions, each of which are consistent for all submodular set functions\nsimultaneously.",
          "link": "http://arxiv.org/abs/2203.08645",
          "publishedOn": "2022-03-19T00:42:48.051Z",
          "wordCount": 575,
          "title": "The Structured Abstain Problem and the Lov\\'asz Hinge. (arXiv:2203.08645v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsubara_Y/0/1/0/all/0/1\">Yoshitomo Matsubara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruihan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levorato_M/0/1/0/all/0/1\">Marco Levorato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Split computing distributes the execution of a neural network (e.g., for a\nclassification task) between a mobile device and a more powerful edge server. A\nsimple alternative to splitting the network is to carry out the supervised task\npurely on the edge server while compressing and transmitting the full data, and\nmost approaches have barely outperformed this baseline. This paper proposes a\nnew approach for discretizing and entropy-coding intermediate feature\nactivations to efficiently transmit them from the mobile device to the edge\nserver. We show that a efficient splittable network architecture results from a\nthree-way tradeoff between (a) minimizing the computation on the mobile device,\n(b) minimizing the size of the data to be transmitted, and (c) maximizing the\nmodel's prediction performance. We propose an architecture based on this\ntradeoff and train the splittable network and entropy model in a knowledge\ndistillation framework. In an extensive set of experiments involving three\nvision tasks, three datasets, nine baselines, and more than 180 trained models,\nwe show that our approach improves supervised rate-distortion tradeoffs while\nmaintaining a considerably smaller encoder size. We also release sc2bench, an\ninstallable Python package, to encourage and facilitate future studies on\nsupervised compression for split computing (SC2).",
          "link": "http://arxiv.org/abs/2203.08875",
          "publishedOn": "2022-03-19T00:42:48.044Z",
          "wordCount": 654,
          "title": "SC2: Supervised Compression for Split Computing. (arXiv:2203.08875v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09347",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Eckstein_S/0/1/0/all/0/1\">Stephan Eckstein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iske_A/0/1/0/all/0/1\">Armin Iske</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Trabs_M/0/1/0/all/0/1\">Mathias Trabs</a>",
          "description": "In a high-dimensional regression framework, we study consequences of the\nnaive two-step procedure where first the dimension of the input variables is\nreduced and second, the reduced input variables are used to predict the output\nvariable. More specifically we combine principal component analysis (PCA) with\nkernel regression. In order to analyze the resulting regression errors, a novel\nstability result of kernel regression with respect to the Wasserstein distance\nis derived. This allows us to bound errors that occur when perturbed input data\nis used to fit a kernel function. We combine the stability result with known\nestimates from the literature on both principal component analysis and kernel\nregression to obtain convergence rates for the two-step procedure.",
          "link": "http://arxiv.org/abs/2203.09347",
          "publishedOn": "2022-03-19T00:42:48.037Z",
          "wordCount": 562,
          "title": "Dimensionality Reduction and Wasserstein Stability for Kernel Regression. (arXiv:2203.09347v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fort_G/0/1/0/all/0/1\">Gersende Fort</a> (IMT), <a href=\"http://arxiv.org/find/cs/1/au:+Pascal_B/0/1/0/all/0/1\">Barbara Pascal</a> (CRIStAL), <a href=\"http://arxiv.org/find/cs/1/au:+Abry_P/0/1/0/all/0/1\">Patrice Abry</a> (Phys-ENS), <a href=\"http://arxiv.org/find/cs/1/au:+Pustelnik_N/0/1/0/all/0/1\">Nelly Pustelnik</a> (Phys-ENS)",
          "description": "Monitoring the Covid19 pandemic constitutes a critical societal stake that\nreceived considerable research efforts. The intensity of the pandemic on a\ngiven territory is efficiently measured by the reproduction number, quantifying\nthe rate of growth of daily new infections. Recently, estimates for the time\nevolution of the reproduction number were produced using an inverse problem\nformulation with a nonsmooth functional minimization. While it was designed to\nbe robust to the limited quality of the Covid19 data (outliers, missing\ncounts), the procedure lacks the ability to output credibility interval based\nestimates. This remains a severe limitation for practical use in actual\npandemic monitoring by epidemiologists that the present work aims to overcome\nby use of Monte Carlo sampling. After interpretation of the functional into a\nBayesian framework, several sampling schemes are tailored to adjust the\nnonsmooth nature of the resulting posterior distribution. The originality of\nthe devised algorithms stems from combining a Langevin Monte Carlo sampling\nscheme with Proximal operators. Performance of the new algorithms in producing\nrelevant credibility intervals for the reproduction number estimates and\ndenoised counts are compared. Assessment is conducted on real daily new\ninfection counts made available by the Johns Hopkins University. The interest\nof the devised monitoring tools are illustrated on Covid19 data from several\ndifferent countries.",
          "link": "http://arxiv.org/abs/2203.09142",
          "publishedOn": "2022-03-19T00:42:48.029Z",
          "wordCount": 719,
          "title": "Covid19 Reproduction Number: Credibility Intervals by Blockwise Proximal Monte Carlo Samplers. (arXiv:2203.09142v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.02612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zih-Syuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Ching-pei Lee</a>",
          "description": "This paper proposes an algorithm (RMDA) for training neural networks (NNs)\nwith a regularization term for promoting desired structures. RMDA does not\nincur computation additional to proximal SGD with momentum, and achieves\nvariance reduction without requiring the objective function to be of the\nfinite-sum form. Through the tool of manifold identification from nonlinear\noptimization, we prove that after a finite number of iterations, all iterates\nof RMDA possess a desired structure identical to that induced by the\nregularizer at the stationary point of asymptotic convergence, even in the\npresence of engineering tricks like data augmentation and dropout that\ncomplicate the training process. Experiments on training NNs with structured\nsparsity confirm that variance reduction is necessary for such an\nidentification, and show that RMDA thus significantly outperforms existing\nmethods for this task. For unstructured sparsity, RMDA also outperforms a\nstate-of-the-art pruning method, validating the benefits of training structured\nNNs through regularization.",
          "link": "http://arxiv.org/abs/2112.02612",
          "publishedOn": "2022-03-19T00:42:48.023Z",
          "wordCount": 619,
          "title": "Training Structured Neural Networks Through Manifold Identification and Variance Reduction. (arXiv:2112.02612v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nash_C/0/1/0/all/0/1\">Charlie Nash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carreira_J/0/1/0/all/0/1\">Jo&#xe3;o Carreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_J/0/1/0/all/0/1\">Jacob Walker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barr_I/0/1/0/all/0/1\">Iain Barr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaegle_A/0/1/0/all/0/1\">Andrew Jaegle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malinowski_M/0/1/0/all/0/1\">Mateusz Malinowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Battaglia_P/0/1/0/all/0/1\">Peter Battaglia</a>",
          "description": "We present a general-purpose framework for image modelling and vision tasks\nbased on probabilistic frame prediction. Our approach unifies a broad range of\ntasks, from image segmentation, to novel view synthesis and video\ninterpolation. We pair this framework with an architecture we term Transframer,\nwhich uses U-Net and Transformer components to condition on annotated context\nframes, and outputs sequences of sparse, compressed image features. Transframer\nis the state-of-the-art on a variety of video generation benchmarks, is\ncompetitive with the strongest models on few-shot view synthesis, and can\ngenerate coherent 30 second videos from a single image without any explicit\ngeometric information. A single generalist Transframer simultaneously produces\npromising results on 8 tasks, including semantic segmentation, image\nclassification and optical flow prediction with no task-specific architectural\ncomponents, demonstrating that multi-task computer vision can be tackled using\nprobabilistic image models. Our approach can in principle be applied to a wide\nrange of applications that require learning the conditional structure of\nannotated image-formatted data.",
          "link": "http://arxiv.org/abs/2203.09494",
          "publishedOn": "2022-03-19T00:42:48.007Z",
          "wordCount": 608,
          "title": "Transframer: Arbitrary Frame Prediction with Generative Models. (arXiv:2203.09494v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.13389",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sushko_V/0/1/0/all/0/1\">Vadim Sushko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1\">Juergen Gall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khoreva_A/0/1/0/all/0/1\">Anna Khoreva</a>",
          "description": "Given a large dataset for training, GANs can achieve remarkable performance\nfor the image synthesis task. However, training GANs in extremely low data\nregimes remains a challenge, as overfitting often occurs, leading to\nmemorization or training divergence. In this work, we introduce SIV-GAN, an\nunconditional generative model that can generate new scene compositions from a\nsingle training image or a single video clip. We propose a two-branch\ndiscriminator architecture, with content and layout branches designed to judge\ninternal content and scene layout realism separately from each other. This\ndiscriminator design enables synthesis of visually plausible, novel\ncompositions of a scene, with varying content and layout, while preserving the\ncontext of the original sample. Compared to previous single-image GANs, our\nmodel generates more diverse, higher quality images, while not being restricted\nto a single image setting. We show that SIV-GAN successfully deals with a new\nchallenging task of learning from a single video, for which prior GAN models\nfail to achieve synthesis of both high quality and diversity.",
          "link": "http://arxiv.org/abs/2103.13389",
          "publishedOn": "2022-03-19T00:42:47.999Z",
          "wordCount": 654,
          "title": "Generating Novel Scene Compositions from Single Images and Videos. (arXiv:2103.13389v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.00710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_A/0/1/0/all/0/1\">Alysa Ziying Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lizhen Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>",
          "description": "In parallel with the rapid adoption of Artificial Intelligence (AI) empowered\nby advances in AI research, there have been growing awareness and concerns of\ndata privacy. Recent significant developments in the data regulation landscape\nhave prompted a seismic shift in interest towards privacy-preserving AI. This\nhas contributed to the popularity of Federated Learning (FL), the leading\nparadigm for the training of machine learning models on data silos in a\nprivacy-preserving manner. In this survey, we explore the domain of\nPersonalized FL (PFL) to address the fundamental challenges of FL on\nheterogeneous data, a universal characteristic inherent in all real-world\ndatasets. We analyze the key motivations for PFL and present a unique taxonomy\nof PFL techniques categorized according to the key challenges and\npersonalization strategies in PFL. We highlight their key ideas, challenges and\nopportunities and envision promising future trajectories of research towards\nnew PFL architectural design, realistic PFL benchmarking, and trustworthy PFL\napproaches.",
          "link": "http://arxiv.org/abs/2103.00710",
          "publishedOn": "2022-03-19T00:42:47.993Z",
          "wordCount": 650,
          "title": "Towards Personalized Federated Learning. (arXiv:2103.00710v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peibo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yixing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagnucco_M/0/1/0/all/0/1\">Maurice Pagnucco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yang Song</a>",
          "description": "Graph neural networks (GNNs) have been extensively developed for graph\nrepresentation learning in various application domains. However, similar to all\nother neural networks models, GNNs suffer from the black-box problem as people\ncannot understand the mechanism underlying them. To solve this problem, several\nGNN explainability methods have been proposed to explain the decisions made by\nGNNs. In this survey, we give an overview of the state-of-the-art GNN\nexplainability methods and how they are evaluated. Furthermore, we propose a\nnew evaluation metric and conduct thorough experiments to compare GNN\nexplainability methods on real world datasets. We also suggest future\ndirections for GNN explainability.",
          "link": "http://arxiv.org/abs/2203.09258",
          "publishedOn": "2022-03-19T00:42:47.851Z",
          "wordCount": 542,
          "title": "Explainability in Graph Neural Networks: An Experimental Survey. (arXiv:2203.09258v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1\">Gitta Kutyniok</a>",
          "description": "We currently witness the spectacular success of artificial intelligence in\nboth science and public life. However, the development of a rigorous\nmathematical foundation is still at an early stage. In this survey article,\nwhich is based on an invited lecture at the International Congress of\nMathematicians 2022, we will in particular focus on the current \"workhorse\" of\nartificial intelligence, namely deep neural networks. We will present the main\ntheoretical directions along with several exemplary results and discuss key\nopen problems.",
          "link": "http://arxiv.org/abs/2203.08890",
          "publishedOn": "2022-03-19T00:42:47.836Z",
          "wordCount": 526,
          "title": "The Mathematics of Artificial Intelligence. (arXiv:2203.08890v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kangsepp_M/0/1/0/all/0/1\">Markus K&#xe4;ngsepp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valk_K/0/1/0/all/0/1\">Kaspar Valk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kull_M/0/1/0/all/0/1\">Meelis Kull</a>",
          "description": "Every uncalibrated classifier has a corresponding true calibration map that\ncalibrates its confidence. Deviations of this idealistic map from the identity\nmap reveal miscalibration. Such calibration errors can be reduced with many\npost-hoc calibration methods which fit some family of calibration maps on a\nvalidation dataset. In contrast, evaluation of calibration with the expected\ncalibration error (ECE) on the test set does not explicitly involve fitting.\nHowever, as we demonstrate, ECE can still be viewed as if fitting a family of\nfunctions on the test data. This motivates the fit-on-the-test view on\nevaluation: first, approximate a calibration map on the test data, and second,\nquantify its distance from the identity. Exploiting this view allows us to\nunlock missed opportunities: (1) use the plethora of post-hoc calibration\nmethods for evaluating calibration; (2) tune the number of bins in ECE with\ncross-validation. Furthermore, we introduce: (3) benchmarking on pseudo-real\ndata where the true calibration map can be estimated very precisely; and (4)\nnovel calibration and evaluation methods using new calibration map families PL\nand PL3.",
          "link": "http://arxiv.org/abs/2203.08958",
          "publishedOn": "2022-03-19T00:42:47.829Z",
          "wordCount": 619,
          "title": "On the Usefulness of the Fit-on-the-Test View on Evaluating Calibration of Classifiers. (arXiv:2203.08958v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09474",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Graczyk_K/0/1/0/all/0/1\">Krzysztof M. Graczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pawlowski_J/0/1/0/all/0/1\">Jaros&#x142;aw Paw&#x142;owski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majchrowska_S/0/1/0/all/0/1\">Sylwia Majchrowska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golan_T/0/1/0/all/0/1\">Tomasz Golan</a>",
          "description": "The statistical properties of the density map (DM) approach to counting\nmicrobiological objects on images are studied in detail. The DM is given by\nU$^2$-Net. Two statistical methods for deep neural networks are utilized: the\nbootstrap and the Monte Carlo (MC) dropout. The detailed analysis of the\nuncertainties for the DM predictions leads to a deeper understanding of the DM\nmodel's deficiencies. Based on our investigation, we propose a\nself-normalization module in the network. The improved network model, called\nSelf-Normalized Density Map (SNDM), can correct its output density map by\nitself to accurately predict the total number of objects in the image. The SNDM\narchitecture outperforms the original model. Moreover, both statistical\nframeworks -- bootstrap and MC dropout -- have consistent statistical results\nfor SNDM, which were not observed in the original model.",
          "link": "http://arxiv.org/abs/2203.09474",
          "publishedOn": "2022-03-19T00:42:47.800Z",
          "wordCount": 587,
          "title": "Self-Normalized Density Map (SNDM) for Counting Microbiological Objects. (arXiv:2203.09474v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.02910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bevilacqua_B/0/1/0/all/0/1\">Beatrice Bevilacqua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frasca_F/0/1/0/all/0/1\">Fabrizio Frasca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_D/0/1/0/all/0/1\">Derek Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_B/0/1/0/all/0/1\">Balasubramaniam Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1\">Chen Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balamurugan_G/0/1/0/all/0/1\">Gopinath Balamurugan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael M. Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maron_H/0/1/0/all/0/1\">Haggai Maron</a>",
          "description": "Message-passing neural networks (MPNNs) are the leading architecture for deep\nlearning on graph-structured data, in large part due to their simplicity and\nscalability. Unfortunately, it was shown that these architectures are limited\nin their expressive power. This paper proposes a novel framework called\nEquivariant Subgraph Aggregation Networks (ESAN) to address this issue. Our\nmain observation is that while two graphs may not be distinguishable by an\nMPNN, they often contain distinguishable subgraphs. Thus, we propose to\nrepresent each graph as a set of subgraphs derived by some predefined policy,\nand to process it using a suitable equivariant architecture. We develop novel\nvariants of the 1-dimensional Weisfeiler-Leman (1-WL) test for graph\nisomorphism, and prove lower bounds on the expressiveness of ESAN in terms of\nthese new WL variants. We further prove that our approach increases the\nexpressive power of both MPNNs and more expressive architectures. Moreover, we\nprovide theoretical results that describe how design choices such as the\nsubgraph selection policy and equivariant neural architecture affect our\narchitecture's expressive power. To deal with the increased computational cost,\nwe propose a subgraph sampling scheme, which can be viewed as a stochastic\nversion of our framework. A comprehensive set of experiments on real and\nsynthetic datasets demonstrates that our framework improves the expressive\npower and overall performance of popular GNN architectures.",
          "link": "http://arxiv.org/abs/2110.02910",
          "publishedOn": "2022-03-19T00:42:47.794Z",
          "wordCount": 705,
          "title": "Equivariant Subgraph Aggregation Networks. (arXiv:2110.02910v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galagali_N/0/1/0/all/0/1\">Nikhil Galagali</a>",
          "description": "Large-scale monitoring, anomaly detection, and root cause analysis of metrics\nare essential requirements of the internet-services industry. To address the\nneed to continuously monitor millions of metrics, many anomaly detection\napproaches are being used on a daily basis by large internet-based companies.\nHowever, in spite of the significant progress made to accurately and\nefficiently detect anomalies in metrics, the sheer scale of the number of\nmetrics has meant there are still a large number of false alarms that need to\nbe investigated. This paper presents a framework for reliable large-scale\nanomaly detection. It is significantly more accurate than existing approaches\nand allows for easy interpretation of models, thus enabling practical data\nmonitoring in the internet-services domain.",
          "link": "http://arxiv.org/abs/2203.08067",
          "publishedOn": "2022-03-19T00:42:47.787Z",
          "wordCount": 569,
          "title": "Practical data monitoring in the internet-services domain. (arXiv:2203.08067v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huaxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>",
          "description": "Meta-learning enables algorithms to quickly learn a newly encountered task\nwith just a few labeled examples by transferring previously learned knowledge.\nHowever, the bottleneck of current meta-learning algorithms is the requirement\nof a large number of meta-training tasks, which may not be accessible in\nreal-world scenarios. To address the challenge that available tasks may not\ndensely sample the space of tasks, we propose to augment the task set through\ninterpolation. By meta-learning with task interpolation (MLTI), our approach\neffectively generates additional tasks by randomly sampling a pair of tasks and\ninterpolating the corresponding features and labels. Under both gradient-based\nand metric-based meta-learning settings, our theoretical analysis shows MLTI\ncorresponds to a data-adaptive meta-regularization and further improves the\ngeneralization. Empirically, in our experiments on eight datasets from diverse\ndomains including image recognition, pose prediction, molecule property\nprediction, and medical image classification, we find that the proposed general\nMLTI framework is compatible with representative meta-learning algorithms and\nconsistently outperforms other state-of-the-art strategies.",
          "link": "http://arxiv.org/abs/2106.02695",
          "publishedOn": "2022-03-19T00:42:47.771Z",
          "wordCount": 623,
          "title": "Meta-Learning with Fewer Tasks through Task Interpolation. (arXiv:2106.02695v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.08450",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaler_T/0/1/0/all/0/1\">Tim Kaler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stathas_N/0/1/0/all/0/1\">Nickolas Stathas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_A/0/1/0/all/0/1\">Anne Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iliopoulos_A/0/1/0/all/0/1\">Alexandros-Stavros Iliopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schardl_T/0/1/0/all/0/1\">Tao B. Schardl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leiserson_C/0/1/0/all/0/1\">Charles E. Leiserson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jie Chen</a>",
          "description": "Improving the training and inference performance of graph neural networks\n(GNNs) is faced with a challenge uncommon in general neural networks: creating\nmini-batches requires a lot of computation and data movement due to the\nexponential growth of multi-hop graph neighborhoods along network layers. Such\na unique challenge gives rise to a diverse set of system design choices. We\nargue in favor of performing mini-batch training with neighborhood sampling in\na distributed multi-GPU environment, under which we identify major performance\nbottlenecks hitherto under-explored by developers: mini-batch preparation and\ntransfer. We present a sequence of improvements to mitigate these bottlenecks,\nincluding a performance-engineered neighborhood sampler, a shared-memory\nparallelization strategy, and the pipelining of batch transfer with GPU\ncomputation. We also conduct an empirical analysis that supports the use of\nsampling for inference, showing that test accuracies are not materially\ncompromised. Such an observation unifies training and inference, simplifying\nmodel implementation. We report comprehensive experimental results with several\nbenchmark data sets and GNN architectures, including a demonstration that, for\nthe ogbn-papers100M data set, our system SALIENT achieves a speedup of 3x over\na standard PyTorch-Geometric implementation with a single GPU and a further 8x\nparallel speedup with 16 GPUs. Therein, training a 3-layer GraphSAGE model with\nsampling fanout (15, 10, 5) takes 2.0 seconds per epoch and inference with\nfanout (20, 20, 20) takes 2.4 seconds, attaining test accuracy 64.58%.",
          "link": "http://arxiv.org/abs/2110.08450",
          "publishedOn": "2022-03-19T00:42:47.764Z",
          "wordCount": 727,
          "title": "Accelerating Training and Inference of Graph Neural Networks with Fast Sampling and Pipelining. (arXiv:2110.08450v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geifman_A/0/1/0/all/0/1\">Amnon Geifman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galun_M/0/1/0/all/0/1\">Meirav Galun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1\">David Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basri_R/0/1/0/all/0/1\">Ronen Basri</a>",
          "description": "We study the properties of various over-parametrized convolutional neural\narchitectures through their respective Gaussian process and neural tangent\nkernels. We prove that, with normalized multi-channel input and ReLU\nactivation, the eigenfunctions of these kernels with the uniform measure are\nformed by products of spherical harmonics, defined over the channels of the\ndifferent pixels. We next use hierarchical factorizable kernels to bound their\nrespective eigenvalues. We show that the eigenvalues decay polynomially,\nquantify the rate of decay, and derive measures that reflect the composition of\nhierarchical features in these networks. Our results provide concrete\nquantitative characterization of over-parameterized convolutional network\narchitectures.",
          "link": "http://arxiv.org/abs/2203.09255",
          "publishedOn": "2022-03-19T00:42:47.757Z",
          "wordCount": 546,
          "title": "On the Spectral Bias of Convolutional Neural Tangent and Gaussian Process Kernels. (arXiv:2203.09255v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahamim_A/0/1/0/all/0/1\">Adir Rahamim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naeh_I/0/1/0/all/0/1\">Itay Naeh</a>",
          "description": "In this paper, we introduce a novel neural network training framework that\nincreases model's adversarial robustness to adversarial attacks while\nmaintaining high clean accuracy by combining contrastive learning (CL) with\nadversarial training (AT). We propose to improve model robustness to\nadversarial attacks by learning feature representations that are consistent\nunder both data augmentations and adversarial perturbations. We leverage\ncontrastive learning to improve adversarial robustness by considering an\nadversarial example as another positive example, and aim to maximize the\nsimilarity between random augmentations of data samples and their adversarial\nexample, while constantly updating the classification head in order to avoid a\ncognitive dissociation between the classification head and the embedding space.\nThis dissociation is caused by the fact that CL updates the network up to the\nembedding space, while freezing the classification head which is used to\ngenerate new positive adversarial examples. We validate our method, Contrastive\nLearning with Adversarial Features(CLAF), on the CIFAR-10 dataset on which it\noutperforms both robust accuracy and clean accuracy over alternative supervised\nand self-supervised adversarial learning methods.",
          "link": "http://arxiv.org/abs/2203.08959",
          "publishedOn": "2022-03-19T00:42:47.751Z",
          "wordCount": 615,
          "title": "Robustness through Cognitive Dissociation Mitigation in Contrastive Adversarial Training. (arXiv:2203.08959v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.15277",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xue_Y/0/1/0/all/0/1\">Yu Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yuan_Z/0/1/0/all/0/1\">Ziming Yuan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Slowik_A/0/1/0/all/0/1\">Adam Slowik</a>",
          "description": "With the development of automatic sleep stage classification (ASSC)\ntechniques, many classical methods such as k-means, decision tree, and SVM have\nbeen used in automatic sleep stage classification. However, few methods explore\ndeep learning on ASSC. Meanwhile, most deep learning methods require extensive\nexpertise and suffer from a mass of handcrafted steps which are time-consuming\nespecially when dealing with multi-classification tasks. In this paper, we\npropose an efficient five-sleep-stage classification method using convolutional\nneural networks (CNNs) with a novel data processing trick and we design neural\narchitecture search (NAS) technique based on genetic algorithm (GA), NAS-G, to\nsearch for the best CNN architecture. Firstly, we attach each kernel with an\nadaptive coefficient to enhance the signal processing of the inputs. This can\nenhance the propagation of informative features and suppress the propagation of\nuseless features in the early stage of the network. Then, we make full use of\nGA's heuristic search and the advantage of no need for the gradient to search\nfor the best architecture of CNN. This can achieve a CNN with better\nperformance than a handcrafted one in a large search space at the minimum cost.\nWe verify the convergence of our data processing trick and compare the\nperformance of traditional CNNs before and after using our trick. Meanwhile, we\ncompare the performance between the CNN generated through NAS-G and the\ntraditional CNNs with our trick. The experiments demonstrate that the\nconvergence of CNNs with data processing trick is faster than without data\nprocessing trick and the CNN with data processing trick generated by NAS-G\noutperforms the handcrafted counterparts that use the data processing trick\ntoo.",
          "link": "http://arxiv.org/abs/2110.15277",
          "publishedOn": "2022-03-19T00:42:47.743Z",
          "wordCount": 765,
          "title": "A Novel Sleep Stage Classification Using CNN Generated by an Efficient Neural Architecture Search with a New Data Processing Trick. (arXiv:2110.15277v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09250",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Higgins_I/0/1/0/all/0/1\">Irina Higgins</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Racaniere_S/0/1/0/all/0/1\">S&#xe9;bastien Racani&#xe8;re</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Rezende_D/0/1/0/all/0/1\">Danilo Rezende</a>",
          "description": "Biological intelligence is remarkable in its ability to produce complex\nbehaviour in many diverse situations through data efficient, generalisable and\ntransferable skill acquisition. It is believed that learning \"good\" sensory\nrepresentations is important for enabling this, however there is little\nagreement as to what a good representation should look like. In this review\narticle we are going to argue that symmetry transformations are a fundamental\nprinciple that can guide our search for what makes a good representation. The\nidea that there exist transformations (symmetries) that affect some aspects of\nthe system but not others, and their relationship to conserved quantities has\nbecome central in modern physics, resulting in a more unified theoretical\nframework and even ability to predict the existence of new particles. Recently,\nsymmetries have started to gain prominence in machine learning too, resulting\nin more data efficient and generalisable algorithms that can mimic some of the\ncomplex behaviours produced by biological intelligence. Finally, first\ndemonstrations of the importance of symmetry transformations for representation\nlearning in the brain are starting to arise in neuroscience. Taken together,\nthe overwhelming positive effect that symmetries bring to these disciplines\nsuggest that they may be an important general framework that determines the\nstructure of the universe, constrains the nature of natural tasks and\nconsequently shapes both biological and artificial intelligence.",
          "link": "http://arxiv.org/abs/2203.09250",
          "publishedOn": "2022-03-19T00:42:47.728Z",
          "wordCount": 669,
          "title": "Symmetry-Based Representations for Artificial and Biological General Intelligence. (arXiv:2203.09250v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08887",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ru_B/0/1/0/all/0/1\">Binxin Ru</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Esperanca_P/0/1/0/all/0/1\">Pedro M. Esperan&#xe7;a</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>",
          "description": "Searching for the architecture cells is a dominant paradigm in NAS. However,\nlittle attention has been devoted to the analysis of the cell-based search\nspaces even though it is highly important for the continual development of NAS.\nIn this work, we conduct an empirical post-hoc analysis of architectures from\nthe popular cell-based search spaces and find that the existing search spaces\ncontain a high degree of redundancy: the architecture performance is minimally\nsensitive to changes at large parts of the cells, and universally adopted\ndesigns, like the explicit search for a reduction cell, significantly increase\nthe complexities but have very limited impact on the performance. Across\narchitectures found by a diverse set of search strategies, we consistently find\nthat the parts of the cells that do matter for architecture performance often\nfollow similar and simple patterns. By explicitly constraining cells to include\nthese patterns, randomly sampled architectures can match or even outperform the\nstate of the art. These findings cast doubts into our ability to discover truly\nnovel architectures in the existing cell-based search spaces, and inspire our\nsuggestions for improvement to guide future NAS research. Code is available at\nhttps://github.com/xingchenwan/cell-based-NAS-analysis.",
          "link": "http://arxiv.org/abs/2203.08887",
          "publishedOn": "2022-03-19T00:42:47.708Z",
          "wordCount": 656,
          "title": "On Redundancy and Diversity in Cell-based Neural Architecture Search. (arXiv:2203.08887v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09450",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuhak Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmaeilpour_S/0/1/0/all/0/1\">Sepideh Esmaeilpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Changnan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bing Liu</a>",
          "description": "Existing continual learning techniques focus on either task incremental\nlearning (TIL) or class incremental learning (CIL) problem, but not both. CIL\nand TIL differ mainly in that the task-id is provided for each test sample\nduring testing for TIL, but not provided for CIL. Continual learning methods\nintended for one problem have limitations on the other problem. This paper\nproposes a novel unified approach based on out-of-distribution (OOD) detection\nand task masking, called CLOM, to solve both problems. The key novelty is that\neach task is trained as an OOD detection model rather than a traditional\nsupervised learning model, and a task mask is trained to protect each task to\nprevent forgetting. Our evaluation shows that CLOM outperforms existing\nstate-of-the-art baselines by large margins. The average TIL/CIL accuracy of\nCLOM over six experiments is 87.6/67.9% while that of the best baselines is\nonly 82.4/55.0%.",
          "link": "http://arxiv.org/abs/2203.09450",
          "publishedOn": "2022-03-19T00:42:47.701Z",
          "wordCount": 588,
          "title": "Continual Learning Based on OOD Detection and Task Masking. (arXiv:2203.09450v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yite Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruoyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Model-agnostic meta-learning (MAML) and its variants have become popular\napproaches for few-shot learning. However, due to the non-convexity of deep\nneural nets (DNNs) and the bi-level formulation of MAML, the theoretical\nproperties of MAML with DNNs remain largely unknown. In this paper, we first\nprove that MAML with over-parameterized DNNs is guaranteed to converge to\nglobal optima at a linear rate. Our convergence analysis indicates that MAML\nwith over-parameterized DNNs is equivalent to kernel regression with a novel\nclass of kernels, which we name as Meta Neural Tangent Kernels (MetaNTK). Then,\nwe propose MetaNTK-NAS, a new training-free neural architecture search (NAS)\nmethod for few-shot learning that uses MetaNTK to rank and select\narchitectures. Empirically, we compare our MetaNTK-NAS with previous NAS\nmethods on two popular few-shot learning benchmarks, miniImageNet, and\ntieredImageNet. We show that the performance of MetaNTK-NAS is comparable or\nbetter than the state-of-the-art NAS method designed for few-shot learning\nwhile enjoying more than 100x speedup. We believe the efficiency of MetaNTK-NAS\nmakes itself more practical for many real-world tasks.",
          "link": "http://arxiv.org/abs/2203.09137",
          "publishedOn": "2022-03-19T00:42:47.695Z",
          "wordCount": 651,
          "title": "Global Convergence of MAML and Theory-Inspired Neural Architecture Search for Few-Shot Learning. (arXiv:2203.09137v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09487",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shao_J/0/1/0/all/0/1\">Jiahao Shao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Geng_S/0/1/0/all/0/1\">Shijia Geng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_Z/0/1/0/all/0/1\">Zhaoji Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_W/0/1/0/all/0/1\">Weilun Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1\">Tong Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hong_S/0/1/0/all/0/1\">Shenda Hong</a>",
          "description": "In clinics, doctors rely on electrocardiograms (ECGs) to assess severe\ncardiac disorders. Owing to the development of technology and the increase in\nhealth awareness, ECG signals are currently obtained by using medical and\ncommercial devices. Deep neural networks (DNNs) can be used to analyze these\nsignals because of their high accuracy rate. However, researchers have found\nthat adversarial attacks can significantly reduce the accuracy of DNNs. Studies\nhave been conducted to defend ECG-based DNNs against traditional adversarial\nattacks, such as projected gradient descent (PGD), and smooth adversarial\nperturbation (SAP) which targets ECG classification; however, to the best of\nour knowledge, no study has completely explored the defense against adversarial\nattacks targeting ECG classification. Thus, we did different experiments to\nexplore the effects of defense methods against white-box adversarial attack and\nblack-box adversarial attack targeting ECG classification, and we found that\nsome common defense methods performed well against these attacks. Besides, we\nproposed a new defense method called Adversarial Distillation Training (ADT)\nwhich comes from defensive distillation and can effectively improve the\ngeneralization performance of DNNs. The results show that our method performed\nmore effectively against adversarial attacks targeting on ECG classification\nthan the other baseline methods, namely, adversarial training, defensive\ndistillation, Jacob regularization, and noise-to-signal ratio regularization.\nFurthermore, we found that our method performed better against PGD attacks with\nlow noise levels, which means that our method has stronger robustness.",
          "link": "http://arxiv.org/abs/2203.09487",
          "publishedOn": "2022-03-19T00:42:47.679Z",
          "wordCount": 686,
          "title": "Defending Against Adversarial Attack in ECG Classification with Adversarial Distillation Training. (arXiv:2203.09487v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arashloo_S/0/1/0/all/0/1\">Shervin R. Arashloo</a>",
          "description": "The support vector data description (SVDD) approach serves as a de facto\nstandard for one-class classification where the learning task entails inferring\nthe smallest hyper-sphere to enclose target objects while linearly penalising\nany errors/slacks via an $\\ell_1$-norm penalty term. In this study, we\ngeneralise this modelling formalism to a general $\\ell_p$-norm ($p\\geq1$) slack\npenalty function. By virtue of an $\\ell_p$ slack norm, the proposed approach\nenables formulating a non-linear cost function with respect to slacks. From a\ndual problem perspective, the proposed method introduces a sparsity-inducing\ndual norm into the objective function, and thus, possesses a higher capacity to\ntune into the inherent sparsity of the problem for enhanced descriptive\ncapability. A theoretical analysis based on Rademacher complexities\ncharacterises the generalisation performance of the proposed approach in terms\nof parameter $p$ while the experimental results on several datasets confirm the\nmerits of the proposed method compared to other alternatives.",
          "link": "http://arxiv.org/abs/2203.08932",
          "publishedOn": "2022-03-19T00:42:47.672Z",
          "wordCount": 575,
          "title": "$\\ell_p$ Slack Norm Support Vector Data Description. (arXiv:2203.08932v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shiebler_D/0/1/0/all/0/1\">Dan Shiebler</a>",
          "description": "A common problem in data science is \"use this function defined over this\nsmall set to generate predictions over that larger set.\" Extrapolation,\ninterpolation, statistical inference and forecasting all reduce to this\nproblem. The Kan extension is a powerful tool in category theory that\ngeneralizes this notion. In this work we explore several applications of Kan\nextensions to data science. We begin by deriving a simple classification\nalgorithm as a Kan extension and experimenting with this algorithm on real\ndata. Next, we use the Kan extension to derive a procedure for learning\nclustering algorithms from labels and explore the performance of this procedure\non real data. We then investigate how Kan extensions can be used to learn a\ngeneral mapping from datasets of labeled examples to functions and to\napproximate a complex function with a simpler one.",
          "link": "http://arxiv.org/abs/2203.09018",
          "publishedOn": "2022-03-19T00:42:47.666Z",
          "wordCount": 568,
          "title": "Kan Extensions in Data Science and Machine Learning. (arXiv:2203.09018v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paguada_S/0/1/0/all/0/1\">Servio Paguada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batina_L/0/1/0/all/0/1\">Lejla Batina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buhan_I/0/1/0/all/0/1\">Ileana Buhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armendariz_I/0/1/0/all/0/1\">Igor Armendariz</a>",
          "description": "This paper introduces a deep learning modular network for side-channel\nanalysis. Our deep learning approach features the capability to exchange part\nof it (modules) with others networks. We aim to introduce reusable trained\nmodules into side-channel analysis instead of building architectures for each\nevaluation, reducing the body of work when conducting those. Our experiments\ndemonstrate that our architecture feasibly assesses a side-channel evaluation\nsuggesting that learning transferability is possible with the network we\npropose in this paper.",
          "link": "http://arxiv.org/abs/2203.08448",
          "publishedOn": "2022-03-19T00:42:47.660Z",
          "wordCount": 540,
          "title": "Playing with blocks: Toward re-usable deep learning models for side-channel profiled attacks. (arXiv:2203.08448v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maunu_T/0/1/0/all/0/1\">Tyler Maunu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chenyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerman_G/0/1/0/all/0/1\">Gilad Lerman</a>",
          "description": "We develop theoretically guaranteed stochastic methods for outlier-robust\nPCA. Outlier-robust PCA seeks an underlying low-dimensional linear subspace\nfrom a dataset that is corrupted with outliers. We are able to show that our\nmethods, which involve stochastic geodesic gradient descent over the\nGrassmannian manifold, converge and recover an underlying subspace in various\nregimes through the development of a novel convergence analysis. The main\napplication of this method is an effective differentially private algorithm for\noutlier-robust PCA that uses a Gaussian noise mechanism within the stochastic\ngradient method. Our results emphasize the advantages of the nonconvex methods\nover another convex approach to solving this problem in the differentially\nprivate setting. Experiments on synthetic and stylized data verify these\nresults.",
          "link": "http://arxiv.org/abs/2203.09276",
          "publishedOn": "2022-03-19T00:42:47.644Z",
          "wordCount": 559,
          "title": "Stochastic and Private Nonconvex Outlier-Robust PCA. (arXiv:2203.09276v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chengrun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Ziyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chee_J/0/1/0/all/0/1\">Jerry Chee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Udell_M/0/1/0/all/0/1\">Madeleine Udell</a>",
          "description": "Low-precision arithmetic trains deep learning models using less energy, less\nmemory and less time. However, we pay a price for the savings: lower precision\nmay yield larger round-off error and hence larger prediction error. As\napplications proliferate, users must choose which precision to use to train a\nnew model, and chip manufacturers must decide which precisions to manufacture.\nWe view these precision choices as a hyperparameter tuning problem, and borrow\nideas from meta-learning to learn the tradeoff between memory and error. In\nthis paper, we introduce Pareto Estimation to Pick the Perfect Precision\n(PEPPP). We use matrix factorization to find non-dominated configurations (the\nPareto frontier) with a limited number of network evaluations. For any given\nmemory budget, the precision that minimizes error is a point on this frontier.\nPractitioners can use the frontier to trade memory for error and choose the\nbest precision for their goals.",
          "link": "http://arxiv.org/abs/2106.09686",
          "publishedOn": "2022-03-19T00:42:47.637Z",
          "wordCount": 636,
          "title": "How Low Can We Go: Trading Memory for Error in Low-Precision Training. (arXiv:2106.09686v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09456",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Kim_Y/0/1/0/all/0/1\">Yeji Kim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Jeong_Y/0/1/0/all/0/1\">Yoonho Jeong</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kim_J/0/1/0/all/0/1\">Jihoo Kim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lee_E/0/1/0/all/0/1\">Eok Kyun Lee</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kim_W/0/1/0/all/0/1\">Won June Kim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Choi_I/0/1/0/all/0/1\">Insung S. Choi</a>",
          "description": "The graph neural network (GNN) has been a powerful deep-learning tool in\nchemistry domain, due to its close connection with molecular graphs. Most GNN\nmodels collect and update atom and molecule features from the fed atom (and, in\nsome cases, bond) features, which are basically based on the two-dimensional\n(2D) graph representation of 3D molecules. Correspondingly, the adjacency\nmatrix, containing the information on covalent bonds, or equivalent data\nstructures (e.g., lists) have been the main core in the feature-updating\nprocesses, such as graph convolution. However, the 2D-based models do not\nfaithfully represent 3D molecules and their physicochemical properties,\nexemplified by the overlooked field effect that is a \"through-space\" effect,\nnot a \"through-bond\" effect. The GNN model proposed herein, denoted as MolNet,\nis chemically intuitive, accommodating the 3D non-bond information in a\nmolecule, with a noncovalent adjacency matrix $\\bf{\\bar A}$, and also\nbond-strength information from a weighted bond matrix $\\bf{B}$. The noncovalent\natoms, not directly bonded to a given atom in a molecule, are identified within\n5 $\\unicode{x212B}$ of cut-off range for the construction of $\\bf{\\bar A}$, and\n$\\bf{B}$ has edge weights of 1, 1.5, 2, and 3 for single, aromatic, double, and\ntriple bonds, respectively. Comparative studies show that MolNet outperforms\nvarious baseline GNN models and gives a state-of-the-art performance in the\nclassification task of BACE dataset and regression task of ESOL dataset. This\nwork suggests a future direction of deep-learning chemistry in the construction\nof deep-learning models that are chemically intuitive and comparable with the\nexisting chemistry concepts and tools.",
          "link": "http://arxiv.org/abs/2203.09456",
          "publishedOn": "2022-03-19T00:42:47.630Z",
          "wordCount": 714,
          "title": "MolNet: A Chemically Intuitive Graph Neural Network for Prediction of Molecular Properties. (arXiv:2203.09456v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bergsson_A/0/1/0/all/0/1\">Andri Bergsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>",
          "description": "Faithful visualizations of data residing on manifolds must take the\nunderlying geometry into account when producing a flat planar view of the data.\nIn this paper, we extend the classic stochastic neighbor embedding (SNE)\nalgorithm to data on general Riemannian manifolds. We replace standard Gaussian\nassumptions with Riemannian diffusion counterparts and propose an efficient\napproximation that only requires access to calculations of Riemannian distances\nand volumes. We demonstrate that the approach also allows for mapping data from\none manifold to another, e.g. from a high-dimensional sphere to a\nlow-dimensional one.",
          "link": "http://arxiv.org/abs/2203.09253",
          "publishedOn": "2022-03-19T00:42:47.624Z",
          "wordCount": 521,
          "title": "Visualizing Riemannian data with Rie-SNE. (arXiv:2203.09253v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08913",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuhuai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabe_M/0/1/0/all/0/1\">Markus N. Rabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutchins_D/0/1/0/all/0/1\">DeLesley Hutchins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szegedy_C/0/1/0/all/0/1\">Christian Szegedy</a>",
          "description": "Language models typically need to be trained or finetuned in order to acquire\nnew knowledge, which involves updating their weights. We instead envision\nlanguage models that can simply read and memorize new data at inference time,\nthus acquiring new knowledge immediately. In this work, we extend language\nmodels with the ability to memorize the internal representations of past\ninputs. We demonstrate that an approximate kNN lookup into a non-differentiable\nmemory of recent (key, value) pairs improves language modeling across various\nbenchmarks and tasks, including generic webtext (C4), math papers (arXiv),\nbooks (PG-19), code (Github), as well as formal theorems (Isabelle). We show\nthat the performance steadily improves when we increase the size of memory up\nto 262K tokens. On benchmarks including code and mathematics, we find that the\nmodel is capable of making use of newly defined functions and theorems during\ntest time.",
          "link": "http://arxiv.org/abs/2203.08913",
          "publishedOn": "2022-03-19T00:42:47.618Z",
          "wordCount": 583,
          "title": "Memorizing Transformers. (arXiv:2203.08913v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wenqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1\">Ting-Kuei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Recent studies on Learning to Optimize (L2O) suggest a promising path to\nautomating and accelerating the optimization procedure for complicated tasks.\nExisting L2O models parameterize optimization rules by neural networks, and\nlearn those numerical rules via meta-training. However, they face two common\npitfalls: (1) scalability: the numerical rules represented by neural networks\ncreate extra memory overhead for applying L2O models, and limit their\napplicability to optimizing larger tasks; (2) interpretability: it is unclear\nwhat an L2O model has learned in its black-box optimization rule, nor is it\nstraightforward to compare different L2O models in an explainable way. To avoid\nboth pitfalls, this paper proves the concept that we can \"kill two birds by one\nstone\", by introducing the powerful tool of symbolic regression to L2O. In this\npaper, we establish a holistic symbolic representation and analysis framework\nfor L2O, which yields a series of insights for learnable optimizers. Leveraging\nour findings, we further propose a lightweight L2O model that can be\nmeta-trained on large-scale problems and outperformed human-designed and tuned\noptimizers. Our work is set to supply a brand-new perspective to L2O research.\nCodes are available at:\nhttps://github.com/VITA-Group/Symbolic-Learning-To-Optimize.",
          "link": "http://arxiv.org/abs/2203.06578",
          "publishedOn": "2022-03-19T00:42:47.612Z",
          "wordCount": 653,
          "title": "Symbolic Learning to Optimize: Towards Interpretability and Scalability. (arXiv:2203.06578v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.04879",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Axelrod_S/0/1/0/all/0/1\">Simon Axelrod</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shakhnovich_E/0/1/0/all/0/1\">Eugene Shakhnovich</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gomez_Bombarelli_R/0/1/0/all/0/1\">Rafael G&#xf3;mez-Bombarelli</a>",
          "description": "Light-induced chemical processes are ubiquitous in nature and have widespread\ntechnological applications. For example, photoisomerization can allow a drug\nwith a photo-switchable scaffold such as azobenzene to be activated with light.\nIn principle, photoswitches with desired photophysical properties like high\nisomerization quantum yields can be identified through virtual screening with\nreactive simulations. In practice, these simulations are rarely used for\nscreening, since they require hundreds of trajectories and expensive quantum\nchemical methods to account for non-adiabatic excited state effects. Here we\nintroduce a diabatic artificial neural network (DANN) based on diabatic states\nto accelerate such simulations for azobenzene derivatives. The network is six\norders of magnitude faster than the quantum chemistry method used for training.\nDANN is transferable to azobenzene molecules outside the training set,\npredicting quantum yields for unseen species that are correlated with\nexperiment. We use the model to virtually screen 3,100 hypothetical molecules,\nand identify novel species with extremely high predicted quantum yields. The\nmodel predictions are confirmed using high accuracy non-adiabatic dynamics. Our\nresults pave the way for fast and accurate virtual screening of photoactive\ncompounds.",
          "link": "http://arxiv.org/abs/2108.04879",
          "publishedOn": "2022-03-19T00:42:47.595Z",
          "wordCount": 654,
          "title": "Excited state, non-adiabatic dynamics of large photoswitchable molecules using a chemically transferable machine learning potential. (arXiv:2108.04879v3 [physics.chem-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.07026",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kell_G/0/1/0/all/0/1\">Gregory Kell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffiths_R/0/1/0/all/0/1\">Ryan-Rhys Griffiths</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bourached_A/0/1/0/all/0/1\">Anthony Bourached</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stork_D/0/1/0/all/0/1\">David G. Stork</a>",
          "description": "We present a novel bi-modal system based on deep networks to address the\nproblem of learning associations and simple meanings of objects depicted in\n\"authored\" images, such as fine art paintings and drawings. Our overall system\nprocesses both the images and associated texts in order to learn associations\nbetween images of individual objects, their identities and the abstract\nmeanings they signify. Unlike past deep nets that describe depicted objects and\ninfer predicates, our system identifies meaning-bearing objects (\"signifiers\")\nand their associations (\"signifieds\") as well as basic overall meanings for\ntarget artworks. Our system had precision of 48% and recall of 78% with an F1\nmetric of 0.6 on a curated set of Dutch vanitas paintings, a genre celebrated\nfor its concentration on conveying a meaning of great import at the time of\ntheir execution. We developed and tested our system on fine art paintings but\nour general methods can be applied to other authored images.",
          "link": "http://arxiv.org/abs/2203.07026",
          "publishedOn": "2022-03-19T00:42:47.588Z",
          "wordCount": 647,
          "title": "Extracting associations and meanings of objects depicted in artworks through bi-modal deep networks. (arXiv:2203.07026v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiaohan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yizhuang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jungong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1\">Guiguang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jian Sun</a>",
          "description": "We revisit large kernel design in modern convolutional neural networks\n(CNNs). Inspired by recent advances of vision transformers (ViTs), in this\npaper, we demonstrate that using a few large convolutional kernels instead of a\nstack of small kernels could be a more powerful paradigm. We suggested five\nguidelines, e.g., applying re-parameterized large depth-wise convolutions, to\ndesign efficient high-performance large-kernel CNNs. Following the guidelines,\nwe propose RepLKNet, a pure CNN architecture whose kernel size is as large as\n31x31, in contrast to commonly used 3x3. RepLKNet greatly closes the\nperformance gap between CNNs and ViTs, e.g., achieving comparable or superior\nresults than Swin Transformer on ImageNet and a few typical downstream tasks,\nwith lower latency. RepLKNet also shows nice scalability to big data and large\nmodels, obtaining 87.8% top-1 accuracy on ImageNet and 56.0% mIoU on ADE20K,\nwhich is very competitive among the state-of-the-arts with similar model sizes.\nOur study further reveals that, in contrast to small-kernel CNNs, large-kernel\nCNNs have much larger effective receptive fields, and higher shape bias rather\nthan texture bias. Code & models at\nhttps://github.com/megvii-research/RepLKNet.",
          "link": "http://arxiv.org/abs/2203.06717",
          "publishedOn": "2022-03-19T00:42:47.570Z",
          "wordCount": 661,
          "title": "Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yangji He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1\">Weihan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hong-Yu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1\">Weifeng Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yizhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenqiang Zhang</a>",
          "description": "This paper presents new hierarchically cascaded transformers that can improve\ndata efficiency through attribute surrogates learning and spectral tokens\npooling. Vision transformers have recently been thought of as a promising\nalternative to convolutional neural networks for visual recognition. But when\nthere is no sufficient data, it gets stuck in overfitting and shows inferior\nperformance. To improve data efficiency, we propose hierarchically cascaded\ntransformers that exploit intrinsic image structures through spectral tokens\npooling and optimize the learnable parameters through latent attribute\nsurrogates. The intrinsic image structure is utilized to reduce the ambiguity\nbetween foreground content and background noise by spectral tokens pooling. And\nthe attribute surrogate learning scheme is designed to benefit from the rich\nvisual information in image-label pairs instead of simple visual concepts\nassigned by their labels. Our Hierarchically Cascaded Transformers, called\nHCTransformers, is built upon a self-supervised learning framework DINO and is\ntested on several popular few-shot learning benchmarks.\n\nIn the inductive setting, HCTransformers surpass the DINO baseline by a large\nmargin of 9.7% 5-way 1-shot accuracy and 9.17% 5-way 5-shot accuracy on\nminiImageNet, which demonstrates HCTransformers are efficient to extract\ndiscriminative features. Also, HCTransformers show clear advantages over SOTA\nfew-shot classification methods in both 5-way 1-shot and 5-way 5-shot settings\non four popular benchmark datasets, including miniImageNet, tieredImageNet,\nFC100, and CIFAR-FS. The trained weights and codes are available at\nhttps://github.com/StomachCold/HCTransformers.",
          "link": "http://arxiv.org/abs/2203.09064",
          "publishedOn": "2022-03-19T00:42:47.448Z",
          "wordCount": 699,
          "title": "Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-shot Learning. (arXiv:2203.09064v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kwon_G/0/1/0/all/0/1\">Gihyun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "There are many recent research efforts to fine-tune a pre-trained generator\nwith a few target images to generate images of a novel domain. Unfortunately,\nthese methods often suffer from overfitting or under-fitting when fine-tuned\nwith a single target image. To address this, here we present a novel\nsingle-shot GAN adaptation method through unified CLIP space manipulations.\nSpecifically, our model employs a two-step training strategy: reference image\nsearch in the source generator using a CLIP-guided latent optimization,\nfollowed by generator fine-tuning with a novel loss function that imposes CLIP\nspace consistency between the source and adapted generators. To further improve\nthe adapted model to produce spatially consistent samples with respect to the\nsource generator, we also propose contrastive regularization for patchwise\nrelationships in the CLIP space. Experimental results show that our model\ngenerates diverse outputs with the target texture and outperforms the baseline\nmodels both qualitatively and quantitatively. Furthermore, we show that our\nCLIP space manipulation strategy allows more effective attribute editing.",
          "link": "http://arxiv.org/abs/2203.09301",
          "publishedOn": "2022-03-19T00:42:47.441Z",
          "wordCount": 610,
          "title": "One-Shot Adaptation of GAN in Just One CLIP. (arXiv:2203.09301v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09179",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Karvonen_T/0/1/0/all/0/1\">Toni Karvonen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Oates_C/0/1/0/all/0/1\">Chris J. Oates</a>",
          "description": "Gaussian process regression underpins countless academic and industrial\napplications of machine learning and statistics, with maximum likelihood\nestimation routinely used to select appropriate parameters for the covariance\nkernel. However, it remains an open problem to establish the circumstances in\nwhich maximum likelihood estimation is well-posed. That is, when the\npredictions of the regression model are continuous (or insensitive to small\nperturbations) in the training data. This article presents a rigorous proof\nthat the maximum likelihood estimator fails to be well-posed in Hellinger\ndistance in a scenario where the data are noiseless. The failure case occurs\nfor any Gaussian process with a stationary covariance function whose\nlengthscale parameter is estimated using maximum likelihood. Although the\nfailure of maximum likelihood estimation is informally well-known, these\ntheoretical results appear to be the first of their kind, and suggest that\nwell-posedness may need to be assessed post-hoc, on a case-by-case basis, when\nmaximum likelihood estimation is used to train a Gaussian process model.",
          "link": "http://arxiv.org/abs/2203.09179",
          "publishedOn": "2022-03-19T00:42:47.435Z",
          "wordCount": 601,
          "title": "Maximum Likelihood Estimation in Gaussian Process Regression is Ill-Posed. (arXiv:2203.09179v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.03250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_D/0/1/0/all/0/1\">David Evans</a>",
          "description": "A fundamental question in adversarial machine learning is whether a robust\nclassifier exists for a given task. A line of research has made some progress\ntowards this goal by studying the concentration of measure, but we argue\nstandard concentration fails to fully characterize the intrinsic robustness of\na classification problem since it ignores data labels which are essential to\nany classification task. Building on a novel definition of label uncertainty,\nwe empirically demonstrate that error regions induced by state-of-the-art\nmodels tend to have much higher label uncertainty than randomly-selected\nsubsets. This observation motivates us to adapt a concentration estimation\nalgorithm to account for label uncertainty, resulting in more accurate\nintrinsic robustness measures for benchmark image classification problems.",
          "link": "http://arxiv.org/abs/2107.03250",
          "publishedOn": "2022-03-19T00:42:47.177Z",
          "wordCount": 582,
          "title": "Understanding Intrinsic Robustness Using Label Uncertainty. (arXiv:2107.03250v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gallicchio_C/0/1/0/all/0/1\">Claudio Gallicchio</a>",
          "description": "Inspired by the numerical solution of ordinary differential equations, in\nthis paper we propose a novel Reservoir Computing (RC) model, called the Euler\nState Network (EuSN). The introduced approach makes use of forward Euler\ndiscretization and antisymmetric recurrent matrices to design reservoir\ndynamics that are both stable and non-dissipative by construction.\n\nOur mathematical analysis shows that the resulting model is biased towards\nunitary effective spectral radius and zero local Lyapunov exponents,\nintrinsically operating at the edge of stability. Experiments on synthetic\ntasks indicate the marked superiority of the proposed approach, compared to\nstandard RC models, in tasks requiring long-term memorization skills.\nFurthermore, results on real-world time series classification benchmarks point\nout that EuSN is capable of matching (or even surpassing) the level of accuracy\nof trainable Recurrent Neural Networks, while allowing up to 100-fold savings\nin computation time and energy consumption.",
          "link": "http://arxiv.org/abs/2203.09382",
          "publishedOn": "2022-03-19T00:42:47.170Z",
          "wordCount": 571,
          "title": "Euler State Networks. (arXiv:2203.09382v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09413",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yuan_X/0/1/0/all/0/1\">Xiao-Tong Yuan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>",
          "description": "In this paper, we analyze the generalization performance of the Iterative\nHard Thresholding (IHT) algorithm widely used for sparse recovery problems. The\nparameter estimation and sparsity recovery consistency of IHT has long been\nknown in compressed sensing. From the perspective of statistical learning,\nanother fundamental question is how well the IHT estimation would predict on\nunseen data. This paper makes progress towards answering this open question by\nintroducing a novel sparse generalization theory for IHT under the notion of\nalgorithmic stability. Our theory reveals that: 1) under natural conditions on\nthe empirical risk function over $n$ samples of dimension $p$, IHT with\nsparsity level $k$ enjoys an $\\mathcal{\\tilde\nO}(n^{-1/2}\\sqrt{k\\log(n)\\log(p)})$ rate of convergence in sparse excess risk;\n2) a tighter $\\mathcal{\\tilde O}(n^{-1/2}\\sqrt{\\log(n)})$ bound can be\nestablished by imposing an additional iteration stability condition on a\nhypothetical IHT procedure invoked to the population risk; and 3) a fast rate\nof order $\\mathcal{\\tilde O}\\left(n^{-1}k(\\log^3(n)+\\log(p))\\right)$ can be\nderived for strongly convex risk function under proper strong-signal\nconditions. The results have been substantialized to sparse linear regression\nand sparse logistic regression models to demonstrate the applicability of our\ntheory. Preliminary numerical evidence is provided to confirm our theoretical\npredictions.",
          "link": "http://arxiv.org/abs/2203.09413",
          "publishedOn": "2022-03-19T00:42:47.161Z",
          "wordCount": 632,
          "title": "Stability and Risk Bounds of Iterative Hard Thresholding. (arXiv:2203.09413v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08977",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duersch_J/0/1/0/all/0/1\">Jed A. Duersch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanach_T/0/1/0/all/0/1\">Thomas A. Catanach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_N/0/1/0/all/0/1\">Niladri Das</a>",
          "description": "Balancing model complexity against the information contained in observed data\nis the central challenge to learning. In order for complexity-efficient models\nto exist and be discoverable in high dimensions, we require a computational\nframework that relates a credible notion of complexity to simple parameter\nrepresentations. Further, this framework must allow excess complexity to be\ngradually removed via gradient-based optimization. Our n-ary, or n-argument,\nactivation functions fill this gap by approximating belief functions\n(probabilistic Boolean logic) using logit representations of probability. Just\nas Boolean logic determines the truth of a consequent claim from relationships\namong a set of antecedent propositions, probabilistic formulations generalize\npredictions when antecedents, truth tables, and consequents all retain\nuncertainty. Our activation functions demonstrate the ability to learn\narbitrary logic, such as the binary exclusive disjunction (p xor q) and ternary\nconditioned disjunction ( c ? p : q ), in a single layer using an activation\nfunction of matching or greater arity. Further, we represent belief tables\nusing a basis that directly associates the number of nonzero parameters to the\neffective arity of the belief function, thus capturing a concrete relationship\nbetween logical complexity and efficient parameter representations. This opens\noptimization approaches to reduce logical complexity by inducing parameter\nsparsity.",
          "link": "http://arxiv.org/abs/2203.08977",
          "publishedOn": "2022-03-19T00:42:47.082Z",
          "wordCount": 640,
          "title": "Adaptive n-ary Activation Functions for Probabilistic Boolean Logic. (arXiv:2203.08977v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_D/0/1/0/all/0/1\">Dong Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhou Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jieming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yudong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiuqiang He</a>",
          "description": "Self-supervised learning, especially contrastive learning, has made an\noutstanding contribution to the development of many deep learning research\nfields. Recently, researchers in the acoustic signal processing field noticed\nits success and leveraged contrastive learning for better music representation.\nTypically, existing approaches maximize the similarity between two distorted\naudio segments sampled from the same music. In other words, they ensure a\nsemantic agreement at the music level. However, those coarse-grained methods\nneglect some inessential or noisy elements at the frame level, which may be\ndetrimental to the model to learn the effective representation of music.\nTowards this end, this paper proposes a novel Positive-nEgative frame mask for\nMusic Representation based on the contrastive learning framework, abbreviated\nas PEMR. Concretely, PEMR incorporates a Positive-Negative Mask Generation\nmodule, which leverages transformer blocks to generate frame masks on the\nLog-Mel spectrogram. We can generate self-augmented negative and positive\nsamples by masking important components or inessential components,\nrespectively. We devise a novel contrastive learning objective to accommodate\nboth self-augmented positives/negatives sampled from the same music. We conduct\nexperiments on four public datasets. The experimental results of two\nmusic-related downstream tasks, music classification, and cover song\nidentification, demonstrate the generalization ability and transferability of\nmusic representation learned by PEMR.",
          "link": "http://arxiv.org/abs/2203.09129",
          "publishedOn": "2022-03-19T00:42:47.059Z",
          "wordCount": 668,
          "title": "Contrastive Learning with Positive-Negative Frame Mask for Music Representation. (arXiv:2203.09129v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.05467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qizhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>",
          "description": "The drastic increase of data quantity often brings the severe decrease of\ndata quality, such as incorrect label annotations, which poses a great\nchallenge for robustly training Deep Neural Networks (DNNs). Existing learning\n\\mbox{methods} with label noise either employ ad-hoc heuristics or restrict to\nspecific noise assumptions. However, more general situations, such as\ninstance-dependent label noise, have not been fully explored, as scarce studies\nfocus on their label corruption process. By categorizing instances into\nconfusing and unconfusing instances, this paper proposes a simple yet universal\nprobabilistic model, which explicitly relates noisy labels to their instances.\nThe resultant model can be realized by DNNs, where the training procedure is\naccomplished by employing an alternating optimization algorithm. Experiments on\ndatasets with both synthetic and real-world label noise verify that the\nproposed method yields significant improvements on robustness over\nstate-of-the-art counterparts.",
          "link": "http://arxiv.org/abs/2101.05467",
          "publishedOn": "2022-03-19T00:42:47.051Z",
          "wordCount": 622,
          "title": "Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model. (arXiv:2101.05467v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.04585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bonassi_F/0/1/0/all/0/1\">Fabio Bonassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scattolini_R/0/1/0/all/0/1\">Riccardo Scattolini</a>",
          "description": "Owing to their superior modeling capabilities, gated Recurrent Neural\nNetworks, such as Gated Recurrent Units (GRUs) and Long Short-Term Memory\nnetworks (LSTMs), have become popular tools for learning dynamical systems.\nThis paper aims to discuss how these networks can be adopted for the synthesis\nof Internal Model Control (IMC) architectures. To this end, first a gated\nrecurrent network is used to learn a model of the unknown input-output stable\nplant. Then, a controller gated recurrent network is trained to approximate the\nmodel inverse. The stability of these networks, ensured by means of a suitable\ntraining procedure, allows to guarantee the input-output closed-loop stability.\nThe proposed scheme is able to cope with the saturation of the control\nvariables, and can be deployed on low-power embedded controllers, as it\nrequires limited online computations. The approach is then tested on the\nQuadruple Tank benchmark system and compared to alternative control laws,\nresulting in remarkable closed-loop performances.",
          "link": "http://arxiv.org/abs/2108.04585",
          "publishedOn": "2022-03-19T00:42:47.043Z",
          "wordCount": 681,
          "title": "Recurrent Neural Network-based Internal Model Control design for stable nonlinear systems. (arXiv:2108.04585v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.06306",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_L/0/1/0/all/0/1\">Li-Wei Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rudnicky_A/0/1/0/all/0/1\">Alexander Rudnicky</a>",
          "description": "In this paper, we present a novel architecture to realize fine-grained style\ncontrol on the transformer-based text-to-speech synthesis (TransformerTTS).\nSpecifically, we model the speaking style by extracting a time sequence of\nlocal style tokens (LST) from the reference speech. The existing content\nencoder in TransformerTTS is then replaced by our designed cross-attention\nblocks for fusion and alignment between content and style. As the fusion is\nperformed along with the skip connection, our cross-attention block provides a\ngood inductive bias to gradually infuse the phoneme representation with a given\nstyle. Additionally, we prevent the style embedding from encoding linguistic\ncontent by randomly truncating LST during training and using wav2vec 2.0\nfeatures. Experiments show that with fine-grained style control, our system\nperforms better in terms of naturalness, intelligibility, and style\ntransferability. Our code and samples are publicly available.",
          "link": "http://arxiv.org/abs/2110.06306",
          "publishedOn": "2022-03-19T00:42:47.035Z",
          "wordCount": 605,
          "title": "Fine-grained style control in Transformer-based Text-to-speech Synthesis. (arXiv:2110.06306v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.03363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weinan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xihuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jian Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Ming Zhou</a>",
          "description": "This paper investigates the model-based methods in multi-agent reinforcement\nlearning (MARL). We specify the dynamics sample complexity and the opponent\nsample complexity in MARL, and conduct a theoretic analysis of return\ndiscrepancy upper bound. To reduce the upper bound with the intention of low\nsample complexity during the whole learning process, we propose a novel\ndecentralized model-based MARL method, named Adaptive Opponent-wise Rollout\nPolicy Optimization (AORPO). In AORPO, each agent builds its multi-agent\nenvironment model, consisting of a dynamics model and multiple opponent models,\nand trains its policy with the adaptive opponent-wise rollout. We further prove\nthe theoretic convergence of AORPO under reasonable assumptions. Empirical\nexperiments on competitive and cooperative tasks demonstrate that AORPO can\nachieve improved sample efficiency with comparable asymptotic performance over\nthe compared MARL methods.",
          "link": "http://arxiv.org/abs/2105.03363",
          "publishedOn": "2022-03-19T00:42:47.014Z",
          "wordCount": 611,
          "title": "Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise Rollouts. (arXiv:2105.03363v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.08059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Romero_D/0/1/0/all/0/1\">David W. Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruintjes_R/0/1/0/all/0/1\">Robert-Jan Bruintjes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1\">Jakub M. Tomczak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bekkers_E/0/1/0/all/0/1\">Erik J. Bekkers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoogendoorn_M/0/1/0/all/0/1\">Mark Hoogendoorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1\">Jan C. van Gemert</a>",
          "description": "When designing Convolutional Neural Networks (CNNs), one must select the\nsize\\break of the convolutional kernels before training. Recent works show CNNs\nbenefit from different kernel sizes at different layers, but exploring all\npossible combinations is unfeasible in practice. A more efficient approach is\nto learn the kernel size during training. However, existing works that learn\nthe kernel size have a limited bandwidth. These approaches scale kernels by\ndilation, and thus the detail they can describe is limited. In this work, we\npropose FlexConv, a novel convolutional operation with which high bandwidth\nconvolutional kernels of learnable kernel size can be learned at a fixed\nparameter cost. FlexNets model long-term dependencies without the use of\npooling, achieve state-of-the-art performance on several sequential datasets,\noutperform recent works with learned kernel sizes, and are competitive with\nmuch deeper ResNets on image benchmark datasets. Additionally, FlexNets can be\ndeployed at higher resolutions than those seen during training. To avoid\naliasing, we propose a novel kernel parameterization with which the frequency\nof the kernels can be analytically controlled. Our novel kernel\nparameterization shows higher descriptive power and faster convergence speed\nthan existing parameterizations. This leads to important improvements in\nclassification accuracy.",
          "link": "http://arxiv.org/abs/2110.08059",
          "publishedOn": "2022-03-19T00:42:47.008Z",
          "wordCount": 699,
          "title": "FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes. (arXiv:2110.08059v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08857",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qiu_Y/0/1/0/all/0/1\">Yuning Qiu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_G/0/1/0/all/0/1\">Guoxu Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_Q/0/1/0/all/0/1\">Qibin Zhao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_S/0/1/0/all/0/1\">Shengli Xie</a>",
          "description": "Tensor completion is a fundamental tool for incomplete data analysis, where\nthe goal is to predict missing entries from partial observations. However,\nexisting methods often make the explicit or implicit assumption that the\nobserved entries are noise-free to provide a theoretical guarantee of exact\nrecovery of missing entries, which is quite restrictive in practice. To remedy\nsuch drawbacks, this paper proposes a novel noisy tensor completion model,\nwhich complements the incompetence of existing works in handling the\ndegeneration of high-order and noisy observations. Specifically, the tensor\nring nuclear norm (TRNN) and least-squares estimator are adopted to regularize\nthe underlying tensor and the observed entries, respectively. In addition, a\nnon-asymptotic upper bound of estimation error is provided to depict the\nstatistical performance of the proposed estimator. Two efficient algorithms are\ndeveloped to solve the optimization problem with convergence guarantee, one of\nwhich is specially tailored to handle large-scale tensors by replacing the\nminimization of TRNN of the original tensor equivalently with that of a much\nsmaller one in a heterogeneous tensor decomposition framework. Experimental\nresults on both synthetic and real-world data demonstrate the effectiveness and\nefficiency of the proposed model in recovering noisy incomplete tensor data\ncompared with state-of-the-art tensor completion models.",
          "link": "http://arxiv.org/abs/2203.08857",
          "publishedOn": "2022-03-19T00:42:47.001Z",
          "wordCount": 640,
          "title": "Noisy Tensor Completion via Low-rank Tensor Ring. (arXiv:2203.08857v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.10863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Regenwetter_L/0/1/0/all/0/1\">Lyle Regenwetter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nobari_A/0/1/0/all/0/1\">Amin Heyrani Nobari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1\">Faez Ahmed</a>",
          "description": "Automated design synthesis has the potential to revolutionize the modern\nengineering design process and improve access to highly optimized and\ncustomized products across countless industries. Successfully adapting\ngenerative Machine Learning to design engineering may enable such automated\ndesign synthesis and is a research subject of great importance. We present a\nreview and analysis of Deep Generative Machine Learning models in engineering\ndesign. Deep Generative Models (DGMs) typically leverage deep networks to learn\nfrom an input dataset and synthesize new designs. Recently, DGMs such as\nfeedforward Neural Networks (NNs), Generative Adversarial Networks (GANs),\nVariational Autoencoders (VAEs), and certain Deep Reinforcement Learning (DRL)\nframeworks have shown promising results in design applications like structural\noptimization, materials design, and shape synthesis. The prevalence of DGMs in\nengineering design has skyrocketed since 2016. Anticipating continued growth,\nwe conduct a review of recent advances to benefit researchers interested in\nDGMs for design. We structure our review as an exposition of the algorithms,\ndatasets, representation methods, and applications commonly used in the current\nliterature. In particular, we discuss key works that have introduced new\ntechniques and methods in DGMs, successfully applied DGMs to a design-related\ndomain, or directly supported the development of DGMs through datasets or\nauxiliary methods. We further identify key challenges and limitations currently\nseen in DGMs across design fields, such as design creativity, handling\nconstraints and objectives, and modeling both form and functional performance\nsimultaneously. In our discussion, we identify possible solution pathways as\nkey areas on which to target future work.",
          "link": "http://arxiv.org/abs/2110.10863",
          "publishedOn": "2022-03-19T00:42:46.994Z",
          "wordCount": 728,
          "title": "Deep Generative Models in Engineering Design: A Review. (arXiv:2110.10863v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yibo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Liang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shixiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiangtai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Modern deep neural networks for classification usually jointly learn a\nbackbone for representation and a linear classifier to output the logit of each\nclass. A recent study has shown a phenomenon called neural collapse that the\nwithin-class means of features and the classifier vectors converge to the\nvertices of a simplex equiangular tight frame (ETF) at the terminal phase of\ntraining on a balanced dataset. Since the ETF geometric structure maximally\nseparates the pair-wise angles of all classes in the classifier, it is natural\nto raise the question, why do we spend an effort to learn a classifier when we\nknow its optimal geometric structure? In this paper, we study the potential of\nlearning a neural network for classification with the classifier randomly\ninitialized as an ETF and fixed during training. Our analytical work based on\nthe layer-peeled model indicates that the feature learning with a fixed ETF\nclassifier naturally leads to the neural collapse state even when the dataset\nis imbalanced among classes. We further show that in this case the cross\nentropy (CE) loss is not necessary and can be replaced by a simple squared loss\nthat shares the same global optimality but enjoys a more accurate gradient and\nbetter convergence property. Our experimental results show that our method is\nable to achieve similar performances on image classification for balanced\ndatasets, and bring significant improvements in the long-tailed and\nfine-grained classification tasks.",
          "link": "http://arxiv.org/abs/2203.09081",
          "publishedOn": "2022-03-19T00:42:46.987Z",
          "wordCount": 690,
          "title": "Do We Really Need a Learnable Classifier at the End of Deep Neural Network?. (arXiv:2203.09081v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09125",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosal_S/0/1/0/all/0/1\">Soumya Suvra Ghosal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1\">Yifei Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yixuan Li</a>",
          "description": "Deep neural networks may be susceptible to learning spurious correlations\nthat hold on average but not in atypical test samples. As with the recent\nemergence of vision transformer (ViT) models, it remains underexplored how\nspurious correlations are manifested in such architectures. In this paper, we\nsystematically investigate the robustness of vision transformers to spurious\ncorrelations on three challenging benchmark datasets and compare their\nperformance with popular CNNs. Our study reveals that when pre-trained on a\nsufficiently large dataset, ViT models are more robust to spurious correlations\nthan CNNs. Key to their success is the ability to generalize better from the\nexamples where spurious correlations do not hold. Further, we perform extensive\nablations and experiments to understand the role of the self-attention\nmechanism in providing robustness under spuriously correlated environments. We\nhope that our work will inspire future research on further understanding the\nrobustness of ViT models.",
          "link": "http://arxiv.org/abs/2203.09125",
          "publishedOn": "2022-03-19T00:42:46.965Z",
          "wordCount": 592,
          "title": "Are Vision Transformers Robust to Spurious Correlations?. (arXiv:2203.09125v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.07904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qizhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Reweighting adversarial data during training has been recently shown to\nimprove adversarial robustness, where data closer to the current decision\nboundaries are regarded as more critical and given larger weights. However,\nexisting methods measuring the closeness are not very reliable: they are\ndiscrete and can take only a few values, and they are path-dependent, i.e.,\nthey may change given the same start and end points with different attack\npaths. In this paper, we propose three types of probabilistic margin (PM),\nwhich are continuous and path-independent, for measuring the aforementioned\ncloseness and reweighting adversarial data. Specifically, a PM is defined as\nthe difference between two estimated class-posterior probabilities, e.g., such\nthe probability of the true label minus the probability of the most confusing\nlabel given some natural data. Though different PMs capture different geometric\nproperties, all three PMs share a negative correlation with the vulnerability\nof data: data with larger/smaller PMs are safer/riskier and should have\nsmaller/larger weights. Experiments demonstrate that PMs are reliable\nmeasurements and PM-based reweighting methods outperform state-of-the-art\nmethods.",
          "link": "http://arxiv.org/abs/2106.07904",
          "publishedOn": "2022-03-19T00:42:46.957Z",
          "wordCount": 648,
          "title": "Probabilistic Margins for Instance Reweighting in Adversarial Training. (arXiv:2106.07904v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hua_M/0/1/0/all/0/1\">Mingzhuang Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereira_F/0/1/0/all/0/1\">Francisco Camara Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuewu Chen</a>",
          "description": "The urban transportation system is a combination of multiple transport modes,\nand the interdependencies across those modes exist. This means that the travel\ndemand across different travel modes could be correlated as one mode may\nreceive demand from or create demand for another mode, not to mention natural\ncorrelations between different demand time series due to general demand flow\npatterns across the network. It is expectable that cross-modal ripple effects\nbecome more prevalent, with Mobility as a Service. Therefore, by propagating\ndemand data across modes, a better demand prediction could be obtained. To this\nend, this study explores various machine learning models and transfer learning\nstrategies for cross-modal demand prediction. The trip data of bike-share,\nmetro, and taxi are processed as the station-level passenger flows, and then\nthe proposed prediction method is tested in the large-scale case studies of\nNanjing and Chicago. The results suggest that prediction models with transfer\nlearning perform better than unimodal prediction models. Furthermore, stacked\nLong Short-Term Memory model performs particularly well in cross-modal demand\nprediction. These results verify our combined method's forecasting improvement\nover existing benchmarks and demonstrate the good transferability for\ncross-modal demand prediction in multiple cities.",
          "link": "http://arxiv.org/abs/2203.09279",
          "publishedOn": "2022-03-19T00:42:46.951Z",
          "wordCount": 642,
          "title": "Transfer learning for cross-modal demand prediction of bike-share and public transit. (arXiv:2203.09279v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Byun_J/0/1/0/all/0/1\">Junyoung Byun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Seungju Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_M/0/1/0/all/0/1\">Myung-Joon Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hee-Seon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Changick Kim</a>",
          "description": "The transferability of adversarial examples allows the deception on black-box\nmodels, and transfer-based targeted attacks have attracted a lot of interest\ndue to their practical applicability. To maximize the transfer success rate,\nadversarial examples should avoid overfitting to the source model, and image\naugmentation is one of the primary approaches for this. However, prior works\nutilize simple image transformations such as resizing, which limits input\ndiversity. To tackle this limitation, we propose the object-based diverse input\n(ODI) method that draws an adversarial image on a 3D object and induces the\nrendered image to be classified as the target class. Our motivation comes from\nthe humans' superior perception of an image printed on a 3D object. If the\nimage is clear enough, humans can recognize the image content in a variety of\nviewing conditions. Likewise, if an adversarial example looks like the target\nclass to the model, the model should also classify the rendered image of the 3D\nobject as the target class. The ODI method effectively diversifies the input by\nleveraging an ensemble of multiple source objects and randomizing viewing\nconditions. In our experimental results on the ImageNet-Compatible dataset,\nthis method boosts the average targeted attack success rate from 28.3% to 47.0%\ncompared to the state-of-the-art methods. We also demonstrate the applicability\nof the ODI method to adversarial examples on the face verification task and its\nsuperior performance improvement. Our code is available at\nhttps://github.com/dreamflake/ODI.",
          "link": "http://arxiv.org/abs/2203.09123",
          "publishedOn": "2022-03-19T00:42:46.944Z",
          "wordCount": 693,
          "title": "Improving the Transferability of Targeted Adversarial Examples through Object-Based Diverse Input. (arXiv:2203.09123v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yi Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zavlanos_M/0/1/0/all/0/1\">Michael M. Zavlanos</a>",
          "description": "We consider an online stochastic game with risk-averse agents whose goal is\nto learn optimal decisions that minimize the risk of incurring significantly\nhigh costs. Specifically, we use the Conditional Value at Risk (CVaR) as a risk\nmeasure that the agents can estimate using bandit feedback in the form of the\ncost values of only their selected actions. Since the distributions of the cost\nfunctions depend on the actions of all agents that are generally unobservable,\nthey are themselves unknown and, therefore, the CVaR values of the costs are\ndifficult to compute. To address this challenge, we propose a new online\nrisk-averse learning algorithm that relies on one-point zeroth-order estimation\nof the CVaR gradients computed using CVaR values that are estimated by\nappropriately sampling the cost functions. We show that this algorithm achieves\nsub-linear regret with high probability. We also propose two variants of this\nalgorithm that improve performance. The first variant relies on a new sampling\nstrategy that uses samples from the previous iteration to improve the\nestimation accuracy of the CVaR values. The second variant employs residual\nfeedback that uses CVaR values from the previous iteration to reduce the\nvariance of the CVaR gradient estimates. We theoretically analyze the\nconvergence properties of these variants and illustrate their performance on an\nonline market problem that we model as a Cournot game.",
          "link": "http://arxiv.org/abs/2203.08957",
          "publishedOn": "2022-03-19T00:42:46.936Z",
          "wordCount": 664,
          "title": "Risk-Averse No-Regret Learning in Online Convex Games. (arXiv:2203.08957v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuzhe Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katabi_D/0/1/0/all/0/1\">Dina Katabi</a>",
          "description": "Real-world data often exhibit imbalanced label distributions. Existing\nstudies on data imbalance focus on single-domain settings, i.e., samples are\nfrom the same data distribution. However, natural data can originate from\ndistinct domains, where a minority class in one domain could have abundant\ninstances from other domains. We formalize the task of Multi-Domain Long-Tailed\nRecognition (MDLT), which learns from multi-domain imbalanced data, addresses\nlabel imbalance, domain shift, and divergent label distributions across\ndomains, and generalizes to all domain-class pairs. We first develop the\ndomain-class transferability graph, and show that such transferability governs\nthe success of learning in MDLT. We then propose BoDA, a theoretically grounded\nlearning strategy that tracks the upper bound of transferability statistics,\nand ensures balanced alignment and calibration across imbalanced domain-class\ndistributions. We curate five MDLT benchmarks based on widely-used multi-domain\ndatasets, and compare BoDA to twenty algorithms that span different learning\nstrategies. Extensive and rigorous experiments verify the superior performance\nof BoDA. Further, as a byproduct, BoDA establishes new state-of-the-art on\nDomain Generalization benchmarks, improving generalization to unseen domains.\nCode and data are available at\nhttps://github.com/YyzHarry/multi-domain-imbalance.",
          "link": "http://arxiv.org/abs/2203.09513",
          "publishedOn": "2022-03-19T00:42:46.916Z",
          "wordCount": 631,
          "title": "On Multi-Domain Long-Tailed Recognition, Generalization and Beyond. (arXiv:2203.09513v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.07258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gecgel_S/0/1/0/all/0/1\">Selen Gecgel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goztepe_C/0/1/0/all/0/1\">Caner Goztepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurt_G/0/1/0/all/0/1\">Gunes Karabulut Kurt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yanikomeroglu_H/0/1/0/all/0/1\">Halim Yanikomeroglu</a>",
          "description": "Communications are realized as a result of successive decisions at the\nphysical layer, from modulation selection to multi-antenna strategy, and each\ndecision affects the performance of the communication systems. Future\ncommunication systems must include extensive capabilities as they will\nencompass a wide variety of devices and applications. Conventional physical\nlayer decision mechanisms may not meet these requirements, as they are often\nbased on impractical and oversimplifying assumptions that result in a trade-off\nbetween complexity and efficiency. By leveraging past experiences,\nlearning-driven designs are promising solutions to present a resilient decision\nmechanism and enable rapid response even under exceptional circumstances. The\ncorresponding design solutions should evolve following the lines of\nlearning-driven paradigms that offer more autonomy and robustness. This\nevolution must take place by considering the facts of real-world systems and\nwithout restraining assumptions. In this paper, the common assumptions in the\nphysical layer are presented to highlight their discrepancies with practical\nsystems. As a solution, learning algorithms are examined by considering the\nimplementation steps and challenges. Furthermore, these issues are discussed\nthrough a real-time case study using software-defined radio nodes to\ndemonstrate the potential performance improvement. A cyber-physical framework\nis presented to incorporate future remedies.",
          "link": "http://arxiv.org/abs/2102.07258",
          "publishedOn": "2022-03-19T00:42:46.910Z",
          "wordCount": 670,
          "title": "A Glimpse of Physical Layer Decision Mechanisms: Facts, Challenges, and Remedies. (arXiv:2102.07258v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nyborg_J/0/1/0/all/0/1\">Joachim Nyborg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelletier_C/0/1/0/all/0/1\">Charlotte Pelletier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assent_I/0/1/0/all/0/1\">Ira Assent</a>",
          "description": "Large-scale crop type classification is a task at the core of remote sensing\nefforts with applications of both economic and ecological importance. Current\nstate-of-the-art deep learning methods are based on self-attention and use\nsatellite image time series (SITS) to discriminate crop types based on their\nunique growth patterns. However, existing methods generalize poorly to regions\nnot seen during training mainly due to not being robust to temporal shifts of\nthe growing season caused by variations in climate. To this end, we propose\nThermal Positional Encoding (TPE) for attention-based crop classifiers. Unlike\nprevious positional encoding based on calendar time (e.g. day-of-year), TPE is\nbased on thermal time, which is obtained by accumulating daily average\ntemperatures over the growing season. Since crop growth is directly related to\nthermal time, but not calendar time, TPE addresses the temporal shifts between\ndifferent regions to improve generalization. We propose multiple TPE\nstrategies, including learnable methods, to further improve results compared to\nthe common fixed positional encodings. We demonstrate our approach on a crop\nclassification task across four different European regions, where we obtain\nstate-of-the-art generalization results.",
          "link": "http://arxiv.org/abs/2203.09175",
          "publishedOn": "2022-03-19T00:42:46.900Z",
          "wordCount": 630,
          "title": "Generalized Classification of Satellite Image Time Series with Thermal Positional Encoding. (arXiv:2203.09175v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.00678",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>",
          "description": "Recent years have witnessed growing interests in multimedia recommendation,\nwhich aims to predict whether a user will interact with an item with multimodal\ncontents. Previous studies focus on modeling user-item interactions with\nmultimodal features included as side information. However, this scheme is not\nwell-designed for multimedia recommendation. Firstly, only collaborative\nitem-item relationships are implicitly modeled through high-order\nitem-user-item co-occurrences. We argue that the latent semantic item-item\nstructures underlying these multimodal contents could be beneficial for\nlearning better item representations and assist the recommender models to\ncomprehensively discover candidate items. Secondly, previous studies disregard\nthe fine-grained multimodal fusion. Although having access to multiple\nmodalities might allow us to capture rich information, we argue that the simple\ncoarse-grained fusion by linear combination or concatenation in previous work\nis insufficient to fully understand content information and item\nrelationships.To this end, we propose a latent structure MIning with\nContRastive mOdality fusion method (MICRO for brevity). To be specific, we\ndevise a novel modality-aware structure learning module, which learns item-item\nrelationships for each modality. Based on the learned modality-aware latent\nitem relationships, we perform graph convolutions that explicitly inject item\naffinities to modality-aware item representations. Then, we design a novel\ncontrastive method to fuse multimodal features. These enriched item\nrepresentations can be plugged into existing collaborative filtering methods to\nmake more accurate recommendations. Extensive experiments on real-world\ndatasets demonstrate the superiority of our method over state-of-the-art\nbaselines.",
          "link": "http://arxiv.org/abs/2111.00678",
          "publishedOn": "2022-03-19T00:42:46.892Z",
          "wordCount": 720,
          "title": "Latent Structure Mining with Contrastive Modality Fusion for Multimedia Recommendation. (arXiv:2111.00678v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hashemifar_S/0/1/0/all/0/1\">Somaye Hashemifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iriondo_C/0/1/0/all/0/1\">Claudia Iriondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casey_E/0/1/0/all/0/1\">Evan Casey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hejrat_M/0/1/0/all/0/1\">Mohsen Hejrat</a>",
          "description": "The ability to predict the future trajectory of a patient is a key step\ntoward the development of therapeutics for complex diseases such as Alzheimer's\ndisease (AD). However, most machine learning approaches developed for\nprediction of disease progression are either single-task or single-modality\nmodels, which can not be directly adopted to our setting involving multi-task\nlearning with high dimensional images. Moreover, most of those approaches are\ntrained on a single dataset (i.e. cohort), which can not be generalized to\nother cohorts. We propose a novel multimodal multi-task deep learning model to\npredict AD progression by analyzing longitudinal clinical and neuroimaging data\nfrom multiple cohorts. Our proposed model integrates high dimensional MRI\nfeatures from a 3D convolutional neural network with other data modalities,\nincluding clinical and demographic information, to predict the future\ntrajectory of patients. Our model employs an adversarial loss to alleviate the\nstudy-specific imaging bias, in particular the inter-study domain shifts. In\naddition, a Sharpness-Aware Minimization (SAM) optimization technique is\napplied to further improve model generalization. The proposed model is trained\nand tested on various datasets in order to evaluate and validate the results.\nOur results showed that 1) our model yields significant improvement over the\nbaseline models, and 2) models using extracted neuroimaging features from 3D\nconvolutional neural network outperform the same models when applied to\nMRI-derived volumetric features.",
          "link": "http://arxiv.org/abs/2203.09096",
          "publishedOn": "2022-03-19T00:42:46.823Z",
          "wordCount": 672,
          "title": "DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression for Real-World Clinical Applications. (arXiv:2203.09096v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09035",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vu_D/0/1/0/all/0/1\">Dat Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngo_B/0/1/0/all/0/1\">Bao Ngo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_H/0/1/0/all/0/1\">Hung Phan</a>",
          "description": "End-to-end Network has become increasingly important in multi-tasking. One\nprominent example of this is the growing significance of a driving perception\nsystem in autonomous driving. This paper systematically studies an end-to-end\nperception network for multi-tasking and proposes several key optimizations to\nimprove accuracy. First, the paper proposes efficient segmentation head and\nbox/class prediction networks based on weighted bidirectional feature network.\nSecond, the paper proposes automatically customized anchor for each level in\nthe weighted bidirectional feature network. Third, the paper proposes an\nefficient training loss function and training strategy to balance and optimize\nnetwork. Based on these optimizations, we have developed an end-to-end\nperception network to perform multi-tasking, including traffic object\ndetection, drivable area segmentation and lane detection simultaneously, called\nHybridNets, which achieves better accuracy than prior art. In particular,\nHybridNets achieves 77.3 mean Average Precision on Berkeley DeepDrive Dataset,\noutperforms lane detection with 31.6 mean Intersection Over Union with 12.83\nmillion parameters and 15.6 billion floating-point operations. In addition, it\ncan perform visual perception tasks in real-time and thus is a practical and\naccurate solution to the multi-tasking problem. Code is available at\nhttps://github.com/datvuthanh/HybridNets.",
          "link": "http://arxiv.org/abs/2203.09035",
          "publishedOn": "2022-03-19T00:42:46.785Z",
          "wordCount": 618,
          "title": "HybridNets: End-to-End Perception Network. (arXiv:2203.09035v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Runqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linlin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Baochang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wentao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doermann_D/0/1/0/all/0/1\">David Doermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_G/0/1/0/all/0/1\">Guodong Guo</a>",
          "description": "Research on the generalization ability of deep neural networks (DNNs) has\nrecently attracted a great deal of attention. However, due to their complex\narchitectures and large numbers of parameters, measuring the generalization\nability of specific DNN models remains an open challenge. In this paper, we\npropose to use multiple factors to measure and rank the relative generalization\nof DNNs based on a new concept of confidence dimension (CD). Furthermore, we\nprovide a feasible framework in our CD to theoretically calculate the upper\nbound of generalization based on the conventional Vapnik-Chervonenk dimension\n(VC-dimension) and Hoeffding's inequality. Experimental results on image\nclassification and object detection demonstrate that our CD can reflect the\nrelative generalization ability for different DNNs. In addition to\nfull-precision DNNs, we also analyze the generalization ability of binary\nneural networks (BNNs), whose generalization ability remains an unsolved\nproblem. Our CD yields a consistent and reliable measure and ranking for both\nfull-precision DNNs and BNNs on all the tasks.",
          "link": "http://arxiv.org/abs/2203.09082",
          "publishedOn": "2022-03-19T00:42:46.777Z",
          "wordCount": 609,
          "title": "Confidence Dimension for Deep Learning based on Hoeffding Inequality and Relative Evaluation. (arXiv:2203.09082v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.12782",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_J/0/1/0/all/0/1\">Jitesh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Anukriti Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orlov_N/0/1/0/all/0/1\">Nikita Orlov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zilong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walton_S/0/1/0/all/0/1\">Steven Walton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Humphrey Shi</a>",
          "description": "Finetuning a pretrained backbone in the encoder part of an image transformer\nnetwork has been the traditional approach for the semantic segmentation task.\nHowever, such an approach leaves out the semantic context that an image\nprovides during the encoding stage. This paper argues that incorporating\nsemantic information of the image into pretrained hierarchical\ntransformer-based backbones while finetuning improves the performance\nconsiderably. To achieve this, we propose SeMask, a simple and effective\nframework that incorporates semantic information into the encoder with the help\nof a semantic attention operation. In addition, we use a lightweight semantic\ndecoder during training to provide supervision to the intermediate semantic\nprior maps at every stage. Our experiments demonstrate that incorporating\nsemantic priors enhances the performance of the established hierarchical\nencoders with a slight increase in the number of FLOPs. We provide empirical\nproof by integrating SeMask into Swin Transformer and Mix Transformer backbones\nas our encoder paired with different decoders. Our framework achieves a new\nstate-of-the-art of 58.22% mIoU on the ADE20K dataset and improvements of over\n3% in the mIoU metric on the Cityscapes dataset. The code and checkpoints are\npublicly available at\nhttps://github.com/Picsart-AI-Research/SeMask-Segmentation .",
          "link": "http://arxiv.org/abs/2112.12782",
          "publishedOn": "2022-03-19T00:42:46.770Z",
          "wordCount": 679,
          "title": "SeMask: Semantically Masked Transformers for Semantic Segmentation. (arXiv:2112.12782v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.07858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1\">Bailin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuxin Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyke_R/0/1/0/all/0/1\">Roberto M. Dyke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Juyong Zhang</a>",
          "description": "Non-rigid registration computes an alignment between a source surface with a\ntarget surface in a non-rigid manner. In the past decade, with the advances in\n3D sensing technologies that can measure time-varying surfaces, non-rigid\nregistration has been applied for the acquisition of deformable shapes and has\na wide range of applications. This survey presents a comprehensive review of\nnon-rigid registration methods for 3D shapes, focusing on techniques related to\ndynamic shape acquisition and reconstruction. In particular, we review\ndifferent approaches for representing the deformation field, and the methods\nfor computing the desired deformation. Both optimization-based and\nlearning-based methods are covered. We also review benchmarks and datasets for\nevaluating non-rigid registration methods, and discuss potential future\nresearch directions.",
          "link": "http://arxiv.org/abs/2203.07858",
          "publishedOn": "2022-03-19T00:42:46.750Z",
          "wordCount": 584,
          "title": "A Survey of Non-Rigid 3D Registration. (arXiv:2203.07858v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.10904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zirui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jiahui Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1\">Adams Wei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zihang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuan Cao</a>",
          "description": "With recent progress in joint modeling of visual and textual representations,\nVision-Language Pretraining (VLP) has achieved impressive performance on many\nmultimodal downstream tasks. However, the requirement for expensive annotations\nincluding clean image captions and regional labels limits the scalability of\nexisting approaches, and complicates the pretraining procedure with the\nintroduction of multiple dataset-specific objectives. In this work, we relax\nthese constraints and present a minimalist pretraining framework, named Simple\nVisual Language Model (SimVLM). Unlike prior work, SimVLM reduces the training\ncomplexity by exploiting large-scale weak supervision, and is trained\nend-to-end with a single prefix language modeling objective. Without utilizing\nextra data or task-specific customization, the resulting model significantly\noutperforms previous pretraining methods and achieves new state-of-the-art\nresults on a wide range of discriminative and generative vision-language\nbenchmarks, including VQA (+3.74% vqa-score), NLVR2 (+1.17% accuracy), SNLI-VE\n(+1.37% accuracy) and image captioning tasks (+10.1% average CIDEr score).\nFurthermore, we demonstrate that SimVLM acquires strong generalization and\ntransfer ability, enabling zero-shot behavior including open-ended visual\nquestion answering and cross-modality transfer.",
          "link": "http://arxiv.org/abs/2108.10904",
          "publishedOn": "2022-03-19T00:42:46.744Z",
          "wordCount": 659,
          "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision. (arXiv:2108.10904v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levine_A/0/1/0/all/0/1\">Alexander Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>",
          "description": "In recent years, researchers have extensively studied adversarial robustness\nin a variety of threat models, including L_0, L_1, L_2, and L_infinity-norm\nbounded adversarial attacks. However, attacks bounded by fractional L_p \"norms\"\n(quasi-norms defined by the L_p distance with 0<p<1) have yet to be thoroughly\nconsidered. We proactively propose a defense with several desirable properties:\nit provides provable (certified) robustness, scales to ImageNet, and yields\ndeterministic (rather than high-probability) certified guarantees when applied\nto quantized data (e.g., images). Our technique for fractional L_p robustness\nconstructs expressive, deep classifiers that are globally Lipschitz with\nrespect to the L_p^p metric, for any 0<p<1. However, our method is even more\ngeneral: we can construct classifiers which are globally Lipschitz with respect\nto any metric defined as the sum of concave functions of components. Our\napproach builds on a recent work, Levine and Feizi (2021), which provides a\nprovable defense against L_1 attacks. However, we demonstrate that our proposed\nguarantees are highly non-vacuous, compared to the trivial solution of using\n(Levine and Feizi, 2021) directly and applying norm inequalities. Code is\navailable at https://github.com/alevine0/fractionalLpRobustness.",
          "link": "http://arxiv.org/abs/2203.08945",
          "publishedOn": "2022-03-19T00:42:46.719Z",
          "wordCount": 620,
          "title": "Provable Adversarial Robustness for Fractional Lp Threat Models. (arXiv:2203.08945v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.07673",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bharadwaj_V/0/1/0/all/0/1\">Vivek Bharadwaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buluc_A/0/1/0/all/0/1\">Aydin Bulu&#xe7;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demmel_J/0/1/0/all/0/1\">James Demmel</a>",
          "description": "Sampled Dense Times Dense Matrix Multiplication (SDDMM) and Sparse Times\nDense Matrix Multiplication (SpMM) appear in diverse settings, such as\ncollaborative filtering, document clustering, and graph embedding. Frequently,\nthe SDDMM output becomes the input sparse matrix for a subsequent SpMM\noperation. Existing work has focused on shared memory parallelization of these\nprimitives. While there has been extensive analysis of communication-minimizing\ndistributed 1.5D algorithms for SpMM, no such analysis exists for SDDMM or the\nback-to-back sequence of SDDMM and SpMM, termed FusedMM. We show that\ndistributed memory 1.5D and 2.5D algorithms for SpMM can be converted to\nalgorithms for SDDMM with identical communication costs and input / output data\nlayouts. Further, we give two communication-eliding strategies to reduce costs\nfurther for FusedMM kernels: either reusing the replication of an input dense\nmatrix for the SDDMM and SpMM in sequence, or fusing the local SDDMM and SpMM\nkernels.\n\nWe benchmark FusedMM algorithms on Cori, a Cray XC40 at LBNL, using\nErdos-Renyi random matrices and large real-world sparse matrices. On 256 nodes\nwith 68 cores each, 1.5D FusedMM algorithms using either communication eliding\napproach can save at least 30% of time spent exclusively in communication\ncompared to executing a distributed-memory SpMM and SDDMM kernel in sequence.\nOn real-world matrices with hundreds of millions of edges, all of our\nalgorithms exhibit at least a 10x speedup over the SpMM algorithm in PETSc. On\nthese matrices, our communication-eliding techniques exhibit runtimes up to 1.6\ntimes faster than an unoptimized sequence of SDDMM and SpMM. We embed and test\nthe scaling of our algorithms in real-world applications, including\ncollaborative filtering via alternating-least-squares and inference for\nattention-based graph neural networks.",
          "link": "http://arxiv.org/abs/2203.07673",
          "publishedOn": "2022-03-19T00:42:46.678Z",
          "wordCount": 714,
          "title": "Distributed-Memory Sparse Kernels for Machine Learning. (arXiv:2203.07673v1 [cs.DC] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.08225",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Muehlebach_M/0/1/0/all/0/1\">Michael Muehlebach</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We introduce a class of first-order methods for smooth constrained\noptimization that are based on an analogy to non-smooth dynamical systems. Two\ndistinctive features of our approach are that (i) projections or optimizations\nover the entire feasible set are avoided, in stark contrast to projected\ngradient methods or the Frank-Wolfe method, and (ii) iterates are allowed to\nbecome infeasible, which differs from active set or feasible direction methods,\nwhere the descent motion stops as soon as a new constraint is encountered. The\nresulting algorithmic procedure is simple to implement even when constraints\nare nonlinear, and is suitable for large-scale constrained optimization\nproblems in which the feasible set fails to have a simple structure. The key\nunderlying idea is that constraints are expressed in terms of velocities\ninstead of positions, which has the algorithmic consequence that optimizations\nover feasible sets at each iteration are replaced with optimizations over\nlocal, sparse convex approximations. In particular, this means that at each\niteration only constraints that are violated are taken into account. The result\nis a simplified suite of algorithms and an expanded range of possible\napplications in machine learning.",
          "link": "http://arxiv.org/abs/2107.08225",
          "publishedOn": "2022-03-19T00:42:46.624Z",
          "wordCount": 656,
          "title": "On Constraints in First-Order Optimization: A View from Non-Smooth Dynamical Systems. (arXiv:2107.08225v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.08644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_U/0/1/0/all/0/1\">Utkarsh Chandra Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Anshuman Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_D/0/1/0/all/0/1\">Dr. K. Sree Kumar</a>",
          "description": "Intracranial hemorrhage, bleeding that occurs inside the cranium, is a\nserious health problem requiring rapid and often intensive medical treatment.\nSuch a condition is traditionally diagnosed by highly-trained specialists\nanalyzing computed tomography (CT) scan of the patient and identifying the\nlocation and type of hemorrhage if one exists. We propose a neural network\napproach to find and classify the condition based upon the CT scan. The model\narchitecture implements a time distributed convolutional network. We observed\naccuracy above 92% from such an architecture, provided enough data. We propose\nfurther extensions to our approach involving the deployment of federated\nlearning. This would be helpful in pooling learned parameters without violating\nthe inherent privacy of the data involved.",
          "link": "http://arxiv.org/abs/2005.08644",
          "publishedOn": "2022-03-19T00:42:46.617Z",
          "wordCount": 608,
          "title": "Intracranial Hemorrhage Detection Using Neural Network Based Methods With Federated Learning. (arXiv:2005.08644v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Renhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "Many recent approaches in contrastive learning have worked to close the gap\nbetween pretraining on iconic images like ImageNet and pretraining on complex\nscenes like COCO. This gap exists largely because commonly used random crop\naugmentations obtain semantically inconsistent content in crowded scene images\nof diverse objects. Previous works use preprocessing pipelines to localize\nsalient objects for improved cropping, but an end-to-end solution is still\nelusive. In this work, we propose a framework which accomplishes this goal via\njoint learning of representations and segmentation. We leverage segmentation\nmasks to train a model with a mask-dependent contrastive loss, and use the\npartially trained model to bootstrap better masks. By iterating between these\ntwo components, we ground the contrastive updates in segmentation information,\nand simultaneously improve segmentation throughout pretraining. Experiments\nshow our representations transfer robustly to downstream tasks in\nclassification, detection and segmentation.",
          "link": "http://arxiv.org/abs/2203.09343",
          "publishedOn": "2022-03-19T00:42:46.609Z",
          "wordCount": 592,
          "title": "CYBORGS: Contrastively Bootstrapping Object Representations by Grounding in Segmentation. (arXiv:2203.09343v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08813",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Nevin L. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Weiyan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_G/0/1/0/all/0/1\">Guanfang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiao-Hui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1\">Caleb Chen Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunpeng Wang</a>",
          "description": "Some examples are easier for humans to classify than others. The same should\nbe true for deep neural networks (DNNs). We use the term example perplexity to\nrefer to the level of difficulty of classifying an example. In this paper, we\npropose a method to measure the perplexity of an example and investigate what\nfactors contribute to high example perplexity. The related codes and resources\nare available at https://github.com/vaynexie/Example-Perplexity.",
          "link": "http://arxiv.org/abs/2203.08813",
          "publishedOn": "2022-03-19T00:42:46.602Z",
          "wordCount": 510,
          "title": "Example Perplexity. (arXiv:2203.08813v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.10199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zaken_E/0/1/0/all/0/1\">Elad Ben Zaken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>",
          "description": "We introduce BitFit, a sparse-finetuning method where only the bias-terms of\nthe model (or a subset of them) are being modified. We show that with\nsmall-to-medium training data, applying BitFit on pre-trained BERT models is\ncompetitive with (and sometimes better than) fine-tuning the entire model. For\nlarger data, the method is competitive with other sparse fine-tuning methods.\nBesides their practical utility, these findings are relevant for the question\nof understanding the commonly-used process of finetuning: they support the\nhypothesis that finetuning is mainly about exposing knowledge induced by\nlanguage-modeling training, rather than learning new task-specific linguistic\nknowledge.",
          "link": "http://arxiv.org/abs/2106.10199",
          "publishedOn": "2022-03-19T00:42:46.580Z",
          "wordCount": 577,
          "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models. (arXiv:2106.10199v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Paritosh Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yen-Chi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Maneesh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tulsiani_S/0/1/0/all/0/1\">Shubham Tulsiani</a>",
          "description": "Powerful priors allow us to perform inference with insufficient information.\nIn this paper, we propose an autoregressive prior for 3D shapes to solve\nmultimodal 3D tasks such as shape completion, reconstruction, and generation.\nWe model the distribution over 3D shapes as a non-sequential autoregressive\ndistribution over a discretized, low-dimensional, symbolic grid-like latent\nrepresentation of 3D shapes. This enables us to represent distributions over 3D\nshapes conditioned on information from an arbitrary set of spatially anchored\nquery locations and thus perform shape completion in such arbitrary settings\n(e.g., generating a complete chair given only a view of the back leg). We also\nshow that the learned autoregressive prior can be leveraged for conditional\ntasks such as single-view reconstruction and language-based generation. This is\nachieved by learning task-specific naive conditionals which can be approximated\nby light-weight models trained on minimal paired data. We validate the\neffectiveness of the proposed method using both quantitative and qualitative\nevaluation and show that the proposed method outperforms the specialized\nstate-of-the-art methods trained for individual tasks. The project page with\ncode and video visualizations can be found at\nhttps://yccyenchicheng.github.io/AutoSDF/.",
          "link": "http://arxiv.org/abs/2203.09516",
          "publishedOn": "2022-03-19T00:42:46.574Z",
          "wordCount": 645,
          "title": "AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation. (arXiv:2203.09516v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schleibaum_S/0/1/0/all/0/1\">S&#xf6;ren Schleibaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_J/0/1/0/all/0/1\">J&#xf6;rg P. M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sester_M/0/1/0/all/0/1\">Monika Sester</a>",
          "description": "To compare alternative taxi schedules and to compute them, as well as to\nprovide insights into an upcoming taxi trip to drivers and passengers, the\nduration of a trip or its Estimated Time of Arrival (ETA) is predicted. To\nreach a high prediction precision, machine learning models for ETA are state of\nthe art. One yet unexploited option to further increase prediction precision is\nto combine multiple ETA models into an ensemble. While an increase of\nprediction precision is likely, the main drawback is that the predictions made\nby such an ensemble become less transparent due to the sophisticated ensemble\narchitecture. One option to remedy this drawback is to apply eXplainable\nArtificial Intelligence (XAI). The contribution of this paper is three-fold.\nFirst, we combine multiple machine learning models from our previous work for\nETA into a two-level ensemble model - a stacked ensemble model - which on its\nown is novel; therefore, we can outperform previous state-of-the-art static\nroute-free ETA approaches. Second, we apply existing XAI methods to explain the\nfirst- and second-level models of the ensemble. Third, we propose three joining\nmethods for combining the first-level explanations with the second-level ones.\nThose joining methods enable us to explain stacked ensembles for regression\ntasks. An experimental evaluation shows that the ETA models correctly learned\nthe importance of those input features driving the prediction.",
          "link": "http://arxiv.org/abs/2203.09438",
          "publishedOn": "2022-03-19T00:42:46.567Z",
          "wordCount": 669,
          "title": "An Explainable Stacked Ensemble Model for Static Route-Free Estimation of Time of Arrival. (arXiv:2203.09438v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.04584",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Asad_M/0/1/0/all/0/1\">Muhammad Asad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fidon_L/0/1/0/all/0/1\">Lucas Fidon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vercauteren_T/0/1/0/all/0/1\">Tom Vercauteren</a>",
          "description": "Automatic segmentation of lung lesions associated with COVID-19 in CT images\nrequires large amount of annotated volumes. Annotations mandate expert\nknowledge and are time-intensive to obtain through fully manual segmentation\nmethods. Additionally, lung lesions have large inter-patient variations, with\nsome pathologies having similar visual appearance as healthy lung tissues. This\nposes a challenge when applying existing semi-automatic interactive\nsegmentation techniques for data labelling. To address these challenges, we\npropose an efficient convolutional neural networks (CNNs) that can be learned\nonline while the annotator provides scribble-based interaction. To accelerate\nlearning from only the samples labelled through user-interactions, a\npatch-based approach is used for training the network. Moreover, we use\nweighted cross-entropy loss to address the class imbalance that may result from\nuser-interactions. During online inference, the learned network is applied to\nthe whole input volume using a fully convolutional approach. We compare our\nproposed method with state-of-the-art using synthetic scribbles and show that\nit outperforms existing methods on the task of annotating lung lesions\nassociated with COVID-19, achieving 16% higher Dice score while reducing\nexecution time by 3$\\times$ and requiring 9000 lesser scribbles-based labelled\nvoxels. Due to the online learning aspect, our approach adapts quickly to user\ninput, resulting in high quality segmentation labels. Source code for ECONet is\navailable at: https://github.com/masadcv/ECONet-MONAILabel.",
          "link": "http://arxiv.org/abs/2201.04584",
          "publishedOn": "2022-03-19T00:42:46.560Z",
          "wordCount": 742,
          "title": "ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation. (arXiv:2201.04584v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Puri_R/0/1/0/all/0/1\">Ravsehaj Singh Puri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parmar_M/0/1/0/all/0/1\">Mihir Parmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>",
          "description": "Recently introduced instruction-paradigm empowers non-expert users to\nleverage NLP resources by defining a new task in natural language.\nInstruction-tuned models have significantly outperformed multitask learning\nmodels (without instruction); however they are far from state of the art task\nspecific models. Conventional approaches to improve model performance via\ncreating large datasets with lots of task instances or architectural/training\nchanges in model may not be feasible for non-expert users. However, they can\nwrite alternate instructions to represent an instruction task. Is\nInstruction-augumentation helpful? We augment a subset of tasks in NATURAL\nINSTRUCTIONS with additional instructions and find that these significantly\nimprove model performance (upto 35%) specially in low-data regime. Our results\nindicate that an additional instruction can be equivalent to ~40 instances on\naverage across our evaluation tasks.",
          "link": "http://arxiv.org/abs/2203.09161",
          "publishedOn": "2022-03-19T00:42:46.554Z",
          "wordCount": 582,
          "title": "How Many Data Samples is an Additional Instruction Worth?. (arXiv:2203.09161v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.11661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khalid_M/0/1/0/all/0/1\">Muhammad Khalid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1\">Cunhua Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aslam_N/0/1/0/all/0/1\">Nauman Aslam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yue Cao</a>",
          "description": "In this paper, to reduce the congestion rate at the city center and increase\nthe quality of experience (QoE) of each user, the framework of long-range\nautonomous valet parking (LAVP) is presented, where an Autonomous Vehicle (AV)\nis deployed in the city, which can pick up, drop off users at their required\nspots, and then drive to the car park out of city center autonomously. In this\nframework, we aim to minimize the overall distance of the AV, while guarantee\nall users are served, i.e., picking up, and dropping off users at their\nrequired spots through optimizing the path planning of the AV and number of\nserving time slots. To this end, we first propose a learning based algorithm,\nwhich is named as Double-Layer Ant Colony Optimization (DL-ACO) algorithm to\nsolve the above problem in an iterative way. Then, to make the real-time\ndecision, while consider the dynamic environment (i.e., the AV may pick up and\ndrop off users from different locations), we further present a deep\nreinforcement learning (DRL) based algorithm, which is known as deep Q network\n(DQN). The experimental results show that the DL-ACO and DQN-based algorithms\nboth achieve the considerable performance.",
          "link": "http://arxiv.org/abs/2109.11661",
          "publishedOn": "2022-03-19T00:42:46.532Z",
          "wordCount": 674,
          "title": "Deep Reinforcement Learning-Based Long-Range Autonomous Valet Parking for Smart Cities. (arXiv:2109.11661v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.07343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thanh Thi Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quoc Viet Hung Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dung Tien Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Samuel Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eklund_P/0/1/0/all/0/1\">Peter W. Eklund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_The_T/0/1/0/all/0/1\">Thien Huynh-The</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thanh Tam Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1\">Quoc-Viet Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razzak_I/0/1/0/all/0/1\">Imran Razzak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_E/0/1/0/all/0/1\">Edbert B. Hsu</a>",
          "description": "Artificial intelligence (AI) has been applied widely in our daily lives in a\nvariety of ways with numerous success stories. AI has also contributed to\ndealing with the coronavirus disease (COVID-19) pandemic, which has been\nhappening around the globe. This paper presents a survey of AI methods being\nused in various applications in the fight against the COVID-19 outbreak and\noutlines the crucial role of AI research in this unprecedented battle. We touch\non areas where AI plays as an essential component, from medical image\nprocessing, data analytics, text mining and natural language processing, the\nInternet of Things, to computational biology and medicine. A summary of\nCOVID-19 related data sources that are available for research purposes is also\npresented. Research directions on exploring the potential of AI and enhancing\nits capability and power in the pandemic battle are thoroughly discussed. We\nidentify 13 groups of problems related to the COVID-19 pandemic and highlight\npromising AI methods and tools that can be used to address these problems. It\nis envisaged that this study will provide AI researchers and the wider\ncommunity with an overview of the current status of AI applications, and\nmotivate researchers to harness AI's potential in the fight against COVID-19.",
          "link": "http://arxiv.org/abs/2008.07343",
          "publishedOn": "2022-03-19T00:42:46.525Z",
          "wordCount": 766,
          "title": "Artificial Intelligence in the Battle against Coronavirus (COVID-19): A Survey and Future Research Directions. (arXiv:2008.07343v4 [cs.CY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bowen Chen</a>",
          "description": "The unprecedented increase of commercial airlines and private jets over the\nnext ten years presents a challenge for air traffic control. Precise flight\ntrajectory prediction is of great significance in air transportation\nmanagement, which contributes to the decision-making for safe and orderly\nflights. Existing research and application mainly focus on the sequence\ngeneration based on historical trajectories, while the aircraft-aircraft\ninteractions in crowded airspace especially the airspaces near busy airports\nhave been largely ignored. On the other hand, there are distinct\ncharacteristics of aerodynamics for different flight phases, and the trajectory\nmay be affected by various uncertainties such as weather and advisories from\nair traffic controllers. However, there is no literature fully considers all\nthese issues. Therefore, we proposed a phased flight trajectory prediction\nframework. Multi-source and multi-modal datasets have been analyzed and mined\nusing variants of recurrent neural network (RNN) mixture. To be specific, we\nfirst introduce spatio temporal graphs into the low-altitude airway prediction\nproblem, and the motion constraints of an aircraft are embedded to the\ninference process for reliable forecasting results. In the en-route phase, the\ndual attention mechanism is employed to adaptively extract much more important\nfeatures from overall datasets to learn the hidden patterns in dynamical\nenvironments. The experimental results demonstrate our proposed framework can\noutperform state-of-the-art methods for flight trajectory prediction for large\npassenger/transport airplanes.",
          "link": "http://arxiv.org/abs/2203.09033",
          "publishedOn": "2022-03-19T00:42:46.519Z",
          "wordCount": 652,
          "title": "Phased Flight Trajectory Prediction with Deep Learning. (arXiv:2203.09033v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08827",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Lucie_Smith_L/0/1/0/all/0/1\">Luisa Lucie-Smith</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Peiris_H/0/1/0/all/0/1\">Hiranya V. Peiris</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Pontzen_A/0/1/0/all/0/1\">Andrew Pontzen</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Nord_B/0/1/0/all/0/1\">Brian Nord</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Thiyagalingam_J/0/1/0/all/0/1\">Jeyan Thiyagalingam</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Piras_D/0/1/0/all/0/1\">Davide Piras</a>",
          "description": "The density profiles of dark matter halos are typically modeled using\nempirical formulae fitted to the density profiles of relaxed halo populations.\nWe present a neural network model that is trained to learn the mapping from the\nraw density field containing each halo to the dark matter density profile. We\nshow that the model recovers the widely-used Navarro-Frenk-White (NFW) profile\nout to the virial radius, and can additionally describe the variability in the\nouter profile of the halos. The neural network architecture consists of a\nsupervised encoder-decoder framework, which first compresses the density inputs\ninto a low-dimensional latent representation, and then outputs $\\rho(r)$ for\nany desired value of radius $r$. The latent representation contains all the\ninformation used by the model to predict the density profiles. This allows us\nto interpret the latent representation by quantifying the mutual information\nbetween the representation and the halos' ground-truth density profiles. A\ntwo-dimensional representation is sufficient to accurately model the density\nprofiles up to the virial radius; however, a three-dimensional representation\nis required to describe the outer profiles beyond the virial radius. The\nadditional dimension in the representation contains information about the\ninfalling material in the outer profiles of dark matter halos, thus discovering\nthe splashback boundary of halos without prior knowledge of the halos'\ndynamical history.",
          "link": "http://arxiv.org/abs/2203.08827",
          "publishedOn": "2022-03-19T00:42:46.511Z",
          "wordCount": 690,
          "title": "Discovering the building blocks of dark matter halo density profiles with neural networks. (arXiv:2203.08827v1 [astro-ph.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08819",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Metulini_R/0/1/0/all/0/1\">Rodolfo Metulini</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gnecco_G/0/1/0/all/0/1\">Giorgio Gnecco</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Biancalani_F/0/1/0/all/0/1\">Francesco Biancalani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Riccaboni_M/0/1/0/all/0/1\">Massimo Riccaboni</a>",
          "description": "World Input-Output (I/O) matrices provide the networks of within- and\ncross-country economic relations. In the context of I/O analysis, the\nmethodology adopted by national statistical offices in data collection raises\nthe issue of obtaining reliable data in a timely fashion and it makes the\nreconstruction of (part of) the I/O matrices of particular interest. In this\nwork, we propose a method combining hierarchical clustering and Matrix\nCompletion (MC) with a LASSO-like nuclear norm penalty, to impute missing\nentries of a partially unknown I/O matrix. Through simulations based on\nsynthetic matrices we study the effectiveness of the proposed method to predict\nmissing values from both previous years data and current data related to\ncountries similar to the one for which current data are obscured. To show the\nusefulness of our method, an application based on World Input-Output Database\n(WIOD) tables - which are an example of industry-by-industry I/O tables - is\nprovided. Strong similarities in structure between WIOD and other I/O tables\nare also found, which make the proposed approach easily generalizable to them.",
          "link": "http://arxiv.org/abs/2203.08819",
          "publishedOn": "2022-03-19T00:42:46.490Z",
          "wordCount": 617,
          "title": "Hierarchical Clustering and Matrix Completion for the Reconstruction of World Input-Output Tables. (arXiv:2203.08819v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09436",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cai_X/0/1/0/all/0/1\">Xufeng Cai</a>, <a href=\"http://arxiv.org/find/math/1/au:+Song_C/0/1/0/all/0/1\">Chaobing Song</a>, <a href=\"http://arxiv.org/find/math/1/au:+Guzman_C/0/1/0/all/0/1\">Crist&#xf3;bal Guzm&#xe1;n</a>, <a href=\"http://arxiv.org/find/math/1/au:+Diakonikolas_J/0/1/0/all/0/1\">Jelena Diakonikolas</a>",
          "description": "We study stochastic monotone inclusion problems, which widely appear in\nmachine learning applications, including robust regression and adversarial\nlearning. We propose novel variants of stochastic Halpern iteration with\nrecursive variance reduction. In the cocoercive -- and more generally\nLipschitz-monotone -- setup, our algorithm attains $\\epsilon$ norm of the\noperator with $\\mathcal{O}(\\frac{1}{\\epsilon^3})$ stochastic operator\nevaluations, which significantly improves over state of the art\n$\\mathcal{O}(\\frac{1}{\\epsilon^4})$ stochastic operator evaluations required\nfor existing monotone inclusion solvers applied to the same problem classes. We\nfurther show how to couple one of the proposed variants of stochastic Halpern\niteration with a scheduled restart scheme to solve stochastic monotone\ninclusion problems with ${\\mathcal{O}}(\\frac{\\log(1/\\epsilon)}{\\epsilon^2})$\nstochastic operator evaluations under additional sharpness or strong\nmonotonicity assumptions. Finally, we argue via reductions between different\nproblem classes that our stochastic oracle complexity bounds are tight up to\nlogarithmic factors in terms of their $\\epsilon$-dependence.",
          "link": "http://arxiv.org/abs/2203.09436",
          "publishedOn": "2022-03-19T00:42:46.484Z",
          "wordCount": 590,
          "title": "A Stochastic Halpern Iteration with Variance Reduction for Stochastic Monotone Inclusion Problems. (arXiv:2203.09436v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08949",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghadirzadeh_A/0/1/0/all/0/1\">Ali Ghadirzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tianhe Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yuan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenzhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_B/0/1/0/all/0/1\">Bin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>",
          "description": "Offline reinforcement learning methods hold the promise of learning policies\nfrom pre-collected datasets without the need to query the environment for new\ntransitions. This setting is particularly well-suited for continuous control\nrobotic applications for which online data collection based on trial-and-error\nis costly and potentially unsafe. In practice, offline datasets are often\nheterogeneous, i.e., collected in a variety of scenarios, such as data from\nseveral human demonstrators or from policies that act with different purposes.\nUnfortunately, such datasets can exacerbate the distribution shift between the\nbehavior policy underlying the data and the optimal policy to be learned,\nleading to poor performance. To address this challenge, we propose to leverage\nlatent-variable policies that can represent a broader class of policy\ndistributions, leading to better adherence to the training data distribution\nwhile maximizing reward via a policy over the latent variable. As we\nempirically show on a range of simulated locomotion, navigation, and\nmanipulation tasks, our method referred to as latent-variable\nadvantage-weighted policy optimization (LAPO), improves the average performance\nof the next best-performing offline reinforcement learning methods by 49% on\nheterogeneous datasets, and by 8% on datasets with narrow and biased\ndistributions.",
          "link": "http://arxiv.org/abs/2203.08949",
          "publishedOn": "2022-03-19T00:42:46.477Z",
          "wordCount": 631,
          "title": "Latent-Variable Advantage-Weighted Policy Optimization for Offline RL. (arXiv:2203.08949v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08810",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Feng_T/0/1/0/all/0/1\">Tiantian Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Narayanan_S/0/1/0/all/0/1\">Shrikanth Narayanan</a>",
          "description": "Speech Emotion Recognition (SER) application is frequently associated with\nprivacy concerns as it often acquires and transmits speech data at the\nclient-side to remote cloud platforms for further processing. These speech data\ncan reveal not only speech content and affective information but the speaker's\nidentity, demographic traits, and health status. Federated learning (FL) is a\ndistributed machine learning algorithm that coordinates clients to train a\nmodel collaboratively without sharing local data. This algorithm shows enormous\npotential for SER applications as sharing raw speech or speech features from a\nuser's device is vulnerable to privacy attacks. However, a major challenge in\nFL is limited availability of high-quality labeled data samples. In this work,\nwe propose a semi-supervised federated learning framework, Semi-FedSER, that\nutilizes both labeled and unlabeled data samples to address the challenge of\nlimited labeled data samples in FL. We show that our Semi-FedSER can generate\ndesired SER performance even when the local label rate l=20 using two SER\nbenchmark datasets: IEMOCAP and MSP-Improv.",
          "link": "http://arxiv.org/abs/2203.08810",
          "publishedOn": "2022-03-19T00:42:46.470Z",
          "wordCount": 634,
          "title": "Semi-FedSER: Semi-supervised Learning for Speech Emotion Recognition On Federated Learning using Multiview Pseudo-Labeling. (arXiv:2203.08810v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08812",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Miller_J/0/1/0/all/0/1\">John D. Miller</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arasu_V/0/1/0/all/0/1\">Vignesh A. Arasu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pu_A/0/1/0/all/0/1\">Albert X. Pu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Margolies_L/0/1/0/all/0/1\">Laurie R. Margolies</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sieh_W/0/1/0/all/0/1\">Weiva Sieh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>",
          "description": "A major limitation in applying deep learning to artificial intelligence (AI)\nsystems is the scarcity of high-quality curated datasets. We investigate strong\naugmentation based self-supervised learning (SSL) techniques to address this\nproblem. Using breast cancer detection as an example, we first identify a\nmammogram-specific transformation paradigm and then systematically compare four\nrecent SSL methods representing a diversity of approaches. We develop a method\nto convert a pretrained model from making predictions on uniformly tiled\npatches to whole images, and an attention-based pooling method that improves\nthe classification performance. We found that the best SSL model substantially\noutperformed the baseline supervised model. The best SSL model also improved\nthe data efficiency of sample labeling by nearly 4-fold and was highly\ntransferrable from one dataset to another. SSL represents a major breakthrough\nin computer vision and may help the AI for medical imaging field to shift away\nfrom supervised learning and dependency on scarce labels.",
          "link": "http://arxiv.org/abs/2203.08812",
          "publishedOn": "2022-03-19T00:42:46.463Z",
          "wordCount": 621,
          "title": "Self-Supervised Deep Learning to Enhance Breast Cancer Detection on Screening Mammography. (arXiv:2203.08812v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08898",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Schreck_J/0/1/0/all/0/1\">John S. Schreck</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gantos_G/0/1/0/all/0/1\">Gabrielle Gantos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hayman_M/0/1/0/all/0/1\">Matthew Hayman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bensemer_A/0/1/0/all/0/1\">Aaron Bensemer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gagne_D/0/1/0/all/0/1\">David John Gagne</a>",
          "description": "HOLODEC, an airborne cloud particle imager, captures holographic images of a\nfixed volume of cloud to characterize the types and sizes of cloud particles,\nsuch as water droplets and ice crystals. Cloud particle properties include\nposition, diameter, and shape. We present a hologram processing algorithm,\nHolodecML, that utilizes a neural segmentation model, GPUs, and computational\nparallelization. HolodecML is trained using synthetically generated holograms\nbased on a model of the instrument, and predicts masks around particles found\nwithin reconstructed images. From these masks, the position and size of the\ndetected particles can be characterized in three dimensions. In order to\nsuccessfully process real holograms, we find we must apply a series of image\ncorrupting transformations and noise to the synthetic images used in training.\n\nIn this evaluation, HolodecML had comparable position and size estimation\nperformance to the standard processing method, but improved particle detection\nby nearly 20\\% on several thousand manually labeled HOLODEC images. However,\nthe improvement only occurred when image corruption was performed on the\nsimulated images during training, thereby mimicking non-ideal conditions in the\nactual probe. The trained model also learned to differentiate artifacts and\nother impurities in the HOLODEC images from the particles, even though no such\nobjects were present in the training data set, while the standard processing\nmethod struggled to separate particles from artifacts. The novelty of the\ntraining approach, which leveraged noise as a means for parameterizing\nnon-ideal aspects of the HOLODEC detector, could be applied in other domains\nwhere the theoretical model is incapable of fully describing the real-world\noperation of the instrument and accurate truth data required for supervised\nlearning cannot be obtained from real-world observations.",
          "link": "http://arxiv.org/abs/2203.08898",
          "publishedOn": "2022-03-19T00:42:46.428Z",
          "wordCount": 735,
          "title": "Neural network processing of holographic images. (arXiv:2203.08898v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bauckhage_C/0/1/0/all/0/1\">Christian Bauckhage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerlach_T/0/1/0/all/0/1\">Thore Gerlach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piatkowski_N/0/1/0/all/0/1\">Nico Piatkowski</a>",
          "description": "We show that the fundamental tasks of sorting lists and building search trees\nor heaps can be modeled as quadratic unconstrained binary optimization problems\n(QUBOs). The idea is to understand these tasks as permutation problems and to\ndevise QUBOs whose solutions represent appropriate permutation matrices. We\ndiscuss how to construct such QUBOs and how to solve them using Hopfield nets\nor adiabatic) quantum computing. In short, we show that neurocomputing methods\nor quantum computers can solve problems usually associated with abstract data\nstructures.",
          "link": "http://arxiv.org/abs/2203.08815",
          "publishedOn": "2022-03-19T00:42:46.420Z",
          "wordCount": 525,
          "title": "QUBOs for Sorting Lists and Building Trees. (arXiv:2203.08815v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08975",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Changxi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dastani_M/0/1/0/all/0/1\">Mehdi Dastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shihan Wang</a>",
          "description": "Communication is an effective mechanism for coordinating the behavior of\nmultiple agents. In the field of multi-agent reinforcement learning, agents can\nimprove the overall learning performance and achieve their objectives by\ncommunication. Moreover, agents can communicate various types of messages,\neither to all agents or to specific agent groups, and through specific\nchannels. With the growing body of research work in MARL with communication\n(Comm-MARL), there is lack of a systematic and structural approach to\ndistinguish and classify existing Comm-MARL systems. In this paper, we survey\nrecent works in the Comm-MARL field and consider various aspects of\ncommunication that can play a role in the design and development of multi-agent\nreinforcement learning systems. With these aspects in mind, we propose several\ndimensions along which Comm-MARL systems can be analyzed, developed, and\ncompared.",
          "link": "http://arxiv.org/abs/2203.08975",
          "publishedOn": "2022-03-19T00:42:46.392Z",
          "wordCount": 574,
          "title": "A Survey of Multi-Agent Reinforcement Learning with Communication. (arXiv:2203.08975v1 [cs.MA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09128",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Valavi_E/0/1/0/all/0/1\">Ehsan Valavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hestness_J/0/1/0/all/0/1\">Joel Hestness</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iansiti_M/0/1/0/all/0/1\">Marco Iansiti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ardalani_N/0/1/0/all/0/1\">Newsha Ardalani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Feng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakhani_K/0/1/0/all/0/1\">Karim R. Lakhani</a>",
          "description": "Data is fundamental to machine learning-based products and services and is\nconsidered strategic due to its externalities for businesses, governments,\nnon-profits, and more generally for society. It is renowned that the value of\norganizations (businesses, government agencies and programs, and even\nindustries) scales with the volume of available data. What is often less\nappreciated is that the data value in making useful organizational predictions\nwill range widely and is prominently a function of data characteristics and\nunderlying algorithms.\n\nIn this research, our goal is to study how the value of data changes over\ntime and how this change varies across contexts and business areas (e.g. next\nword prediction in the context of history, sports, politics). We focus on data\nfrom Reddit.com and compare the value's time-dependency across various Reddit\ntopics (Subreddits). We make this comparison by measuring the rate at which\nuser-generated text data loses its relevance to the algorithmic prediction of\nconversations. We show that different subreddits have different rates of\nrelevance decline over time.\n\nRelating the text topics to various business areas of interest, we argue that\ncompeting in a business area in which data value decays rapidly alters\nstrategies to acquire competitive advantage. When data value decays rapidly,\naccess to a continuous flow of data will be more valuable than access to a\nfixed stock of data. In this kind of setting, improving user engagement and\nincreasing user-base help creating and maintaining a competitive advantage.",
          "link": "http://arxiv.org/abs/2203.09128",
          "publishedOn": "2022-03-19T00:42:46.385Z",
          "wordCount": 689,
          "title": "Time Dependency, Data Flow, and Competitive Advantage. (arXiv:2203.09128v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maeda_T/0/1/0/all/0/1\">Takahiro Maeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ukita_N/0/1/0/all/0/1\">Norimichi Ukita</a>",
          "description": "This paper presents a motion data augmentation scheme incorporating motion\nsynthesis encouraging diversity and motion correction imposing physical\nplausibility. This motion synthesis consists of our modified Variational\nAutoEncoder (VAE) and Inverse Kinematics (IK). In this VAE, our proposed\nsampling-near-samples method generates various valid motions even with\ninsufficient training motion data. Our IK-based motion synthesis method allows\nus to generate a variety of motions semi-automatically. Since these two schemes\ngenerate unrealistic artifacts in the synthesized motions, our motion\ncorrection rectifies them. This motion correction scheme consists of imitation\nlearning with physics simulation and subsequent motion debiasing. For this\nimitation learning, we propose the PD-residual force that significantly\naccelerates the training process. Furthermore, our motion debiasing\nsuccessfully offsets the motion bias induced by imitation learning to maximize\nthe effect of augmentation. As a result, our method outperforms previous\nnoise-based motion augmentation methods by a large margin on both Recurrent\nNeural Network-based and Graph Convolutional Network-based human motion\nprediction models. The code is available at {\\rm\n\\url{https://github.com/meaten/MotionAug}}.",
          "link": "http://arxiv.org/abs/2203.09116",
          "publishedOn": "2022-03-19T00:42:46.379Z",
          "wordCount": 606,
          "title": "MotionAug: Augmentation with Physical Correction for Human Motion Prediction. (arXiv:2203.09116v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08820",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Ge_C/0/1/0/all/0/1\">Cheng Ge</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lu_Y/0/1/0/all/0/1\">Yi Lu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qu_J/0/1/0/all/0/1\">Jia Qu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xie_L/0/1/0/all/0/1\">Liangxu Xie</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_F/0/1/0/all/0/1\">Feng Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_H/0/1/0/all/0/1\">Hong Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kong_R/0/1/0/all/0/1\">Ren Kong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chang_S/0/1/0/all/0/1\">Shan Chang</a>",
          "description": "De novo peptide sequencing from mass spectrometry data is an important method\nfor protein identification. Recently, various deep learning approaches were\napplied for de novo peptide sequencing and DeepNovoV2 is one of the\nrepresetative models. In this study, we proposed an enhanced model, DePS, which\ncan improve the accuracy of de novo peptide sequencing even with missing signal\npeaks or large number of noisy peaks in tandem mass spectrometry data. It is\nshowed that, for the same test set of DeepNovoV2, the DePS model achieved\nexcellent results of 74.22%, 74.21% and 41.68% for amino acid recall, amino\nacid precision and peptide recall respectively. Furthermore, the results\nsuggested that DePS outperforms DeepNovoV2 on the cross species dataset.",
          "link": "http://arxiv.org/abs/2203.08820",
          "publishedOn": "2022-03-19T00:42:46.372Z",
          "wordCount": 579,
          "title": "DePS: An improved deep learning model for de novo peptide sequencing. (arXiv:2203.08820v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08802",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Coutinho_E/0/1/0/all/0/1\">E.J.R. Coutinho</a>, <a href=\"http://arxiv.org/find/physics/1/au:+DallAqua_M/0/1/0/all/0/1\">M. Dall&#x27;Aqua</a>, <a href=\"http://arxiv.org/find/physics/1/au:+McClenny_L/0/1/0/all/0/1\">L. McClenny</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhong_M/0/1/0/all/0/1\">M. Zhong</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Braga_Neto_U/0/1/0/all/0/1\">U. Braga-Neto</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gildin_E/0/1/0/all/0/1\">E. Gildin</a>",
          "description": "Physics-informed Neural Network (PINN) is a promising tool that has been\napplied in a variety of physical phenomena described by partial differential\nequations (PDE). However, it has been observed that PINNs are difficult to\ntrain in certain \"stiff\" problems, which include various nonlinear hyperbolic\nPDEs that display shocks in their solutions. Recent studies added a diffusion\nterm to the PDE, and an artificial viscosity (AV) value was manually tuned to\nallow PINNs to solve these problems. In this paper, we propose three approaches\nto address this problem, none of which rely on an a priori definition of the\nartificial viscosity value. The first method learns a global AV value, whereas\nthe other two learn localized AV values around the shocks, by means of a\nparametrized AV map or a residual-based AV map. We applied the proposed methods\nto the inviscid Burgers equation and the Buckley-Leverett equation, the latter\nbeing a classical problem in Petroleum Engineering. The results show that the\nproposed methods are able to learn both a small AV value and the accurate shock\nlocation and improve the approximation error over a nonadaptive global AV\nalternative method.",
          "link": "http://arxiv.org/abs/2203.08802",
          "publishedOn": "2022-03-19T00:42:46.352Z",
          "wordCount": 628,
          "title": "Physics-Informed Neural Networks with Adaptive Localized Artificial Viscosity. (arXiv:2203.08802v1 [physics.flu-dyn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karantzas_N/0/1/0/all/0/1\">Nikos Karantzas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besier_E/0/1/0/all/0/1\">Emma Besier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caro_J/0/1/0/all/0/1\">Josue Ortega Caro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pitkow_X/0/1/0/all/0/1\">Xaq Pitkow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tolias_A/0/1/0/all/0/1\">Andreas S. Tolias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1\">Ankit B. Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anselmi_F/0/1/0/all/0/1\">Fabio Anselmi</a>",
          "description": "Despite the enormous success of artificial neural networks (ANNs) in many\ndisciplines, the characterization of their computations and the origin of key\nproperties such as generalization and robustness remain open questions. Recent\nliterature suggests that robust networks with good generalization properties\ntend to be biased towards processing low frequencies in images. To explore the\nfrequency bias hypothesis further, we develop an algorithm that allows us to\nlearn modulatory masks highlighting the essential input frequencies needed for\npreserving a trained network's performance. We achieve this by imposing\ninvariance in the loss with respect to such modulations in the input\nfrequencies. We first use our method to test the low-frequency preference\nhypothesis of adversarially trained or data-augmented networks. Our results\nsuggest that adversarially robust networks indeed exhibit a low-frequency bias\nbut we find this bias is also dependent on directions in frequency space.\nHowever, this is not necessarily true for other types of data augmentation. Our\nresults also indicate that the essential frequencies in question are\neffectively the ones used to achieve generalization in the first place.\nSurprisingly, images seen through these modulatory masks are not recognizable\nand resemble texture-like patterns.",
          "link": "http://arxiv.org/abs/2203.08822",
          "publishedOn": "2022-03-19T00:42:46.344Z",
          "wordCount": 653,
          "title": "Understanding robustness and generalization of artificial neural networks through Fourier masks. (arXiv:2203.08822v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Razavi_S/0/1/0/all/0/1\">Shahab Razavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gamazon_E/0/1/0/all/0/1\">Eric R. Gamazon</a>",
          "description": "We develop a symbolic regression framework for extracting the governing\nmathematical expressions from observed data. The evolutionary approach, faiGP,\nis designed to leverage the properties of a function algebra that have been\nencoded into a grammar, providing a theoretical guarantee of universal\napproximation and a way to minimize bloat. In this framework, the choice of\noperators of the grammar may be informed by a physical theory or symmetry\nconsiderations. Since there is currently no theory that can derive the\n'constants of nature', an empirical investigation on extracting these\ncoefficients from an evolutionary process is of methodological interest. We\nquantify the impact of different types of regularizers, including a diversity\nmetric adapted from studies of the transcriptome and a complexity measure, on\nthe performance of the framework. Our implementation, which leverages neural\nnetworks and a genetic programmer, generates non-trivial symbolically\nequivalent expressions (\"Ramanujan expressions\") or approximations with\npotentially interesting numerical applications. To illustrate the framework, a\nmodel of ligand-receptor binding kinetics, including an account of gene\nregulation by transcription factors, and a model of the regulatory range of the\ncistrome from omics data are presented. This study has important implications\non the development of data-driven methodologies for the discovery of governing\nequations in experimental data derived from new sensing systems and\nhigh-throughput screening technologies.",
          "link": "http://arxiv.org/abs/2203.08808",
          "publishedOn": "2022-03-19T00:42:46.186Z",
          "wordCount": 650,
          "title": "Neural-Network-Directed Genetic Programmer for Discovery of Governing Equations. (arXiv:2203.08808v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08806",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Adelmann_A/0/1/0/all/0/1\">Andreas Adelmann</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Hopkins_W/0/1/0/all/0/1\">Walter Hopkins</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Kourlitis_E/0/1/0/all/0/1\">Evangelos Kourlitis</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Kagan_M/0/1/0/all/0/1\">Michael Kagan</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Kasieczka_G/0/1/0/all/0/1\">Gregor Kasieczka</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Krause_C/0/1/0/all/0/1\">Claudius Krause</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Shih_D/0/1/0/all/0/1\">David Shih</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Mikuni_V/0/1/0/all/0/1\">Vinicius Mikuni</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Nachman_B/0/1/0/all/0/1\">Benjamin Nachman</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Pedro_K/0/1/0/all/0/1\">Kevin Pedro</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Winklehner_D/0/1/0/all/0/1\">Daniel Winklehner</a>",
          "description": "The computational cost for high energy physics detector simulation in future\nexperimental facilities is going to exceed the current available resources. To\novercome this challenge, new ideas on surrogate models using machine learning\nmethods are being explored to replace computationally expensive components.\nAdditionally, differentiable programming has been proposed as a complementary\napproach, providing controllable and scalable simulation routines. In this\ndocument, new and ongoing efforts for surrogate models and differential\nprogramming applied to detector simulation are discussed in the context of the\n2021 Particle Physics Community Planning Exercise (`Snowmass').",
          "link": "http://arxiv.org/abs/2203.08806",
          "publishedOn": "2022-03-19T00:42:46.146Z",
          "wordCount": 579,
          "title": "New directions for surrogate models and differentiable programming for High Energy Physics detector simulation. (arXiv:2203.08806v1 [hep-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08807",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Daneshjou_R/0/1/0/all/0/1\">Roxana Daneshjou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vodrahalli_K/0/1/0/all/0/1\">Kailas Vodrahalli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Novoa_R/0/1/0/all/0/1\">Roberto A Novoa</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jenkins_M/0/1/0/all/0/1\">Melissa Jenkins</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_W/0/1/0/all/0/1\">Weixin Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rotemberg_V/0/1/0/all/0/1\">Veronica Rotemberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ko_J/0/1/0/all/0/1\">Justin Ko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Swetter_S/0/1/0/all/0/1\">Susan M Swetter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bailey_E/0/1/0/all/0/1\">Elizabeth E Bailey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gevaert_O/0/1/0/all/0/1\">Olivier Gevaert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mukherjee_P/0/1/0/all/0/1\">Pritam Mukherjee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Phung_M/0/1/0/all/0/1\">Michelle Phung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yekrang_K/0/1/0/all/0/1\">Kiana Yekrang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fong_B/0/1/0/all/0/1\">Bradley Fong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sahasrabudhe_R/0/1/0/all/0/1\">Rachna Sahasrabudhe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Allerup_J/0/1/0/all/0/1\">Johan A. C. Allerup</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Okata_Karigane_U/0/1/0/all/0/1\">Utako Okata-Karigane</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chiou_A/0/1/0/all/0/1\">Albert Chiou</a>",
          "description": "Access to dermatological care is a major issue, with an estimated 3 billion\npeople lacking access to care globally. Artificial intelligence (AI) may aid in\ntriaging skin diseases. However, most AI models have not been rigorously\nassessed on images of diverse skin tones or uncommon diseases. To ascertain\npotential biases in algorithm performance in this context, we curated the\nDiverse Dermatology Images (DDI) dataset-the first publicly available, expertly\ncurated, and pathologically confirmed image dataset with diverse skin tones.\nUsing this dataset of 656 images, we show that state-of-the-art dermatology AI\nmodels perform substantially worse on DDI, with receiver operator curve area\nunder the curve (ROC-AUC) dropping by 27-36 percent compared to the models'\noriginal test results. All the models performed worse on dark skin tones and\nuncommon diseases, which are represented in the DDI dataset. Additionally, we\nfind that dermatologists, who typically provide visual labels for AI training\nand test datasets, also perform worse on images of dark skin tones and uncommon\ndiseases compared to ground truth biopsy annotations. Finally, fine-tuning AI\nmodels on the well-characterized and diverse DDI images closed the performance\ngap between light and dark skin tones. Moreover, algorithms fine-tuned on\ndiverse skin tones outperformed dermatologists on identifying malignancy on\nimages of dark skin tones. Our findings identify important weaknesses and\nbiases in dermatology AI that need to be addressed to ensure reliable\napplication to diverse patients and diseases.",
          "link": "http://arxiv.org/abs/2203.08807",
          "publishedOn": "2022-03-19T00:42:45.477Z",
          "wordCount": 729,
          "title": "Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set. (arXiv:2203.08807v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.15640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Preechakul_K/0/1/0/all/0/1\">Konpat Preechakul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatthee_N/0/1/0/all/0/1\">Nattanat Chatthee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wizadwongsa_S/0/1/0/all/0/1\">Suttisak Wizadwongsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suwajanakorn_S/0/1/0/all/0/1\">Supasorn Suwajanakorn</a>",
          "description": "Diffusion probabilistic models (DPMs) have achieved remarkable quality in\nimage generation that rivals GANs'. But unlike GANs, DPMs use a set of latent\nvariables that lack semantic meaning and cannot serve as a useful\nrepresentation for other tasks. This paper explores the possibility of using\nDPMs for representation learning and seeks to extract a meaningful and\ndecodable representation of an input image via autoencoding. Our key idea is to\nuse a learnable encoder for discovering the high-level semantics, and a DPM as\nthe decoder for modeling the remaining stochastic variations. Our method can\nencode any image into a two-part latent code, where the first part is\nsemantically meaningful and linear, and the second part captures stochastic\ndetails, allowing near-exact reconstruction. This capability enables\nchallenging applications that currently foil GAN-based methods, such as\nattribute manipulation on real images. We also show that this two-level\nencoding improves denoising efficiency and naturally facilitates various\ndownstream tasks including few-shot conditional sampling. Please visit our\nproject page: https://Diff-AE.github.io/",
          "link": "http://arxiv.org/abs/2111.15640",
          "publishedOn": "2022-03-12T00:41:17.268Z",
          "wordCount": 656,
          "title": "Diffusion Autoencoders: Toward a Meaningful and Decodable Representation. (arXiv:2111.15640v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Putra_R/0/1/0/all/0/1\">Rachmad Vidya Wicaksana Putra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanif_M/0/1/0/all/0/1\">Muhammad Abdullah Hanif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1\">Muhammad Shafique</a>",
          "description": "Specialized hardware accelerators have been designed and employed to maximize\nthe performance efficiency of Spiking Neural Networks (SNNs). However, such\naccelerators are vulnerable to transient faults (i.e., soft errors), which\noccur due to high-energy particle strikes, and manifest as bit flips at the\nhardware layer. These errors can change the weight values and neuron operations\nin the compute engine of SNN accelerators, thereby leading to incorrect outputs\nand accuracy degradation. However, the impact of soft errors in the compute\nengine and the respective mitigation techniques have not been thoroughly\nstudied yet for SNNs. A potential solution is employing redundant executions\n(re-execution) for ensuring correct outputs, but it leads to huge latency and\nenergy overheads. Toward this, we propose SoftSNN, a novel methodology to\nmitigate soft errors in the weight registers (synapses) and neurons of SNN\naccelerators without re-execution, thereby maintaining the accuracy with low\nlatency and energy overheads. Our SoftSNN methodology employs the following key\nsteps: (1) analyzing the SNN characteristics under soft errors to identify\nfaulty weights and neuron operations, which are required for recognizing faulty\nSNN behavior; (2) a Bound-and-Protect technique that leverages this analysis to\nimprove the SNN fault tolerance by bounding the weight values and protecting\nthe neurons from faulty operations; and (3) devising lightweight hardware\nenhancements for the neural hardware accelerator to efficiently support the\nproposed technique. The experimental results show that, for a 900-neuron\nnetwork with even a high fault rate, our SoftSNN maintains the accuracy\ndegradation below 3%, while reducing latency and energy by up to 3x and 2.3x\nrespectively, as compared to the re-execution technique.",
          "link": "http://arxiv.org/abs/2203.05523",
          "publishedOn": "2022-03-12T00:41:17.246Z",
          "wordCount": 734,
          "title": "SoftSNN: Low-Cost Fault Tolerance for Spiking Neural Network Accelerators under Soft Errors. (arXiv:2203.05523v1 [cs.AR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.00265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagamori_T/0/1/0/all/0/1\">Teru Nagamori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ito_H/0/1/0/all/0/1\">Hiroki Ito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maung_A/0/1/0/all/0/1\">April Pyone Maung Maung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiya_H/0/1/0/all/0/1\">Hitoshi Kiya</a>",
          "description": "In this paper, we propose an access control method for object detection\nmodels. The use of encrypted images or encrypted feature maps has been\ndemonstrated to be effective in access control of models from unauthorized\naccess. However, the effectiveness of the approach has been confirmed in only\nimage classification models and semantic segmentation models, but not in object\ndetection models. In this paper, the use of encrypted feature maps is shown to\nbe effective in access control of object detection models for the first time.",
          "link": "http://arxiv.org/abs/2202.00265",
          "publishedOn": "2022-03-12T00:41:17.238Z",
          "wordCount": 576,
          "title": "Access Control of Object Detection Models Using Encrypted Feature Maps. (arXiv:2202.00265v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.11667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Samuel Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Peter Y. Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loh_C/0/1/0/all/0/1\">Charlotte Loh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1\">Jamie Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snoek_J/0/1/0/all/0/1\">Jasper Snoek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soljacic_M/0/1/0/all/0/1\">Marin Solja&#x10d;i&#x107;</a>",
          "description": "Bayesian optimization (BO) is a popular paradigm for global optimization of\nexpensive black-box functions, but there are many domains where the function is\nnot completely black-box. The data may have some known structure (e.g.\nsymmetries) and/or the data generation process can yield useful intermediate or\nauxiliary information in addition to the value of the optimization objective.\nHowever, surrogate models traditionally employed in BO, such as Gaussian\nProcesses (GPs), scale poorly with dataset size and do not easily accommodate\nknown structure or auxiliary information. Instead, we propose performing BO on\ncomplex, structured problems by using deep learning models with uncertainty, a\nclass of scalable surrogate models that have the representation power and\nflexibility to handle structured data and exploit auxiliary information. We\ndemonstrate BO on a number of realistic problems in physics and chemistry,\nincluding topology optimization of photonic crystal materials using\nconvolutional neural networks, and chemical property optimization of molecules\nusing graph neural networks. On these complex tasks, we show that neural\nnetworks often outperform GPs as surrogate models for BO in terms of both\nsampling efficiency and computational cost.",
          "link": "http://arxiv.org/abs/2104.11667",
          "publishedOn": "2022-03-12T00:41:17.225Z",
          "wordCount": 675,
          "title": "Deep Learning for Bayesian Optimization of Scientific Problems with High-Dimensional Structure. (arXiv:2104.11667v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.02195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weisz_G/0/1/0/all/0/1\">Gell&#xe9;rt Weisz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesv&#xe1;ri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andr&#xe1;s Gy&#xf6;rgy</a>",
          "description": "We consider the minimax query complexity of online planning with a generative\nmodel in fixed-horizon Markov decision processes (MDPs) with linear function\napproximation. Following recent works, we consider broad classes of problems\nwhere either (i) the optimal value function $v^\\star$ or (ii) the optimal\naction-value function $q^\\star$ lie in the linear span of some features; or\n(iii) both $v^\\star$ and $q^\\star$ lie in the linear span when restricted to\nthe states reachable from the starting state. Recently, Weisz et al. (2021b)\nshowed that under (ii) the minimax query complexity of any planning algorithm\nis at least exponential in the horizon $H$ or in the feature dimension $d$ when\nthe size $A$ of the action set can be chosen to be exponential in $\\min(d,H)$.\nOn the other hand, for the setting (i), Weisz et al. (2021a) introduced\nTensorPlan, a planner whose query cost is polynomial in all relevant quantities\nwhen the number of actions is fixed. Among other things, these two works left\nopen the question whether polynomial query complexity is possible when $A$ is\nsubexponential in $\\min(d,H)$. In this paper we answer this question in the\nnegative: we show that an exponentially large lower bound holds when\n$A=\\Omega(\\min(d^{1/4},H^{1/2}))$, under either (i), (ii) or (iii). In\nparticular, this implies a perhaps surprising exponential separation of query\ncomplexity compared to the work of Du et al. (2021) who prove a polynomial\nupper bound when (iii) holds for all states. Furthermore, we show that the\nupper bound of TensorPlan can be extended to hold under (iii) and, for MDPs\nwith deterministic transitions and stochastic rewards, also under (ii).",
          "link": "http://arxiv.org/abs/2110.02195",
          "publishedOn": "2022-03-12T00:41:17.218Z",
          "wordCount": 753,
          "title": "TensorPlan and the Few Actions Lower Bound for Planning in MDPs under Linear Realizability of Optimal Value Functions. (arXiv:2110.02195v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.06767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiaxi Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1\">Xiaojun Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guansong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lu Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_M/0/1/0/all/0/1\">Minzhe Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1\">Lewei Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Runhui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chunjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hang Xu</a>",
          "description": "Vision-Language Pre-training (VLP) models have shown remarkable performance\non various downstream tasks. Their success heavily relies on the scale of\npre-trained cross-modal datasets. However, the lack of large-scale datasets and\nbenchmarks in Chinese hinders the development of Chinese VLP models and broader\nmultilingual applications. In this work, we release a large-scale Chinese\ncross-modal dataset named Wukong, containing 100 million Chinese image-text\npairs from the web. Wukong aims to benchmark different multi-modal pre-training\nmethods to facilitate the VLP research and community development. Furthermore,\nwe release a group of models pre-trained with various image encoders\n(ViT-B/ViT-L/SwinT) and also apply advanced pre-training techniques into VLP\nsuch as locked-image text tuning, token-wise similarity in contrastive\nlearning, and reduced-token interaction. Extensive experiments and a deep\nbenchmarking of different downstream tasks are also provided. Experiments show\nthat Wukong can serve as a promising Chinese pre-training dataset and benchmark\nfor different cross-modal learning methods. For the zero-shot image\nclassification task on 10 datasets, our model achieves an average accuracy of\n73.03%. For the image-text retrieval task,our model achieves a mean recall of\n71.6% on AIC-ICC which is 12.9% higher than the result of WenLan 2.0. More\ninformation can refer to https://wukong-dataset.github.io/wukong-dataset/.",
          "link": "http://arxiv.org/abs/2202.06767",
          "publishedOn": "2022-03-12T00:41:17.171Z",
          "wordCount": 680,
          "title": "Wukong: 100 Million Large-scale Chinese Cross-modal Pre-training Dataset and A Foundation Framework. (arXiv:2202.06767v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.11022",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yao_K/0/1/0/all/0/1\">Kai Yao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1\">Kaizhu Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Jie Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jude_C/0/1/0/all/0/1\">Curran Jude</a>",
          "description": "We consider unsupervised cell nuclei segmentation in this paper. Exploiting\nthe recently-proposed unpaired image-to-image translation between cell nuclei\nimages and randomly synthetic masks, existing approaches, e.g., CycleGAN, have\nachieved encouraging results. However, these methods usually take a two-stage\npipeline and fail to learn end-to-end in cell nuclei images. More seriously,\nthey could lead to the lossy transformation problem, i.e., the content\ninconsistency between the original images and the corresponding segmentation\noutput. To address these limitations, we propose a novel end-to-end\nunsupervised framework called Aligned Disentangling Generative Adversarial\nNetwork (AD-GAN). Distinctively, AD-GAN introduces representation\ndisentanglement to separate content representation (the underling spatial\nstructure) from style representation (the rendering of the structure). With\nthis framework, spatial structure can be preserved explicitly, enabling a\nsignificant reduction of macro-level lossy transformation. We also propose a\nnovel training algorithm able to align the disentangled content in the latent\nspace to reduce micro-level lossy transformation. Evaluations on real-world 2D\nand 3D datasets show that AD-GAN substantially outperforms the other comparison\nmethods and the professional software both quantitatively and qualitatively.\nSpecifically, the proposed AD-GAN leads to significant improvement over the\ncurrent best unsupervised methods by an average 17.8% relatively (w.r.t. the\nmetric DICE) on four cell nuclei datasets. As an unsupervised method, AD-GAN\neven performs competitive with the best supervised models, taking a further\nleap towards end-to-end unsupervised nuclei segmentation.",
          "link": "http://arxiv.org/abs/2107.11022",
          "publishedOn": "2022-03-12T00:41:17.163Z",
          "wordCount": 694,
          "title": "AD-GAN: End-to-end Unsupervised Nuclei Segmentation with Aligned Disentangling Training. (arXiv:2107.11022v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.03560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xudong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jingke Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lanjun Wang</a>",
          "description": "News Recommendation System(NRS) has become a fundamental technology to many\nonline news services. Meanwhile, several studies show that recommendation\nsystems(RS) are vulnerable to data poisoning attacks, and the attackers have\nthe ability to mislead the system to perform as their desires. A widely studied\nattack approach, injecting fake users, can be applied on the NRS when the NRS\nis treated the same as the other systems whose items are fixed. However, in the\nNRS, as each item (i.e. news) is more informative, we propose a novel approach\nto poison the NRS, which is to perturb contents of some browsed news that\nresults in the manipulation of the rank of the target news. Intuitively, an\nattack is useless if it is highly likely to be caught, i.e., exposed. To\naddress this, we introduce a notion of the exposure risk and propose a novel\nproblem of attacking a history news dataset by means of perturbations where the\ngoal is to maximize the manipulation of the target news rank while keeping the\nrisk of exposure under a given budget. We design a reinforcement learning\nframework, called TDP-CP, which contains a two-stage hierarchical model to\nreduce the searching space. Meanwhile, influence estimation is also applied to\nsave the time on retraining the NRS for rewards. We test the performance of\nTDP-CP under three NRSs and on different target news. Our experiments show that\nTDP-CP can increase the rank of the target news successfully with a limited\nexposure budget.",
          "link": "http://arxiv.org/abs/2203.03560",
          "publishedOn": "2022-03-12T00:41:17.155Z",
          "wordCount": 714,
          "title": "Targeted Data Poisoning Attack on News Recommendation System by Content Perturbation. (arXiv:2203.03560v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.04064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Coupette_C/0/1/0/all/0/1\">Corinna Coupette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalleiger_S/0/1/0/all/0/1\">Sebastian Dalleiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vreeken_J/0/1/0/all/0/1\">Jilles Vreeken</a>",
          "description": "How does neural connectivity in autistic children differ from neural\nconnectivity in healthy children or autistic youths? What patterns in global\ntrade networks are shared across classes of goods, and how do these patterns\nchange over time? Answering questions like these requires us to differentially\ndescribe groups of graphs: Given a set of graphs and a partition of these\ngraphs into groups, discover what graphs in one group have in common, how they\nsystematically differ from graphs in other groups, and how multiple groups of\ngraphs are related. We refer to this task as graph group analysis, which seeks\nto describe similarities and differences between graph groups by means of\nstatistically significant subgraphs. To perform graph group analysis, we\nintroduce Gragra, which uses maximum entropy modeling to identify a\nnon-redundant set of subgraphs with statistically significant associations to\none or more graph groups. Through an extensive set of experiments on a wide\nrange of synthetic and real-world graph groups, we confirm that Gragra works\nwell in practice.",
          "link": "http://arxiv.org/abs/2201.04064",
          "publishedOn": "2022-03-12T00:41:17.148Z",
          "wordCount": 642,
          "title": "Differentially Describing Groups of Graphs. (arXiv:2201.04064v2 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05337",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Fabiani_G/0/1/0/all/0/1\">Gianluca Fabiani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Galaris_E/0/1/0/all/0/1\">Evangelos Galaris</a>, <a href=\"http://arxiv.org/find/math/1/au:+Russo_L/0/1/0/all/0/1\">Lucia Russo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Siettos_C/0/1/0/all/0/1\">Constantinos Siettos</a>",
          "description": "We address a physics-informed neural network based on the concept of random\nprojections for the numerical solution of IVPs of nonlinear ODEs in\nlinear-implicit form and index-1 DAEs, which may also arise from the spatial\ndiscretization of PDEs. The scheme has a single hidden layer with appropriately\nrandomly parametrized Gaussian kernels and a linear output layer, while the\ninternal weights are fixed to ones. The unknown weights between the hidden and\noutput layer are computed by Newton's iterations, using the Moore-Penrose\npseudoinverse for low to medium, and sparse QR decomposition with\nregularization for medium to large scale systems. To deal with stiffness and\nsharp gradients, we propose a variable step size scheme for adjusting the\ninterval of integration and address a continuation method for providing good\ninitial guesses for the Newton iterations. Based on previous works on random\nprojections, we prove the approximation capability of the scheme for ODEs in\nthe canonical form and index-1 DAEs in the semiexplicit form. The optimal\nbounds of the uniform distribution are parsimoniously chosen based on the\nbias-variance trade-off. The performance of the scheme is assessed through\nseven benchmark problems: four index-1 DAEs, the Robertson model, a model of\nfive DAEs describing the motion of a bead, a model of six DAEs describing a\npower discharge control problem, the chemical Akzo Nobel problem and three\nstiff problems, the Belousov-Zhabotinsky, the Allen-Cahn PDE and the\nKuramoto-Sivashinsky PDE. The efficiency of the scheme is compared with three\nsolvers ode23t, ode23s, ode15s of the MATLAB ODE suite. Our results show that\nthe proposed scheme outperforms the stiff solvers in several cases, especially\nin regimes where high stiffness or sharp gradients arise in terms of numerical\naccuracy, while the computational costs are for any practical purposes\ncomparable.",
          "link": "http://arxiv.org/abs/2203.05337",
          "publishedOn": "2022-03-12T00:41:17.139Z",
          "wordCount": 750,
          "title": "Parsimonious Random Projection Neural Networks for the Numerical Solution of Initial-Value Problems of ODEs and index-1 DAEs. (arXiv:2203.05337v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.01996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Minami_Y/0/1/0/all/0/1\">Yota Minami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaneiwa_K/0/1/0/all/0/1\">Ken Kaneiwa</a>",
          "description": "The Resource Description Framework (RDF) is a framework for describing\nmetadata, such as attributes and relationships of resources on the Web. Machine\nlearning tasks for RDF graphs adopt three methods: (i) support vector machines\n(SVMs) with RDF graph kernels, (ii) RDF graph embeddings, and (iii) relational\ngraph convolutional networks. In this paper, we propose a novel feature vector\n(called a Skip vector) that represents some features of each resource in an RDF\ngraph by extracting various combinations of neighboring edges and nodes. In\norder to make the Skip vector low-dimensional, we select important features for\nclassification tasks based on the information gain ratio of each feature. The\nclassification tasks can be performed by applying the low-dimensional Skip\nvector of each resource to conventional machine learning algorithms, such as\nSVMs, the k-nearest neighbors method, neural networks, random forests, and\nAdaBoost. In our evaluation experiments with RDF data, such as Wikidata,\nDBpedia, and YAGO, we compare our method with RDF graph kernels in an SVM. We\nalso compare our method with the two approaches: RDF graph embeddings such as\nRDF2vec and relational graph convolutional networks on the AIFB, MUTAG, BGS,\nand AM benchmarks.",
          "link": "http://arxiv.org/abs/2201.01996",
          "publishedOn": "2022-03-12T00:41:17.114Z",
          "wordCount": 664,
          "title": "Skip Vectors for RDF Data: Extraction Based on the Complexity of Feature Patterns. (arXiv:2201.01996v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.03954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chmielinski_K/0/1/0/all/0/1\">Kasia S. Chmielinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newman_S/0/1/0/all/0/1\">Sarah Newman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1\">Matt Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joseph_J/0/1/0/all/0/1\">Josh Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_K/0/1/0/all/0/1\">Kemi Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yurkofsky_J/0/1/0/all/0/1\">Jessica Yurkofsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yue Chelsea Qiu</a>",
          "description": "As the production of and reliance on datasets to produce automated\ndecision-making systems (ADS) increases, so does the need for processes for\nevaluating and interrogating the underlying data. After launching the Dataset\nNutrition Label in 2018, the Data Nutrition Project has made significant\nupdates to the design and purpose of the Label, and is launching an updated\nLabel in late 2020, which is previewed in this paper. The new Label includes\ncontext-specific Use Cases &Alerts presented through an updated design and user\ninterface targeted towards the data scientist profile. This paper discusses the\nharm and bias from underlying training data that the Label is intended to\nmitigate, the current state of the work including new datasets being labeled,\nnew and existing challenges, and further directions of the work, as well as\nFigures previewing the new label.",
          "link": "http://arxiv.org/abs/2201.03954",
          "publishedOn": "2022-03-12T00:41:17.107Z",
          "wordCount": 618,
          "title": "The Dataset Nutrition Label (2nd Gen): Leveraging Context to Mitigate Harms in Artificial Intelligence. (arXiv:2201.03954v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.13464",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaohu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>",
          "description": "Federated learning (FL) is rapidly gaining popularity and enables multiple\ndata owners ({\\em a.k.a.} FL participants) to collaboratively train machine\nlearning models in a privacy-preserving way. A key unaddressed scenario is that\nthese FL participants are in a competitive market, where market shares\nrepresent their competitiveness. Although they are interested to enhance the\nperformance of their respective models through FL, market leaders (who are\noften data owners who can contribute significantly to building high performance\nFL models) want to avoid losing their market shares by enhancing their\ncompetitors' models. Currently, there is no modeling tool to analyze such\nscenarios and support informed decision-making. In this paper, we bridge this\ngap by proposing the \\underline{mar}ket \\underline{s}hare-based decision\nsupport framework for participation in \\underline{FL} (MarS-FL). We introduce\n{\\em two notions of $\\delta$-stable market} and {\\em friendliness} to measure\nthe viability of FL and the market acceptability of FL. The FL participants'\nbehaviours can then be predicted using game theoretic tools (i.e., their\noptimal strategies concerning participation in FL). If the market\n$\\delta$-stability is achievable, the final model performance improvement of\neach FL-PT shall be bounded, which relates to the market conditions of FL\napplications. We provide tight bounds and quantify the friendliness, $\\kappa$,\nof given market conditions to FL. Experimental results show the viability of FL\nin a wide range of market conditions. Our results are useful for identifying\nthe market conditions under which collaborative FL model training is viable\namong competitors, and the requirements that have to be imposed while applying\nFL under these conditions.",
          "link": "http://arxiv.org/abs/2110.13464",
          "publishedOn": "2022-03-12T00:41:17.100Z",
          "wordCount": 717,
          "title": "MarS-FL: Enabling Competitors to Collaborate in Federated Learning. (arXiv:2110.13464v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kiani_B/0/1/0/all/0/1\">Bobak Kiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lecun_Y/0/1/0/all/0/1\">Yann Lecun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lloyd_S/0/1/0/all/0/1\">Seth Lloyd</a>",
          "description": "In learning with recurrent or very deep feed-forward networks, employing\nunitary matrices in each layer can be very effective at maintaining long-range\nstability. However, restricting network parameters to be unitary typically\ncomes at the cost of expensive parameterizations or increased training runtime.\nWe propose instead an efficient method based on rank-$k$ updates -- or their\nrank-$k$ approximation -- that maintains performance at a nearly optimal\ntraining runtime. We introduce two variants of this method, named Direct\n(projUNN-D) and Tangent (projUNN-T) projected Unitary Neural Networks, that can\nparameterize full $N$-dimensional unitary or orthogonal matrices with a\ntraining runtime scaling as $O(kN^2)$. Our method either projects low-rank\ngradients onto the closest unitary matrix (projUNN-T) or transports unitary\nmatrices in the direction of the low-rank gradient (projUNN-D). Even in the\nfastest setting ($k=1$), projUNN is able to train a model's unitary parameters\nto reach comparable performances against baseline implementations. By\nintegrating our projUNN algorithm into both recurrent and convolutional neural\nnetworks, our models can closely match or exceed benchmarked results from\nstate-of-the-art algorithms.",
          "link": "http://arxiv.org/abs/2203.05483",
          "publishedOn": "2022-03-12T00:41:17.092Z",
          "wordCount": 617,
          "title": "projUNN: efficient method for training deep networks with unitary matrices. (arXiv:2203.05483v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.11723",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Doshi_A/0/1/0/all/0/1\">Akash Doshi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Andrews_J/0/1/0/all/0/1\">Jeffrey G. Andrews</a>",
          "description": "Spectrum scarcity has led to growth in the use of unlicensed spectrum for\ncellular systems. This motivates intelligent adaptive approaches to spectrum\naccess for both WiFi and 5G that improve upon traditional carrier sensing and\nlisten-before-talk methods. We study decentralized contention-based medium\naccess for base stations (BSs) of a single Radio Access Technology (RAT)\noperating on unlicensed shared spectrum. We devise a learning-based algorithm\nfor both contention and adaptive modulation that attempts to maximize a\nnetwork-wide downlink throughput objective. We formulate and develop novel\ndistributed implementations of two deep reinforcement learning approaches -\nDeep Q Networks and Proximal Policy Optimization - modelled on a two stage\nMarkov decision process. Empirically, we find the (proportional fairness)\nreward accumulated by the policy gradient approach to be significantly higher\nthan even a genie-aided adaptive energy detection threshold. Our approaches are\nfurther validated by improved sum and peak throughput. The scalability of our\napproach to large networks is demonstrated via an improved cumulative reward\nearned on both indoor and outdoor layouts with a large number of BSs.",
          "link": "http://arxiv.org/abs/2109.11723",
          "publishedOn": "2022-03-12T00:41:17.071Z",
          "wordCount": 661,
          "title": "Distributed Deep Reinforcement Learning for Adaptive Medium Access and Modulation in Shared Spectrum. (arXiv:2109.11723v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02096",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Berrevoets_J/0/1/0/all/0/1\">Jeroen Berrevoets</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Imrie_F/0/1/0/all/0/1\">Fergus Imrie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kyono_T/0/1/0/all/0/1\">Trent Kyono</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jordon_J/0/1/0/all/0/1\">James Jordon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Missing data is a systemic problem in practical scenarios that causes noise\nand bias when estimating treatment effects. This makes treatment effect\nestimation from data with missingness a particularly tricky endeavour. A key\nreason for this is that standard assumptions on missingness are rendered\ninsufficient due to the presence of an additional variable, treatment, besides\nthe individual and the outcome. Having a treatment variable introduces\nadditional complexity with respect to why some variables are missing that is\nnot fully explored by previous work. In our work we identify a new missingness\nmechanism, which we term mixed confounded missingness (MCM), where some\nmissingness determines treatment selection and other missingness is determined\nby treatment selection. Given MCM, we show that naively imputing all data leads\nto poor performing treatment effects models, as the act of imputation\neffectively removes information necessary to provide unbiased estimates.\nHowever, no imputation at all also leads to biased estimates, as missingness\ndetermined by treatment divides the population in distinct subpopulations,\nwhere estimates across these populations will be biased. Our solution is\nselective imputation, where we use insights from MCM to inform precisely which\nvariables should be imputed and which should not. We empirically demonstrate\nhow various learners benefit from selective imputation compared to other\nsolutions for missing data.",
          "link": "http://arxiv.org/abs/2202.02096",
          "publishedOn": "2022-03-12T00:41:17.002Z",
          "wordCount": 677,
          "title": "To Impute or not to Impute? Missing Data in Treatment Effect Estimation. (arXiv:2202.02096v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09988",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+K_D/0/1/0/all/0/1\">Devika K</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Oruganti_V/0/1/0/all/0/1\">Venkata Ramana Murthy Oruganti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mahapatra_D/0/1/0/all/0/1\">Dwarikanath Mahapatra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Subramanian_R/0/1/0/all/0/1\">Ramanathan Subramanian</a>",
          "description": "Diagnosis of Autism Spectrum Disorder (ASD) using clinical evaluation\n(cognitive tests) is challenging due to wide variations amongst individuals.\nSince no effective treatment exists, prompt and reliable ASD diagnosis can\nenable the effective preparation of treatment regimens. This paper proposes\nstructural Magnetic Resonance Imaging (sMRI)-based ASD diagnosis via an outlier\ndetection approach. To learn Spatio-temporal patterns in structural brain\nconnectivity, a Generative Adversarial Network (GAN) is trained exclusively\nwith sMRI scans of healthy subjects. Given a stack of three adjacent slices as\ninput, the GAN generator reconstructs the next three adjacent slices; the GAN\ndiscriminator then identifies ASD sMRI scan reconstructions as outliers. This\nmodel is compared against two other baselines -- a simpler UNet and a\nsophisticated Self-Attention GAN. Axial, Coronal, and Sagittal sMRI slices from\nthe multi-site ABIDE II dataset are used for evaluation. Extensive experiments\nreveal that our ASD detection framework performs comparably with the\nstate-of-the-art with far fewer training data. Furthermore, longitudinal data\n(two scans per subject over time) achieve 17-28% higher accuracy than\ncross-sectional data (one scan per subject). Among other findings, metrics\nemployed for model training as well as reconstruction loss computation impact\ndetection performance, and the coronal modality is found to best encode\nstructural information for ASD detection.",
          "link": "http://arxiv.org/abs/2202.09988",
          "publishedOn": "2022-03-12T00:41:16.995Z",
          "wordCount": 687,
          "title": "Outlier-based Autism Detection using Longitudinal Structural MRI. (arXiv:2202.09988v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.15141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinsheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yongxin Chen</a>",
          "description": "We present Path Integral Sampler~(PIS), a novel algorithm to draw samples\nfrom unnormalized probability density functions. The PIS is built on the\nSchr\\\"odinger bridge problem which aims to recover the most likely evolution of\na diffusion process given its initial distribution and terminal distribution.\nThe PIS draws samples from the initial distribution and then propagates the\nsamples through the Schr\\\"odinger bridge to reach the terminal distribution.\nApplying the Girsanov theorem, with a simple prior diffusion, we formulate the\nPIS as a stochastic optimal control problem whose running cost is the control\nenergy and terminal cost is chosen according to the target distribution. By\nmodeling the control as a neural network, we establish a sampling algorithm\nthat can be trained end-to-end. We provide theoretical justification of the\nsampling quality of PIS in terms of Wasserstein distance when sub-optimal\ncontrol is used. Moreover, the path integrals theory is used to compute\nimportance weights of the samples to compensate for the bias induced by the\nsub-optimality of the controller and time-discretization. We experimentally\ndemonstrate the advantages of PIS compared with other start-of-the-art sampling\nmethods on a variety of tasks.",
          "link": "http://arxiv.org/abs/2111.15141",
          "publishedOn": "2022-03-12T00:41:16.976Z",
          "wordCount": 646,
          "title": "Path Integral Sampler: a stochastic control approach for sampling. (arXiv:2111.15141v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eddin_A/0/1/0/all/0/1\">Ahmad Naser Eddin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bono_J/0/1/0/all/0/1\">Jacopo Bono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aparicio_D/0/1/0/all/0/1\">David Apar&#xed;cio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polido_D/0/1/0/all/0/1\">David Polido</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ascensao_J/0/1/0/all/0/1\">Jo&#xe3;o Tiago Ascens&#xe3;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bizarro_P/0/1/0/all/0/1\">Pedro Bizarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_P/0/1/0/all/0/1\">Pedro Ribeiro</a>",
          "description": "Money laundering is a global problem that concerns legitimizing proceeds from\nserious felonies (1.7-4 trillion euros annually) such as drug dealing, human\ntrafficking, or corruption. The anti-money laundering systems deployed by\nfinancial institutions typically comprise rules aligned with regulatory\nframeworks. Human investigators review the alerts and report suspicious cases.\nSuch systems suffer from high false-positive rates, undermining their\neffectiveness and resulting in high operational costs. We propose a machine\nlearning triage model, which complements the rule-based system and learns to\npredict the risk of an alert accurately. Our model uses both entity-centric\nengineered features and attributes characterizing inter-entity relations in the\nform of graph-based features. We leverage time windows to construct the dynamic\ngraph, optimizing for time and space efficiency. We validate our model on a\nreal-world banking dataset and show how the triage model can reduce the number\nof false positives by 80% while detecting over 90% of true positives. In this\nway, our model can significantly improve anti-money laundering operations.",
          "link": "http://arxiv.org/abs/2112.07508",
          "publishedOn": "2022-03-12T00:41:16.968Z",
          "wordCount": 642,
          "title": "Anti-Money Laundering Alert Optimization Using Machine Learning with Graphs. (arXiv:2112.07508v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.05763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manduchi_L/0/1/0/all/0/1\">Laura Manduchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcinkevics_R/0/1/0/all/0/1\">Ri&#x10d;ards Marcinkevi&#x10d;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massi_M/0/1/0/all/0/1\">Michela C. Massi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weikert_T/0/1/0/all/0/1\">Thomas Weikert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sauter_A/0/1/0/all/0/1\">Alexander Sauter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotta_V/0/1/0/all/0/1\">Verena Gotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1\">Timothy M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasella_F/0/1/0/all/0/1\">Flavio Vasella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neidert_M/0/1/0/all/0/1\">Marian C. Neidert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_M/0/1/0/all/0/1\">Marc Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stieltjes_B/0/1/0/all/0/1\">Bram Stieltjes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "In this work, we study the problem of clustering survival data $-$ a\nchallenging and so far under-explored task. We introduce a novel\nsemi-supervised probabilistic approach to cluster survival data by leveraging\nrecent advances in stochastic gradient variational inference. In contrast to\nprevious work, our proposed method employs a deep generative model to uncover\nthe underlying distribution of both the explanatory variables and censored\nsurvival times. We compare our model to the related work on clustering and\nmixture models for survival data in comprehensive experiments on a wide range\nof synthetic, semi-synthetic, and real-world datasets, including medical\nimaging data. Our method performs better at identifying clusters and is\ncompetitive at predicting survival times. Relying on novel generative\nassumptions, the proposed model offers a holistic perspective on clustering\nsurvival data and holds a promise of discovering subpopulations whose survival\nis regulated by different generative mechanisms.",
          "link": "http://arxiv.org/abs/2106.05763",
          "publishedOn": "2022-03-12T00:41:16.825Z",
          "wordCount": 640,
          "title": "A Deep Variational Approach to Clustering Survival Data. (arXiv:2106.05763v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuejiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cadei_R/0/1/0/all/0/1\">Riccardo Cadei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schweizer_J/0/1/0/all/0/1\">Jonas Schweizer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahmani_S/0/1/0/all/0/1\">Sherwin Bahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alahi_A/0/1/0/all/0/1\">Alexandre Alahi</a>",
          "description": "Learning behavioral patterns from observational data has been a de-facto\napproach to motion forecasting. Yet, the current paradigm suffers from two\nshortcomings: brittle under distribution shifts and inefficient for knowledge\ntransfer. In this work, we propose to address these challenges from a causal\nrepresentation perspective. We first introduce a causal formalism of motion\nforecasting, which casts the problem as a dynamic process with three groups of\nlatent variables, namely invariant variables, style confounders, and spurious\nfeatures. We then introduce a learning framework that treats each group\nseparately: (i) unlike the common practice mixing datasets collected from\ndifferent locations, we exploit their subtle distinctions by means of an\ninvariance loss encouraging the model to suppress spurious correlations; (ii)\nwe devise a modular architecture that factorizes the representations of\ninvariant mechanisms and style confounders to approximate a sparse causal\ngraph; (iii) we introduce a style contrastive loss that not only enforces the\nstructure of style representations but also serves as a self-supervisory signal\nfor test-time refinement on the fly. Experiments on synthetic and real datasets\nshow that our proposed method improves the robustness and reusability of\nlearned motion representations, significantly outperforming prior\nstate-of-the-art motion forecasting models for out-of-distribution\ngeneralization and low-shot transfer.",
          "link": "http://arxiv.org/abs/2111.14820",
          "publishedOn": "2022-03-12T00:41:16.817Z",
          "wordCount": 690,
          "title": "Towards Robust and Adaptive Motion Forecasting: A Causal Representation Perspective. (arXiv:2111.14820v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whitehouse_J/0/1/0/all/0/1\">Justin Whitehouse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_R/0/1/0/all/0/1\">Ryan Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>",
          "description": "Composition is a key feature of differential privacy. Well-known advanced\ncomposition theorems allow one to query a private database quadratically more\ntimes than basic privacy composition would permit. However, these results\nrequire that the privacy parameters of all algorithms be fixed before\ninteracting with the data. To address this, Rogers et al. introduced fully\nadaptive composition, wherein both algorithms and their privacy parameters can\nbe selected adaptively. The authors introduce two probabilistic objects to\nmeasure privacy in adaptive composition: privacy filters, which provide\ndifferential privacy guarantees for composed interactions, and privacy\nodometers, time-uniform bounds on privacy loss. There are substantial gaps\nbetween advanced composition and existing filters and odometers. First,\nexisting filters place stronger assumptions on the algorithms being composed.\nSecond, these odometers and filters suffer from large constants, making them\nimpractical. We construct filters that match the tightness of advanced\ncomposition, including constants, despite allowing for adaptively chosen\nprivacy parameters. We also construct several general families of odometers.\nThese odometers can match the tightness of advanced composition at an\narbitrary, preselected point in time, or at all points in time simultaneously,\nup to a doubly-logarithmic factor. We obtain our results by leveraging recent\nadvances in time-uniform martingale concentration. In sum, we show that fully\nadaptive privacy is obtainable at almost no loss, and conjecture that our\nresults are essentially unimprovable (even in constants) in general.",
          "link": "http://arxiv.org/abs/2203.05481",
          "publishedOn": "2022-03-12T00:41:16.810Z",
          "wordCount": 677,
          "title": "Fully Adaptive Composition in Differential Privacy. (arXiv:2203.05481v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.08199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hwanjun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minseok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">Dongmin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yooju Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-Gil Lee</a>",
          "description": "Deep learning has achieved remarkable success in numerous domains with help\nfrom large amounts of big data. However, the quality of data labels is a\nconcern because of the lack of high-quality labels in many real-world\nscenarios. As noisy labels severely degrade the generalization performance of\ndeep neural networks, learning from noisy labels (robust training) is becoming\nan important task in modern deep learning applications. In this survey, we\nfirst describe the problem of learning with label noise from a supervised\nlearning perspective. Next, we provide a comprehensive review of 62\nstate-of-the-art robust training methods, all of which are categorized into\nfive groups according to their methodological difference, followed by a\nsystematic comparison of six properties used to evaluate their superiority.\nSubsequently, we perform an in-depth analysis of noise rate estimation and\nsummarize the typically used evaluation methodology, including public noisy\ndatasets and evaluation metrics. Finally, we present several promising research\ndirections that can serve as a guideline for future studies. All the contents\nwill be available at https://github.com/songhwanjun/Awesome-Noisy-Labels.",
          "link": "http://arxiv.org/abs/2007.08199",
          "publishedOn": "2022-03-12T00:41:16.803Z",
          "wordCount": 703,
          "title": "Learning from Noisy Labels with Deep Neural Networks: A Survey. (arXiv:2007.08199v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.00942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hakhamaneshi_K/0/1/0/all/0/1\">Kourosh Hakhamaneshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stojanovic_V/0/1/0/all/0/1\">Vladimir Stojanovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1\">Aditya Grover</a>",
          "description": "The goal of Multi-task Bayesian Optimization (MBO) is to minimize the number\nof queries required to accurately optimize a target black-box function, given\naccess to offline evaluations of other auxiliary functions. When offline\ndatasets are large, the scalability of prior approaches comes at the expense of\nexpressivity and inference quality. We propose JUMBO, an MBO algorithm that\nsidesteps these limitations by querying additional data based on a combination\nof acquisition signals derived from training two Gaussian Processes (GP): a\ncold-GP operating directly in the input domain and a warm-GP that operates in\nthe feature space of a deep neural network pretrained using the offline data.\nSuch a decomposition can dynamically control the reliability of information\nderived from the online and offline data and the use of pretrained neural\nnetworks permits scalability to large offline datasets. Theoretically, we\nderive regret bounds for JUMBO and show that it achieves no-regret under\nconditions analogous to GP-UCB (Srinivas et. al. 2010). Empirically, we\ndemonstrate significant performance improvements over existing approaches on\ntwo real-world optimization problems: hyper-parameter optimization and\nautomated circuit design.",
          "link": "http://arxiv.org/abs/2106.00942",
          "publishedOn": "2022-03-12T00:41:16.779Z",
          "wordCount": 642,
          "title": "JUMBO: Scalable Multi-task Bayesian Optimization using Offline Data. (arXiv:2106.00942v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1\">Shashi Raj Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Lam D. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popovski_P/0/1/0/all/0/1\">Petar Popovski</a>",
          "description": "In a Federated Learning (FL) setup, a number of devices contribute to the\ntraining of a common model. We present a method for selecting the devices that\nprovide updates in order to achieve improved generalization, fast convergence,\nand better device-level performance. We formulate a min-max optimization\nproblem and decompose it into a primal-dual setup, where the duality gap is\nused to quantify the device-level performance. Our strategy combines\n\\emph{exploration} of data freshness through a random device selection with\n\\emph{exploitation} through simplified estimates of device contributions. This\nimproves the performance of the trained model both in terms of generalization\nand personalization. A modified Truncated Monte-Carlo (TMC) method is applied\nduring the exploitation phase to estimate the device's contribution and lower\nthe communication overhead. The experimental results show that the proposed\napproach has a competitive performance, with lower communication overhead and\ncompetitive personalization performance against the baseline schemes.",
          "link": "http://arxiv.org/abs/2203.05369",
          "publishedOn": "2022-03-12T00:41:16.772Z",
          "wordCount": 604,
          "title": "A Contribution-based Device Selection Scheme in Federated Learning. (arXiv:2203.05369v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.11410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_A/0/1/0/all/0/1\">Ayush Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">Krishnateja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danilevsky_M/0/1/0/all/0/1\">Marina Danilevsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popa_L/0/1/0/all/0/1\">Lucian Popa</a>",
          "description": "A critical bottleneck in supervised machine learning is the need for large\namounts of labeled data which is expensive and time consuming to obtain.\nHowever, it has been shown that a small amount of labeled data, while\ninsufficient to re-train a model, can be effectively used to generate\nhuman-interpretable labeling functions (LFs). These LFs, in turn, have been\nused to generate a large amount of additional noisy labeled data, in a paradigm\nthat is now commonly referred to as data programming. However, previous\napproaches to automatically generate LFs make no attempt to further use the\ngiven labeled data for model training, thus giving up opportunities for\nimproved performance. Moreover, since the LFs are generated from a relatively\nsmall labeled dataset, they are prone to being noisy, and naively aggregating\nthese LFs can lead to very poor performance in practice. In this work, we\npropose an LF based reweighting framework \\ouralgo{} to solve these two\ncritical limitations. Our algorithm learns a joint model on the (same) labeled\ndataset used for LF induction along with any unlabeled data in a\nsemi-supervised manner, and more critically, reweighs each LF according to its\ngoodness, influencing its contribution to the semi-supervised loss using a\nrobust bi-level optimization algorithm. We show that our algorithm\nsignificantly outperforms prior approaches on several text classification\ndatasets.",
          "link": "http://arxiv.org/abs/2109.11410",
          "publishedOn": "2022-03-12T00:41:16.766Z",
          "wordCount": 693,
          "title": "Learning to Robustly Aggregate Labeling Functions for Semi-supervised Data Programming. (arXiv:2109.11410v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.00429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cohn_T/0/1/0/all/0/1\">Thomas Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devraj_N/0/1/0/all/0/1\">Nikhil Devraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jenkins_O/0/1/0/all/0/1\">Odest Chadwicke Jenkins</a>",
          "description": "We present a new technique that enables manifold learning to accurately embed\ndata manifolds that contain holes, without discarding any topological\ninformation. Manifold learning aims to embed high dimensional data into a lower\ndimensional Euclidean space by learning a coordinate chart, but it requires\nthat the entire manifold can be embedded in a single chart. This is impossible\nfor manifolds with holes. In such cases, it is necessary to learn an atlas: a\ncollection of charts that collectively cover the entire manifold. We begin with\nmany small charts, and combine them in a bottom-up approach, where charts are\nonly combined if doing so will not introduce problematic topological features.\nWhen it is no longer possible to combine any charts, each chart is individually\nembedded with standard manifold learning techniques, completing the\nconstruction of the atlas. We show the efficacy of our method by constructing\natlases for challenging synthetic manifolds; learning human motion embeddings\nfrom motion capture data; and learning kinematic models of articulated objects.",
          "link": "http://arxiv.org/abs/2110.00429",
          "publishedOn": "2022-03-12T00:41:16.758Z",
          "wordCount": 636,
          "title": "Topologically-Informed Atlas Learning. (arXiv:2110.00429v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.06340",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Bocchi_G/0/1/0/all/0/1\">Giovanni Bocchi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Botteghi_S/0/1/0/all/0/1\">Stefano Botteghi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Brasini_M/0/1/0/all/0/1\">Martina Brasini</a>, <a href=\"http://arxiv.org/find/math/1/au:+Frosini_P/0/1/0/all/0/1\">Patrizio Frosini</a>, <a href=\"http://arxiv.org/find/math/1/au:+Quercioli_N/0/1/0/all/0/1\">Nicola Quercioli</a>",
          "description": "The study of $G$-equivariant operators is of great interest to explain and\nunderstand the architecture of neural networks. In this paper we show that each\nlinear $G$-equivariant operator can be produced by a suitable permutant\nmeasure, provided that the group $G$ transitively acts on a finite signal\ndomain $X$. This result makes available a new method to build linear\n$G$-equivariant operators in the finite setting.",
          "link": "http://arxiv.org/abs/2008.06340",
          "publishedOn": "2022-03-12T00:41:16.727Z",
          "wordCount": 601,
          "title": "On the finite representation of group equivariant operators via permutant measures. (arXiv:2008.06340v2 [math.GR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11191",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Morani_K/0/1/0/all/0/1\">Kenan Morani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Unay_D/0/1/0/all/0/1\">Devrim Unay</a>",
          "description": "The paper presents a Convolutional Neural Networks (CNN) model for image\nclassification, aiming at increasing predictive performance for COVID-19\ndiagnosis while avoiding deeper and thus more complex alternatives. The\nproposed model includes four similar convolutional layers followed by a\nflattening and two dense layers. This work proposes a less complex solution\nbased on simply classifying 2D CT-Scan slices of images using their pixels via\na 2D CNN model. Despite the simplicity in architecture, the proposed model\nshowed improved quantitative results exceeding state-of-the-art on the same\ndataset of images, in terms of the macro f1 score. In this case study,\nextracting features from images, segmenting parts of the images, or other more\ncomplex techniques, ultimately aiming at images classification, do not yield\nbetter results. With that, this paper introduces a simple yet powerful deep\nlearning based solution for automated COVID-19 classification.",
          "link": "http://arxiv.org/abs/2111.11191",
          "publishedOn": "2022-03-12T00:41:16.719Z",
          "wordCount": 653,
          "title": "Deep Learning Based Automated COVID-19 Classification from Computed Tomography Images. (arXiv:2111.11191v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Evans_B/0/1/0/all/0/1\">Ben Evans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thankaraj_A/0/1/0/all/0/1\">Abitha Thankaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinto_L/0/1/0/all/0/1\">Lerrel Pinto</a>",
          "description": "Understanding environment dynamics is necessary for robots to act safely and\noptimally in the world. In realistic scenarios, dynamics are non-stationary and\nthe causal variables such as environment parameters cannot necessarily be\nprecisely measured or inferred, even during training. We propose Implicit\nIdentification for Dynamics Adaptation (IIDA), a simple method to allow\npredictive models to adapt to changing environment dynamics. IIDA assumes no\naccess to the true variations in the world and instead implicitly infers\nproperties of the environment from a small amount of contextual data. We\ndemonstrate IIDA's ability to perform well in unseen environments through a\nsuite of simulated experiments on MuJoCo environments and a real robot dynamic\nsliding task. In general, IIDA significantly reduces model error and results in\nhigher task performance over commonly used methods. Our code and robot videos\nare at https://bennevans.github.io/iida/",
          "link": "http://arxiv.org/abs/2203.05549",
          "publishedOn": "2022-03-12T00:41:16.712Z",
          "wordCount": 581,
          "title": "Context is Everything: Implicit Identification for Dynamics Adaptation. (arXiv:2203.05549v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.08981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hakhamaneshi_K/0/1/0/all/0/1\">Kourosh Hakhamaneshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Ruihan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_A/0/1/0/all/0/1\">Albert Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskin_M/0/1/0/all/0/1\">Michael Laskin</a>",
          "description": "A desirable property of autonomous agents is the ability to both solve\nlong-horizon problems and generalize to unseen tasks. Recent advances in\ndata-driven skill learning have shown that extracting behavioral priors from\noffline data can enable agents to solve challenging long-horizon tasks with\nreinforcement learning. However, generalization to tasks unseen during\nbehavioral prior training remains an outstanding challenge. To this end, we\npresent Few-shot Imitation with Skill Transition Models (FIST), an algorithm\nthat extracts skills from offline data and utilizes them to generalize to\nunseen tasks given a few downstream demonstrations. FIST learns an inverse\nskill dynamics model, a distance function, and utilizes a semi-parametric\napproach for imitation. We show that FIST is capable of generalizing to new\ntasks and substantially outperforms prior baselines in navigation experiments\nrequiring traversing unseen parts of a large maze and 7-DoF robotic arm\nexperiments requiring manipulating previously unseen objects in a kitchen.",
          "link": "http://arxiv.org/abs/2107.08981",
          "publishedOn": "2022-03-12T00:41:16.705Z",
          "wordCount": 614,
          "title": "Hierarchical Few-Shot Imitation with Skill Transition Models. (arXiv:2107.08981v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kaiyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jingkang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>",
          "description": "With the rise of powerful pre-trained vision-language models like CLIP, it\nbecomes essential to investigate ways to adapt these models to downstream\ndatasets. A recently proposed method named Context Optimization (CoOp)\nintroduces the concept of prompt learning -- a recent trend in NLP -- to the\nvision domain for adapting pre-trained vision-language models. Specifically,\nCoOp turns context words in a prompt into a set of learnable vectors and, with\nonly a few labeled images for learning, can achieve huge improvements over\nintensively-tuned manual prompts. In our study we identify a critical problem\nof CoOp: the learned context is not generalizable to wider unseen classes\nwithin the same dataset, suggesting that CoOp overfits base classes observed\nduring training. To address the problem, we propose Conditional Context\nOptimization (CoCoOp), which extends CoOp by further learning a lightweight\nneural network to generate for each image an input-conditional token (vector).\nCompared to CoOp's static prompts, our dynamic prompts adapt to each instance\nand are thus less sensitive to class shift. Extensive experiments show that\nCoCoOp generalizes much better than CoOp to unseen classes, even showing\npromising transferability beyond a single dataset; and yields stronger domain\ngeneralization performance as well. Code is available at\nhttps://github.com/KaiyangZhou/CoOp.",
          "link": "http://arxiv.org/abs/2203.05557",
          "publishedOn": "2022-03-12T00:41:16.697Z",
          "wordCount": 670,
          "title": "Conditional Prompt Learning for Vision-Language Models. (arXiv:2203.05557v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.10869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Strawn_N/0/1/0/all/0/1\">Nate Strawn</a>",
          "description": "The efficiency of modern computer graphics allows us to explore collections\nof space curves simultaneously with \"drag-to-rotate\" interfaces. This inspires\nus to replace \"scatterplots of points\" with \"scatterplots of curves\" to\nsimultaneously visualize relationships across an entire dataset. Since spaces\nof curves are infinite dimensional, scatterplots of curves avoid the \"lossy\"\nnature of scatterplots of points. In particular, if two points are close in a\nscatterplot of points derived from high-dimensional data, it does not generally\nfollow that the two associated data points are close in the data space.\nStandard Andrews plots provide scatterplots of curves that perfectly preserve\nEuclidean distances, but simultaneous visualization of these graphs over an\nentire dataset produces visual clutter because graphs of functions generally\noverlap in 2D. We mitigate this visual clutter issue by constructing\ncomputationally inexpensive 3D extensions of Andrews plots. First, we construct\noptimally smooth 3D Andrews plots by considering linear isometries from\nEuclidean data spaces to spaces of planar parametric curves. We rigorously\nparametrize the linear isometries that produce (on average) optimally smooth\ncurves over a given dataset. This parameterization of optimal isometries\nreveals many degrees of freedom, and (using recent results on generalized Gauss\nsums) we identify a particular member of this set which admits an asymptotic\n\"tour\" property that avoids certain local degeneracies as well. Finally, we\nconstruct unit-length 3D curves (filaments) by numerically solving\nFrenet-Serret systems given data from these 3D Andrews plots. We conclude with\nexamples of filament plots for several standard datasets, illustrating how\nfilament plots avoid visual clutter. Code and examples available at\nhttps://github.com/n8epi/filaments/ and https://n8epi.github.io/filaments/",
          "link": "http://arxiv.org/abs/2107.10869",
          "publishedOn": "2022-03-12T00:41:16.674Z",
          "wordCount": 748,
          "title": "Filament Plots for Data Visualization. (arXiv:2107.10869v3 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lopes_V/0/1/0/all/0/1\">Vasco Lopes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexandre_L/0/1/0/all/0/1\">Lu&#xed;s A. Alexandre</a>",
          "description": "Networks found with Neural Architecture Search (NAS) achieve state-of-the-art\nperformance in a variety of tasks, out-performing human-designed networks.\nHowever, most NAS methods heavily rely on human-defined assumptions that\nconstrain the search: architecture's outer-skeletons, number of layers,\nparameter heuristics and search spaces. Additionally, common search spaces\nconsist of repeatable modules (cells) instead of fully exploring the\narchitecture's search space by designing entire architectures (macro-search).\nImposing such constraints requires deep human expertise and restricts the\nsearch to pre-defined settings. In this paper, we propose LCMNAS, a method that\npushes NAS to less constrained search spaces by performing macro-search without\nrelying on pre-defined heuristics or bounded search spaces. LCMNAS introduces\nthree components for the NAS pipeline: i) a method that leverages information\nabout well-known architectures to autonomously generate complex search spaces\nbased on Weighted Directed Graphs with hidden properties, ii) a evolutionary\nsearch strategy that generates complete architectures from scratch, and iii) a\nmixed-performance estimation approach that combines information about\narchitectures at initialization stage and lower fidelity estimates to infer\ntheir trainability and capacity to model complex functions. We present\nexperiments showing that LCMNAS generates state-of-the-art architectures from\nscratch with minimal GPU computation. We study the importance of different NAS\ncomponents on a macro-search setting. Code for reproducibility is public at\n\\url{https://github.com/VascoLopes/LCMNAS}.",
          "link": "http://arxiv.org/abs/2203.05508",
          "publishedOn": "2022-03-12T00:41:16.666Z",
          "wordCount": 665,
          "title": "Towards Less Constrained Macro-Neural Architecture Search. (arXiv:2203.05508v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.10858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yeom_S/0/1/0/all/0/1\">Seul-Ki Yeom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shim_K/0/1/0/all/0/1\">Kyung-Hwan Shim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Jee-Hyun Hwang</a>",
          "description": "Despite the remarkable performance, modern deep neural networks are\ninevitably accompanied by a significant amount of computational cost for\nlearning and deployment, which may be incompatible with their usage on edge\ndevices. Recent efforts to reduce these overheads involve pruning and\ndecomposing the parameters of various layers without performance deterioration.\nInspired by several decomposition studies, in this paper, we propose a novel\nenergy-aware pruning method that quantifies the importance of each filter in\nthe network using nuclear-norm (NN). Proposed energy-aware pruning leads to\nstate-of-the-art performance for Top-1 accuracy, FLOPs, and parameter reduction\nacross a wide range of scenarios with multiple network architectures on\nCIFAR-10 and ImageNet after fine-grained classification tasks. On toy\nexperiment, without fine-tuning, we can visually observe that NN has a minute\nchange in decision boundaries across classes and outperforms the previous\npopular criteria. We achieve competitive results with 40.4/49.8% of FLOPs and\n45.9/52.9% of parameter reduction with 94.13/94.61% in the Top-1 accuracy with\nResNet-56/110 on CIFAR-10, respectively. In addition, our observations are\nconsistent for a variety of different pruning setting in terms of data size as\nwell as data quality which can be emphasized in the stability of the\nacceleration and compression with negligible accuracy loss.",
          "link": "http://arxiv.org/abs/2103.10858",
          "publishedOn": "2022-03-12T00:41:16.658Z",
          "wordCount": 670,
          "title": "Toward Compact Deep Neural Networks via Energy-Aware Pruning. (arXiv:2103.10858v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.02705",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rugamer_D/0/1/0/all/0/1\">David R&#xfc;gamer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kolb_C/0/1/0/all/0/1\">Chris Kolb</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fritz_C/0/1/0/all/0/1\">Cornelius Fritz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pfisterer_F/0/1/0/all/0/1\">Florian Pfisterer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kopper_P/0/1/0/all/0/1\">Philipp Kopper</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shen_R/0/1/0/all/0/1\">Ruolin Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bukas_C/0/1/0/all/0/1\">Christina Bukas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sousa_L/0/1/0/all/0/1\">Lisa Barros de Andrade e Sousa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thalmeier_D/0/1/0/all/0/1\">Dominik Thalmeier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baumann_P/0/1/0/all/0/1\">Philipp Baumann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kook_L/0/1/0/all/0/1\">Lucas Kook</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Klein_N/0/1/0/all/0/1\">Nadja Klein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Muller_C/0/1/0/all/0/1\">Christian L. M&#xfc;ller</a>",
          "description": "In this paper we describe the implementation of semi-structured deep\ndistributional regression, a flexible framework to learn conditional\ndistributions based on the combination of additive regression models and deep\nnetworks. Our implementation encompasses (1) a modular neural network building\nsystem based on the deep learning library \\pkg{TensorFlow} for the fusion of\nvarious statistical and deep learning approaches, (2) an orthogonalization cell\nto allow for an interpretable combination of different subnetworks, as well as\n(3) pre-processing steps necessary to set up such models. The software package\nallows to define models in a user-friendly manner via a formula interface that\nis inspired by classical statistical model frameworks such as \\pkg{mgcv}. The\npackages' modular design and functionality provides a unique resource for both\nscalable estimation of complex statistical models and the combination of\napproaches from deep learning and statistics. This allows for state-of-the-art\npredictive performance while simultaneously retaining the indispensable\ninterpretability of classical statistical models.",
          "link": "http://arxiv.org/abs/2104.02705",
          "publishedOn": "2022-03-12T00:41:16.650Z",
          "wordCount": 649,
          "title": "deepregression: a Flexible Neural Network Framework for Semi-Structured Deep Distributional Regression. (arXiv:2104.02705v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.12996",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ghosh_S/0/1/0/all/0/1\">Subhro Ghosh</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rigollet_P/0/1/0/all/0/1\">Philippe Rigollet</a>",
          "description": "Motivated by cutting-edge applications like cryo-electron microscopy\n(cryo-EM), the Multi-Reference Alignment (MRA) model entails the learning of an\nunknown signal from repeated measurements of its images under the latent action\nof a group of isometries and additive noise of magnitude $\\sigma$. Despite\nsignificant interest, a clear picture for understanding rates of estimation in\nthis model has emerged only recently, particularly in the high-noise regime\n$\\sigma \\gg 1$ that is highly relevant in applications. Recent investigations\nhave revealed a remarkable asymptotic sample complexity of order $\\sigma^6$ for\ncertain signals whose Fourier transforms have full support, in stark contrast\nto the traditional $\\sigma^2$ that arise in regular models. Often prohibitively\nlarge in practice, these results have prompted the investigation of variations\naround the MRA model where better sample complexity may be achieved. In this\npaper, we show that sparse signals exhibit an intermediate $\\sigma^4$ sample\ncomplexity even in the classical MRA model. Further, we characterise the\ndependence of the estimation rate on the support size $s$ as $O_p(1)$ and\n$O_p(s^{3.5})$ in the dilute and moderate regimes of sparsity respectively. Our\ntechniques have implications for the problem of crystallographic phase\nretrieval, indicating a certain local uniqueness for the recovery of sparse\nsignals from their power spectrum. Our results explore and exploit connections\nof the MRA estimation problem with two classical topics in applied mathematics:\nthe beltway problem from combinatorial optimization, and uniform uncertainty\nprinciples from harmonic analysis. Our techniques include a certain enhanced\nform of the probabilistic method, which might be of general interest in its own\nright.",
          "link": "http://arxiv.org/abs/2106.12996",
          "publishedOn": "2022-03-12T00:41:16.642Z",
          "wordCount": 734,
          "title": "Sparse Multi-Reference Alignment : Phase Retrieval, Uniform Uncertainty Principles and the Beltway Problem. (arXiv:2106.12996v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.01064",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Davies_S/0/1/0/all/0/1\">Sami Davies</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>, <a href=\"http://arxiv.org/find/math/1/au:+Pal_S/0/1/0/all/0/1\">Soumyabrata Pal</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rashtchian_C/0/1/0/all/0/1\">Cyrus Rashtchian</a>",
          "description": "Mixtures of high dimensional Gaussian distributions have been studied\nextensively in statistics and learning theory. While the total variation\ndistance appears naturally in the sample complexity of distribution learning,\nit is analytically difficult to obtain tight lower bounds for mixtures.\nExploiting a connection between total variation distance and the characteristic\nfunction of the mixture, we provide fairly tight functional approximations.\nThis enables us to derive new lower bounds on the total variation distance\nbetween pairs of two-component Gaussian mixtures that have a shared covariance\nmatrix.",
          "link": "http://arxiv.org/abs/2109.01064",
          "publishedOn": "2022-03-12T00:41:16.617Z",
          "wordCount": 565,
          "title": "Lower Bounds on the Total Variation Distance Between Mixtures of Two Gaussians. (arXiv:2109.01064v2 [math.PR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.07465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shrestha_S/0/1/0/all/0/1\">Sohil Lal Shrestha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Csallner_C/0/1/0/all/0/1\">Christoph Csallner</a>",
          "description": "Finding bugs in a commercial cyber-physical system (CPS) development tool\nsuch as Simulink is hard as its codebase contains millions of lines of code and\ncomplete formal language specifications are not available. While deep learning\ntechniques promise to learn such language specifications from sample models,\ndeep learning needs a large number of training data to work well. SLGPT\naddresses this problem by using transfer learning to leverage the powerful\nGenerative Pre-trained Transformer 2 (GPT-2) model, which has been pre-trained\non a large set of training data. SLGPT adapts GPT-2 to Simulink with both\nrandomly generated models and models mined from open-source repositories. SLGPT\nproduced Simulink models that are both more similar to open-source models than\nits closest competitor, DeepFuzzSL, and found a super-set of the Simulink\ndevelopment toolchain bugs found by DeepFuzzSL.",
          "link": "http://arxiv.org/abs/2105.07465",
          "publishedOn": "2022-03-12T00:41:16.609Z",
          "wordCount": 647,
          "title": "SLGPT: Using Transfer Learning to Directly Generate Simulink Model Files and Find Bugs in the Simulink Toolchain. (arXiv:2105.07465v3 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.11773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_F/0/1/0/all/0/1\">Fan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panagiotelis_A/0/1/0/all/0/1\">Anastasios Panagiotelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hyndman_R/0/1/0/all/0/1\">Rob J Hyndman</a>",
          "description": "Analyzing high-dimensional data with manifold learning algorithms often\nrequires searching for the nearest neighbors of all observations. This presents\na computational bottleneck in statistical manifold learning when observations\nof probability distributions rather than vector-valued variables are available\nor when data size is large. We resolve this problem by proposing a new method\nfor approximation in statistical manifold learning. The novelty of our\napproximation is the strongly consistent distance estimators based on\nindependent and identically distributed samples from probability distributions.\nBy exploiting the connection between Hellinger/total variation distance for\ndiscrete distributions and the L2/L1 norm, we demonstrate that the proposed\ndistance estimators, combined with approximate nearest neighbor searching,\ncould largely improve the computational efficiency with little to no loss in\nthe accuracy of manifold embedding. The result is robust to different manifold\nlearning algorithms and different approximate nearest neighbor algorithms. The\nproposed method is applied to learning statistical manifolds of electricity\nusage. This application demonstrates how underlying structures in high\ndimensional data, including anomalies, can be visualized and identified, in a\nway that is scalable to large datasets.",
          "link": "http://arxiv.org/abs/2103.11773",
          "publishedOn": "2022-03-12T00:41:16.602Z",
          "wordCount": 644,
          "title": "Computationally Efficient Learning of Statistical Manifolds. (arXiv:2103.11773v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05434",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Natale_L/0/1/0/all/0/1\">Loris Di Natale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svetozarevic_B/0/1/0/all/0/1\">Bratislav Svetozarevic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heer_P/0/1/0/all/0/1\">Philipp Heer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_C/0/1/0/all/0/1\">Colin N. Jones</a>",
          "description": "Replacing poorly performing existing controllers with smarter solutions will\ndecrease the energy intensity of the building sector. Recently, controllers\nbased on Deep Reinforcement Learning (DRL) have been shown to be more effective\nthan conventional baselines. However, since the optimal solution is usually\nunknown, it is still unclear if DRL agents are attaining near-optimal\nperformance in general or if there is still a large gap to bridge.\n\nIn this paper, we investigate the performance of DRL agents compared to the\ntheoretically optimal solution. To that end, we leverage Physically Consistent\nNeural Networks (PCNNs) as simulation environments, for which optimal control\ninputs are easy to compute. Furthermore, PCNNs solely rely on data to be\ntrained, avoiding the difficult physics-based modeling phase, while retaining\nphysical consistency. Our results hint that DRL agents not only clearly\noutperform conventional rule-based controllers, they furthermore attain\nnear-optimal performance.",
          "link": "http://arxiv.org/abs/2203.05434",
          "publishedOn": "2022-03-12T00:41:16.565Z",
          "wordCount": 604,
          "title": "Near-optimal Deep Reinforcement Learning Policies from Data for Zone Temperature Control. (arXiv:2203.05434v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.02776",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Eftekhari_A/0/1/0/all/0/1\">Armin Eftekhari</a>, <a href=\"http://arxiv.org/find/math/1/au:+Esfahani_P/0/1/0/all/0/1\">Peyman Mohajerin Esfahani</a>",
          "description": "The gauge function, closely related to the atomic norm, measures the\ncomplexity of a statistical model, and has found broad applications in machine\nlearning and statistical signal processing. In a high-dimensional learning\nproblem, the gauge function attempts to safeguard against overfitting by\npromoting a sparse (concise) representation within the learning alphabet.\n\nIn this work, within the context of linear inverse problems, we pinpoint the\nsource of its success, but also argue that the applicability of the gauge\nfunction is inherently limited by its convexity, and showcase several learning\nproblems where the classical gauge function theory fails. We then introduce a\nnew notion of statistical complexity, gauge$_p$ function, which overcomes the\nlimitations of the gauge function. The gauge$_p$ function is a simple\ngeneralization of the gauge function that can tightly control the sparsity of a\nstatistical model within the learning alphabet and, perhaps surprisingly, draws\nfurther inspiration from the Burer-Monteiro factorization in computational\nmathematics.\n\nWe also propose a new learning machine, with the building block of gauge$_p$\nfunction, and arm this machine with a number of statistical guarantees. The\npotential of the proposed gauge$_p$ function theory is then studied for two\nstylized applications. Finally, we discuss the computational aspects and, in\nparticular, suggest a tractable numerical algorithm for implementing the new\nlearning machine.",
          "link": "http://arxiv.org/abs/2101.02776",
          "publishedOn": "2022-03-12T00:41:16.520Z",
          "wordCount": 670,
          "title": "The Nonconvex Geometry of Linear Inverse Problems. (arXiv:2101.02776v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenhongyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ochal_M/0/1/0/all/0/1\">Mateusz Ochal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1\">Amos Storkey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowley_E/0/1/0/all/0/1\">Elliot J. Crowley</a>",
          "description": "Real-world object detection models should be cheap and accurate. Knowledge\ndistillation (KD) can boost the accuracy of a small, cheap detection model by\nleveraging useful information from a larger teacher model. However, a key\nchallenge is identifying the most informative features produced by the teacher\nfor distillation. In this work, we show that only a very small fraction of\nfeatures within a ground-truth bounding box are responsible for a teacher's\nhigh detection performance. Based on this, we propose Prediction-Guided\nDistillation (PGD), which focuses distillation on these key predictive regions\nof the teacher and yields considerable gains in performance over many existing\nKD baselines. In addition, we propose an adaptive weighting scheme over the key\nregions to smooth out their influence and achieve even better performance. Our\nproposed approach outperforms current state-of-the-art KD baselines on a\nvariety of advanced one-stage detection architectures. Specifically, on the\nCOCO dataset, our method achieves between +3.1% and +4.6% AP improvement using\nResNet-101 and ResNet-50 as the teacher and student backbones, respectively. On\nthe CrowdHuman dataset, we achieve +3.2% and +2.0% improvements in MR and AP,\nalso using these backbones. Our code is available at\nhttps://github.com/ChenhongyiYang/PGD.",
          "link": "http://arxiv.org/abs/2203.05469",
          "publishedOn": "2022-03-12T00:41:16.513Z",
          "wordCount": 631,
          "title": "Prediction-Guided Distillation for Dense Object Detection. (arXiv:2203.05469v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gurina_E/0/1/0/all/0/1\">Ekaterina Gurina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klyuchnikov_N/0/1/0/all/0/1\">Nikita Klyuchnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antipova_K/0/1/0/all/0/1\">Ksenia Antipova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koroteev_D/0/1/0/all/0/1\">Dmitry Koroteev</a>",
          "description": "We present a data-driven and physics-informed algorithm for drilling accident\nforecasting. The core machine-learning algorithm uses the data from the\ndrilling telemetry representing the time-series. We have developed a\nBag-of-features representation of the time series that enables the algorithm to\npredict the probabilities of six types of drilling accidents in real-time. The\nmachine-learning model is trained on the 125 past drilling accidents from 100\ndifferent Russian oil and gas wells. Validation shows that the model can\nforecast 70% of drilling accidents with a false positive rate equals to 40%.\nThe model addresses partial prevention of the drilling accidents at the well\nconstruction.",
          "link": "http://arxiv.org/abs/2203.05378",
          "publishedOn": "2022-03-12T00:41:16.366Z",
          "wordCount": 555,
          "title": "Forecasting the abnormal events at well drilling with machine learning. (arXiv:2203.05378v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1902.10890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Burghal_D/0/1/0/all/0/1\">Daoud Burghal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alghafis_A/0/1/0/all/0/1\">Abdullah Alghafis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molisch_A/0/1/0/all/0/1\">Andreas F. Molisch</a>",
          "description": "Many wireless networks, including 5G NR (New Radio) and future beyond 5G\ncellular systems, are expected to operate on multiple frequency bands. This\npaper considers the band assignment (BA) problem in dual-band systems, where\nthe basestation (BS) chooses one of the two available frequency bands\n(centimeter-wave and millimeter-wave bands) to communicate with the user\nequipment (UE). While the millimeter-wave band might offer higher data rate,\nthere is a significant probability of outage during which the communication\nshould be carried on the (more reliable) centimeter-wave band. With mobility,\nthe BA can be perceived as a sequential problem, where the BS uses previously\nobserved information to predict the best band for a future time step.\n\nWe formulate the BA as a binary classification problem and propose supervised\nMachine Learning (ML) solutions. We study the problem when both the BS and the\nUE use (i) omnidirectional antennas and (ii) both use directional antennas. In\nthe omnidirectional case, we derive analytical benchmark solutions based on the\nGaussian Process (GP) assumption for the inter-band shadow fading. In the\ndirectional case, where the labeling is shown to be complex, we propose an\nefficient labeling approach based on the Viterbi Algorithm (VA). We compare the\nperformances for two channel models: (i) a stochastic channel and (ii) a\nray-tracing based channel.",
          "link": "http://arxiv.org/abs/1902.10890",
          "publishedOn": "2022-03-12T00:41:16.289Z",
          "wordCount": 707,
          "title": "Supervised ML Solution for Band Assignment in Dual-Band Systems with Omnidirectional and Directional Antennas. (arXiv:1902.10890v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.03350",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Munkhdalai_L/0/1/0/all/0/1\">Lkhagvadorj Munkhdalai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Munkhdalai_T/0/1/0/all/0/1\">Tsendsuren Munkhdalai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ryu_K/0/1/0/all/0/1\">Keun Ho Ryu</a>",
          "description": "Machine learning models with both good predictability and high\ninterpretability are crucial for decision support systems. Linear regression is\none of the most interpretable prediction models. However, the linearity in a\nsimple linear regression worsens its predictability. In this work, we introduce\na locally adaptive interpretable regression (LoAIR). In LoAIR, a metamodel\nparameterized by neural networks predicts percentile of a Gaussian distribution\nfor the regression coefficients for a rapid adaptation. Our experimental\nresults on public benchmark datasets show that our model not only achieves\ncomparable or better predictive performance than the other state-of-the-art\nbaselines but also discovers some interesting relationships between input and\ntarget variables such as a parabolic relationship between CO2 emissions and\nGross National Product (GNP). Therefore, LoAIR is a step towards bridging the\ngap between econometrics, statistics, and machine learning by improving the\npredictive ability of linear regression without depreciating its\ninterpretability.",
          "link": "http://arxiv.org/abs/2005.03350",
          "publishedOn": "2022-03-12T00:41:16.281Z",
          "wordCount": 603,
          "title": "A Locally Adaptive Interpretable Regression. (arXiv:2005.03350v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.08853",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Han_R/0/1/0/all/0/1\">Ruijian Han</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_Y/0/1/0/all/0/1\">Yiming Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_K/0/1/0/all/0/1\">Kani Chen</a>",
          "description": "Statistical inference using pairwise comparison data is an effective approach\nto analyzing large-scale sparse networks. In this paper, we propose a general\nframework to model the mutual interactions in a network, which enjoys ample\nflexibility in terms of model parametrization. Under this setup, we show that\nthe maximum likelihood estimator for the latent score vector of the subjects is\nuniformly consistent under a near-minimal condition on network sparsity. This\ncondition is sharp in terms of the leading order asymptotics describing the\nsparsity. Our analysis utilizes a novel chaining technique and illustrates an\nimportant connection between graph topology and model consistency. Our results\nguarantee that the maximum likelihood estimator is justified for estimation in\nlarge-scale pairwise comparison networks where data are asymptotically\ndeficient. Simulation studies are provided in support of our theoretical\nfindings.",
          "link": "http://arxiv.org/abs/2002.08853",
          "publishedOn": "2022-03-12T00:41:16.259Z",
          "wordCount": 608,
          "title": "A General Pairwise Comparison Model for Extremely Sparse Networks. (arXiv:2002.08853v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gorishniy_Y/0/1/0/all/0/1\">Yura Gorishniy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubachev_I/0/1/0/all/0/1\">Ivan Rubachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1\">Artem Babenko</a>",
          "description": "Recently, Transformer-like deep architectures have shown strong performance\non tabular data problems. Unlike traditional models, e.g., MLP, these\narchitectures map scalar values of numerical features to high-dimensional\nembeddings before mixing them in the main backbone. In this work, we argue that\nembeddings for numerical features are an underexplored degree of freedom in\ntabular DL, which allows constructing more powerful DL models and competing\nwith GBDT on some traditionally GBDT-friendly benchmarks. We start by\ndescribing two conceptually different approaches to building embedding modules:\nthe first one is based on a piecewise linear encoding of scalar values, and the\nsecond one utilizes periodic activations. Then, we empirically demonstrate that\nthese two approaches can lead to significant performance boosts compared to the\nembeddings based on conventional blocks such as linear layers and ReLU\nactivations. Importantly, we also show that embedding numerical features is\nbeneficial for many backbones, not only for Transformers. Specifically, after\nproper embeddings, simple MLP-like models can perform on par with the\nattention-based architectures. Overall, we highlight that embeddings for\nnumerical features are an important design aspect, which has good potential for\nfurther improvements in tabular DL.",
          "link": "http://arxiv.org/abs/2203.05556",
          "publishedOn": "2022-03-12T00:41:16.252Z",
          "wordCount": 624,
          "title": "On Embeddings for Numerical Features in Tabular Deep Learning. (arXiv:2203.05556v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wortsman_M/0/1/0/all/0/1\">Mitchell Wortsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilharco_G/0/1/0/all/0/1\">Gabriel Ilharco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadre_S/0/1/0/all/0/1\">Samir Yitzhak Gadre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1\">Rebecca Roelofs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gontijo_Lopes_R/0/1/0/all/0/1\">Raphael Gontijo-Lopes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari S. Morcos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namkoong_H/0/1/0/all/0/1\">Hongseok Namkoong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carmon_Y/0/1/0/all/0/1\">Yair Carmon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kornblith_S/0/1/0/all/0/1\">Simon Kornblith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1\">Ludwig Schmidt</a>",
          "description": "The conventional recipe for maximizing model accuracy is to (1) train\nmultiple models with various hyperparameters and (2) pick the individual model\nwhich performs best on a held-out validation set, discarding the remainder. In\nthis paper, we revisit the second step of this procedure in the context of\nfine-tuning large pre-trained models, where fine-tuned models often appear to\nlie in a single low error basin. We show that averaging the weights of multiple\nmodels fine-tuned with different hyperparameter configurations often improves\naccuracy and robustness. Unlike a conventional ensemble, we may average many\nmodels without incurring any additional inference or memory costs -- we call\nthe results \"model soups.\" When fine-tuning large pre-trained models such as\nCLIP, ALIGN, and a ViT-G pre-trained on JFT, our soup recipe provides\nsignificant improvements over the best model in a hyperparameter sweep on\nImageNet. As a highlight, the resulting ViT-G model attains 90.94% top-1\naccuracy on ImageNet, a new state of the art. Furthermore, we show that the\nmodel soup approach extends to multiple image classification and natural\nlanguage processing tasks, improves out-of-distribution performance, and\nimproves zero-shot performance on new downstream tasks. Finally, we\nanalytically relate the performance similarity of weight-averaging and\nlogit-ensembling to flatness of the loss and confidence of the predictions, and\nvalidate this relation empirically.",
          "link": "http://arxiv.org/abs/2203.05482",
          "publishedOn": "2022-03-12T00:41:16.246Z",
          "wordCount": 693,
          "title": "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. (arXiv:2203.05482v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Baihan Lin</a>",
          "description": "Understanding the deep representations of complex networks is an important\nstep of building interpretable and trustworthy machine learning applications in\nthe age of internet. Global surrogate models that approximate the predictions\nof a black box model (e.g. an artificial or biological neural net) are usually\nused to provide valuable theoretical insights for the model interpretability.\nIn order to evaluate how well a surrogate model can account for the\nrepresentation in another model, we need to develop inference methods for model\ncomparison. Previous studies have compared models and brains in terms of their\nrepresentational geometries (characterized by the matrix of distances between\nrepresentations of the input patterns in a model layer or cortical area). In\nthis study, we propose to explore these summary statistical descriptions of\nrepresentations in models and brains as part of a broader class of statistics\nthat emphasize the topology as well as the geometry of representations. The\ntopological summary statistics build on topological data analysis (TDA) and\nother graph-based methods. We evaluate these statistics in terms of the\nsensitivity and specificity that they afford when used for model selection,\nwith the goal to relate different neural network models to each other and to\nmake inferences about the computational mechanism that might best account for a\nblack box representation. These new methods enable brain and computer\nscientists to visualize the dynamic representational transformations learned by\nbrains and models, and to perform model-comparative statistical inference.",
          "link": "http://arxiv.org/abs/2203.05488",
          "publishedOn": "2022-03-12T00:41:16.238Z",
          "wordCount": 709,
          "title": "Geometric and Topological Inference for Deep Representations of Complex Networks. (arXiv:2203.05488v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jie Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinlei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ning Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengjiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1\">Tamara L. Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Licheng Yu</a>",
          "description": "Dual encoders and cross encoders have been widely used for image-text\nretrieval. Between the two, the dual encoder encodes the image and text\nindependently followed by a dot product, while the cross encoder jointly feeds\nimage and text as the input and performs dense multi-modal fusion. These two\narchitectures are typically modeled separately without interaction. In this\nwork, we propose LoopITR, which combines them in the same network for joint\nlearning. Specifically, we let the dual encoder provide hard negatives to the\ncross encoder, and use the more discriminative cross encoder to distill its\npredictions back to the dual encoder. Both steps are efficiently performed\ntogether in the same model. Our work centers on empirical analyses of this\ncombined architecture, putting the main focus on the design of the distillation\nobjective. Our experimental results highlight the benefits of training the two\nencoders in the same network, and demonstrate that distillation can be quite\neffective with just a few hard negative examples. Experiments on two standard\ndatasets (Flickr30K and COCO) show our approach achieves state-of-the-art dual\nencoder performance when compared with approaches using a similar amount of\ndata.",
          "link": "http://arxiv.org/abs/2203.05465",
          "publishedOn": "2022-03-12T00:41:16.231Z",
          "wordCount": 650,
          "title": "LoopITR: Combining Dual and Cross Encoder Architectures for Image-Text Retrieval. (arXiv:2203.05465v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_S/0/1/0/all/0/1\">Shaojie Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hongyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_R/0/1/0/all/0/1\">Ramchalam Kinattinkara Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tommy Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1\">Chen Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yicheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Parker Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Liang Shen</a>",
          "description": "Tiny machine learning (tinyML) has emerged during the past few years aiming\nto deploy machine learning models to embedded AI processors with highly\nconstrained memory and computation capacity. Low precision quantization is an\nimportant model compression technique that can greatly reduce both memory\nconsumption and computation cost of model inference. In this study, we focus on\npost-training quantization (PTQ) algorithms that quantize a model to low-bit\n(less than 8-bit) precision with only a small set of calibration data and\nbenchmark them on different tinyML use cases. To achieve a fair comparison, we\nbuild a simulated quantization framework to investigate recent PTQ algorithms.\nFurthermore, we break down those algorithms into essential components and\nre-assembled a generic PTQ pipeline. With ablation study on different\nalternatives of components in the pipeline, we reveal key design choices when\nperforming low precision quantization. We hope this work could provide useful\ndata points and shed lights on the future research of low precision\nquantization.",
          "link": "http://arxiv.org/abs/2203.05492",
          "publishedOn": "2022-03-12T00:41:16.207Z",
          "wordCount": 608,
          "title": "An Empirical Study of Low Precision Quantization for TinyML. (arXiv:2203.05492v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05443",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rocks_J/0/1/0/all/0/1\">Jason W. Rocks</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mehta_P/0/1/0/all/0/1\">Pankaj Mehta</a>",
          "description": "In classical statistics, the bias-variance trade-off describes how varying a\nmodel's complexity (e.g., number of fit parameters) affects its ability to make\naccurate predictions. According to this trade-off, optimal performance is\nachieved when a model is expressive enough to capture trends in the data, yet\nnot so complex that it overfits idiosyncratic features of the training data.\nRecently, it has become clear that this classic understanding of the\nbias-variance must be fundamentally revisited in light of the incredible\npredictive performance of \"overparameterized models\" -- models that avoid\noverfitting even when the number of fit parameters is large enough to perfectly\nfit the training data. Here, we present results for one of the simplest\nexamples of an overparameterized model: regression with random linear features\n(i.e. a two-layer neural network with a linear activation function). Using the\nzero-temperature cavity method, we derive analytic expressions for the training\nerror, test error, bias, and variance. We show that the linear random features\nmodel exhibits three phase transitions: two different transitions to an\ninterpolation regime where the training error is zero, along with an additional\ntransition between regimes with large bias and minimal bias. Using random\nmatrix theory, we show how each transition arises due to small nonzero\neigenvalues in the Hessian matrix. Finally, we compare and contrast the phase\ndiagram of the random linear features model to the random nonlinear features\nmodel and ordinary regression, highlighting the new phase transitions that\nresult from the use of linear basis functions.",
          "link": "http://arxiv.org/abs/2203.05443",
          "publishedOn": "2022-03-12T00:41:16.199Z",
          "wordCount": 702,
          "title": "Bias-variance decomposition of overparameterized regression with random linear features. (arXiv:2203.05443v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05363",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ye_J/0/1/0/all/0/1\">Jiayuan Ye</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shokri_R/0/1/0/all/0/1\">Reza Shokri</a>",
          "description": "Differential privacy analysis of randomized learning algorithms typically\nrelies on composition theorems, where the implicit assumption is that the\ninternal state of the iterative algorithm is revealed to the adversary.\nHowever, by assuming hidden states for DP algorithms (when only the\nlast-iterate is observable), recent works prove a converging privacy bound for\nnoisy gradient descent (on strongly convex smooth loss function) that is\nsignificantly smaller than composition bounds after $O(1/\\text{step-size})$\nepochs. In this paper, we extend this hidden-state analysis to the noisy\nmini-batch stochastic gradient descent algorithms on strongly-convex smooth\nloss functions. We prove converging R\\'enyi DP bounds under various mini-batch\nsampling schemes, such as \"shuffle and partition\" (which are used in practical\nimplementations of DP-SGD) and \"sampling without replacement\". We prove that,\nin these settings, our privacy bound is much smaller than the composition bound\nfor training with a large number of iterations (which is the case for learning\nfrom high-dimensional data). Our converging privacy analysis, thus, shows that\ndifferentially private learning, with a tight bound, needs hidden state privacy\nanalysis or a fast convergence. To complement our theoretical results, we run\nexperiment on training classification models on MNIST, FMNIST and CIFAR-10\ndatasets, and observe a better accuracy given fixed privacy budgets, under the\nhidden-state analysis.",
          "link": "http://arxiv.org/abs/2203.05363",
          "publishedOn": "2022-03-12T00:41:16.192Z",
          "wordCount": 650,
          "title": "Differentially Private Learning Needs Hidden State (Or Much Faster Convergence). (arXiv:2203.05363v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_X/0/1/0/all/0/1\">Xiaotian Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weixun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Hangyu Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jianye Hao</a>",
          "description": "Multi-agent reinforcement learning suffers from poor sample efficiency due to\nthe exponential growth of the state-action space. Considering a homogeneous\nmultiagent system, a global state consisting of $m$ homogeneous components has\n$m!$ differently ordered representations, thus designing functions satisfying\npermutation invariant (PI) can reduce the state space by a factor of\n$\\frac{1}{m!}$. However, mainstream MARL algorithms ignore this property and\nlearn over the original state space. To achieve PI, previous works including\ndata augmentation based methods and embedding-sharing architecture based\nmethods, suffer from training instability and limited model capacity. In this\nwork, we propose two novel designs to achieve PI, while avoiding the above\nlimitations. The first design permutes the same but differently ordered inputs\nback to the same order and the downstream networks only need to learn function\nmapping over fixed-ordering inputs instead of all permutations, which is much\neasier to train. The second design applies a hypernetwork to generate\ncustomized embedding for each component, which has higher representational\ncapacity than the previous embedding-sharing method. Empirical results on the\nSMAC benchmark show that the proposed method achieves 100% win-rates in almost\nall hard and super-hard scenarios (never achieved before), and superior\nsample-efficiency than the state-of-the-art baselines by up to 400%.",
          "link": "http://arxiv.org/abs/2203.05285",
          "publishedOn": "2022-03-12T00:41:16.185Z",
          "wordCount": 649,
          "title": "API: Boosting Multi-Agent Reinforcement Learning via Agent-Permutation-Invariant Networks. (arXiv:2203.05285v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05407",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Scholkemper_M/0/1/0/all/0/1\">Michael Scholkemper</a>, <a href=\"http://arxiv.org/find/math/1/au:+Schaub_M/0/1/0/all/0/1\">Michael Schaub</a>",
          "description": "Finding equitable partitions is closely related to the extraction of graph\nsymmetries and of interest in a variety of applications context such as node\nrole detection, cluster synchronization, consensus dynamics, and network\ncontrol problems. In this work we study a blind identification problem in which\nwe aim to recover an equitable partition of a network without the knowledge of\nthe network's edges but based solely on the observations of the outputs of an\nunknown graph filter. Specifically, we consider two settings. First, we\nconsider a scenario in which we can control the input to the graph filter and\npresent a method to extract the partition inspired by the well known\nWeisfeiler-Lehman (color refinement) algorithm. Second, we generalize this idea\nto a setting where only observe the outputs to random, low-rank excitations of\nthe graph filter, and present a simple spectral algorithm to extract the\nrelevant equitable partitions. Finally, we establish theoretical bounds on the\nerror that this spectral detection scheme incurs and perform numerical\nexperiments that illustrate our theoretical results and compare both\nalgorithms.",
          "link": "http://arxiv.org/abs/2203.05407",
          "publishedOn": "2022-03-12T00:41:16.178Z",
          "wordCount": 619,
          "title": "Blind Extraction of Equitable Partitions from Graph Signals. (arXiv:2203.05407v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Popovic_N/0/1/0/all/0/1\">Nicholas Popovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laurito_W/0/1/0/all/0/1\">Walter Laurito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farber_M/0/1/0/all/0/1\">Michael F&#xe4;rber</a>",
          "description": "In this paper, we present an end-to-end joint entity and relation extraction\napproach based on transformer-based language models. We apply the model to the\ntask of linking mathematical symbols to their descriptions in LaTeX documents.\nIn contrast to existing approaches, which perform entity and relation\nextraction in sequence, our system incorporates information from relation\nextraction into entity extraction. This means that the system can be trained\neven on data sets where only a subset of all valid entity spans is annotated.\nWe provide an extensive evaluation of the proposed system and its strengths and\nweaknesses. Our approach, which can be scaled dynamically in computational\ncomplexity at inference time, produces predictions with high precision and\nreaches 3rd place in the leaderboard of SemEval-2022 Task 12. For inputs in the\ndomain of physics and math, it achieves high relation extraction macro f1\nscores of 95.43% and 79.17%, respectively. The code used for training and\nevaluating our models is available at: https://github.com/nicpopovic/RE1st",
          "link": "http://arxiv.org/abs/2203.05325",
          "publishedOn": "2022-03-12T00:41:16.156Z",
          "wordCount": 627,
          "title": "AIFB-WebScience at SemEval-2022 Task 12: Relation Extraction First -- Using Relation Extraction to Identify Entities. (arXiv:2203.05325v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yiqi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xianming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Junjun Jiang</a>",
          "description": "Robustness of deep neural networks (DNNs) to malicious perturbations is a hot\ntopic in trustworthy AI. Existing techniques obtain robust models given fixed\ndatasets, either by modifying model structures, or by optimizing the process of\ninference or training. While significant improvements have been made, the\npossibility of constructing a high-quality dataset for model robustness remain\nunexplored. Follow the campaign of data-centric AI launched by Andrew Ng, we\npropose a novel algorithm for dataset enhancement that works well for many\nexisting DNN models to improve robustness. Transferable adversarial examples\nand 14 kinds of common corruptions are included in our optimized dataset. In\nthe data-centric robust learning competition hosted by Alibaba Group and\nTsinghua University, our algorithm came third out of more than 3000 competitors\nin the first stage while we ranked fourth in the second stage. Our code is\navailable at \\url{https://github.com/hncszyq/tianchi_challenge}.",
          "link": "http://arxiv.org/abs/2203.05323",
          "publishedOn": "2022-03-12T00:41:16.150Z",
          "wordCount": 598,
          "title": "Exploiting the Potential of Datasets: A Data-Centric Approach for Model Robustness. (arXiv:2203.05323v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05417",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Didisheim_A/0/1/0/all/0/1\">Antoine Didisheim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kelly_B/0/1/0/all/0/1\">Bryan Kelly</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Malamud_S/0/1/0/all/0/1\">Semyon Malamud</a>",
          "description": "We introduce a methodology for designing and training deep neural networks\n(DNN) that we call \"Deep Regression Ensembles\" (DRE). It bridges the gap\nbetween DNN and two-layer neural networks trained with random feature\nregression. Each layer of DRE has two components, randomly drawn input weights\nand output weights trained myopically (as if the final output layer) using\nlinear ridge regression. Within a layer, each neuron uses a different subset of\ninputs and a different ridge penalty, constituting an ensemble of random\nfeature ridge regressions. Our experiments show that a single DRE architecture\nis at par with or exceeds state-of-the-art DNN in many data sets. Yet, because\nDRE neural weights are either known in closed-form or randomly drawn, its\ncomputational cost is orders of magnitude smaller than DNN.",
          "link": "http://arxiv.org/abs/2203.05417",
          "publishedOn": "2022-03-12T00:41:16.143Z",
          "wordCount": 551,
          "title": "Deep Regression Ensembles. (arXiv:2203.05417v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiuwei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1\">Yongming Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiwen Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "In this paper, we propose a weakly-supervised approach for 3D object\ndetection, which makes it possible to train strong 3D detector with\nposition-level annotations (i.e. annotations of object centers). In order to\nremedy the information loss from box annotations to centers, our method, namely\nBack to Reality (BR), makes use of synthetic 3D shapes to convert the weak\nlabels into fully-annotated virtual scenes as stronger supervision, and in turn\nutilizes the perfect virtual labels to complement and refine the real labels.\nSpecifically, we first assemble 3D shapes into physically reasonable virtual\nscenes according to the coarse scene layout extracted from position-level\nannotations. Then we go back to reality by applying a virtual-to-real domain\nadaptation method, which refine the weak labels and additionally supervise the\ntraining of detector with the virtual scenes. Furthermore, we propose a more\nchallenging benckmark for indoor 3D object detection with more diversity in\nobject sizes to better show the potential of BR. With less than 5% of the\nlabeling labor, we achieve comparable detection performance with some popular\nfully-supervised approaches on the widely used ScanNet dataset. Code is\navailable at: https://github.com/xuxw98/BackToReality",
          "link": "http://arxiv.org/abs/2203.05238",
          "publishedOn": "2022-03-12T00:41:16.135Z",
          "wordCount": 648,
          "title": "Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided Label Enhancement. (arXiv:2203.05238v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_K/0/1/0/all/0/1\">Kilian Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rapp_M/0/1/0/all/0/1\">Martin Rapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalili_R/0/1/0/all/0/1\">Ramin Khalili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henkel_J/0/1/0/all/0/1\">J&#xf6;rg Henkel</a>",
          "description": "Devices participating in federated learning (FL) typically have heterogeneous\ncommunication and computation resources. However, all devices need to finish\ntraining by the same deadline dictated by the server when applying synchronous\nFL, as we consider in this paper. Reducing the complexity of the trained neural\nnetwork (NN) at constrained devices, i.e., by dropping neurons/filters, is\ninsufficient as it tightly couples reductions in communication and computation\nrequirements, wasting resources. Quantization has proven effective to\naccelerate inference, but quantized training suffers from accuracy losses. We\npresent a novel mechanism that quantizes during training parts of the NN to\nreduce the computation requirements, freezes them to reduce the communication\nand computation requirements, and trains the remaining parts in full precision\nto maintain a high convergence speed and final accuracy. Using this mechanism,\nwe present the first FL technique that independently optimizes for specific\ncommunication and computation constraints in FL: CoCo-FL. We show that CoCo-FL\nreaches a much higher convergence speed than the state of the art and a\nsignificantly higher final accuracy.",
          "link": "http://arxiv.org/abs/2203.05468",
          "publishedOn": "2022-03-12T00:41:16.110Z",
          "wordCount": 610,
          "title": "CoCo-FL: Communication- and Computation-Aware Federated Learning via Partial NN Freezing and Quantization. (arXiv:2203.05468v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guangyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Arash Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takac_M/0/1/0/all/0/1\">Martin Takac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Motee_N/0/1/0/all/0/1\">Nader Motee</a>",
          "description": "For a given stable recurrent neural network (RNN) that is trained to perform\na classification task using sequential inputs, we quantify explicit robustness\nbounds as a function of trainable weight matrices. The sequential inputs can be\nperturbed in various ways, e.g., streaming images can be deformed due to robot\nmotion or imperfect camera lens. Using the notion of the Voronoi diagram and\nLipschitz properties of stable RNNs, we provide a thorough analysis and\ncharacterize the maximum allowable perturbations while guaranteeing the full\naccuracy of the classification task. We illustrate and validate our theoretical\nresults using a map dataset with clouds as well as the MNIST dataset.",
          "link": "http://arxiv.org/abs/2203.05403",
          "publishedOn": "2022-03-12T00:41:16.103Z",
          "wordCount": 546,
          "title": "Robustness Analysis of Classification Using Recurrent Neural Networks with Perturbed Sequential Input. (arXiv:2203.05403v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duarte_M/0/1/0/all/0/1\">Maria Duarte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_P/0/1/0/all/0/1\">Pedro A. Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dias_J/0/1/0/all/0/1\">Jo&#xe3;o Dias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baptista_J/0/1/0/all/0/1\">Jorge Baptista</a>",
          "description": "Being able to clearly interpret legal texts and fully understanding our\nrights, obligations and other legal norms has become progressively more\nimportant in the digital society. However, simply giving citizens access to the\nlaws is not enough, as there is a need to provide meaningful information that\ncater to their specific queries and needs. For this, it is necessary to extract\nthe relevant semantic information present in legal texts. Thus, we introduce\nthe SNR (Semantic Norm Recognition) system, an automatic semantic information\nextraction system trained on a domain-specific (legal) text corpus taken from\nPortuguese Consumer Law. The SNR system uses the Portuguese Bert (BERTimbau)\nand was trained on a legislative Portuguese corpus. We demonstrate how our\nsystem achieved good results (81.44\\% F1-score) on this domain-specific corpus,\ndespite existing noise, and how it can be used to improve downstream tasks such\nas information retrieval.",
          "link": "http://arxiv.org/abs/2203.05425",
          "publishedOn": "2022-03-12T00:41:16.094Z",
          "wordCount": 585,
          "title": "Semantic Norm Recognition and its application to Portuguese Law. (arXiv:2203.05425v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05400",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Karvonen_T/0/1/0/all/0/1\">Toni Karvonen</a>",
          "description": "It is common to model a deterministic response function, such as the output\nof a computer experiment, as a Gaussian process with a Mat\\'ern covariance\nkernel. The smoothness parameter of a Mat\\'ern kernel determines many important\nproperties of the model in the large data limit, such as the rate of\nconvergence of the conditional mean to the response function. We prove that the\nmaximum likelihood and cross-validation estimates of the smoothness parameter\ncannot asymptotically undersmooth the truth when the data are obtained on a\nfixed bounded subset of $\\mathbb{R}^d$. That is, if the data-generating\nresponse function has Sobolev smoothness $\\nu_0 + d/2$, then the smoothness\nparameter estimates cannot remain below $\\nu_0$ as more data are obtained.\nThese results are based on a general theorem, proved using reproducing kernel\nHilbert space techniques, about sets of values the parameter estimates cannot\ntake and approximation theory in Sobolev spaces.",
          "link": "http://arxiv.org/abs/2203.05400",
          "publishedOn": "2022-03-12T00:41:16.060Z",
          "wordCount": 589,
          "title": "Asymptotic Bounds for Smoothness Parameter Estimates in Gaussian Process Regression. (arXiv:2203.05400v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junlin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1\">Xinchen Lyu</a>",
          "description": "Split learning is deemed as a promising paradigm for privacy-preserving\ndistributed learning, where the learning model can be cut into multiple\nportions to be trained at the participants collaboratively. The participants\nonly exchange the intermediate learning results at the cut layer, including\nsmashed data via forward-pass (i.e., features extracted from the raw data) and\ngradients during backward-propagation.Understanding the security performance of\nsplit learning is critical for various privacy-sensitive applications.With the\nemphasis on private labels, this paper proposes a passive clustering label\ninference attack for practical split learning. The adversary (either clients or\nservers) can accurately retrieve the private labels by collecting the exchanged\ngradients and smashed data.We mathematically analyse potential label leakages\nin split learning and propose the cosine and Euclidean similarity measurements\nfor clustering attack. Experimental results validate that the proposed approach\nis scalable and robust under different settings (e.g., cut layer positions,\nepochs, and batch sizes) for practical split learning.The adversary can still\nachieve accurate predictions, even when differential privacy and gradient\ncompression are adopted for label protections.",
          "link": "http://arxiv.org/abs/2203.05222",
          "publishedOn": "2022-03-12T00:41:16.048Z",
          "wordCount": 608,
          "title": "Clustering Label Inference Attack against Practical Split Learning. (arXiv:2203.05222v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Doshi_K/0/1/0/all/0/1\">Keval Doshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abudalou_S/0/1/0/all/0/1\">Shatha Abudalou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yilmaz_Y/0/1/0/all/0/1\">Yasin Yilmaz</a>",
          "description": "While anomaly detection in time series has been an active area of research\nfor several years, most recent approaches employ an inadequate evaluation\ncriterion leading to an inflated F1 score. We show that a rudimentary Random\nGuess method can outperform state-of-the-art detectors in terms of this popular\nbut faulty evaluation criterion. In this work, we propose a proper evaluation\nmetric that measures the timeliness and precision of detecting sequential\nanomalies. Moreover, most existing approaches are unable to capture temporal\nfeatures from long sequences. Self-attention based approaches, such as\ntransformers, have been demonstrated to be particularly efficient in capturing\nlong-range dependencies while being computationally efficient during training\nand inference. We also propose an efficient transformer approach for anomaly\ndetection in time series and extensively evaluate our proposed approach on\nseveral popular benchmark datasets.",
          "link": "http://arxiv.org/abs/2203.05167",
          "publishedOn": "2022-03-12T00:41:16.026Z",
          "wordCount": 566,
          "title": "TiSAT: Time Series Anomaly Transformer. (arXiv:2203.05167v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Soni_S/0/1/0/all/0/1\">Sanskar Soni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chouhan_S/0/1/0/all/0/1\">Satyendra Singh Chouhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rathore_S/0/1/0/all/0/1\">Santosh Singh Rathore</a>",
          "description": "In recent years, deep learning-based models have significantly improved the\nNatural Language Processing (NLP) tasks. Specifically, the Convolutional Neural\nNetwork (CNN), initially used for computer vision, has shown remarkable\nperformance for text data in various NLP problems. Most of the existing\nCNN-based models use 1-dimensional convolving filters n-gram detectors), where\neach filter specialises in extracting n-grams features of a particular input\nword embedding. The input word embeddings, also called sentence matrix, is\ntreated as a matrix where each row is a word vector. Thus, it allows the model\nto apply one-dimensional convolution and only extract n-gram based features\nfrom a sentence matrix. These features can be termed as intra-sentence n-gram\nfeatures. To the extent of our knowledge, all the existing CNN models are based\non the aforementioned concept. In this paper, we present a CNN-based\narchitecture TextConvoNet that not only extracts the intra-sentence n-gram\nfeatures but also captures the inter-sentence n-gram features in input text\ndata. It uses an alternative approach for input matrix representation and\napplies a two-dimensional multi-scale convolutional operation on the input. To\nevaluate the performance of TextConvoNet, we perform an experimental study on\nfive text classification datasets. The results are evaluated by using various\nperformance metrics. The experimental results show that the presented\nTextConvoNet outperforms state-of-the-art machine learning and deep learning\nmodels for text classification purposes.",
          "link": "http://arxiv.org/abs/2203.05173",
          "publishedOn": "2022-03-12T00:41:15.656Z",
          "wordCount": null,
          "title": "TextConvoNet:A Convolutional Neural Network based Architecture for Text Classification. (arXiv:2203.05173v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haiyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zihao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwamoto_N/0/1/0/all/0/1\">Naoya Iwamoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yichen Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhengqing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">You Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bozkurt_E/0/1/0/all/0/1\">Elif Bozkurt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bo Zheng</a>",
          "description": "Achieving realistic, vivid, and human-like synthesized conversational\ngestures conditioned on multi-modal data is still an unsolved problem, due to\nthe lack of available datasets, models and standard evaluation metrics. To\naddress this, we build Body-Expression-Audio-Text dataset, BEAT, which has i)\n76 hours, high-quality, multi-modal data captured from 30 speakers talking with\neight different emotions and in four different languages, ii) 32 millions\nframe-level emotion and semantic relevance annotations.Our statistical analysis\non BEAT demonstrates the correlation of conversational gestures with facial\nexpressions, emotions, and semantics, in addition to the known correlation with\naudio, text, and speaker identity. Qualitative and quantitative experiments\ndemonstrate metrics' validness, ground truth data quality, and baseline's\nstate-of-the-art performance. To the best of our knowledge, BEAT is the largest\nmotion capture dataset for investigating the human gestures, which may\ncontribute to a number of different research fields including controllable\ngesture synthesis, cross-modality analysis, emotional gesture recognition. The\ndata, code and model will be released for research.",
          "link": "http://arxiv.org/abs/2203.05297",
          "publishedOn": "2022-03-12T00:41:15.415Z",
          "wordCount": 627,
          "title": "BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for Conversational Gestures Synthesis. (arXiv:2203.05297v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yokota_T/0/1/0/all/0/1\">Tatsuya Yokota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hontani_H/0/1/0/all/0/1\">Hidekata Hontani</a>",
          "description": "This study proposes a framework for manifold learning of image patches using\nthe concept of equivalence classes: manifold modeling in quotient space (MMQS).\nIn MMQS, we do not consider a set of local patches of the image as it is, but\nrather the set of their canonical patches obtained by introducing the concept\nof equivalence classes and performing manifold learning on their canonical\npatches. Canonical patches represent equivalence classes, and their\nauto-encoder constructs a manifold in the quotient space. Based on this\nframework, we produce a novel manifold-based image model by introducing\nrotation-flip-equivalence relations. In addition, we formulate an image\nreconstruction problem by fitting the proposed image model to a corrupted\nobserved image and derive an algorithm to solve it. Our experiments show that\nthe proposed image model is effective for various self-supervised image\nreconstruction tasks, such as image inpainting, deblurring, super-resolution,\nand denoising.",
          "link": "http://arxiv.org/abs/2203.05134",
          "publishedOn": "2022-03-12T00:41:15.408Z",
          "wordCount": 595,
          "title": "Manifold Modeling in Quotient Space: Learning An Invariant Mapping with Decodability of Image Patches. (arXiv:2203.05134v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05174",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Sun_T/0/1/0/all/0/1\">Tony Y. Sun</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bhave_S/0/1/0/all/0/1\">Shreyas Bhave</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Altosaar_J/0/1/0/all/0/1\">Jaan Altosaar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Elhadad_N/0/1/0/all/0/1\">No&#xe9;mie Elhadad</a>",
          "description": "Disease identification is a core, routine activity in observational health\nresearch. Cohorts impact downstream analyses, such as how a condition is\ncharacterized, how patient risk is defined, and what treatments are studied. It\nis thus critical to ensure that selected cohorts are representative of all\npatients, independently of their demographics or social determinants of health.\nWhile there are multiple potential sources of bias when constructing phenotype\ndefinitions which may affect their fairness, it is not standard in the field of\nphenotyping to consider the impact of different definitions across subgroups of\npatients. In this paper, we propose a set of best practices to assess the\nfairness of phenotype definitions. We leverage established fairness metrics\ncommonly used in predictive models and relate them to commonly used\nepidemiological cohort description metrics. We describe an empirical study for\nCrohn's disease and diabetes type 2, each with multiple phenotype definitions\ntaken from the literature across two sets of patient subgroups (gender and\nrace). We show that the different phenotype definitions exhibit widely varying\nand disparate performance according to the different fairness metrics and\nsubgroups. We hope that the proposed best practices can help in constructing\nfair and inclusive phenotype definitions.",
          "link": "http://arxiv.org/abs/2203.05174",
          "publishedOn": "2022-03-12T00:41:15.368Z",
          "wordCount": 649,
          "title": "Assessing Phenotype Definitions for Algorithmic Fairness. (arXiv:2203.05174v1 [q-bio.OT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_H/0/1/0/all/0/1\">Hui Guan</a>",
          "description": "Tree-structured multi-task architectures have been employed to jointly tackle\nmultiple vision tasks in the context of multi-task learning (MTL). The major\nchallenge is to determine where to branch out for each task given a backbone\nmodel to optimize for both task accuracy and computation efficiency. To address\nthe challenge, this paper proposes a recommender that, given a set of tasks and\na convolutional neural network-based backbone model, automatically suggests\ntree-structured multi-task architectures that could achieve a high task\nperformance while meeting a user-specified computation budget without\nperforming model training. Extensive evaluations on popular MTL benchmarks show\nthat the recommended architectures could achieve competitive task accuracy and\ncomputation efficiency compared with state-of-the-art MTL methods.",
          "link": "http://arxiv.org/abs/2203.05092",
          "publishedOn": "2022-03-12T00:41:15.360Z",
          "wordCount": 551,
          "title": "A Tree-Structured Multi-Task Model Recommender. (arXiv:2203.05092v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ong_Y/0/1/0/all/0/1\">Yong Zheng Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zuowei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haizhao Yang</a>",
          "description": "Discretization invariant learning aims at learning in the\ninfinite-dimensional function spaces with the capacity to process heterogeneous\ndiscrete representations of functions as inputs and/or outputs of a learning\nmodel. This paper proposes a novel deep learning framework based on integral\nautoencoders (IAE-Net) for discretization invariant learning. The basic\nbuilding block of IAE-Net consists of an encoder and a decoder as integral\ntransforms with data-driven kernels, and a fully connected neural network\nbetween the encoder and decoder. This basic building block is applied in\nparallel in a wide multi-channel structure, which are repeatedly composed to\nform a deep and densely connected neural network with skip connections as\nIAE-Net. IAE-Net is trained with randomized data augmentation that generates\ntraining data with heterogeneous structures to facilitate the performance of\ndiscretization invariant learning. The proposed IAE-Net is tested with various\napplications in predictive data science, solving forward and inverse problems\nin scientific computing, and signal/image processing. Compared with\nalternatives in the literature, IAE-Net achieves state-of-the-art performance\nin existing applications and creates a wide range of new applications.",
          "link": "http://arxiv.org/abs/2203.05142",
          "publishedOn": "2022-03-12T00:41:15.353Z",
          "wordCount": 607,
          "title": "IAE-Net: Integral Autoencoders for Discretization-Invariant Learning. (arXiv:2203.05142v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Faniband_Y/0/1/0/all/0/1\">Yunus Parvej Faniband</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ishak_I/0/1/0/all/0/1\">Iskandar Ishak</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Sait_S/0/1/0/all/0/1\">Sadiq M.Sait</a> (1) ((1) Office of Industrial Collaboration, King Fahd University of Petroleum &amp; Minerals, Dhahran, Saudi Arabia (2) Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, Serdang, Selangor Darul Ehsan, Malaysia)",
          "description": "Time series data is used in a wide range of real world applications. In a\nvariety of domains , detailed analysis of time series data (via Forecasting and\nAnomaly Detection) leads to a better understanding of how events associated\nwith a specific time instance behave. Time Series Analysis (TSA) is commonly\nperformed with plots and traditional models. Machine Learning (ML) approaches ,\non the other hand , have seen an increase in the state of the art for\nForecasting and Anomaly Detection because they provide comparable results when\ntime and data constraints are met. A number of time series toolboxes are\navailable that offer rich interfaces to specific model classes (ARIMA/filters ,\nneural networks) or framework interfaces to isolated time series modelling\ntasks (forecasting , feature extraction , annotation , classification).\nNonetheless , open source machine learning capabilities for time series remain\nlimited , and existing libraries are frequently incompatible with one another.\nThe goal of this paper is to provide a concise and user friendly overview of\nthe most important open source tools for time series analysis. This article\nexamines two related toolboxes (1) forecasting and (2) anomaly detection. This\npaper describes a typical Time Series Analysis (TSA) framework with an\narchitecture and lists the main features of TSA framework. The tools are\ncategorized based on the criteria of analysis tasks completed , data\npreparation methods employed , and evaluation methods for results generated.\nThis paper presents quantitative analysis and discusses the current state of\nactively developed open source Time Series Analysis frameworks. Overall , this\narticle considered 60 time series analysis tools , and 32 of which provided\nforecasting modules , and 21 packages included anomaly detection.",
          "link": "http://arxiv.org/abs/2203.05195",
          "publishedOn": "2022-03-12T00:41:15.346Z",
          "wordCount": 764,
          "title": "A Review of Open Source Software Tools for Time Series Analysis. (arXiv:2203.05195v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ngo_T/0/1/0/all/0/1\">Trung Ngo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hautamaki_V/0/1/0/all/0/1\">Ville Hautam&#xe4;ki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinaniemi_M/0/1/0/all/0/1\">Merja Hein&#xe4;niemi</a>",
          "description": "Paradoxically, a Variational Autoencoder (VAE) could be pushed in two\nopposite directions, utilizing powerful decoder model for generating realistic\nimages but collapsing the learned representation, or increasing regularization\ncoefficient for disentangling representation but ultimately generating blurry\nexamples. Existing methods narrow the issues to the rate-distortion trade-off\nbetween compression and reconstruction. We argue that a good reconstruction\nmodel does learn high capacity latents that encode more details, however, its\nuse is hindered by two major issues: the prior is random noise which is\ncompletely detached from the posterior and allow no controllability in the\ngeneration; mean-field variational inference doesn't enforce hierarchy\nstructure which makes the task of recombining those units into plausible novel\noutput infeasible. As a result, we develop a system that learns a hierarchy of\ndisentangled representation together with a mechanism for recombining the\nlearned representation for generalization. This is achieved by introducing a\nminimal amount of inductive bias to learn controllable prior for the VAE. The\nidea is supported by here developed transitive information theory, that is, the\nmutual information between two target variables could alternately be maximized\nthrough the mutual information to the third variable, thus bypassing the\nrate-distortion bottleneck in VAE design. In particular, we show that our\nmodel, named SemafoVAE (inspired by the similar concept in computer science),\ncould generate high-quality examples in a controllable manner, perform smooth\ntraversals of the disentangled factors and intervention at a different level of\nrepresentation hierarchy.",
          "link": "http://arxiv.org/abs/2203.05074",
          "publishedOn": "2022-03-12T00:41:15.312Z",
          "wordCount": 685,
          "title": "The Transitive Information Theory and its Application to Deep Generative Models. (arXiv:2203.05074v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05079",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chester_A/0/1/0/all/0/1\">Andrew Chester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dann_M/0/1/0/all/0/1\">Michael Dann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zambetta_F/0/1/0/all/0/1\">Fabio Zambetta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thangarajah_J/0/1/0/all/0/1\">John Thangarajah</a>",
          "description": "Model-based reinforcement learning algorithms are typically more sample\nefficient than their model-free counterparts, especially in sparse reward\nproblems. Unfortunately, many interesting domains are too complex to specify\nthe complete models required by traditional model-based approaches. Learning a\nmodel takes a large number of environment samples, and may not capture critical\ninformation if the environment is hard to explore. If we could specify an\nincomplete model and allow the agent to learn how best to use it, we could take\nadvantage of our partial understanding of many domains. Existing hybrid\nplanning and learning systems which address this problem often impose highly\nrestrictive assumptions on the sorts of models which can be used, limiting\ntheir applicability to a wide range of domains. In this work we propose SAGE,\nan algorithm combining learning and planning to exploit a previously unusable\nclass of incomplete models. This combines the strengths of symbolic planning\nand neural learning approaches in a novel way that outperforms competing\nmethods on variations of taxi world and Minecraft.",
          "link": "http://arxiv.org/abs/2203.05079",
          "publishedOn": "2022-03-12T00:41:15.296Z",
          "wordCount": 620,
          "title": "SAGE: Generating Symbolic Goals for Myopic Models in Deep Reinforcement Learning. (arXiv:2203.05079v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05115",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lazaridou_A/0/1/0/all/0/1\">Angeliki Lazaridou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gribovskaya_E/0/1/0/all/0/1\">Elena Gribovskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stokowiec_W/0/1/0/all/0/1\">Wojciech Stokowiec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grigorev_N/0/1/0/all/0/1\">Nikolai Grigorev</a>",
          "description": "In this work, we aim to capitalize on the unique few-shot capabilities\noffered by large-scale language models to overcome some of their challenges\nwith respect to grounding to factual and up-to-date information. Motivated by\nsemi-parametric language models, which ground their decisions in external\nretrieved evidence, we use few-shot prompting to learn to condition language\nmodels on information returned from the web using Google Search, a broad and\nconstantly updated knowledge source. Our approach does not involve fine-tuning\nor learning additional parameters, thus making it applicable to any language\nmodel, offering like this a strong baseline. Indeed, we find that language\nmodels conditioned on the web surpass performance of closed-book models of\nsimilar, or even larger, model sizes in open-domain question answering.\nFinally, we find that increasing the inference-time compute of models, achieved\nvia using multiple retrieved evidences to generate multiple answers followed by\na reranking stage, alleviates generally decreased performance of smaller\nfew-shot language models. All in all, our findings suggest that it might be\nbeneficial to slow down the race towards the biggest model and instead shift\nthe attention towards finding more effective ways to use models, including but\nnot limited to better prompting or increasing inference-time compute.",
          "link": "http://arxiv.org/abs/2203.05115",
          "publishedOn": "2022-03-12T00:41:15.289Z",
          "wordCount": 641,
          "title": "Internet-augmented language models through few-shot prompting for open-domain question answering. (arXiv:2203.05115v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05127",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ho_Y/0/1/0/all/0/1\">Yung-Han Ho</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_Y/0/1/0/all/0/1\">Yun Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kao_C/0/1/0/all/0/1\">Chia-Hao Kao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_W/0/1/0/all/0/1\">Wen-Hsiao Peng</a>",
          "description": "This paper presents a reinforcement learning (RL) framework that leverages\nFrank-Wolfe policy optimization to address frame-level bit allocation for\nHEVC/H.265. Most previous RL-based approaches adopt the single-critic design,\nwhich weights the rewards for distortion minimization and rate regularization\nby an empirically chosen hyper-parameter. More recently, the dual-critic design\nis proposed to update the actor network by alternating the rate and distortion\ncritics. However, the convergence of training is not guaranteed. To address\nthis issue, we introduce Neural Frank-Wolfe Policy Optimization (NFWPO) in\nformulating the frame-level bit allocation as an action-constrained RL problem.\nIn this new framework, the rate critic serves to specify a feasible action set,\nand the distortion critic updates the actor network towards maximizing the\nreconstruction quality while conforming to the action constraint. Experimental\nresults show that when trained to optimize the video multi-method assessment\nfusion (VMAF) metric, our NFWPO-based model outperforms both the single-critic\nand the dual-critic methods. It also demonstrates comparable rate-distortion\nperformance to the 2-pass average bit rate control of x265.",
          "link": "http://arxiv.org/abs/2203.05127",
          "publishedOn": "2022-03-12T00:41:15.267Z",
          "wordCount": 620,
          "title": "Action-Constrained Reinforcement Learning for Frame-Level Bit Allocation in HEVC/H.265 through Frank-Wolfe Policy Optimization. (arXiv:2203.05127v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Lizhou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lafia_S/0/1/0/all/0/1\">Sara Lafia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bleckley_D/0/1/0/all/0/1\">David Bleckley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moss_E/0/1/0/all/0/1\">Elizabeth Moss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomer_A/0/1/0/all/0/1\">Andrea Thomer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hemphill_L/0/1/0/all/0/1\">Libby Hemphill</a>",
          "description": "Data citations provide a foundation for studying research data impact.\nCollecting and managing data citations is a new frontier in archival science\nand scholarly communication. However, the discovery and curation of research\ndata citations is labor intensive. Data citations that reference unique\nidentifiers (i.e. DOIs) are readily findable; however, informal mentions made\nto research data are more challenging to infer. We propose a natural language\nprocessing (NLP) paradigm to support the human task of identifying informal\nmentions made to research datasets. The work of discovering informal data\nmentions is currently performed by librarians and their staff in the\nInter-university Consortium for Political and Social Research (ICPSR), a large\nsocial science data archive that maintains a large bibliography of data-related\nliterature. The NLP model is bootstrapped from data citations actively\ncollected by librarians at ICPSR. The model combines pattern matching with\nmultiple iterations of human annotations to learn additional rules for\ndetecting informal data mentions. These examples are then used to train an NLP\npipeline. The librarian-in-the-loop paradigm is centered in the data work\nperformed by ICPSR librarians, supporting broader efforts to build a more\ncomprehensive bibliography of data-related literature that reflects the\nscholarly communities of research data users.",
          "link": "http://arxiv.org/abs/2203.05112",
          "publishedOn": "2022-03-12T00:41:15.260Z",
          "wordCount": 664,
          "title": "Librarian-in-the-Loop: A Natural Language Processing Paradigm for Detecting Informal Mentions of Research Data in Academic Literature. (arXiv:2203.05112v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05121",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greige_L/0/1/0/all/0/1\">Laura Greige</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_F/0/1/0/all/0/1\">Fernando De Mesentier Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trotter_M/0/1/0/all/0/1\">Meredith Trotter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrence_C/0/1/0/all/0/1\">Chris Lawrence</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_P/0/1/0/all/0/1\">Peter Chin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varadarajan_D/0/1/0/all/0/1\">Dilip Varadarajan</a>",
          "description": "In the context of competitive multiplayer games, collusion happens when two\nor more teams decide to collaborate towards a common goal, with the intention\nof gaining an unfair advantage from this cooperation. The task of identifying\ncolluders from the player population is however infeasible to game designers\ndue to the sheer size of the player population. In this paper, we propose a\nsystem that detects colluding behaviors in team-based multiplayer games and\nhighlights the players that most likely exhibit colluding behaviors. The game\ndesigners then proceed to analyze a smaller subset of players and decide what\naction to take. For this reason, it is important and necessary to be extremely\ncareful with false positives when automating the detection. The proposed method\nanalyzes the players' social relationships paired with their in-game behavioral\npatterns and, using tools from graph theory, infers a feature set that allows\nus to detect and measure the degree of collusion exhibited by each pair of\nplayers from opposing teams. We then automate the detection using Isolation\nForest, an unsupervised learning technique specialized in highlighting\noutliers, and show the performance and efficiency of our approach on two real\ndatasets, each with over 170,000 unique players and over 100,000 different\nmatches.",
          "link": "http://arxiv.org/abs/2203.05121",
          "publishedOn": "2022-03-12T00:41:15.252Z",
          "wordCount": 649,
          "title": "Collusion Detection in Team-Based Multiplayer Games. (arXiv:2203.05121v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05071",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kontolati_K/0/1/0/all/0/1\">Katiana Kontolati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_S/0/1/0/all/0/1\">Somdatta Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shields_M/0/1/0/all/0/1\">Michael D. Shields</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Constructing accurate and generalizable approximators for complex\nphysico-chemical processes exhibiting highly non-smooth dynamics is\nchallenging. In this work, we propose new developments and perform comparisons\nfor two promising approaches: manifold-based polynomial chaos expansion (m-PCE)\nand the deep neural operator (DeepONet), and we examine the effect of\nover-parameterization on generalization. We demonstrate the performance of\nthese methods in terms of generalization accuracy by solving the 2D\ntime-dependent Brusselator reaction-diffusion system with uncertainty sources,\nmodeling an autocatalytic chemical reaction between two species. We first\npropose an extension of the m-PCE by constructing a mapping between latent\nspaces formed by two separate embeddings of input functions and output QoIs. To\nenhance the accuracy of the DeepONet, we introduce weight self-adaptivity in\nthe loss function. We demonstrate that the performance of m-PCE and DeepONet is\ncomparable for cases of relatively smooth input-output mappings. However, when\nhighly non-smooth dynamics is considered, DeepONet shows higher accuracy. We\nalso find that for m-PCE, modest over-parameterization leads to better\ngeneralization, both within and outside of distribution, whereas aggressive\nover-parameterization leads to over-fitting. In contrast, an even highly\nover-parameterized DeepONet leads to better generalization for both smooth and\nnon-smooth dynamics. Furthermore, we compare the performance of the above\nmodels with another operator learning model, the Fourier Neural Operator, and\nshow that its over-parameterization also leads to better generalization. Our\nstudies show that m-PCE can provide very good accuracy at very low training\ncost, whereas a highly over-parameterized DeepONet can provide better accuracy\nand robustness to noise but at higher training cost. In both methods, the\ninference cost is negligible.",
          "link": "http://arxiv.org/abs/2203.05071",
          "publishedOn": "2022-03-12T00:41:15.243Z",
          "wordCount": 710,
          "title": "On the influence of over-parameterization in manifold based surrogates and deep neural operators. (arXiv:2203.05071v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_H/0/1/0/all/0/1\">Hari Prasanna Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spanos_C/0/1/0/all/0/1\">Costas J. Spanos</a>",
          "description": "Personal thermal comfort models aim to predict an individual's thermal\ncomfort response, instead of the average response of a large group. Recently,\nmachine learning algorithms have proven to be having enormous potential as a\ncandidate for personal thermal comfort models. But, often within the normal\nsettings of a building, personal thermal comfort data obtained via experiments\nare heavily class-imbalanced. There are a disproportionately high number of\ndata samples for the \"Prefer No Change\" class, as compared with the \"Prefer\nWarmer\" and \"Prefer Cooler\" classes. Machine learning algorithms trained on\nsuch class-imbalanced data perform sub-optimally when deployed in the real\nworld. To develop robust machine learning-based applications using the above\nclass-imbalanced data, as well as for privacy-preserving data sharing, we\npropose to implement a state-of-the-art conditional synthetic data generator to\ngenerate synthetic data corresponding to the low-frequency classes. Via\nexperiments, we show that the synthetic data generated has a distribution that\nmimics the real data distribution. The proposed method can be extended for use\nby other smart building datasets/use-cases.",
          "link": "http://arxiv.org/abs/2203.05242",
          "publishedOn": "2022-03-12T00:41:15.236Z",
          "wordCount": 608,
          "title": "Conditional Synthetic Data Generation for Personal Thermal Comfort Models. (arXiv:2203.05242v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongkuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bingyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannan_R/0/1/0/all/0/1\">Rajgopal Kannan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prasanna_V/0/1/0/all/0/1\">Viktor Prasanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Busart_C/0/1/0/all/0/1\">Carl Busart</a>",
          "description": "Temporal Graph Neural Networks (TGNNs) are powerful models to capture\ntemporal, structural, and contextual information on temporal graphs. The\ngenerated temporal node embeddings outperform other methods in many downstream\ntasks. Real-world applications require high performance inference on real-time\nstreaming dynamic graphs. However, these models usually rely on complex\nattention mechanisms to capture relationships between temporal neighbors. In\naddition, maintaining vertex memory suffers from intrinsic temporal data\ndependency that hinders task-level parallelism, making it inefficient on\ngeneral-purpose processors. In this work, we present a novel model-architecture\nco-design for inference in memory-based TGNNs on FPGAs. The key modeling\noptimizations we propose include a light-weight method to compute attention\nscores and a related temporal neighbor pruning strategy to further reduce\ncomputation and memory accesses. These are holistically coupled with key\nhardware optimizations that leverage FPGA hardware. We replace the temporal\nsampler with an on-chip FIFO based hardware sampler and the time encoder with a\nlook-up-table. We train our simplified models using knowledge distillation to\nensure similar accuracy vis-\\'a-vis the original model. Taking advantage of the\nmodel optimizations, we propose a principled hardware architecture using\nbatching, pipelining, and prefetching techniques to further improve the\nperformance. We also propose a hardware mechanism to ensure the chronological\nvertex updating without sacrificing the computation parallelism. We evaluate\nthe performance of the proposed hardware accelerator on three real-world\ndatasets.",
          "link": "http://arxiv.org/abs/2203.05095",
          "publishedOn": "2022-03-12T00:41:15.209Z",
          "wordCount": 666,
          "title": "Model-Architecture Co-Design for High Performance Temporal GNN Inference on FPGA. (arXiv:2203.05095v1 [cs.AR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05026",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nivarthi_C/0/1/0/all/0/1\">Chandana Priya Nivarthi</a>",
          "description": "Transfer learning (TL), the next frontier in machine learning (ML), has\ngained much popularity in recent years, due to the various challenges faced in\nML, like the requirement of vast amounts of training data, expensive and\ntime-consuming labelling processes for data samples, and long training duration\nfor models. TL is useful in tackling these problems, as it focuses on\ntransferring knowledge from previously solved tasks to new tasks. Digital twins\nand other intelligent systems need to utilise TL to use the previously gained\nknowledge and solve new tasks in a more self-reliant way, and to incrementally\nincrease their knowledge base. Therefore, in this article, the critical\nchallenges in power forecasting and anomaly detection in the context of\nrenewable energy systems are identified, and a potential TL framework to meet\nthese challenges is proposed. This article also proposes a feature embedding\napproach to handle the missing sensors data. The proposed TL methods help to\nmake a system more autonomous in the context of organic computing.",
          "link": "http://arxiv.org/abs/2203.05026",
          "publishedOn": "2022-03-12T00:41:15.199Z",
          "wordCount": 614,
          "title": "Transfer Learning as an Essential Tool for Digital Twins in Renewable Energy Systems. (arXiv:2203.05026v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05103",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_H/0/1/0/all/0/1\">Haoyu Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Shikui Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1\">Qiming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yao Zhao</a>",
          "description": "Neural Ordinary Differential Equations (Neural ODEs) construct the continuous\ndynamics of hidden units using ordinary differential equations specified by a\nneural network, demonstrating promising results on many tasks. However, Neural\nODEs still do not perform well on image recognition tasks. The possible reason\nis that the one-hot encoding vector commonly used in Neural ODEs can not\nprovide enough supervised information. We propose a new training based on\nknowledge distillation to construct more powerful and robust Neural ODEs\nfitting image recognition tasks. Specially, we model the training of Neural\nODEs into a teacher-student learning process, in which we propose ResNets as\nthe teacher model to provide richer supervised information. The experimental\nresults show that the new training manner can improve the classification\naccuracy of Neural ODEs by 24% on CIFAR10 and 5% on SVHN. In addition, we also\nquantitatively discuss the effect of both knowledge distillation and time\nhorizon in Neural ODEs on robustness against adversarial examples. The\nexperimental analysis concludes that introducing the knowledge distillation and\nincreasing the time horizon can improve the robustness of Neural ODEs against\nadversarial examples.",
          "link": "http://arxiv.org/abs/2203.05103",
          "publishedOn": "2022-03-12T00:41:15.192Z",
          "wordCount": 618,
          "title": "Improving Neural ODEs via Knowledge Distillation. (arXiv:2203.05103v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blanchard_M/0/1/0/all/0/1\">Mo&#xef;se Blanchard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaillet_P/0/1/0/all/0/1\">Patrick Jaillet</a>",
          "description": "We provide algorithms for regression with adversarial responses under large\nclasses of non-i.i.d. instance sequences, on general separable metric spaces,\nwith provably minimal assumptions. We also give characterizations of\nlearnability in this regression context. We consider universal consistency\nwhich asks for strong consistency of a learner without restrictions on the\nvalue responses. Our analysis shows that such objective is achievable for a\nsignificantly larger class of instance sequences than stationary processes, and\nunveils a fundamental dichotomy between value spaces: whether finite-horizon\nmean-estimation is achievable or not. We further provide optimistically\nuniversal learning rules, i.e., such that if they fail to achieve universal\nconsistency, any other algorithm will fail as well. For unbounded losses, we\npropose a mild integrability condition under which there exist algorithms for\nadversarial regression under large classes of non-i.i.d. instance sequences. In\naddition, our analysis also provides a learning rule for mean-estimation in\ngeneral metric spaces that is consistent under adversarial responses without\nany moment conditions on the sequence, a result of independent interest.",
          "link": "http://arxiv.org/abs/2203.05067",
          "publishedOn": "2022-03-12T00:41:15.184Z",
          "wordCount": 596,
          "title": "Universal Regression with Adversarial Responses. (arXiv:2203.05067v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chaoyue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Libin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belkin_M/0/1/0/all/0/1\">Mikhail Belkin</a>",
          "description": "Wide neural networks with linear output layer have been shown to be\nnear-linear, and to have near-constant neural tangent kernel (NTK), in a region\ncontaining the optimization path of gradient descent. These findings seem\ncounter-intuitive since in general neural networks are highly complex models.\nWhy does a linear structure emerge when the networks become wide? In this work,\nwe provide a new perspective on this \"transition to linearity\" by considering a\nneural network as an assembly model recursively built from a set of sub-models\ncorresponding to individual neurons. In this view, we show that the linearity\nof wide neural networks is, in fact, an emerging property of assembling a large\nnumber of diverse \"weak\" sub-models, none of which dominate the assembly.",
          "link": "http://arxiv.org/abs/2203.05104",
          "publishedOn": "2022-03-12T00:41:15.176Z",
          "wordCount": 573,
          "title": "Transition to Linearity of Wide Neural Networks is an Emerging Property of Assembling Weak Models. (arXiv:2203.05104v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05008",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">W. Ronny Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyser_C/0/1/0/all/0/1\">Cal Peyser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1\">Ruoming Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strohman_T/0/1/0/all/0/1\">Trevor Strohman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shankar Kumar</a>",
          "description": "Language model fusion helps smart assistants recognize words which are rare\nin acoustic data but abundant in text-only corpora (typed search logs).\nHowever, such corpora have properties that hinder downstream performance,\nincluding being (1) too large, (2) beset with domain-mismatched content, and\n(3) heavy-headed rather than heavy-tailed (excessively many duplicate search\nqueries such as \"weather\"). We show that three simple strategies for selecting\nlanguage modeling data can dramatically improve rare-word recognition without\nharming overall performance. First, to address the heavy-headedness, we\ndownsample the data according to a soft log function, which tunably reduces\nhigh frequency (head) sentences. Second, to encourage rare-word exposure, we\nexplicitly filter for words rare in the acoustic data. Finally, we tackle\ndomain-mismatch via perplexity-based contrastive selection, filtering for\nexamples matched to the target domain. We down-select a large corpus of web\nsearch queries by a factor of 53x and achieve better LM perplexities than\nwithout down-selection. When shallow-fused with a state-of-the-art, production\nspeech engine, our LM achieves WER reductions of up to 24% relative on\nrare-word sentences (without changing overall WER) compared to a baseline LM\ntrained on the raw corpus. These gains are further validated through favorable\nside-by-side evaluations on live voice search traffic.",
          "link": "http://arxiv.org/abs/2203.05008",
          "publishedOn": "2022-03-12T00:41:15.155Z",
          "wordCount": 659,
          "title": "Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word Speech Recognition. (arXiv:2203.05008v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Howard_J/0/1/0/all/0/1\">John J. Howard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laird_E/0/1/0/all/0/1\">Eli J. Laird</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sirotin_Y/0/1/0/all/0/1\">Yevgeniy B. Sirotin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_R/0/1/0/all/0/1\">Rebecca E. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tipton_J/0/1/0/all/0/1\">Jerry L. Tipton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vemury_A/0/1/0/all/0/1\">Arun R. Vemury</a>",
          "description": "The development of face recognition algorithms by academic and commercial\norganizations is growing rapidly due to the onset of deep learning and the\nwidespread availability of training data. Though tests of face recognition\nalgorithm performance indicate yearly performance gains, error rates for many\nof these systems differ based on the demographic composition of the test set.\nThese \"demographic differentials\" in algorithm performance can contribute to\nunequal or unfair outcomes for certain groups of people, raising concerns with\nincreased worldwide adoption of face recognition systems. Consequently,\nregulatory bodies in both the United States and Europe have proposed new rules\nrequiring audits of biometric systems for \"discriminatory impacts\" (European\nUnion Artificial Intelligence Act) and \"fairness\" (U.S. Federal Trade\nCommission). However, no standard for measuring fairness in biometric systems\nyet exists. This paper characterizes two proposed measures of face recognition\nalgorithm fairness (fairness measures) from scientists in the U.S. and Europe.\nWe find that both proposed methods are challenging to interpret when applied to\ndisaggregated face recognition error rates as they are commonly experienced in\npractice. To address this, we propose a set of interpretability criteria,\ntermed the Functional Fairness Measure Criteria (FFMC), that outlines a set of\nproperties desirable in a face recognition algorithm fairness measure. We\nfurther develop a new fairness measure, the Gini Aggregation Rate for Biometric\nEquitability (GARBE), and show how, in conjunction with the Pareto\noptimization, this measure can be used to select among alternative algorithms\nbased on the accuracy/fairness trade-space. Finally, we have open-sourced our\ndataset of machine-readable, demographically disaggregated error rates. We\nbelieve this is currently the largest open-source dataset of its kind.",
          "link": "http://arxiv.org/abs/2203.05051",
          "publishedOn": "2022-03-12T00:41:15.148Z",
          "wordCount": 725,
          "title": "Evaluating Proposed Fairness Models for Face Recognition Algorithms. (arXiv:2203.05051v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Nan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levinboim_T/0/1/0/all/0/1\">Tomer Levinboim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Changpinyo_B/0/1/0/all/0/1\">Beer Changpinyo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1\">Radu Soricut</a>",
          "description": "With the increasing abundance of pretrained models in recent years, the\nproblem of selecting the best pretrained checkpoint for a particular downstream\nclassification task has been gaining increased attention. Although several\nmethods have recently been proposed to tackle the selection problem (e.g. LEEP,\nH-score), these methods resort to applying heuristics that are not well\nmotivated by learning theory. In this paper we present PACTran, a theoretically\ngrounded family of metrics for pretrained model selection and transferability\nmeasurement. We first show how to derive PACTran metrics from the optimal\nPAC-Bayesian bound under the transfer learning setting. We then empirically\nevaluate three metric instantiations of PACTran on a number of vision tasks\n(VTAB) as well as a language-and-vision (OKVQA) task. An analysis of the\nresults shows PACTran is a more consistent and effective transferability\nmeasure compared to existing selection methods.",
          "link": "http://arxiv.org/abs/2203.05126",
          "publishedOn": "2022-03-12T00:41:15.140Z",
          "wordCount": 582,
          "title": "PACTran: PAC-Bayesian Metrics for Estimating the Transferability of Pretrained Models to Classification Tasks. (arXiv:2203.05126v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zhixuan Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rathbun_S/0/1/0/all/0/1\">Stephen L. Rathbun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>",
          "description": "Estimating treatment effects from observational data provides insights about\ncausality guiding many real-world applications such as different clinical study\ndesigns, which are the formulations of trials, experiments, and observational\nstudies in medical, clinical, and other types of research. In this paper, we\ndescribe causal inference for application in a novel clinical design called\nbasket trial that tests how well a new drug works in patients who have\ndifferent types of cancer that all have the same mutation. We propose a\nmulti-task adversarial learning (MTAL) method, which incorporates feature\nselection multi-task representation learning and adversarial learning to\nestimate potential outcomes across different tumor types for patients sharing\nthe same genetic mutation but having different tumor types. In our paper, the\nbasket trial is employed as an intuitive example to present this new causal\ninference setting. This new causal inference setting includes, but is not\nlimited to basket trials. This setting has the same challenges as the\ntraditional causal inference problem, i.e., missing counterfactual outcomes\nunder different subgroups and treatment selection bias due to confounders. We\npresent the practical advantages of our MTAL method for the analysis of\nsynthetic basket trial data and evaluate the proposed estimator on two\nbenchmarks, IHDP and News. The results demonstrate the superiority of our MTAL\nmethod over the competing state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2203.05123",
          "publishedOn": "2022-03-12T00:41:15.132Z",
          "wordCount": 673,
          "title": "Multi-Task Adversarial Learning for Treatment Effect Estimation in Basket Trials. (arXiv:2203.05123v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05086",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Colgan_R/0/1/0/all/0/1\">Robert E. Colgan</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Marka_Z/0/1/0/all/0/1\">Zsuzsa M&#xe1;rka</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Yan_J/0/1/0/all/0/1\">Jingkai Yan</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Bartos_I/0/1/0/all/0/1\">Imre Bartos</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wright_J/0/1/0/all/0/1\">John N. Wright</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Marka_S/0/1/0/all/0/1\">Szabolcs M&#xe1;rka</a>",
          "description": "As engineered systems grow in complexity, there is an increasing need for\nautomatic methods that can detect, diagnose, and even correct transient\nanomalies that inevitably arise and can be difficult or impossible to diagnose\nand fix manually. Among the most sensitive and complex systems of our\ncivilization are the detectors that search for incredibly small variations in\ndistance caused by gravitational waves -- phenomena originally predicted by\nAlbert Einstein to emerge and propagate through the universe as the result of\ncollisions between black holes and other massive objects in deep space. The\nextreme complexity and precision of such detectors causes them to be subject to\ntransient noise issues that can significantly limit their sensitivity and\neffectiveness.\n\nIn this work, we present a demonstration of a method that can detect and\ncharacterize emergent transient anomalies of such massively complex systems. We\nillustrate the performance, precision, and adaptability of the automated\nsolution via one of the prevalent issues limiting gravitational-wave\ndiscoveries: noise artifacts of terrestrial origin that contaminate\ngravitational wave observatories' highly sensitive measurements and can obscure\nor even mimic the faint astrophysical signals for which they are listening.\nSpecifically, we demonstrate how a highly interpretable convolutional\nclassifier can automatically learn to detect transient anomalies from auxiliary\ndetector data without needing to observe the anomalies themselves. We also\nillustrate several other useful features of the model, including how it\nperforms automatic variable selection to reduce tens of thousands of auxiliary\ndata channels to only a few relevant ones; how it identifies behavioral\nsignatures predictive of anomalies in those channels; and how it can be used to\ninvestigate individual anomalies and the channels associated with them.",
          "link": "http://arxiv.org/abs/2203.05086",
          "publishedOn": "2022-03-12T00:41:15.112Z",
          "wordCount": 733,
          "title": "Detecting and Diagnosing Terrestrial Gravitational-Wave Mimics Through Feature Learning. (arXiv:2203.05086v1 [astro-ph.IM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05076",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhouib_S/0/1/0/all/0/1\">Sofien Dhouib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maghsudi_S/0/1/0/all/0/1\">Setareh Maghsudi</a>",
          "description": "Recent advances in domain adaptation establish that requiring a low risk on\nthe source domain and equal feature marginals degrade the adaptation's\nperformance. At the same time, empirical evidence shows that incorporating an\nunsupervised target domain term that pushes decision boundaries away from the\nhigh-density regions, along with relaxed alignment, improves adaptation. In\nthis paper, we theoretically justify such observations via a new bound on the\ntarget risk, and we connect two notions of relaxation for divergence, namely\n$\\beta-$relaxed divergences and localization. This connection allows us to\nincorporate the source domain's categorical structure into the relaxation of\nthe considered divergence, provably resulting in a better handling of the label\nshift case in particular.",
          "link": "http://arxiv.org/abs/2203.05076",
          "publishedOn": "2022-03-12T00:41:15.104Z",
          "wordCount": 552,
          "title": "Connecting sufficient conditions for domain adaptation: source-guided uncertainty, relaxed divergences and discrepancy localization. (arXiv:2203.05076v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05117",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Lan_G/0/1/0/all/0/1\">Gaunghui Lan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhe Zhang</a>",
          "description": "This paper studies the communication complexity of risk averse optimization\nover a network. The problem generalizes the well-studied risk-neutral\nfinite-sum distributed optimization problem and its importance stems from the\nneed to handle risk in an uncertain environment. For algorithms in the\nliterature, there exists a gap in communication complexities for solving\nrisk-averse and risk-neutral problems. We propose two distributed algorithms,\nnamely the distributed risk averse optimization (DRAO) method and the\ndistributed risk averse optimization with sliding (DRAO-S) method, to close the\ngap. Specifically, the DRAO method achieves the optimal communication\ncomplexity by assuming a certain saddle point subproblem can be easily solved\nin the server node. The DRAO-S method removes the strong assumption by\nintroducing a novel saddle point sliding subroutine which only requires the\nprojection over the ambiguity set $P$. We observe that the number of\n$P$-projections performed by DRAO-S is optimal. Moreover, we develop matching\nlower complexity bounds to show that communication complexities of both DRAO\nand DRAO-S are not improvable. Numerical experiments are conducted to\ndemonstrate the encouraging empirical performance of the DRAO-S method.",
          "link": "http://arxiv.org/abs/2203.05117",
          "publishedOn": "2022-03-12T00:41:15.097Z",
          "wordCount": 617,
          "title": "Optimal Methods for Risk Averse Distributed Optimization. (arXiv:2203.05117v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Buchanan_S/0/1/0/all/0/1\">Sam Buchanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jingkai Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haber_E/0/1/0/all/0/1\">Ellie Haber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1\">John Wright</a>",
          "description": "Achieving invariance to nuisance transformations is a fundamental challenge\nin the construction of robust and reliable vision systems. Existing approaches\nto invariance scale exponentially with the dimension of the family of\ntransformations, making them unable to cope with natural variabilities in\nvisual data such as changes in pose and perspective. We identify a common\nlimitation of these approaches--they rely on sampling to traverse the\nhigh-dimensional space of transformations--and propose a new computational\nprimitive for building invariant networks based instead on optimization, which\nin many scenarios provides a provably more efficient method for\nhigh-dimensional exploration than sampling. We provide empirical and\ntheoretical corroboration of the efficiency gains and soundness of our proposed\nmethod, and demonstrate its utility in constructing an efficient invariant\nnetwork for a simple hierarchical object detection task when combined with\nunrolled optimization. Code for our networks and experiments is available at\nhttps://github.com/sdbuch/refine.",
          "link": "http://arxiv.org/abs/2203.05006",
          "publishedOn": "2022-03-12T00:41:15.076Z",
          "wordCount": 595,
          "title": "Resource-Efficient Invariant Networks: Exponential Gains by Unrolled Optimization. (arXiv:2203.05006v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05025",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Przewlocka_Rus_D/0/1/0/all/0/1\">Dominika Przewlocka-Rus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarwar_S/0/1/0/all/0/1\">Syed Shakib Sarwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sumbul_H/0/1/0/all/0/1\">H. Ekin Sumbul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuecheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvo_B/0/1/0/all/0/1\">Barbara De Salvo</a>",
          "description": "Deploying Deep Neural Networks in low-power embedded devices for real\ntime-constrained applications requires optimization of memory and computational\ncomplexity of the networks, usually by quantizing the weights. Most of the\nexisting works employ linear quantization which causes considerable degradation\nin accuracy for weight bit widths lower than 8. Since the distribution of\nweights is usually non-uniform (with most weights concentrated around zero),\nother methods, such as logarithmic quantization, are more suitable as they are\nable to preserve the shape of the weight distribution more precise. Moreover,\nusing base-2 logarithmic representation allows optimizing the multiplication by\nreplacing it with bit shifting. In this paper, we explore non-linear\nquantization techniques for exploiting lower bit precision and identify\nfavorable hardware implementation options. We developed the Quantization Aware\nTraining (QAT) algorithm that allowed training of low bit width Power-of-Two\n(PoT) networks and achieved accuracies on par with state-of-the-art floating\npoint models for different tasks. We explored PoT weight encoding techniques\nand investigated hardware designs of MAC units for three different quantization\nschemes - uniform, PoT and Additive-PoT (APoT) - to show the increased\nefficiency when using the proposed approach. Eventually, the experiments showed\nthat for low bit width precision, non-uniform quantization performs better than\nuniform, and at the same time, PoT quantization vastly reduces the\ncomputational complexity of the neural network.",
          "link": "http://arxiv.org/abs/2203.05025",
          "publishedOn": "2022-03-12T00:41:15.067Z",
          "wordCount": 664,
          "title": "Power-of-Two Quantization for Low Bitwidth and Hardware Compliant Neural Networks. (arXiv:2203.05025v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.04961",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Szafranowska_Z/0/1/0/all/0/1\">Zuzanna Szafranowska</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Osuala_R/0/1/0/all/0/1\">Richard Osuala</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Breier_B/0/1/0/all/0/1\">Bennet Breier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kushibar_K/0/1/0/all/0/1\">Kaisar Kushibar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lekadir_K/0/1/0/all/0/1\">Karim Lekadir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Diaz_O/0/1/0/all/0/1\">Oliver Diaz</a>",
          "description": "Early detection of breast cancer in mammography screening via deep-learning\nbased computer-aided detection systems shows promising potential in improving\nthe curability and mortality rates of breast cancer. However, many clinical\ncentres are restricted in the amount and heterogeneity of available data to\ntrain such models to (i) achieve promising performance and to (ii) generalise\nwell across acquisition protocols and domains. As sharing data between centres\nis restricted due to patient privacy concerns, we propose a potential solution:\nsharing trained generative models between centres as substitute for real\npatient data. In this work, we use three well known mammography datasets to\nsimulate three different centres, where one centre receives the trained\ngenerator of Generative Adversarial Networks (GANs) from the two remaining\ncentres in order to augment the size and heterogeneity of its training dataset.\nWe evaluate the utility of this approach on mammography patch classification on\nthe test set of the GAN-receiving centre using two different classification\nmodels, (a) a convolutional neural network and (b) a transformer neural\nnetwork. Our experiments demonstrate that shared GANs notably increase the\nperformance of both transformer and convolutional classification models and\nhighlight this approach as a viable alternative to inter-centre data sharing.",
          "link": "http://arxiv.org/abs/2203.04961",
          "publishedOn": "2022-03-12T00:41:15.044Z",
          "wordCount": 693,
          "title": "Sharing Generative Models Instead of Private Data: A Simulation Study on Mammography Patch Classification. (arXiv:2203.04961v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05012",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sultangazin_A/0/1/0/all/0/1\">Alimzhan Sultangazin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pannocchi_L/0/1/0/all/0/1\">Luigi Pannocchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fraile_L/0/1/0/all/0/1\">Lucas Fraile</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tabuada_P/0/1/0/all/0/1\">Paulo Tabuada</a>",
          "description": "In this paper, we revisit the problem of learning a stabilizing controller\nfrom a finite number of demonstrations by an expert. By first focusing on\nfeedback linearizable systems, we show how to combine expert demonstrations\ninto a stabilizing controller, provided that demonstrations are sufficiently\nlong and there are at least $n+1$ of them, where $n$ is the number of states of\nthe system being controlled. When we have more than $n+1$ demonstrations, we\ndiscuss how to optimally choose the best $n+1$ demonstrations to construct the\nstabilizing controller. We then extend these results to a class of systems that\ncan be embedded into a higher-dimensional system containing a chain of\nintegrators. The feasibility of the proposed algorithm is demonstrated by\napplying it on a CrazyFlie 2.0 quadrotor.",
          "link": "http://arxiv.org/abs/2203.05012",
          "publishedOn": "2022-03-12T00:41:15.031Z",
          "wordCount": 573,
          "title": "Learning to control from expert demonstrations. (arXiv:2203.05012v1 [eess.SY])",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "stat.ML updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/stat.ML",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2103.06428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ibriga_H/0/1/0/all/0/1\">Hilda S Ibriga</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>",
          "description": "We aim to provably complete a sparse and highly-missing tensor in the\npresence of covariate information along tensor modes. Our motivation comes from\nonline advertising where users click-through-rates (CTR) on ads over various\ndevices form a CTR tensor that has about 96% missing entries and has many zeros\non non-missing entries, which makes the standalone tensor completion method\nunsatisfactory. Beside the CTR tensor, additional ad features or user\ncharacteristics are often available. In this paper, we propose\nCovariate-assisted Sparse Tensor Completion (COSTCO) to incorporate covariate\ninformation for the recovery of the sparse tensor. The key idea is to jointly\nextract latent components from both the tensor and the covariate matrix to\nlearn a synthetic representation. Theoretically, we derive the error bound for\nthe recovered tensor components and explicitly quantify the improvements on\nboth the reveal probability condition and the tensor recovery accuracy due to\ncovariates. Finally, we apply COSTCO to an advertisement dataset consisting of\na CTR tensor and ad covariate matrix, leading to 23% accuracy improvement over\nthe baseline. An important by-product is that ad latent components from COSTCO\nreveal interesting ad clusters, which are useful for better ad targeting.",
          "link": "http://arxiv.org/abs/2103.06428",
          "publishedOn": "2022-04-09T00:48:55.162Z",
          "wordCount": 664,
          "title": "Covariate-assisted Sparse Tensor Completion. (arXiv:2103.06428v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03495",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Gordon_M/0/1/0/all/0/1\">Max Hunter Gordon</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cerezo_M/0/1/0/all/0/1\">M. Cerezo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>",
          "description": "Principal component analysis (PCA) is a dimensionality reduction method in\ndata analysis that involves diagonalizing the covariance matrix of the dataset.\nRecently, quantum algorithms have been formulated for PCA based on\ndiagonalizing a density matrix. These algorithms assume that the covariance\nmatrix can be encoded in a density matrix, but a concrete protocol for this\nencoding has been lacking. Our work aims to address this gap. Assuming\namplitude encoding of the data, with the data given by the ensemble $\\{p_i,|\n\\psi_i \\rangle\\}$, then one can easily prepare the ensemble average density\nmatrix $\\overline{\\rho} = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i |$. We first\nshow that $\\overline{\\rho}$ is precisely the covariance matrix whenever the\ndataset is centered. For quantum datasets, we exploit global phase symmetry to\nargue that there always exists a centered dataset consistent with\n$\\overline{\\rho}$, and hence $\\overline{\\rho}$ can always be interpreted as a\ncovariance matrix. This provides a simple means for preparing the covariance\nmatrix for arbitrary quantum datasets or centered classical datasets. For\nuncentered classical datasets, our method is so-called \"PCA without centering\",\nwhich we interpret as PCA on a symmetrized dataset. We argue that this closely\ncorresponds to standard PCA, and we derive equations and inequalities that\nbound the deviation of the spectrum obtained with our method from that of\nstandard PCA. We numerically illustrate our method for the MNIST handwritten\ndigit dataset. We also argue that PCA on quantum datasets is natural and\nmeaningful, and we numerically implement our method for molecular ground-state\ndatasets.",
          "link": "http://arxiv.org/abs/2204.03495",
          "publishedOn": "2022-04-09T00:48:55.140Z",
          "wordCount": 702,
          "title": "Covariance matrix preparation for quantum principal component analysis. (arXiv:2204.03495v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.07896",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Esteban_Perez_A/0/1/0/all/0/1\">Adri&#xe1;n Esteban-P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Morales_J/0/1/0/all/0/1\">Juan M. Morales</a>",
          "description": "In this paper, we develop a distributionally robust chance-constrained\nformulation of the Optimal Power Flow problem (OPF) whereby the system operator\ncan leverage contextual information. For this purpose, we exploit an ambiguity\nset based on probability trimmings and optimal transport through which the\ndispatch solution is protected against the incomplete knowledge of the\nrelationship between the OPF uncertainties and the context that is conveyed by\na sample of their joint probability distribution. We provide a tractable\nreformulation of the proposed distributionally robust chance-constrained OPF\nproblem under the popular conditional-value-at-risk approximation. By way of\nnumerical experiments run on a modified IEEE-118 bus network with wind\nuncertainty, we show how the power system can substantially benefit from taking\ninto account the well-known statistical dependence between the point forecast\nof wind power outputs and its associated prediction error. Furthermore, the\nexperiments conducted also reveal that the distributional robustness conferred\non the OPF solution by our probability-trimmings-based approach is superior to\nthat bestowed by alternative approaches in terms of expected cost and system\nreliability.",
          "link": "http://arxiv.org/abs/2109.07896",
          "publishedOn": "2022-04-09T00:48:55.132Z",
          "wordCount": 629,
          "title": "Distributionally Robust Optimal Power Flow with Contextual Information. (arXiv:2109.07896v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01533",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cuesta_Ramirez_J/0/1/0/all/0/1\">Jhouben Cuesta-Ramirez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Riche_R/0/1/0/all/0/1\">Rodolphe Le Riche</a>, <a href=\"http://arxiv.org/find/math/1/au:+Roustant_O/0/1/0/all/0/1\">Olivier Roustant</a>, <a href=\"http://arxiv.org/find/math/1/au:+Perrin_G/0/1/0/all/0/1\">Guillaume Perrin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Durantin_C/0/1/0/all/0/1\">Cedric Durantin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gliere_A/0/1/0/all/0/1\">Alain Gliere</a>",
          "description": "Most real optimization problems are defined over a mixed search space where\nthe variables are both discrete and continuous. In engineering applications,\nthe objective function is typically calculated with a numerically costly\nblack-box simulation.General mixed and costly optimization problems are\ntherefore of a great practical interest, yet their resolution remains in a\nlarge part an open scientific question. In this article, costly mixed problems\nare approached through Gaussian processes where the discrete variables are\nrelaxed into continuous latent variables. The continuous space is more easily\nharvested by classical Bayesian optimization techniques than a mixed space\nwould. Discrete variables are recovered either subsequently to the continuous\noptimization, or simultaneously with an additional continuous-discrete\ncompatibility constraint that is handled with augmented Lagrangians. Several\npossible implementations of such Bayesian mixed optimizers are compared. In\nparticular, the reformulation of the problem with continuous latent variables\nis put in competition with searches working directly in the mixed space. Among\nthe algorithms involving latent variables and an augmented Lagrangian, a\nparticular attention is devoted to the Lagrange multipliers for which a local\nand a global estimation techniques are studied. The comparisons are based on\nthe repeated optimization of three analytical functions and a beam design\nproblem.",
          "link": "http://arxiv.org/abs/2111.01533",
          "publishedOn": "2022-04-09T00:48:55.116Z",
          "wordCount": 683,
          "title": "A comparison of mixed-variables Bayesian optimization approaches. (arXiv:2111.01533v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1906.06717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vasic_M/0/1/0/all/0/1\">Marko Vasic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrovic_A/0/1/0/all/0/1\">Andrija Petrovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kaiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolic_M/0/1/0/all/0/1\">Mladen Nikolic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rishabh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurshid_S/0/1/0/all/0/1\">Sarfraz Khurshid</a>",
          "description": "Rapid advancements in deep learning have led to many recent breakthroughs.\nWhile deep learning models achieve superior performance, often statistically\nbetter than humans, their adoption into safety-critical settings, such as\nhealthcare or self-driving cars is hindered by their inability to provide\nsafety guarantees or to expose the inner workings of the model in a human\nunderstandable form. We present Mo\\\"ET, a novel model based on Mixture of\nExperts, consisting of decision tree experts and a generalized linear model\ngating function. Thanks to such gating function the model is more expressive\nthan the standard decision tree. To support non-differentiable decision trees\nas experts, we formulate a novel training procedure. In addition, we introduce\na hard thresholding version, Mo\\\"ETH, in which predictions are made solely by a\nsingle expert chosen via the gating function. Thanks to that property, Mo\\\"ETH\nallows each prediction to be easily decomposed into a set of logical rules in a\nform which can be easily verified. While Mo\\\"ET is a general use model, we\nillustrate its power in the reinforcement learning setting. By training Mo\\\"ET\nmodels using an imitation learning procedure on deep RL agents we outperform\nthe previous state-of-the-art technique based on decision trees while\npreserving the verifiability of the models. Moreover, we show that Mo\\\"ET can\nalso be used in real-world supervised problems on which it outperforms other\nverifiable machine learning models.",
          "link": "http://arxiv.org/abs/1906.06717",
          "publishedOn": "2022-04-09T00:48:55.098Z",
          "wordCount": 750,
          "title": "Mo\\\"ET: Mixture of Expert Trees and its Application to Verifiable Reinforcement Learning. (arXiv:1906.06717v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yuxin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neiswanger_W/0/1/0/all/0/1\">Willie Neiswanger</a>",
          "description": "With the surge in the number of hyperparameters and training times of modern\nmachine learning models, hyperparameter tuning is becoming increasingly\nexpensive. However, after assessing 40 tuning methods systematically, we find\nthat each faces certain limitations. In particular, methods that speed up\ntuning via knowledge transfer typically require the final performance of\nhyperparameters and do not focus on low-fidelity information. As we demonstrate\nempirically, this common practice is suboptimal and can incur an unnecessary\nuse of resources. It is more cost-efficient to instead leverage low-fidelity\ntuning observations to measure inter-task similarity and transfer knowledge\nfrom existing to new tasks accordingly. However, performing multi-fidelity\ntuning comes with its own challenges in the transfer setting: the noise in\nadditional observations and the need for performance forecasting. Therefore, we\npropose and conduct a thorough analysis of a multi-task multi-fidelity Bayesian\noptimization framework, which leads to the best instantiation--amortized\nauto-tuning (AT2). We further present an offline-computed 27-task\nhyperparameter recommendation (HyperRec) database to serve the community.\nExtensive experiments on HyperRec and other real-world databases illustrate the\neffectiveness of our AT2 method.",
          "link": "http://arxiv.org/abs/2106.09179",
          "publishedOn": "2022-04-09T00:48:55.076Z",
          "wordCount": 647,
          "title": "Amortized Auto-Tuning: Cost-Efficient Bayesian Transfer Optimization for Hyperparameter Recommendation. (arXiv:2106.09179v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_J/0/1/0/all/0/1\">Jeffrey Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_R/0/1/0/all/0/1\">Rajat Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tumma_N/0/1/0/all/0/1\">Neehal Tumma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhishek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "Topic models are some of the most popular ways to represent textual data in\nan interpret-able manner. Recently, advances in deep generative models,\nspecifically auto-encoding variational Bayes (AEVB), have led to the\nintroduction of unsupervised neural topic models, which leverage deep\ngenerative models as opposed to traditional statistics-based topic models. We\nextend upon these neural topic models by introducing the Label-Indexed Neural\nTopic Model (LI-NTM), which is, to the extent of our knowledge, the first\neffective upstream semi-supervised neural topic model. We find that LI-NTM\noutperforms existing neural topic models in document reconstruction benchmarks,\nwith the most notable results in low labeled data regimes and for data-sets\nwith informative labels; furthermore, our jointly learned classifier\noutperforms baseline classifiers in ablation studies.",
          "link": "http://arxiv.org/abs/2204.03208",
          "publishedOn": "2022-04-09T00:48:55.069Z",
          "wordCount": 586,
          "title": "A Joint Learning Approach for Semi-supervised Neural Topic Modeling. (arXiv:2204.03208v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.09745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1\">Sivakanth Gopi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulhane_P/0/1/0/all/0/1\">Pankaj Gulhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1\">Janardhan Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Judy Hanwen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yekhanin_S/0/1/0/all/0/1\">Sergey Yekhanin</a>",
          "description": "We study the basic operation of set union in the global model of differential\nprivacy. In this problem, we are given a universe $U$ of items, possibly of\ninfinite size, and a database $D$ of users. Each user $i$ contributes a subset\n$W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially\nprivate algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the\nsize of $S$ is as large as possible. The problem arises in countless real world\napplications; it is particularly ubiquitous in natural language processing\n(NLP) applications as vocabulary extraction. For example, discovering words,\nsentences, $n$-grams etc., from private text data belonging to users is an\ninstance of the set union problem.\n\nKnown algorithms for this problem proceed by collecting a subset of items\nfrom each user, taking the union of such subsets, and disclosing the items\nwhose noisy counts fall above a certain threshold. Crucially, in the above\nprocess, the contribution of each individual user is always independent of the\nitems held by other users, resulting in a wasteful aggregation process, where\nsome item counts happen to be way above the threshold. We deviate from the\nabove paradigm by allowing users to contribute their items in a\n$\\textit{dependent fashion}$, guided by a $\\textit{policy}$. In this new\nsetting ensuring privacy is significantly delicate. We prove that any policy\nwhich has certain $\\textit{contractive}$ properties would result in a\ndifferentially private algorithm. We design two new algorithms, one using\nLaplace noise and other Gaussian noise, as specific instances of policies\nsatisfying the contractive properties. Our experiments show that the new\nalgorithms significantly outperform previously known mechanisms for the\nproblem.",
          "link": "http://arxiv.org/abs/2002.09745",
          "publishedOn": "2022-04-09T00:48:55.060Z",
          "wordCount": 754,
          "title": "Differentially Private Set Union. (arXiv:2002.09745v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krug_A/0/1/0/all/0/1\">Andreas Krug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratul_R/0/1/0/all/0/1\">Raihan Kabir Ratul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stober_S/0/1/0/all/0/1\">Sebastian Stober</a>",
          "description": "Machine Learning with Deep Neural Networks (DNNs) has become a successful\ntool in solving tasks across various fields of application. The success of DNNs\nis strongly connected to their high complexity in terms of the number of\nnetwork layers or of neurons in each layer, which severely complicates to\nunderstand how DNNs solve their learned task. To improve the explainability of\nDNNs, we adapt methods from neuroscience because this field has a rich\nexperience in analyzing complex and opaque systems. In this work, we draw\ninspiration from how neuroscience uses topographic maps to visualize the\nactivity of the brain when it performs certain tasks. Transferring this\napproach to DNNs can help to visualize and understand their internal processes\nmore intuitively, too. However, the inner structures of brains and DNNs differ\nsubstantially. Therefore, to be able to visualize activations of neurons in\nDNNs as topographic maps, we research techniques to layout the neurons in a\ntwo-dimensional space in which neurons of similar activity are in the vicinity\nof each other. In this work, we introduce and compare different methods to\nobtain a topographic layout of the neurons in a network layer. Moreover, we\ndemonstrate how to use the resulting topographic activation maps to identify\nerrors or encoded biases in DNNs or data sets. Our novel visualization\ntechnique improves the transparency of DNN-based algorithmic decision-making\nsystems and is accessible to a broad audience because topographic maps are\nintuitive to interpret without expert-knowledge in Machine Learning.",
          "link": "http://arxiv.org/abs/2204.03528",
          "publishedOn": "2022-04-09T00:48:55.052Z",
          "wordCount": null,
          "title": "Visualizing Deep Neural Networks with Topographic Activation Maps. (arXiv:2204.03528v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1\">Leon Bottou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>",
          "description": "Regularization is a fundamental technique to prevent over-fitting and to\nimprove generalization performances by constraining a model's complexity.\nCurrent Deep Networks heavily rely on regularizers such as Data-Augmentation\n(DA) or weight-decay, and employ structural risk minimization, i.e.\ncross-validation, to select the optimal regularization hyper-parameters. In\nthis study, we demonstrate that techniques such as DA or weight decay produce a\nmodel with a reduced complexity that is unfair across classes. The optimal\namount of DA or weight decay found from cross-validation leads to disastrous\nmodel performances on some classes e.g. on Imagenet with a resnet50, the \"barn\nspider\" classification test accuracy falls from $68\\%$ to $46\\%$ only by\nintroducing random crop DA during training. Even more surprising, such\nperformance drop also appears when introducing uninformative regularization\ntechniques such as weight decay. Those results demonstrate that our search for\never increasing generalization performance -- averaged over all classes and\nsamples -- has left us with models and regularizers that silently sacrifice\nperformances on some classes. This scenario can become dangerous when deploying\na model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on\nINaturalist sees its performances fall from $70\\%$ to $30\\%$ on class \\#8889\nwhen introducing random crop DA during the Imagenet pre-training phase. Those\nresults demonstrate that designing novel regularizers without class-dependent\nbias remains an open research question.",
          "link": "http://arxiv.org/abs/2204.03632",
          "publishedOn": "2022-04-09T00:48:55.052Z",
          "wordCount": null,
          "title": "The Effects of Regularization and Data Augmentation are Class Dependent. (arXiv:2204.03632v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03406",
          "author": "<a href=\"http://arxiv.org/find/hep-th/1/au:+Loukas_O/0/1/0/all/0/1\">Orestis Loukas</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Chung_H/0/1/0/all/0/1\">Ho Ryun Chung</a>",
          "description": "The estimation of categorical distributions under marginal constraints\nsummarizing some sample from a population in the most-generalizable way is key\nfor many machine-learning and data-driven approaches. We provide a\nparameter-agnostic theoretical framework that enables this task ensuring (i)\nthat a categorical distribution of Maximum Entropy under marginal constraints\nalways exists and (ii) that it is unique. The procedure of iterative\nproportional fitting (IPF) naturally estimates that distribution from any\nconsistent set of marginal constraints directly in the space of probabilities,\nthus deductively identifying a least-biased characterization of the population.\nThe theoretical framework together with IPF leads to a holistic workflow that\nenables modeling any class of categorical distributions solely using the\nphenomenological information provided.",
          "link": "http://arxiv.org/abs/2204.03406",
          "publishedOn": "2022-04-09T00:48:55.049Z",
          "wordCount": 565,
          "title": "Categorical Distributions of Maximum Entropy under Marginal Constraints. (arXiv:2204.03406v1 [hep-th])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_T/0/1/0/all/0/1\">Tristan Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1\">Edward J. Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahlou_S/0/1/0/all/0/1\">Salem Lahlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_M/0/1/0/all/0/1\">Mo Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1\">Emmanuel Bengio</a>",
          "description": "Generative Flow Networks (GFlowNets) have been introduced as a method to\nsample a diverse set of candidates in an active learning context, with a\ntraining objective that makes them approximately sample in proportion to a\ngiven reward function. In this paper, we show a number of additional\ntheoretical properties of GFlowNets. They can be used to estimate joint\nprobability distributions and the corresponding marginal distributions where\nsome variables are unspecified and, of particular interest, can represent\ndistributions over composite objects like sets and graphs. GFlowNets amortize\nthe work typically done by computationally expensive MCMC methods in a single\nbut trained generative pass. They could also be used to estimate partition\nfunctions and free energies, conditional probabilities of supersets\n(supergraphs) given a subset (subgraph), as well as marginal distributions over\nall supersets (supergraphs) of a given set (graph). We introduce variations\nenabling the estimation of entropy and mutual information, sampling from a\nPareto frontier, connections to reward-maximizing policies, and extensions to\nstochastic environments, continuous actions and modular energy functions.",
          "link": "http://arxiv.org/abs/2111.09266",
          "publishedOn": "2022-04-09T00:48:55.042Z",
          "wordCount": 632,
          "title": "GFlowNet Foundations. (arXiv:2111.09266v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05845",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Simpson_I/0/1/0/all/0/1\">Ivor J.A. Simpson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McManamon_A/0/1/0/all/0/1\">Ashley McManamon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Orzsik_B/0/1/0/all/0/1\">Bal&#xe1;zs &#xd6;rzsik</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stone_A/0/1/0/all/0/1\">Alan J. Stone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blockley_N/0/1/0/all/0/1\">Nicholas P. Blockley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asllani_I/0/1/0/all/0/1\">Iris Asllani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Colasanti_A/0/1/0/all/0/1\">Alessandro Colasanti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cercignani_M/0/1/0/all/0/1\">Mara Cercignani</a>",
          "description": "Streamlined qBOLD acquisitions enable experimentally straightforward\nobservations of brain oxygen metabolism. $R_2^\\prime$ maps are easily inferred;\nhowever, the Oxygen extraction fraction (OEF) and deoxygenated blood volume\n(DBV) are more ambiguously determined from the data. As such, existing\ninference methods tend to yield very noisy and underestimated OEF maps, while\noverestimating DBV.\n\nThis work describes a novel probabilistic machine learning approach that can\ninfer plausible distributions of OEF and DBV. Initially, we create a model that\nproduces informative voxelwise prior distribution based on synthetic training\ndata. Contrary to prior work, we model the joint distribution of OEF and DBV\nthrough a scaled multivariate logit-Normal distribution, which enables the\nvalues to be constrained within a plausible range. The prior distribution model\nis used to train an efficient amortized variational Bayesian inference model.\nThis model learns to infer OEF and DBV by predicting real image data, with few\ntraining data required, using the signal equations as a forward model.\n\nWe demonstrate that our approach enables the inference of smooth OEF and DBV\nmaps, with a physiologically plausible distribution that can be adapted through\nspecification of an informative prior distribution. Other benefits include\nmodel comparison (via the evidence lower bound) and uncertainty quantification\nfor identifying image artefacts. Results are demonstrated on a small study\ncomparing subjects undergoing hyperventilation and at rest. We illustrate that\nthe proposed approach allows measurement of gray matter differences in OEF and\nDBV and enables voxelwise comparison between conditions, where we observe\nsignificant increases in OEF and $R_2^\\prime$ during hyperventilation.",
          "link": "http://arxiv.org/abs/2203.05845",
          "publishedOn": "2022-04-09T00:48:55.020Z",
          "wordCount": 733,
          "title": "Flexible Amortized Variational Inference in qBOLD MRI. (arXiv:2203.05845v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.15783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polk_S/0/1/0/all/0/1\">Sam L. Polk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_J/0/1/0/all/0/1\">James M. Murphy</a>",
          "description": "Clustering algorithms partition a dataset into groups of similar points. The\nprimary contribution of this article is the Multiscale Spatially-Regularized\nDiffusion Learning (M-SRDL) clustering algorithm, which uses\nspatially-regularized diffusion distances to efficiently and accurately learn\nmultiple scales of latent structure in hyperspectral images. The M-SRDL\nclustering algorithm extracts clusterings at many scales from a hyperspectral\nimage and outputs these clusterings' variation of information-barycenter as an\nexemplar for all underlying cluster structure. We show that incorporating\nspatial regularization into a multiscale clustering framework results in\nsmoother and more coherent clusters when applied to hyperspectral data,\nyielding more accurate clustering labels.",
          "link": "http://arxiv.org/abs/2103.15783",
          "publishedOn": "2022-04-09T00:48:55.011Z",
          "wordCount": 581,
          "title": "Multiscale Clustering of Hyperspectral Images Through Spectral-Spatial Diffusion Geometry. (arXiv:2103.15783v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03562",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cheng_K/0/1/0/all/0/1\">Kai Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zimmermann_R/0/1/0/all/0/1\">Ralf Zimmermann</a>",
          "description": "Gradient-enhanced Kriging (GE-Kriging) is a well-established surrogate\nmodelling technique for approximating expensive computational models. However,\nit tends to get impractical for high-dimensional problems due to the large\ninherent correlation matrix and the associated high-dimensional hyper-parameter\ntuning problem. To address these issues, we propose a new method in this paper,\ncalled sliced GE-Kriging (SGE-Kriging) for reducing both the size of the\ncorrelation matrix and the number of hyper-parameters. Firstly, we perform a\nderivative-based global sensitivity analysis to detect the relative importance\nof each input variable with respect to model response. Then, we propose to\nsplit the training sample set into multiple slices, and invoke Bayes' theorem\nto approximate the full likelihood function via a sliced likelihood function,\nin which multiple small correlation matrices are utilized to describe the\ncorrelation of the sample set. Additionally, we replace the original\nhigh-dimensional hyper-parameter tuning problem with a low-dimensional\ncounterpart by learning the relationship between the hyper-parameters and the\nglobal sensitivity indices. Finally, we validate SGE-Kriging by means of\nnumerical experiments with several benchmarks problems. The results show that\nthe SGE-Kriging model features an accuracy and robustness that is comparable to\nthe standard one but comes at much less training costs. The benefits are most\nevident in high-dimensional problems.",
          "link": "http://arxiv.org/abs/2204.03562",
          "publishedOn": "2022-04-09T00:48:54.964Z",
          "wordCount": null,
          "title": "Sliced gradient-enhanced Kriging for high-dimensional function approximation. (arXiv:2204.03562v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.11079",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Leiner_J/0/1/0/all/0/1\">James Leiner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duan_B/0/1/0/all/0/1\">Boyan Duan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wasserman_L/0/1/0/all/0/1\">Larry Wasserman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "Suppose we observe a random vector $X$ from some distribution $P$ in a known\nfamily with unknown parameters. We ask the following question: when is it\npossible to split $X$ into two parts $f(X)$ and $g(X)$ such that neither part\nis sufficient to reconstruct $X$ by itself, but both together can recover $X$\nfully, and the joint distribution of $(f(X),g(X))$ is tractable? As one\nexample, if $X=(X_1,\\dots,X_n)$ and $P$ is a product distribution, then for any\n$m<n$, we can split the sample to define $f(X)=(X_1,\\dots,X_m)$ and\n$g(X)=(X_{m+1},\\dots,X_n)$. Rasines and Young (2021) offers an alternative\nroute of accomplishing this task through randomization of $X$ with additive\nGaussian noise which enables post-selection inference in finite samples for\nGaussian distributed data and asymptotically for non-Gaussian additive models.\nIn this paper, we offer a more general methodology for achieving such a split\nin finite samples by borrowing ideas from Bayesian inference to yield a\n(frequentist) solution that can be viewed as a continuous analog of data\nsplitting. We call our method data blurring, as an alternative to data\nsplitting, data carving and p-value masking. We exemplify the method on a few\nprototypical applications, such as post-selection inference for trend filtering\nand other regression problems.",
          "link": "http://arxiv.org/abs/2112.11079",
          "publishedOn": "2022-04-09T00:48:54.964Z",
          "wordCount": null,
          "title": "Data blurring: sample splitting a single sample. (arXiv:2112.11079v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.03706",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ramprasad_P/0/1/0/all/0/1\">Pratik Ramprasad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yuantong Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1\">Guang Cheng</a>",
          "description": "The recent emergence of reinforcement learning has created a demand for\nrobust statistical inference methods for the parameter estimates computed using\nthese algorithms. Existing methods for statistical inference in online learning\nare restricted to settings involving independently sampled observations, while\nexisting statistical inference methods in reinforcement learning (RL) are\nlimited to the batch setting. The online bootstrap is a flexible and efficient\napproach for statistical inference in linear stochastic approximation\nalgorithms, but its efficacy in settings involving Markov noise, such as RL,\nhas yet to be explored. In this paper, we study the use of the online bootstrap\nmethod for statistical inference in RL. In particular, we focus on the temporal\ndifference (TD) learning and Gradient TD (GTD) learning algorithms, which are\nthemselves special instances of linear stochastic approximation under Markov\nnoise. The method is shown to be distributionally consistent for statistical\ninference in policy evaluation, and numerical experiments are included to\ndemonstrate the effectiveness of this algorithm at statistical inference tasks\nacross a range of real RL environments.",
          "link": "http://arxiv.org/abs/2108.03706",
          "publishedOn": "2022-04-09T00:48:54.961Z",
          "wordCount": 673,
          "title": "Online Bootstrap Inference For Policy Evaluation in Reinforcement Learning. (arXiv:2108.03706v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.14836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhun Deng</a>",
          "description": "Representations of the world environment play a crucial role in artificial\nintelligence. It is often inefficient to conduct reasoning and inference\ndirectly in the space of raw sensory representations, such as pixel values of\nimages. Representation learning allows us to automatically discover suitable\nrepresentations from raw sensory data. For example, given raw sensory data, a\ndeep neural network learns nonlinear representations at its hidden layers,\nwhich are subsequently used for classification at its output layer. This\nhappens implicitly during training through minimizing a supervised or\nunsupervised loss. In this paper, we study the dynamics of such implicit\nnonlinear representation learning. We identify a pair of a new assumption and a\nnovel condition, called the common model structure assumption and the\ndata-architecture alignment condition. Under the common model structure\nassumption, the data-architecture alignment condition is shown to be sufficient\nfor the global convergence and necessary for the global optimality. Moreover,\nour theory explains how and when increasing the network size does and does not\nimprove the training behaviors in the practical regime. Our results provide\npractical guidance for designing a model structure: e.g., the common model\nstructure assumption can be used as a justification for using a particular\nmodel structure instead of others. We also derive a new training framework,\nwhich satisfies the data-architecture alignment condition by automatically\nmodifying any given training algorithm. Given a standard training algorithm,\nthe framework running its modified version is empirically shown to maintain\ncompetitive test performances while providing global convergence guarantees for\ndeep residual neural networks with convolutions, skip connections, and batch\nnormalization with datasets, including MNIST, CIFAR-10, CIFAR-100, Semeion,\nKMNIST and SVHN.",
          "link": "http://arxiv.org/abs/2106.14836",
          "publishedOn": "2022-04-09T00:48:54.953Z",
          "wordCount": 777,
          "title": "Understanding Dynamics of Nonlinear Representation Learning and Its Application. (arXiv:2106.14836v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daesoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aune_E/0/1/0/all/0/1\">Erlend Aune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langet_N/0/1/0/all/0/1\">Nad&#xe8;ge Langet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eidsvik_J/0/1/0/all/0/1\">Jo Eidsvik</a>",
          "description": "One of the latest self-supervised learning (SSL) methods, VICReg, showed a\ngreat performance both in the linear evaluation and the fine-tuning evaluation.\nHowever, VICReg is proposed in computer vision and it learns by pulling\nrepresentations of random crops of an image while maintaining the\nrepresentation space by the variance and covariance loss. However, VICReg would\nbe ineffective on non-stationary time series where different parts/crops of\ninput should be differently encoded to consider the non-stationarity. Another\nrecent SSL proposal, Temporal Neighborhood Coding (TNC) is effective for\nencoding non-stationary time series. This study shows that a combination of a\nVICReg-style method and TNC is very effective for SSL on non-stationary time\nseries, where a non-stationary seismic signal time series is used as an\nevaluation dataset.",
          "link": "http://arxiv.org/abs/2204.02697",
          "publishedOn": "2022-04-09T00:48:54.916Z",
          "wordCount": 592,
          "title": "VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance Evaluated on Non-stationary Seismic Signal Time Series. (arXiv:2204.02697v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.02601",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lock_E/0/1/0/all/0/1\">Eric F. Lock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_J/0/1/0/all/0/1\">Jun Young Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hoadley_K/0/1/0/all/0/1\">Katherine A. Hoadley</a>",
          "description": "Several modern applications require the integration of multiple large data\nmatrices that have shared rows and/or columns. For example, cancer studies that\nintegrate multiple omics platforms across multiple types of cancer, pan-omics\npan-cancer analysis, have extended our knowledge of molecular heterogenity\nbeyond what was observed in single tumor and single platform studies. However,\nthese studies have been limited by available statistical methodology. We\npropose a flexible approach to the simultaneous factorization and decomposition\nof variation across such bidimensionally linked matrices, BIDIFAC+. This\ndecomposes variation into a series of low-rank components that may be shared\nacross any number of row sets (e.g., omics platforms) or column sets (e.g.,\ncancer types). This builds on a growing literature for the factorization and\ndecomposition of linked matrices, which has primarily focused on multiple\nmatrices that are linked in one dimension (rows or columns) only. Our objective\nfunction extends nuclear norm penalization, is motivated by random matrix\ntheory, gives an identifiable decomposition under relatively mild conditions,\nand can be shown to give the mode of a Bayesian posterior distribution. We\napply BIDIFAC+ to pan-omics pan-cancer data from TCGA, identifying shared and\nspecific modes of variability across 4 different omics platforms and 29\ndifferent cancer types.",
          "link": "http://arxiv.org/abs/2002.02601",
          "publishedOn": "2022-04-09T00:48:54.898Z",
          "wordCount": 683,
          "title": "Bidimensional linked matrix factorization for pan-omics pan-cancer analysis. (arXiv:2002.02601v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2004.10888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shangtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "We present a mean-variance policy iteration (MVPI) framework for risk-averse\ncontrol in a discounted infinite horizon MDP optimizing the variance of a\nper-step reward random variable. MVPI enjoys great flexibility in that any\npolicy evaluation method and risk-neutral control method can be dropped in for\nrisk-averse control off the shelf, in both on- and off-policy settings. This\nflexibility reduces the gap between risk-neutral control and risk-averse\ncontrol and is achieved by working on a novel augmented MDP directly. We\npropose risk-averse TD3 as an example instantiating MVPI, which outperforms\nvanilla TD3 and many previous risk-averse control methods in challenging Mujoco\nrobot simulation tasks under a risk-aware performance metric. This risk-averse\nTD3 is the first to introduce deterministic policies and off-policy learning\ninto risk-averse reinforcement learning, both of which are key to the\nperformance boost we show in Mujoco domains.",
          "link": "http://arxiv.org/abs/2004.10888",
          "publishedOn": "2022-04-09T00:48:54.883Z",
          "wordCount": 644,
          "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning. (arXiv:2004.10888v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03145",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saragadam_V/0/1/0/all/0/1\">Vishwanath Saragadam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Veeraraghavan_A/0/1/0/all/0/1\">Ashok Veeraraghavan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>",
          "description": "DeepTensor is a computationally efficient framework for low-rank\ndecomposition of matrices and tensors using deep generative networks. We\ndecompose a tensor as the product of low-rank tensor factors (e.g., a matrix as\nthe outer product of two vectors), where each low-rank tensor is generated by a\ndeep network (DN) that is trained in a self-supervised manner to minimize the\nmean-squared approximation error. Our key observation is that the implicit\nregularization inherent in DNs enables them to capture nonlinear signal\nstructures (e.g., manifolds) that are out of the reach of classical linear\nmethods like the singular value decomposition (SVD) and principal component\nanalysis (PCA). Furthermore, in contrast to the SVD and PCA, whose performance\ndeteriorates when the tensor's entries deviate from additive white Gaussian\nnoise, we demonstrate that the performance of DeepTensor is robust to a wide\nrange of distributions. We validate that DeepTensor is a robust and\ncomputationally efficient drop-in replacement for the SVD, PCA, nonnegative\nmatrix factorization (NMF), and similar decompositions by exploring a range of\nreal-world applications, including hyperspectral image denoising, 3D MRI\ntomography, and image classification. In particular, DeepTensor offers a 6dB\nsignal-to-noise ratio improvement over standard denoising methods for signals\ncorrupted by Poisson noise and learns to decompose 3D tensors 60 times faster\nthan a single DN equipped with 3D convolutions.",
          "link": "http://arxiv.org/abs/2204.03145",
          "publishedOn": "2022-04-09T00:48:53.175Z",
          "wordCount": 659,
          "title": "DeepTensor: Low-Rank Tensor Decomposition with Deep Network Priors. (arXiv:2204.03145v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03193",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiahao Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Shiqi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1\">Guang Lin</a>",
          "description": "A new data-driven method for operator learning of stochastic differential\nequations(SDE) is proposed in this paper. The central goal is to solve forward\nand inverse stochastic problems more effectively using limited data. Deep\noperator network(DeepONet) has been proposed recently for operator learning.\nCompared to other neural networks to learn functions, it aims at the problem of\nlearning nonlinear operators. However, it can be challenging by using the\noriginal model to learn nonlinear operators for high-dimensional stochastic\nproblems. We propose a new multi-resolution autoencoder DeepONet model referred\nto as MultiAuto-DeepONet to deal with this difficulty with the aid of\nconvolutional autoencoder. The encoder part of the network is designed to\nreduce the dimensionality as well as discover the hidden features of\nhigh-dimensional stochastic inputs. The decoder is designed to have a special\nstructure, i.e. in the form of DeepONet. The first DeepONet in decoder is\ndesigned to reconstruct the input function involving randomness while the\nsecond one is used to approximate the solution of desired equations. Those two\nDeepONets has a common branch net and two independent trunk nets. This\narchitecture enables us to deal with multi-resolution inputs naturally. By\nadding $L_1$ regularization to our network, we found the outputs from the\nbranch net and two trunk nets all have sparse structures. This reduces the\nnumber of trainable parameters in the neural network thus making the model more\nefficient. Finally, we conduct several numerical experiments to illustrate the\neffectiveness of our proposed MultiAuto-DeepONet model with uncertainty\nquantification.",
          "link": "http://arxiv.org/abs/2204.03193",
          "publishedOn": "2022-04-09T00:48:53.167Z",
          "wordCount": 705,
          "title": "MultiAuto-DeepONet: A Multi-resolution Autoencoder DeepONet for Nonlinear Dimension Reduction, Uncertainty Quantification and Operator Learning of Forward and Inverse Stochastic Problems. (arXiv:2204.03193v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03123",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+John_M/0/1/0/all/0/1\">Majnu John</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vettam_S/0/1/0/all/0/1\">Sujit Vettam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yihren Wu</a>",
          "description": "Nonconvex penalties are utilized for regularization in high-dimensional\nstatistical learning algorithms primarily because they yield unbiased or nearly\nunbiased estimators for the parameters in the model. Nonconvex penalties\nexisting in the literature such as SCAD, MCP, Laplace and arctan have a\nsingularity at origin which makes them useful also for variable selection.\nHowever, in several high-dimensional frameworks such as deep learning, variable\nselection is less of a concern. In this paper, we present a nonconvex penalty\nwhich is smooth at origin. The paper includes asymptotic results for ordinary\nleast squares estimators regularized with the new penalty function, showing\nasymptotic bias that vanishes exponentially fast. We also conducted an\nempirical study employing deep neural network architecture on three datasets\nand convolutional neural network on four datasets. The empirical study showed\nbetter performance for the new regularization approach in five out of the seven\ndatasets.",
          "link": "http://arxiv.org/abs/2204.03123",
          "publishedOn": "2022-04-09T00:48:53.143Z",
          "wordCount": 594,
          "title": "A novel nonconvex, smooth-at-origin penalty for statistical learning. (arXiv:2204.03123v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barkhof_C/0/1/0/all/0/1\">Claartje Barkhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1\">Wilker Aziz</a>",
          "description": "We propose a framework for the statistical evaluation of variational\nauto-encoders (VAEs) and test two instances of this framework in the context of\nmodelling images of handwritten digits and a corpus of English text. Our take\non evaluation is based on the idea of statistical model criticism, popular in\nBayesian data analysis, whereby a statistical model is evaluated in terms of\nits ability to reproduce statistics of an unknown data generating process from\nwhich we can obtain samples. A VAE learns not one, but two joint distributions\nover a shared sample space, each exploiting a choice of factorisation that\nmakes sampling tractable in one of two directions (latent-to-data,\ndata-to-latent). We evaluate samples from these distributions, assessing their\n(marginal) fit to the observed data and our choice of prior, and we also\nevaluate samples through a pipeline that connects the two distributions\nstarting from a data sample, assessing whether together they exploit and reveal\nlatent factors of variation that are useful to a practitioner. We show that\nthis methodology offers possibilities for model selection qualitatively beyond\nintrinsic evaluation metrics and at a finer granularity than commonly used\nstatistics can offer.",
          "link": "http://arxiv.org/abs/2204.03030",
          "publishedOn": "2022-04-09T00:48:53.135Z",
          "wordCount": 625,
          "title": "Statistical Model Criticism of Variational Auto-Encoders. (arXiv:2204.03030v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulynych_B/0/1/0/all/0/1\">Bogdan Kulynych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yao-Yuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1\">Jaros&#x142;aw B&#x142;asiok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1\">Preetum Nakkiran</a>",
          "description": "We investigate and leverage a connection between Differential Privacy (DP)\nand the recently proposed notion of Distributional Generalization (DG).\nApplying this connection, we introduce new conceptual tools for designing\ndeep-learning methods that bypass \"pathologies\" of standard stochastic gradient\ndescent (SGD). First, we prove that differentially private methods satisfy a\n\"What You See Is What You Get (WYSIWYG)\" generalization guarantee: whatever a\nmodel does on its train data is almost exactly what it will do at test time.\nThis guarantee is formally captured by distributional generalization. WYSIWYG\nenables principled algorithm design in deep learning by reducing\n$\\textit{generalization}$ concerns to $\\textit{optimization}$ ones: in order to\nmitigate unwanted behavior at test time, it is provably sufficient to mitigate\nthis behavior on the train data. This is notably false for standard (non-DP)\nmethods, hence this observation has applications even when privacy is not\nrequired. For example, importance sampling is known to fail for standard SGD,\nbut we show that it has exactly the intended effect for DP-trained models.\nThus, with DP-SGD, unlike with SGD, we can influence test-time behavior by\nmaking principled train-time interventions. We use these insights to construct\nsimple algorithms which match or outperform SOTA in several distributional\nrobustness applications, and to significantly improve the privacy vs. disparate\nimpact trade-off of DP-SGD. Finally, we also improve on known theoretical\nbounds relating differential privacy, stability, and distributional\ngeneralization.",
          "link": "http://arxiv.org/abs/2204.03230",
          "publishedOn": "2022-04-09T00:48:53.125Z",
          "wordCount": 701,
          "title": "What You See is What You Get: Distributional Generalization for Algorithm Design in Deep Learning. (arXiv:2204.03230v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03248",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sekimoto_K/0/1/0/all/0/1\">Kaiji Sekimoto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yasuda_M/0/1/0/all/0/1\">Muneki Yasuda</a>",
          "description": "Although evaluation of the expectations on the Ising model is essential in\nvarious applications, this is frequently infeasible because of intractable\nmultiple summations (or integrations). Spatial Monte Carlo integration (SMCI)\nis a sampling-based approximation, and can provide high-accuracy estimations\nfor such intractable expectations. To evaluate the expectation of a function of\nvariables in a specific region (called target region), SMCI considers a larger\nregion containing the target region (called sum region). In SMCI, the multiple\nsummation for the variables in the sum region is precisely executed, and that\nin the outer region is evaluated by the sampling approximation such as the\nstandard Monte Carlo integration. It is guaranteed that the accuracy of the\nSMCI estimator is monotonically improved as the size of the sum region\nincreases. However, a haphazard expansion of the sum region could cause a\ncombinatorial explosion. Therefore, we hope to improve the accuracy without\nsuch region expansion. In this study, based on the theory of generalized least\nsquares, a new effective method is proposed by combining multiple SMCI\nestimators. The validity of the proposed method is demonstrated theoretically\nand numerically. The results indicate that the proposed method can be effective\nin the inverse Ising problem (or Boltzmann machine learning).",
          "link": "http://arxiv.org/abs/2204.03248",
          "publishedOn": "2022-04-09T00:48:49.945Z",
          "wordCount": 660,
          "title": "Composite Spatial Monte Carlo Integration Based on Generalized Least Squares. (arXiv:2204.03248v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.04671",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_T/0/1/0/all/0/1\">Tianyi Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1\">Yuejiao Sun</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xiao_Q/0/1/0/all/0/1\">Quan Xiao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1\">Wotao Yin</a>",
          "description": "Stochastic bilevel optimization generalizes the classic stochastic\noptimization from the minimization of a single objective to the minimization of\nan objective function that depends the solution of another optimization\nproblem. Recently, stochastic bilevel optimization is regaining popularity in\nemerging machine learning applications such as hyper-parameter optimization and\nmodel-agnostic meta learning. To solve this class of stochastic optimization\nproblems, existing methods require either double-loop or two-timescale updates,\nwhich are sometimes less efficient. This paper develops a new optimization\nmethod for a class of stochastic bilevel problems that we term Single-Timescale\nstochAstic BiLevEl optimization (STABLE) method. STABLE runs in a single loop\nfashion, and uses a single-timescale update with a fixed batch size. To achieve\nan $\\epsilon$-stationary point of the bilevel problem, STABLE requires ${\\cal\nO}(\\epsilon^{-2})$ samples in total; and to achieve an $\\epsilon$-optimal\nsolution in the strongly convex case, STABLE requires ${\\cal O}(\\epsilon^{-1})$\nsamples. To the best of our knowledge, this is the first bilevel optimization\nalgorithm achieving the same order of sample complexity as the stochastic\ngradient descent method for the single-level stochastic optimization.",
          "link": "http://arxiv.org/abs/2102.04671",
          "publishedOn": "2022-04-02T00:47:19.824Z",
          "wordCount": null,
          "title": "A Single-Timescale Method for Stochastic Bilevel Optimization. (arXiv:2102.04671v4 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujita_O/0/1/0/all/0/1\">Osamu Fujita</a>",
          "description": "This paper investigates probability density functions (PDFs) that are\ncontinuous everywhere, nearly uniform around the mode of distribution, and\nadaptable to a variety of distribution shapes ranging from bell-shaped to\nrectangular. From the viewpoint of computational tractability, the PDF based on\nthe Fermi-Dirac or logistic function is advantageous in estimating its shape\nparameters. The most appropriate PDF for $n$-variate distribution is of the\nform:\n$p\\left(\\mathbf{x}\\right)\\propto\\left[\\cosh\\left(\\left[\\left(\\mathbf{x}-\\mathbf{m}\\right)^{\\mathsf{T}}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{x}-\\mathbf{m}\\right)\\right]^{n/2}\\right)+\\cosh\\left(r^{n}\\right)\\right]^{-1}$\nwhere $\\mathbf{x},\\mathbf{m}\\in\\mathbb{R}^{n}$, $\\boldsymbol{\\Sigma}$ is an\n$n\\times n$ positive definite matrix, and $r>0$ is a shape parameter. The\nflat-topped PDFs can be used as a component of mixture models in machine\nlearning to improve goodness of fit and make a model as simple as possible.",
          "link": "http://arxiv.org/abs/2203.17027",
          "publishedOn": "2022-04-02T00:47:19.817Z",
          "wordCount": null,
          "title": "Flat-topped Probability Density Functions for Mixture Models. (arXiv:2203.17027v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1\">Emiel Hoogeboom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satorras_V/0/1/0/all/0/1\">Victor Garcia Satorras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vignac_C/0/1/0/all/0/1\">Cl&#xe9;ment Vignac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "This work introduces a diffusion model for molecule generation in 3D that is\nequivariant to Euclidean transformations. Our E(3) Equivariant Diffusion Model\n(EDM) learns to denoise a diffusion process with an equivariant network that\njointly operates on both continuous (atom coordinates) and categorical features\n(atom types). In addition, we provide a probabilistic analysis which admits\nlikelihood computation of molecules using our model. Experimentally, the\nproposed method significantly outperforms previous 3D molecular generative\nmethods regarding the quality of generated samples and efficiency at training\ntime.",
          "link": "http://arxiv.org/abs/2203.17003",
          "publishedOn": "2022-04-02T00:47:19.814Z",
          "wordCount": null,
          "title": "Equivariant Diffusion for Molecule Generation in 3D. (arXiv:2203.17003v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.16712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1\">Thomas M. Moerland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broekens_J/0/1/0/all/0/1\">Joost Broekens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>",
          "description": "Sequential decision making, commonly formalized as Markov Decision Process\n(MDP) optimization, is a important challenge in artificial intelligence. Two\nkey approaches to this problem are reinforcement learning (RL) and planning.\nThis paper presents a survey of the integration of both fields, better known as\nmodel-based reinforcement learning. Model-based RL has two main steps. First,\nwe systematically cover approaches to dynamics model learning, including\nchallenges like dealing with stochasticity, uncertainty, partial observability,\nand temporal abstraction. Second, we present a systematic categorization of\nplanning-learning integration, including aspects like: where to start planning,\nwhat budgets to allocate to planning and real data collection, how to plan, and\nhow to integrate planning in the learning and acting loop. After these two\nsections, we also discuss implicit model-based RL as an end-to-end alternative\nfor model learning and planning, and we cover the potential benefits of\nmodel-based RL. Along the way, the survey also draws connections to several\nrelated RL fields, like hierarchical RL and transfer learning. Altogether, the\nsurvey presents a broad conceptual overview of the combination of planning and\nlearning for MDP optimization.",
          "link": "http://arxiv.org/abs/2006.16712",
          "publishedOn": "2022-04-02T00:47:19.814Z",
          "wordCount": null,
          "title": "Model-based Reinforcement Learning: A Survey. (arXiv:2006.16712v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yuhao Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kunlin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Song Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_I/0/1/0/all/0/1\">Ignavier Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1\">Jinmeng Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1\">Shan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_T/0/1/0/all/0/1\">Teng Fei</a>",
          "description": "Spatial clustering has been widely used for spatial data mining and knowledge\ndiscovery. An ideal multivariate spatial clustering should consider both\nspatial contiguity and aspatial attributes. Existing spatial clustering\napproaches may face challenges for discovering repeated geographic patterns\nwith spatial contiguity maintained. In this paper, we propose a Spatial\nToeplitz Inverse Covariance-Based Clustering (STICC) method that considers both\nattributes and spatial relationships of geographic objects for multivariate\nspatial clustering. A subregion is created for each geographic object serving\nas the basic unit when performing clustering. A Markov random field is then\nconstructed to characterize the attribute dependencies of subregions. Using a\nspatial consistency strategy, nearby objects are encouraged to belong to the\nsame cluster. To test the performance of the proposed STICC algorithm, we apply\nit in two use cases. The comparison results with several baseline methods show\nthat the STICC outperforms others significantly in terms of adjusted rand index\nand macro-F1 score. Join count statistics is also calculated and shows that the\nspatial contiguity is well preserved by STICC. Such a spatial clustering method\nmay benefit various applications in the fields of geography, remote sensing,\ntransportation, and urban planning, etc.",
          "link": "http://arxiv.org/abs/2203.09611",
          "publishedOn": "2022-04-02T00:47:19.814Z",
          "wordCount": null,
          "title": "STICC: A multivariate spatial clustering method for repeated geographic pattern discovery with consideration of spatial contiguity. (arXiv:2203.09611v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16711",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1\">Junyu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Najafi_K/0/1/0/all/0/1\">Khadijeh Najafi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sharma_K/0/1/0/all/0/1\">Kunal Sharma</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tacchino_F/0/1/0/all/0/1\">Francesco Tacchino</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jiang_L/0/1/0/all/0/1\">Liang Jiang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Mezzacapo_A/0/1/0/all/0/1\">Antonio Mezzacapo</a>",
          "description": "Parametrized quantum circuits can be used as quantum neural networks and have\nthe potential to outperform their classical counterparts when trained for\naddressing learning problems. To date, much of the results on their performance\non practical problems are heuristic in nature. In particular, the convergence\nrate for the training of quantum neural networks is not fully understood. Here,\nwe analyze the dynamics of gradient descent for the training error of a class\nof variational quantum machine learning models. We define wide quantum neural\nnetworks as parameterized quantum circuits in the limit of a large number of\nqubits and variational parameters. We then find a simple analytic formula that\ncaptures the average behavior of their loss function and discuss the\nconsequences of our findings. For example, for random quantum circuits, we\npredict and characterize an exponential decay of the residual training error as\na function of the parameters of the system. We finally validate our analytic\nresults with numerical experiments.",
          "link": "http://arxiv.org/abs/2203.16711",
          "publishedOn": "2022-04-02T00:47:19.813Z",
          "wordCount": null,
          "title": "An analytic theory for the dynamics of wide quantum neural networks. (arXiv:2203.16711v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17128",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cohen_S/0/1/0/all/0/1\">Samuel N. Cohen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jiang_D/0/1/0/all/0/1\">Deqing Jiang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sirignano_J/0/1/0/all/0/1\">Justin Sirignano</a>",
          "description": "Solving high-dimensional partial differential equations (PDEs) is a major\nchallenge in scientific computing. We develop a new numerical method for\nsolving elliptic-type PDEs by adapting the Q-learning algorithm in\nreinforcement learning. Our \"Q-PDE\" algorithm is mesh-free and therefore has\nthe potential to overcome the curse of dimensionality. Using a neural tangent\nkernel (NTK) approach, we prove that the neural network approximator for the\nPDE solution, trained with the Q-PDE algorithm, converges to the trajectory of\nan infinite-dimensional ordinary differential equation (ODE) as the number of\nhidden units $\\rightarrow \\infty$. For monotone PDE (i.e. those given by\nmonotone operators, which may be nonlinear), despite the lack of a spectral gap\nin the NTK, we then prove that the limit neural network, which satisfies the\ninfinite-dimensional ODE, converges in $L^2$ to the PDE solution as the\ntraining time $\\rightarrow \\infty$. More generally, we can prove that any fixed\npoint of the wide-network limit for the Q-PDE algorithm is a solution of the\nPDE (not necessarily under the monotone condition). The numerical performance\nof the Q-PDE algorithm is studied for several elliptic PDEs.",
          "link": "http://arxiv.org/abs/2203.17128",
          "publishedOn": "2022-04-02T00:47:19.813Z",
          "wordCount": null,
          "title": "Neural Q-learning for solving elliptic PDEs. (arXiv:2203.17128v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1812.00086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Heda Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Haiping Lu</a>",
          "description": "Graph convolutional network (GCN) is an emerging neural network approach. It\nlearns new representation of a node by aggregating feature vectors of all\nneighbors in the aggregation process without considering whether the neighbors\nor features are useful or not. Recent methods have improved solutions by\nsampling a fixed size set of neighbors, or assigning different weights to\ndifferent neighbors in the aggregation process, but features within a feature\nvector are still treated equally in the aggregation process. In this paper, we\nintroduce a new convolution operation on regular size feature maps constructed\nfrom features of a fixed node bandwidth via sampling to get the first-level\nnode representation, which is then passed to a standard GCN to learn the\nsecond-level node representation. Experiments show that our method outperforms\ncompeting methods in semi-supervised node classification tasks. Furthermore,\nour method opens new doors for exploring new GCN architectures, particularly\ndeeper GCN models.",
          "link": "http://arxiv.org/abs/1812.00086",
          "publishedOn": "2022-04-02T00:47:19.813Z",
          "wordCount": null,
          "title": "Graph Node-Feature Convolution for Representation Learning. (arXiv:1812.00086v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16912",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ath_G/0/1/0/all/0/1\">George De Ath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chugh_T/0/1/0/all/0/1\">Tinkle Chugh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahat_A/0/1/0/all/0/1\">Alma A. M. Rahat</a>",
          "description": "Optimisation problems often have multiple conflicting objectives that can be\ncomputationally and/or financially expensive. Mono-surrogate Bayesian\noptimisation (BO) is a popular model-based approach for optimising such\nblack-box functions. It combines objective values via scalarisation and builds\na Gaussian process (GP) surrogate of the scalarised values. The location which\nmaximises a cheap-to-query acquisition function is chosen as the next location\nto expensively evaluate. While BO is an effective strategy, the use of GPs is\nlimiting. Their performance decreases as the problem input dimensionality\nincreases, and their computational complexity scales cubically with the amount\nof data. To address these limitations, we extend previous work on BO by\ndensity-ratio estimation (BORE) to the multi-objective setting. BORE links the\ncomputation of the probability of improvement acquisition function to that of\nprobabilistic classification. This enables the use of state-of-the-art\nclassifiers in a BO-like framework. In this work we present MBORE:\nmulti-objective Bayesian optimisation by density-ratio estimation, and compare\nit to BO across a range of synthetic and real-world benchmarks. We find that\nMBORE performs as well as or better than BO on a wide variety of problems, and\nthat it outperforms BO on high-dimensional and real-world problems.",
          "link": "http://arxiv.org/abs/2203.16912",
          "publishedOn": "2022-04-02T00:47:19.811Z",
          "wordCount": null,
          "title": "MBORE: Multi-objective Bayesian Optimisation by Density-Ratio Estimation. (arXiv:2203.16912v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1\">Stephen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frostig_R/0/1/0/all/0/1\">Roy Frostig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1\">Mahdi Soltanolkotabi</a>",
          "description": "We initiate a study of supervised learning from many independent sequences\n(\"trajectories\") of non-independent covariates, reflecting tasks in sequence\nmodeling, control, and reinforcement learning. Conceptually, our\nmulti-trajectory setup sits between two traditional settings in statistical\nlearning theory: learning from independent examples and learning from a single\nauto-correlated sequence. Our conditions for efficient learning generalize the\nformer setting--trajectories must be non-degenerate in ways that extend\nstandard requirements for independent examples. They do not require that\ntrajectories be ergodic, long, nor strictly stable.\n\nFor linear least-squares regression, given $n$-dimensional examples produced\nby $m$ trajectories, each of length $T$, we observe a notable change in\nstatistical efficiency as the number of trajectories increases from a few\n(namely $m \\lesssim n$) to many (namely $m \\gtrsim n$). Specifically, we\nestablish that the worst-case error rate this problem is $\\Theta(n / m T)$\nwhenever $m \\gtrsim n$. Meanwhile, when $m \\lesssim n$, we establish a (sharp)\nlower bound of $\\Omega(n^2 / m^2 T)$ on the worst-case error rate, realized by\na simple, marginally unstable linear dynamical system. A key upshot is that, in\ndomains where trajectories regularly reset, the error rate eventually behaves\nas if all of the examples were independent altogether, drawn from their\nmarginals. As a corollary of our analysis, we also improve guarantees for the\nlinear system identification problem.",
          "link": "http://arxiv.org/abs/2203.17193",
          "publishedOn": "2022-04-02T00:47:19.809Z",
          "wordCount": null,
          "title": "Learning from many trajectories. (arXiv:2203.17193v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16749",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Koizumi_Y/0/1/0/all/0/1\">Yuma Koizumi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zen_H/0/1/0/all/0/1\">Heiga Zen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yatabe_K/0/1/0/all/0/1\">Kohei Yatabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_N/0/1/0/all/0/1\">Nanxin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bacchiani_M/0/1/0/all/0/1\">Michiel Bacchiani</a>",
          "description": "Neural vocoder using denoising diffusion probabilistic model (DDPM) has been\nimproved by adaptation of the diffusion noise distribution to given acoustic\nfeatures. In this study, we propose SpecGrad that adapts the diffusion noise so\nthat its time-varying spectral envelope becomes close to the conditioning\nlog-mel spectrogram. This adaptation by time-varying filtering improves the\nsound quality especially in the high-frequency bands. It is processed in the\ntime-frequency domain to keep the computational cost almost the same as the\nconventional DDPM-based neural vocoders. Experimental results showed that\nSpecGrad generates higher-fidelity speech waveform than conventional DDPM-based\nneural vocoders in both analysis-synthesis and speech enhancement scenarios.\nAudio demos are available at wavegrad.github.io/specgrad/.",
          "link": "http://arxiv.org/abs/2203.16749",
          "publishedOn": "2022-04-02T00:47:19.804Z",
          "wordCount": null,
          "title": "SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with Adaptive Noise Spectral Shaping. (arXiv:2203.16749v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.04184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Ziang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1\">Song Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>",
          "description": "Multi-agent reinforcement learning has made substantial empirical progresses\nin solving games with a large number of players. However, theoretically, the\nbest known sample complexity for finding a Nash equilibrium in general-sum\ngames scales exponentially in the number of players due to the size of the\njoint action space, and there is a matching exponential lower bound. This paper\ninvestigates what learning goals admit better sample complexities in the\nsetting of $m$-player general-sum Markov games with $H$ steps, $S$ states, and\n$A_i$ actions per player. First, we design algorithms for learning an\n$\\epsilon$-Coarse Correlated Equilibrium (CCE) in\n$\\widetilde{\\mathcal{O}}(H^5S\\max_{i\\le m} A_i / \\epsilon^2)$ episodes, and an\n$\\epsilon$-Correlated Equilibrium (CE) in\n$\\widetilde{\\mathcal{O}}(H^6S\\max_{i\\le m} A_i^2 / \\epsilon^2)$ episodes. This\nis the first line of results for learning CCE and CE with sample complexities\npolynomial in $\\max_{i\\le m} A_i$. Our algorithm for learning CE integrates an\nadversarial bandit subroutine which minimizes a weighted swap regret, along\nwith several novel designs in the outer loop. Second, we consider the important\nspecial case of Markov Potential Games, and design an algorithm that learns an\n$\\epsilon$-approximate Nash equilibrium within\n$\\widetilde{\\mathcal{O}}(S\\sum_{i\\le m} A_i / \\epsilon^3)$ episodes (when only\nhighlighting the dependence on $S$, $A_i$, and $\\epsilon$), which only depends\nlinearly in $\\sum_{i\\le m} A_i$ and significantly improves over existing\nefficient algorithm in the $\\epsilon$ dependence. Overall, our results shed\nlight on what equilibria or structural assumptions on the game may enable\nsample-efficient learning with many players.",
          "link": "http://arxiv.org/abs/2110.04184",
          "publishedOn": "2022-04-02T00:47:19.782Z",
          "wordCount": null,
          "title": "When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?. (arXiv:2110.04184v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chuizheng Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Sungyong Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griesemer_S/0/1/0/all/0/1\">Sam Griesemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "Physics-informed machine learning (PIML), referring to the combination of\nprior knowledge of physics, which is the high level abstraction of natural\nphenomenons and human behaviours in the long history, with data-driven machine\nlearning models, has emerged as an effective way to mitigate the shortage of\ntraining data, to increase models' generalizability and to ensure the physical\nplausibility of results. In this paper, we survey an abundant number of recent\nworks in PIML and summarize them from three aspects: (1) motivations of PIML,\n(2) physics knowledge in PIML, (3) methods of physics knowledge integration in\nPIML. We also discuss current challenges and corresponding research\nopportunities in PIML.",
          "link": "http://arxiv.org/abs/2203.16797",
          "publishedOn": "2022-04-02T00:47:19.777Z",
          "wordCount": null,
          "title": "When Physics Meets Machine Learning: A Survey of Physics-Informed Machine Learning. (arXiv:2203.16797v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.05630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_N/0/1/0/all/0/1\">Nian Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhengyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanchet_J/0/1/0/all/0/1\">Jose Blanchet</a>",
          "description": "Policy learning using historical observational data is an important problem\nthat has found widespread applications. Examples include selecting offers,\nprices, advertisements to send to customers, as well as selecting which\nmedication to prescribe to a patient. However, existing literature rests on the\ncrucial assumption that the future environment where the learned policy will be\ndeployed is the same as the past environment that has generated the data -- an\nassumption that is often false or too coarse an approximation. In this paper,\nwe lift this assumption and aim to learn a distributionally robust policy with\nincomplete observational data. We first present a policy evaluation procedure\nthat allows us to assess how well the policy does under the worst-case\nenvironment shift. We then establish a central limit theorem type guarantee for\nthis proposed policy evaluation scheme. Leveraging this evaluation scheme, we\nfurther propose a novel learning algorithm that is able to learn a policy that\nis robust to adversarial perturbations and unknown covariate shifts with a\nperformance guarantee based on the theory of uniform convergence. Finally, we\nempirically test the effectiveness of our proposed algorithm in synthetic\ndatasets and demonstrate that it provides the robustness that is missing using\nstandard policy learning algorithms. We conclude the paper by providing a\ncomprehensive application of our methods in the context of a real-world voting\ndataset.",
          "link": "http://arxiv.org/abs/2006.05630",
          "publishedOn": "2022-04-02T00:47:19.775Z",
          "wordCount": null,
          "title": "Distributional Robust Batch Contextual Bandits. (arXiv:2006.05630v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.12967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haroush_M/0/1/0/all/0/1\">Matan Haroush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frostig_T/0/1/0/all/0/1\">Tzviel Frostig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_R/0/1/0/all/0/1\">Ruth Heller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soudry_D/0/1/0/all/0/1\">Daniel Soudry</a>",
          "description": "Background. Commonly, Deep Neural Networks (DNNs) generalize well on samples\ndrawn from a distribution similar to that of the training set. However, DNNs'\npredictions are brittle and unreliable when the test samples are drawn from a\ndissimilar distribution. This is a major concern for deployment in real-world\napplications, where such behavior may come at a considerable cost, such as\nindustrial production lines, autonomous vehicles, or healthcare applications.\nContributions. We frame Out Of Distribution (OOD) detection in DNNs as a\nstatistical hypothesis testing problem. Tests generated within our proposed\nframework combine evidence from the entire network. Unlike previous OOD\ndetection heuristics, this framework returns a $p$-value for each test sample.\nIt is guaranteed to maintain the Type I Error (T1E - incorrectly predicting OOD\nfor an actual in-distribution sample) for test data. Moreover, this allows to\ncombine several detectors while maintaining the T1E. Building on this\nframework, we suggest a novel OOD procedure based on low-order statistics. Our\nmethod achieves comparable or better results than state-of-the-art methods on\nwell-accepted OOD benchmarks, without retraining the network parameters or\nassuming prior knowledge on the test distribution -- and at a fraction of the\ncomputational cost.",
          "link": "http://arxiv.org/abs/2102.12967",
          "publishedOn": "2022-04-02T00:47:19.775Z",
          "wordCount": null,
          "title": "A statistical framework for efficient out of distribution detection in deep neural networks. (arXiv:2102.12967v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.06053",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galhotra_S/0/1/0/all/0/1\">Sainyam Galhotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1\">Prasanna Sattigeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1\">Kush R. Varshney</a>",
          "description": "The use of machine learning (ML) in high-stakes societal decisions has\nencouraged the consideration of fairness throughout the ML lifecycle. Although\ndata integration is one of the primary steps to generate high quality training\ndata, most of the fairness literature ignores this stage. In this work, we\nconsider fairness in the integration component of data management, aiming to\nidentify features that improve prediction without adding any bias to the\ndataset. We work under the causal interventional fairness paradigm. Without\nrequiring the underlying structural causal model a priori, we propose an\napproach to identify a sub-collection of features that ensure the fairness of\nthe dataset by performing conditional independence tests between different\nsubsets of features. We use group testing to improve the complexity of the\napproach. We theoretically prove the correctness of the proposed algorithm to\nidentify features that ensure interventional fairness and show that sub-linear\nconditional independence tests are sufficient to identify these variables. A\ndetailed empirical evaluation is performed on real-world datasets to\ndemonstrate the efficacy and efficiency of our technique.",
          "link": "http://arxiv.org/abs/2006.06053",
          "publishedOn": "2022-04-02T00:47:19.773Z",
          "wordCount": null,
          "title": "Causal Feature Selection for Algorithmic Fairness. (arXiv:2006.06053v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shaohan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yunpeng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerman_G/0/1/0/all/0/1\">Gilad Lerman</a>",
          "description": "Previous partial permutation synchronization (PPS) algorithms, which are\ncommonly used for multi-object matching, often involve computation-intensive\nand memory-demanding matrix operations. These operations become intractable for\nlarge scale structure-from-motion datasets. For pure permutation\nsynchronization, the recent Cycle-Edge Message Passing (CEMP) framework\nsuggests a memory-efficient and fast solution. Here we overcome the restriction\nof CEMP to compact groups and propose an improved algorithm, CEMP-Partial, for\nestimating the corruption levels of the observed partial permutations. It\nallows us to subsequently implement a nonconvex weighted projected power method\nwithout the need of spectral initialization. The resulting new PPS algorithm,\nMatchFAME (Fast, Accurate and Memory-Efficient Matching), only involves sparse\nmatrix operations, and thus enjoys lower time and space complexities in\ncomparison to previous PPS algorithms. We prove that under adversarial\ncorruption, though without additive noise and with certain assumptions,\nCEMP-Partial is able to exactly classify corrupted and clean partial\npermutations. We demonstrate the state-of-the-art accuracy, speed and memory\nefficiency of our method on both synthetic and real datasets.",
          "link": "http://arxiv.org/abs/2203.16505",
          "publishedOn": "2022-04-02T00:47:19.773Z",
          "wordCount": null,
          "title": "Fast, Accurate and Memory-Efficient Partial Permutation Synchronization. (arXiv:2203.16505v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Przyborowski_M/0/1/0/all/0/1\">Mateusz Przyborowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pabis_M/0/1/0/all/0/1\">Mateusz Pabi&#x15b;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janusz_A/0/1/0/all/0/1\">Andrzej Janusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slezak_D/0/1/0/all/0/1\">Dominik &#x15a;l&#x119;zak</a>",
          "description": "Gaussian mixture models find their place as a powerful tool, mostly in the\nclustering problem, but with proper preparation also in feature extraction,\npattern recognition, image segmentation and in general machine learning. When\nfaced with the problem of schema matching, different mixture models computed on\ndifferent pieces of data can maintain crucial information about the structure\nof the dataset. In order to measure or compare results from mixture models, the\nWasserstein distance can be very useful, however it is not easy to calculate\nfor mixture distributions. In this paper we derive one of possible\napproximations for the Wasserstein distance between Gaussian mixture models and\nreduce it to linear problem. Furthermore, application examples concerning real\nworld data are shown.",
          "link": "http://arxiv.org/abs/2111.14244",
          "publishedOn": "2022-04-02T00:47:19.734Z",
          "wordCount": null,
          "title": "Schema matching using Gaussian mixture models with Wasserstein distance. (arXiv:2111.14244v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carranza_A/0/1/0/all/0/1\">Aldo Gael Carranza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "Many popular contextual bandit algorithms estimate reward models to inform\ndecision making. However, true rewards can contain action-independent\nredundancies that are not relevant for decision making and only increase the\nstatistical complexity of accurate estimation. It is sufficient and more\ndata-efficient to estimate the simplest function that explains the reward\ndifferences between actions, that is, the heterogeneous treatment effect,\ncommonly understood to be more structured and simpler than the reward.\nMotivated by this observation, building on recent work on oracle-based\nalgorithms, we design a statistically optimal and computationally efficient\nalgorithm using heterogeneous treatment effect estimation oracles. Our results\nprovide the first universal reduction of contextual bandits to a\ngeneral-purpose heterogeneous treatment effect estimation method. We show that\nour approach is more robust to model misspecification than reward estimation\nmethods based on squared error regression oracles. Experimentally, we show the\nbenefits of heterogeneous treatment effect estimation in contextual bandits\nover reward estimation.",
          "link": "http://arxiv.org/abs/2203.16668",
          "publishedOn": "2022-04-02T00:47:19.726Z",
          "wordCount": null,
          "title": "Flexible and Efficient Contextual Bandits with Heterogeneous Treatment Effect Oracle. (arXiv:2203.16668v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16673",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yue Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oymak_S/0/1/0/all/0/1\">Samet Oymak</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fazel_M/0/1/0/all/0/1\">Maryam Fazel</a>",
          "description": "This paper studies the problem of identifying low-order linear systems via\nHankel nuclear norm regularization. Hankel regularization encourages the\nlow-rankness of the Hankel matrix, which maps to the low-orderness of the\nsystem. We provide novel statistical analysis for this regularization and\ncarefully contrast it with the unregularized ordinary least-squares (OLS)\nestimator. Our analysis leads to new bounds on estimating the impulse response\nand the Hankel matrix associated with the linear system. We first design an\ninput excitation and show that Hankel regularization enables one to recover the\nsystem using optimal number of observations in the true system order and\nachieve strong statistical estimation rates. Surprisingly, we demonstrate that\nthe input design indeed matters, by showing that intuitive choices such as\ni.i.d. Gaussian input leads to provably sub-optimal sample complexity. To\nbetter understand the benefits of regularization, we also revisit the OLS\nestimator. Besides refining existing bounds, we experimentally identify when\nregularized approach improves over OLS: (1) For low-order systems with slow\nimpulse-response decay, OLS method performs poorly in terms of sample\ncomplexity, (2) Hankel matrix returned by regularization has a more clear\nsingular value gap that ease identification of the system order, (3) Hankel\nregularization is less sensitive to hyperparameter choice. Finally, we\nestablish model selection guarantees through a joint train-validation procedure\nwhere we tune the regularization parameter for near-optimal estimation.",
          "link": "http://arxiv.org/abs/2203.16673",
          "publishedOn": "2022-04-02T00:47:19.726Z",
          "wordCount": null,
          "title": "System Identification via Nuclear Norm Regularization. (arXiv:2203.16673v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16662",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Beckham_C/0/1/0/all/0/1\">Christopher Beckham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Laradji_I/0/1/0/all/0/1\">Issam Laradji</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rodriguez_P/0/1/0/all/0/1\">Pau Rodriguez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vazquez_D/0/1/0/all/0/1\">David Vazquez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nowrouzezahrai_D/0/1/0/all/0/1\">Derek Nowrouzezahrai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "In this paper, we explore the use of GAN-based few-shot data augmentation as\na method to improve few-shot classification performance. We perform an\nexploration into how a GAN can be fine-tuned for such a task (one of which is\nin a class-incremental manner), as well as a rigorous empirical investigation\ninto how well these models can perform to improve few-shot classification. We\nidentify issues related to the difficulty of training such generative models\nunder a purely supervised regime with very few examples, as well as issues\nregarding the evaluation protocols of existing works. We also find that in this\nregime, classification accuracy is highly sensitive to how the classes of the\ndataset are randomly split. Therefore, we propose a semi-supervised fine-tuning\napproach as a more pragmatic way forward to address these problems.",
          "link": "http://arxiv.org/abs/2203.16662",
          "publishedOn": "2022-04-02T00:47:19.718Z",
          "wordCount": null,
          "title": "Challenges in leveraging GANs for few-shot data augmentation. (arXiv:2203.16662v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16587",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chatterjee_S/0/1/0/all/0/1\">Sabyasachi Chatterjee</a>, <a href=\"http://arxiv.org/find/math/1/au:+Goswami_S/0/1/0/all/0/1\">Subhajit Goswami</a>",
          "description": "We consider the problem of estimating piecewise regular functions in an\nonline setting, i.e., the data arrive sequentially and at any round our task is\nto predict the value of the true function at the next revealed point using the\navailable data from past predictions. We propose a suitably modified version of\na recently developed online learning algorithm called the sleeping experts\naggregation algorithm. We show that this estimator satisfies oracle risk bounds\nsimultaneously for all local regions of the domain. As concrete instantiations\nof the expert aggregation algorithm proposed here, we study an online mean\naggregation and an online linear regression aggregation algorithm where experts\ncorrespond to the set of dyadic subrectangles of the domain. The resulting\nalgorithms are near linear time computable in the sample size. We specifically\nfocus on the performance of these online algorithms in the context of\nestimating piecewise polynomial and bounded variation function classes in the\nfixed design setup. The simultaneous oracle risk bounds we obtain for these\nestimators in this context provide new and improved (in certain aspects)\nguarantees even in the batch setting and are not available for the state of the\nart batch learning estimators.",
          "link": "http://arxiv.org/abs/2203.16587",
          "publishedOn": "2022-04-02T00:47:19.544Z",
          "wordCount": null,
          "title": "Spatially Adaptive Online Prediction of Piecewise Regular Functions. (arXiv:2203.16587v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bombari_S/0/1/0/all/0/1\">Simone Bombari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1\">Alessandro Achille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yusheng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1\">Kunwar Yashraj Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Appalaraju_S/0/1/0/all/0/1\">Srikar Appalaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadevan_V/0/1/0/all/0/1\">Vijay Mahadevan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Memorization of the relation between entities in a dataset can lead to\nprivacy issues when using a trained model for question answering. We introduce\nRelational Memorization (RM) to understand, quantify and control this\nphenomenon. While bounding general memorization can have detrimental effects on\nthe performance of a trained model, bounding RM does not prevent effective\nlearning. The difference is most pronounced when the data distribution is\nlong-tailed, with many queries having only few training examples: Impeding\ngeneral memorization prevents effective learning, while impeding only\nrelational memorization still allows learning general properties of the\nunderlying concepts. We formalize the notion of Relational Privacy (RP) and,\ninspired by Differential Privacy (DP), we provide a possible definition of\nDifferential Relational Privacy (DrP). These notions can be used to describe\nand compute bounds on the amount of RM in a trained model. We illustrate\nRelational Privacy concepts in experiments with large-scale models for Question\nAnswering.",
          "link": "http://arxiv.org/abs/2203.16701",
          "publishedOn": "2022-04-02T00:47:19.531Z",
          "wordCount": null,
          "title": "Towards Differential Relational Privacy and its use in Question Answering. (arXiv:2203.16701v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17065",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chugh_T/0/1/0/all/0/1\">Tinkle Chugh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ymeraj_E/0/1/0/all/0/1\">Endi Ymeraj</a>",
          "description": "Wind energy is one of the cleanest renewable electricity sources and can help\nin addressing the challenge of climate change. One of the drawbacks of\nwind-generated energy is the large space necessary to install a wind farm; this\narises from the fact that placing wind turbines in a limited area would hinder\ntheir productivity and therefore not be economically convenient. This naturally\nleads to an optimisation problem, which has three specific challenges: (1)\nmultiple conflicting objectives (2) computationally expensive simulation models\nand (3) optimisation over design sets instead of design vectors. The first and\nsecond challenges can be addressed by using surrogate-assisted e.g.\\ Bayesian\nmulti-objective optimisation. However, the traditional Bayesian optimisation\ncannot be applied as the optimisation function in the problem relies on design\nsets instead of design vectors. This paper extends the applicability of\nBayesian multi-objective optimisation to set based optimisation for solving the\nwind farm layout problem. We use a set-based kernel in Gaussian process to\nquantify the correlation between wind farms (with a different number of\nturbines). The results on the given data set of wind energy and direction\nclearly show the potential of using set-based Bayesian multi-objective\noptimisation.",
          "link": "http://arxiv.org/abs/2203.17065",
          "publishedOn": "2022-04-02T00:47:19.529Z",
          "wordCount": null,
          "title": "Wind Farm Layout Optimisation using Set Based Multi-objective Bayesian Optimisation. (arXiv:2203.17065v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.12438",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gupta_V/0/1/0/all/0/1\">Vishal Gupta</a>, <a href=\"http://arxiv.org/find/math/1/au:+Huang_M/0/1/0/all/0/1\">Michael Huang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rusmevichientong_P/0/1/0/all/0/1\">Paat Rusmevichientong</a>",
          "description": "Motivated by the poor performance of cross-validation in settings where data\nare scarce, we propose a novel estimator of the out-of-sample performance of a\npolicy in data-driven optimization.Our approach exploits the optimization\nproblem's sensitivity analysis to estimate the gradient of the optimal\nobjective value with respect to the amount of noise in the data and uses the\nestimated gradient to debias the policy's in-sample performance. Unlike\ncross-validation techniques, our approach avoids sacrificing data for a test\nset, utilizes all data when training and, hence, is well-suited to settings\nwhere data are scarce. We prove bounds on the bias and variance of our\nestimator for optimization problems with uncertain linear objectives but known,\npotentially non-convex, feasible regions. For more specialized optimization\nproblems where the feasible region is \"weakly-coupled\" in a certain sense, we\nprove stronger results. Specifically, we provide explicit high-probability\nbounds on the error of our estimator that hold uniformly over a policy class\nand depends on the problem's dimension and policy class's complexity. Our\nbounds show that under mild conditions, the error of our estimator vanishes as\nthe dimension of the optimization problem grows, even if the amount of\navailable data remains small and constant. Said differently, we prove our\nestimator performs well in the small-data, large-scale regime. Finally, we\nnumerically compare our proposed method to state-of-the-art approaches through\na case-study on dispatching emergency medical response services using real\ndata. Our method provides more accurate estimates of out-of-sample performance\nand learns better-performing policies.",
          "link": "http://arxiv.org/abs/2107.12438",
          "publishedOn": "2022-04-02T00:47:19.529Z",
          "wordCount": null,
          "title": "Debiasing In-Sample Policy Performance for Small-Data, Large-Scale Optimization. (arXiv:2107.12438v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17153",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Baagmark_K/0/1/0/all/0/1\">Kasper B&#xe5;gmark</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Andersson_A/0/1/0/all/0/1\">Adam Andersson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Larsson_S/0/1/0/all/0/1\">Stig Larsson</a>",
          "description": "The main goal of this paper is to approximately solve the nonlinear filtering\nproblem through deep learning. This is achieved by solving the Zakai equation\nby a deep splitting method, previously developed for approximate solution of\n(stochastic) partial differential equations. This is combined with an\nenergy-based model for the approximation of functions by a deep neural network.\nThis results in a computationally fast filter that takes observations as input\nand that does not require re-training when new observations are received. The\nmethod is tested on three examples, one linear Gaussian and two nonlinear. The\nmethod shows promising performance when benchmarked against the Kalman filter\nand the bootstrap particle filter.",
          "link": "http://arxiv.org/abs/2203.17153",
          "publishedOn": "2022-04-02T00:47:19.332Z",
          "wordCount": null,
          "title": "An energy-based deep splitting method for the nonlinear filtering problem. (arXiv:2203.17153v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.12558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1\">Constantinos Daskalakis</a>",
          "description": "Machine learning has developed a variety of tools for learning and\nrepresenting high-dimensional distributions with structure. Recent years have\nalso seen big advances in designing multi-item mechanisms. Akin to overfitting,\nhowever, these mechanisms can be extremely sensitive to the Bayesian prior that\nthey target, which becomes problematic when that prior is only approximately\nknown. At the same time, even if access to the exact Bayesian prior is given,\nit is known that optimal or even approximately optimal multi-item mechanisms\nrun into sample, computational, representation and communication intractability\nbarriers.\n\nWe consider a natural class of multi-item mechanism design problems with very\nlarge numbers of items, but where the bidders' value distributions can be\nwell-approximated by a topic model akin to those used in recommendation systems\nwith very large numbers of possible recommendations. We propose a mechanism\ndesign framework for this setting, building on a recent robustification\nframework by Brustle et al., which disentangles the statistical challenge of\nestimating a multi-dimensional prior from the task of designing a good\nmechanism for it, and robustifies the performance of the latter against the\nestimation error of the former. We provide an extension of this framework\nappropriate for our setting, which allows us to exploit the expressive power of\ntopic models to reduce the effective dimensionality of the mechanism design\nproblem and remove the dependence of its computational, communication and\nrepresentation complexity on the number of items.",
          "link": "http://arxiv.org/abs/2110.12558",
          "publishedOn": "2022-04-02T00:47:19.332Z",
          "wordCount": null,
          "title": "Recommender Systems meet Mechanism Design. (arXiv:2110.12558v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.15009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1\">Thomas M. Moerland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broekens_J/0/1/0/all/0/1\">Joost Broekens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>",
          "description": "Sequential decision making, commonly formalized as optimization of a Markov\nDecision Process, is a key challenge in artificial intelligence. Two successful\napproaches to MDP optimization are reinforcement learning and planning, which\nboth largely have their own research communities. However, if both research\nfields solve the same problem, then we might be able to disentangle the common\nfactors in their solution approaches. Therefore, this paper presents a unifying\nalgorithmic framework for reinforcement learning and planning (FRAP), which\nidentifies underlying dimensions on which MDP planning and learning algorithms\nhave to decide. At the end of the paper, we compare a variety of well-known\nplanning, model-free and model-based RL algorithms along these dimensions.\nAltogether, the framework may help provide deeper insight in the algorithmic\ndesign space of planning and reinforcement learning.",
          "link": "http://arxiv.org/abs/2006.15009",
          "publishedOn": "2022-04-02T00:47:19.034Z",
          "wordCount": null,
          "title": "A Unifying Framework for Reinforcement Learning and Planning. (arXiv:2006.15009v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.01382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cheng-Yu Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jieyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratner_A/0/1/0/all/0/1\">Alexander Ratner</a>",
          "description": "Weak Supervision (WS) techniques allow users to efficiently create large\ntraining datasets by programmatically labeling data with heuristic sources of\nsupervision. While the success of WS relies heavily on the provided labeling\nheuristics, the process of how these heuristics are created in practice has\nremained under-explored. In this work, we formalize the development process of\nlabeling heuristics as an interactive procedure, built around the existing\nworkflow where users draw ideas from a selected set of development data for\ndesigning the heuristic sources. With the formalism, we study two core problems\nof how to strategically select the development data to guide users in\nefficiently creating informative heuristics, and how to exploit the information\nwithin the development process to contextualize and better learn from the\nresultant heuristics. Building upon two novel methodologies that effectively\ntackle the respective problems considered, we present Nemo, an end-to-end\ninteractive system that improves the overall productivity of WS learning\npipeline by an average 20% (and up to 47% in one task) compared to the\nprevailing WS approach.",
          "link": "http://arxiv.org/abs/2203.01382",
          "publishedOn": "2022-03-26T00:46:07.122Z",
          "wordCount": null,
          "title": "Nemo: Guiding and Contextualizing Weak Supervision for Interactive Data Programming. (arXiv:2203.01382v2 [cs.LG] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.13207",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Heese_R/0/1/0/all/0/1\">Raoul Heese</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Bickert_P/0/1/0/all/0/1\">Patricia Bickert</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Niederle_A/0/1/0/all/0/1\">Astrid Elisa Niederle</a>",
          "description": "We propose a quantum representation of binary classification trees with\nbinary features based on a probabilistic approach. By using the quantum\ncomputer as a processor for probability distributions, a probabilistic\ntraversal of the decision tree can be realized via measurements of a quantum\ncircuit. We describe how tree inductions and the prediction of class labels of\nquery data can be integrated into this framework. An on-demand sampling method\nenables predictions with a constant number of classical memory slots,\nindependent of the tree depth. We experimentally study our approach using both\na quantum computing simulator and actual IBM quantum hardware. To our\nknowledge, this is the first realization of a decision tree classifier on a\nquantum device.",
          "link": "http://arxiv.org/abs/2108.13207",
          "publishedOn": "2022-03-26T00:46:05.894Z",
          "wordCount": 585,
          "title": "Representation of binary classification trees with binary features by quantum circuits. (arXiv:2108.13207v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1709.00944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1\">Jen-Cheng Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Syu-Siang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1\">Ying-Hui Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Hsiu-Wen Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>",
          "description": "Speech enhancement (SE) aims to reduce noise in speech signals. Most SE\ntechniques focus on addressing audio information only. In this work, inspired\nby multimodal learning, which utilizes data from different modalities, and the\nrecent success of convolutional neural networks (CNNs) in SE, we propose an\naudio-visual deep CNN (AVDCNN) SE model, which incorporates audio and visual\nstreams into a unified network model. In the proposed AVDCNN SE model, audio\nand visual data are first processed using individual CNNs, and then, fused into\na joint network to generate enhanced speech at the output layer. The AVDCNN\nmodel is trained in an end-to-end manner, and parameters are jointly learned\nthrough back-propagation. We evaluate enhanced speech using five objective\ncriteria. Results show that the AVDCNN yields notably better performance,\ncompared with an audio-only CNN-based SE model and two conventional SE\napproaches, confirming the effectiveness of integrating visual information into\nthe SE process.",
          "link": "http://arxiv.org/abs/1709.00944",
          "publishedOn": "2022-03-26T00:46:05.874Z",
          "wordCount": 662,
          "title": "Audio-Visual Speech Enhancement using Multimodal Deep Convolutional Neural Network. (arXiv:1709.00944v4 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.08781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Birrell_J/0/1/0/all/0/1\">Jeremiah Birrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katsoulakis_M/0/1/0/all/0/1\">Markos A. Katsoulakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pantazis_Y/0/1/0/all/0/1\">Yannis Pantazis</a>",
          "description": "Variational representations of divergences and distances between\nhigh-dimensional probability distributions offer significant theoretical\ninsights and practical advantages in numerous research areas. Recently, they\nhave gained popularity in machine learning as a tractable and scalable approach\nfor training probabilistic models and for statistically differentiating between\ndata distributions. Their advantages include: 1) They can be estimated from\ndata as statistical averages. 2) Such representations can leverage the ability\nof neural networks to efficiently approximate optimal solutions in function\nspaces. However, a systematic and practical approach to improving the tightness\nof such variational formulas, and accordingly accelerate statistical learning\nand estimation from data, is currently lacking. Here we develop such a\nmethodology for building new, tighter variational representations of\ndivergences. Our approach relies on improved objective functionals constructed\nvia an auxiliary optimization problem. Furthermore, the calculation of the\nfunctional Hessian of objective functionals unveils the local curvature\ndifferences around the common optimal variational solution; this quantifies and\norders the tightness gains between different variational representations.\nFinally, numerical simulations utilizing neural network optimization\ndemonstrate that tighter representations can result in significantly faster\nlearning and more accurate estimation of divergences in both synthetic and real\ndatasets (of more than 1000 dimensions), often accelerated by nearly an order\nof magnitude.",
          "link": "http://arxiv.org/abs/2006.08781",
          "publishedOn": "2022-03-26T00:46:05.867Z",
          "wordCount": 695,
          "title": "Optimizing Variational Representations of Divergences and Accelerating their Statistical Estimation. (arXiv:2006.08781v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bijl_E/0/1/0/all/0/1\">Etienne van de Bijl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_J/0/1/0/all/0/1\">Jan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pries_J/0/1/0/all/0/1\">Joris Pries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhulai_S/0/1/0/all/0/1\">Sandjai Bhulai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoogendoorn_M/0/1/0/all/0/1\">Mark Hoogendoorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_R/0/1/0/all/0/1\">Rob van der Mei</a>",
          "description": "Novel prediction methods should always be compared to a baseline to know how\nwell they perform. Without this frame of reference, the performance score of a\nmodel is basically meaningless. What does it mean when a model achieves an\n$F_1$ of 0.8 on a test set? A proper baseline is needed to evaluate the\n`goodness' of a performance score. Comparing with the latest state-of-the-art\nmodel is usually insightful. However, being state-of-the-art can change rapidly\nwhen newer models are developed. Contrary to an advanced model, a simple dummy\nclassifier could be used. However, the latter could be beaten too easily,\nmaking the comparison less valuable. This paper presents a universal baseline\nmethod for all binary classification models, named the Dutch Draw (DD). This\napproach weighs simple classifiers and determines the best classifier to use as\na baseline. We theoretically derive the DD baseline for many commonly used\nevaluation measures and show that in most situations it reduces to (almost)\nalways predicting either zero or one. Summarizing, the DD baseline is: (1)\ngeneral, as it is applicable to all binary classification problems; (2) simple,\nas it is quickly determined without training or parameter-tuning; (3)\ninformative, as insightful conclusions can be drawn from the results. The DD\nbaseline serves two purposes. First, to enable comparisons across research\npapers by this robust and universal baseline. Secondly, to provide a sanity\ncheck during the development process of a prediction model. It is a major\nwarning sign when a model is outperformed by the DD baseline.",
          "link": "http://arxiv.org/abs/2203.13084",
          "publishedOn": "2022-03-26T00:46:05.860Z",
          "wordCount": 714,
          "title": "The Dutch Draw: Constructing a Universal Baseline for Binary Prediction Models. (arXiv:2203.13084v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2004.05599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Domingues_O/0/1/0/all/0/1\">Omar Darwiche Domingues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menard_P/0/1/0/all/0/1\">Pierre M&#xe9;nard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pirotta_M/0/1/0/all/0/1\">Matteo Pirotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufmann_E/0/1/0/all/0/1\">Emilie Kaufmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>",
          "description": "We consider the exploration-exploitation dilemma in finite-horizon\nreinforcement learning problems whose state-action space is endowed with a\nmetric. We introduce Kernel-UCBVI, a model-based optimistic algorithm that\nleverages the smoothness of the MDP and a non-parametric kernel estimator of\nthe rewards and transitions to efficiently balance exploration and\nexploitation. For problems with $K$ episodes and horizon $H$, we provide a\nregret bound of $\\widetilde{O}\\left( H^3 K^{\\frac{2d}{2d+1}}\\right)$, where $d$\nis the covering dimension of the joint state-action space. This is the first\nregret bound for kernel-based RL using smoothing kernels, which requires very\nweak assumptions on the MDP and has been previously applied to a wide range of\ntasks. We empirically validate our approach in continuous MDPs with sparse\nrewards.",
          "link": "http://arxiv.org/abs/2004.05599",
          "publishedOn": "2022-03-26T00:46:05.845Z",
          "wordCount": 605,
          "title": "Kernel-Based Reinforcement Learning: A Finite-Time Analysis. (arXiv:2004.05599v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.10750",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zewang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yibin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xinhui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Li Lu</a>",
          "description": "In this paper, we develop a new multi-singer Chinese neural singing voice\nsynthesis (SVS) system named WeSinger. To improve the accuracy and naturalness\nof synthesized singing voice, we design several specifical modules and\ntechniques: 1) A deep bi-directional LSTM based duration model with multi-scale\nrhythm loss and post-processing step; 2) A Transformer-alike acoustic model\nwith progressive pitch-weighted decoder loss; 3) a 24 kHz pitch-aware LPCNet\nneural vocoder to produce high-quality singing waveforms; 4) A novel data\naugmentation method with multi-singer pre-training for stronger robustness and\nnaturalness. Both quantitative and qualitative evaluation results demonstrate\nthe effectiveness of WeSinger in terms of accuracy and naturalness, and\nWeSinger achieves state-of-the-art performance on the public corpus Opencpop.\nSome synthesized singing samples are available online\n(https://zzw922cn.github.io/WeSinger/).",
          "link": "http://arxiv.org/abs/2203.10750",
          "publishedOn": "2022-03-26T00:46:05.826Z",
          "wordCount": 591,
          "title": "WeSinger: Data-augmented Singing Voice Synthesis with Auxiliary Losses. (arXiv:2203.10750v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12961",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chada_N/0/1/0/all/0/1\">Neil K. Chada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jasra_A/0/1/0/all/0/1\">Ajay Jasra</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Law_K/0/1/0/all/0/1\">Kody J. H. Law</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Singh_S/0/1/0/all/0/1\">Sumeetpal S. Singh</a>",
          "description": "In this article we consider Bayesian inference associated to deep neural\nnetworks (DNNs) and in particular, trace-class neural network (TNN) priors\nwhich were proposed by Sell et al. [39]. Such priors were developed as more\nrobust alternatives to classical architectures in the context of inference\nproblems. For this work we develop multilevel Monte Carlo (MLMC) methods for\nsuch models. MLMC is a popular variance reduction technique, with particular\napplications in Bayesian statistics and uncertainty quantification. We show how\na particular advanced MLMC method that was introduced in [4] can be applied to\nBayesian inference from DNNs and establish mathematically, that the\ncomputational cost to achieve a particular mean square error, associated to\nposterior expectation computation, can be reduced by several orders, versus\nmore conventional techniques. To verify such results we provide numerous\nnumerical experiments on model problems arising in machine learning. These\ninclude Bayesian regression, as well as Bayesian classification and\nreinforcement learning.",
          "link": "http://arxiv.org/abs/2203.12961",
          "publishedOn": "2022-03-26T00:46:05.820Z",
          "wordCount": 592,
          "title": "Multilevel Bayesin Deep Neural Networks. (arXiv:2203.12961v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.05078",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Domingues_O/0/1/0/all/0/1\">Omar Darwiche Domingues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menard_P/0/1/0/all/0/1\">Pierre M&#xe9;nard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pirotta_M/0/1/0/all/0/1\">Matteo Pirotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufmann_E/0/1/0/all/0/1\">Emilie Kaufmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>",
          "description": "In this work, we propose KeRNS: an algorithm for episodic reinforcement\nlearning in non-stationary Markov Decision Processes (MDPs) whose state-action\nset is endowed with a metric. Using a non-parametric model of the MDP built\nwith time-dependent kernels, we prove a regret bound that scales with the\ncovering dimension of the state-action space and the total variation of the MDP\nwith time, which quantifies its level of non-stationarity. Our method\ngeneralizes previous approaches based on sliding windows and exponential\ndiscounting used to handle changing environments. We further propose a\npractical implementation of KeRNS, we analyze its regret and validate it\nexperimentally.",
          "link": "http://arxiv.org/abs/2007.05078",
          "publishedOn": "2022-03-26T00:46:05.813Z",
          "wordCount": 589,
          "title": "A Kernel-Based Approach to Non-Stationary Reinforcement Learning in Metric Spaces. (arXiv:2007.05078v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13154",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kehrenberg_T/0/1/0/all/0/1\">Thomas Kehrenberg</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bartlett_M/0/1/0/all/0/1\">Myles Bartlett</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sharmanska_V/0/1/0/all/0/1\">Viktoriia Sharmanska</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Quadrianto_N/0/1/0/all/0/1\">Novi Quadrianto</a>",
          "description": "When trained on diverse labeled data, machine learning models have proven\nthemselves to be a powerful tool in all facets of society. However, due to\nbudget limitations, deliberate or non-deliberate censorship, and other problems\nduring data collection and curation, the labeled training set might exhibit a\nsystematic shortage of data for certain groups. We investigate a scenario in\nwhich the absence of certain data is linked to the second level of a two-level\nhierarchy in the data. Inspired by the idea of protected groups from\nalgorithmic fairness, we refer to the partitions carved by this second level as\n\"subgroups\"; we refer to combinations of subgroups and classes, or leaves of\nthe hierarchy, as \"sources\". To characterize the problem, we introduce the\nconcept of classes with incomplete subgroup support. The representational bias\nin the training set can give rise to spurious correlations between the classes\nand the subgroups which render standard classification models ungeneralizable\nto unseen sources. To overcome this bias, we make use of an additional, diverse\nbut unlabeled dataset, called the \"deployment set\", to learn a representation\nthat is invariant to subgroup. This is done by adversarially matching the\nsupport of the training and deployment sets in representation space. In order\nto learn the desired invariance, it is paramount that the sets of samples\nobserved by the discriminator are balanced by class; this is easily achieved\nfor the training set, but requires using semi-supervised clustering for the\ndeployment set. We demonstrate the effectiveness of our method with experiments\non several datasets and variants of the problem.",
          "link": "http://arxiv.org/abs/2203.13154",
          "publishedOn": "2022-03-26T00:46:05.807Z",
          "wordCount": 690,
          "title": "Addressing Missing Sources with Adversarial Support-Matching. (arXiv:2203.13154v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Benato_L/0/1/0/all/0/1\">Lisa Benato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buhmann_E/0/1/0/all/0/1\">Erik Buhmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdmann_M/0/1/0/all/0/1\">Martin Erdmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fackeldey_P/0/1/0/all/0/1\">Peter Fackeldey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glombitza_J/0/1/0/all/0/1\">Jonas Glombitza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartmann_N/0/1/0/all/0/1\">Nikolai Hartmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasieczka_G/0/1/0/all/0/1\">Gregor Kasieczka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korcari_W/0/1/0/all/0/1\">William Korcari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhr_T/0/1/0/all/0/1\">Thomas Kuhr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinheimer_J/0/1/0/all/0/1\">Jan Steinheimer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stocker_H/0/1/0/all/0/1\">Horst St&#xf6;cker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plehn_T/0/1/0/all/0/1\">Tilman Plehn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kai Zhou</a>",
          "description": "We introduce a Python package that provides simply and unified access to a\ncollection of datasets from fundamental physics research - including particle\nphysics, astroparticle physics, and hadron- and nuclear physics - for\nsupervised machine learning studies. The datasets contain hadronic top quarks,\ncosmic-ray induced air showers, phase transitions in hadronic matter, and\ngenerator-level histories. While public datasets from multiple fundamental\nphysics disciplines already exist, the common interface and provided reference\nmodels simplify future work on cross-disciplinary machine learning and transfer\nlearning in fundamental physics. We discuss the design and structure and line\nout how additional datasets can be submitted for inclusion.\n\nAs showcase application, we present a simple yet flexible graph-based neural\nnetwork architecture that can easily be applied to a wide range of supervised\nlearning tasks. We show that our approach reaches performance close to\ndedicated methods on all datasets. To simplify adaptation for various problems,\nwe provide easy-to-follow instructions on how graph-based representations of\ndata structures, relevant for fundamental physics, can be constructed and\nprovide code implementations for several of them. Implementations are also\nprovided for our proposed method and all reference algorithms.",
          "link": "http://arxiv.org/abs/2107.00656",
          "publishedOn": "2022-03-26T00:46:05.801Z",
          "wordCount": 720,
          "title": "Shared Data and Algorithms for Deep Learning in Fundamental Physics. (arXiv:2107.00656v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11528",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_R/0/1/0/all/0/1\">Ruoyu Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yi_M/0/1/0/all/0/1\">Mingyang Yi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1\">Zhitang Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_S/0/1/0/all/0/1\">Shengyu Zhu</a>",
          "description": "In real-world applications, it is important and desirable to learn a model\nthat performs well on out-of-distribution (OOD) data. Recently, causality has\nbecome a powerful tool to tackle the OOD generalization problem, with the idea\nresting on the causal mechanism that is invariant across domains of interest.\nTo leverage the generally unknown causal mechanism, existing works assume a\nlinear form of causal feature or require sufficiently many and diverse training\ndomains, which are usually restrictive in practice. In this work, we obviate\nthese assumptions and tackle the OOD problem without explicitly recovering the\ncausal feature. Our approach is based on transformations that modify the\nnon-causal feature but leave the causal part unchanged, which can be either\nobtained from prior knowledge or learned from the training data in the\nmulti-domain scenario. Under the setting of invariant causal mechanism, we\ntheoretically show that if all such transformations are available, then we can\nlearn a minimax optimal model across the domains using only single domain data.\nNoticing that knowing a complete set of these causal invariant transformations\nmay be impractical, we further show that it suffices to know only a subset of\nthese transformations. Based on the theoretical findings, a regularized\ntraining procedure is proposed to improve the OOD generalization capability.\nExtensive experimental results on both synthetic and real datasets verify the\neffectiveness of the proposed algorithm, even with only a few causal invariant\ntransformations.",
          "link": "http://arxiv.org/abs/2203.11528",
          "publishedOn": "2022-03-26T00:46:05.780Z",
          "wordCount": 695,
          "title": "Out-of-distribution Generalization with Causal Invariant Transformations. (arXiv:2203.11528v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_S/0/1/0/all/0/1\">Shaopeng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_F/0/1/0/all/0/1\">Fengxiang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "The right to be forgotten has been legislated in many countries, but its\nenforcement in the AI industry would cause unbearable costs. When single data\ndeletion requests come, companies may need to delete the whole models learned\nwith massive resources. Existing works propose methods to remove knowledge\nlearned from data for explicitly parameterized models, which however are not\nappliable to the sampling-based Bayesian inference, i.e., Markov chain Monte\nCarlo (MCMC), as MCMC can only infer implicit distributions. In this paper, we\npropose the first machine unlearning algorithm for MCMC. We first convert the\nMCMC unlearning problem into an explicit optimization problem. Based on this\nproblem conversion, an {\\it MCMC influence function} is designed to provably\ncharacterize the learned knowledge from data, which then delivers the MCMC\nunlearning algorithm. Theoretical analysis shows that MCMC unlearning would not\ncompromise the generalizability of the MCMC models. Experiments on Gaussian\nmixture models and Bayesian neural networks confirm the effectiveness of the\nproposed algorithm. The code is available at\n\\url{https://github.com/fshp971/mcmc-unlearning}.",
          "link": "http://arxiv.org/abs/2203.12964",
          "publishedOn": "2022-03-26T00:46:05.774Z",
          "wordCount": 611,
          "title": "Knowledge Removal in Sampling-based Bayesian Inference. (arXiv:2203.12964v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.09478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parunandi_K/0/1/0/all/0/1\">Karthikeya S. Parunandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Aayushman Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_R/0/1/0/all/0/1\">Raman Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravorty_S/0/1/0/all/0/1\">Suman Chakravorty</a>",
          "description": "The problem of Reinforcement Learning (RL) in an unknown nonlinear dynamical\nsystem is equivalent to the search for an optimal feedback law utilizing the\nsimulations/ rollouts of the dynamical system. Most RL techniques search over a\ncomplex global nonlinear feedback parametrization making them suffer from high\ntraining times as well as variance. Instead, we advocate searching over a local\nfeedback representation consisting of an open-loop sequence, and an associated\noptimal linear feedback law completely determined by the open-loop. We show\nthat this alternate approach results in highly efficient training, the answers\nobtained are repeatable and hence reliable, and the resulting closed\nperformance is superior to global state-of-the-art RL techniques. Finally, if\nwe replan, whenever required, which is feasible due to the fast and reliable\nlocal solution, it allows us to recover global optimality of the resulting\nfeedback law.",
          "link": "http://arxiv.org/abs/2002.09478",
          "publishedOn": "2022-03-26T00:46:05.768Z",
          "wordCount": 656,
          "title": "On the Search for Feedback in Reinforcement Learning. (arXiv:2002.09478v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brekelmans_R/0/1/0/all/0/1\">Rob Brekelmans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Genewein_T/0/1/0/all/0/1\">Tim Genewein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grau_Moya_J/0/1/0/all/0/1\">Jordi Grau-Moya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deletang_G/0/1/0/all/0/1\">Gr&#xe9;goire Del&#xe9;tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunesch_M/0/1/0/all/0/1\">Markus Kunesch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Legg_S/0/1/0/all/0/1\">Shane Legg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortega_P/0/1/0/all/0/1\">Pedro Ortega</a>",
          "description": "Policy regularization methods such as maximum entropy regularization are\nwidely used in reinforcement learning to improve the robustness of a learned\npolicy. In this paper, we show how this robustness arises from hedging against\nworst-case perturbations of the reward function, which are chosen from a\nlimited set by an imagined adversary. Using convex duality, we characterize\nthis robust set of adversarial reward perturbations under KL and\nalpha-divergence regularization, which includes Shannon and Tsallis entropy\nregularization as special cases. Importantly, generalization guarantees can be\ngiven within this robust set. We provide detailed discussion of the worst-case\nreward perturbations, and present intuitive empirical examples to illustrate\nthis robustness and its relationship with generalization. Finally, we discuss\nhow our analysis complements and extends previous results on adversarial reward\nrobustness and path consistency optimality conditions.",
          "link": "http://arxiv.org/abs/2203.12592",
          "publishedOn": "2022-03-26T00:46:05.762Z",
          "wordCount": 592,
          "title": "Your Policy Regularizer is Secretly an Adversary. (arXiv:2203.12592v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.10973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ko_T/0/1/0/all/0/1\">Taehee Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiantao Li</a>",
          "description": "Non-convex loss functions arise frequently in modern machine learning, and\nfor the theoretical analysis of stochastic optimization methods, the presence\nof non-isolated minima presents a unique challenge that has remained\nunder-explored. In this paper, we study the local convergence of the stochastic\ngradient descent method to non-isolated global minima. Under mild assumptions,\nwe estimate the probability for the iterations to stay near the minima by\nadopting the notion of stochastic stability. After establishing such stability,\nwe present the lower bound complexity in terms of various error criteria for a\ngiven error tolerance $\\epsilon$ and a failure probability $\\gamma$.",
          "link": "http://arxiv.org/abs/2203.10973",
          "publishedOn": "2022-03-26T00:46:05.742Z",
          "wordCount": 574,
          "title": "A Local Convergence Theory for the Stochastic Gradient Descent Method in Non-Convex Optimization With Non-isolated Local Minima. (arXiv:2203.10973v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.16745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Makhlouf_K/0/1/0/all/0/1\">Karima Makhlouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhioua_S/0/1/0/all/0/1\">Sami Zhioua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1\">Catuscia Palamidessi</a>",
          "description": "Fairness emerged as an important requirement to guarantee that Machine\nLearning (ML) predictive systems do not discriminate against specific\nindividuals or entire sub-populations, in particular, minorities. Given the\ninherent subjectivity of viewing the concept of fairness, several notions of\nfairness have been introduced in the literature. This paper is a survey that\nillustrates the subtleties between fairness notions through a large number of\nexamples and scenarios. In addition, unlike other surveys in the literature, it\naddresses the question of: which notion of fairness is most suited to a given\nreal-world scenario and why? Our attempt to answer this question consists in\n(1) identifying the set of fairness-related characteristics of the real-world\nscenario at hand, (2) analyzing the behavior of each fairness notion, and then\n(3) fitting these two elements to recommend the most suitable fairness notion\nin every specific setup. The results are summarized in a decision diagram that\ncan be used by practitioners and policymakers to navigate the relatively large\ncatalog of ML.",
          "link": "http://arxiv.org/abs/2006.16745",
          "publishedOn": "2022-03-26T00:46:05.736Z",
          "wordCount": 643,
          "title": "On the Applicability of ML Fairness Notions. (arXiv:2006.16745v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.09855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_G/0/1/0/all/0/1\">Guojun Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rahul Singh</a>",
          "description": "We study a finite-horizon restless multi-armed bandit problem with multiple\nactions, dubbed R(MA)^2B. The state of each arm evolves according to a\ncontrolled Markov decision process (MDP), and the reward of pulling an arm\ndepends on both the current state of the corresponding MDP and the action\ntaken. The goal is to sequentially choose actions for arms so as to maximize\nthe expected value of the cumulative rewards collected. Since finding the\noptimal policy is typically intractable, we propose a computationally appealing\nindex policy which we call Occupancy-Measured-Reward Index Policy. Our policy\nis well-defined even if the underlying MDPs are not indexable. We prove that it\nis asymptotically optimal when the activation budget and number of arms are\nscaled up, while keeping their ratio as a constant. For the case when the\nsystem parameters are unknown, we develop a learning algorithm. Our learning\nalgorithm uses the principle of optimism in the face of uncertainty and further\nuses a generative model in order to fully exploit the structure of\nOccupancy-Measured-Reward Index Policy. We call it the R(MA)^2B-UCB algorithm.\nAs compared with the existing algorithms, R(MA)^2B-UCB performs close to an\noffline optimum policy, and also achieves a sub-linear regret with a low\ncomputational complexity. Experimental results show that R(MA)^2B-UCB\noutperforms the existing algorithms in both regret and run time.",
          "link": "http://arxiv.org/abs/2109.09855",
          "publishedOn": "2022-03-26T00:46:05.730Z",
          "wordCount": 704,
          "title": "Reinforcement Learning for Finite-Horizon Restless Multi-Armed Multi-Action Bandits. (arXiv:2109.09855v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12913",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Ka Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paritosh_P/0/1/0/all/0/1\">Praveen Paritosh</a>",
          "description": "Since the inception of crowdsourcing, aggregation has been a common strategy\nfor dealing with unreliable data. Aggregate ratings are more reliable than\nindividual ones. However, many natural language processing (NLP) applications\nthat rely on aggregate ratings only report the reliability of individual\nratings, which is the incorrect unit of analysis. In these instances, the data\nreliability is under-reported, and a proposed k-rater reliability (kRR) should\nbe used as the correct data reliability for aggregated datasets. It is a\nmulti-rater generalization of inter-rater reliability (IRR). We conducted two\nreplications of the WordSim-353 benchmark, and present empirical, analytical,\nand bootstrap-based methods for computing kRR on WordSim-353. These methods\nproduce very similar results. We hope this discussion will nudge researchers to\nreport kRR in addition to IRR.",
          "link": "http://arxiv.org/abs/2203.12913",
          "publishedOn": "2022-03-26T00:46:05.723Z",
          "wordCount": 563,
          "title": "k-Rater Reliability: The Correct Unit of Reliability for Aggregated Human Annotations. (arXiv:2203.12913v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levada_A/0/1/0/all/0/1\">Alexandre L. M. Levada</a>",
          "description": "The Kullback-Leibler divergence or relative entropy is an\ninformation-theoretic measure between statistical models that play an important\nrole in measuring a distance between random variables. In the study of complex\nsystems, random fields are mathematical structures that models the interaction\nbetween these variables by means of an inverse temperature parameter,\nresponsible for controlling the spatial dependence structure along the field.\nIn this paper, we derive closed-form expressions for the Kullback-Leibler\ndivergence between two pairwise isotropic Gaussian-Markov random fields in both\nunivariate and multivariate cases. The proposed equation allows the development\nof novel similarity measures in image processing and machine learning\napplications, such as image denoising and unsupervised metric learning.",
          "link": "http://arxiv.org/abs/2203.13164",
          "publishedOn": "2022-03-26T00:46:05.716Z",
          "wordCount": 570,
          "title": "On the Kullback-Leibler divergence between pairwise isotropic Gaussian-Markov random fields. (arXiv:2203.13164v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12794",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xin_L/0/1/0/all/0/1\">Lei Xin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chiu_G/0/1/0/all/0/1\">George Chiu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sundaram_S/0/1/0/all/0/1\">Shreyas Sundaram</a>",
          "description": "We consider the problem of learning the dynamics of autonomous linear systems\n(i.e., systems that are not affected by external control inputs) from\nobservations of multiple trajectories of those systems, with finite sample\nguarantees. Existing results on learning rate and consistency of autonomous\nlinear system identification rely on observations of steady state behaviors\nfrom a single long trajectory, and are not applicable to unstable systems. In\ncontrast, we consider the scenario of learning system dynamics based on\nmultiple short trajectories, where there are no easily observed steady state\nbehaviors. We provide a finite sample analysis, which shows that the dynamics\ncan be learned at a rate $\\mathcal{O}(\\frac{1}{\\sqrt{N}})$ for both stable and\nunstable systems, where $N$ is the number of trajectories, when the initial\nstate of the system has zero mean (which is a common assumption in the existing\nliterature). We further generalize our result to the case where the initial\nstate has non-zero mean. We show that one can adjust the length of the\ntrajectories to achieve a learning rate of\n$\\mathcal{O}(\\sqrt{\\frac{\\log{N}}{N})}$ for strictly stable systems and a\nlearning rate of $\\mathcal{O}(\\frac{(\\log{N})^d}{\\sqrt{N}})$ for marginally\nstable systems, where $d$ is some constant.",
          "link": "http://arxiv.org/abs/2203.12794",
          "publishedOn": "2022-03-26T00:46:05.696Z",
          "wordCount": 652,
          "title": "Learning the Dynamics of Autonomous Linear Systems From Multiple Trajectories. (arXiv:2203.12794v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Urteaga_I/0/1/0/all/0/1\">I&#xf1;igo Urteaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Draidia_M/0/1/0/all/0/1\">Moulay-Za&#xef;dane Dra&#xef;dia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lancewicki_T/0/1/0/all/0/1\">Tomer Lancewicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_S/0/1/0/all/0/1\">Shahram Khadivi</a>",
          "description": "Transformer-based language models (TLMs) provide state-of-the-art performance\nin many modern natural language processing applications. TLM training is\nconducted in two phases. First, the model is pre-trained over large volumes of\ntext to minimize a generic objective function, such as the Masked Language\nModel (MLM). Second, the model is fine-tuned in specific downstream tasks.\nPre-training requires large volumes of data and high computational resources,\nwhile introducing many still unresolved design choices. For instance, selecting\nhyperparameters for language model pre-training is often carried out based on\nheuristics or grid-based searches. In this work, we propose a multi-armed\nbandit-based online optimization framework for the sequential selection of\npre-training hyperparameters to optimize language model performance. We pose\nthe pre-training procedure as a sequential decision-making task, where at each\npre-training step, an agent must determine what hyperparameters to use towards\noptimizing the pre-training objective. We propose a Thompson sampling bandit\nalgorithm, based on a surrogate Gaussian process reward model of the MLM\npre-training objective, for its sequential minimization. We empirically show\nhow the proposed Gaussian process based Thompson sampling pre-trains robust and\nwell-performing language models. Namely, by sequentially selecting masking\nhyperparameters of the TLM, we achieve satisfactory performance in less epochs,\nnot only in terms of the pre-training MLM objective, but in diverse downstream\nfine-tuning tasks. The proposed bandit-based technique provides an automated\nhyperparameter selection method for pre-training TLMs of interest to\npractitioners. In addition, our results indicate that, instead of MLM\npre-training with fixed masking probabilities, sequentially adapting the\nmasking hyperparameters improves both pre-training loss and downstream task\nmetrics.",
          "link": "http://arxiv.org/abs/2203.13151",
          "publishedOn": "2022-03-26T00:46:05.689Z",
          "wordCount": 712,
          "title": "Multi-armed bandits for online optimization of language model pre-training: the use case of dynamic masking. (arXiv:2203.13151v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_C/0/1/0/all/0/1\">Cheng Kevin Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wardak_A/0/1/0/all/0/1\">Asem Wardak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_P/0/1/0/all/0/1\">Pulin Gong</a>",
          "description": "Deep neural networks (DNNs) have been successfully applied to many real-world\nproblems, but a complete understanding of their dynamical and computational\nprinciples is still lacking. Conventional theoretical frameworks for analysing\nDNNs often assume random networks with coupling weights obeying Gaussian\nstatistics. However, non-Gaussian, heavy-tailed coupling is a ubiquitous\nphenomenon in DNNs. Here, by weaving together theories of heavy-tailed random\nmatrices and non-equilibrium statistical physics, we develop a new type of mean\nfield theory for DNNs which predicts that heavy-tailed weights enable the\nemergence of an extended critical regime without fine-tuning parameters. In\nthis extended critical regime, DNNs exhibit rich and complex propagation\ndynamics across layers. We further elucidate that the extended criticality\nendows DNNs with profound computational advantages: balancing the contraction\nas well as expansion of internal neural representations and speeding up\ntraining processes, hence providing a theoretical guide for the design of\nefficient neural architectures.",
          "link": "http://arxiv.org/abs/2203.12967",
          "publishedOn": "2022-03-26T00:46:05.681Z",
          "wordCount": 596,
          "title": "Extended critical regimes of deep neural networks. (arXiv:2203.12967v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Friedlander_T/0/1/0/all/0/1\">Tomer Friedlander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>",
          "description": "Canonical Correlation Analysis (CCA) is a method for feature extraction of\ntwo views by finding maximally correlated linear projections of them. Several\nvariants of CCA have been introduced in the literature, in particular, variants\nbased on deep neural networks for learning highly correlated nonlinear\ntransformations of two views. As these models are parameterized conventionally,\ntheir learnable parameters remain independent of the inputs after the training\nprocess, which may limit their capacity for learning highly correlated\nrepresentations. We introduce a novel dynamic scaling method for training an\ninput-dependent canonical correlation model. In our deep-CCA models, the\nparameters of the last layer are scaled by a second neural network that is\nconditioned on the model's input, resulting in a parameterization that is\ndependent on the input samples. We evaluate our model on multiple datasets and\ndemonstrate that the learned representations are more correlated in comparison\nto the conventionally-parameterized CCA-based models and also obtain preferable\nretrieval results. Our code is available at\nhttps://github.com/tomerfr/DynamicallyScaledDeepCCA.",
          "link": "http://arxiv.org/abs/2203.12377",
          "publishedOn": "2022-03-26T00:46:05.674Z",
          "wordCount": 607,
          "title": "Dynamically-Scaled Deep Canonical Correlation Analysis. (arXiv:2203.12377v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.03820",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Amoukou_S/0/1/0/all/0/1\">Salim I. Amoukou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brunel_N/0/1/0/all/0/1\">Nicolas J-B. Brunel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Salaun_T/0/1/0/all/0/1\">Tangi Sala&#xfc;n</a>",
          "description": "Although Shapley Values (SV) are widely used in explainable AI, they can be\npoorly understood and estimated, implying that their analysis may lead to\nspurious inferences and explanations. As a starting point, we remind an\ninvariance principle for SV and derive the correct approach for computing the\nSV of categorical variables that are particularly sensitive to the encoding\nused. In the case of tree-based models, we introduce two estimators of Shapley\nValues that exploit the tree structure efficiently and are more accurate than\nstate-of-the-art methods. Simulations and comparisons are performed with\nstate-of-the-art algorithms and show the practical gain of our approach.\nFinally, we discuss the ability of SV to provide reliable local explanations.\nWe also provide a Python package that computes our estimators at\nhttps://github.com/salimamoukou/acv00.",
          "link": "http://arxiv.org/abs/2106.03820",
          "publishedOn": "2022-03-26T00:46:05.656Z",
          "wordCount": 611,
          "title": "Accurate Shapley Values for explaining tree-based models. (arXiv:2106.03820v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12808",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Guo_Z/0/1/0/all/0/1\">Zijian Guo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Buhlmann_P/0/1/0/all/0/1\">Peter B&#xfc;hlmann</a>",
          "description": "Instrumental variables regression is a popular causal inference method for\nendogenous treatment. A significant concern in practical applications is the\nvalidity and strength of instrumental variables. This paper aims to perform\ncausal inference when all instruments are possibly invalid. To do this, we\npropose a novel methodology called two stage curvature identification (TSCI)\ntogether with a generalized concept to measure the strengths of possibly\ninvalid instruments: such invalid instruments can still be used for inference\nin our framework. We fit the treatment model with a general machine learning\nmethod and propose a novel bias correction method to remove the overfitting\nbias from machine learning methods. Among a collection of spaces of violation\nfunctions, we choose the best one by evaluating invalid instrumental variables'\nstrength. We demonstrate our proposed TSCI methodology in a large-scale\nsimulation study and revisit the important economics question on the effect of\neducation on earnings.",
          "link": "http://arxiv.org/abs/2203.12808",
          "publishedOn": "2022-03-26T00:46:05.650Z",
          "wordCount": 596,
          "title": "Two Stage Curvature Identification with Machine Learning: Causal Inference with Possibly Invalid Instrumental Variables. (arXiv:2203.12808v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12720",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+McCarter_C/0/1/0/all/0/1\">Calvin McCarter</a>",
          "description": "Current domain adaptation methods address the problems of covariate shift or\nlabel shift, but are not applicable to the setting where they occur\nsimultaneously and interact with each other. In this paper, we propose an\nassumption, confounded shift, to begin to address this problem. We also propose\na framework for this task, based on minimizing the expected divergence between\nthe source and target conditional distributions. Within this framework, we\npropose using the reverse KL divergence, demonstrating the use of both\nparametric linear Gaussian and nonparametric nonlinear Gaussian Process\nestimators of the conditional distribution. We also propose using the Maximum\nMean Discrepancy (MMD) within our framework. To make confounded domain\nadaptation with the MMD effective, we propose an intelligent dynamic strategy\nfor choosing the kernel bandwidth, which may be of independent interest even\noutside of the confounded shift context. Finally, we show that our approach is\nadvantageous on a variety of synthetic and real datasets.",
          "link": "http://arxiv.org/abs/2203.12720",
          "publishedOn": "2022-03-26T00:46:05.630Z",
          "wordCount": 580,
          "title": "Towards All-Purpose Domain Adaptation Under Confounding. (arXiv:2203.12720v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dullerud_N/0/1/0/all/0/1\">Natalie Dullerud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Karsten Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamidieh_K/0/1/0/all/0/1\">Kimia Hamidieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1\">Nicolas Papernot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Marzyeh Ghassemi</a>",
          "description": "Deep metric learning (DML) enables learning with less supervision through its\nemphasis on the similarity structure of representations. There has been much\nwork on improving generalization of DML in settings like zero-shot retrieval,\nbut little is known about its implications for fairness. In this paper, we are\nthe first to evaluate state-of-the-art DML methods trained on imbalanced data,\nand to show the negative impact these representations have on minority subgroup\nperformance when used for downstream tasks. In this work, we first define\nfairness in DML through an analysis of three properties of the representation\nspace -- inter-class alignment, intra-class alignment, and uniformity -- and\npropose finDML, the fairness in non-balanced DML benchmark to characterize\nrepresentation fairness. Utilizing finDML, we find bias in DML representations\nto propagate to common downstream classification tasks. Surprisingly, this bias\nis propagated even when training data in the downstream task is re-balanced. To\naddress this problem, we present Partial Attribute De-correlation (PARADE) to\nde-correlate feature representations from sensitive attributes and reduce\nperformance gaps between subgroups in both embedding space and downstream\nmetrics.",
          "link": "http://arxiv.org/abs/2203.12748",
          "publishedOn": "2022-03-26T00:46:05.620Z",
          "wordCount": 646,
          "title": "Is Fairness Only Metric Deep? Evaluating and Addressing Subgroup Gaps in Deep Metric Learning. (arXiv:2203.12748v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12730",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lenz_D/0/1/0/all/0/1\">David Lenz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yeh_R/0/1/0/all/0/1\">Raine Yeh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mahadevan_V/0/1/0/all/0/1\">Vijay Mahadevan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Grindeanu_I/0/1/0/all/0/1\">Iulian Grindeanu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Peterka_T/0/1/0/all/0/1\">Tom Peterka</a>",
          "description": "B-spline models are a powerful way to represent scientific data sets with a\nfunctional approximation. However, these models can suffer from spurious\noscillations when the data to be approximated are not uniformly distributed.\nModel regularization (i.e., smoothing) has traditionally been used to minimize\nthese oscillations; unfortunately, it is sometimes impossible to sufficiently\nremove unwanted artifacts without smoothing away key features of the data set.\nIn this article, we present a method of model regularization that preserves\nsignificant features of a data set while minimizing artificial oscillations.\nOur method varies the strength of a smoothing parameter throughout the domain\nautomatically, removing artifacts in poorly-constrained regions while leaving\nother regions unchanged. The behavior of our method is validated on a\ncollection of two- and three-dimensional data sets produced by scientific\nsimulations.",
          "link": "http://arxiv.org/abs/2203.12730",
          "publishedOn": "2022-03-26T00:46:05.609Z",
          "wordCount": 590,
          "title": "Adaptive Regularization of B-Spline Models for Scientific Data. (arXiv:2203.12730v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Costales_R/0/1/0/all/0/1\">Robby Costales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_S/0/1/0/all/0/1\">Shariq Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_F/0/1/0/all/0/1\">Fei Sha</a>",
          "description": "Reinforcement learning algorithms struggle on tasks with complex hierarchical\ndependency structures. Humans and other intelligent agents do not waste time\nassessing the utility of every high-level action in existence, but instead only\nconsider ones they deem possible in the first place. By focusing only on what\nis feasible, or \"afforded\", at the present moment, an agent can spend more time\nboth evaluating the utility of and acting on what matters. To this end, we\npresent Hierarchical Affordance Learning (HAL), a method that learns a model of\nhierarchical affordances in order to prune impossible subtasks for more\neffective learning. Existing works in hierarchical reinforcement learning\nprovide agents with structural representations of subtasks but are not\naffordance-aware, and by grounding our definition of hierarchical affordances\nin the present state, our approach is more flexible than the multitude of\napproaches that ground their subtask dependencies in a symbolic history. While\nthese logic-based methods often require complete knowledge of the subtask\nhierarchy, our approach is able to utilize incomplete and varying symbolic\nspecifications. Furthermore, we demonstrate that relative to\nnon-affordance-aware methods, HAL agents are better able to efficiently learn\ncomplex tasks, navigate environment stochasticity, and acquire diverse skills\nin the absence of extrinsic supervision -- all of which are hallmarks of human\nlearning.",
          "link": "http://arxiv.org/abs/2203.12686",
          "publishedOn": "2022-03-26T00:46:05.592Z",
          "wordCount": 659,
          "title": "Possibility Before Utility: Learning And Using Hierarchical Affordances. (arXiv:2203.12686v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stanton_S/0/1/0/all/0/1\">Samuel Stanton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddox_W/0/1/0/all/0/1\">Wesley Maddox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruver_N/0/1/0/all/0/1\">Nate Gruver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maffettone_P/0/1/0/all/0/1\">Phillip Maffettone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delaney_E/0/1/0/all/0/1\">Emily Delaney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenside_P/0/1/0/all/0/1\">Peyton Greenside</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>",
          "description": "Bayesian optimization is a gold standard for query-efficient continuous\noptimization. However, its adoption for drug and antibody sequence design has\nbeen hindered by the discrete, high-dimensional nature of the decision\nvariables. We develop a new approach (LaMBO) which jointly trains a denoising\nautoencoder with a discriminative multi-task Gaussian process head, enabling\ngradient-based optimization of multi-objective acquisition functions in the\nlatent space of the autoencoder. These acquisition functions allow LaMBO to\nbalance the explore-exploit trade-off over multiple design rounds, and to\nbalance objective tradeoffs by optimizing sequences at many different points on\nthe Pareto frontier. We evaluate LaMBO on a small-molecule task based on the\nZINC dataset and introduce a new large-molecule task targeting fluorescent\nproteins. In our experiments, LaMBO outperforms genetic optimizers and does not\nrequire a large pretraining corpus, demonstrating that Bayesian optimization is\npractical and effective for biological sequence design.",
          "link": "http://arxiv.org/abs/2203.12742",
          "publishedOn": "2022-03-26T00:46:05.585Z",
          "wordCount": 602,
          "title": "Accelerating Bayesian Optimization for Biological Sequence Design with Denoising Autoencoders. (arXiv:2203.12742v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09472",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Entwistle_M/0/1/0/all/0/1\">Mike Entwistle</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schatzle_Z/0/1/0/all/0/1\">Zeno Sch&#xe4;tzle</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Erdman_P/0/1/0/all/0/1\">Paolo A. Erdman</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hermann_J/0/1/0/all/0/1\">Jan Hermann</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Noe_F/0/1/0/all/0/1\">Frank No&#xe9;</a>",
          "description": "Obtaining accurate ground and low-lying excited states of electronic systems\nis crucial in a multitude of important applications. One ab initio method for\nsolving the electronic Schr\\\"odinger equation that scales favorably for large\nsystems and whose accuracy is limited only by the choice of wavefunction ansatz\nemployed is variational quantum Monte Carlo (QMC). The recently introduced deep\nQMC approach, using a new class of ansatzes represented by deep neural\nnetworks, has been shown to generate nearly exact ground-state solutions for\nmolecules containing up to a few dozen electrons, with the potential to scale\nto much larger systems where other highly accurate methods are not feasible. In\nthis paper, we advance one such ansatz (PauliNet) to compute electronic excited\nstates through a simple variational procedure. We demonstrate our method on a\nvariety of small atoms and molecules where we consistently achieve high\naccuracy for low-lying states. To highlight the method's potential for larger\nsystems, we show that for the benzene molecule, PauliNet is on par with\nsignificantly more expensive high-level electronic structure methods in terms\nof the excitation energy and outperforms them in terms of absolute energies.",
          "link": "http://arxiv.org/abs/2203.09472",
          "publishedOn": "2022-03-19T00:42:46.442Z",
          "wordCount": 630,
          "title": "Electronic excited states in deep variational Monte Carlo. (arXiv:2203.09472v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seitzer_M/0/1/0/all/0/1\">Maximilian Seitzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavakoli_A/0/1/0/all/0/1\">Arash Tavakoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antic_D/0/1/0/all/0/1\">Dimitrije Antic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martius_G/0/1/0/all/0/1\">Georg Martius</a>",
          "description": "Capturing aleatoric uncertainty is a critical part of many machine learning\nsystems. In deep learning, a common approach to this end is to train a neural\nnetwork to estimate the parameters of a heteroscedastic Gaussian distribution\nby maximizing the logarithm of the likelihood function under the observed data.\nIn this work, we examine this approach and identify potential hazards\nassociated with the use of log-likelihood in conjunction with gradient-based\noptimizers. First, we present a synthetic example illustrating how this\napproach can lead to very poor but stable parameter estimates. Second, we\nidentify the culprit to be the log-likelihood loss, along with certain\nconditions that exacerbate the issue. Third, we present an alternative\nformulation, termed $\\beta$-NLL, in which each data point's contribution to the\nloss is weighted by the $\\beta$-exponentiated variance estimate. We show that\nusing an appropriate $\\beta$ largely mitigates the issue in our illustrative\nexample. Fourth, we evaluate this approach on a range of domains and tasks and\nshow that it achieves considerable improvements and performs more robustly\nconcerning hyperparameters, both in predictive RMSE and log-likelihood\ncriteria.",
          "link": "http://arxiv.org/abs/2203.09168",
          "publishedOn": "2022-03-19T00:42:46.435Z",
          "wordCount": 633,
          "title": "On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks. (arXiv:2203.09168v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08887",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ru_B/0/1/0/all/0/1\">Binxin Ru</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Esperanca_P/0/1/0/all/0/1\">Pedro M. Esperan&#xe7;a</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>",
          "description": "Searching for the architecture cells is a dominant paradigm in NAS. However,\nlittle attention has been devoted to the analysis of the cell-based search\nspaces even though it is highly important for the continual development of NAS.\nIn this work, we conduct an empirical post-hoc analysis of architectures from\nthe popular cell-based search spaces and find that the existing search spaces\ncontain a high degree of redundancy: the architecture performance is minimally\nsensitive to changes at large parts of the cells, and universally adopted\ndesigns, like the explicit search for a reduction cell, significantly increase\nthe complexities but have very limited impact on the performance. Across\narchitectures found by a diverse set of search strategies, we consistently find\nthat the parts of the cells that do matter for architecture performance often\nfollow similar and simple patterns. By explicitly constraining cells to include\nthese patterns, randomly sampled architectures can match or even outperform the\nstate of the art. These findings cast doubts into our ability to discover truly\nnovel architectures in the existing cell-based search spaces, and inspire our\nsuggestions for improvement to guide future NAS research. Code is available at\nhttps://github.com/xingchenwan/cell-based-NAS-analysis.",
          "link": "http://arxiv.org/abs/2203.08887",
          "publishedOn": "2022-03-19T00:42:46.193Z",
          "wordCount": 656,
          "title": "On Redundancy and Diversity in Cell-based Neural Architecture Search. (arXiv:2203.08887v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schleibaum_S/0/1/0/all/0/1\">S&#xf6;ren Schleibaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_J/0/1/0/all/0/1\">J&#xf6;rg P. M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sester_M/0/1/0/all/0/1\">Monika Sester</a>",
          "description": "To compare alternative taxi schedules and to compute them, as well as to\nprovide insights into an upcoming taxi trip to drivers and passengers, the\nduration of a trip or its Estimated Time of Arrival (ETA) is predicted. To\nreach a high prediction precision, machine learning models for ETA are state of\nthe art. One yet unexploited option to further increase prediction precision is\nto combine multiple ETA models into an ensemble. While an increase of\nprediction precision is likely, the main drawback is that the predictions made\nby such an ensemble become less transparent due to the sophisticated ensemble\narchitecture. One option to remedy this drawback is to apply eXplainable\nArtificial Intelligence (XAI). The contribution of this paper is three-fold.\nFirst, we combine multiple machine learning models from our previous work for\nETA into a two-level ensemble model - a stacked ensemble model - which on its\nown is novel; therefore, we can outperform previous state-of-the-art static\nroute-free ETA approaches. Second, we apply existing XAI methods to explain the\nfirst- and second-level models of the ensemble. Third, we propose three joining\nmethods for combining the first-level explanations with the second-level ones.\nThose joining methods enable us to explain stacked ensembles for regression\ntasks. An experimental evaluation shows that the ETA models correctly learned\nthe importance of those input features driving the prediction.",
          "link": "http://arxiv.org/abs/2203.09438",
          "publishedOn": "2022-03-19T00:42:46.179Z",
          "wordCount": 669,
          "title": "An Explainable Stacked Ensemble Model for Static Route-Free Estimation of Time of Arrival. (arXiv:2203.09438v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08161",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Bazarov_A/0/1/0/all/0/1\">Abdullah Bazarov</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Benito_M/0/1/0/all/0/1\">Mar&#xed;a Benito</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Hutsi_G/0/1/0/all/0/1\">Gert H&#xfc;tsi</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kipper_R/0/1/0/all/0/1\">Rain Kipper</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Pata_J/0/1/0/all/0/1\">Joosep Pata</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Poder_S/0/1/0/all/0/1\">Sven P&#xf5;der</a>",
          "description": "The abundance of dark matter subhalos orbiting a host galaxy is a generic\nprediction of the cosmological framework. It is a promising way to constrain\nthe nature of dark matter. Here we describe the challenges of detecting stars\nwhose phase-space distribution may be perturbed by the passage of dark matter\nsubhalos using a machine learning approach. The training data are three Milky\nWay-like galaxies and nine synthetic Gaia DR2 surveys derived from these. We\nfirst quantify the magnitude of the perturbations in the simulated galaxies\nusing an anomaly detection algorithm. We also estimate the feasibility of this\napproach in the Gaia DR2-like catalogues by comparing the anomaly detection\nbased approach with a supervised classification. We find that a classification\nalgorithm optimized on about half a billion synthetic star observables exhibits\nmild but nonzero sensitivity. This classification-based approach is not\nsufficiently sensitive to pinpoint the exact locations of subhalos in the\nsimulation, as would be expected from the very limited number of subhalos in\nthe detectable region. The enormous size of the Gaia dataset motivates the\nfurther development of scalable and accurate computational methods that could\nbe used to select potential regions of interest for dark matter searches to\nultimately constrain the Milky Way's subhalo mass function.",
          "link": "http://arxiv.org/abs/2203.08161",
          "publishedOn": "2022-03-19T00:42:46.172Z",
          "wordCount": 691,
          "title": "Sensitivity Estimation for Dark Matter Subhalos in Synthetic Gaia DR2 using Deep Learning. (arXiv:2203.08161v1 [astro-ph.GA] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08857",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qiu_Y/0/1/0/all/0/1\">Yuning Qiu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_G/0/1/0/all/0/1\">Guoxu Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_Q/0/1/0/all/0/1\">Qibin Zhao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_S/0/1/0/all/0/1\">Shengli Xie</a>",
          "description": "Tensor completion is a fundamental tool for incomplete data analysis, where\nthe goal is to predict missing entries from partial observations. However,\nexisting methods often make the explicit or implicit assumption that the\nobserved entries are noise-free to provide a theoretical guarantee of exact\nrecovery of missing entries, which is quite restrictive in practice. To remedy\nsuch drawbacks, this paper proposes a novel noisy tensor completion model,\nwhich complements the incompetence of existing works in handling the\ndegeneration of high-order and noisy observations. Specifically, the tensor\nring nuclear norm (TRNN) and least-squares estimator are adopted to regularize\nthe underlying tensor and the observed entries, respectively. In addition, a\nnon-asymptotic upper bound of estimation error is provided to depict the\nstatistical performance of the proposed estimator. Two efficient algorithms are\ndeveloped to solve the optimization problem with convergence guarantee, one of\nwhich is specially tailored to handle large-scale tensors by replacing the\nminimization of TRNN of the original tensor equivalently with that of a much\nsmaller one in a heterogeneous tensor decomposition framework. Experimental\nresults on both synthetic and real-world data demonstrate the effectiveness and\nefficiency of the proposed model in recovering noisy incomplete tensor data\ncompared with state-of-the-art tensor completion models.",
          "link": "http://arxiv.org/abs/2203.08857",
          "publishedOn": "2022-03-19T00:42:46.165Z",
          "wordCount": 640,
          "title": "Noisy Tensor Completion via Low-rank Tensor Ring. (arXiv:2203.08857v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.05467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qizhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>",
          "description": "The drastic increase of data quantity often brings the severe decrease of\ndata quality, such as incorrect label annotations, which poses a great\nchallenge for robustly training Deep Neural Networks (DNNs). Existing learning\n\\mbox{methods} with label noise either employ ad-hoc heuristics or restrict to\nspecific noise assumptions. However, more general situations, such as\ninstance-dependent label noise, have not been fully explored, as scarce studies\nfocus on their label corruption process. By categorizing instances into\nconfusing and unconfusing instances, this paper proposes a simple yet universal\nprobabilistic model, which explicitly relates noisy labels to their instances.\nThe resultant model can be realized by DNNs, where the training procedure is\naccomplished by employing an alternating optimization algorithm. Experiments on\ndatasets with both synthetic and real-world label noise verify that the\nproposed method yields significant improvements on robustness over\nstate-of-the-art counterparts.",
          "link": "http://arxiv.org/abs/2101.05467",
          "publishedOn": "2022-03-19T00:42:46.139Z",
          "wordCount": 622,
          "title": "Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model. (arXiv:2101.05467v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09347",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Eckstein_S/0/1/0/all/0/1\">Stephan Eckstein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iske_A/0/1/0/all/0/1\">Armin Iske</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Trabs_M/0/1/0/all/0/1\">Mathias Trabs</a>",
          "description": "In a high-dimensional regression framework, we study consequences of the\nnaive two-step procedure where first the dimension of the input variables is\nreduced and second, the reduced input variables are used to predict the output\nvariable. More specifically we combine principal component analysis (PCA) with\nkernel regression. In order to analyze the resulting regression errors, a novel\nstability result of kernel regression with respect to the Wasserstein distance\nis derived. This allows us to bound errors that occur when perturbed input data\nis used to fit a kernel function. We combine the stability result with known\nestimates from the literature on both principal component analysis and kernel\nregression to obtain convergence rates for the two-step procedure.",
          "link": "http://arxiv.org/abs/2203.09347",
          "publishedOn": "2022-03-19T00:42:46.073Z",
          "wordCount": 562,
          "title": "Dimensionality Reduction and Wasserstein Stability for Kernel Regression. (arXiv:2203.09347v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00520",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Puli_A/0/1/0/all/0/1\">Aahlad Puli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lily H. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oermann_E/0/1/0/all/0/1\">Eric K. Oermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>",
          "description": "In many prediction problems, spurious correlations are induced by a changing\nrelationship between the label and a nuisance variable that is also correlated\nwith the covariates. For example, in classifying animals in natural images, the\nbackground, which is a nuisance, can predict the type of animal. This\nnuisance-label relationship does not always hold, and the performance of a\nmodel trained under one such relationship may be poor on data with a different\nnuisance-label relationship. To build predictive models that perform well\nregardless of the nuisance-label relationship, we develop Nuisance-Randomized\nDistillation (NURD). We introduce the nuisance-randomized distribution, a\ndistribution where the nuisance and the label are independent. Under this\ndistribution, we define the set of representations such that conditioning on\nany member, the nuisance and the label remain independent. We prove that the\nrepresentations in this set always perform better than chance, while\nrepresentations outside of this set may not. NURD finds a representation from\nthis set that is most informative of the label under the nuisance-randomized\ndistribution, and we prove that this representation achieves the highest\nperformance regardless of the nuisance-label relationship. We evaluate NURD on\nseveral tasks including chest X-ray classification where, using non-lung\npatches as the nuisance, NURD produces models that predict pneumonia under\nstrong spurious correlations.",
          "link": "http://arxiv.org/abs/2107.00520",
          "publishedOn": "2022-03-19T00:42:46.067Z",
          "wordCount": 700,
          "title": "Out-of-distribution Generalization in the Presence of Nuisance-Induced Spurious Correlations. (arXiv:2107.00520v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.06853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozbay_E/0/1/0/all/0/1\">Eren Ozbay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamble_V/0/1/0/all/0/1\">Vijay Kamble</a>",
          "description": "On-demand labor platforms aim to train a skilled workforce to serve its\nincoming demand for jobs. Since limited jobs are available for training, and it\nis usually not necessary to train all workers, efficient matching of training\njobs requires prioritizing fast learners over slow ones. However, the learning\nrates of novice workers are unknown, resulting in a tradeoff between\nexploration (learning the learning rates) and exploitation (training the best\nworkers). Motivated to study this tradeoff, we analyze a novel objective within\nthe stochastic multi-armed bandit framework. Given $K$ arms, instead of\nmaximizing the expected total reward from $T$ pulls (the traditional \"sum\"\nobjective), we consider the vector of cumulative rewards earned from the $K$\narms at the end of $T$ pulls and aim to maximize the expected highest\ncumulative reward (the \"max\" objective). When rewards represent skill\nincrements, this corresponds to the objective of training a single highly\nskilled worker from a set of novice workers, using a limited supply of training\njobs. For this objective, we show that any policy must incur an\ninstance-dependent asymptotic regret of $\\Omega(\\log T)$ (with a higher\ninstance-dependent constant) and a worst-case regret of\n$\\Omega(K^{1/3}T^{2/3})$. We then design an explore-then-commit policy\nfeaturing exploration based on appropriately tuned confidence bounds on the\nmean reward and an adaptive stopping criterion, which adapts to the problem\ndifficulty and achieves these bounds (up to logarithmic factors). We generalize\nour algorithmic insights to the problem of maximizing the expected value of the\naverage cumulative reward of the top $m$ arms with the highest cumulative\nrewards, corresponding to the case where multiple workers must be trained. Our\nnumerical experiments demonstrate the efficacy of our policies compared to\nseveral natural alternatives in practical parameter regimes.",
          "link": "http://arxiv.org/abs/2006.06853",
          "publishedOn": "2022-03-19T00:42:46.060Z",
          "wordCount": 769,
          "title": "Bandit Labor Training. (arXiv:2006.06853v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruihan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_P/0/1/0/all/0/1\">Prakhar Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Denoising diffusion probabilistic models are a promising new class of\ngenerative models that are competitive with GANs on perceptual metrics. In this\npaper, we explore their potential for sequentially generating video. Inspired\nby recent advances in neural video compression, we use denoising diffusion\nmodels to stochastically generate a residual to a deterministic next-frame\nprediction. We compare this approach to two sequential VAE and two GAN\nbaselines on four datasets, where we test the generated frames for perceptual\nquality and forecasting accuracy against ground truth frames. We find\nsignificant improvements in terms of perceptual quality on all data and\nimprovements in terms of frame forecasting for complex high-resolution videos.",
          "link": "http://arxiv.org/abs/2203.09481",
          "publishedOn": "2022-03-19T00:42:46.037Z",
          "wordCount": 562,
          "title": "Diffusion Probabilistic Modeling for Video Generation. (arXiv:2203.09481v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hua_M/0/1/0/all/0/1\">Mingzhuang Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereira_F/0/1/0/all/0/1\">Francisco Camara Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuewu Chen</a>",
          "description": "The urban transportation system is a combination of multiple transport modes,\nand the interdependencies across those modes exist. This means that the travel\ndemand across different travel modes could be correlated as one mode may\nreceive demand from or create demand for another mode, not to mention natural\ncorrelations between different demand time series due to general demand flow\npatterns across the network. It is expectable that cross-modal ripple effects\nbecome more prevalent, with Mobility as a Service. Therefore, by propagating\ndemand data across modes, a better demand prediction could be obtained. To this\nend, this study explores various machine learning models and transfer learning\nstrategies for cross-modal demand prediction. The trip data of bike-share,\nmetro, and taxi are processed as the station-level passenger flows, and then\nthe proposed prediction method is tested in the large-scale case studies of\nNanjing and Chicago. The results suggest that prediction models with transfer\nlearning perform better than unimodal prediction models. Furthermore, stacked\nLong Short-Term Memory model performs particularly well in cross-modal demand\nprediction. These results verify our combined method's forecasting improvement\nover existing benchmarks and demonstrate the good transferability for\ncross-modal demand prediction in multiple cities.",
          "link": "http://arxiv.org/abs/2203.09279",
          "publishedOn": "2022-03-19T00:42:46.031Z",
          "wordCount": 642,
          "title": "Transfer learning for cross-modal demand prediction of bike-share and public transit. (arXiv:2203.09279v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.02910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bevilacqua_B/0/1/0/all/0/1\">Beatrice Bevilacqua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frasca_F/0/1/0/all/0/1\">Fabrizio Frasca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_D/0/1/0/all/0/1\">Derek Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_B/0/1/0/all/0/1\">Balasubramaniam Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1\">Chen Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balamurugan_G/0/1/0/all/0/1\">Gopinath Balamurugan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael M. Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maron_H/0/1/0/all/0/1\">Haggai Maron</a>",
          "description": "Message-passing neural networks (MPNNs) are the leading architecture for deep\nlearning on graph-structured data, in large part due to their simplicity and\nscalability. Unfortunately, it was shown that these architectures are limited\nin their expressive power. This paper proposes a novel framework called\nEquivariant Subgraph Aggregation Networks (ESAN) to address this issue. Our\nmain observation is that while two graphs may not be distinguishable by an\nMPNN, they often contain distinguishable subgraphs. Thus, we propose to\nrepresent each graph as a set of subgraphs derived by some predefined policy,\nand to process it using a suitable equivariant architecture. We develop novel\nvariants of the 1-dimensional Weisfeiler-Leman (1-WL) test for graph\nisomorphism, and prove lower bounds on the expressiveness of ESAN in terms of\nthese new WL variants. We further prove that our approach increases the\nexpressive power of both MPNNs and more expressive architectures. Moreover, we\nprovide theoretical results that describe how design choices such as the\nsubgraph selection policy and equivariant neural architecture affect our\narchitecture's expressive power. To deal with the increased computational cost,\nwe propose a subgraph sampling scheme, which can be viewed as a stochastic\nversion of our framework. A comprehensive set of experiments on real and\nsynthetic datasets demonstrates that our framework improves the expressive\npower and overall performance of popular GNN architectures.",
          "link": "http://arxiv.org/abs/2110.02910",
          "publishedOn": "2022-03-19T00:42:46.024Z",
          "wordCount": 705,
          "title": "Equivariant Subgraph Aggregation Networks. (arXiv:2110.02910v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09413",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yuan_X/0/1/0/all/0/1\">Xiao-Tong Yuan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>",
          "description": "In this paper, we analyze the generalization performance of the Iterative\nHard Thresholding (IHT) algorithm widely used for sparse recovery problems. The\nparameter estimation and sparsity recovery consistency of IHT has long been\nknown in compressed sensing. From the perspective of statistical learning,\nanother fundamental question is how well the IHT estimation would predict on\nunseen data. This paper makes progress towards answering this open question by\nintroducing a novel sparse generalization theory for IHT under the notion of\nalgorithmic stability. Our theory reveals that: 1) under natural conditions on\nthe empirical risk function over $n$ samples of dimension $p$, IHT with\nsparsity level $k$ enjoys an $\\mathcal{\\tilde\nO}(n^{-1/2}\\sqrt{k\\log(n)\\log(p)})$ rate of convergence in sparse excess risk;\n2) a tighter $\\mathcal{\\tilde O}(n^{-1/2}\\sqrt{\\log(n)})$ bound can be\nestablished by imposing an additional iteration stability condition on a\nhypothetical IHT procedure invoked to the population risk; and 3) a fast rate\nof order $\\mathcal{\\tilde O}\\left(n^{-1}k(\\log^3(n)+\\log(p))\\right)$ can be\nderived for strongly convex risk function under proper strong-signal\nconditions. The results have been substantialized to sparse linear regression\nand sparse logistic regression models to demonstrate the applicability of our\ntheory. Preliminary numerical evidence is provided to confirm our theoretical\npredictions.",
          "link": "http://arxiv.org/abs/2203.09413",
          "publishedOn": "2022-03-19T00:42:46.017Z",
          "wordCount": 632,
          "title": "Stability and Risk Bounds of Iterative Hard Thresholding. (arXiv:2203.09413v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shiebler_D/0/1/0/all/0/1\">Dan Shiebler</a>",
          "description": "A common problem in data science is \"use this function defined over this\nsmall set to generate predictions over that larger set.\" Extrapolation,\ninterpolation, statistical inference and forecasting all reduce to this\nproblem. The Kan extension is a powerful tool in category theory that\ngeneralizes this notion. In this work we explore several applications of Kan\nextensions to data science. We begin by deriving a simple classification\nalgorithm as a Kan extension and experimenting with this algorithm on real\ndata. Next, we use the Kan extension to derive a procedure for learning\nclustering algorithms from labels and explore the performance of this procedure\non real data. We then investigate how Kan extensions can be used to learn a\ngeneral mapping from datasets of labeled examples to functions and to\napproximate a complex function with a simpler one.",
          "link": "http://arxiv.org/abs/2203.09018",
          "publishedOn": "2022-03-19T00:42:45.996Z",
          "wordCount": 568,
          "title": "Kan Extensions in Data Science and Machine Learning. (arXiv:2203.09018v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tirinzoni_A/0/1/0/all/0/1\">Andrea Tirinzoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Marjani_A/0/1/0/all/0/1\">Aymen Al-Marjani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufmann_E/0/1/0/all/0/1\">Emilie Kaufmann</a>",
          "description": "In probably approximately correct (PAC) reinforcement learning (RL), an agent\nis required to identify an $\\epsilon$-optimal policy with probability\n$1-\\delta$. While minimax optimal algorithms exist for this problem, its\ninstance-dependent complexity remains elusive in episodic Markov decision\nprocesses (MDPs). In this paper, we propose the first (nearly) matching upper\nand lower bounds on the sample complexity of PAC RL in deterministic episodic\nMDPs with finite state and action spaces. In particular, our bounds feature a\nnew notion of sub-optimality gap for state-action pairs that we call the\ndeterministic return gap. While our instance-dependent lower bound is written\nas a linear program, our algorithms are very simple and do not require solving\nsuch an optimization problem during learning. Their design and analyses employ\nnovel ideas, including graph-theoretical concepts such as minimum flows and\nmaximum cuts, which we believe to shed new light on this problem.",
          "link": "http://arxiv.org/abs/2203.09251",
          "publishedOn": "2022-03-19T00:42:45.990Z",
          "wordCount": 580,
          "title": "Near Instance-Optimal PAC Reinforcement Learning for Deterministic MDPs. (arXiv:2203.09251v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Runqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linlin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Baochang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wentao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doermann_D/0/1/0/all/0/1\">David Doermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_G/0/1/0/all/0/1\">Guodong Guo</a>",
          "description": "Research on the generalization ability of deep neural networks (DNNs) has\nrecently attracted a great deal of attention. However, due to their complex\narchitectures and large numbers of parameters, measuring the generalization\nability of specific DNN models remains an open challenge. In this paper, we\npropose to use multiple factors to measure and rank the relative generalization\nof DNNs based on a new concept of confidence dimension (CD). Furthermore, we\nprovide a feasible framework in our CD to theoretically calculate the upper\nbound of generalization based on the conventional Vapnik-Chervonenk dimension\n(VC-dimension) and Hoeffding's inequality. Experimental results on image\nclassification and object detection demonstrate that our CD can reflect the\nrelative generalization ability for different DNNs. In addition to\nfull-precision DNNs, we also analyze the generalization ability of binary\nneural networks (BNNs), whose generalization ability remains an unsolved\nproblem. Our CD yields a consistent and reliable measure and ranking for both\nfull-precision DNNs and BNNs on all the tasks.",
          "link": "http://arxiv.org/abs/2203.09082",
          "publishedOn": "2022-03-19T00:42:45.983Z",
          "wordCount": 609,
          "title": "Confidence Dimension for Deep Learning based on Hoeffding Inequality and Relative Evaluation. (arXiv:2203.09082v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.05131",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1\">Yinglun Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Katz_Samuels_J/0/1/0/all/0/1\">Julian Katz-Samuels</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nowak_R/0/1/0/all/0/1\">Robert Nowak</a>",
          "description": "We introduce the model selection problem in pure exploration linear bandits,\nwhere the learner needs to adapt to the instance-dependent complexity measure\nof the smallest hypothesis class containing the true model. We design\nalgorithms in both fixed confidence and fixed budget settings with near\ninstance optimal guarantees. The core of our algorithms is a new optimization\nproblem based on experimental design that leverages the geometry of the action\nset to identify a near-optimal hypothesis class. Our fixed budget algorithm is\ndeveloped based on a novel selection-validation procedure, which provides a new\nway to study the understudied fixed budget setting (even without the added\nchallenge of model selection). We adapt our algorithms, in both fixed\nconfidence and fixed budget settings, to problems with model misspecification.",
          "link": "http://arxiv.org/abs/2109.05131",
          "publishedOn": "2022-03-19T00:42:45.976Z",
          "wordCount": 580,
          "title": "Near Instance Optimal Model Selection for Pure Exploration Linear Bandits. (arXiv:2109.05131v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.12034",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1\">Yinglun Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_D/0/1/0/all/0/1\">Dongruo Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jiang_R/0/1/0/all/0/1\">Ruoxi Jiang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Willett_R/0/1/0/all/0/1\">Rebecca Willett</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nowak_R/0/1/0/all/0/1\">Robert Nowak</a>",
          "description": "We study pure exploration in bandits, where the dimension of the feature\nrepresentation can be much larger than the number of arms. To overcome the\ncurse of dimensionality, we propose to adaptively embed the feature\nrepresentation of each arm into a lower-dimensional space and carefully deal\nwith the induced model misspecification. Our approach is conceptually very\ndifferent from existing works that can either only handle low-dimensional\nlinear bandits or passively deal with model misspecification. We showcase the\napplication of our approach to two pure exploration settings that were\npreviously under-studied: (1) the reward function belongs to a possibly\ninfinite-dimensional Reproducing Kernel Hilbert Space, and (2) the reward\nfunction is nonlinear and can be approximated by neural networks. Our main\nresults provide sample complexity guarantees that only depend on the effective\ndimension of the feature spaces in the kernel or neural representations.\nExtensive experiments conducted on both synthetic and real-world datasets\ndemonstrate the efficacy of our methods.",
          "link": "http://arxiv.org/abs/2106.12034",
          "publishedOn": "2022-03-19T00:42:45.969Z",
          "wordCount": 612,
          "title": "Pure Exploration in Kernel and Neural Bandits. (arXiv:2106.12034v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08149",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Hasanzadeh_A/0/1/0/all/0/1\">Arman Hasanzadeh</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hajiramezanali_E/0/1/0/all/0/1\">Ehsan Hajiramezanali</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Duffield_N/0/1/0/all/0/1\">Nick Duffield</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qian_X/0/1/0/all/0/1\">Xiaoning Qian</a>",
          "description": "Multi-omics data analysis has the potential to discover hidden molecular\ninteractions, revealing potential regulatory and/or signal transduction\npathways for cellular processes of interest when studying life and disease\nsystems. One of critical challenges when dealing with real-world multi-omics\ndata is that they may manifest heterogeneous structures and data quality as\noften existing data may be collected from different subjects under different\nconditions for each type of omics data. We propose a novel deep Bayesian\ngenerative model to efficiently infer a multi-partite graph encoding molecular\ninteractions across such heterogeneous views, using a fused Gromov-Wasserstein\n(FGW) regularization between latent representations of corresponding views for\nintegrative analysis. With such an optimal transport regularization in the deep\nBayesian generative model, it not only allows incorporating view-specific side\ninformation, either with graph-structured or unstructured data in different\nviews, but also increases the model flexibility with the distribution-based\nregularization. This allows efficient alignment of heterogeneous latent\nvariable distributions to derive reliable interaction predictions compared to\nthe existing point-based graph embedding methods. Our experiments on several\nreal-world datasets demonstrate enhanced performance of MoReL in inferring\nmeaningful interactions compared to existing baselines.",
          "link": "http://arxiv.org/abs/2203.08149",
          "publishedOn": "2022-03-19T00:42:45.962Z",
          "wordCount": 619,
          "title": "MoReL: Multi-omics Relational Learning. (arXiv:2203.08149v1 [q-bio.QM] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Benz_N/0/1/0/all/0/1\">Nina Corvelo Benz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_M/0/1/0/all/0/1\">Manuel Gomez Rodriguez</a>",
          "description": "Automated decision support systems that are able to infer second opinions\nfrom experts can potentially facilitate a more efficient allocation of\nresources; they can help decide when and from whom to seek a second opinion. In\nthis paper, we look at the design of this type of support systems from the\nperspective of counterfactual inference. We focus on a multiclass\nclassification setting and first show that, if experts make predictions on\ntheir own, the underlying causal mechanism generating their predictions needs\nto satisfy a desirable set invariant property. Further, we show that, for any\ncausal mechanism satisfying this property, there exists an equivalent mechanism\nwhere the predictions by each expert are generated by independent\nsub-mechanisms governed by a common noise. This motivates the design of a set\ninvariant Gumbel-Max structural causal model where the structure of the noise\ngoverning the sub-mechanisms underpinning the model depends on an intuitive\nnotion of similarity between experts which can be estimated from data.\nExperiments on both synthetic and real data show that our model can be used to\ninfer second opinions more accurately than its non-causal counterpart.",
          "link": "http://arxiv.org/abs/2203.08653",
          "publishedOn": "2022-03-19T00:42:45.945Z",
          "wordCount": 626,
          "title": "Counterfactual Inference of Second Opinions. (arXiv:2203.08653v1 [cs.LG] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.08812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiongjie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yongxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunpeng Li</a>",
          "description": "While theoretically appealing, the application of the Wasserstein distance to\nlarge-scale machine learning problems has been hampered by its prohibitive\ncomputational cost. The sliced Wasserstein distance and its variants improve\nthe computational efficiency through the random projection, yet they suffer\nfrom low accuracy if the number of projections is not sufficiently large,\nbecause the majority of projections result in trivially small values. In this\nwork, we propose a new family of distance metrics, called augmented sliced\nWasserstein distances (ASWDs), constructed by first mapping samples to\nhigher-dimensional hypersurfaces parameterized by neural networks. It is\nderived from a key observation that (random) linear projections of samples\nresiding on these hypersurfaces would translate to much more flexible nonlinear\nprojections in the original sample space, so they can capture complex\nstructures of the data distribution. We show that the hypersurfaces can be\noptimized by gradient ascent efficiently. We provide the condition under which\nthe ASWD is a valid metric and show that this can be obtained by an injective\nneural network architecture. Numerical results demonstrate that the ASWD\nsignificantly outperforms other Wasserstein variants for both synthetic and\nreal-world problems.",
          "link": "http://arxiv.org/abs/2006.08812",
          "publishedOn": "2022-03-19T00:42:45.938Z",
          "wordCount": 698,
          "title": "Augmented Sliced Wasserstein Distances. (arXiv:2006.08812v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yite Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruoyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Model-agnostic meta-learning (MAML) and its variants have become popular\napproaches for few-shot learning. However, due to the non-convexity of deep\nneural nets (DNNs) and the bi-level formulation of MAML, the theoretical\nproperties of MAML with DNNs remain largely unknown. In this paper, we first\nprove that MAML with over-parameterized DNNs is guaranteed to converge to\nglobal optima at a linear rate. Our convergence analysis indicates that MAML\nwith over-parameterized DNNs is equivalent to kernel regression with a novel\nclass of kernels, which we name as Meta Neural Tangent Kernels (MetaNTK). Then,\nwe propose MetaNTK-NAS, a new training-free neural architecture search (NAS)\nmethod for few-shot learning that uses MetaNTK to rank and select\narchitectures. Empirically, we compare our MetaNTK-NAS with previous NAS\nmethods on two popular few-shot learning benchmarks, miniImageNet, and\ntieredImageNet. We show that the performance of MetaNTK-NAS is comparable or\nbetter than the state-of-the-art NAS method designed for few-shot learning\nwhile enjoying more than 100x speedup. We believe the efficiency of MetaNTK-NAS\nmakes itself more practical for many real-world tasks.",
          "link": "http://arxiv.org/abs/2203.09137",
          "publishedOn": "2022-03-19T00:42:45.931Z",
          "wordCount": 651,
          "title": "Global Convergence of MAML and Theory-Inspired Neural Architecture Search for Few-Shot Learning. (arXiv:2203.09137v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1\">Gitta Kutyniok</a>",
          "description": "We currently witness the spectacular success of artificial intelligence in\nboth science and public life. However, the development of a rigorous\nmathematical foundation is still at an early stage. In this survey article,\nwhich is based on an invited lecture at the International Congress of\nMathematicians 2022, we will in particular focus on the current \"workhorse\" of\nartificial intelligence, namely deep neural networks. We will present the main\ntheoretical directions along with several exemplary results and discuss key\nopen problems.",
          "link": "http://arxiv.org/abs/2203.08890",
          "publishedOn": "2022-03-19T00:42:45.520Z",
          "wordCount": 526,
          "title": "The Mathematics of Artificial Intelligence. (arXiv:2203.08890v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.08648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuelong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>",
          "description": "Graph-based clustering plays an important role in the clustering area. Recent\nstudies about graph convolution neural networks have achieved impressive\nsuccess on graph type data. However, in general clustering tasks, the graph\nstructure of data does not exist such that the strategy to construct a graph is\ncrucial for performance. Therefore, how to extend graph convolution networks\ninto general clustering tasks is an attractive problem. In this paper, we\npropose a graph auto-encoder for general data clustering, which constructs the\ngraph adaptively according to the generative perspective of graphs. The\nadaptive process is designed to induce the model to exploit the high-level\ninformation behind data and utilize the non-Euclidean structure sufficiently.\nWe further design a novel mechanism with rigorous analysis to avoid the\ncollapse caused by the adaptive construction. Via combining the generative\nmodel for network embedding and graph-based clustering, a graph auto-encoder\nwith a novel decoder is developed such that it performs well in weighted graph\nused scenarios. Extensive experiments prove the superiority of our model.",
          "link": "http://arxiv.org/abs/2002.08648",
          "publishedOn": "2022-03-19T00:42:45.498Z",
          "wordCount": 667,
          "title": "Adaptive Graph Auto-Encoder for General Data Clustering. (arXiv:2002.08648v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.10863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Regenwetter_L/0/1/0/all/0/1\">Lyle Regenwetter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nobari_A/0/1/0/all/0/1\">Amin Heyrani Nobari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1\">Faez Ahmed</a>",
          "description": "Automated design synthesis has the potential to revolutionize the modern\nengineering design process and improve access to highly optimized and\ncustomized products across countless industries. Successfully adapting\ngenerative Machine Learning to design engineering may enable such automated\ndesign synthesis and is a research subject of great importance. We present a\nreview and analysis of Deep Generative Machine Learning models in engineering\ndesign. Deep Generative Models (DGMs) typically leverage deep networks to learn\nfrom an input dataset and synthesize new designs. Recently, DGMs such as\nfeedforward Neural Networks (NNs), Generative Adversarial Networks (GANs),\nVariational Autoencoders (VAEs), and certain Deep Reinforcement Learning (DRL)\nframeworks have shown promising results in design applications like structural\noptimization, materials design, and shape synthesis. The prevalence of DGMs in\nengineering design has skyrocketed since 2016. Anticipating continued growth,\nwe conduct a review of recent advances to benefit researchers interested in\nDGMs for design. We structure our review as an exposition of the algorithms,\ndatasets, representation methods, and applications commonly used in the current\nliterature. In particular, we discuss key works that have introduced new\ntechniques and methods in DGMs, successfully applied DGMs to a design-related\ndomain, or directly supported the development of DGMs through datasets or\nauxiliary methods. We further identify key challenges and limitations currently\nseen in DGMs across design fields, such as design creativity, handling\nconstraints and objectives, and modeling both form and functional performance\nsimultaneously. In our discussion, we identify possible solution pathways as\nkey areas on which to target future work.",
          "link": "http://arxiv.org/abs/2110.10863",
          "publishedOn": "2022-03-19T00:42:45.491Z",
          "wordCount": 728,
          "title": "Deep Generative Models in Engineering Design: A Review. (arXiv:2110.10863v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09179",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Karvonen_T/0/1/0/all/0/1\">Toni Karvonen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Oates_C/0/1/0/all/0/1\">Chris J. Oates</a>",
          "description": "Gaussian process regression underpins countless academic and industrial\napplications of machine learning and statistics, with maximum likelihood\nestimation routinely used to select appropriate parameters for the covariance\nkernel. However, it remains an open problem to establish the circumstances in\nwhich maximum likelihood estimation is well-posed. That is, when the\npredictions of the regression model are continuous (or insensitive to small\nperturbations) in the training data. This article presents a rigorous proof\nthat the maximum likelihood estimator fails to be well-posed in Hellinger\ndistance in a scenario where the data are noiseless. The failure case occurs\nfor any Gaussian process with a stationary covariance function whose\nlengthscale parameter is estimated using maximum likelihood. Although the\nfailure of maximum likelihood estimation is informally well-known, these\ntheoretical results appear to be the first of their kind, and suggest that\nwell-posedness may need to be assessed post-hoc, on a case-by-case basis, when\nmaximum likelihood estimation is used to train a Gaussian process model.",
          "link": "http://arxiv.org/abs/2203.09179",
          "publishedOn": "2022-03-19T00:42:45.484Z",
          "wordCount": 601,
          "title": "Maximum Likelihood Estimation in Gaussian Process Regression is Ill-Posed. (arXiv:2203.09179v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kwon_G/0/1/0/all/0/1\">Gihyun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "There are many recent research efforts to fine-tune a pre-trained generator\nwith a few target images to generate images of a novel domain. Unfortunately,\nthese methods often suffer from overfitting or under-fitting when fine-tuned\nwith a single target image. To address this, here we present a novel\nsingle-shot GAN adaptation method through unified CLIP space manipulations.\nSpecifically, our model employs a two-step training strategy: reference image\nsearch in the source generator using a CLIP-guided latent optimization,\nfollowed by generator fine-tuning with a novel loss function that imposes CLIP\nspace consistency between the source and adapted generators. To further improve\nthe adapted model to produce spatially consistent samples with respect to the\nsource generator, we also propose contrastive regularization for patchwise\nrelationships in the CLIP space. Experimental results show that our model\ngenerates diverse outputs with the target texture and outperforms the baseline\nmodels both qualitatively and quantitatively. Furthermore, we show that our\nCLIP space manipulation strategy allows more effective attribute editing.",
          "link": "http://arxiv.org/abs/2203.09301",
          "publishedOn": "2022-03-19T00:42:45.470Z",
          "wordCount": 610,
          "title": "One-Shot Adaptation of GAN in Just One CLIP. (arXiv:2203.09301v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09270",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wickstrom_K/0/1/0/all/0/1\">Kristoffer Wickstr&#xf8;m</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kampffmeyer_M/0/1/0/all/0/1\">Michael Kampffmeyer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mikalsen_K/0/1/0/all/0/1\">Karl &#xd8;yvind Mikalsen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jenssen_R/0/1/0/all/0/1\">Robert Jenssen</a>",
          "description": "The lack of labeled data is a key challenge for learning useful\nrepresentation from time series data. However, an unsupervised representation\nframework that is capable of producing high quality representations could be of\ngreat value. It is key to enabling transfer learning, which is especially\nbeneficial for medical applications, where there is an abundance of data but\nlabeling is costly and time consuming. We propose an unsupervised contrastive\nlearning framework that is motivated from the perspective of label smoothing.\nThe proposed approach uses a novel contrastive loss that naturally exploits a\ndata augmentation scheme in which new samples are generated by mixing two data\nsamples with a mixing component. The task in the proposed framework is to\npredict the mixing component, which is utilized as soft targets in the loss\nfunction. Experiments demonstrate the framework's superior performance compared\nto other representation learning approaches on both univariate and multivariate\ntime series and illustrate its benefits for transfer learning for clinical time\nseries.",
          "link": "http://arxiv.org/abs/2203.09270",
          "publishedOn": "2022-03-19T00:42:45.446Z",
          "wordCount": 635,
          "title": "Mixing Up Contrastive Learning: Self-Supervised Representation Learning for Time Series. (arXiv:2203.09270v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09281",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Wilsenach_J/0/1/0/all/0/1\">James B. Wilsenach</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Warnaby_C/0/1/0/all/0/1\">Catherine E. Warnaby</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deane_C/0/1/0/all/0/1\">Charlotte M. Deane</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Reinert_G/0/1/0/all/0/1\">Gesine D. Reinert</a>",
          "description": "As a relatively new field, network neuroscience has tended to focus on\naggregate behaviours of the brain averaged over many successive experiments or\nover long recordings in order to construct robust brain models. These models\nare limited in their ability to explain dynamic state changes in the brain\nwhich occurs spontaneously as a result of normal brain function. Hidden Markov\nModels (HMMs) trained on neuroimaging time series data have since arisen as a\nmethod to produce dynamical models that are easy to train but can be difficult\nto fully parametrise or analyse. We propose an interpretation of these neural\nHMMs as multiplex brain state graph models we term Hidden Markov Graph Models\n(HMGMs). This interpretation allows for dynamic brain activity to be analysed\nusing the full repertoire of network analysis techniques. Furthermore, we\npropose a general method for selecting HMM hyperparameters in the absence of\nexternal data, based on the principle of maximum entropy, and use this to\nselect the number of layers in the multiplex model. We produce a new tool for\ndetermining important communities of brain regions using a spatiotemporal\nrandom walk-based procedure that takes advantage of the underlying Markov\nstructure of the model. Our analysis of real multi-subject fMRI data provides\nnew results that corroborate the modular processing hypothesis of the brain at\nrest as well as contributing new evidence of functional overlap between and\nwithin dynamic brain state communities. Our analysis pipeline provides a way to\ncharacterise dynamic network activity of the brain under novel behaviours or\nconditions.",
          "link": "http://arxiv.org/abs/2203.09281",
          "publishedOn": "2022-03-19T00:42:45.439Z",
          "wordCount": 758,
          "title": "Ranking of Communities in Multiplex Spatiotemporal Models of Brain Dynamics. (arXiv:2203.09281v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.02612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zih-Syuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Ching-pei Lee</a>",
          "description": "This paper proposes an algorithm (RMDA) for training neural networks (NNs)\nwith a regularization term for promoting desired structures. RMDA does not\nincur computation additional to proximal SGD with momentum, and achieves\nvariance reduction without requiring the objective function to be of the\nfinite-sum form. Through the tool of manifold identification from nonlinear\noptimization, we prove that after a finite number of iterations, all iterates\nof RMDA possess a desired structure identical to that induced by the\nregularizer at the stationary point of asymptotic convergence, even in the\npresence of engineering tricks like data augmentation and dropout that\ncomplicate the training process. Experiments on training NNs with structured\nsparsity confirm that variance reduction is necessary for such an\nidentification, and show that RMDA thus significantly outperforms existing\nmethods for this task. For unstructured sparsity, RMDA also outperforms a\nstate-of-the-art pruning method, validating the benefits of training structured\nNNs through regularization.",
          "link": "http://arxiv.org/abs/2112.02612",
          "publishedOn": "2022-03-19T00:42:45.432Z",
          "wordCount": 619,
          "title": "Training Structured Neural Networks Through Manifold Identification and Variance Reduction. (arXiv:2112.02612v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10541",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+OReilly_E/0/1/0/all/0/1\">Eliza O&#x27;Reilly</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tran_N/0/1/0/all/0/1\">Ngoc Mai Tran</a>",
          "description": "Random forests are a popular class of algorithms used for regression and\nclassification. The original algorithm introduced by Breiman in 2001 and many\nof its variants are ensembles of randomized decision trees built from\naxis-aligned partitions of the feature space. One such variant, called Mondrian\nforests, was proposed to handle the online setting and is the first class of\nrandom forests for which minimax rates were obtained in arbitrary dimension.\nHowever, the restriction to axis-aligned splits fails to capture dependencies\nbetween features, and random forests that use oblique splits have shown\nimproved empirical performance for many tasks. In this work, we show that a\nlarge class of random forests with general split directions also achieve\nminimax rates in arbitrary dimension. This class includes STIT forests, a\ngeneralization of Mondrian forests to arbitrary split directions, as well as\nrandom forests derived from Poisson hyperplane tessellations. Crucially, our\nrates adapt to sparsity in the sense that they depend only on the dimension of\nthe relevant feature subspace as opposed to the ambient dimension of the\nfeature space. This generalizes the known rates for Mondrian random forests.\nThese are the first results showing that random forest variants with oblique\nsplits can achieve minimax rates in arbitrary dimension. Our proof technique\nrelies on the novel application of the theory of stationary random\ntessellations in stochastic geometry to statistical learning theory.",
          "link": "http://arxiv.org/abs/2109.10541",
          "publishedOn": "2022-03-19T00:42:45.425Z",
          "wordCount": 709,
          "title": "Minimax Rates for High-Dimensional Random Tessellation Forests. (arXiv:2109.10541v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.07138",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shulei Wang</a>",
          "description": "Self-supervised metric learning has been a successful approach for learning a\ndistance from an unlabeled dataset. The resulting distance is broadly useful\nfor improving various distance-based downstream tasks, even when no information\nfrom downstream tasks is utilized in the metric learning stage. To gain\ninsights into this approach, we develop a statistical framework to\ntheoretically study how self-supervised metric learning can benefit downstream\ntasks in the context of multi-view data. Under this framework, we show that the\ntarget distance of metric learning satisfies several desired properties for the\ndownstream tasks. On the other hand, our investigation suggests the target\ndistance can be further improved by moderating each direction's weights. In\naddition, our analysis precisely characterizes the improvement by\nself-supervised metric learning on four commonly used downstream tasks: sample\nidentification, two-sample testing, $k$-means clustering, and $k$-nearest\nneighbor classification. When the distance is estimated from an unlabeled\ndataset, we establish the upper bound on distance estimation's accuracy and the\nnumber of samples sufficient for downstream task improvement. Finally,\nnumerical experiments are presented to support the theoretical results in the\npaper.",
          "link": "http://arxiv.org/abs/2106.07138",
          "publishedOn": "2022-03-19T00:42:45.403Z",
          "wordCount": 657,
          "title": "Self-Supervised Metric Learning in Multi-View Data: A Downstream Task Perspective. (arXiv:2106.07138v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.07835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horn_M/0/1/0/all/0/1\">Max Horn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brouwer_E/0/1/0/all/0/1\">Edward De Brouwer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moor_M/0/1/0/all/0/1\">Michael Moor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreau_Y/0/1/0/all/0/1\">Yves Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1\">Bastian Rieck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgwardt_K/0/1/0/all/0/1\">Karsten Borgwardt</a>",
          "description": "Graph neural networks (GNNs) are a powerful architecture for tackling graph\nlearning tasks, yet have been shown to be oblivious to eminent substructures\nsuch as cycles. We present TOGL, a novel layer that incorporates global\ntopological information of a graph using persistent homology. TOGL can be\neasily integrated into any type of GNN and is strictly more expressive (in\nterms the Weisfeiler--Lehman graph isomorphism test) than message-passing GNNs.\nAugmenting GNNs with TOGL leads to improved predictive performance for graph\nand node classification tasks, both on synthetic data sets, which can be\nclassified by humans using their topology but not by ordinary GNNs, and on\nreal-world data.",
          "link": "http://arxiv.org/abs/2102.07835",
          "publishedOn": "2022-03-19T00:42:45.397Z",
          "wordCount": 606,
          "title": "Topological Graph Neural Networks. (arXiv:2102.07835v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.13485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhizhou Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruihan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jian Peng</a>",
          "description": "Many practical applications of reinforcement learning require agents to learn\nfrom sparse and delayed rewards. It challenges the ability of agents to\nattribute their actions to future outcomes. In this paper, we consider the\nproblem formulation of episodic reinforcement learning with trajectory\nfeedback. It refers to an extreme delay of reward signals, in which the agent\ncan only obtain one reward signal at the end of each trajectory. A popular\nparadigm for this problem setting is learning with a designed auxiliary dense\nreward function, namely proxy reward, instead of sparse environmental signals.\nBased on this framework, this paper proposes a novel reward redistribution\nalgorithm, randomized return decomposition (RRD), to learn a proxy reward\nfunction for episodic reinforcement learning. We establish a surrogate problem\nby Monte-Carlo sampling that scales up least-squares-based reward\nredistribution to long-horizon problems. We analyze our surrogate loss function\nby connection with existing methods in the literature, which illustrates the\nalgorithmic properties of our approach. In experiments, we extensively evaluate\nour proposed method on a variety of benchmark tasks with episodic rewards and\ndemonstrate substantial improvement over baseline algorithms.",
          "link": "http://arxiv.org/abs/2111.13485",
          "publishedOn": "2022-03-19T00:42:45.390Z",
          "wordCount": 661,
          "title": "Learning Long-Term Reward Redistribution via Randomized Return Decomposition. (arXiv:2111.13485v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marfoq_O/0/1/0/all/0/1\">Othmane Marfoq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neglia_G/0/1/0/all/0/1\">Giovanni Neglia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kameni_L/0/1/0/all/0/1\">Laetitia Kameni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Richard Vidal</a>",
          "description": "Federated learning allows clients to collaboratively learn statistical models\nwhile keeping their data local. Federated learning was originally used to train\na unique global model to be served to all clients, but this approach might be\nsub-optimal when clients' local data distributions are heterogeneous. In order\nto tackle this limitation, recent personalized federated learning methods train\na separate model for each client while still leveraging the knowledge available\nat other clients. In this work, we exploit the ability of deep neural networks\nto extract high quality vectorial representations (embeddings) from non-tabular\ndata, e.g., images and text, to propose a personalization mechanism based on\nlocal memorization. Personalization is obtained interpolating a pre-trained\nglobal model with a $k$-nearest neighbors (kNN) model based on the shared\nrepresentation provided by the global model. We provide generalization bounds\nfor the proposed approach and we show on a suite of federated datasets that\nthis approach achieves significantly higher accuracy and fairness than\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2111.09360",
          "publishedOn": "2022-03-19T00:42:45.371Z",
          "wordCount": 621,
          "title": "Personalized Federated Learning through Local Memorization. (arXiv:2111.09360v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08819",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Metulini_R/0/1/0/all/0/1\">Rodolfo Metulini</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gnecco_G/0/1/0/all/0/1\">Giorgio Gnecco</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Biancalani_F/0/1/0/all/0/1\">Francesco Biancalani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Riccaboni_M/0/1/0/all/0/1\">Massimo Riccaboni</a>",
          "description": "World Input-Output (I/O) matrices provide the networks of within- and\ncross-country economic relations. In the context of I/O analysis, the\nmethodology adopted by national statistical offices in data collection raises\nthe issue of obtaining reliable data in a timely fashion and it makes the\nreconstruction of (part of) the I/O matrices of particular interest. In this\nwork, we propose a method combining hierarchical clustering and Matrix\nCompletion (MC) with a LASSO-like nuclear norm penalty, to impute missing\nentries of a partially unknown I/O matrix. Through simulations based on\nsynthetic matrices we study the effectiveness of the proposed method to predict\nmissing values from both previous years data and current data related to\ncountries similar to the one for which current data are obscured. To show the\nusefulness of our method, an application based on World Input-Output Database\n(WIOD) tables - which are an example of industry-by-industry I/O tables - is\nprovided. Strong similarities in structure between WIOD and other I/O tables\nare also found, which make the proposed approach easily generalizable to them.",
          "link": "http://arxiv.org/abs/2203.08819",
          "publishedOn": "2022-03-19T00:42:45.339Z",
          "wordCount": 617,
          "title": "Hierarchical Clustering and Matrix Completion for the Reconstruction of World Input-Output Tables. (arXiv:2203.08819v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yi Liu</a>",
          "description": "For marketing, we sometimes need to recommend content for multiple pages in\nsequence. Different from general sequential decision making process, the use\ncases have a simpler flow where customers per seeing recommended content on\neach page can only return feedback as moving forward in the process or dropping\nfrom it until a termination state. We refer to this type of problems as\nsequential decision making in linear--flow. We propose to formulate the problem\nas an MDP with Bandits where Bandits are employed to model the transition\nprobability matrix. At recommendation time, we use Thompson sampling (TS) to\nsample the transition probabilities and allocate the best series of actions\nwith analytical solution through exact dynamic programming. The way that we\nformulate the problem allows us to leverage TS's efficiency in balancing\nexploration and exploitation and Bandit's convenience in modeling actions'\nincompatibility. In the simulation study, we observe the proposed MDP with\nBandits algorithm outperforms Q-learning with $\\epsilon$-greedy and decreasing\n$\\epsilon$, independent Bandits, and interaction Bandits. We also find the\nproposed algorithm's performance is the most robust to changes in the\nacross-page interdependence strength.",
          "link": "http://arxiv.org/abs/2107.00204",
          "publishedOn": "2022-03-19T00:42:45.307Z",
          "wordCount": 664,
          "title": "Markov Decision Process modeled with Bandits for Sequential Decision Making in Linear-flow. (arXiv:2107.00204v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fort_G/0/1/0/all/0/1\">Gersende Fort</a> (IMT), <a href=\"http://arxiv.org/find/cs/1/au:+Pascal_B/0/1/0/all/0/1\">Barbara Pascal</a> (CRIStAL), <a href=\"http://arxiv.org/find/cs/1/au:+Abry_P/0/1/0/all/0/1\">Patrice Abry</a> (Phys-ENS), <a href=\"http://arxiv.org/find/cs/1/au:+Pustelnik_N/0/1/0/all/0/1\">Nelly Pustelnik</a> (Phys-ENS)",
          "description": "Monitoring the Covid19 pandemic constitutes a critical societal stake that\nreceived considerable research efforts. The intensity of the pandemic on a\ngiven territory is efficiently measured by the reproduction number, quantifying\nthe rate of growth of daily new infections. Recently, estimates for the time\nevolution of the reproduction number were produced using an inverse problem\nformulation with a nonsmooth functional minimization. While it was designed to\nbe robust to the limited quality of the Covid19 data (outliers, missing\ncounts), the procedure lacks the ability to output credibility interval based\nestimates. This remains a severe limitation for practical use in actual\npandemic monitoring by epidemiologists that the present work aims to overcome\nby use of Monte Carlo sampling. After interpretation of the functional into a\nBayesian framework, several sampling schemes are tailored to adjust the\nnonsmooth nature of the resulting posterior distribution. The originality of\nthe devised algorithms stems from combining a Langevin Monte Carlo sampling\nscheme with Proximal operators. Performance of the new algorithms in producing\nrelevant credibility intervals for the reproduction number estimates and\ndenoised counts are compared. Assessment is conducted on real daily new\ninfection counts made available by the Johns Hopkins University. The interest\nof the devised monitoring tools are illustrated on Covid19 data from several\ndifferent countries.",
          "link": "http://arxiv.org/abs/2203.09142",
          "publishedOn": "2022-03-19T00:42:45.298Z",
          "wordCount": 719,
          "title": "Covid19 Reproduction Number: Credibility Intervals by Blockwise Proximal Monte Carlo Samplers. (arXiv:2203.09142v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.05446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eastwood_C/0/1/0/all/0/1\">Cian Eastwood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mason_I/0/1/0/all/0/1\">Ian Mason</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_C/0/1/0/all/0/1\">Christopher K. I. Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "Source-free domain adaptation (SFDA) aims to adapt a model trained on\nlabelled data in a source domain to unlabelled data in a target domain without\naccess to the source-domain data during adaptation. Existing methods for SFDA\nleverage entropy-minimization techniques which: (i) apply only to\nclassification; (ii) destroy model calibration; and (iii) rely on the source\nmodel achieving a good level of feature-space class-separation in the target\ndomain. We address these issues for a particularly pervasive type of domain\nshift called measurement shift which can be resolved by restoring the source\nfeatures rather than extracting new ones. In particular, we propose Feature\nRestoration (FR) wherein we: (i) store a lightweight and flexible approximation\nof the feature distribution under the source data; and (ii) adapt the\nfeature-extractor such that the approximate feature distribution under the\ntarget data realigns with that saved on the source. We additionally propose a\nbottom-up training scheme which boosts performance, which we call Bottom-Up\nFeature Restoration (BUFR). On real and synthetic data, we demonstrate that\nBUFR outperforms existing SFDA methods in terms of accuracy, calibration, and\ndata efficiency, while being less reliant on the performance of the source\nmodel in the target domain.",
          "link": "http://arxiv.org/abs/2107.05446",
          "publishedOn": "2022-03-19T00:42:45.291Z",
          "wordCount": 689,
          "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration. (arXiv:2107.05446v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09410",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Holzmuller_D/0/1/0/all/0/1\">David Holzm&#xfc;ller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zaverkin_V/0/1/0/all/0/1\">Viktor Zaverkin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kastner_J/0/1/0/all/0/1\">Johannes K&#xe4;stner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steinwart_I/0/1/0/all/0/1\">Ingo Steinwart</a>",
          "description": "We study the performance of different pool-based Batch Mode Deep Active\nLearning (BMDAL) methods for regression on tabular data, focusing on methods\nthat do not require to modify the network architecture and training. Our\ncontributions are three-fold: First, we present a framework for constructing\nBMDAL methods out of kernels, kernel transformations and selection methods,\nshowing that many of the most popular BMDAL methods fit into our framework.\nSecond, we propose new components, leading to a new BMDAL method. Third, we\nintroduce an open-source benchmark with 15 large tabular data sets, which we\nuse to compare different BMDAL methods. Our benchmark results show that a\ncombination of our novel components yields new state-of-the-art results in\nterms of RMSE and is computationally efficient. We provide open-source code\nthat includes efficient implementations of all kernels, kernel transformations,\nand selection methods, and can be used for reproducing our results.",
          "link": "http://arxiv.org/abs/2203.09410",
          "publishedOn": "2022-03-19T00:42:45.283Z",
          "wordCount": 604,
          "title": "A Framework and Benchmark for Deep Batch Active Learning for Regression. (arXiv:2203.09410v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09250",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Higgins_I/0/1/0/all/0/1\">Irina Higgins</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Racaniere_S/0/1/0/all/0/1\">S&#xe9;bastien Racani&#xe8;re</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Rezende_D/0/1/0/all/0/1\">Danilo Rezende</a>",
          "description": "Biological intelligence is remarkable in its ability to produce complex\nbehaviour in many diverse situations through data efficient, generalisable and\ntransferable skill acquisition. It is believed that learning \"good\" sensory\nrepresentations is important for enabling this, however there is little\nagreement as to what a good representation should look like. In this review\narticle we are going to argue that symmetry transformations are a fundamental\nprinciple that can guide our search for what makes a good representation. The\nidea that there exist transformations (symmetries) that affect some aspects of\nthe system but not others, and their relationship to conserved quantities has\nbecome central in modern physics, resulting in a more unified theoretical\nframework and even ability to predict the existence of new particles. Recently,\nsymmetries have started to gain prominence in machine learning too, resulting\nin more data efficient and generalisable algorithms that can mimic some of the\ncomplex behaviours produced by biological intelligence. Finally, first\ndemonstrations of the importance of symmetry transformations for representation\nlearning in the brain are starting to arise in neuroscience. Taken together,\nthe overwhelming positive effect that symmetries bring to these disciplines\nsuggest that they may be an important general framework that determines the\nstructure of the universe, constrains the nature of natural tasks and\nconsequently shapes both biological and artificial intelligence.",
          "link": "http://arxiv.org/abs/2203.09250",
          "publishedOn": "2022-03-19T00:42:45.276Z",
          "wordCount": 669,
          "title": "Symmetry-Based Representations for Artificial and Biological General Intelligence. (arXiv:2203.09250v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gallicchio_C/0/1/0/all/0/1\">Claudio Gallicchio</a>",
          "description": "Inspired by the numerical solution of ordinary differential equations, in\nthis paper we propose a novel Reservoir Computing (RC) model, called the Euler\nState Network (EuSN). The introduced approach makes use of forward Euler\ndiscretization and antisymmetric recurrent matrices to design reservoir\ndynamics that are both stable and non-dissipative by construction.\n\nOur mathematical analysis shows that the resulting model is biased towards\nunitary effective spectral radius and zero local Lyapunov exponents,\nintrinsically operating at the edge of stability. Experiments on synthetic\ntasks indicate the marked superiority of the proposed approach, compared to\nstandard RC models, in tasks requiring long-term memorization skills.\nFurthermore, results on real-world time series classification benchmarks point\nout that EuSN is capable of matching (or even surpassing) the level of accuracy\nof trainable Recurrent Neural Networks, while allowing up to 100-fold savings\nin computation time and energy consumption.",
          "link": "http://arxiv.org/abs/2203.09382",
          "publishedOn": "2022-03-19T00:42:45.256Z",
          "wordCount": 571,
          "title": "Euler State Networks. (arXiv:2203.09382v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09380",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pfister_N/0/1/0/all/0/1\">Niklas Pfister</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Peters_J/0/1/0/all/0/1\">Jonas Peters</a>",
          "description": "Exogenous heterogeneity, for example, in the form of instrumental variables\ncan help us learn a system's underlying causal structure and predict the\noutcome of unseen intervention experiments. In this paper, we consider linear\nmodels in which the causal effect from covariates $X$ on a response $Y$ is\nsparse. We prove that the causal coefficient becomes identifiable under weak\nconditions and may even be identified in models, where the number of\ninstruments is as small as the number of causal parents. We also develop\ngraphical criteria under which the identifiability holds with probability one\nif the edge coefficients are sampled randomly from a distribution that is\nabsolutely continuous with respect to Lebesgue measure. As an estimator, we\npropose spaceIV and prove that it consistently estimates the causal effect if\nthe model is identifiable and evaluate its performance on simulated data.",
          "link": "http://arxiv.org/abs/2203.09380",
          "publishedOn": "2022-03-19T00:42:45.249Z",
          "wordCount": 575,
          "title": "Identifiability of Sparse Causal Effects using Instrumental Variables. (arXiv:2203.09380v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.02195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weisz_G/0/1/0/all/0/1\">Gell&#xe9;rt Weisz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesv&#xe1;ri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andr&#xe1;s Gy&#xf6;rgy</a>",
          "description": "We consider the minimax query complexity of online planning with a generative\nmodel in fixed-horizon Markov decision processes (MDPs) with linear function\napproximation. Following recent works, we consider broad classes of problems\nwhere either (i) the optimal value function $v^\\star$ or (ii) the optimal\naction-value function $q^\\star$ lie in the linear span of some features; or\n(iii) both $v^\\star$ and $q^\\star$ lie in the linear span when restricted to\nthe states reachable from the starting state. Recently, Weisz et al. (2021b)\nshowed that under (ii) the minimax query complexity of any planning algorithm\nis at least exponential in the horizon $H$ or in the feature dimension $d$ when\nthe size $A$ of the action set can be chosen to be exponential in $\\min(d,H)$.\nOn the other hand, for the setting (i), Weisz et al. (2021a) introduced\nTensorPlan, a planner whose query cost is polynomial in all relevant quantities\nwhen the number of actions is fixed. Among other things, these two works left\nopen the question whether polynomial query complexity is possible when $A$ is\nsubexponential in $\\min(d,H)$. In this paper we answer this question in the\nnegative: we show that an exponentially large lower bound holds when\n$A=\\Omega(\\min(d^{1/4},H^{1/2}))$, under either (i), (ii) or (iii). In\nparticular, this implies a perhaps surprising exponential separation of query\ncomplexity compared to the work of Du et al. (2021) who prove a polynomial\nupper bound when (iii) holds for all states. Furthermore, we show that the\nupper bound of TensorPlan can be extended to hold under (iii) and, for MDPs\nwith deterministic transitions and stochastic rewards, also under (ii).",
          "link": "http://arxiv.org/abs/2110.02195",
          "publishedOn": "2022-03-12T00:41:14.802Z",
          "wordCount": 753,
          "title": "TensorPlan and the Few Actions Lower Bound for Planning in MDPs under Linear Realizability of Optimal Value Functions. (arXiv:2110.02195v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02096",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Berrevoets_J/0/1/0/all/0/1\">Jeroen Berrevoets</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Imrie_F/0/1/0/all/0/1\">Fergus Imrie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kyono_T/0/1/0/all/0/1\">Trent Kyono</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jordon_J/0/1/0/all/0/1\">James Jordon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Missing data is a systemic problem in practical scenarios that causes noise\nand bias when estimating treatment effects. This makes treatment effect\nestimation from data with missingness a particularly tricky endeavour. A key\nreason for this is that standard assumptions on missingness are rendered\ninsufficient due to the presence of an additional variable, treatment, besides\nthe individual and the outcome. Having a treatment variable introduces\nadditional complexity with respect to why some variables are missing that is\nnot fully explored by previous work. In our work we identify a new missingness\nmechanism, which we term mixed confounded missingness (MCM), where some\nmissingness determines treatment selection and other missingness is determined\nby treatment selection. Given MCM, we show that naively imputing all data leads\nto poor performing treatment effects models, as the act of imputation\neffectively removes information necessary to provide unbiased estimates.\nHowever, no imputation at all also leads to biased estimates, as missingness\ndetermined by treatment divides the population in distinct subpopulations,\nwhere estimates across these populations will be biased. Our solution is\nselective imputation, where we use insights from MCM to inform precisely which\nvariables should be imputed and which should not. We empirically demonstrate\nhow various learners benefit from selective imputation compared to other\nsolutions for missing data.",
          "link": "http://arxiv.org/abs/2202.02096",
          "publishedOn": "2022-03-12T00:41:14.781Z",
          "wordCount": 677,
          "title": "To Impute or not to Impute? Missing Data in Treatment Effect Estimation. (arXiv:2202.02096v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.10869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Strawn_N/0/1/0/all/0/1\">Nate Strawn</a>",
          "description": "The efficiency of modern computer graphics allows us to explore collections\nof space curves simultaneously with \"drag-to-rotate\" interfaces. This inspires\nus to replace \"scatterplots of points\" with \"scatterplots of curves\" to\nsimultaneously visualize relationships across an entire dataset. Since spaces\nof curves are infinite dimensional, scatterplots of curves avoid the \"lossy\"\nnature of scatterplots of points. In particular, if two points are close in a\nscatterplot of points derived from high-dimensional data, it does not generally\nfollow that the two associated data points are close in the data space.\nStandard Andrews plots provide scatterplots of curves that perfectly preserve\nEuclidean distances, but simultaneous visualization of these graphs over an\nentire dataset produces visual clutter because graphs of functions generally\noverlap in 2D. We mitigate this visual clutter issue by constructing\ncomputationally inexpensive 3D extensions of Andrews plots. First, we construct\noptimally smooth 3D Andrews plots by considering linear isometries from\nEuclidean data spaces to spaces of planar parametric curves. We rigorously\nparametrize the linear isometries that produce (on average) optimally smooth\ncurves over a given dataset. This parameterization of optimal isometries\nreveals many degrees of freedom, and (using recent results on generalized Gauss\nsums) we identify a particular member of this set which admits an asymptotic\n\"tour\" property that avoids certain local degeneracies as well. Finally, we\nconstruct unit-length 3D curves (filaments) by numerically solving\nFrenet-Serret systems given data from these 3D Andrews plots. We conclude with\nexamples of filament plots for several standard datasets, illustrating how\nfilament plots avoid visual clutter. Code and examples available at\nhttps://github.com/n8epi/filaments/ and https://n8epi.github.io/filaments/",
          "link": "http://arxiv.org/abs/2107.10869",
          "publishedOn": "2022-03-12T00:41:14.724Z",
          "wordCount": 748,
          "title": "Filament Plots for Data Visualization. (arXiv:2107.10869v3 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.12996",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ghosh_S/0/1/0/all/0/1\">Subhro Ghosh</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rigollet_P/0/1/0/all/0/1\">Philippe Rigollet</a>",
          "description": "Motivated by cutting-edge applications like cryo-electron microscopy\n(cryo-EM), the Multi-Reference Alignment (MRA) model entails the learning of an\nunknown signal from repeated measurements of its images under the latent action\nof a group of isometries and additive noise of magnitude $\\sigma$. Despite\nsignificant interest, a clear picture for understanding rates of estimation in\nthis model has emerged only recently, particularly in the high-noise regime\n$\\sigma \\gg 1$ that is highly relevant in applications. Recent investigations\nhave revealed a remarkable asymptotic sample complexity of order $\\sigma^6$ for\ncertain signals whose Fourier transforms have full support, in stark contrast\nto the traditional $\\sigma^2$ that arise in regular models. Often prohibitively\nlarge in practice, these results have prompted the investigation of variations\naround the MRA model where better sample complexity may be achieved. In this\npaper, we show that sparse signals exhibit an intermediate $\\sigma^4$ sample\ncomplexity even in the classical MRA model. Further, we characterise the\ndependence of the estimation rate on the support size $s$ as $O_p(1)$ and\n$O_p(s^{3.5})$ in the dilute and moderate regimes of sparsity respectively. Our\ntechniques have implications for the problem of crystallographic phase\nretrieval, indicating a certain local uniqueness for the recovery of sparse\nsignals from their power spectrum. Our results explore and exploit connections\nof the MRA estimation problem with two classical topics in applied mathematics:\nthe beltway problem from combinatorial optimization, and uniform uncertainty\nprinciples from harmonic analysis. Our techniques include a certain enhanced\nform of the probabilistic method, which might be of general interest in its own\nright.",
          "link": "http://arxiv.org/abs/2106.12996",
          "publishedOn": "2022-03-12T00:41:14.715Z",
          "wordCount": 734,
          "title": "Sparse Multi-Reference Alignment : Phase Retrieval, Uniform Uncertainty Principles and the Beltway Problem. (arXiv:2106.12996v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.05763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manduchi_L/0/1/0/all/0/1\">Laura Manduchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcinkevics_R/0/1/0/all/0/1\">Ri&#x10d;ards Marcinkevi&#x10d;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massi_M/0/1/0/all/0/1\">Michela C. Massi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weikert_T/0/1/0/all/0/1\">Thomas Weikert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sauter_A/0/1/0/all/0/1\">Alexander Sauter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotta_V/0/1/0/all/0/1\">Verena Gotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1\">Timothy M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasella_F/0/1/0/all/0/1\">Flavio Vasella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neidert_M/0/1/0/all/0/1\">Marian C. Neidert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_M/0/1/0/all/0/1\">Marc Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stieltjes_B/0/1/0/all/0/1\">Bram Stieltjes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "In this work, we study the problem of clustering survival data $-$ a\nchallenging and so far under-explored task. We introduce a novel\nsemi-supervised probabilistic approach to cluster survival data by leveraging\nrecent advances in stochastic gradient variational inference. In contrast to\nprevious work, our proposed method employs a deep generative model to uncover\nthe underlying distribution of both the explanatory variables and censored\nsurvival times. We compare our model to the related work on clustering and\nmixture models for survival data in comprehensive experiments on a wide range\nof synthetic, semi-synthetic, and real-world datasets, including medical\nimaging data. Our method performs better at identifying clusters and is\ncompetitive at predicting survival times. Relying on novel generative\nassumptions, the proposed model offers a holistic perspective on clustering\nsurvival data and holds a promise of discovering subpopulations whose survival\nis regulated by different generative mechanisms.",
          "link": "http://arxiv.org/abs/2106.05763",
          "publishedOn": "2022-03-12T00:41:14.706Z",
          "wordCount": 640,
          "title": "A Deep Variational Approach to Clustering Survival Data. (arXiv:2106.05763v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1902.10890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Burghal_D/0/1/0/all/0/1\">Daoud Burghal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alghafis_A/0/1/0/all/0/1\">Abdullah Alghafis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molisch_A/0/1/0/all/0/1\">Andreas F. Molisch</a>",
          "description": "Many wireless networks, including 5G NR (New Radio) and future beyond 5G\ncellular systems, are expected to operate on multiple frequency bands. This\npaper considers the band assignment (BA) problem in dual-band systems, where\nthe basestation (BS) chooses one of the two available frequency bands\n(centimeter-wave and millimeter-wave bands) to communicate with the user\nequipment (UE). While the millimeter-wave band might offer higher data rate,\nthere is a significant probability of outage during which the communication\nshould be carried on the (more reliable) centimeter-wave band. With mobility,\nthe BA can be perceived as a sequential problem, where the BS uses previously\nobserved information to predict the best band for a future time step.\n\nWe formulate the BA as a binary classification problem and propose supervised\nMachine Learning (ML) solutions. We study the problem when both the BS and the\nUE use (i) omnidirectional antennas and (ii) both use directional antennas. In\nthe omnidirectional case, we derive analytical benchmark solutions based on the\nGaussian Process (GP) assumption for the inter-band shadow fading. In the\ndirectional case, where the labeling is shown to be complex, we propose an\nefficient labeling approach based on the Viterbi Algorithm (VA). We compare the\nperformances for two channel models: (i) a stochastic channel and (ii) a\nray-tracing based channel.",
          "link": "http://arxiv.org/abs/1902.10890",
          "publishedOn": "2022-03-12T00:41:14.024Z",
          "wordCount": 707,
          "title": "Supervised ML Solution for Band Assignment in Dual-Band Systems with Omnidirectional and Directional Antennas. (arXiv:1902.10890v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.08199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hwanjun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minseok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">Dongmin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yooju Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-Gil Lee</a>",
          "description": "Deep learning has achieved remarkable success in numerous domains with help\nfrom large amounts of big data. However, the quality of data labels is a\nconcern because of the lack of high-quality labels in many real-world\nscenarios. As noisy labels severely degrade the generalization performance of\ndeep neural networks, learning from noisy labels (robust training) is becoming\nan important task in modern deep learning applications. In this survey, we\nfirst describe the problem of learning with label noise from a supervised\nlearning perspective. Next, we provide a comprehensive review of 62\nstate-of-the-art robust training methods, all of which are categorized into\nfive groups according to their methodological difference, followed by a\nsystematic comparison of six properties used to evaluate their superiority.\nSubsequently, we perform an in-depth analysis of noise rate estimation and\nsummarize the typically used evaluation methodology, including public noisy\ndatasets and evaluation metrics. Finally, we present several promising research\ndirections that can serve as a guideline for future studies. All the contents\nwill be available at https://github.com/songhwanjun/Awesome-Noisy-Labels.",
          "link": "http://arxiv.org/abs/2007.08199",
          "publishedOn": "2022-03-12T00:41:14.017Z",
          "wordCount": 703,
          "title": "Learning from Noisy Labels with Deep Neural Networks: A Survey. (arXiv:2007.08199v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.02705",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rugamer_D/0/1/0/all/0/1\">David R&#xfc;gamer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kolb_C/0/1/0/all/0/1\">Chris Kolb</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fritz_C/0/1/0/all/0/1\">Cornelius Fritz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pfisterer_F/0/1/0/all/0/1\">Florian Pfisterer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kopper_P/0/1/0/all/0/1\">Philipp Kopper</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shen_R/0/1/0/all/0/1\">Ruolin Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bukas_C/0/1/0/all/0/1\">Christina Bukas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sousa_L/0/1/0/all/0/1\">Lisa Barros de Andrade e Sousa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thalmeier_D/0/1/0/all/0/1\">Dominik Thalmeier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baumann_P/0/1/0/all/0/1\">Philipp Baumann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kook_L/0/1/0/all/0/1\">Lucas Kook</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Klein_N/0/1/0/all/0/1\">Nadja Klein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Muller_C/0/1/0/all/0/1\">Christian L. M&#xfc;ller</a>",
          "description": "In this paper we describe the implementation of semi-structured deep\ndistributional regression, a flexible framework to learn conditional\ndistributions based on the combination of additive regression models and deep\nnetworks. Our implementation encompasses (1) a modular neural network building\nsystem based on the deep learning library \\pkg{TensorFlow} for the fusion of\nvarious statistical and deep learning approaches, (2) an orthogonalization cell\nto allow for an interpretable combination of different subnetworks, as well as\n(3) pre-processing steps necessary to set up such models. The software package\nallows to define models in a user-friendly manner via a formula interface that\nis inspired by classical statistical model frameworks such as \\pkg{mgcv}. The\npackages' modular design and functionality provides a unique resource for both\nscalable estimation of complex statistical models and the combination of\napproaches from deep learning and statistics. This allows for state-of-the-art\npredictive performance while simultaneously retaining the indispensable\ninterpretability of classical statistical models.",
          "link": "http://arxiv.org/abs/2104.02705",
          "publishedOn": "2022-03-12T00:41:13.997Z",
          "wordCount": 649,
          "title": "deepregression: a Flexible Neural Network Framework for Semi-Structured Deep Distributional Regression. (arXiv:2104.02705v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.03350",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Munkhdalai_L/0/1/0/all/0/1\">Lkhagvadorj Munkhdalai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Munkhdalai_T/0/1/0/all/0/1\">Tsendsuren Munkhdalai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ryu_K/0/1/0/all/0/1\">Keun Ho Ryu</a>",
          "description": "Machine learning models with both good predictability and high\ninterpretability are crucial for decision support systems. Linear regression is\none of the most interpretable prediction models. However, the linearity in a\nsimple linear regression worsens its predictability. In this work, we introduce\na locally adaptive interpretable regression (LoAIR). In LoAIR, a metamodel\nparameterized by neural networks predicts percentile of a Gaussian distribution\nfor the regression coefficients for a rapid adaptation. Our experimental\nresults on public benchmark datasets show that our model not only achieves\ncomparable or better predictive performance than the other state-of-the-art\nbaselines but also discovers some interesting relationships between input and\ntarget variables such as a parabolic relationship between CO2 emissions and\nGross National Product (GNP). Therefore, LoAIR is a step towards bridging the\ngap between econometrics, statistics, and machine learning by improving the\npredictive ability of linear regression without depreciating its\ninterpretability.",
          "link": "http://arxiv.org/abs/2005.03350",
          "publishedOn": "2022-03-12T00:41:13.962Z",
          "wordCount": 603,
          "title": "A Locally Adaptive Interpretable Regression. (arXiv:2005.03350v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05363",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ye_J/0/1/0/all/0/1\">Jiayuan Ye</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shokri_R/0/1/0/all/0/1\">Reza Shokri</a>",
          "description": "Differential privacy analysis of randomized learning algorithms typically\nrelies on composition theorems, where the implicit assumption is that the\ninternal state of the iterative algorithm is revealed to the adversary.\nHowever, by assuming hidden states for DP algorithms (when only the\nlast-iterate is observable), recent works prove a converging privacy bound for\nnoisy gradient descent (on strongly convex smooth loss function) that is\nsignificantly smaller than composition bounds after $O(1/\\text{step-size})$\nepochs. In this paper, we extend this hidden-state analysis to the noisy\nmini-batch stochastic gradient descent algorithms on strongly-convex smooth\nloss functions. We prove converging R\\'enyi DP bounds under various mini-batch\nsampling schemes, such as \"shuffle and partition\" (which are used in practical\nimplementations of DP-SGD) and \"sampling without replacement\". We prove that,\nin these settings, our privacy bound is much smaller than the composition bound\nfor training with a large number of iterations (which is the case for learning\nfrom high-dimensional data). Our converging privacy analysis, thus, shows that\ndifferentially private learning, with a tight bound, needs hidden state privacy\nanalysis or a fast convergence. To complement our theoretical results, we run\nexperiment on training classification models on MNIST, FMNIST and CIFAR-10\ndatasets, and observe a better accuracy given fixed privacy budgets, under the\nhidden-state analysis.",
          "link": "http://arxiv.org/abs/2203.05363",
          "publishedOn": "2022-03-12T00:41:13.952Z",
          "wordCount": 650,
          "title": "Differentially Private Learning Needs Hidden State (Or Much Faster Convergence). (arXiv:2203.05363v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blanchard_M/0/1/0/all/0/1\">Mo&#xef;se Blanchard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaillet_P/0/1/0/all/0/1\">Patrick Jaillet</a>",
          "description": "We provide algorithms for regression with adversarial responses under large\nclasses of non-i.i.d. instance sequences, on general separable metric spaces,\nwith provably minimal assumptions. We also give characterizations of\nlearnability in this regression context. We consider universal consistency\nwhich asks for strong consistency of a learner without restrictions on the\nvalue responses. Our analysis shows that such objective is achievable for a\nsignificantly larger class of instance sequences than stationary processes, and\nunveils a fundamental dichotomy between value spaces: whether finite-horizon\nmean-estimation is achievable or not. We further provide optimistically\nuniversal learning rules, i.e., such that if they fail to achieve universal\nconsistency, any other algorithm will fail as well. For unbounded losses, we\npropose a mild integrability condition under which there exist algorithms for\nadversarial regression under large classes of non-i.i.d. instance sequences. In\naddition, our analysis also provides a learning rule for mean-estimation in\ngeneral metric spaces that is consistent under adversarial responses without\nany moment conditions on the sequence, a result of independent interest.",
          "link": "http://arxiv.org/abs/2203.05067",
          "publishedOn": "2022-03-12T00:41:13.944Z",
          "wordCount": 596,
          "title": "Universal Regression with Adversarial Responses. (arXiv:2203.05067v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05400",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Karvonen_T/0/1/0/all/0/1\">Toni Karvonen</a>",
          "description": "It is common to model a deterministic response function, such as the output\nof a computer experiment, as a Gaussian process with a Mat\\'ern covariance\nkernel. The smoothness parameter of a Mat\\'ern kernel determines many important\nproperties of the model in the large data limit, such as the rate of\nconvergence of the conditional mean to the response function. We prove that the\nmaximum likelihood and cross-validation estimates of the smoothness parameter\ncannot asymptotically undersmooth the truth when the data are obtained on a\nfixed bounded subset of $\\mathbb{R}^d$. That is, if the data-generating\nresponse function has Sobolev smoothness $\\nu_0 + d/2$, then the smoothness\nparameter estimates cannot remain below $\\nu_0$ as more data are obtained.\nThese results are based on a general theorem, proved using reproducing kernel\nHilbert space techniques, about sets of values the parameter estimates cannot\ntake and approximation theory in Sobolev spaces.",
          "link": "http://arxiv.org/abs/2203.05400",
          "publishedOn": "2022-03-12T00:41:13.936Z",
          "wordCount": 589,
          "title": "Asymptotic Bounds for Smoothness Parameter Estimates in Gaussian Process Regression. (arXiv:2203.05400v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.08853",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Han_R/0/1/0/all/0/1\">Ruijian Han</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_Y/0/1/0/all/0/1\">Yiming Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_K/0/1/0/all/0/1\">Kani Chen</a>",
          "description": "Statistical inference using pairwise comparison data is an effective approach\nto analyzing large-scale sparse networks. In this paper, we propose a general\nframework to model the mutual interactions in a network, which enjoys ample\nflexibility in terms of model parametrization. Under this setup, we show that\nthe maximum likelihood estimator for the latent score vector of the subjects is\nuniformly consistent under a near-minimal condition on network sparsity. This\ncondition is sharp in terms of the leading order asymptotics describing the\nsparsity. Our analysis utilizes a novel chaining technique and illustrates an\nimportant connection between graph topology and model consistency. Our results\nguarantee that the maximum likelihood estimator is justified for estimation in\nlarge-scale pairwise comparison networks where data are asymptotically\ndeficient. Simulation studies are provided in support of our theoretical\nfindings.",
          "link": "http://arxiv.org/abs/2002.08853",
          "publishedOn": "2022-03-12T00:41:13.914Z",
          "wordCount": 608,
          "title": "A General Pairwise Comparison Model for Extremely Sparse Networks. (arXiv:2002.08853v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Doshi_K/0/1/0/all/0/1\">Keval Doshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abudalou_S/0/1/0/all/0/1\">Shatha Abudalou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yilmaz_Y/0/1/0/all/0/1\">Yasin Yilmaz</a>",
          "description": "While anomaly detection in time series has been an active area of research\nfor several years, most recent approaches employ an inadequate evaluation\ncriterion leading to an inflated F1 score. We show that a rudimentary Random\nGuess method can outperform state-of-the-art detectors in terms of this popular\nbut faulty evaluation criterion. In this work, we propose a proper evaluation\nmetric that measures the timeliness and precision of detecting sequential\nanomalies. Moreover, most existing approaches are unable to capture temporal\nfeatures from long sequences. Self-attention based approaches, such as\ntransformers, have been demonstrated to be particularly efficient in capturing\nlong-range dependencies while being computationally efficient during training\nand inference. We also propose an efficient transformer approach for anomaly\ndetection in time series and extensively evaluate our proposed approach on\nseveral popular benchmark datasets.",
          "link": "http://arxiv.org/abs/2203.05167",
          "publishedOn": "2022-03-12T00:41:13.907Z",
          "wordCount": 566,
          "title": "TiSAT: Time Series Anomaly Transformer. (arXiv:2203.05167v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05443",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rocks_J/0/1/0/all/0/1\">Jason W. Rocks</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mehta_P/0/1/0/all/0/1\">Pankaj Mehta</a>",
          "description": "In classical statistics, the bias-variance trade-off describes how varying a\nmodel's complexity (e.g., number of fit parameters) affects its ability to make\naccurate predictions. According to this trade-off, optimal performance is\nachieved when a model is expressive enough to capture trends in the data, yet\nnot so complex that it overfits idiosyncratic features of the training data.\nRecently, it has become clear that this classic understanding of the\nbias-variance must be fundamentally revisited in light of the incredible\npredictive performance of \"overparameterized models\" -- models that avoid\noverfitting even when the number of fit parameters is large enough to perfectly\nfit the training data. Here, we present results for one of the simplest\nexamples of an overparameterized model: regression with random linear features\n(i.e. a two-layer neural network with a linear activation function). Using the\nzero-temperature cavity method, we derive analytic expressions for the training\nerror, test error, bias, and variance. We show that the linear random features\nmodel exhibits three phase transitions: two different transitions to an\ninterpolation regime where the training error is zero, along with an additional\ntransition between regimes with large bias and minimal bias. Using random\nmatrix theory, we show how each transition arises due to small nonzero\neigenvalues in the Hessian matrix. Finally, we compare and contrast the phase\ndiagram of the random linear features model to the random nonlinear features\nmodel and ordinary regression, highlighting the new phase transitions that\nresult from the use of linear basis functions.",
          "link": "http://arxiv.org/abs/2203.05443",
          "publishedOn": "2022-03-12T00:41:13.899Z",
          "wordCount": 702,
          "title": "Bias-variance decomposition of overparameterized regression with random linear features. (arXiv:2203.05443v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05164",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ebers_M/0/1/0/all/0/1\">Megan R. Ebers</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steele_K/0/1/0/all/0/1\">Katherine M. Steele</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kutz_J/0/1/0/all/0/1\">J. Nathan Kutz</a>",
          "description": "Physics-based and first-principles models pervade the engineering and\nphysical sciences, allowing for the ability to model the dynamics of complex\nsystems with a prescribed accuracy. The approximations used in deriving\ngoverning equations often result in discrepancies between the model and\nsensor-based measurements of the system, revealing the approximate nature of\nthe equations and/or the signal-to-noise ratio of the sensor itself. In modern\ndynamical systems, such discrepancies between model and measurement can lead to\npoor quantification, often undermining the ability to produce accurate and\nprecise control algorithms. We introduce a discrepancy modeling framework to\nresolve deterministic model-measurement mismatch with two distinct approaches:\n(i) by learning a model for the evolution of systematic state-space residual,\nand (ii) by discovering a model for the missing deterministic physics.\nRegardless of approach, a common suite of data-driven model discovery methods\ncan be used. Specifically, we use four fundamentally different methods to\ndemonstrate the mathematical implementations of discrepancy modeling: (i) the\nsparse identification of nonlinear dynamics (SINDy), (ii) dynamic mode\ndecomposition (DMD), (iii) Gaussian process regression (GPR), and (iv) neural\nnetworks (NN). The choice of method depends on one's intent for discrepancy\nmodeling, as well as quantity and quality of the sensor measurements. We\ndemonstrate the utility and suitability for both discrepancy modeling\napproaches using the suite of data-driven modeling methods on three dynamical\nsystems under varying signal-to-noise ratios. We compare reconstruction and\nforecasting accuracies and provide detailed comparatives, allowing one to\nselect the appropriate approach and method in practice.",
          "link": "http://arxiv.org/abs/2203.05164",
          "publishedOn": "2022-03-12T00:41:13.890Z",
          "wordCount": 703,
          "title": "Discrepancy Modeling Framework: Learning missing physics, modeling systematic residuals, and disambiguating between deterministic and random effects. (arXiv:2203.05164v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05120",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Provost_M/0/1/0/all/0/1\">Mathieu Le Provost</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Baptista_R/0/1/0/all/0/1\">Ricardo Baptista</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Marzouk_Y/0/1/0/all/0/1\">Youssef Marzouk</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Eldredge_J/0/1/0/all/0/1\">Jeff D. Eldredge</a>",
          "description": "We propose a regularization method for ensemble Kalman filtering (EnKF) with\nelliptic observation operators. Commonly used EnKF regularization methods\nsuppress state correlations at long distances. For observations described by\nelliptic partial differential equations, such as the pressure Poisson equation\n(PPE) in incompressible fluid flows, distance localization cannot be applied,\nas we cannot disentangle slowly decaying physical interactions from spurious\nlong-range correlations. This is particularly true for the PPE, in which\ndistant vortex elements couple nonlinearly to induce pressure. Instead, these\ninverse problems have a low effective dimension: low-dimensional projections of\nthe observations strongly inform a low-dimensional subspace of the state space.\nWe derive a low-rank factorization of the Kalman gain based on the spectrum of\nthe Jacobian of the observation operator. The identified eigenvectors\ngeneralize the source and target modes of the multipole expansion,\nindependently of the underlying spatial distribution of the problem. Given\nrapid spectral decay, inference can be performed in the low-dimensional\nsubspace spanned by the dominant eigenvectors. This low-rank EnKF is assessed\non dynamical systems with Poisson observation operators, where we seek to\nestimate the positions and strengths of point singularities over time from\npotential or pressure observations. We also comment on the broader\napplicability of this approach to elliptic inverse problems outside the context\nof filtering.",
          "link": "http://arxiv.org/abs/2203.05120",
          "publishedOn": "2022-03-12T00:41:13.869Z",
          "wordCount": 669,
          "title": "A low-rank ensemble Kalman filter for elliptic observations. (arXiv:2203.05120v1 [physics.flu-dyn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05417",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Didisheim_A/0/1/0/all/0/1\">Antoine Didisheim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kelly_B/0/1/0/all/0/1\">Bryan Kelly</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Malamud_S/0/1/0/all/0/1\">Semyon Malamud</a>",
          "description": "We introduce a methodology for designing and training deep neural networks\n(DNN) that we call \"Deep Regression Ensembles\" (DRE). It bridges the gap\nbetween DNN and two-layer neural networks trained with random feature\nregression. Each layer of DRE has two components, randomly drawn input weights\nand output weights trained myopically (as if the final output layer) using\nlinear ridge regression. Within a layer, each neuron uses a different subset of\ninputs and a different ridge penalty, constituting an ensemble of random\nfeature ridge regressions. Our experiments show that a single DRE architecture\nis at par with or exceeds state-of-the-art DNN in many data sets. Yet, because\nDRE neural weights are either known in closed-form or randomly drawn, its\ncomputational cost is orders of magnitude smaller than DNN.",
          "link": "http://arxiv.org/abs/2203.05417",
          "publishedOn": "2022-03-12T00:41:13.861Z",
          "wordCount": 551,
          "title": "Deep Regression Ensembles. (arXiv:2203.05417v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whitehouse_J/0/1/0/all/0/1\">Justin Whitehouse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_R/0/1/0/all/0/1\">Ryan Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>",
          "description": "Composition is a key feature of differential privacy. Well-known advanced\ncomposition theorems allow one to query a private database quadratically more\ntimes than basic privacy composition would permit. However, these results\nrequire that the privacy parameters of all algorithms be fixed before\ninteracting with the data. To address this, Rogers et al. introduced fully\nadaptive composition, wherein both algorithms and their privacy parameters can\nbe selected adaptively. The authors introduce two probabilistic objects to\nmeasure privacy in adaptive composition: privacy filters, which provide\ndifferential privacy guarantees for composed interactions, and privacy\nodometers, time-uniform bounds on privacy loss. There are substantial gaps\nbetween advanced composition and existing filters and odometers. First,\nexisting filters place stronger assumptions on the algorithms being composed.\nSecond, these odometers and filters suffer from large constants, making them\nimpractical. We construct filters that match the tightness of advanced\ncomposition, including constants, despite allowing for adaptively chosen\nprivacy parameters. We also construct several general families of odometers.\nThese odometers can match the tightness of advanced composition at an\narbitrary, preselected point in time, or at all points in time simultaneously,\nup to a doubly-logarithmic factor. We obtain our results by leveraging recent\nadvances in time-uniform martingale concentration. In sum, we show that fully\nadaptive privacy is obtainable at almost no loss, and conjecture that our\nresults are essentially unimprovable (even in constants) in general.",
          "link": "http://arxiv.org/abs/2203.05481",
          "publishedOn": "2022-03-12T00:41:13.843Z",
          "wordCount": 677,
          "title": "Fully Adaptive Composition in Differential Privacy. (arXiv:2203.05481v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05197",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cabel_D/0/1/0/all/0/1\">Danielle Cabel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kato_M/0/1/0/all/0/1\">Masahiro Kato</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McAlinn_K/0/1/0/all/0/1\">Kenichiro McAlinn</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugasawa_S/0/1/0/all/0/1\">Shonosuke Sugasawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takanashi_K/0/1/0/all/0/1\">Kosaku Takanashi</a>",
          "description": "Spatial data are characterized by their spatial dependence, which is often\ncomplex, non-linear, and difficult to capture with a single model. Significant\nlevels of model uncertainty -- arising from these characteristics -- cannot be\nresolved by model selection or simple ensemble methods, as performances are not\nhomogeneous. We address this issue by proposing a novel methodology that\ncaptures spatially-varying model uncertainty, which we call spatial Bayesian\npredictive synthesis. Our proposal is defined by specifying a latent factor\nspatially-varying coefficient model as the synthesis function, which enables\nmodel coefficients to vary over the region to achieve flexible spatial model\nensembling. Two MCMC strategies are implemented for full uncertainty\nquantification, as well as a variational inference strategy for fast point\ninference. We also extend the estimations strategy for general responses. A\nfinite sample theoretical guarantee is given for the predictive performance of\nour methodology, showing that the predictions are exact minimax. Through\nsimulation examples and two real data applications, we demonstrate that our\nproposed spatial Bayesian predictive synthesis outperforms standard spatial\nmodels and advanced machine learning methods, in terms of predictive accuracy,\nwhile maintaining interpretability of the prediction mechanism.",
          "link": "http://arxiv.org/abs/2203.05197",
          "publishedOn": "2022-03-12T00:41:13.824Z",
          "wordCount": 630,
          "title": "Spatially-Varying Bayesian Predictive Synthesis for Flexible and Interpretable Spatial Prediction. (arXiv:2203.05197v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.09363",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Caragea_A/0/1/0/all/0/1\">Andrei Caragea</a>, <a href=\"http://arxiv.org/find/math/1/au:+Petersen_P/0/1/0/all/0/1\">Philipp Petersen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Voigtlaender_F/0/1/0/all/0/1\">Felix Voigtlaender</a>",
          "description": "We prove bounds for the approximation and estimation of certain binary\nclassification functions using ReLU neural networks. Our estimation bounds\nprovide a priori performance guarantees for empirical risk minimization using\nnetworks of a suitable size, depending on the number of training samples\navailable. The obtained approximation and estimation rates are independent of\nthe dimension of the input, showing that the curse of dimensionality can be\novercome in this setting; in fact, the input dimension only enters in the form\nof a polynomial factor. Regarding the regularity of the target classification\nfunction, we assume the interfaces between the different classes to be locally\nof Barron-type. We complement our results by studying the relations between\nvarious Barron-type spaces that have been proposed in the literature. These\nspaces differ substantially more from each other than the current literature\nsuggests.",
          "link": "http://arxiv.org/abs/2011.09363",
          "publishedOn": "2022-03-12T00:41:13.815Z",
          "wordCount": 607,
          "title": "Neural network approximation and estimation of classifiers with classification boundary in a Barron class. (arXiv:2011.09363v2 [math.FA] UPDATED)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Machine Learning",
      "feedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
      "siteUrl": "https://www.reddit.com/r/MachineLearning/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u02p5x/r_local_learning_matters_rethinking_data/",
          "author": null,
          "description": "#cvpr-2022\n Happy to share our CVPR-2022 paper \"Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning\"\n Paper: https://arxiv.org/pdf/2111.14213.pdf\n Code: https://github.com/mmendiet/FedAlign\n Federated learning (FL) is a promising strategy for performing privacy-preserving, distributed learning with a network of clients (i.e., edge devices). However, the data distribution among clients is often non-IID in nature, making efficient optimization difficult. To alleviate this issue, many FL algorithms focus on mitigating the effects of data heterogeneity across clients by introducing a variety of proximal terms, some incurring considerable compute and/or memory overheads, to restrain local updates with respect to the global model. Instead, we consider rethinking solutions to data heterogeneity in FL with a focus on local learning generality rather than proximal restriction. To this end, we first present a systematic study informed by second-order indicators to better understand algorithm effectiveness in FL. Interestingly, we find that standard regularization methods are surprisingly strong performers in mitigating data heterogeneity effects. Based on our findings, we further propose a simple and effective method, FedAlign, to overcome data heterogeneity and the pitfalls of previous methods. FedAlign achieves competitive accuracy with state-of-the-art FL methods across a variety of settings while minimizing computation and memory overhead.\n    submitted by    /u/Extension-Sun1816  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u02p5x/r_local_learning_matters_rethinking_data/",
          "publishedOn": "2022-04-09T21:25:49.000Z",
          "wordCount": 295,
          "title": "[R] Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzvxb9/d_icml2022_domain_conflicts_system/",
          "author": null,
          "description": "I was wondering if the Domain conflicts system working well?\n I got an email from the PCs and seems that the domain conflict system is not working well. It said that we can enter the conflict now but I cannot edit the conflict in the system. Could anyone tell me how to do it? Thanks!\n  \nDear ICML Authors, \n As we are seeing this happen, we just wanted to send you a brief explanation -- this only applies to some few papers. A few papers are losing reviews because of newly arising conflicts. If you did not enter your conflicts in CMT during the submission phase (as requested via CMT), then they could not be used in paper assignments. If you enter them now, any reviews by reviewers with conflicting domains will disappear, and you may see fewer reviews as a result. Unfortunately, we have no control over this, as the conflicts should have been entered when the paper was submitted. \n Best, \n Stefanie, Le and Csaba\n  \n   submitted by    /u/Snoo_97274  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzvxb9/d_icml2022_domain_conflicts_system/",
          "publishedOn": "2022-04-09T15:47:54.000Z",
          "wordCount": 249,
          "title": "[D] ICML2022 Domain conflicts system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzp4kv/d_poll_how_do_you_deploy_models_endpoints/",
          "author": null,
          "description": "View Poll\n    submitted by    /u/martolini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzp4kv/d_poll_how_do_you_deploy_models_endpoints/",
          "publishedOn": "2022-04-09T08:47:40.000Z",
          "wordCount": 179,
          "title": "[D] Poll: How do you deploy models & endpoints?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzowos/rp_generate_images_from_text_with_latent/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzowos/rp_generate_images_from_text_with_latent/",
          "publishedOn": "2022-04-09T08:30:09.000Z",
          "wordCount": 447,
          "title": "[R][P] Generate images from text with Latent Diffusion LAION-400M Model + Gradio Demo",
          "imageUrl": "https://preview.redd.it/58fjuz70sgs81.png?auto=webp&s=849a5c0a11df3431e2e785b4e7bba43547fd2ae2"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzouo4/p_tinydl_library_to_help_with_hyperparameter/",
          "author": null,
          "description": "Hi everyone,\n I built a small library to help with hyperparameter search for deep learning models created with pytorch, because I got kinda tired of having to rewrite large pieces code over and over again.\n You can check it out here: https://github.com/michi-jeremias/tinydl or you can even install it with pip (pip install tinydl). I have included a readme and an example of how the library can be used.\n About the library, it's pretty flexible about reporting different metrics to the console and to tensorboard (add_scalar, add_hparam) at each stage of the process, like after a batch, epoch of after a whole run over multiple epochs. It can also be easily extended to include other metrics or new types of outputs.\n Since this is basically my first attempt at a software project that's not intended only to be used by myself I'd be happy about any feedback you have for me!\n If the project doesn't qualify to be posted here due to being too simple/too much on a beginner level, apologies for that.\n    submitted by    /u/abacaxiquaxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzouo4/p_tinydl_library_to_help_with_hyperparameter/",
          "publishedOn": "2022-04-09T08:26:02.000Z",
          "wordCount": 283,
          "title": "[P] tinydl - library to help with hyperparameter search and metric reporting in pytorch",
          "imageUrl": "https://external-preview.redd.it/LAHK1MYtwhgtja_z8t-OxpLe_RGNXrgwE2G9Vcnyza8.jpg?auto=webp&s=4da53c43496a4a8b26c374fab44c26f0fe4664ca"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzoqg2/d_stylegan2_path_length_regularization/",
          "author": null,
          "description": "I am trying to implement stylegan2 and there are so many things here that are not explained either well, or at all in the paper.\n ​\n  \nHow exactly is path length regularization implemented? In this PT code we can see that the $|J^T_w.y|$ is computed as follows:\n  \n​\n def g_path_regularize(fake_img, latents, mean_path_length, decay=0.01): noise = torch.randn_like(fake_img) / math.sqrt( fake_img.shape[2] * fake_img.shape[3] ) grad, = autograd.grad( outputs=(fake_img * noise).sum(), inputs=latents, create_graph=True ) path_lengths = torch.sqrt(grad.pow(2).sum(2).mean(1)) path_mean = mean_path_length + decay * (path_lengths.mean() - mean_path_length) path_penalty = (path_lengths - path_mean).pow(2).mean() return path_penalty, path_mean.detach(), path_lengths \n This is based on this official TF implementation.\n The problem I have is that from what I understand, fake_img is 4D, and latents is 2D. The grad output in this case will be 2D and grad.pow(2).sum(2) cannot be computed because the third axis does not exist. Obviously people who are using these repos have not reported any issue regarding mismatch of shapes and axes, so I believe there is something else going on. Since I'm trying to implement this in my own network, I cannot get the desired shape any how. I get a 2D gradient output.\n    submitted by    /u/feryet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzoqg2/d_stylegan2_path_length_regularization/",
          "publishedOn": "2022-04-09T08:16:53.000Z",
          "wordCount": 280,
          "title": "[D] StyleGAN2 Path Length Regularization Implementation Clarification",
          "imageUrl": "https://external-preview.redd.it/O-Qa83OpjON3SWHV-wEplWm6hveg9MwnypL-8LbGhj0.jpg?auto=webp&s=5f87229a3d481d78fb390659e8ae68f1dd7cb61c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzo5ih/p_jaxhaiku_pretrained_models_mobilenet_resnet_vgg/",
          "author": null,
          "description": "I released a repository of models with optional pretrained weights(Weights are taken from TF/Keras) to be used for tasks like prediction, feature extraction and fine-tuning.\n Github: https://github.com/abarcel/haikumodels\n Currently Available Models\n  \nMobileNet\n ResNet [50, 101, 152]\n VGG [16, 19]\n Xception\n  \nAlso planning to release more, as soon as I find time for it.\n    submitted by    /u/abarcel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzo5ih/p_jaxhaiku_pretrained_models_mobilenet_resnet_vgg/",
          "publishedOn": "2022-04-09T07:31:55.000Z",
          "wordCount": 143,
          "title": "[P] Jax/Haiku pretrained models: MobileNet, ResNet, VGG, Xception.",
          "imageUrl": "https://external-preview.redd.it/XjGrYB5ZZF-dofoIIZW3gcfGriVD2PvY0cLghzZCTaY.jpg?auto=webp&s=4f0457113cf97eb52cfefb596f2a88fe97274084"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tznijk/d_denoising_in_the_latent_space/",
          "author": null,
          "description": "I spent some time reading about and playing around with speech denoising DNNs ~2019. At the time the popular architecture was U-Net (encoder -> bottleneck -> decoder with skip connections) operating on spectrograms. These U-Nets were trained directly on noisy/clean speech pairs and the loss was the difference between the predicted denoised images and actual denoised image. MSE between the predicted/actual images was a baseline loss but people alse added \"feature loss\" or sometimes a GAN-based loss function as well.\n Anyway a cursory reading of the DALL-E 2 paper has me thinking about that approach. I'm curious to know if a similar approach used for DALL-E has been tried for audio denoising:\n  \npre-train an encoder/decoder in a self-supervised fashion on a large dataset of audio\n train a denoiser to operate only in the latent space (ie the most compressed representation that is passed from the encoder to the decoder)\n  \nstep 1 - self-supervised training of encoder/decoder\n https://preview.redd.it/nprc40ob9gs81.png?width=1668&format=png&auto=webp&s=3a9b181ceff6c4530b5f41abf793dfb6409c0ec2\n step 2 - train denoiser in latent space only\n ​\n https://preview.redd.it/hreajdpe9gs81.png?width=1279&format=png&auto=webp&s=e16490fff00fe82487ca214b11b642ffcb30fb1c\n step 3 - do inference by feeding denoised latent space vector into the decoder\n https://preview.redd.it/7nox4ezh9gs81.png?width=2034&format=png&auto=webp&s=ccc69bbb2096d84a9e4a824000e62bb0f80fbe29\n Is this a common approach already? It seems like once you have a good pretrained encoder/decoder pair then the denoiser training would be much more efficient than training an entire network that does everything at once from scratch (smaller search space, faster training loop)\n    submitted by    /u/The_Amp_Walrus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tznijk/d_denoising_in_the_latent_space/",
          "publishedOn": "2022-04-09T06:46:23.000Z",
          "wordCount": 382,
          "title": "[D] Denoising in the latent space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzhbxj/discussion_mlops_vs_platform_engineering/",
          "author": null,
          "description": "Hey guys, I have the opportunity to either move to the platform engineering team or the freshly created MLOps team within my company. I'm interested in both careers, as I like to build Infra. I'm currently a Data Eng, and I find myself to like building apps and enabling applications to talk to each other, better than cleaning up data. I worked as a data scientist before, but I didn't like the science. I was always into engineering. What would make sense from a career perspective (both long and short term), i.e., money, promotions, attractiveness, etc.\n    submitted by    /u/dash2392  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzhbxj/discussion_mlops_vs_platform_engineering/",
          "publishedOn": "2022-04-09T00:27:17.000Z",
          "wordCount": 185,
          "title": "[Discussion] MLOps vs Platform Engineering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzg9p2/d_any_guesstimates_for_how_much_a_dalle_2/",
          "author": null,
          "description": "Just based on the estimated running costs of GPT3, and then whatever profit gets applied on top of that, are there any estimates for what openai will eventually charge for image generation?\n    submitted by    /u/EugeneJudo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzg9p2/d_any_guesstimates_for_how_much_a_dalle_2/",
          "publishedOn": "2022-04-08T23:29:44.000Z",
          "wordCount": 254,
          "title": "[D] Any guesstimates for how much a DALLE 2 generation will eventually cost?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzf2r1/problem_with_cvpr_template_and_arxiv_d/",
          "author": null,
          "description": "I don't know what would be the best place to post this. But I am having trouble uploading an Overleaf manuscript to arXiv based on the CVPR 2022 template. I am getting the following error. Does anyone have any ideas?\n ​\n https://preview.redd.it/y9jq0rbysds81.png?width=1614&format=png&auto=webp&s=16be3d32468837f649e846ec8a309dab2854c762\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzf2r1/problem_with_cvpr_template_and_arxiv_d/",
          "publishedOn": "2022-04-08T22:29:46.000Z",
          "wordCount": 135,
          "title": "Problem with CVPR template and arXiv? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tze09r/rsocratic_models_composing_zeroshot_multimodal/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2204.00598\n https://socraticmodels.github.io/\n Twitter: https://twitter.com/andyzengtweets/status/1512089759497269251\n Abstract: \" Large foundation models can exhibit unique capabilities depending on the domain of data they are trained on. While these domains are generic, they may only barely overlap. For example, visual-language models (VLMs) are trained on Internet-scale image captions, but large language models (LMs) are further trained on Internet-scale text with no images (e.g. from spreadsheets, to SAT questions). As a result, these models store different forms of commonsense knowledge across different domains. In this work, we show that this model diversity is symbiotic, and can be leveraged to build AI systems with structured Socratic dialogue -- in whi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tze09r/rsocratic_models_composing_zeroshot_multimodal/",
          "publishedOn": "2022-04-08T21:37:47.000Z",
          "wordCount": 333,
          "title": "[R]Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language - Google Apr 2022",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzcnwb/d_what_to_do_next_after_the_sanity_check/",
          "author": null,
          "description": "I have two years of time-series data taken from two sensors which I have split into 80/10/10 non-overlapping train/val/test splits. The task is to denoise one sensor data into another and I am handling it as a regression problem.\n I am following this website and considered an already published model (5 convolutional and 1 fully connected layer) which is trained on a similar dataset and same task.\n For the sake of sanity check, as per the website, I have trained the model on a subset of trainset (3 months) and tried to overfit it (while evaluating on complete val set), which works fine.\n However, I am not sure what to do next from this point on? Shall I just train on the complete trainset now? Or do I increase the layers or play with other hyper params to find more details about my regression problem/data? I would really appreciate your comments. Thank you.\n PS. The target value is sparse i.e. more than 85% of the time it is zero.\n    submitted by    /u/muaz_usmani  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzcnwb/d_what_to_do_next_after_the_sanity_check/",
          "publishedOn": "2022-04-08T20:33:36.000Z",
          "wordCount": 266,
          "title": "[D] What to do next after the sanity check?",
          "imageUrl": "https://external-preview.redd.it/ts0z7cd5buLjkX6R5TQi7kMqPtwQY7jK8s3fPJ8fANQ.jpg?auto=webp&s=617f0844a3718900a927c1e1fa7130f4dfa3765e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz9obh/d_leaving_ml_for_software_engineering/",
          "author": null,
          "description": "I'm keen to hear from people who have made the transition from ML Research/Engineering positions to software engineering roles (or who are considering it). What were your reasons for doing it and did you regret it? I see so many articles about transition from software to ML but none about going the opposite direction.\n Context: I've been working as an ML Engineer for a little over a year, and I'm just... not enjoying it. I want to love my job so badly as I like my boss, my colleagues, and the company (and I'm paid quite well for my level), but I just don't. I feel like the type of work I'm doing is not very smart and yet it's extremely draining: I spend so many hours just looking at loss curves, tweaking features and parameters. I'm somehow bored and stressed at the same time, because I don't enjoy the work and yet I feel the pressure to produce good models, and when they don't work as expected I can't help but take it personally as if if I just tried hard enough they would work. I find that the days were I end up having to take care of more purely engineering tasks I just have a lot more fun and I finish the day more satisfied and less drained. I think I just want to build something instead of spending hours banging my head against shit data. I would love to hear from people who feel or have felt the same way because whenever I speak about this with friends who are in ML they look at me like I'm a lunatic for wanting to leave it for software engineering.\n I'm obviously aware that swe roles are not all fun and games, but I just feel like there's been an excessive push for so many people to move to ML as it's \"cool\" and \"smart\" when in reality they're just different things who are going to suit different people.\n    submitted by    /u/hedy-m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz9obh/d_leaving_ml_for_software_engineering/",
          "publishedOn": "2022-04-08T18:12:46.000Z",
          "wordCount": 1541,
          "title": "[D] Leaving ML for Software Engineering?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz6izi/d_is_virtual_iclr_2022_worth_paying_for/",
          "author": null,
          "description": "The 2022 ICLR conference at the end of this month is virtual and costs $100 to attend. I was thinking of attending for networking opportunities but I’m not sure. Is it a good idea to go for it?\n    submitted by    /u/sybar142857  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz6izi/d_is_virtual_iclr_2022_worth_paying_for/",
          "publishedOn": "2022-04-08T15:49:34.000Z",
          "wordCount": 349,
          "title": "[D] Is virtual ICLR 2022 worth paying for",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz50is/d_triplet_vs_contrastive_loss/",
          "author": null,
          "description": "The online triplet mining strategy is more efficient than the offline one. It implies \"getting a batch of n samples and their associated labels, and form triplets on the fly.\" Here is an article about Triplet vs. Contrastive Loss comparison and its efficient implementation. I would like to know your feedback.\n    submitted by    /u/devzaya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz50is/d_triplet_vs_contrastive_loss/",
          "publishedOn": "2022-04-08T14:38:54.000Z",
          "wordCount": 140,
          "title": "[D] Triplet vs. Contrastive Loss",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz4dic/p_animated_character_generator/",
          "author": null,
          "description": "Hello everybody,\n I'd like to share the latest machine learning project of mine. It allows one to generate animated characters in the style of old video game consoles. Here are some examples. I would appreciate any feedback.\n https://i.redd.it/sig6ilpi8bs81.gif\n https://i.redd.it/xaf906qi8bs81.gif\n https://i.redd.it/8v7lz2qi8bs81.gif\n    submitted by    /u/ie9res  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz4dic/p_animated_character_generator/",
          "publishedOn": "2022-04-08T14:08:32.000Z",
          "wordCount": 122,
          "title": "[P] Animated Character Generator",
          "imageUrl": "https://external-preview.redd.it/GwQJ7G0XyNNGMXuRx3aaIeyjj8ou-FRsHor14m2yPPc.jpg?auto=webp&s=ff631469a0fd9b87dcbbe2f7e3bf848919109891"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz3x87/d_annotation_formats_for_image_annotations/",
          "author": null,
          "description": "Hey ML people, what is your favorite annotation format for image bounding boxes/labels? I know coco is very popular, we are rethinking parts of our data infrastructure wondering what everyone is using. Our platform hosts hundreds of millions of images. Ideal format would support running queries on data stored in a Data lake\n If the format supports 3D annotation types that is even better. Thanks for your insights in advance.\n    submitted by    /u/mmuppidi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz3x87/d_annotation_formats_for_image_annotations/",
          "publishedOn": "2022-04-08T13:47:05.000Z",
          "wordCount": 208,
          "title": "[D] Annotation formats for image annotations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz3qc8/n_openais_dalle_2_paper_hierarchical/",
          "author": null,
          "description": "New version of paper is linked to in the DALL-E 2 blog post and also here (pdf file format).\n Tweet announcing updated paper.\n Older version of paper (pdf file format).\n Original Reddit post.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz3qc8/n_openais_dalle_2_paper_hierarchical/",
          "publishedOn": "2022-04-08T13:37:13.000Z",
          "wordCount": 273,
          "title": "[N] OpenAI's DALL-E 2 paper \"Hierarchical Text-Conditional Image Generation with CLIP Latents\" has been updated with added section \"Training details\" (see Appendix C)",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz32ub/dense_passage_retrieverdpr_openqa_system_p/",
          "author": null,
          "description": "Hi, I made a video explaining Dense Passage Retriever(DPR) paper. We specifically explain the End to End QA system suggested in the latter part of the paper which discusses how to build an Open-QA system using dense retrievers.\n DPR was one of the first papers that discussed building dense retrievers using QA pairs only and didn't require a big pretraining computational setup like ORQA or REALM. It is currently used in a lot of places as a dense retriever. You can find Hugginface and Haystack implementations also.\n This video is part of a series on Open-QA using dense retrievers. We have made 2 videos on DPR. In the latter, we discuss how to build a dense retriever from scratch. Thanks for the support and it would be great if you could give any feedback.\n https://www.youtube.com/watch?v=rvcyyJNjPU0\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz32ub/dense_passage_retrieverdpr_openqa_system_p/",
          "publishedOn": "2022-04-08T13:03:32.000Z",
          "wordCount": 224,
          "title": "Dense Passage Retriever(DPR) Open-QA System [P]",
          "imageUrl": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?auto=webp&s=720b78add0a3005c4f67eaed6897df409cc040c6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz2o0b/d_works_that_can_process_variable_input/",
          "author": null,
          "description": "Hi. I'm looking for existing computer vision papers /networks that can process variable input resolution. Can anyone share me with similar works? For example, a network/layer N can take both inputs with H*W and 2H*2H individually and give correct prediction. One of them I know is ROI pooling used in Faster RCNN. Thanks very much.\n    submitted by    /u/vincent341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz2o0b/d_works_that_can_process_variable_input/",
          "publishedOn": "2022-04-08T12:41:56.000Z",
          "wordCount": 327,
          "title": "[D] Works that can process variable input resolution of images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz05tg/d_machine_learning_engineers_what_does_your_day/",
          "author": null,
          "description": "Hey, I'm looking to transition from my current role as a data scientist to one that has a machine learning engineering focus. I was wondering if anyone could provide insights into how they plan their day, or what activities you do throughout the day/week. I'd be particularly interested to understand the balance between deploying models/writing production worthy code and your time spent learning/developing given the field is moving so fast.\n    submitted by    /u/MenArePigs69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz05tg/d_machine_learning_engineers_what_does_your_day/",
          "publishedOn": "2022-04-08T10:06:51.000Z",
          "wordCount": 1320,
          "title": "[D] Machine Learning Engineers - What Does Your Day Involve?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tywuga/d_bayesian_nonparametrics_for_ranking/",
          "author": null,
          "description": "I am currently sitting at a difficult machine-learning problem that I have found no literature on how to solve it. \n I am given n datapoints x_1,...,x_n that are ordered according to a ranking preference rank(x_1)<rank(x_2)<...<rank(x_n). I am assuming there exists a function f, such, that f(x_i)<f(x_i+1). I am now searching a Bayesian non-parametric model that gives the posterior probability of functions f that abide f(x_i)<f(x_i+1), so that i can estimate the relative rank preferences at new points.\n I have tried out a few things. The naive approach is using a GP prior on f. Unfortunately, computing the posterior distribution p(f(x_1), ... f(x_n)| f(x_1)<...<f(x_n)) has no closed form solution (it is a normal distribution with N linear constraints, which is absolutely terrible to sample from). This makes computing conditional distributions for predictions very challenging. \n I am currently approximating the solution by using a GP regression model with label y_i = rank(x_i)=i. But this is systematically under-estimating the shape-variation, due to the fact that it adds the assumption that function values between ranks are equidistant. \n Is there any known approach how to do this?\n    submitted by    /u/Ulfgardleo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tywuga/d_bayesian_nonparametrics_for_ranking/",
          "publishedOn": "2022-04-08T06:03:54.000Z",
          "wordCount": 494,
          "title": "[D] Bayesian Non-Parametrics for Ranking?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tywmy0/r_video_diffusion_models/",
          "author": null,
          "description": "From the webpage:\n We present results on video generation using diffusion models. We propose an architecture for video diffusion models which is a natural extension of the standard image architecture. We show that this architecture is effective for jointly training from image and video data. To generate long and higher resolution videos we introduce a new conditioning technique that performs better than previously proposed methods. We present results on text-conditioned video generation and state-of-the-art results on an unconditional video generation benchmark.\n Paper: https://arxiv.org/abs/2204.03458\n https://video-diffusion.github.io/\n    submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tywmy0/r_video_diffusion_models/",
          "publishedOn": "2022-04-08T05:50:09.000Z",
          "wordCount": 205,
          "title": "[R] Video Diffusion Models",
          "imageUrl": "https://external-preview.redd.it/3oqkCt6VNVPKLWns6Tm8iCS8Ssrcd3AFU4klA6NCY8o.jpg?auto=webp&s=f509d332edc21fdb071d2bd7177e91a9b4cbd42e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyv2tu/d_how_to_decide_publication_venue/",
          "author": null,
          "description": "How to decide if a paper is appropriate for a specific venue? Moreover, how would you categorize the difference between a good NiPs publication and a good CvPR or ICCV publication?\n    submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyv2tu/d_how_to_decide_publication_venue/",
          "publishedOn": "2022-04-08T04:12:23.000Z",
          "wordCount": 216,
          "title": "[D] how to decide publication venue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyu1n6/n_lr_warmup_for_pytorch/",
          "author": null,
          "description": "​\n RadamWarmup + CosineAnnealingLR + StepLR\n Colab Link\n pytorch_warmup v0.1.0 was released.\n    submitted by    /u/TonyY_RIMCS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyu1n6/n_lr_warmup_for_pytorch/",
          "publishedOn": "2022-04-08T03:13:36.000Z",
          "wordCount": 98,
          "title": "[N] LR Warmup for PyTorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyo9qd/d_self_attention_visualization/",
          "author": null,
          "description": "Has anyone ever come across seemingly chaotic self attention maps during visualization. If your model is performing well but no insights can be gleaned from the visualization how do you explain it in a paper?\n    submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyo9qd/d_self_attention_visualization/",
          "publishedOn": "2022-04-07T22:13:00.000Z",
          "wordCount": 262,
          "title": "[D] self attention visualization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyn0yt/n_palms_googles_530b_llm_training_costs_around_9m/",
          "author": null,
          "description": "Here's the blogpost estimating the cost.\n What would it cost you to train PaLM using cloud computing (and you're not Google)? Something around $9M to $17M.\n    submitted by    /u/cirqe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyn0yt/n_palms_googles_530b_llm_training_costs_around_9m/",
          "publishedOn": "2022-04-07T21:14:22.000Z",
          "wordCount": 382,
          "title": "[N] PaLM's (Google's 530B LLM) training costs around $9M to $17M.",
          "imageUrl": "https://external-preview.redd.it/XV6Bw55gOCr7mrIMQ_xiFS365To1cJ6BcQQYprVY0iQ.jpg?auto=webp&s=2f3079fb965cc21e23397be43a0945248880c31e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tymu9e/d_feature_selection_methods/",
          "author": null,
          "description": "I'm working on a ML project and I'm working with a dataset with 20 columns, for feature selection I just removed one column one by one and looked at the error of the ML outputs for each, then saw when what column is removed gives a lower error and kept repeating that but that didn't seem to help the model at all and the error went down very little. Is this an okay way of doing feature selection is there another way that gives better results. I tried PCA and LDA and Pearson Correlation method as well in Python and that didn't seem to help or is this the best I could do. Thanks!\n    submitted by    /u/ihshosv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tymu9e/d_feature_selection_methods/",
          "publishedOn": "2022-04-07T21:05:46.000Z",
          "wordCount": 334,
          "title": "[D] Feature selection methods",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tykn7y/d_overfitting_a_sign_high_learning_capacity/",
          "author": null,
          "description": "This is a two part question:\n  \nIf a neural network can overfit the a large dataset is this a sign that a neural network has high learning capacity? \n If a neural network can overfit a dataset with substantially less parameters than other neural networks developed for the same learning task is this a sign that the neural network has a high learning capacity relative to other datasets?\n  \n   submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tykn7y/d_overfitting_a_sign_high_learning_capacity/",
          "publishedOn": "2022-04-07T19:24:50.000Z",
          "wordCount": 331,
          "title": "[D] Overfitting a sign high learning capacity?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyjj3z/d_training_cnn_with_synthetic_data_should_i_mix/",
          "author": null,
          "description": "I'm doing research on the use of synthetic data for a computer vision task and i have generally always tried to train in a mixed setting from scratch, but i have noticed that in similar papers, researchers always pretrain on synth first and then finetune on real data. Is there a logic behind that? Should i expect better results by finetuning?\n    submitted by    /u/TheManveru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyjj3z/d_training_cnn_with_synthetic_data_should_i_mix/",
          "publishedOn": "2022-04-07T18:34:01.000Z",
          "wordCount": 729,
          "title": "[D] training cnn with synthetic data. Should i mix synth and real and train from the scratch or pretrain the network with synth and finetune with real?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyhxl2/r_sampling_in_dirichlet_process_mixture_models/",
          "author": null,
          "description": "Hi Everyone,\n We have recently published the code for our AISTATS 2022 paper -\n Sampling in Dirichlet Process Mixture Models for Clustering Streaming Data\n ​\n Video Segmentation Example\n In our work, we have proposed a solution for clustering streaming data. Unlike 'standard' clustering scenarios, in the streaming case the data stream is possibly infinite, you cannot backtrack to previously processed points, and the data statistics are dynamic and change over time.\n Our solution is based on the Dirichlet Process Mixture Model (DPMM), can work with different types of observations, and is very fast, outperforming other methods both in the quality of the results and the speed with which it achieves them.\n It can even be distributed across several processes and/or machines!\n  \nPaper: https://dinarior.github.io/papers/Dinari_AISTATS_streaming.pdf\n Code (Julia Package): https://github.com/BGU-CS-VIL/DPMMSubClustersStreaming.jl\n Code (Python wrapper): https://github.com/BGU-CS-VIL/dpmmpythonStreaming\n Notebook (Julia) for creating the video: https://nbviewer.org/github/BGU-CS-VIL/DPMMSubClustersStreaming.jl/blob/main/examples/VideoSeg.ipynb\n  \n   submitted by    /u/dinarior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyhxl2/r_sampling_in_dirichlet_process_mixture_models/",
          "publishedOn": "2022-04-07T17:20:31.000Z",
          "wordCount": 424,
          "title": "[R] Sampling in Dirichlet Process Mixture Models for Clustering Streaming Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyfltn/d_best_way_to_handle_encoding_disconnected_graphs/",
          "author": null,
          "description": "I am thinking of building a graph classifier that takes in graphs and labels the incoming graph.\n The dataset of interest to me is RadGraph: https://arxiv.org/abs/2106.14463\n The issue I am having is that the graphs in RadGraph are disconnected in nature (on average 20 disconnected components), making it difficult for the various graph encoders I am aware of to do a good job classifying the graphs.\n    submitted by    /u/AICoderGamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyfltn/d_best_way_to_handle_encoding_disconnected_graphs/",
          "publishedOn": "2022-04-07T15:31:10.000Z",
          "wordCount": 174,
          "title": "[D] Best way to handle encoding disconnected graphs at the graph level.",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyfj7d/d_does_someone_know_how_much_faster_deepspeeds/",
          "author": null,
          "description": "Implementation here\n Looks like they manually calculate the gradient? I'm very curious how much of a difference this makes!\n    submitted by    /u/fasttosmile  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyfj7d/d_does_someone_know_how_much_faster_deepspeeds/",
          "publishedOn": "2022-04-07T15:27:53.000Z",
          "wordCount": 195,
          "title": "[D] Does someone know how much faster deepspeed's transformer implementation is?",
          "imageUrl": "https://external-preview.redd.it/tEPdTFlU-uawNZzkicwUlD9W5f2jMOt9Ho6WP7Zbh7M.jpg?auto=webp&s=f5e8d53aeee5139d4a8684ee18339cc5d0dfde18"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty8oi7/r_my_research_group_is_publicly_sharing_its_paper/",
          "author": null,
          "description": "https://outsystems-ai-reading-group.github.io/\n    submitted by    /u/JClub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty8oi7/r_my_research_group_is_publicly_sharing_its_paper/",
          "publishedOn": "2022-04-07T08:47:55.000Z",
          "wordCount": 118,
          "title": "[R] My research group is publicly sharing its paper presentations! Check it out!",
          "imageUrl": "https://external-preview.redd.it/okw9CoDOpAQ1q_mUTvkkFthoqq22j0xfreN13Amh1Rw.jpg?auto=webp&s=6f24b4084a5650db879165128873fd8d71d36b12"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty7h2p/r_onthefly_strategy_adaptation_for_adhoc_agent/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty7h2p/r_onthefly_strategy_adaptation_for_adhoc_agent/",
          "publishedOn": "2022-04-07T07:15:38.000Z",
          "wordCount": 99,
          "title": "[R] On-the-fly Strategy Adaptation for ad-hoc Agent Coordination",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty6hee/d_any_good_free_to_use_dalle_style_datasets/",
          "author": null,
          "description": "Are there any free to use datasets that contain image/annotation pairs in the style OpenAI used to train the DALL-E models? Pretty inspired by DALL-E 2 and think it would be cool to create a tiny less powerful replication\n    submitted by    /u/puppet_pals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty6hee/d_any_good_free_to_use_dalle_style_datasets/",
          "publishedOn": "2022-04-07T06:06:51.000Z",
          "wordCount": 163,
          "title": "[D] Any good free to use DALL-E style datasets?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty6g23/d_tensorflow_tfrange_vs_range/",
          "author": null,
          "description": "TLDR: TensorFlow AutoGraph unwraps native Python ranges, baking each value into the graph. This can be an unexpected cause of graph size explosion. \n This recently caused an issue in my project, so I thought I'd share some more details:\n https://lukewood.xyz/blog/to-unroll-or-to-not-unroll\n    submitted by    /u/puppet_pals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty6g23/d_tensorflow_tfrange_vs_range/",
          "publishedOn": "2022-04-07T06:04:17.000Z",
          "wordCount": 182,
          "title": "[D] TensorFlow tf.range() vs range()",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty4gw4/r_a_benchmarking_framework_for_timeseries/",
          "author": null,
          "description": "Our work \"AdaTime: A Systematic Evaluation of Domain Adaptation Algorithms on Time Series Data\" is now public. We provide a benchmarking framework named \"AdaTime\" to fairly evaluate Unsupervised domain adaptation (UDA) approaches on time-series data. We find that UDA approaches proposed for visual data can be directly applied to time-series data, and still achieve excellent performance, even better than methods specially proposed for time-series UDA. Se were impressed by the consistently superior performance of \"DIRT-T\" method on all the datasets. We provide the code publicly on github https://github.com/emadeldeen24/AdaTime\n    submitted by    /u/emad_eldeen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty4gw4/r_a_benchmarking_framework_for_timeseries/",
          "publishedOn": "2022-04-07T04:01:52.000Z",
          "wordCount": 189,
          "title": "[R] A benchmarking framework for time-series unsupervised domain adaptation",
          "imageUrl": "https://external-preview.redd.it/sPvr39oleAaAzL2Fx1s3W-hVlQLmkPCmIYm8DTQI1IE.jpg?auto=webp&s=d21d49a0c4335a7c16878c30293b7641634cb8cb"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty3w48/pr_announcing_dataset_denoising_shabby_pages/",
          "author": null,
          "description": "Into machine learning? Want a chance to earn a new MacBook Pro? Check out the Denoising ShabbyPages competition! The ShabbyPages dataset is being produced as a way to help train, test, and calibrate computer vision machine learning algorithms designed for working with documents. Enter the competition by training a model to remove the noise, and be awarded a MacBook Pro or some swag in the process! Check out the short paper introducing the dataset, and learn more about the competition at denoising-shabby.com.\n    submitted by    /u/proofconstruct  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty3w48/pr_announcing_dataset_denoising_shabby_pages/",
          "publishedOn": "2022-04-07T03:29:34.000Z",
          "wordCount": 180,
          "title": "[P][R] Announcing: Dataset & Denoising Shabby Pages Competition",
          "imageUrl": "https://external-preview.redd.it/3_5RF7j_Wg4iYno2Cpz3or2Md6GYBVeX1z8U_fyZIYE.jpg?auto=webp&s=2788014920175df6b4b456e2dcdb428445d0d887"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty3jae/r_facesigns_semifragile_neural_watermarks_for/",
          "author": null,
          "description": "Hi Everyone! \n We have released the preprint and google colab demo for our paper FaceSigns. FaceSigns embeds a secret bit-string as a semi-fragile watermark in the image pixels. The message is recoverable if benign image operations such as color/contrast adjustment, JPEG compression, Instagram filters are applied. However, the message cannot be decoded if the image is facially tampered (eg. DeepFake manipulation) . This selective fragility allows reliable detection of DeepFake manipulations applied on images signed using FaceSigns. \n Try out our google colab demo to see message encoding and decoding using FaceSigns!\n Paper: https://arxiv.org/abs/2204.01960\n Project Webpage: https://shehzeen.github.io/facesigns\n Demo: https://github.com/paarthneekhara/FaceSignsDemo\n    submitted by    /u/LynxCompetitive7637  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty3jae/r_facesigns_semifragile_neural_watermarks_for/",
          "publishedOn": "2022-04-07T03:09:27.000Z",
          "wordCount": 200,
          "title": "[R] FaceSigns: Semi-Fragile Neural Watermarks for Media Authentication and Countering Deepfakes",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty25fi/d_machine_learning_models_ideas_for_google_search/",
          "author": null,
          "description": "Hi guys!\n I work in house and I’m part of our Google search team. Our ad spend is pretty large (9 figures per year, in USD). We build/manage stuff at scale using SQL, R, Javascript, and so on. So everything is pretty much “big data” in flavour.\n Lately I’ve been more and more interested in data science, and I’m looking to take things to the next level by incorporating machine learning into our workflow. I’d really love to build some useful machine learning models using popular Python libraries such as Pandas, SciKit Learn, NumPy, TensorFlow, PyTorch, and so on.\n Any suggestions on cool, and most importantly useful machine learning models I could build? (By “useful”, I mean something that could help increase the profits.) I think some classification, predictive, or recommender models would be great to start with. Cheers! 😄\n    submitted by    /u/TropicalBound111  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty25fi/d_machine_learning_models_ideas_for_google_search/",
          "publishedOn": "2022-04-07T01:57:24.000Z",
          "wordCount": 568,
          "title": "[D] Machine learning models / ideas for Google search ads?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txy6il/r_using_gamma_distribution_to_improve_longtail/",
          "author": null,
          "description": "Predicting longtail events can be one of the more challenging ML tasks. Last year my team published a blog article where we improved DoorDash’s ETA predictions by 10% by tweaking the loss function with historical and real-time features. I thought members of the community would be interested in learning how we improved the model even more by using Gamma distribution-based inverse sampling approach to loss function tunning. Please check out the new article for all the technical details and let us know your feedback on our approach.\n https://doordash.engineering/2022/04/06/using-gamma-distribution-to-improve-long-tail-event-predictions/\n    submitted by    /u/pmp-dash1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txy6il/r_using_gamma_distribution_to_improve_longtail/",
          "publishedOn": "2022-04-06T22:34:20.000Z",
          "wordCount": 194,
          "title": "[R] Using Gamma Distribution to Improve Long-Tail Event Predictions at Doordash",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txvlf0/d_icml_author_response_what_reviewers_expect/",
          "author": null,
          "description": "Hi, we submitted to ICML for the first time. We got 4 reviews and 3 of them are mostly positive. Major comments by the reviewers include: more justification on the assumptions, discussion on choices of parameters, and experiments in more complex and different environments. \n We want to address all the major and minor comments as best as we can but given that the response is limited to one page we cannot explain everything in detail. I am not sure what is the acceptable norm here. Do reviewers expect the authors to conduct some experiments during the rebuttal and provide sample results or just explain what additional experiment we will conduct and how we will do it. Justification and reasoning should be in details or a brief explanation with an assurance to add a detailed discussion in the final version suffices.\n TIA\n    submitted by    /u/srvsinha186  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txvlf0/d_icml_author_response_what_reviewers_expect/",
          "publishedOn": "2022-04-06T20:36:00.000Z",
          "wordCount": 234,
          "title": "[D] ICML author response. What reviewers expect.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txvky1/d_questions_for_a_tpm_for_ml_interview_at_google/",
          "author": null,
          "description": "Hey all,\n I have a technical program manager interview soon for an ML team at google and I want to know if anyone has any sample role-related questions I can gauge myself with.\n I have a strong data science & statistics background but that doesn't always translate to deep ML knowledge like an ML Engineer might have.\n Any resources or sample questions? I have not found adequate results from google regarding this team area specifically.\n    submitted by    /u/math_is_my_religion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txvky1/d_questions_for_a_tpm_for_ml_interview_at_google/",
          "publishedOn": "2022-04-06T20:35:25.000Z",
          "wordCount": 176,
          "title": "[D] Questions for a TPM for ML interview at Google",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txv5o3/d_anyone_knows_any_high_accuracy_models_on_uci/",
          "author": null,
          "description": "Hi everyone. This is my first-time post here, and I hope I did not break any sub rules.\n Currently, I am doing some research with the UCI Adult dataset(https://archive.ics.uci.edu/ml/datasets/adult). This first step is to build a high-accuracy classifier model. \n Does anyone know any high accuracy model on this dataset (more than 90%)? I use many machine learning models like logistic regression and neural network. But no matter how complex the model is, I can only get an accuracy of about 85% on the test set. I tried to google but I found many others also have similar results of about 85%.\n Any posts or papers will be helpful! Thanks in advance for your help!\n    submitted by    /u/Akasakura888  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txv5o3/d_anyone_knows_any_high_accuracy_models_on_uci/",
          "publishedOn": "2022-04-06T20:16:14.000Z",
          "wordCount": 218,
          "title": "[D] Anyone knows any high accuracy models on UCI adult dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txtp5u/r_using_gamma_distribution_to_improve_longtail/",
          "author": null,
          "description": "Predicting longtail events can be one of the more challenging ML tasks. Last year my team published a blog article where we improved DoorDash’s ETA predictions by 10% by tweaking the loss function with historical and real-time features. I thought members of the community would be interested in learning how we improved the model even more by using Gamma distribution-based inverse sampling approach to loss function tuning. Please check out the new article for all the technical details and let us know your feedback on our approach.\n ​\n https://doordash.engineering/2022/04/06/using-gamma-distribution-to-improve-long-tail-event-predictions/\n    submitted by    /u/pmp-dash1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txtp5u/r_using_gamma_distribution_to_improve_longtail/",
          "publishedOn": "2022-04-06T19:10:10.000Z",
          "wordCount": 188,
          "title": "[R] Using Gamma Distribution to Improve Long-Tail Event Predictions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txth9e/d_reading_the_tea_leaves_expert_endusers/",
          "author": null,
          "description": "Hey there, just a heads up we at The Gradient just published a new article discussing explainability - \n  \n\"This article uses the common backdrop of competitive games to explore the ways in which domain experts adapt to new technologies that lack explainability. I illustrate how interpretations vary based on user experience and model architecture, and how special care must be taken when adapting models to human-centric problems.\"\n  \nCheck it out here if you think it's interesting / worth discussing:\n Reading the Tea Leaves: Expert End-Users Explaining the Unexplainable\n    submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txth9e/d_reading_the_tea_leaves_expert_endusers/",
          "publishedOn": "2022-04-06T19:00:19.000Z",
          "wordCount": 189,
          "title": "[D] Reading the Tea Leaves: Expert End-Users Explaining the Unexplainable",
          "imageUrl": "https://external-preview.redd.it/wnVaar4ZXR3zqeMsXegEzJEPVdp1PkLFsHJagJ249DM.jpg?auto=webp&s=53c299a85d48eb7bedf6e5ec47ca846a5c52c38f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txqkin/project_learning_to_play_settlers_of_catan_with/",
          "author": null,
          "description": "Hi all,\n I just wanted to share a project I've been working on for the past year - using deep RL to learn to play the board game Settlers of Catan.\n I expect everyone is aware of the results that DeepMind/OpenAI have got recently on Go, DOTA 2, Starcraft 2 etc, but I was motivated to see how much progress could be made with existing RL techniques on a reasonably complex game - but with access to significantly less computational resources.\n Whilst I didn't end up with an agent that performs at a super-human level, there was clear learning progress and the results were quite interesting. I decided to do a full write-up of the project here, which I figured could be useful for anyone else who is interested in trying to apply DRL to a new, complicated environment. I also open-sourced all the code here for anyone interested.\n If anyone has any feedback or any questions at all that'd be great!\n    submitted by    /u/henrythepaw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txqkin/project_learning_to_play_settlers_of_catan_with/",
          "publishedOn": "2022-04-06T16:49:47.000Z",
          "wordCount": 952,
          "title": "[Project] Learning to Play \"Settlers of Catan\" With Deep RL - Writeup and Code",
          "imageUrl": "https://external-preview.redd.it/MCy14opBjTIKzwl5JN-l_h8ogp8jGD7JGmk-A4mmZJI.jpg?auto=webp&s=b34f246a1d389b97fb2013f3661ccf8afbf4403e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txqapw/d_icml_rebuttals_optional_or_semimandatory/",
          "author": null,
          "description": "Hi,\n We just submitted to ICML 2022 and got our reviews back. We were excited to see that 4/4 reviews were positive and acknowledged the contribution of the paper. However, there were some minor criticisms (e.g. didn't do good enough lit reviews, could use a few more experiments) across several reviews.\n I was wondering if it is ever acceptable to not submit a rebuttal? Can a rebuttal in this case actually hurt us by rocking the boat---or for ICML is the norm that you should always submit a rebuttal that addresses all the reviewers' criticisms.\n We were wondering what the norm is for ICML specifically?\n    submitted by    /u/optimistic313  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txqapw/d_icml_rebuttals_optional_or_semimandatory/",
          "publishedOn": "2022-04-06T16:37:16.000Z",
          "wordCount": 335,
          "title": "[D] ICML rebuttals optional or semi-mandatory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txples/r_hierarchical_textconditional_image_generation/",
          "author": null,
          "description": "Blog post.\n Paper (pdf file format). The paper is also linked to in the above blog post.\n Abstract\n  \nContrastive models like CLIP have been shown to learn robust representations of images that capture both semantics and style. To leverage these representations for image generation, we propose a two-stage model: a prior that generates a CLIP image embedding given a text caption, and a decoder that generates an image conditioned on the image embedding. We show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity. Our decoders conditioned on image representations can also produce variations of an image that preserve both its semantics and style, while varying the non-essential details absent from the image representation. We use diffusion models for the decoder and experiment with both autoregressive and diffusion models for the prior, finding that the latter are computationally more efficient and produce higher-quality samples.\n  \nOpenAI's Sam Altman used DALL-E 2 to generate ~20 text prompt requests from Twitter users. The results are here, with individual result links and other samples in this comment from another Reddit user in a different post.\n Twitter thread about the paper (not from the paper authors).\n Sam Altman's blog post about DALL-E 2.\n  \nHopefully this summer, we’ll do a product launch and people will be able to use it for all sorts of things.\n  \n   submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txples/r_hierarchical_textconditional_image_generation/",
          "publishedOn": "2022-04-06T16:04:57.000Z",
          "wordCount": 773,
          "title": "[R] Hierarchical Text-Conditional Image Generation with CLIP Latents. This is the paper for OpenAI's DALL-E 2",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txm40w/is_the_first_boss_attempt_phenomenon_know_to/",
          "author": null,
          "description": "I'm curious about wether this unusual learning trajectory observed in humans has also been observed in artificial neural nets. A well known phenomenon in the 'dark souls' video game series is that ones first attempt at a boss is often much better than subsequent attempts. Boss hp at time of death by attempt might go something like: 35%, 55%, 85%, 87%, 75%, 54%, , 60%, 43%, 27%, 38%, 12%, 0%. This sounds very anecdotal, but its know to the community of these games to be a real thing. See this thread for evidence. Have NN playing games been known to exhibit a similar pattern, with peak in success early on, followed by a step descent , then a slow gradual climb? Or is this a purely human phenomenon?\n My hypothesis as to why this happens is that over the course of the first couple attempts, the player learns a bunch of bad strategies which must be slowly unlearned, whereas on attempt one, the player has no defined strategies good or bad.\n    submitted by    /u/Greenface1998  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txm40w/is_the_first_boss_attempt_phenomenon_know_to/",
          "publishedOn": "2022-04-06T13:24:35.000Z",
          "wordCount": 888,
          "title": "Is the 'first boss attempt' phenomenon know to occur amongst NN playing games, or is this learning trajectory unique to human players?[D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txktli/r_disentangling_abstraction_from_statistical/",
          "author": null,
          "description": "submitted by    /u/papajan18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txktli/r_disentangling_abstraction_from_statistical/",
          "publishedOn": "2022-04-06T12:16:57.000Z",
          "wordCount": 116,
          "title": "[R] Disentangling Abstraction from Statistical Pattern Matching in Human and Machine Learning",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txkl43/projectp_who_invented_graph_neural_networks/",
          "author": null,
          "description": "Just a side project (only for me) in which I try to sum up some history of DL. Can't be 100% sure this is the first article in which they appear: Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., & Monfardini, G. (2008). The graph neural network model. IEEE transactions on neural networks, 20(1), 61-80. Would appreciate any help. Thanks\n    submitted by    /u/Siddh__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txkl43/projectp_who_invented_graph_neural_networks/",
          "publishedOn": "2022-04-06T12:03:35.000Z",
          "wordCount": 633,
          "title": "[Project][P] Who invented Graph Neural Networks?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txkh8m/r_gpbart_a_novel_bayesian_additive_regression/",
          "author": null,
          "description": "(not my paper)\n paper: https://arxiv.org/abs/2204.02112\n abstract: \"The Bayesian additive regression trees (BART) model is an ensemble method extensively and successfully used in regression tasks due to its consistently strong predictive performance and its ability to quantify uncertainty. BART combines \"weak\" tree models through a set of shrinkage priors, whereby each tree explains a small portion of the variability in the data. However, the lack of smoothness and the absence of a covariance structure over the observations in standard BART can yield poor performance in cases where such assumptions would be necessary. We propose Gaussian processes Bayesian additive regression trees (GP-BART) as an extension of BART which assumes Gaussian process (GP) priors for the predictions of each terminal node among all trees. We illustrate our model on simulated and real data and compare its performance to traditional modelling approaches, outperforming them in many scenarios. An implementation of our method is available in the \\textsf{R} package \\texttt{rGPBART} available at: https://github.com/MateusMaiaDS/gpbart.\"\n    submitted by    /u/bikeskata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txkh8m/r_gpbart_a_novel_bayesian_additive_regression/",
          "publishedOn": "2022-04-06T11:57:53.000Z",
          "wordCount": 468,
          "title": "[R] GP-BART: a novel Bayesian additive regression trees approach using Gaussian processes",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txijls/d_anyone_know_about_any_interesting_recent/",
          "author": null,
          "description": "I’m currently writing a research paper for my MSc on neuromorphic sensing and spike neural networks and most good papers are from around 2015 and was looking for something more recent.\n Anyone here heard of any interesting upgrades in architecture or applications?\n Cheers!\n    submitted by    /u/GandhisLittleHelper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txijls/d_anyone_know_about_any_interesting_recent/",
          "publishedOn": "2022-04-06T09:54:31.000Z",
          "wordCount": 145,
          "title": "[D] Anyone know about any interesting recent improvements with SNNs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txha3z/noticing_that_profs_focus_on_male_students_goals/",
          "author": null,
          "description": "Hello, I’m currently a graduate student. I do different projects and for some I get to decide on what I want the scope to be. I do have to get the scope/ plan/ idea approved first. I pitch my ideas to profs who aren’t directly my profs and normally 5-6 other students will pitch ideas to the same group of profs at the same time….. I noticed that i get really different questions and feedback in comparison to my peers. I’m a female and my peers are male… I didn’t start out with this outlook but I’m starting to search for reasons why I often get questioned about my capabilities to preform a project ( which is normal enough but I get questioned to the point where explaining my approach isn’t enough and they ask me for examples of codes) and my peers definitely do not get asked about there capabilities, rather they tell them what they can do and they don’t get questioned. …………… really frustrating.\n    submitted by    /u/tyger-lily  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txha3z/noticing_that_profs_focus_on_male_students_goals/",
          "publishedOn": "2022-04-06T08:19:25.000Z",
          "wordCount": 1258,
          "title": "Noticing that profs focus on male student’s goals and female student’s capabilities, any weigh-in? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txgmti/d_how_to_write_a_mlhealthcare_paper_where_the/",
          "author": null,
          "description": "As a project in the course of my PhD, I had to create a prototype for a project. My PhD is application of machine learning in health care. The project definition and scope was faaaar too wide. However, I managed to create a working demo which encompasses some use cases of the project. At best, it can be called a framework, where I have put in different DL components and it works okay for those use cases only. Most of the components, I have used are pre-trained language models (maybe fine tuned them to my use case). However, there is no active training or learning involved. This is because I created this for a demo only. I also created a very small dataset and tested the framework over the dataset and the results were ok. However, my supervisor now wants me to write a paper, as he is confident, that the use case is rather unique and my working framework is a good first step. I believe, his aim is to get me started on the paper writing process, which I appreciate. However, I am not confident about it at all.\n My question is, can a 'framework' composed of pre-trained models with the end goal of solving a problem in health care is good enough? Are there precedents of any such paper? And if I trust my supervisor's instincts, are there any fancy ways to frame the framework so that it does not look so basic?\n    submitted by    /u/Complex_State9960  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txgmti/d_how_to_write_a_mlhealthcare_paper_where_the/",
          "publishedOn": "2022-04-06T07:30:09.000Z",
          "wordCount": 556,
          "title": "[D] How to write a ML+Healthcare paper where the research was a framework with pre-trained models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txfq52/p_building_a_knowledge_based_recommender_system/",
          "author": null,
          "description": "I am trying to build a knowledge based recommender system but do not have prior knowledge. \n We first take in user inputs such as occasion, weather, top wear and bottom wear, color. Based on this we want to create a knowledge base and recommend clothes. \n Can anyone help me on how to go about on doing this process step by step and what algorithms and technology to be used?\n    submitted by    /u/bills70  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txfq52/p_building_a_knowledge_based_recommender_system/",
          "publishedOn": "2022-04-06T06:26:17.000Z",
          "wordCount": 162,
          "title": "[P] Building a knowledge based recommender system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txdhxt/d_icml_2022_paper_reviews/",
          "author": null,
          "description": "ICML 2022 paper reviews are supposed to be released soon. Creating a discussion thread for this year's reviews.\n    submitted by    /u/zy415  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txdhxt/d_icml_2022_paper_reviews/",
          "publishedOn": "2022-04-06T04:06:11.000Z",
          "wordCount": 657,
          "title": "[D] ICML 2022 Paper Reviews",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txbyy7/d_in_general_should_you_let_the_model_find/",
          "author": null,
          "description": "I’ll give an example to better explain my question (don’t get hung up on the numbers, it’s all made up). Say you are using a tree based model trying to project how many points a player will score in a given basketball game.\n Most players shoot free throws at a slightly lower percentage on the road, than they do at home. However, the magnitude varies player to player. Let’s assume for 95% of players with significant data, the ratio of home free throw percentage to away is 1 to 1.15. Generally speaking, older players are closer to 1 and younger players are around 1.1 (since older players get used to the opposing crowd).\n Now also say it takes 100 home and 100 away free throws to get a stable reliable ratio.\n Now say a young player only has 50 home, and 50 away free throws. With this amount of data he has a ratio of 1, however the sample size is not enough to be fully stable.\n Which would be better…\n 5 features into this model, his home away ratio, average ratio for players his age, home free throw count, and away free throw attempts.\n 1 feature. His ‘projected’ home away ratio, which is a weighted average of his ratio with the average for plaeyrs his age. Since he’s 50% of the way to significance, 0.5 * 1 + 0.5 * 1.1 = 1.05\n The benefit of the of the first choice is that it may find other interactions that I never conceived of, however, it could incorporate noise. Is there a general consensus, or is this just a try both and see what works?\n    submitted by    /u/irndk10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txbyy7/d_in_general_should_you_let_the_model_find/",
          "publishedOn": "2022-04-06T02:41:45.000Z",
          "wordCount": 1317,
          "title": "[D] In general, should you let the model find interactions between many basic features, or should you use feature engineering to ‘help’ the model find the interaction?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx7e34/d_why_arent_new_llms_using_the_perceiver/",
          "author": null,
          "description": "Perceiver and PerceiverIO (https://arxiv.org/abs/2107.14795) appear to offer significantly improved FLOP efficiency, but new LLMs (including Deepmind's own Gopher) don't use it.\n What gives? Is it still too new, or is the Perceiver architecture not appropriate for LLMs?\n    submitted by    /u/deeceeo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx7e34/d_why_arent_new_llms_using_the_perceiver/",
          "publishedOn": "2022-04-05T22:48:26.000Z",
          "wordCount": 137,
          "title": "[D] Why aren't new LLMs using the Perceiver architecture?",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx59tj/r_metalearning_machines_in_a_single_lifelong/",
          "author": null,
          "description": "Saw this posted on Schmidhuber's Twitter:\n Meta-Learning Machines in a Single Lifelong Trial: lecture video (24 min) presented at meta-learning workshops at ICML 2020 and NeurIPS 2021. URL of talk: https://youtu.be/2GgGVdkq2bU\n Abstract\n The most widely used machine learning algorithms were designed by humans and thus are hindered by our cognitive biases and limitations. Can we also construct meta-learning algorithms that can learn better learning algorithms so that our self-improving AIs have no limits other than those inherited from computability and physics? This question has been a main driver of my research since I wrote a thesis on it in 1987. In the past decade, it has become a driver of many other people's research as well. Here I summarize our work starting in 1994 on meta-reinforcement learning with self-modifying policies in a single lifelong trial, and - since 2003 - mathematically optimal meta-learning through the self-referential Gödel Machine. This talk was previously presented at meta-learning workshops at ICML 2020 and NeurIPS 2021. Many additional publications on meta-learning can be found at https://people.idsia.ch/~juergen/metalearning.html\n    submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx59tj/r_metalearning_machines_in_a_single_lifelong/",
          "publishedOn": "2022-04-05T21:11:28.000Z",
          "wordCount": 318,
          "title": "[R] Meta-Learning Machines in a Single Lifelong Trial: lecture video (24 min) presented at meta-learning workshops at ICML 2020 and NeurIPS 2021 (Schmidhuber YouTube Talk)",
          "imageUrl": "https://external-preview.redd.it/vi10fYGumGdDuKtmrgIT6Ts5ESncbLCIuBXVAMdVDLw.jpg?auto=webp&s=91df7b5da1afb82cc84b2707d6c5641d50b8959b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx42h9/d_hyperparameter_tuning_does_it_even_work/",
          "author": null,
          "description": "Hi *,\n I've been working for the last 5 years as Data Scientist. During this time I have tried dozens of times to improve my models via hyperparameter tuning, but I've never got improvements from there. I've tried all the possible approaches: grid search, random search, bayesian search, etc. But in no case did I get satisfactory results.\n Does this happen to anyone else? Have you ever got robust improvements via HP tuning?\n    submitted by    /u/AM_DS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx42h9/d_hyperparameter_tuning_does_it_even_work/",
          "publishedOn": "2022-04-05T20:19:19.000Z",
          "wordCount": 291,
          "title": "[D] Hyperparameter Tuning: does it even work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx3f5g/d_autoregressive_model_for_graph_generation/",
          "author": null,
          "description": "Autoregressive models like GPT-2 do fairly well in text generation. Is it possible to do the same for graph data? A transformer based model Graphormer has recently shown its effectiveness in graph representation learning. Is there any way I can train Graphormer or any other model to generate graphs from an initial graph context?\n    submitted by    /u/ratt_m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx3f5g/d_autoregressive_model_for_graph_generation/",
          "publishedOn": "2022-04-05T19:51:08.000Z",
          "wordCount": 146,
          "title": "[D] Autoregressive model for graph generation?",
          "imageUrl": "https://external-preview.redd.it/eoBMYj_duATkDQ_aqqR_eU3Icw0zdJNAY3EmrOgWvT8.jpg?auto=webp&s=710b35efc10fa9f6ffadea65f77fe714c87184c5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx1bjv/d_how_do_you_guys_hear_about_the_latest_papers/",
          "author": null,
          "description": "Hi! I'm a first-year Grad Student in Computer Vision and I am trying to get caught up on the latest research in my field. It seems like everyone in CS has heard about all of the latest papers but I just have no idea how. My knowledge is limited to general ideas and doesn't know any specific papers unless they have like 20000+ citations.\n So my question is: how do you hear about these papers and get caught up? Is there a reference somewhere that puts together a list of all the \"must-read\" papers that have come out? I feel like I am already 5 years behind in my knowledge. It would be great if there was something like \"Top 5 papers of the week\" that I could read to stay on top of things.\n Also, this doesn't just apply to Vision. I would like to have an idea of the other major developments in other fields (like NLP, general ML/DL, etc.) since I think that can carry over to my field.\n Thanks! Looking forward to your replies\n    submitted by    /u/TobusFire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx1bjv/d_how_do_you_guys_hear_about_the_latest_papers/",
          "publishedOn": "2022-04-05T18:18:42.000Z",
          "wordCount": 709,
          "title": "[D] How do you guys hear about the latest papers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx0z89/d_fake_authors_and_paper_riders/",
          "author": null,
          "description": "Based on my experiences in both academia and industry, I see that many researchers get listed as authors on papers solely for having attended the relevant project meetings, despite not contributing anything substantial to the work. I know of several people who've gotten on dozens of papers this way, despite not being able to explain the main details behind many of the papers they \"co-authored.\" Of course, they can then claim credit for the work publicly as well as have their academic profile benefit from the citations accrued by the work.\n I've noticed that typically, these people are initially invited onto the project because they are on chummy terms with someone on the project. Concerningly, the more someone successfully \"paper-rides\" this way, the stronger their publication record looks, which makes it easier for them to find their way onto more projects to paper ride in the future.\n It seems that the obsessive focus on paper counts and citations has encouraged the rise of intellectually dishonest strategies for maximizing one's academic footprint. The huge research scientist salaries at top industry labs, which similarly obsess over paper counts and citations in their hiring process, only amplifies the incentive for paper riding.\n The reason I think it is bad: As more people paper ride, co-authorship on a paper gradually becomes a worse indication of expertise. Not to mention, paper riders are intellectually dishonest, by claiming credit for research that they didn't significantly contribute to. In a sense, it seems like a roundabout form of plagiarism.\n I know some might disagree with this take, as some people believe in being as generous about co-authorship as possible. I find that mindset to create the perfect environment for paper riders to flourish. I'm wondering if you've also seen paper riding happen and whether you think this behavior is good or bad.\n    submitted by    /u/alwayshumming  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx0z89/d_fake_authors_and_paper_riders/",
          "publishedOn": "2022-04-05T18:03:17.000Z",
          "wordCount": 2044,
          "title": "[D] Fake authors and paper riders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twzqsk/dr_generate_random_sample_for_exponentiated/",
          "author": null,
          "description": "Hi there experts, I have a real distribution for which I had run this scipy script to detect the best fit:\n However, the script outputs 4 parameter values and the best fit is actually a Exponentiated Weibull distribution.\n Now I am clueless how to generate a sample list of data of n-size. I know for sure about the normal distribution after getting these params as mean and sigma. How to I generate such list. Please help.\n ​\n ​\n https://preview.redd.it/79n28icmsqr81.png?width=1141&format=png&auto=webp&s=d9478691c06f5cdfe03af4f82db8293443e91f1e\n    submitted by    /u/GoldenDew9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twzqsk/dr_generate_random_sample_for_exponentiated/",
          "publishedOn": "2022-04-05T17:06:57.000Z",
          "wordCount": 172,
          "title": "[D][R] Generate random sample for exponentiated Weibull distribution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twznq8/rd_vae_embedding_space_can_we_force_it_to_learn_a/",
          "author": null,
          "description": "I understand that certain AE types such as B-VAE disentangle certain aspects of variation in the data, and those such as Conditional AE or VAE allow us to separate these aspects with labels.\n However, what I have seen is that the embedding space doesn't cluster the images as well as some contrastive methods. However contrastive methods require non-elegant negative sampling etc. \n Can we somehow force the VAE to learn both the variational lower bound as well as learn a good metric between samples such as visually similar samples are better clustered together?\n    submitted by    /u/jim_from_truckistan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twznq8/rd_vae_embedding_space_can_we_force_it_to_learn_a/",
          "publishedOn": "2022-04-05T17:03:16.000Z",
          "wordCount": 203,
          "title": "[R][D] VAE Embedding Space - Can we force it to learn a metric?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twylnl/d_jetson_agx_orin_dev_kit_as_a_standalone/",
          "author": null,
          "description": "The Jetson Orin 64gb model has \"275 Sparse|138 Dense INT8 TOPS\", and I am a little confused about how to compare this to something like the RTX a6000's performance. I am looking to do deep rl training and am new to the field. What metrics make a difference for deep rl? Any thoughts on the Orin dev kit's ability to train deep rl?\n    submitted by    /u/here_to_create  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twylnl/d_jetson_agx_orin_dev_kit_as_a_standalone/",
          "publishedOn": "2022-04-05T16:14:45.000Z",
          "wordCount": 206,
          "title": "[D] Jetson AGX Orin dev kit as a stand-alone training platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twxmk9/d_with_the_rise_of_automl_what_are_the_important/",
          "author": null,
          "description": "Some time down the road, when AutoML becomes more established, it can help us determine the best ML model and hyperparameters for a particular problem. This will not replace data scientist, as we still need data scientists for their domain knowledge, which is critical for scoping business problems, pre-processing data, and deriving business insights from the trained model. However, since data scientists no longer need to deal with the technicalities of a model in the near future (i.e. they no longer have to tune hyperparameters, determine the best opitmistion function etc), is there still a need for aspiring data scientists to learn about the intricacies and nuances behind the various models (maybe by coding the model from scratch)? Or is it enough for them to learn how to operate an AutoML system? (My question is referring to the corporate world in general and not to academia) Thanks in advance for your answers :)\n    submitted by    /u/smart_oinker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twxmk9/d_with_the_rise_of_automl_what_are_the_important/",
          "publishedOn": "2022-04-05T15:30:36.000Z",
          "wordCount": 2045,
          "title": "[D] With the rise of AutoML, what are the important skills for a ML career?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twu1z5/p_automlconf_competition_dac4automl/",
          "author": null,
          "description": "Hi everyone!\n We've just launched a competition at the AutoML-Conf 2022, the DAC4AutoML competition. It has two tracks, one for configuring a Computer Vision model and one for a RL pipeline: https://automl.github.io/dac4automlcomp/ \n And what is DAC exactly? It means we want to find well-performing hyperparameter configurations like in Algorithm Configuration, but we do it dynamically - thus DAC, Dynamic Algorithm Configuration. As to how that is supposed to happen? We don't put any restrictions on the solutions for the competitions, so you can submit your hand-tuned static hyperparameter setting if you want. Or you can use some sort of heuristic, a regression model, reinforcement learning, ... whatever works. \n If you're interested in participating, you can submit from now on until the 18.06. AOE, the winners will be announced at the AutoML-Conf.\n    submitted by    /u/catsortion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twu1z5/p_automlconf_competition_dac4automl/",
          "publishedOn": "2022-04-05T12:42:17.000Z",
          "wordCount": 320,
          "title": "[P] AutoML-Conf Competition: DAC4AutoML",
          "imageUrl": "https://external-preview.redd.it/hwN3EBf7WXi3MEvXiPgqOQzZmfA3yEU8ZOPYIry-WJw.jpg?auto=webp&s=e08b4e79f3d8a80bcf43263d687e29f7665b1ad1"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twtg6d/d_imagenet_original_pictures/",
          "author": null,
          "description": "As I understood it Imagenet got generated from internet images, but I am unable to to find the originals using naive image search. Is there any mapping? I wonder if imagenet data is a cropped versions of original pictures or not, i don't see it in the paper.\n    submitted by    /u/LeanderKu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twtg6d/d_imagenet_original_pictures/",
          "publishedOn": "2022-04-05T12:07:50.000Z",
          "wordCount": 222,
          "title": "[D] Imagenet Original Pictures",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twt98b/p_ufo_lands_on_highway_or_depth_estimation_using/",
          "author": null,
          "description": "Article describing depth estimation using machine learning models and 3D visualization of depth maps using three.js.\n https://www.storminthecastle.com/posts/ufos_and_depth/\n    submitted by    /u/CakeStandard3577  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twt98b/p_ufo_lands_on_highway_or_depth_estimation_using/",
          "publishedOn": "2022-04-05T11:57:51.000Z",
          "wordCount": 120,
          "title": "[P] UFO Lands on Highway! Or Depth Estimation using ML",
          "imageUrl": "https://external-preview.redd.it/EYCpGAaDtOBH3R2hcX5A8p4nQUaWGRn3Vhhp-gVnshg.jpg?auto=webp&s=73ce7b6d98e380ab00fbb89bc361e6c1054e477f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twspe4/d_could_styleganxl_be_great_for_outofdomain/",
          "author": null,
          "description": "In the context of text-to-image generation, I'd say one of the reasons VQGAN is so used in popular notebooks is that it can deal with many concepts, while stylegan used to be limited to the domain it was trained for. \n That may be about to change with the rollout release of Stylegan-XL weights trained on Imagenet. This notebook (https://github.com/CasualGANPapers/StyleGANXL-CLIP) has had nice results with objects never seen by the model, such as \"apple\" and \"ant\", as well as scenes such as \"judo athletes fighting\"\n Please note that the Stylegan-XL weights are currently available for 128x128 pixels. ETA for the 256 resolution is 14.04.22\n    submitted by    /u/HrodRuck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twspe4/d_could_styleganxl_be_great_for_outofdomain/",
          "publishedOn": "2022-04-05T11:25:38.000Z",
          "wordCount": 222,
          "title": "[D] Could Stylegan-XL be great for out-of-domain generation?",
          "imageUrl": "https://external-preview.redd.it/ZKt6uousVLNiB0ssq6GUS-K_Hr81UD28U8l9oMEB5Hw.jpg?auto=webp&s=e8d1d8a82b656126d33e6d703410f037e33552e1"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twqel5/discussion_support_vector_machines_in_2022/",
          "author": null,
          "description": "My post is inspired by this discussion.\n In that thread, OP asked why support vector machines are still taught. People offered several thoughts: they're easier to think about, they're still perfectly good for some real-world problems, and for some problems they apparently rival deep networks.\n I did a project for a class around six years ago using an SVM as implemented in scikit-learn. I was pretty satisfied with the project, but I also experienced some frustrations, and came away with some questions. I started working with Tensorflow and DNNs in earnest soon after finishing that project, and I largely stopped thinking about SVM. I would like to revive the questions I asked, but never answered, here.\n  \nA DNN with multiple outputs can potentially use a single neuron in the prediction of more than one output. For multiple, mutually-exclusive categories, this makes good sense. An SVM with multiple outputs in scikit-learn was implemented as pairs of one-vs-one SVMs, each of which was independently fit to data. This gets inefficient quickly. Has this changed? Can it be changed?\n DNN training at scale is a problem that many people have worked hard to make practical. Even non-experts like myself use our home GPUs to accelerate training of DNNs on large data sets. In scikit-learn, SVM training was implemented in a single thread on one CPU core. If you are performing cross-validation or a hyperparameter optimization study, it might be practical to parallelize fitting; one thread for each distinct condition. But can you parallelize the SVM fitting algorithm for a single condition? I went looking for software, but I couldn't find anything.\n  \nOver to you folks. Cheers.\n    submitted by    /u/aotus_trivirgatus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twqel5/discussion_support_vector_machines_in_2022/",
          "publishedOn": "2022-04-05T08:46:32.000Z",
          "wordCount": 1715,
          "title": "[Discussion] Support Vector Machines... in 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twqeei/r_restormer_efficient_transformer_for/",
          "author": null,
          "description": "​\n Visual Results\n With Restormer, you can remove noise, motion blur, defocus blur, and rain streaks from your own images.\n Paper: https://arxiv.org/abs/2111.09881\n Github: https://github.com/swz30/Restormer\n Colab Demo: https://colab.research.google.com/drive/1C2818h7KnjNv4R1sabe14_AYL7lWhmu6?usp=sharing\n Gradio Web Demo: https://huggingface.co/spaces/swzamir/Restormer\n    submitted by    /u/swz30  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twqeei/r_restormer_efficient_transformer_for/",
          "publishedOn": "2022-04-05T08:46:08.000Z",
          "wordCount": 166,
          "title": "[R] Restormer: Efficient Transformer for High-Resolution Image Restoration (CVPR 2022--ORAL) + Colab Demo + Gradio Web Demo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twmnol/r_d_seq2seq_model_hyperparameters_tuning/",
          "author": null,
          "description": "Does anyone have any advices or research papers on what hyperparameters do researchers use for their seq2seq model? \n I am interested in knowing whether hyperparameters such as dropout, or recurrent dropout, batchnorm, etc etc, are even necessary in the usage of seq2seq model, but couldn’t find anything on it for weeks.\n In the case, let’s say, using gridsearchCV, what hyperparameters do you tweak for ur seq2seq model? (Other than the usual stuff like number of neurons, etc). There is absolutely zero information for that on seq2seq model, and everyone just assumes that putting an attention mechanism solves everything without hyperparameters tunings. I have also looked up on codes on seq2seq, and no hyperparameters tunings were shown whatsoever. \n FYI, this is in the context of time series data, using seq2seq, if that matters.\n Thanks\n    submitted by    /u/plsendfast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twmnol/r_d_seq2seq_model_hyperparameters_tuning/",
          "publishedOn": "2022-04-05T04:32:59.000Z",
          "wordCount": 318,
          "title": "[R] [D] Seq2seq model hyperparameters tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twmfom/d_has_anyone_seen_any_papers_related_to_gans/",
          "author": null,
          "description": "I’ve been reading many papers lately pertaining to GANs, with more and more introducing supervised loss into the generator’s objective function. However, no one ever seems to show that the optimum remains undisturbed. Results seem to be strictly empirical most of the time. \n Has anyone seen any papers where it is shown that the disruption to the generator’s loss doesn’t harm convergence?\n    submitted by    /u/king_of_walrus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twmfom/d_has_anyone_seen_any_papers_related_to_gans/",
          "publishedOn": "2022-04-05T04:19:49.000Z",
          "wordCount": 291,
          "title": "[D] Has anyone seen any papers related to GANs which prove that the optimum remains unchanged when adding supervised loss (e.g. L1, L2)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twidsn/d_what_is_your_experience_with_fake_results_or/",
          "author": null,
          "description": "I am curious what is everyones experience with completely faked, falsified, or fabricated results in the area? Another aspect of this I think is people taking heavily overfitted results and finding one decent example that is from the test set and claiming their method is awesome. How much of this have you seen and how much of the research out there fits into this category?\n    submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twidsn/d_what_is_your_experience_with_fake_results_or/",
          "publishedOn": "2022-04-05T00:48:43.000Z",
          "wordCount": 183,
          "title": "[D] What is your experience with Fake results or overfitted results being sold as awesome?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twcdt2/d_why_do_we_still_teach_support_vector_machines/",
          "author": null,
          "description": "Honest question: are there any applications for which SVMs are the best choice? In my experience, no one seems to use this methodology anymore, though maybe I'm wrong. It just kinda feels like teaching people how to use a slide rule when everyone has calculators.\n    submitted by    /u/WartimeHotTot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twcdt2/d_why_do_we_still_teach_support_vector_machines/",
          "publishedOn": "2022-04-04T20:38:01.000Z",
          "wordCount": 937,
          "title": "[D] Why do we still teach support vector machines?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twc4or/d_paper_explained_continual_backprop_stochastic/",
          "author": null,
          "description": "https://youtu.be/zEMOX3Di2Tc\n This paper finds what seems to be a new phenomenon when working in the continual learning/life-long learning domain. If new tasks are continually introduced to an agent, it seems to loose it's ability to learn the more time progresses. Intuitively it's similar to this idea that \"an old dog can't learn new tricks\". They propose a fairly simple method of overcoming this limitation that involves resetting weights that are not contributing much to the outcome of the network. They call the method Continual Backprop.\n ​\n Outline:\n 0:00 - Overview\n 2:00 - Paper Intro\n 2:53 - Problems & Environments\n 8:11 - Plasticity Decay Experiments\n 11:45 - Continual Backprop Explained\n 15:54 - Continual Backprop Experiments\n 22:00 - Extra Interesting Experiments\n 25:34 - Summary \n ​\n Paper link: https://arxiv.org/abs/2108.06325\n    submitted by    /u/SlickBlueML  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twc4or/d_paper_explained_continual_backprop_stochastic/",
          "publishedOn": "2022-04-04T20:27:50.000Z",
          "wordCount": 237,
          "title": "[D] Paper Explained - Continual Backprop: Stochastic Gradient Descent with Persistent Randomness",
          "imageUrl": "https://external-preview.redd.it/fOTo43KuL6oL4o_WNxFDpy-aere0pzHjmcSlF2unamc.jpg?auto=webp&s=bc72dbd3a79a558d333d642635b7f1cc1b5d73a8"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw9jp5/r_googles_540b_dense_model_pathways_llm_unlocks/",
          "author": null,
          "description": "Blog: https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\n Paper: https://goo.gle/palm-paper\n - AFAIK from the Blogpost, Scaling laws still hold up (i.e not yet plateaued)\n - New transfer learning capabilities, outperforms fine-tuned models with 50x less data (Codex-12B)\n - The interesting part is how it meta-learns techy geeky jokes and is able to correlate concepts, and explain jokes suggesting starting doing a bit more meta-learning than GPT3 ever could.... But still not enough to generate decent ones (though the joke wasn't particularly humorous, so I may be underestimating)\n SoTA on various tasks, chain-of-thought-reasoning still holds up to scaling and outperforms some reasoning benchmarks, BIG-bench sees a huge improvement and general LLM thingys :)\n    submitted by    /u/Competitive-Rub-1958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw9jp5/r_googles_540b_dense_model_pathways_llm_unlocks/",
          "publishedOn": "2022-04-04T18:42:07.000Z",
          "wordCount": 1256,
          "title": "[R] Google's 540B (Dense) model Pathways LLM, \"Unlocks\" new tasks proportional to scale",
          "imageUrl": "https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?auto=webp&s=d45552298a94c0bc0e771853afe179cbb0e3f951"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw4wyj/r_minimum_description_length_recurrent_neural/",
          "author": null,
          "description": "https://arxiv.org/abs/2111.00600\n https://preview.redd.it/l6dni0007jr81.png?width=4888&format=png&auto=webp&s=82c7c9b9433b79c66318090ff85e4535c35ddb18\n    submitted by    /u/inland-1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw4wyj/r_minimum_description_length_recurrent_neural/",
          "publishedOn": "2022-04-04T15:33:42.000Z",
          "wordCount": 153,
          "title": "[R] Minimum Description Length Recurrent Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw2ec1/r_cfp_evorl_gecco_2022_one_week_before_the/",
          "author": null,
          "description": "CALL FOR PAPERS\n EvoRL 2022\n Evolutionary Reinforcement Learning workshop at GECCO 2022, July 9-13, Boston, USA\n \n In recent years reinforcement learning (RL) has received a lot of attention thanks to its performance and ability to address complex tasks. At the same time, multiple recent papers, notably work from OpenAI, have shown that evolution strategies (ES) can be competitive with standard RL algorithms on some problems while being simpler and more scalable. Similar results were obtained by researchers from Uber, this time using a gradient-free genetic algorithm (GA) to train deep neural networks on complex control tasks. Moreover, recent research in the field of evolutionary algorithms (EA) has led to the development of algorithms like Novelty Search and Quality Diversity, capable of…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw2ec1/r_cfp_evorl_gecco_2022_one_week_before_the/",
          "publishedOn": "2022-04-04T13:45:43.000Z",
          "wordCount": 600,
          "title": "[R] CfP EvoRL @ GECCO 2022. One week before the deadline!",
          "imageUrl": "https://external-preview.redd.it/lK42WwByGG32nygWSBuOYR3KR5RyUTDVfuLYvfjqmTI.jpg?auto=webp&s=02c389b64acc7a9d40c4c4ad6555c2381750877f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw0c1o/p_looking_for_a_dataset/",
          "author": null,
          "description": "Hey! New Here. I logged back into Reddit after years just to ask this question on this forum. I need to test a model, based loosely on BERT, that classifies a piece of text as having right or left political ideology leaning and whether it promotes any racial or religious stereotypes.\n For training purpose we used SBIC, IBC, and Stereoset. Though these only contain short sentences which are labeled as belonging to only one of the above categories.\n Is anyone aware of any other Dataset which can be used for this purpose, which hopefully contains text labeled as promoting or containing a political leaning (left/right, conservative/liberal, neutral) and further either any racial or religious stereotypes?\n Very thankful in adv\n    submitted by    /u/Fee_Imaginary  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw0c1o/p_looking_for_a_dataset/",
          "publishedOn": "2022-04-04T12:02:44.000Z",
          "wordCount": 205,
          "title": "[P] Looking for a dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvwnwy/p_random_relational_graph_convolutional_networks/",
          "author": null,
          "description": "📑 The Random R-GCN code has just been released!\n 📝 With just a few lines of code, you can now create embeddings of entities in a Knowledge Graph.\n ​\n Minimal example on how to create embeddings with RR-GCN\n ​\n 💡 RR-GCN does not require training and is competitive to fully trained R-GCNs.\n 👉 https://github.com/predict-idlab/RR-GCN\n    submitted by    /u/givdwiel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvwnwy/p_random_relational_graph_convolutional_networks/",
          "publishedOn": "2022-04-04T08:07:48.000Z",
          "wordCount": 143,
          "title": "[P] Random Relational Graph Convolutional Networks (RR-GCN)",
          "imageUrl": "https://external-preview.redd.it/hbnqn3Smcm-XXgFP9D-4dlKcnNwPcAkdToaX-b-_zw0.jpg?auto=webp&s=0bafa0817ea6dee3b3d7c145ec6dead117ef8d65"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvug94/r_diffusionclip_textguided_diffusion_models_for/",
          "author": null,
          "description": "submitted by    /u/ImBradleyKim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvug94/r_diffusionclip_textguided_diffusion_models_for/",
          "publishedOn": "2022-04-04T05:38:01.000Z",
          "wordCount": 388,
          "title": "[R] DiffusionCLIP: Text-Guided Diffusion Models for \"Robust\" Image Manipulation (CVPR 2022)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvr2ib/p_transformers_for_software_engineers/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvr2ib/p_transformers_for_software_engineers/",
          "publishedOn": "2022-04-04T02:36:40.000Z",
          "wordCount": 95,
          "title": "[P] Transformers for Software Engineers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvntfs/d_unconventional_computer_vision_problems_that/",
          "author": null,
          "description": "Given that most benchmarks for image classification are based on regular, everyday world objects RGB images (or grayscale), what are some unconventional science cases where 2D inputs are substantially different from what we are used to perceive by eye? \n For example, I'm interested in cases where spatial information can't be constrained to narrow pixel value ranges, such as exponential signals. Or that any standard normalisation (say min-max, zscore) and normalisation layers are not applicable and could lead to the loss of information.\n One of these cases is Astronomy. However, most practitioners try to to adapt the problem to established standards (say fake RGB images, log scaling flux images, etc). What are other cases out there where the nature of the 2D inputs are very distinct to what we are used to parse through our eyes and what deep nets are benchmarked on? I'm curious about tailored solutions that would intrinsically change the way the deep nets are constructed to solve the research question.\n    submitted by    /u/astroferreira  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvntfs/d_unconventional_computer_vision_problems_that/",
          "publishedOn": "2022-04-03T23:58:19.000Z",
          "wordCount": 322,
          "title": "[D] Unconventional computer vision problems that are intrinsically different from classifying ordinary stuff",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvjw43/researchprojectlibrary_dogfeeding_a_new_machine/",
          "author": null,
          "description": "Hi everyone!\n I'm Atindriyo Sanyal, one of the founders of the ML company Galileo (https://rungalileo.io/). We're building a cool new tool/framework for ML practitioners that helps shine a light on the data you are training your models with.\n I'd love to get some feedback on the product, and since we're still in private beta, I'm looking for folks to try out the product on their datasets and models. It's easy to use and hooks into popular frameworks such as pyTorch, Tensorflow, Keras, SpaCy etc. \n Caveat: Currently the tool only works for NLP use cases (think text classification, NER etc).\n I'll be giving $100 to folks who are willing to give some time to this and provide feedback on the usability of the product. If you're interested, here's a really tiny form (should take <1 minute to fill) for you to fill out. I'll review the applications and send you an email for a follow up Zoom chat where I'll share the software artifacts with you!\n https://docs.google.com/forms/d/11V20C_J_SyNaX7QL6DasnTe7f0UiueUyaKdmt3xL1oI/edit\n Look forward and happy (machine) learning!\n - Atindriyo\n P.S. If you have any questions or want to chat personally, send me an email at [atin@rungalileo.io](mailto:atin@rungalileo.io).\n    submitted by    /u/atindriyo_galileo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvjw43/researchprojectlibrary_dogfeeding_a_new_machine/",
          "publishedOn": "2022-04-03T21:03:32.000Z",
          "wordCount": 295,
          "title": "[Research][Project][Library] Dog-feeding a new Machine Learning data tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvfx9r/d_pain_points_when_using_gpu_instance_platforms/",
          "author": null,
          "description": "Hi everyone, I just launched a GPU compute instance platform (think lambdalabs, fluidstack, aws EC2, vast), and I was wondering what pain points everyone has with existing solutions. I'm not trying to sell anyone anything, but I want to look for feedback that will help me to build a better product.\n My current thoughts are\n  \nEase of getting data into the platform\n Ease of getting data off of the platform\n Automation for spinning up and down instances\n Availability of the type of instance you want\n Price too high\n Not enough/too many abstractions\n  \nTIA and I look forward to some good discussions!\n    submitted by    /u/runpod-io  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvfx9r/d_pain_points_when_using_gpu_instance_platforms/",
          "publishedOn": "2022-04-03T18:23:04.000Z",
          "wordCount": 269,
          "title": "[D] Pain points when using GPU instance platforms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvc7xl/r_efficientvdvae_an_opensource_memoryefficient/",
          "author": null,
          "description": "Hello everyone :)\n We have released last week our paper \"Efficient-VDVAE: Less is more\" with code!\n We present simple modifications to the Very Deep VAE to make it converge up to 2.6x times faster and save up to 20x times memory load. We also introduce a gradient smoothing technique to improve stability during training. Our model achieves comparable or better negative log-likelihood (NLL) on 7 commonly used datasets.\n Additionally, we make an argument against existing 5-bit benchmarks. We empirically show as well that 3% of the latent space is enough to encode the data information without any performance loss. Thus, indicating the potential to efficiently leverage the Hierarchical VAE's latent space in downstream tasks.\n  \nPaper: https://arxiv.org/abs/2203.13751\n Code: https://github.com/Rayhane-mamah/Efficient-VDVAE\n Paperswithcode: https://paperswithcode.com/paper/efficient-vdvae-less-is-more\n  \nFeedback is very much appreciated!\n https://preview.redd.it/tjua1xpq3cr81.png?width=878&format=png&auto=webp&s=718bd91fd648acd673ddab1ad5342207e8be09e7\n    submitted by    /u/Louay-AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvc7xl/r_efficientvdvae_an_opensource_memoryefficient/",
          "publishedOn": "2022-04-03T15:46:10.000Z",
          "wordCount": 225,
          "title": "[R] Efficient-VDVAE: An open-source memory-efficient and stable very deep hierarchical VAE",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tv9fuv/r_deepdpm_deep_clustering_with_an_unknown_number/",
          "author": null,
          "description": "Hey everyone :)\n We've just released the code for our paper (accepted to CVPR2022) \n DeepDPM is a nonparametric deep-clustering method which unlike most deep clustering methods, does not require knowing the number of clusters, K; rather, it infers it as a part of the overall learning. Using a split/merge framework to change the clusters number adaptively and a novel loss, our proposed method outperforms existing (both classical and deep) nonparametric methods.\n While the few existing deep nonparametric methods lack scalability, we show ours by being the first such method that reports its performance on ImageNet.\n ​\n  \nPaper: https://arxiv.org/abs/2203.14309\n Code: https://github.com/BGU-CS-VIL/DeepDPM/\n  \nBelow are some examples of clusters our method found in ImageNet.\n https://preview.redd.it/jw5kvcuzfbr81.jpg?width=737&format=pjpg&auto=webp&s=5b61cdd0efdea7c92aba611171e5dc7f4276c892\n    submitted by    /u/shahaff32  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tv9fuv/r_deepdpm_deep_clustering_with_an_unknown_number/",
          "publishedOn": "2022-04-03T13:36:53.000Z",
          "wordCount": 1327,
          "title": "[R] DeepDPM: Deep Clustering With an Unknown Number of Clusters",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tuzn4m/d_why_are_confidence_regions_elliptic/",
          "author": null,
          "description": "Confidence regions are the 2D version of a confidence interval. Almost everywhere in the literature, the shape is elliptic, but no justification is provided. You would think that a confidence region of level γ is defined as the domain of minimum area, covering a mass γ of the underlying probability distribution. That sounds perfectly logical, but it is mentioned nowhere. Based on this definition, the boundary of a confidence region is obtained by solving an optimization problem: it is a problem in calculus of variations -- finding a boundary curve encompassing a domain of minimum area. These problems are usually hard to solve, but in this case, the solution seems trivial: it must be a contour line. And if the underlying distribution is Gaussian, contour lines are obviously ellipses. This would be a solid justification as to why ellipses are so widespread.\n https://preview.redd.it/42mr1t1je8r81.png?width=1072&format=png&auto=webp&s=2fb9cedbbb15895827ed00edc4912ac39fad0b71\n My question here is whether or not my argumentation makes sense, or if there is something faulty in my math. I discuss it in more details in one of my articles, here. If you need clarifications, please reply on Reddit, I will do my best to explain.\n    submitted by    /u/MLRecipes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tuzn4m/d_why_are_confidence_regions_elliptic/",
          "publishedOn": "2022-04-03T03:18:05.000Z",
          "wordCount": 494,
          "title": "[D] Why are confidence regions elliptic?",
          "imageUrl": "https://external-preview.redd.it/ZqF9VX191mBPz4Lgbx4Etb5sHzOihemERSUo-VbfADQ.jpg?auto=webp&s=9a1ecbd9154dd6cde162b9f64f1b914eae390f6d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tux0p3/dnew_scaling_laws_for_large_language_models/",
          "author": null,
          "description": "https://www.lesswrong.com/posts/midXmMb2Xg37F2Kgn/new-scaling-laws-for-large-language-models\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tux0p3/dnew_scaling_laws_for_large_language_models/",
          "publishedOn": "2022-04-03T00:01:56.000Z",
          "wordCount": 325,
          "title": "[D]New Scaling Laws for Large Language Models",
          "imageUrl": "https://external-preview.redd.it/AE9lX1YhkCRE38raan8DE9_Y-2h4jvTJZ4LU_z68bio.jpg?auto=webp&s=a0fd488a512423074c7d8c4f8475b6e811c9f1cd"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tul97t/d_how_logistic_regression_nomogram_is_constructed/",
          "author": null,
          "description": "Well I' ve been reading some scientific works and I don't understand how nomograms are constructed from logistic regression models.\n In this example I have:\n https://ieeexplore-1ieee-1org-1000007l206e9.han.bg.pg.edu.pl/document/9514609\n And they train LR model on Covid19 dataset [death/ didn't die] so it's binary classification problem However later on, they construct nomogram, which determines whether there is low/moderate/high risk of covid19 mortality. What I don't undestand is how they calculate the score the establish chances of death. E.G. If the score is <0.05 there is low possibility that patient will die.\n My general question is, how they constructed this nomogram from the binary classifier they had?\n    submitted by    /u/s168501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tul97t/d_how_logistic_regression_nomogram_is_constructed/",
          "publishedOn": "2022-04-02T15:19:36.000Z",
          "wordCount": 202,
          "title": "[D] How Logistic Regression nomogram is constructed from binary classifier?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tujtva/r_neural_head_avatars_from_monocular_rgb_videos/",
          "author": null,
          "description": "submitted by    /u/Mandelmus100  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tujtva/r_neural_head_avatars_from_monocular_rgb_videos/",
          "publishedOn": "2022-04-02T14:15:11.000Z",
          "wordCount": 120,
          "title": "[R] Neural Head Avatars from Monocular RGB Videos (CVPR 2022)",
          "imageUrl": "https://external-preview.redd.it/RA2ZBowRGMfH1kL1WDUvWsfYOa1Pmik5Mst-t5245WY.jpg?auto=webp&s=9eacda6953d6e58088993d1828194a5b4db15105"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tuhgid/d_predicting_hard_properties_of_graphs_using/",
          "author": null,
          "description": "Hello everyone,\n there is a lot of work in the field of geometric deep learning for combinatorial optimization that yields good approximation algorithms for \"hard\" problems on graphs (see here), with the most prominent example being the TSP problem. However, as far as I can see, all these considered problems share the fact that the computed solution is a subset of the vertices/edges of the original graph. In my field (graph drawing), one of the most important considered properties is the crossing number). Hence, the solution would not consists of a labeling of the edges/vertices, but is rather a regression task on the whole graph. I have a dataset that consists of roughly 10000 graphs together with their crossing number. Treating the above problem as a supervised regression task and simply inserting the graph into a GNN does not work for me at all - is this a problem of my choice of architecture or is this sort of \"function\" that maps a graph to its crossing number something we can expect no current architecture to find.\n I appreciate any comment, even if it is just your intuition on the problem.\n Best regards,\n MrLemming\n    submitted by    /u/MrLemming2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tuhgid/d_predicting_hard_properties_of_graphs_using/",
          "publishedOn": "2022-04-02T12:11:38.000Z",
          "wordCount": 378,
          "title": "[D] Predicting hard properties of graphs using Machine Learning",
          "imageUrl": "https://external-preview.redd.it/tA9m1F8qnewJWZPWIeJ3NpCGpGA9UWzVtPeZUeg_nm8.jpg?auto=webp&s=f2e6ef1657311ed8a546bcd357bc74512d54b2d7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tugeo8/n_announcement_call_for_papers_for_our_icml/",
          "author": null,
          "description": "Dear community, I hope I do not violate rules by advertizing our Call for Papers here. In a nutshell, submissions can be robustness or OOD datasets and new metrics which we will consolidate in one benchmark. More infos on our website.\n I am happy to answer any questions in regards to the call.\n    submitted by    /u/helavisa4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tugeo8/n_announcement_call_for_papers_for_our_icml/",
          "publishedOn": "2022-04-02T11:08:24.000Z",
          "wordCount": 156,
          "title": "[N] Announcement: Call for Papers for our ICML ShiftHappens Workshop!",
          "imageUrl": "https://external-preview.redd.it/GqSShE36VS2-_QXTT7hNTjAfewg5eKg_7Hc-NSwTExU.jpg?auto=webp&s=4190508fc667dc5ea6a12862a9ecdccc01136fef"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tuf0vv/p_openai_codex_helping_to_write_shell_commands/",
          "author": null,
          "description": "submitted by    /u/tomd_96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tuf0vv/p_openai_codex_helping_to_write_shell_commands/",
          "publishedOn": "2022-04-02T09:36:21.000Z",
          "wordCount": 274,
          "title": "[P] OpenAI Codex helping to write shell commands",
          "imageUrl": "https://preview.redd.it/dbgbskqg53r81.gif?format=png8&s=a6ba284e6bf2600d95aa9235e353d5546790b1f7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tucu1d/rp_styleganxl_scaling_stylegan_to_large_diverse/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tucu1d/rp_styleganxl_scaling_stylegan_to_large_diverse/",
          "publishedOn": "2022-04-02T07:02:35.000Z",
          "wordCount": 185,
          "title": "[R][P] StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets + Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/Lvp4nEYrvAlYtFhADumRvacvOAbM1my-2xRV3EbmEu8.png?format=pjpg&auto=webp&s=25ab218429c1bafa2166d1f845c42a113412fd24"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tu8szc/d_petaflops_as_a_unit_of_measure_in_machine/",
          "author": null,
          "description": "I was looking at this paper (https://arxiv.org/pdf/2005.14165.pdf) and came across this graph:\n ​\n https://preview.redd.it/49ydy9bo61r81.png?width=665&format=png&auto=webp&s=729743449d6a99d2b84b81610e7e32d87ea4dfeb\n I am trying to understand the following two things about this graph:\n ​\n  \nWhat is PetaFLOP/s-days? I read that a PetaFLOP is 1,000,000,000,000,000 calculations (e.g. addition, subtraction). I am guessing that 10^2 would imply 100 * 1,000,000,000,000,000 calculations per day - is this correct? Is there any difference between PetaFLOP/days and PetaFLOP/s-days? (I also find it interesting they are probably referring to \"computer resources\" as simply \"compute\")\n What does \"C\" stand for in L = 2.57 * C^-0.048? I am guessing that the \"dotted line\" probably refers to the \"average loss\" for different Neural Networks with differing amounts of Parameters - but what exactly does \"C\" stand for?\n Finally, is there a reason that \"Validation Loss\" is not expressed as a percentage? For instance, what is a Validation Loss of 3? Is a Validation Loss of 3 the same as a Loss of 30%? Or does Validation Loss simply refer to the value of the Loss Function obtained during the Validation stage of Cross Validation?\n  \nThank you!\n    submitted by    /u/blueest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tu8szc/d_petaflops_as_a_unit_of_measure_in_machine/",
          "publishedOn": "2022-04-02T02:59:28.000Z",
          "wordCount": 548,
          "title": "[D] PetaFLOPS as a Unit of Measure in Machine Learning Applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tu41tl/p_how_to_add_padding_to_an_image_in_pytorch/",
          "author": null,
          "description": "Hi guys,\n I am trying to add padding to images in Pytorch - I need to standardize all the images in my dataset to be of the same size. I spent the whole day trying to find a good solution but nothing worked. I succeeded in resizing but that compromised my image quality, so that is why I want to proceed with padding. How to do this?\n Thanks in advance! :)\n    submitted by    /u/whyhateverything  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tu41tl/p_how_to_add_padding_to_an_image_in_pytorch/",
          "publishedOn": "2022-04-01T22:57:47.000Z",
          "wordCount": 196,
          "title": "[P] How to add padding to an image in Pytorch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tu3qn2/p_sso_single_signon_for_cvat_the_labelling_tool/",
          "author": null,
          "description": "Hi everyone,\n For quite a long time, I have seen folks looking for a way to do SSO (Single Sign-On) for CVAT, a popular labeling tool. But unfortunately such capability is not readily available. It only supports local authentication and LDAP.\n So we decided to make a change proactively, and now we are in the process of enabling SSO for it. The initial result looks promising. Check it out to see what we have done: https://www.youtube.com/watch?v=R7hBBLG5Fdc\n Is this something that you would love to have?\n Any other machine learning tools that you want to have SSO capability as well?\n Any feedback are welcome.\n    submitted by    /u/alexcgg1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tu3qn2/p_sso_single_signon_for_cvat_the_labelling_tool/",
          "publishedOn": "2022-04-01T22:43:11.000Z",
          "wordCount": 241,
          "title": "[P] SSO (Single Sign-On) for CVAT, the labelling tool",
          "imageUrl": "https://external-preview.redd.it/2wqpHoLzIB0dVStIRiQV7mcT4yrCfrO-bXq1Gfr9t7A.jpg?auto=webp&s=6874055cb31bb0c8094615a878dd86502dae858c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tu2z97/d_take_information_theory_before_the_first_course/",
          "author": null,
          "description": "Hello,\n I will study further Reinforcement Learning and Deep Learning in the future. I have completed probability theory, linear algebra, and multivariable calculus. I am taking Mathematical Statistics. Should I take Information Theory (IT) before ML? For me, I would definitely take IT, but I don't know whether to take it now or later.\n    submitted by    /u/nwe2rw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tu2z97/d_take_information_theory_before_the_first_course/",
          "publishedOn": "2022-04-01T22:08:51.000Z",
          "wordCount": 208,
          "title": "[D] Take Information Theory before the first course in machine learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttyr0f/d_paper_explained_improving_intrinsic_exploration/",
          "author": null,
          "description": "https://youtu.be/NeGJAUSQEJI\n Exploration is one of the oldest challenges for Reinforcement Learning algorithms, with no clear solution to date. Especially in environments with sparse rewards, agents face significant challenges in deciding which parts of the environment to explore further. Providing intrinsic motivation in form of a pseudo-reward is sometimes used to overcome this challenge, but often relies on hand-crafted heuristics, and can lead to deceptive dead-ends. This paper proposes to use language descriptions of encountered states as a method of assessing novelty. In two procedurally generated environments, they demonstrate the usefulness of language, which is in itself highly concise and abstractive, which lends itself well for this task.\n ​\n OUTLINE:\n 0:00 - Intro\n 1:10 - Paper Overview: Language for exploration\n 5:40 - The MiniGrid & MiniHack environments\n 7:00 - Annotating states with language\n 9:05 - Baseline algorithm: AMIGo\n 12:20 - Adding language to AMIGo\n 22:55 - Baseline algorithm: NovelD and Random Network Distillation\n 29:45 - Adding language to NovelD\n 31:50 - Aren't we just using extra data?\n 34:55 - Investigating the experimental results\n 40:45 - Final comments\n ​\n Paper: https://arxiv.org/abs/2202.08938\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttyr0f/d_paper_explained_improving_intrinsic_exploration/",
          "publishedOn": "2022-04-01T19:06:41.000Z",
          "wordCount": 276,
          "title": "[D] Paper Explained - Improving Intrinsic Exploration with Language Abstractions (Full Video Analysis)",
          "imageUrl": "https://external-preview.redd.it/QmXKqcvZCu-4PfGS4aIztJnVf75BUY5bHHzzfiI01lM.jpg?auto=webp&s=f569332656f0137e26cdab130bd7839ed1cc7235"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttxn7q/n_are_we_running_out_of_ai_benchmarks/",
          "author": null,
          "description": "Benchmarks are an important way to measure progress in AI research – but artificial intelligence is constantly achieving new bests. Are we running out of AI benchmarks? \n ...\n Researchers at the Medical University of Vienna and the University of Oxford now show in a meta-study of AI benchmarks that saturated or stagnant benchmarks are common. The researchers examined 1,688 benchmarks with 406 tasks in computer vision and natural language processing since 2013, and draw the following conclusions:\n  \nIn some cases, there would be continuous growth, such as in the ImageNet benchmark.\n However, a majority of all benchmarks quickly reach technological stagnation or saturation.\n In some cases, a lack of research interest is also a cause of stagnation. The researchers cite the UCF101 action recognition benchmark as an example of saturation.\n However, the dynamics of performance improvement do not follow a clearly discernible pattern: in some cases, phases of stagnation are followed by unpredictable leaps. This is what happened in the PROTEINS benchmark.\n  \n...\n Moreover, of the 1,688 benchmarks, only 66 percent have more than three results at different points in time – so in practice, 33 percent of all AI benchmarks are not used and therefore useless. \n ...\n In the future, new benchmarks should be developed by large, collaborative teams from many institutions, knowledge domains, and cultures to ensure high-quality benchmarks and avoid fragmentation of the benchmark landscape, the researchers conclude. \n Source: https://mixed-news.com/en/are-we-running-out-of-ai-benchmarks/\n    submitted by    /u/Sephirio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttxn7q/n_are_we_running_out_of_ai_benchmarks/",
          "publishedOn": "2022-04-01T18:19:42.000Z",
          "wordCount": 320,
          "title": "[N] Are we running out of AI benchmarks?",
          "imageUrl": "https://external-preview.redd.it/d_CzxPSnMiRfxvkW2wZCdrAVSdc0mHYmhbyFIJu4rYI.jpg?auto=webp&s=b86c9b97aa8542120b98b5c677748c5faf74d745"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttwzjy/d_methods_for_anomaly_detection_clustering_with/",
          "author": null,
          "description": "I'm looking for models, workflows, algorithms in the pursuit of principled ways of conducting anomaly detection on high dimensional datasets from physical systems. I am already familiar with the application of autoencoders, isolation forests, etc. to trivial feature sets. \n I have feature sets that abide physical equations and so there is also the capability of using differential equations or some prior generating process to also bound what is and isn't an \"outlier\". \n Looking for papers/methods/texts that are in this vein.\n    submitted by    /u/memproc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttwzjy/d_methods_for_anomaly_detection_clustering_with/",
          "publishedOn": "2022-04-01T17:52:48.000Z",
          "wordCount": 510,
          "title": "[D] Methods for anomaly detection / clustering with high dimensional physics data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttw7w8/rejecting_gan_offmanifold_samples_d/",
          "author": null,
          "description": "I am working on a project, where I do image editing in the latent space of an image. Are there any papers or suggestions on how to enforce that the samples lie on the manifold?\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttw7w8/rejecting_gan_offmanifold_samples_d/",
          "publishedOn": "2022-04-01T17:21:08.000Z",
          "wordCount": 155,
          "title": "Rejecting GAN Off-Manifold Samples? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttt0l1/r_crosslingual_wikipedia_dataset/",
          "author": null,
          "description": "Hi! For a research project, I am trying to create a dataset that contains: the abstract of an article in EN; the abstract of the article in simple EN; the rest of the article in EN; the rest of the article in simple EN.\n When I worked in one language, I preprocessed the XML directly (the APIs seemed quite slow for processing the whole encyclopedia). However, I am struggling to find a way to join Wikis in different languages, as the dumps seem not to include a language-independent id.\n This seems to be a relatively \"standard\" task for creating cross-lingual datasets, so I hope someone has some tips, and I do not need to spend the next week reinventing the wheel :)\n    submitted by    /u/ombelicoInfinito  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttt0l1/r_crosslingual_wikipedia_dataset/",
          "publishedOn": "2022-04-01T15:09:33.000Z",
          "wordCount": 241,
          "title": "[R] Cross-lingual Wikipedia dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttswq1/d_activation_functions_for_neural_networks_in/",
          "author": null,
          "description": "Hi everyone,\n I want to run a feedforward autoregressive network to forecast the potential sales of specific SKUs for the following months. The idea is to capture the non-linearity in the data. Does it make sense to use ReLU? or given that all my data points are positive values this function will return the same number (max(0,x)), therefore is not suitable for what I am trying to do?\n I have also checked other activation functions, but sigmoid for example is for classification, and hyperbolic tangent returns values that can be negative.\n ​\n Any help would be much appreciated\n Thanks!\n    submitted by    /u/Old-Box-6684  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttswq1/d_activation_functions_for_neural_networks_in/",
          "publishedOn": "2022-04-01T15:05:06.000Z",
          "wordCount": 195,
          "title": "[D] Activation functions for Neural Networks in Time Series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tts3ac/d_i_just_watched_alphago_the_movie_are_there_any/",
          "author": null,
          "description": "AlphaGo - The Movie on Youtube\n    submitted by    /u/Mighty__hammer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tts3ac/d_i_just_watched_alphago_the_movie_are_there_any/",
          "publishedOn": "2022-04-01T14:31:10.000Z",
          "wordCount": 309,
          "title": "[D] I just watched AlphaGo - The Movie, are there any more well made documentaries about AI available?",
          "imageUrl": "https://external-preview.redd.it/tK4IZMKXA_sU90ULATnz4ASagF5NHZC_vvqL5eVLreY.jpg?auto=webp&s=c6915f316e973e6a1eb6deb71eadc657339e7d9f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttpg0e/p_cyclemoid_a_new_activation_function_inspired_by/",
          "author": null,
          "description": "Excited to share our latest research. The cyclemoid activation was inspired by the success of cyclical learning rate. Moreover, it has nice mathematical properties to stabilize gradients and maintain strong gradient signals in desired regions during training. \n We designed it as a drop-in replacement for ReLU, and we would love to hear what you think.\n The code is up on GitHub, and the preprint should be up soon, too: https://github.com/rasbt/cyclemoid-pytorch\n PS: Currently, we only have a PyTorch implementation but would welcome it if someone could port it to TensorFlow/Keras (my Tf/Keras skills are just too rusty for it.)\n    submitted by    /u/seraschka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttpg0e/p_cyclemoid_a_new_activation_function_inspired_by/",
          "publishedOn": "2022-04-01T12:26:20.000Z",
          "wordCount": 556,
          "title": "[P] Cyclemoid -- a new activation function inspired by cyclical learning rates; SOTA on several benchmarks",
          "imageUrl": "https://external-preview.redd.it/U14LT5IkG6HLrrnrIsVZjM9oswoJnsJgnLe7BM_JK9Y.jpg?auto=webp&s=ed71fee1fec70353db36c66c34938f53f901420c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttp6fu/d_im_creating_a_tool_to_enrich_your_datasets_with/",
          "author": null,
          "description": "Hey all,\n I love doing market research and all kinds of exploratory analyses, but getting the data is a major pain point, as it is in many places (data dumps, apis, marketplaces, web data) and in all kinds of formats\n I'm trying a different approach, where instead of searching for data sources, and then integrating manually, you just upload your dataset. My service has a large index with datasets and api providers, and finds relevant ones for your dataset which you can add easily.\n ​\n example search via sdk\n Does this seem useful to you? Would love to hear your thoughts\n    submitted by    /u/salmiakdrop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttp6fu/d_im_creating_a_tool_to_enrich_your_datasets_with/",
          "publishedOn": "2022-04-01T12:11:40.000Z",
          "wordCount": 532,
          "title": "[D] I'm creating a tool to enrich your datasets with relevant external data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttp4ub/d_have_there_been_successful_applications_of_deep/",
          "author": null,
          "description": "Some successful applications I am able to gather, mostly from Deepmind:\n - comma.ai self-driving system.\n - Weather nowcasting\n - Tokamak fision reactor feeedback control\n - Hardware design: New gen. TPU\n - Datacenter cooling optimization\n - Adaptive locomotion for quadrupedal robots *\n - Portfolio optimization (financial instruments)\n There is a lot of work in games, particularly board games, but these do not really solve something \"useful\" for society. I have seen also lots of toy examples with libraries like gym and some robotics but in general these are rather proof-of-concept models or just models that do not work at all. One that actually does work is Solving Rubik’s Cube with a Robot Hand, not regarding the solution of the cube but its dexterous manipulation with a robotic hand. This is pretty cool, but again, the domain of the problem is too narrow to be considered actually a successful application to a real-world problem. So my question is, am I missing some examples? For example, is any company out there trying to apply deep RL to self-driving vehicles or to NLP, and have they had any success?\n * Boston dynamics solves this without ML, just good'ol control theory so this is a 50-50 win for RL.\n ​\n Edit: Thanks everyone for the responses, I have updated the list with more projects from the comments.\n Edit 2: Took Alphafold out because the current version (2.x) does not use RL.\n    submitted by    /u/sid_276  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttp4ub/d_have_there_been_successful_applications_of_deep/",
          "publishedOn": "2022-04-01T12:09:05.000Z",
          "wordCount": 1183,
          "title": "[D] Have there been successful applications of Deep RL to real problems other than board games/Atari?",
          "imageUrl": "https://external-preview.redd.it/6tuXmcur0bFJS0quIejtKY6sJ-nBSuWkVCpxUhmQca4.jpg?auto=webp&s=1dad25d9a1de288db063eefdc5a76945afdb447d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttnj4i/d_request_for_advice_texttoimage_synthesis/",
          "author": null,
          "description": "Hello all, I hope that you are all doing good.\n The thing is that I want to study text-to-image synthesis; but I see that there are lots of work already done up until now. I am kind of confused about how I should start studying.\n About my experience, I am trying to learn as much as I can. I started by following Andrew Ng’s Machine Learning course on Coursera; and now I continue with Deep Learning Specialization (almost finished). Apart from these, I check NVIDIA blog, some YouTube channels, Slack communities and of course here on Reddit along with a few other channels. As I said, I am trying to follow what’s going on. \n To tell the truth, I didn’t do much in terms of building models. I mean, not a real-life project or something like that. My experience is more based on projects for the courses that I attend/attended. By the way, I don’t know how it will affect things’ turning out; but I have recently begun a graduate program as well in artificial intelligence. Moreover, during my undergraduate program, I took some courses that might help (at least I guess so) including Calculus and Linear Algebra.\n I also want to mention that as for hardware there is an NVIDIA Jetson Nano Developer Kit available to me.\n I hope that what I am asking is clear and information I provided help you answering. If not, please ask me.\n Best regards.\n    submitted by    /u/fgokmenoglu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttnj4i/d_request_for_advice_texttoimage_synthesis/",
          "publishedOn": "2022-04-01T10:32:56.000Z",
          "wordCount": 327,
          "title": "[D] Request for Advice: Text-to-Image Synthesis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttncof/d_do_you_use_data_engineering_pipelines_for_real/",
          "author": null,
          "description": "Usually I am working on huge and complex datasets with millions of rows (or images if it's CV) and most often I just feed them to pandas in a notebook, then transfer the code to a script and run it when it's needed. Then with the result I train my models. No external tools used for this.\n Do you have experience with data pipeline tools/frameworks and data validation tools/frameworks?\n For example I just found \"Great Expectations\" and \"Kedro\", \"Flyte\" and I was wondering at which point in time and project complexity should we choose one of these tools instead of the ancient cave man way?\n Any success/failure stories?\n    submitted by    /u/gabegabe6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttncof/d_do_you_use_data_engineering_pipelines_for_real/",
          "publishedOn": "2022-04-01T10:20:31.000Z",
          "wordCount": 1386,
          "title": "[D] Do you use data engineering pipelines for real life projects?",
          "imageUrl": "https://external-preview.redd.it/9aMOb066CeL6cuV4L_Twfj7nPc9ZY-PmH1mwS0SBCBY.jpg?auto=webp&s=80f57c71ebf2c0b3121df52d87b15aa86a25bdc4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttm00m/d_the_joy_of_finding_things_out_essay/",
          "author": null,
          "description": "Currently I’m trying to figure out if I want to stay in academia or not. My decision hinges on what makes doing science enjoyable. My current understanding is in order for science to be enjoyable, there has to be an element of surprise. A tension that builds. And release of that tension. This is most obvious in theoretical works where the scientist makes a prediction, and later empirical data verifies that prediction. Excitement. Joy. Wonder. In experimental work, surprise can take the form of not knowing how the experiment will turn out. Once you get the result of the experiment, it'll disambiguate competing theories you had in your mind or elucidate a new theory. \"Everything clicks\" or at the very least you'll be put into a fever trying to integrate the new surprising data with previous …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttm00m/d_the_joy_of_finding_things_out_essay/",
          "publishedOn": "2022-04-01T08:43:49.000Z",
          "wordCount": 2919,
          "title": "[D] The Joy of Finding Things Out (essay)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttjoiy/d_a_fine_grained_classification_dilemma/",
          "author": null,
          "description": "Hi Folks,\n I'm in a bit of a dilemma here on a specific fine grained classification problem that we have. The task at hand is to classify the subspecies of plant seeds. Firstly, the seeds are super tiny, but we have camera setup to take zoomed images of the seeds. Secondly, even the experts can't tell the exact difference between 2 subspecies of seeds. They go by their experience and intuition. All the subspecies put together looks similar but the data points within the same subspecies are vastly different. The requirement being classifying the subspecies based on their morphological properties. Here is the catch, the requirement is 98%+ accuracy. I tried few preprocessing and models (transformers, resnets, inception and other sort) but can't hit the 98% accuracy mark. Even if I could, the model sometimes fail on external sets or on production.\n I would like some expert (ML side) take on this issue on how to approach this.\n    submitted by    /u/happy_happy_feet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttjoiy/d_a_fine_grained_classification_dilemma/",
          "publishedOn": "2022-04-01T05:58:33.000Z",
          "wordCount": 1059,
          "title": "[D] A fine grained classification dilemma",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttibtz/d_how_to_preprocess_a_13k_column_dataset/",
          "author": null,
          "description": "I have a single cell rna seq dataset containing 13k features. I would like to preprocess the dataset. What are the best methods to do that? Also, how to apply feature elimination/selection on this unsupervised data? Thanks\n    submitted by    /u/Striking-Machine2763  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttibtz/d_how_to_preprocess_a_13k_column_dataset/",
          "publishedOn": "2022-04-01T04:34:09.000Z",
          "wordCount": 198,
          "title": "[D] how to preprocess a 13k column dataset.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttgsr4/r_nixtts_an_incredibly_lightweight_texttospeech/",
          "author": null,
          "description": "Hi, Reddit!\n Excited to share with you guys, Nix-TTS 🐤! Our latest research in lightweight neural Text-to-Speech.\n We've seen how synthetic voices generated by recent neural TTS are getting more and more natural, but most of the time the models suffer from slow CPU inference and are not end-to-end, which requires an additional vocoder model.\n Nix-TTS 🐤 is an incredibly lightweight end-to-end TTS model achieved by applying non end-to-end knowledge distillation to a powerful yet large-sized generative TTS teacher model.\n Our proposed model is end-to-end (vocoder-free) with only 5.23M parameters or up to 82% reduction of the teacher model. We also employed a stochastic duration predictor to improve its expressiveness.\n It is capable to run 10x faster than real-time on Intel i7 CPU and 0.5 times faster than real-time on Raspberry Pi Model 3B. Making it suitable for deployment in resource-constrained settings. Here we attached the complexity and speedup detail from the paper.\n ​\n Nix-TTS speedup and complexity compared to other models.\n ​\n We released the paper (submitted to INTERSPEECH 2022) and the pre-trained models on the attached link below:\n  \n📄 Paper: https://arxiv.org/abs/2203.15643\n 📦 Repository: https://github.com/rendchevi/nix-tts\n 🤗 Interactive Demo: https://huggingface.co/spaces/rendchevi/nix-tts\n  \nA short video demo from the 🤗 HuggingFace Spaces:\n Nix-TTS Short Demo\n Let me know what you guys think in the thread! We're very excited to see the potential improvements & applications of this model or method and lightweight TTS in general. Feel free to reach me via DM as well if you'd like to discuss anything further.\n    submitted by    /u/sourpeach_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttgsr4/r_nixtts_an_incredibly_lightweight_texttospeech/",
          "publishedOn": "2022-04-01T03:06:19.000Z",
          "wordCount": 580,
          "title": "[R] Nix-TTS 🐤: An incredibly lightweight text-to-speech via non end-to-end distillation",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttd3bl/dare_there_any_good_solutions_for_multimodal/",
          "author": null,
          "description": "Hi, Reddit! I'm a data scientist working in the dating app startup field. We have been trying to set up people with blind dates. We can get multimodal data(texts, images, and audio) and we want to do this: collect negative and positive pairs from each user's swiping history and do a binary classification (matching). Then we would get together as many users' data as possible and train a model.\n Though it sounds nice, this is hard as we could not find an existing developer tool or paper that supports combining such rich multimodal data. Any existing research out there to achieve this task? Moreover, is there already any library or AutoML tool that supports this? Checked Google AutoML, does not support this.\n Any help and advice would be much appreciated.\n    submitted by    /u/meame2010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttd3bl/dare_there_any_good_solutions_for_multimodal/",
          "publishedOn": "2022-03-31T23:48:50.000Z",
          "wordCount": 311,
          "title": "[D]Are there any good solutions for multimodal classification? Libraries, AutoML tool?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttcsqz/p_laion5b_public_dataset_of_585_billion_imagetext/",
          "author": null,
          "description": "LAION-5B: A new era of open large-scale multi-modal datasets.\n Twitter thread.\n Related: [P] LAION-400M: open-source dataset of 400 million image-text pairs.\n I am not affiliated with this project.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttcsqz/p_laion5b_public_dataset_of_585_billion_imagetext/",
          "publishedOn": "2022-03-31T23:33:06.000Z",
          "wordCount": 131,
          "title": "[P] LAION-5B: public dataset of 5.85 billion image-text pairs",
          "imageUrl": "https://external-preview.redd.it/zIzZWgf2-det-DQnCxz38cfTU2OBk2b9rFFJZe5GdMY.jpg?auto=webp&s=6900de17119ed0ef290741a6b2832ee35cc22a14"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt9lib/p_adapting_pixel_attribution_methods_for_models/",
          "author": null,
          "description": "Hi r/MachineLearning,\n https://github.com/jacobgil/pytorch-grad-cam is a project that has a comprehensive collection of Pixel Attribution Methods for PyTorch (like the package name grad-cam that was the original algorithm implemented).\n Typically pixel attribution methods are adapted for classification: they let you understand what part of the image correspond to a certain classification category.\n However some deep learning models output embeddings instead of category scores.You can then match these embeddings against other embeddings and measure their similarity. For example: in face recognition models, or in self supervised networks.\n In this case to apply pixel attribution, we could create embeddings of concepts, and then for new query images we would be asking: \"what parts of the image have feature representations that match the concept features?\"\n Or in other words: \"where in the query image do we see the concepts?\"\n ​\n I wrote a tutorial that shows how to use the pytorch-grad-cam project, to adapt pixel attribution for the embedding case, and visualize where different concept feature representations match the image:\n https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/Pixel%20Attribution%20for%20embeddings.ipynb\n An example is the image below. The two left images are \"concept\" images of clouds, and a car.\n Then given a new query image, we can try to see where in the image do we feature representations that match these concepts.\n Given images of concepts and a query image, attribute what parts of the query image match the concepts\n I hope someone finds this useful !\n    submitted by    /u/jacobgil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt9lib/p_adapting_pixel_attribution_methods_for_models/",
          "publishedOn": "2022-03-31T20:59:12.000Z",
          "wordCount": 378,
          "title": "[P] Adapting pixel attribution methods for models that output embeddings",
          "imageUrl": "https://external-preview.redd.it/hNkHJFL_Y7QUpq-mVaOEdwMBH_0G7BjrEA-aYSKuNDg.jpg?auto=webp&s=e80028eac0b3799bb56f29c9a141a8bb24bb0b89"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt8sel/d_does_anyone_know_how_to_create_animations_like/",
          "author": null,
          "description": "I really would like to do some visualization of my ideas. I found the animation in the google ai blog:\n https://ai.googleblog.com/2022/02/4d-net-learning-multi-modal-alignment.html\n Anyone knows how to do this stuff, especially with the flowing lines? Any software suggestions?\n    submitted by    /u/KonArtist01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt8sel/d_does_anyone_know_how_to_create_animations_like/",
          "publishedOn": "2022-03-31T20:23:04.000Z",
          "wordCount": 286,
          "title": "[D] Does anyone know how to create animations like in the Google AI Blog?",
          "imageUrl": "https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?auto=webp&s=d45552298a94c0bc0e771853afe179cbb0e3f951"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt7q5h/d_data_centric_fixes_to_a_model_thats_fit_to_a/",
          "author": null,
          "description": "Say a computer vision model learns a pattern you don't want it to, you know that it's learnt it because of analysis through tools like occlusion sensitivity map.\n What data-centric techniques can you use to resolve it? Could some form of cropping augmentation do the trick?Classic example is ruler beside melanoma, while there may be a correlation between presence of ruler and presence of melanoma you don't want to the model to depend on that information because it may not exist 'in production'. Below is a quotation describing another similar problem.\n \"In another paper a similar issue was found because doctors sometimes use purple markers to highlight potentially-malignant skin cancers for easier examination. Some argue that the purple marks are a real signal that should be incorporated in the model just as the visual appearance of the tumor itself is incorporated. However, if your goal is robust generalizability over time it is probably best to not have your AI incorporate the human applied purple marks as signal, as the standards for applying those marks may vary across teams and across time.\" https://menloml.com/2020/01/11/recognizing-a-ruler-instead-of-a-cancer/\n f you're working with that dataset, what tools are available to you to solve that problem?\n    submitted by    /u/Georgehwp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt7q5h/d_data_centric_fixes_to_a_model_thats_fit_to_a/",
          "publishedOn": "2022-03-31T19:34:38.000Z",
          "wordCount": 308,
          "title": "[D] Data centric fixes to a model that's fit to a spurious correlation",
          "imageUrl": "https://external-preview.redd.it/F6AGihc6sjMmnVLm-XWIe0jcP2vPZpBwjOqH2PhZX-c.jpg?auto=webp&s=13353f39561ed11ccd79ec9880d3b36c19dcc81c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt4abi/p_marketing_mix_modeling_how_can_we_solve_for/",
          "author": null,
          "description": "Hi everyone\n I'm working on a Marketing Mix Modeling project for a client\n I'm using Python and sci-kit learn library to do regression analysis with Ridge and Linear Regression.\n I have pretty good results:\n R^2=0.87\n mape= 0.2\n But some of my media coefficients are negative\n And this doesn't make sense business-wise\n How can I model positive media coefficients without using Bayesian modeling?\n    submitted by    /u/datagabriele  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt4abi/p_marketing_mix_modeling_how_can_we_solve_for/",
          "publishedOn": "2022-03-31T16:59:06.000Z",
          "wordCount": 830,
          "title": "[P] Marketing Mix Modeling - How can we solve for negative Media Coefficients?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt3qor/r_projunn_efficient_method_for_training_deep/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2203.05483\n TL;DR; from LeCun: Recurrent nets in which the weight matrix is unitary are interesting beasts: they are invertible, they don't suffer from vanishing/exploding gradient, and they perform computation akin to what happens in quantum computers. training them can be difficult or expensive. We propose a low-rank (low-cost) update method to update unitary weight matrices with gradient descent.\n Abstract: In learning with recurrent or very deep feed-forward networks, employing unitary matrices in each layer can be very effective at maintaining long-range stability. However, restricting network parameters to be unitary typically comes at the cost of expensive parameterizations or increased training runtime. We propose instead an efficient method based on rank-k updates -- or their rank-k approximation -- that maintains performance at a nearly optimal training runtime. We introduce two variants of this method, named Direct (projUNN-D) and Tangent (projUNN-T) projected Unitary Neural Networks, that can parameterize full N-dimensional unitary or orthogonal matrices with a training runtime scaling as O(kN^2). Our method either projects low-rank gradients onto the closest unitary matrix (projUNN-T) or transports unitary matrices in the direction of the low-rank gradient (projUNN-D). Even in the fastest setting (k=1), projUNN is able to train a model's unitary parameters to reach comparable performances against baseline implementations. By integrating our projUNN algorithm into both recurrent and convolutional neural networks, our models can closely match or exceed benchmarked results from state-of-the-art algorithms.\n    submitted by    /u/lostmsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt3qor/r_projunn_efficient_method_for_training_deep/",
          "publishedOn": "2022-03-31T16:34:13.000Z",
          "wordCount": 335,
          "title": "[R] projUNN: efficient method for training deep networks with unitary matrices",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt21k9/d_are_text_embeddings_tabular_data/",
          "author": null,
          "description": "I keep hearing that NNs are not the best way to approach tabular data. But when it comes to document classification, in terms of using embeddings for a downstream classification task, would that be considered tabular data? You will end up with data that fits in a table that you wish to classify...it's high dimensional but you could reduce dimensions until you end up with just a smaller set of columns and the labels. \n I guess I'm unclear about what defines tabular data in this context, and if it makes sense to use a different model (like XBGboost) for the classification task, vs having it as a final layer in the embedding network.\n    submitted by    /u/bandalorian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt21k9/d_are_text_embeddings_tabular_data/",
          "publishedOn": "2022-03-31T15:16:49.000Z",
          "wordCount": 918,
          "title": "[D] Are text embeddings tabular data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsyt3l/r_causal_inference_in_natural_language_processing/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2109.00725\n Abstract: A fundamental goal of scientific research is to learn about causal relationships. However, despite its critical role in the life and social sciences, causality has not had the same importance in Natural Language Processing (NLP), which has traditionally placed more emphasis on predictive tasks. This distinction is beginning to fade, with an emerging area of interdisciplinary research at the convergence of causal inference and language processing. Still, research on causality in NLP remains scattered across domains without unified definitions, benchmark datasets and clear articulations of the remaining challenges. In this survey, we consolidate research across academic areas and situate it in the broader NLP landscape. We introduce the statistical challenge of estimating causal effects, encompassing settings where text is used as an outcome, treatment, or as a means to address confounding. In addition, we explore potential uses of causal inference to improve the performance, robustness, fairness, and interpretability of NLP models. We thus provide a unified overview of causal inference for the computational linguistics community.\n    submitted by    /u/bikeskata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsyt3l/r_causal_inference_in_natural_language_processing/",
          "publishedOn": "2022-03-31T12:37:13.000Z",
          "wordCount": 277,
          "title": "[R] Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsxu8x/p_aiy_vision_kit/",
          "author": null,
          "description": "Working on a group project for college, utilizing a AIY Vision kit and implementing some variation of machine learning with it. The initial idea was to use the camera to identify playing cards and sorting them into groups, like different suits, odd/even, face and non face, but after meeting with the professor in charge, was informed that this idea of identifying and sorting is not really marketable. I tried explaining that sorting in the different ways could be used in many different applications and businesses, but still was told it was not really marketable. I was wondering if maybe there was a way to tweak it a bit to make it so, or if maybe turning it into an API would help. Any ideas and/or opinions on the project would be very helpful. Thank you very much.\n I understand this may fall under beginner related questions and project, but was curious to know if my group and I are on a right track or not, as we haven’t had any sort of guidance up to date.\n    submitted by    /u/EETQuestions  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsxu8x/p_aiy_vision_kit/",
          "publishedOn": "2022-03-31T11:40:27.000Z",
          "wordCount": 266,
          "title": "[P] AIY Vision Kit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsxj8q/d_what_kind_of_teams_do_you_work_on/",
          "author": null,
          "description": "I am looking to stand up a small ML group in my non big tech but pretty big organization. We have a few use cases, only see the list growing, and would like to have a dedicated group rather than having disparate teams each trying to roll their own algorithms for their own applications. I am starting to look at what the costs might be, and I can see some pushback and lowballing (eg onshore/offshore, skill set, % junior/senior), but I don’t have a lot of stories to start my thoughts with, let alone data. So, I’m interested to know what your teams are like to start thinking about it, and any other data or literature would also be appreciated!\n    submitted by    /u/Stranger_Dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsxj8q/d_what_kind_of_teams_do_you_work_on/",
          "publishedOn": "2022-03-31T11:20:43.000Z",
          "wordCount": 221,
          "title": "[D] What kind of teams do you work on?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsvfor/r_china_researches_brainscale_ai/",
          "author": null,
          "description": "https://mixed-news.com/en/artificial-intelligence-china-researches-brain-scale-ai/\n In China, the state and companies are researching AI models with trillions of parameters. They want to prove that they can develop “brain-scale” AI.\n In the race to build ever-larger AI models, China is showing that cooperation between the state, universities and the private sector holds the potential for gigantic AI models. The researchers are talking about “brain-scale” AI: according to their definition, these are AI models with parameters beyond the 100-trillion mark.\n ...\n In a new paper, researchers from Tsinghua University, Alibaba Group, Zhejiang Lab and Beijing Academy of Artificial Intelligence present BaGuaLu, a framework that enables the training of large AI models using the Mixture-of-Experts (MoE) architecture.\n ...\n In an initial test, the researchers trained a 1.93 trillion model with their framework, outperforming Google’s Switch Transformer. They also demonstrate that their framework enables models with 14.5 trillion and a full 174 trillion parameters.\n ...\n BaGuaLu could soon be used to train the first models beyond 100 trillion parameters.\n    submitted by    /u/Zirius_Sadfaces  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsvfor/r_china_researches_brainscale_ai/",
          "publishedOn": "2022-03-31T08:47:59.000Z",
          "wordCount": 467,
          "title": "[R] China researches “brain-scale” AI",
          "imageUrl": "https://external-preview.redd.it/JhZYBigKAty1Eq96lCCsaxYnvApivFIyrmwoeLVCjDk.jpg?auto=webp&s=70729ea061997be594080e36d0fcf14e4b9aff66"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsvc7m/d_coreset_terrible_perfomance_on_datasets_with_a/",
          "author": null,
          "description": "Hello reddit hivemind,\n This might be a quite specific question but im not sure where else to go and ask. I'm currently an intern and charged with implementing and comparing different active learning algorithms to see which work best for our specific usecase. Since the coreset approach ( [1708.00489] Active Learning for Convolutional Neural Networks: A Core-Set Approach (arxiv.org) ) is now around for a long time, one of the best documented and shows promising results in a variety of papers I implemented it and ran some experiments with it. The results were a bit dissappointing. It got even outperformed by the random baseline .... To understand the bad performance I dug a bit deeper since I spend a significant amount of time implementing it. What I made out now as the issue is using the l_2 norm of penultimate layer as the metric. This leads to an oversampling of data samples with a certain softmax output due to the way the softmax function behaves. Has someone experienced the same issues? The only point where I could see coreset to be of some use is with a dataset that has a ton of redundant/similar images.\n Thank's a lot\n    submitted by    /u/Fearless-Pumpkin-745  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsvc7m/d_coreset_terrible_perfomance_on_datasets_with_a/",
          "publishedOn": "2022-03-31T08:40:25.000Z",
          "wordCount": 362,
          "title": "[D] Coreset terrible perfomance on Datasets with a lot of redundancy",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsv4sv/r_reinforcement_learning_in_finance_research/",
          "author": null,
          "description": "Hello, I hope that this message finds you in good health\n FinRL: Deep Reinforcement Learning for Quantitative Finance https://github.com/AI4Finance-Foundation/FinRL is a project from Columbia University. It offers environments for cryptocurrency, paper trading, stock trading, and forex trading. Also, it has support for three reinforcement learning libraries: Stable Baselines3, RLlib, and ElegantRL. This is from AI4Finance-foundation and it aims to provide a plug-play platform for RL in finance. Do check it out and help us to improve this project\n Some resources:\n  \nMy contributions: https://medium.com/@athekunal/list/finrl-contributions-59de6997c5b1\n Resources to learn FinRL: https://github.com/AI4Finance-Foundation/FinRL#tutorials\n All tutorial notebooks: https://github.com/AI4Finance-Foundation/FinRL/tree/master/tutorials\n YouTube Channel: https://www.youtube.com/channel/UCrVri6k3KPBa3NhapVV4K5g\n  \n   submitted by    /u/A_the_kunal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsv4sv/r_reinforcement_learning_in_finance_research/",
          "publishedOn": "2022-03-31T08:24:27.000Z",
          "wordCount": 185,
          "title": "[R] Reinforcement Learning in Finance research",
          "imageUrl": "https://external-preview.redd.it/26WP_8wiR4eM6G0YebGmMkj2k6iO24IWXjkX2zAG8Eg.jpg?auto=webp&s=febf91202e8cc5f45f9bc0a588436e70101652d3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsv020/p_point_cloud_annotation_tool/",
          "author": null,
          "description": "Hi Everyone,\n Some time ago, we had the idea to start building tools to facilitate 3D computer vision development. We started by looking at some of the 3D tools out there and realized that there wasn't anything that fit our needs or could be extended to do some of the things we wanted to do. \n We started working on a tool to annotate point clouds with different label types (bounding box, rectangles, keypoints) to use as a base for our projects. We recently open sourced the tool, which you can find here: https://github.com/StrayRobots/3d-annotation-tool\n In the future we might add more tools, for example to paint point clouds or a polygon label type. \n We would love to hear your feedback on the tool. Has anyone here built any 3D vision datasets? What kind of tools did you use?\n    submitted by    /u/slash-dot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsv020/p_point_cloud_annotation_tool/",
          "publishedOn": "2022-03-31T08:14:01.000Z",
          "wordCount": 222,
          "title": "[P] Point Cloud Annotation Tool",
          "imageUrl": "https://external-preview.redd.it/3QUD2bNaGQoxY2OfIVK2louOdnTZ_QFvFFNCaliXQdc.jpg?auto=webp&s=bceaea6359ae85e790f73def5f80e862642d4e9f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsutvx/dis_it_just_me_or_is_machine_learning_difficult/",
          "author": null,
          "description": "Hello, \n My Background:\n I work as a web dev for almost 2 years. Before that when I was studying in college, I thought ML is the only field which was in demand. I put my 100% into it but the professor was so bad that not only me but a lot of my peers found ML,DS to be very difficult. We were able to built project around but never tried to learn more. \n I tired many udemy or coursea courses but never found it engaging. \n Is it just me or did you also found ML difficult? Is my approach to learning it wrong? If anyone has any advice I'd really appreciate it\n    submitted by    /u/Notalabel_4566  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsutvx/dis_it_just_me_or_is_machine_learning_difficult/",
          "publishedOn": "2022-03-31T08:00:41.000Z",
          "wordCount": 889,
          "title": "[D]Is it just me or is machine learning difficult to learn?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsu81d/d_how_to_combine_multimodal_data_of_different/",
          "author": null,
          "description": "I'm currently working on a project related to multimodal summarization using transformers.\n My input is a image and long text and output will be a summary of the text pertaining to the image.\n ​\n For extracting image features, I'm using pretrained resnet model. It gives me a [49 * 2048] vector for an image.\n For extracting paragraph features, I'm getting embeddings for each sentence, so the data_dimension will be [no_of_sentences * 512]\n ​\n I need to attend to both these set of features and generate output. I have gone through tutorials to understand the working of transformers but couldn't understand how to combine these into a single input so that the encoder can attend over both image and the paragraph together at the same time.\n ​\n Any pointers to tutorials will be very helpful.\n    submitted by    /u/abisekrk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsu81d/d_how_to_combine_multimodal_data_of_different/",
          "publishedOn": "2022-03-31T07:14:22.000Z",
          "wordCount": 287,
          "title": "[D] How to combine multimodal data of different sequence lengths in training?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tssy7n/n_an_open_letter_to_deepminders/",
          "author": null,
          "description": "Yesterday, an anonymous open letter and accompanying Financial Times (paywall) article were published accusing DeepMind of mishandling allegations of sexual abuse by a senior member of the research team. \n The FT article (reported on here in Fortune) goes on to suggest that the mishandling may have been deliberate in order to exploit legal loopholes in the UK where victims have a limited amount of time to take a case to employment tribunal. \n This comes shortly after Mustafa Suleyman, one of the cofounders was quietly shuffled out to Google (he has subsequently left and founded a new startup with another DeepMind alum) after he was found to have bullied and humiliated staff for years.\n Google itself also has a poor record when it comes to sexual harassment, bullying and retaliation at the highest levels resulting in payouts of hundreds of millions of dollars. \n Given that DeepMind and Google have a pretty strong grip on the development of AI in terms of employing many of the key people across many of the various subfields, having access to unparalleled data and compute and pushing forward more and more into health (for example the DeepMind offshoot Isomorphic Labs which itself is headed by Demis and staffed by DeepMinders, and the various Google healthcare bets and projects), can we really trust them to be stewards of fair and responsible AI development? \n Bad things happen in all large organizations. But DeepMind isn’t that big and in the past five years, DeepMind leadership have presided over a steady stream of sexual harassment, bullying and other scandals and handled them all extremely poorly and showed little signs that things have changed. This points to something rotten in the culture and leadership there and at it’s parent organization.\n    submitted by    /u/ml-anon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tssy7n/n_an_open_letter_to_deepminders/",
          "publishedOn": "2022-03-31T05:44:33.000Z",
          "wordCount": 984,
          "title": "[N] An open letter to DeepMinders",
          "imageUrl": "https://external-preview.redd.it/woxo4bvgGvm5mdcr1peGe8hkoBpqRx8189TaYW5w5ic.jpg?auto=webp&s=4dc20b15a9e8b4dd512b3e4cc699ec742e61a6a7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsrdhl/d_use_of_kesler_construction_for_multiclass/",
          "author": null,
          "description": "I noticed that in some literature they use the Kesler construction when discussing multi-class prediction: https://uclanlp.github.io/CS269-17/slides/CS269-03.pdf. Why do they do this versus represent all the w_i vectors in a K x N matrix, where N is the length of x and K is the number of classes, and then generate Wx = [w1^Tx, ..., wKx], which will essentially produce the same result but be more efficient because of the lack of zero multiplications which are in the Kesler construction?\n    submitted by    /u/newperson77777777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsrdhl/d_use_of_kesler_construction_for_multiclass/",
          "publishedOn": "2022-03-31T04:05:43.000Z",
          "wordCount": 177,
          "title": "[D] Use of Kesler Construction for Multi-class Prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsmryt/r_making_robots_achieve_tasks_like_animals_with/",
          "author": null,
          "description": "This work from Berkeley + Google Brain (Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions) describes using RL and GANs for transferring motion styles from animals successfully onto robots. \n Super neat idea, and love to see ML being used more and more on real robots!\n Love the Cost of Transport analysis - naturalistic movement really is very efficient, and good luck getting RL to solve the hard exploration problem of good motion and task performance simultaneously tabula rasa!\n In particular I love this image. Down with hand specified reward functions! Let imitating nature reign supreme.\n What's next, GANs for moral style transfer?\n    submitted by    /u/AristocraticOctopus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsmryt/r_making_robots_achieve_tasks_like_animals_with/",
          "publishedOn": "2022-03-30T23:55:18.000Z",
          "wordCount": 210,
          "title": "[R] Making Robots Achieve Tasks Like Animals with Style Transfer + RL",
          "imageUrl": "https://external-preview.redd.it/VURBVjzpmMi0ax-TyZhzmNterlDvl4_-ID9S6MsC46M.jpg?auto=webp&s=e9f8b9fbbf84cb8168b896a8346523e9c2c9f390"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsitmb/d_low_mpjpe_and_low_pck_and_auc/",
          "author": null,
          "description": "So in the pose estimation landscape (specifically 3D) there are 3 common evaluation metrics MPJPE (mean per joint precision error measured in mm), PCK (percent correct keypoints measured at a 150mm threshold) and then AUC. One oddity I have noticed when training a few models is that a model with a lower MPJPE then some methods does not alwayshave a higher PCK (higher is better for this metric) but the mean joint precsion error is substantially below the threshold used for PCK (I do recognize that this metric is an average). \n ​\n Does anyone have any experience with this, seen the same behavior, or have any intuition why this would be occurring?\n    submitted by    /u/AbjectDrink3276  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsitmb/d_low_mpjpe_and_low_pck_and_auc/",
          "publishedOn": "2022-03-30T20:47:35.000Z",
          "wordCount": 208,
          "title": "[D] Low MPJPE and low PCK and AUC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsigde/r_a_conversational_paradigm_for_program_synthesis/",
          "author": null,
          "description": "submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsigde/r_a_conversational_paradigm_for_program_synthesis/",
          "publishedOn": "2022-03-30T20:30:45.000Z",
          "wordCount": 94,
          "title": "[R] A Conversational Paradigm for Program Synthesis",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsid21/r_training_computeoptimal_large_language_models/",
          "author": null,
          "description": "submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsid21/r_training_computeoptimal_large_language_models/",
          "publishedOn": "2022-03-30T20:26:33.000Z",
          "wordCount": 191,
          "title": "[R] Training Compute-Optimal Large Language Models. From the abstract: \"We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant.\"",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsfppe/d_some_challenges_that_must_be_taken_care_of/",
          "author": null,
          "description": "More than a year ago, I wrote an article regarding some key obstacles that someone may face regarding working with AI in the medical field. A few days ago I submitted that article to \"Towards Data Science\", a 'Medium' based online publication. It got published yesterday. I am giving the link here. If anyone is interested in that topic, you can take a look. It mainly focuses on the part that - even if you have some previous experience in working with machine learning, there are some things you must know and be aware of before working with medical datasets. Link - https://towardsdatascience.com/some-key-challenges-in-building-an-ai-model-for-medical-diagnosis-63f7438f14a\n    submitted by    /u/ishtiakmahmud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsfppe/d_some_challenges_that_must_be_taken_care_of/",
          "publishedOn": "2022-03-30T19:38:50.000Z",
          "wordCount": 222,
          "title": "[D] Some challenges that must be taken care of while working with ML using medical data",
          "imageUrl": "https://external-preview.redd.it/9-Jyevv4atlG7KMN0YirFJNE6IknmhnIvI681bAUJjY.jpg?auto=webp&s=0898e807c680005ebdd0d50df6b2850f819541af"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsffzi/d_is_quantum_ml_pointless/",
          "author": null,
          "description": "Today Google had a webinar on Tensorflow Quantum for big data, which I attended. I was surprised that it was almost all quantum computing theory, but there was a link in the talk resources to Tensorflow Quantum where I was told I could find a tutorial with demo code for a classifier system to compare it to my classical approaches -- I use logistic regression, support vector machine, and Tensorflow DNN classifiers; mostly SVM because it works almost as accurately on my job's data sets as DNNs but takes a tiny fraction of the time to train.\n So, I took a look at it: https://www.tensorflow.org/quantum/tutorials/mnist\n This was the first sign that quantum classification might not be a viable alternative:\n  \nAn image size of 28x28 is much too large for current quantum computers.\n -- https://www.tensorflow.org/quantum/tutorials/mnist#12_downscale_the_images\n  \nYou really have to see it to believe it, but this demo requires downscaling legible digits for handwriting recognition to 4-by-4 pixel completely indiscernible blobs! Resulting in, as you might expect, terrible accuracy. A classical model using the full resolution images achieves 99.9%+ accuracy in relatively almost no time to train.\n So I scrolled down to the \"Comparison\" section and saw this:\n  \na classical model of similar power (~32 parameters) trains to a similar accuracy in a fraction of the time. One way or the other, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network.\n  \nThe remainder of the tutorial didn't offer any improvement. The \"quantum convolutional\" NN classifier wasn't any better in speed or accuracy.\n  \nSo, am I correct in assuming that I am best off ignoring quantum computing for classification tasks for the foreseeable future?\n How long do you think it will be until quantum ML can compete on real-world problems?\n    submitted by    /u/Competitive_Travel16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsffzi/d_is_quantum_ml_pointless/",
          "publishedOn": "2022-03-30T19:36:14.000Z",
          "wordCount": 1217,
          "title": "[D] Is quantum ML pointless?",
          "imageUrl": "https://external-preview.redd.it/VJG_v5pS1UlsunnyMTpCImDzpp8RvxLtAgF4Fp1drDw.jpg?auto=webp&s=877bc8e94abb5f14b2e1ed87a222488f8b415e70"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsd28t/r_codegen_up_to_161b_code_generating_transformer/",
          "author": null,
          "description": "https://twitter.com/erik_nijkamp/status/1508956485379715072\n Paper: https://arxiv.org/abs/2203.13474\n Blog: https://blog.salesforceairesearch.com/codegen/\n Code: https://github.com/salesforce/CodeGen\n    submitted by    /u/lucidraisin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsd28t/r_codegen_up_to_161b_code_generating_transformer/",
          "publishedOn": "2022-03-30T18:31:35.000Z",
          "wordCount": 117,
          "title": "[R] CodeGen (up to 16.1B code generating transformer trained on TPU-v4) is open-source",
          "imageUrl": "https://external-preview.redd.it/v4L76FMpJgH6HQXUBUbyZPpMX-bYPiCfuxBx3XrcM-g.jpg?auto=webp&s=63c58763cc5f6a59b8ce473091217ad6f3905712"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts8omj/d_do_you_know_application_fields_in_the_sector_of/",
          "author": null,
          "description": "Self-Synchronizing Oscillators are mainly a hardware-software combination that uses swinging oscillators for decentral synchronization of distributed units without a central steering element. It is a new approach to synchronize two or more entities with another. Instead of relying on a central clock which the other ones communicate with, this technology is mutually or naturally synchronized, so both entities know at any time what the other one is doing.\n My question would be, are there any possible application fields you could think of for this technology?\n    submitted by    /u/mikeseboss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts8omj/d_do_you_know_application_fields_in_the_sector_of/",
          "publishedOn": "2022-03-30T15:14:25.000Z",
          "wordCount": 274,
          "title": "[D] Do you know application fields in the sector of machine learning where precise coordination might play a role?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts81uq/d_predicting_and_correcting_error_of_a_simple/",
          "author": null,
          "description": "I tried to keep the title somewhat general in case my problem is interesting for others, but before continuing with the discussion I'll introduce some specifics to make it easier to talk about the specific problem.\n I'm a fluid dynamics engineer, in particular a CFD engineer (fluid simulations and such), working on a phenomenon known as cavitation on hydrofoils.\n The most common way to perform a full simulation for a cavitating hydrofoil requires approximately 8 hours to run on a 512 cores.\n I'm currently working on an approximate model that solves the same problem in less than a minute on a common laptop. Of course, as an approximate model it is less faithful than the full model, with the relative error increasing or decreasing as some of the foilparameters change.\n Namely, a foil is defi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts81uq/d_predicting_and_correcting_error_of_a_simple/",
          "publishedOn": "2022-03-30T14:45:24.000Z",
          "wordCount": 540,
          "title": "[D] Predicting and correcting error of a simple model with a lot of data against a much more complex model with less data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts7rta/dp_guidance_required_for_solving_a_unique_problem/",
          "author": null,
          "description": "Hello All,\n I am currently working on the project wherein I have to apply DL to CFD simulations. The simulation data is basically a set of 2d points (x,y) and their corresponding velocity and pressure values. I have such data for a 100 timesteps. The goal is to predict the flow(i.e. velocity and pressure) for each grid point for the last time step. I was thinking of reshaping the data in the form of a square so that I can use a CNN, but using a CNN wouldn't take care of the time dependence between the data. Is there a hybrid approach I can use that can take care of both temporal and spatial dependencies?\n ​\n Really need some guidance. Even any unrelated advice would be much appreciated. Thank you in advance!\n ​\n Edit: Also needed some help with regards to making the dataset. I have 100 csv files, each file corresponding to one time step. Each file contains the pressure and velocities of around 900 points. How do I make a dataset out of this either in pytorch or tensorflow?\n    submitted by    /u/Hour_Amphibian9738  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts7rta/dp_guidance_required_for_solving_a_unique_problem/",
          "publishedOn": "2022-03-30T14:32:31.000Z",
          "wordCount": 486,
          "title": "[D],[P] Guidance required for solving a unique problem in application of DL in CFD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts4vbq/d_how_dstack_works/",
          "author": null,
          "description": "Hi everyone, I’m the creator of dstack, an open-core tool to train models and manage data. I’ve just published a post where I elaborated on the challenges AI researchers face today when training models, and how we at dstack aim to address them. In the post, you may find the details on the design decision we made for our tool. \n Blog post: https://blog.dstack.ai/p/how-dstack-works\n Invite everyone to read it, and share their thoughts. Happy to discuss the future of the developer tooling for training models!\n    submitted by    /u/cheptsov  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts4vbq/d_how_dstack_works/",
          "publishedOn": "2022-03-30T12:02:15.000Z",
          "wordCount": 196,
          "title": "[D] How dstack works",
          "imageUrl": "https://external-preview.redd.it/NMDuEknhgjAtqwsrqtHhYwr4E94Rrdtbflmw0NVYdFU.jpg?auto=webp&s=04373965af0ab6f94849b024ac4b1d70002ab7a2"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts3wsb/r_differentiable_conv_layer_using_fft/",
          "author": null,
          "description": "This is convolutional layer for torch using fourier transform. I wouldn't be surprised if this already existed somewhere, but I could not find one with derivatives. \n This is meant to be a drop in replacement for torch.Conv. It should be performant on kernel sizes above 20, depending on implementation. \n One interesting thing, even if a person already had one of these, is the way the bias and bias gradient were calculated. It only cost O(out_channels), ignoring the data size entirely.\n github\n    submitted by    /u/MKmisfit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts3wsb/r_differentiable_conv_layer_using_fft/",
          "publishedOn": "2022-03-30T11:04:46.000Z",
          "wordCount": 571,
          "title": "[R] Differentiable Conv Layer using FFT",
          "imageUrl": "https://external-preview.redd.it/Lgb5lDL4I-tLRZZZhpoLQeEyYwL555lbScwI5o7n3-Q.jpg?auto=webp&s=7aadb156963927e0808d13a7daa2347d29db5288"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts3k7z/r_fully_unsupervised_multidomain_imagetoimage/",
          "author": null,
          "description": "The code of \"A Style-aware Discriminator for Controllable Image Translation\" has been released! This is a novel multi-domain image-to-image translation method, which is fully unsupervised, and provide various applications, including style interpolation, content transplantation, and local image translation.\n Example of the prototype-guided synthesis\n Example of the reference-guided synthesis\n Paper: https://arxiv.org/abs/2203.15375\n Code: https://github.com/kunheek/style-aware-discriminator\n    submitted by    /u/graysp4rrow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts3k7z/r_fully_unsupervised_multidomain_imagetoimage/",
          "publishedOn": "2022-03-30T10:42:37.000Z",
          "wordCount": 186,
          "title": "[R] Fully unsupervised multi-domain image-to-image translation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts3dqg/d_any_well_known_approaches_to_compare_two_sets/",
          "author": null,
          "description": "Say given an MLP of 2 layers with non-linearity, are there established papers which explore if the sets of weights obtained after 2 trials of training end up with 'similar' weights.\n From an old stackexchange thread(2017) two possible methods outlined are. 1. Compare similarity on the predictions on validation inputs. 2. Instead of comparing pairwise similarity, simply concat them and use t-sne for dimensionality reduction. Based on a 2009 work.\n Link: https://cs.stackexchange.com/questions/74488/measuring-difference-between-two-sets-of-neural-network-weights\n Does anyone know of any recent work which tackles this problem ?\n    submitted by    /u/PaganPasta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts3dqg/d_any_well_known_approaches_to_compare_two_sets/",
          "publishedOn": "2022-03-30T10:30:32.000Z",
          "wordCount": 685,
          "title": "[D] Any well known approaches to compare two sets of neural network weights ?",
          "imageUrl": "https://external-preview.redd.it/62kLd8L6dwu0tEncBgcuLw_o-vkyeE6sZ4Rb720w_vY.jpg?auto=webp&s=ee5f3d315567f7cbde47ca378d48b3ea1cf250b7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts19ao/d_stable_reference_for_candidate_ops_in_nas/",
          "author": null,
          "description": "Good day, my fellow researchers and engineers.\n Recently I'm on research about neural architecture search. While reading through tons of papers about neural architecture search, I just got curious about 'how do we predefine primitive operations?' Because most of the paper goes like 'we have these ops in candidates, and we searched through candidates so elegantly...' I mean, how do we know we've predefined our candidates well? Is there any reference to 'good ops candidates'? I know certain cells and ops are often used in certain tasks, but still, I want to find a robust reference about 'The ops candidates for NAS'.\n It will cure my high blood pressure if you guys give your precious opinions about it.\n    submitted by    /u/KindAd9527  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts19ao/d_stable_reference_for_candidate_ops_in_nas/",
          "publishedOn": "2022-03-30T07:49:58.000Z",
          "wordCount": 327,
          "title": "[D] Stable Reference for candidate ops in NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts0wad/rintroducing_causal_inference_in_the/",
          "author": null,
          "description": "submitted by    /u/Mammoth-Ad-5527  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts0wad/rintroducing_causal_inference_in_the/",
          "publishedOn": "2022-03-30T07:22:23.000Z",
          "wordCount": 102,
          "title": "[R]Introducing causal inference in the energy-efficient building design process",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts0fcs/d_why_does_almost_no_one_study_weakly_supervised/",
          "author": null,
          "description": "I notice that there is almost no papers in this area since 2020. And the rank of WSOD hasn't been updated since 2020:https://paperswithcode.com/sota/weakly-supervised-object-detection-on-pascal-1\n    submitted by    /u/voclee4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts0fcs/d_why_does_almost_no_one_study_weakly_supervised/",
          "publishedOn": "2022-03-30T06:48:46.000Z",
          "wordCount": 628,
          "title": "[D]: Why does almost no one study \"Weakly Supervised Object Detection\"(WSOD) since 2020?",
          "imageUrl": "https://external-preview.redd.it/Yu7ffWTmZA4SI7v3owcUV2qpJ66ddbDE0wFMc9Cuzc0.jpg?auto=webp&s=3ef2187bdd0ffdd620a4b25e3088664744a3a48b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts0dfs/d_recursive_error_prediction/",
          "author": null,
          "description": "I had an idea recently for a ML regression strategy and I'm just wondering if something like this already exists. It has similarities with both boosting and bagging, but I think it's ultimately different from both.\n The basic idea is that you start with a subset of input features and train a model on that subset. Any common model will do as long as it doesn't just spit out the exact target value when making a prediction on the training set (i.e., you couldn't use a 1-neighbor KNN). After fitting the model, you make predictions on the training set (with the same subset of features) and calculate the prediction errors.\n Then using another subset of features (I would think it should be mutually exclusive from the first subset but maybe it doesn't have to be), you train a separate model, but rather than training on the original Y training data, you use the error of the previous model as the target for the second model.\n You repeat this process until all features have been used or as many times as desired. To make a prediction, the parent model would simply sum the predictions of the child models.\n As an additional thought, you might use more regularization, larger leaf size for decision trees, etc. for each additional model. You could also use bagging to create multiple instances of the strategy with different feature subsets in order to create multiple \"pathways\" through the data.\n A few questions:\n  \nIs this sufficiently different from existing boosting/bagging techniques?\n If yes to #1, are there any existing packages (preferably in Python) that implement this kind of technique?\n Could this be used to reduce overfitting for higher dimensional datasets? If so, would additional steps need to be taken (e.g., like the iterative regularization scheme I mentioned)? My thought is that it's a kind of divide-and-conquer strategy where each subsequent model is asked to do a little less than the previous model.\n  \nAny thoughts are appreciated.\n    submitted by    /u/JHogg11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts0dfs/d_recursive_error_prediction/",
          "publishedOn": "2022-03-30T06:44:56.000Z",
          "wordCount": 554,
          "title": "[D] Recursive error prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts0757/r_star_bootstrapping_reasoning_with_reasoning/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts0757/r_star_bootstrapping_reasoning_with_reasoning/",
          "publishedOn": "2022-03-30T06:32:24.000Z",
          "wordCount": 122,
          "title": "[R] STaR: Bootstrapping Reasoning With Reasoning",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trzo02/r_pathways_asynchronous_distributed_dataflow_for/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trzo02/r_pathways_asynchronous_distributed_dataflow_for/",
          "publishedOn": "2022-03-30T05:57:29.000Z",
          "wordCount": 104,
          "title": "[R] Pathways: Asynchronous Distributed Dataflow for Machine Learning",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tryeym/n_torchmultimodal_is_a_pytorch_library_for/",
          "author": null,
          "description": "It provides:\n  \nA repository of modular and composable building blocks (models, fusion layers, loss functions, datasets and utilities).\n \nA repository of examples that show how to combine these building blocks with components and common infrastructure from across the PyTorch Ecosystem to replicate state-of-the-art models published in the literature. These examples should serve as baselines for ongoing research in the field, as well as a starting point for future work.\n \n https://github.com/facebookresearch/multimodal\n    submitted by    /u/gurkitier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tryeym/n_torchmultimodal_is_a_pytorch_library_for/",
          "publishedOn": "2022-03-30T04:37:33.000Z",
          "wordCount": 181,
          "title": "[N] TorchMultimodal is a PyTorch library for training state-of-the-art multimodal multi-task models at scale.",
          "imageUrl": "https://external-preview.redd.it/k0zPC35uqP3XjD5mMOdcKZKsN5PTmijyjhqUQLRtock.jpg?auto=webp&s=13251b95cb0fb745cb285463417b6346a425e60b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trvkih/r_ai_simulators_for_assisted_living_from_facebook/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trvkih/r_ai_simulators_for_assisted_living_from_facebook/",
          "publishedOn": "2022-03-30T01:56:47.000Z",
          "wordCount": 108,
          "title": "[R] AI Simulators for Assisted Living (from Facebook, CMU, et al)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trvfjk/r_desiderata_for_representation_learning_a_causal/",
          "author": null,
          "description": "Authors: Yixin Wang, Michael I. Jordan\n Abstract: Representation learning constructs low-dimensional representations to summarize essential features of high-dimensional data. This learning problem is often approached by describing various desiderata associated with learned representations; e.g., that they be non-spurious, efficient, or disentangled. It can be challenging, however, to turn these intuitive desiderata into formal criteria that can be measured and enhanced based on observed data. In this paper, we take a causal perspective on representation learning, formalizing non-spuriousness and efficiency (in supervised representation learning) and disentanglement (in unsupervised representation learning) using counterfactual quantities and observable consequences of causal assertions. This yields computable metrics that can be used to assess the degree to which representations satisfy the desiderata of interest and learn non-spurious and disentangled representations from single observational datasets. \n Paper: https://arxiv.org/abs/2109.03795\n Slides: https://yixinwang.github.io/papers/causal-rep-slides-public.pdf\n    submitted by    /u/bikeskata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trvfjk/r_desiderata_for_representation_learning_a_causal/",
          "publishedOn": "2022-03-30T01:49:27.000Z",
          "wordCount": 227,
          "title": "[R] Desiderata for Representation Learning: A Causal Perspective",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trstl4/d_what_would_a_production_rl_stack_look_like_in/",
          "author": null,
          "description": "I was hoping I could get some insight into the tooling that you use (or would use) for some production RL work? I'm mostly doing it all on my home machine as a fun side project. \n I've got the following existing infrastructure: \n - An interface based loosely on the standard RL setup. I'm thinking about adapting it to fit Acme to let it do more heavy lifting since I quite like `Haiku`, `rlax` and the rest of what they do.\n - I've got some models across languages (Pytorch and Jax) and this has been causing me some headache trying to make sure everything is abstract enough. Should I just stick to one language and make sure all my friends just use that same language? \n - I'm currently using comet-ml for my experiment tracking, and for the most part I like it. However, I'm now looking around to see what's out there and I'm a little overwhelmed by (1) how many tools there are and (2) how some of them seem to \"overlap\" so I don't really know how to compose them.\n - configs all stored in a python file in a separate repo that is kept synced between my other repos.\n - I currently store my agent experiences (off policy) in a database that I later query to rapidly fill up the replay buffer. The limitation is that this is for a single agent. What drew me to Acme is that it seems to allow multiple agents to all use the same buffer? \n _____________\n tl;dr\n 1) Has anyone used Acme? I'm thinking of moving my project to it, but it might end up being a lot of effort for very little reward\n 2) How do you and your teams handle multiple languages? Do you just have abstract gym wrappers that convert data? \n 3) What tools do you use and how do you compose them together? I'm so so lost trying to navigate this space\n 4) How do you keep your configs synced when they are used between repos?\n    submitted by    /u/whynotmehmm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trstl4/d_what_would_a_production_rl_stack_look_like_in/",
          "publishedOn": "2022-03-29T23:28:58.000Z",
          "wordCount": 435,
          "title": "[D] What would a \"Production\" RL stack look like in terms of tooling?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trrpbd/p_i_have_data_with_connections_and_links_but_i/",
          "author": null,
          "description": "My dates are as follows:\n ​\n https://preview.redd.it/9htkypafgeq81.png?width=198&format=png&auto=webp&s=35e5475cf71364b8958b34e6100bd0ada2dc756d\n What I would like is to be able to map the following to a script:\n - Value 1440/1 in column FROM represented value 144019/1 in column TO.\n - Find value 144019/1 again in column FROM.\n - If found, take the value in column TO and find it again in column FROM. Not found, stop searching.\n ​\n Note: value 1440/1 does not have to be the initial value. In my data, 1440/1 can refer to another value again that is from column TO.\n ​\n I would like the following as output:\n - 1440/1, 144019/1, 144019/2;\n - 1440/1, 144018/1, 144018/2, 6038/1.\n    submitted by    /u/Silver-Panda2518  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trrpbd/p_i_have_data_with_connections_and_links_but_i/",
          "publishedOn": "2022-03-29T22:33:06.000Z",
          "wordCount": 228,
          "title": "[P] I have data with connections and links but I don't know how to write a scrip for this. Help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tro8go/d_quantization_aware_training_advice/",
          "author": null,
          "description": "Hi, I'm trying to run QAT on a MobileNetV2 based model but having some issues hitting the same training losses in the QAT phase as I did in the not-QAT phase.\n As a test, I'd trained the network for 1 epoch, then trained the QAT phase for 5 epochs and managed to get the same loss (actually lower). However, after training the model (non-QAT part) for 150 epochs, the QAT phase is really struggling to get down to the same loss.\n In my first test it dropped then completely levelled off for 2-3 epochs then nosedived again for another epoch, I'm not seeing the same in this longer train though.\n I was wondering if anyone has any advice on things like, should the learning rate be reset at the start of the QAT phase or should it carry on from where the training left off? I'm using Adam as the optimiser in the first phase, is that still ok in the second phase. Any other things that I could try? I did read a paper on improving quantization loss in MobileNet by L2 weighting the separable conv weights and swapping out ReLU6 for ReLU but I wasn't really seeing the same benefit as the paper (https://arxiv.org/pdf/1803.08607.pdf) did in my tests, I was getting a worse initial network.\n Thanks for any insight that anyone can provide!\n    submitted by    /u/ColdChancer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tro8go/d_quantization_aware_training_advice/",
          "publishedOn": "2022-03-29T21:57:47.000Z",
          "wordCount": 310,
          "title": "[D] Quantization Aware Training Advice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trno8g/p_interactive_demo_for_paper_sketchedit_maskfree/",
          "author": null,
          "description": "​\n https://reddit.com/link/trno8g/video/84uuyln8ceq81/player\n Hi everyone, here's an interactive demo I made for paper SketchEdit: Mask-Free Local Image Manipulation with Partial Sketches\n Demo: http://47.57.135.203:8001/\n Paper: https://arxiv.org/abs/2111.15078\n Project page: https://zengxianyu.github.io/sketchedit/\n Code: https://github.com/zengxianyu/sketchedit\n    submitted by    /u/Educational_Ebb2502  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trno8g/p_interactive_demo_for_paper_sketchedit_maskfree/",
          "publishedOn": "2022-03-29T21:45:39.000Z",
          "wordCount": 163,
          "title": "[P] Interactive Demo for Paper SketchEdit: Mask-Free Local Image Manipulation with Partial Sketches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trm12l/d_dailyml_quiz_a_very_high_variance_means_the/",
          "author": null,
          "description": "Yesterday's answer: Pandas\n View Poll\n    submitted by    /u/daichrony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trm12l/d_dailyml_quiz_a_very_high_variance_means_the/",
          "publishedOn": "2022-03-29T21:08:42.000Z",
          "wordCount": 127,
          "title": "[D] DailyML quiz: A very high variance means the model likely has…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trjiul/pn_compilergym_tutorial_cgo/",
          "author": null,
          "description": "This weekend we (Hugh, Mostafa, and Chris from Meta AI) will be running a tutorial on Autotuning and Reinforcement Learning for compilers using CompilerGym at CGO’22. Join us for a hands-on session that takes you from “zero to RL” in three hours! The tutorial stats 1:30pm ET on Saturday April 2nd. Full schedule:\n https://conf.researchr.org/program/cgo-2022/program-cgo-2022/?date=Sat%202%20Apr%202022\n    submitted by    /u/melhoushi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trjiul/pn_compilergym_tutorial_cgo/",
          "publishedOn": "2022-03-29T20:34:32.000Z",
          "wordCount": 147,
          "title": "[P][N] CompilerGym Tutorial @ CGO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trgzx4/rlooking_for_papers_with_date_inference_from_text/",
          "author": null,
          "description": "Hey all,\n I'm going through research to figure out how the Date Inference protocols might be implemented. Given a text containing the phrase \"5 days from now\", I would need it to infer the date April 3rd. The 'now' part is a trivial problem, but the inference is something I'm struggling with. I could use regex but all the possible edge cases are tricky. \n The inference would need to work on unstructured cases like \"April 23rd\", \"Next Sunday\", etc. It would need to work forwards and backward (5 days ago etc.)\n ​\n Any great papers/resources? I searched for date inference, but nothing similar to what I'm looking for\n    submitted by    /u/ISeeThings404  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trgzx4/rlooking_for_papers_with_date_inference_from_text/",
          "publishedOn": "2022-03-29T20:03:03.000Z",
          "wordCount": 224,
          "title": "[R]Looking for papers with Date Inference from text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trglxa/research_audiotagging_done_right_2nd_comparison/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2203.13448\n Code: https://github.com/lijuncheng16/AudioTaggingDoneRight\n For anyone who's interested in AudioSet (2million youtube videos' sound). This is the SOTA comparison of models and training procedures.\n    submitted by    /u/billyli_16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trglxa/research_audiotagging_done_right_2nd_comparison/",
          "publishedOn": "2022-03-29T19:59:22.000Z",
          "wordCount": 138,
          "title": "[Research] AudioTagging Done Right: 2nd comparison of deep learning methods for environmental sound classification",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trejlz/p_college_course_on_ml_with_an_object_detection/",
          "author": null,
          "description": "The objective is simple, a kit with some small hardware is given to us (nuts, bolts, washers, etc). Using our laptop cameras, we need to develop a model that is able to accurate classify what object is what when placed infront of the camera. There can be any number of objects in any orientation, displayed on any color surface. What is the best way to approach this problem, what is a good model structure (high level) and what can I do to be a step above the competition.\n    submitted by    /u/Certified_User  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trejlz/p_college_course_on_ml_with_an_object_detection/",
          "publishedOn": "2022-03-29T18:54:42.000Z",
          "wordCount": 234,
          "title": "[P] College course on ML with an object detection project and competition between teams within the class. Help me make the best model possible.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trbwwb/d_there_is_no_time_to_read_the_textbook_as_a/",
          "author": null,
          "description": "I'm a researcher who is deeply interested in deep generative models. There are excellent textbooks I want to read if time allows, such as:\n Probabilistic ML: https://probml.github.io/pml-book/book1.html\n PRML: https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf\n However, there are also many papers I have to read, new theories I have to learn, and works I need to finish. The problem is that reading textbooks could deepen the fundamental understanding of the field but rarely gives an immediate reward. Practically, reading a textbook from start to end can take > 1000 hours, in which one can read more than a hundred papers. Given the situation, I have studied basic stuff only when I need them for my research (you know, publish or perish).\n ​\n However, I think the time to read textbooks will decrease rather than increase, and only junior researchers will be able to afford to read them. It means that if I don't read them now, I won't be able to read later. Is there any general advice on this?\n    submitted by    /u/SnooPandas3529  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trbwwb/d_there_is_no_time_to_read_the_textbook_as_a/",
          "publishedOn": "2022-03-29T18:09:40.000Z",
          "wordCount": 1804,
          "title": "[D] There is no time to read the textbook as a researcher",
          "imageUrl": "https://external-preview.redd.it/Ohq8BMzEcYr-l5BkFrKwi1-fYvKQ7KFnl7qJRyriLZI.jpg?auto=webp&s=28657cc423393863aad04c53ec0042e9cc8491b2"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/traoa1/p_will_a_recommender_system_alone_solve_this_issue/",
          "author": null,
          "description": "I have a project featuring 5+ years of data detailing mechanic reports. Essentially, I want to use ML to build a model that can make suggested actions to fix an issue based on these mechanic reports. For example, if a user typed in that a car “makes a squeaky sound” then it suggests three courses of action that may fix the issue based on similar issues and solutions detailed in the mechanic reports. \n Furthermore, when returning these suggestions, I want the user to see some sort of score indicating how likely it is to fix the issue (i.e. option A worked 97% of the time, option B 2% of the time, and option C 1% of the time). I also want the user to be able to try the options and give feedback on if they fixed the issue. \n My brain immediately went to a recommender system, but I don’t have much experience with creating them. Can they do all of the above (recommend solutions, score solutions, and allow for user input to keep training the model) or do I need to somehow pair with another method/model? I’m just not sure where to start.\n    submitted by    /u/ambiguousalmond  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/traoa1/p_will_a_recommender_system_alone_solve_this_issue/",
          "publishedOn": "2022-03-29T17:45:39.000Z",
          "wordCount": 423,
          "title": "[P] Will a recommender system alone solve this issue?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr93ls/r_understanding_dimensional_collapse_in/",
          "author": null,
          "description": "submitted by    /u/fasttosmile  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr93ls/r_understanding_dimensional_collapse_in/",
          "publishedOn": "2022-03-29T16:56:50.000Z",
          "wordCount": 118,
          "title": "[R] Understanding Dimensional Collapse in Contrastive Self-supervised Learning",
          "imageUrl": "https://external-preview.redd.it/X0iUTaLs2Nk1xsiLuHSXDEF24fJPyIBmmpqk4epPlYg.jpg?auto=webp&s=036dcf53a951d6bafbf5c2dd6b37ccf914dabf13"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr8g5s/avoid_vver_fitting_in_iterative_pruning_d/",
          "author": null,
          "description": "Avoid over fitting in iterative pruning \n For iterative pruning algorithms referring to research papers like:\n ​\n  \nLearning both Weights and Connections for Efficient Neural Networks\n Deep Compression\n Comparing Rewinding and Fine-Tuning in Neural Network Pruning\n  \nI have found that during these pruning rounds, the pruned sub-network starts to overfit excessively, with training accuracy approaching almost 100%. This can be attributed to the fact that the surviving trained parameters are not reinitialized to either the randomly initialized values or to a previous value from earlier in the training.\n Whereas, for \"The Lottery Ticket Hypothesis\" and it's family of related research papers such as:\n  \nThe Lottery Ticket Hypothesis\n Stabilizing the Lottery Ticket Hypothesis\n One ticket to win them all\n Deconstructing Lottery Tickets\n  \nsuch overfitting is usually not observed due to the weight rewinding scheme.\n Since, the original & unpruned deep learning architecture is already trained with strategies such as: data augmentation, weight decay, learning rate schedule, etc., the resulting iterative pruning rounds result in overfitting.\n Can you suggest a way to avoid these overfitting during these iterative pruning rounds?\n    submitted by    /u/grid_world  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr8g5s/avoid_vver_fitting_in_iterative_pruning_d/",
          "publishedOn": "2022-03-29T16:50:33.000Z",
          "wordCount": 582,
          "title": "Avoid vver fitting in iterative pruning [D]",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr6ej7/signapse_harnessing_cnns_to_teach_sign_langauge/",
          "author": null,
          "description": "Hi,\n I'm a student at the University of Glasgow building a linux app that is trying to use CNNs to teach people the ASL (american sign language) alphabet. We just released the first version of our software which (although admittedly buggy) is worth sharing with interested communities. In brief, a MobileNetv2 model is trained on kaggle data for each sign in the ASL alphabet, this is executed within the OpenCV framework and run on camera frames of the user in real time. The user is challenged to make different signs and rewarded when the correct sign is made. We would love for interested people to try out our software and let us know about enhancement ideas or any bugs they may find.\n If you are interested in the project, please head over to our GitHub to have a look:\n https://github.com/albanjoseph/Signapse\n You can also follow us on Facebook:\n https://www.facebook.com/Signapse-125793226671815\n Twitter:\n https://twitter.com/GU_Signapse\n and YouTube:\n https://www.youtube.com/channel/UCh2uG2pYoSloEU0IFeqDQMA\n Cheers!\n Signapse Team\n    submitted by    /u/rossythebossy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr6ej7/signapse_harnessing_cnns_to_teach_sign_langauge/",
          "publishedOn": "2022-03-29T16:17:52.000Z",
          "wordCount": 246,
          "title": "Signapse: Harnessing CNNs to Teach Sign Langauge [Project] [Discussion]",
          "imageUrl": "https://external-preview.redd.it/ABeQUg5sFMFa-3c9UlvcjE9mghWNwgnSeiLEvY1NFZI.jpg?auto=webp&s=d40c93665c0ea87a971767fe0018f71f0fcd14f9"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr0vaq/dhugging_face_model_comparator_space_builder/",
          "author": null,
          "description": "You can now build a space comparing Hugging Face Models and Spaces or create clones of them with Model Comparator Space Builder 📷📷📷\n https://huggingface.co/spaces/farukozderim/Model-Comparator-Space-Builder\n ​\n https://preview.redd.it/t40n9amr0cq81.png?width=1813&format=png&auto=webp&s=f151ea9060f7c5b43f8dbcf3f91d1c308bdbb422\n ​\n https://preview.redd.it/fx1ztghs0cq81.png?width=1848&format=png&auto=webp&s=f1cfcb2b47831b10744b4d0e114fd21ed725b195\n Gradio: https://github.com/gradio-app/gradio\n Hugging Face: https://huggingface.co/\n    submitted by    /u/Mundane-Apartment224  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr0vaq/dhugging_face_model_comparator_space_builder/",
          "publishedOn": "2022-03-29T14:21:55.000Z",
          "wordCount": 118,
          "title": "[D]Hugging Face Model Comparator Space Builder",
          "imageUrl": "https://external-preview.redd.it/BDzEmJWh3jEsypQ1KSA94O-DYVnBlp4qU_esZ-RDm4E.jpg?auto=webp&s=1431103a871a610160474029201cc79f5483ea8f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr0glo/p_scikitlearn_transformer_that_turns_categorical/",
          "author": null,
          "description": "Hi everyone. Our DS & DA team open sourced a Python library that helps in dealing with categorical variables for machine learning algorithms.\n It leverages Tensorflow/Keras embedding layers and builds a neural network that learns a dense representation of each unique class. This is all packaged inside a regular scikit-learn transformer that can be used within pipelines and can have its hyperparameters optimized with regular sklearn methods.\n Just do pip install embedding-encoder[tf]. Check out the readme at Github or the blog post for examples.\n Github: https://github.com/cpa-analytics/embedding-encoder\n PyPI: https://pypi.org/project/embedding-encoder/\n Blog post: https://cpa-analytics.github.io/embedding-encoder-intro/\n This was inspired by the 3rd place solution in the Rossmann Store Sales Kaggle competition. Some implementations have surfaced over the years but we are not aware of working one that integrates well with existing libraries.\n This is just another preprocessing technique. It can be optimal for your task or not. As always, try multiple approaches and evaluate the results!\n    submitted by    /u/rafa10pj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr0glo/p_scikitlearn_transformer_that_turns_categorical/",
          "publishedOn": "2022-03-29T14:02:41.000Z",
          "wordCount": 627,
          "title": "[P] scikit-learn transformer that turns categorical variables into dense vector representations",
          "imageUrl": "https://external-preview.redd.it/43lw-vjgTJp6_14KvFjo7KRqd6JiHENPHeVKoJmvGcQ.jpg?auto=webp&s=78b885185f6dcca36ab60dee4d4c1b0778668573"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr055q/research_dealing_with_variable_length_input_data/",
          "author": null,
          "description": "I am building a ML model to classify malware. My input data are windows binaries which get de-compiled into functions. From these functions I create embeddings, each is 150 float numbers. \n https://preview.redd.it/4ejwz7ukubq81.png?width=581&format=png&auto=webp&s=cbde0b534a8424f2a17ea5f1c77fccd2860685f5\n Problem: Each binary has a variable amount of functions. Some may have 40 functions while others may have over 1000. Most will have between 50 and 200. The order of the functions is not important.\n Question: What is the best way to deal with these variable amount of input. Hashing trick? Or Deep sets? What would you recommend?\n    submitted by    /u/laddi27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr055q/research_dealing_with_variable_length_input_data/",
          "publishedOn": "2022-03-29T13:47:21.000Z",
          "wordCount": 447,
          "title": "[Research] Dealing with variable length input data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqzno6/discussion_podcast_with_jonathan_frankle_of/",
          "author": null,
          "description": "Jonathan came on the Weaviate Podcast to discuss the story of MosaicML, their new open-source Python library for Efficient Deep Learning called Composer, Pareto Curves of Training Time X Accuracy, Model Surgey augmentations, Maximizing CPU and GPU throughput, and many more! I hope you find this useful, happy to continue discussions of what Jonathan presented!\n https://www.youtube.com/watch?v=ZiBkspwrICA\n    submitted by    /u/HenryAILabs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqzno6/discussion_podcast_with_jonathan_frankle_of/",
          "publishedOn": "2022-03-29T13:23:34.000Z",
          "wordCount": 176,
          "title": "[Discussion] Podcast with Jonathan Frankle of MosaicML",
          "imageUrl": "https://external-preview.redd.it/YCKHLUjfYtgwj1bsM4k42UgT0xbL--xuPmSVXEhD-f0.jpg?auto=webp&s=60e3a937f8a19429373339338ca6414259d2faef"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqzlrh/d_using_large_language_models_for_classification/",
          "author": null,
          "description": "Hey everyone!\n I'd like to use a large language model like T0pp or GPT-NeoX-20B to take a natural-language input from a user and map it to one of ~2000 possible VS Code command palette commands. Essentially, this is a classification problem of the form \"NLP input -> command\".\n The idea is to let users give voice input in natural language and then have the model figure out what command they most likely want to activate.\n Given the number of possible commands I clearly can't rely on prompt design to solve this. It might be a good fit for a model with explicit retrieval augmentation like a memorizing transformer. But that's still a very active area of research without high-quality pre-trained models.\n Given that, I'm thinking that doing some kind of fine tuning to an existing model is the best bet. But it's unclear to me what the training data should look like... should I just generate a few examples of each command of the form input: \"vscode command: 'open new file'\", output: \"explorer.newFile\", and then fine-tune on those? Is there some way to ensure that the model understands that I *always* want it to return one of the commands provided in fine-tuning, instead of arbitrary text?\n Interested in others' experiences with similar tasks! \n Background: I'm working on an open source VS Code extension called Clippy AI. Currently it only performs code modifications to the current file and is a thin wrapper around the OpenAI API. But I'd like to use it to automate other editor actions as well!\n    submitted by    /u/corbt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqzlrh/d_using_large_language_models_for_classification/",
          "publishedOn": "2022-03-29T13:20:47.000Z",
          "wordCount": 598,
          "title": "[D] Using large language models for classification of natural-language input",
          "imageUrl": "https://external-preview.redd.it/y2lfc4rWbAhcBOgAM89rfyc1xin3Ckl8qDzfHdHNH0E.jpg?auto=webp&s=6787ad1c737d4a066ca3274c379e4ca8029953f7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqynd5/visualizing_pathologies_in_ultrasound_images/",
          "author": null,
          "description": "As part of our AI Challenge with a health-tech startup: https://omdena.com/blog/pathology-streamlit/\n https://preview.redd.it/zew2baykgbq81.png?width=640&format=png&auto=webp&s=e66180724c08f22db3d322d8b1fd6f56e8765a3c\n    submitted by    /u/Lordobba  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqynd5/visualizing_pathologies_in_ultrasound_images/",
          "publishedOn": "2022-03-29T12:28:13.000Z",
          "wordCount": 115,
          "title": "Visualizing Pathologies in Ultrasound Images Using OpenCV and Streamlit [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqxr2u/d_it_is_possible_to_build_a_time_series_model/",
          "author": null,
          "description": "So basically, I started my internship in business intelligence, and when my boss know that I have a background in machine learning and deep learning. so, he asked me to build a model that predicts a specific number for the next month. so, it time series problem, and the datasets that I have it is very small it starts from May 2019 so it is just 31 rows. And when I plotted the data, it had no clear trend. This pitcher for the graph looks like my dataset here! dataset (sorry I cannot share the dataset because of privacy). So, I started to take the difference in the data to remove the seasonality and log transformation and after that, I bullied the model using the Arima algorithm and LSTM, and prophet. And I applied a prediction interval for the predicted number to get periods and expect the number will be inside this interval. But unfortunately, the actual number (for this month) was out of the interval. So, I decided to look back in a database and I found a feature I think that may help and have a high correlation with the main feature now becoming a multivariate time series problem. so, I tried to use the VAR algorithm but unfortunately, the model also filed and the actual number for each feature was out of interval. This first time for me to build a time series model in the industry for a real dataset and I worked alone. So, there is an approach that can help me to build a better model that I do not follow in my step. Or I should go to my boss tell him cannot build a model for this dataset, especially the data is impacted by a coronavirus.\n    submitted by    /u/xxsalehxx140  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqxr2u/d_it_is_possible_to_build_a_time_series_model/",
          "publishedOn": "2022-03-29T11:36:52.000Z",
          "wordCount": 560,
          "title": "[D] It is possible to build a time series model with this dataset.",
          "imageUrl": "https://external-preview.redd.it/VwDh6e8p18FQXsFgIgb7CNvQNvcqUmIgjANK9aXApMY.jpg?auto=webp&s=a516240355f0a87693bcfe8366c778a959b9278f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqx0u7/process_models_for_data_science_academic_r/",
          "author": null,
          "description": "Hello everyone,\n I am a german student and currently writing my masters thesis. It is a rather simple ML task but for my thesis I need to describe the methodology and which process models are used and I am new to this. I found CRISP-DM and its successor ASUM-DM. However, I know that sounds stupid, I am not able to find information on these or useful pdfs. Like the general information and descriptions are accessable but I need an officisl source that I can cite. IBM itself has a link: ftp: //ftp.software.ibm.com/software/data/ sw-library/services/ASUM.pdf However, its not working for me as I have no ftp access. \n So my question is, does anyone have a link where I can find relevant official information to these models and furthermore are there any other standards or process models to describe the approach of working with data that are rather used in the industry.\n    submitted by    /u/terektus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqx0u7/process_models_for_data_science_academic_r/",
          "publishedOn": "2022-03-29T10:48:47.000Z",
          "wordCount": 247,
          "title": "Process Models for Data Science? (academic) [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqnhin/d_object_inputs_with_multiple_features/",
          "author": null,
          "description": "Hello,\n I am looking at having a neural network take inputs of 8 objects that all have different features/attributes and then an input of the different features/attributes of the environment the objects are in. The output of this would be the rank of each object. The attached image demonstrates a diagram of the neural network. The objects actively interact/compete with each other. I thought about inputting a single object's features and the environment into a neural network with the output as a performance score of the object. However, the object does worse or better depending on what other objects it is competing against. The objects also get better or worse over time, so it may be good to backpropagate and analyze the objects also as a time series.\n Is it possible to input the object/object features as a matrix? I have not figured out a way to group this data. I was thinking maybe a convolution neural network may work. I am somewhat new to the machine learning world. Any recommendation or help would be great. Thank you\n https://preview.redd.it/ng7q9haxw7q81.jpg?width=6450&format=pjpg&auto=webp&s=9393006f00583a1a4a9af02044e726559176c403\n    submitted by    /u/hypercar_junkie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqnhin/d_object_inputs_with_multiple_features/",
          "publishedOn": "2022-03-29T00:31:44.000Z",
          "wordCount": 268,
          "title": "[D] Object Inputs with Multiple Features",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqn4k4/r_time_series_clustering_resources/",
          "author": null,
          "description": "Hi, I am intending to write a paper (almost 25-30 pages) about time series clustering. I have done my online research, however, I ll be grateful if you can mention some other resources that might be of interest, either theoretical or applied. It can be blogs about machine learning you find interesting in this area, video series, lectures, lecture notes, whatever. Thank you very much.\n    submitted by    /u/jiii95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqn4k4/r_time_series_clustering_resources/",
          "publishedOn": "2022-03-29T00:12:36.000Z",
          "wordCount": 154,
          "title": "[R] time series clustering resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tql5b8/p_any_resources_on_finetuning_models_decision/",
          "author": null,
          "description": "Hello, i'm trying to reproduce the Decision Transformer paper, however i feel seriously lost on how to do it. I find no documentation on fine-tuning models and have no idea how to use the datasets.\n Any help would be much appreciated, thanks.\n    submitted by    /u/PM_ME_FREE_GAMES  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tql5b8/p_any_resources_on_finetuning_models_decision/",
          "publishedOn": "2022-03-28T22:31:22.000Z",
          "wordCount": 142,
          "title": "[P] Any resources on fine-tuning models? - Decision Transformer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqjqjp/p_seems_like_people_are_finding_my_dataml_job/",
          "author": null,
          "description": "Hey everybody,\n around half a year ago, I created a simple job aggregator called datajoblist.com, which fetches/scrapes remote jobs in data science, data engineering and AI from multiple sources and presents them in a simple, unified interface. The jobs are collected both directly from interesting (to me) companies like Stripe or Shopify, as well as filtered from job boards such as weworkremotely.com.\n I have not touched the site since when I first built it half a year ago, but it seems that people are finding it helpful, as it is now getting rather stable lower few thousand unique visitors per month, and has facilitated thousands of “apply” click-throughs to company sites. A few dozen people even signed up for the mailing list. So, I was thinking about investing a little more time now and adding some improvements.\n Is there any information/functionality that you would like to see there?\n Shortly, I will be adding the possibility to post jobs for a small fee (till now, all jobs on the site have been aggregated from elsewhere), but would love to add some usability improvements that are reasonably simple to implement for me. (Perhaps salary ranges, where available?)\n Thanks for any feedback and have a great day!\n    submitted by    /u/k_kristian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqjqjp/p_seems_like_people_are_finding_my_dataml_job/",
          "publishedOn": "2022-03-28T21:22:50.000Z",
          "wordCount": 327,
          "title": "[P] Seems like people are finding my data/ML job aggregator helpful… do you have any feedback for me?",
          "imageUrl": "https://external-preview.redd.it/VX5BlMXY6hbRdKozcruBmIMfeKDQHgE88xTLxGOb8Ik.jpg?auto=webp&s=37f17936923c5011eb9fae0f449cf9c72e2cec22"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqjd3w/d_neural_networks_are_not_the_only_universal/",
          "author": null,
          "description": "I often here the success of neural networks attributed to their status as universal approximators, but there are many algorithms that are universal approximators. For example, decision trees can also be universal approximators, but they don't seem to have nearly as much success. Why is this? What do neural networks have beyond just being universal approximators that makes them special?\n ​\n Is this a question that is currently well understood or is the answer to this question still an area of research?\n    submitted by    /u/029187  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqjd3w/d_neural_networks_are_not_the_only_universal/",
          "publishedOn": "2022-03-28T21:04:54.000Z",
          "wordCount": 760,
          "title": "[D] Neural Networks are not the only universal approximators, so why are they so uniquely effective?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqdpf8/d_why_gnns_suffer_from_oversmoothing_but_cnns_dont/",
          "author": null,
          "description": "Many articles online say GNNs suffer from over-smoothing because nodes aggregate their neighbors and many nodes share similar sets of neighbors. However, in CNN, each pixel also aggregates its neighbors. But CNN can still perform well on some pixel-level classification tasks such as segmentation.\n    submitted by    /u/AirZealousideal1342  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqdpf8/d_why_gnns_suffer_from_oversmoothing_but_cnns_dont/",
          "publishedOn": "2022-03-28T16:51:57.000Z",
          "wordCount": 393,
          "title": "[D] Why GNNs suffer from over-smoothing but CNNs don't?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqd22m/d_paper_review_video_memoryassisted_prompt/",
          "author": null,
          "description": "https://youtu.be/gYxJEd3EUKs\n Large language models such as GPT-3 have enabled many breakthroughs and new applications recently, but they come with an important downside: Training them is very expensive, and even fine-tuning is often difficult. This paper presents an adaptive method to improve performance of such models after deployment, without ever changing the model itself. This is done by maintaining a memory of interactions and then dynamically adapting new prompts by augmenting them with memory content. This has many applications, from non-intrusive fine-tuning to personalization.\n ​\n OUTLINE:\n 0:00 - Intro\n 0:40 - Sponsor: Introduction to GNNs Course (link in description)\n 1:30 - Paper Overview: Improve GPT-3 after deployment via user feedback\n 5:30 - Proposed memory-based architecture\n 13:00 - A detailed look at the components\n 15:00 - Example tasks\n 24:30 - My concerns with the example setup\n 26:20 - Baselines used for comparison\n 29:50 - Experimental Results\n 34:20 - Conclusion & Comments\n ​\n Paper: https://arxiv.org/abs/2201.06009\n Code & Data: https://github.com/madaan/memprompt\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqd22m/d_paper_review_video_memoryassisted_prompt/",
          "publishedOn": "2022-03-28T16:23:08.000Z",
          "wordCount": 269,
          "title": "[D] Paper Review Video - Memory-assisted prompt editing to improve GPT-3 after deployment",
          "imageUrl": "https://external-preview.redd.it/GzqzM44_xv46etrLcJuHT-qngCBZsBvKGZQVGqNvyJ0.jpg?auto=webp&s=c725fcefbdc20b96757c8f4a6214fa65a0024719"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqbpk5/d_diversity_in_recommendation_systems_with_a/",
          "author": null,
          "description": "Many recommendation systems start with a few very popular items that were heavily marketed. The rest of the item list is largely unexplored. How do recommender systems get around this bias and \"test\" out new items on users to develop richer training data?\n I could see how a multi-arm bandit might fix this problem but I'd love to hear other ideas and lessons learned.\n    submitted by    /u/Shap177  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqbpk5/d_diversity_in_recommendation_systems_with_a/",
          "publishedOn": "2022-03-28T15:21:51.000Z",
          "wordCount": 170,
          "title": "[D] Diversity in Recommendation Systems with a Mostly Unexplored Item List",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqbmwq/p_ive_released_a_python_package_which_lets_you/",
          "author": null,
          "description": "https://github.com/minimaxir/imgbeddings\n Instead, this package uses an ONNX INT8-quantized version of CLIP's Vision layers, which in testing works just as well, with a significant performance boost.\n The demos also turned out very well, and try to a bit more fun than usual.\n    submitted by    /u/minimaxir  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqbmwq/p_ive_released_a_python_package_which_lets_you/",
          "publishedOn": "2022-03-28T15:18:29.000Z",
          "wordCount": 202,
          "title": "[P] I've released a Python package which lets you generate vector representations of images with a twist: neither PyTorch nor TensorFlow is used!",
          "imageUrl": "https://external-preview.redd.it/tdsX1I8bgzTfp3bs-wIJzQ4TWsVWjypXKod6JYKGVPE.jpg?auto=webp&s=f9906514cd0c716c0083812e13da7c237c53a38f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqb7py/p_decision_transformers_in_transformers_library/",
          "author": null,
          "description": "Hey there,\n We’re happy to announce that Edward Beeching from Hugging Face has integrated Decision Transformers an Offline Reinforcement Learning method, into the 🤗 transformers library and the Hugging Face Hub.\n In addition, we share nine pre-trained model checkpoints for continuous control tasks in the Gym environment.\n If you want to know more about Decision Transformers and how to start using it, we wrote a tutorial 👉 https://huggingface.co/blog/decision-transformers\n We would love to hear your feedback about it,\n Thanks,\n    submitted by    /u/cranthir_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqb7py/p_decision_transformers_in_transformers_library/",
          "publishedOn": "2022-03-28T14:59:36.000Z",
          "wordCount": 267,
          "title": "[P] Decision Transformers in Transformers library and in Hugging Face Hub",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqb4v0/d_catboost_performance_on_python_vs_c/",
          "author": null,
          "description": "Hi fellow nerds, was wondering if anyone has trained the same catboost model on the same dataset in Python and C++ to see which is quicker. Also posting in case someone knows why one language may be inherently quicker. \n I assume that they are the same program with the same run time but I can’t be too sure of that. Thanks.\n    submitted by    /u/econ1mods1are1cucks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqb4v0/d_catboost_performance_on_python_vs_c/",
          "publishedOn": "2022-03-28T14:55:57.000Z",
          "wordCount": 259,
          "title": "[D] Catboost performance on Python vs C++",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqb2mb/p_release_the_vision_transformer_cookbook_with/",
          "author": null,
          "description": "​\n Vision Transformer Cookbook\n ​\n Hello, I have released the Vision Transformer Cookbook with Tensorflow !\n Therefore, you can easy to use the 22 transformer architectures via just copy & paste.\n I hope this repository would help many people, including tensorflow users.\n Thank you.\n ​\n * code: vit-tensorflow\n    submitted by    /u/taki0112  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqb2mb/p_release_the_vision_transformer_cookbook_with/",
          "publishedOn": "2022-03-28T14:53:08.000Z",
          "wordCount": 165,
          "title": "[P] Release the Vision Transformer Cookbook with Tensorflow ! (Thanks to @lucidrains)",
          "imageUrl": "https://external-preview.redd.it/ebuMUe4Vpk4o7taF_wbulAfqA1foTC-S3Dl2bCXfwOw.jpg?auto=webp&s=df0b61c8232f6083ea6276f2c3ae595c9aefba39"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqak1i/discussion_create_a_random_forest_regression_to/",
          "author": null,
          "description": "I am using Random Forest Regression on a power vs time data of an experiment that is performed for a certain time duration. Using that data, I want to predict the trend of power in future using time as an input. The code that has been implemented is mentioned below.\n The data set consists of approximately 30 hours of power vs time values as mentioned below. Only active power and time_h columns are used in the algorithm.\n ​\n Data set used for modelling\n # Creating X and y X = np.array(series[['time_h']]).reshape(-1,1) y = np.array(series['active_power']) # Splitting dataset in training and testing X_train2,X_test2,y_train2,y_test2 = train_test_split(X,y,test_size = 0.15, random_state = 1) # Creating Random Forest model and fitting it on training data forest = RandomForestRegressor(n_estimat…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqak1i/discussion_create_a_random_forest_regression_to/",
          "publishedOn": "2022-03-28T14:29:12.000Z",
          "wordCount": 526,
          "title": "\"[Discussion] Create a Random Forest Regression to predict multiple values in future using past data\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq7cjn/discussion_i_am_a_sample_in_the_dataset_i_have_to/",
          "author": null,
          "description": "Basically the title. I work as a data engineer for a company I am also a customer of. From an Ethics in ML point of view: what do you think this implies on my responsibilities?\n    submitted by    /u/Bani57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq7cjn/discussion_i_am_a_sample_in_the_dataset_i_have_to/",
          "publishedOn": "2022-03-28T11:42:10.000Z",
          "wordCount": 332,
          "title": "[Discussion] I am a sample in the dataset I have to analyze",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq40t9/d_everything_about_attention_family/",
          "author": null,
          "description": "Hey, I have just published my latest medium article. \n These days, in deep learning, it is usual to hear about transformers’ outstanding performance on the challenges where other algorithms can not meet our expectations when most of them are based on attention. This article gives you a detailed illustration of the code and mathematics of the four most-used types of attention in the Deep Learning era.\n https://rezayazdanfar.medium.com/everything-about-attention-family-644747903c60\n    submitted by    /u/rezayazdanfar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq40t9/d_everything_about_attention_family/",
          "publishedOn": "2022-03-28T07:40:25.000Z",
          "wordCount": 160,
          "title": "[D] Everything about Attention Family",
          "imageUrl": "https://external-preview.redd.it/EKWOzyGXMdUqAqJYhL82vLWaQkBk3-ml_g6HqnUPA6k.jpg?auto=webp&s=109d698053ded955f4a2208edc303aed709e8cfe"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq1ia3/r_new_tsne_guidelines_an_experimental_study_and/",
          "author": null,
          "description": "t-SNE remains a popular embedding method for visualizing high-dimensional data. However, there is little consensus on how to select hyperparameters such as perplexity, learning rate, and exaggeration to best visualize arbitrary data sets.\n This work systematically explores t-SNE hyperparameters using almost 700 data sets. We replicate past studies, proving that some t-SNE guidelines generalize beyond their original context. But we find that some guidelines do not appear to generalize. We also show a proof of concept neural network system for featurizing data sets and automatically recommending good t-SNE hyperparameters.\n Paper: https://osf.io/6t5ax/\n Blog: https://twosixtech.com/new-guidance-for-using-t-sne/\n    submitted by    /u/rpgove  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq1ia3/r_new_tsne_guidelines_an_experimental_study_and/",
          "publishedOn": "2022-03-28T04:47:59.000Z",
          "wordCount": 862,
          "title": "[R] New t-SNE guidelines, an experimental study, and automatic t-SNE hyperparameter selection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq0e3k/r_text_to_mesh_without_3d_supervision_using_limit/",
          "author": null,
          "description": "submitted by    /u/InfamousPancakes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq0e3k/r_text_to_mesh_without_3d_supervision_using_limit/",
          "publishedOn": "2022-03-28T03:39:52.000Z",
          "wordCount": 622,
          "title": "[R] Text to Mesh Without 3D Supervision Using Limit Subdivision (Clipmesh)",
          "imageUrl": "https://preview.redd.it/x8etj6w9p1q81.gif?format=png8&s=339435fd2695a73a2d0e704ded901789540b3bc7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq0dt3/p_mlbot_opensource_tool_to_train_ml_models_in/",
          "author": null,
          "description": "Hey ML Reddit!\n I just released the initial version of MLbot (https://github.com/thecooltechguy/mlbot): a new open-source tool that I’ve been working on for running distributed ML training jobs in your cloud, with a single command.\n How it works:\n In short, it allows you to run your training script in the cloud by simply swapping “python” for “mlbot run”.\n For example, if ``python train.py … can run your training script locally, then mlbot run --instance-type p3dn.24xlarge --num-nodes 2 train.py … should be able to run your code in the cloud across 2 GPU machines.\n Since this tool runs entirely inside your cloud environment, you don’t have to transfer your training data to a 3rd party, while having full observability into the underlying infrastructure.\n Why I built this:\n In a recent ML pr…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq0dt3/p_mlbot_opensource_tool_to_train_ml_models_in/",
          "publishedOn": "2022-03-28T03:39:23.000Z",
          "wordCount": 627,
          "title": "[P] MLbot – Open-source tool to train ML models in your cloud, with a single command.",
          "imageUrl": "https://external-preview.redd.it/r6wuHnVZTvC1fK_HjgCwBMj7B5oYlRNQx0d1AJO8HBI.jpg?auto=webp&s=407ae7feaf63b13bfada5a61a85d3d55ecb47dee"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq097n/d_what_is_the_following_nlp_task_called/",
          "author": null,
          "description": "Looking for ideas and pointers on how to solve this problem. Dependency parsing? Are there any open source ML models to solve this problem? Googling isn't helping.\n Made a mistake in the description - we want to explain the negative sentiment of the aspect \"tone\" (rather than guitar)\n    submitted by    /u/ml_guy1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq097n/d_what_is_the_following_nlp_task_called/",
          "publishedOn": "2022-03-28T03:31:59.000Z",
          "wordCount": 343,
          "title": "[D] What is the following NLP task called - explaining WHY someone feels a particular way in a product review? For example with the sentence - \"I don't like the tone of the guitar because the strings are too old\", the explanation for negative sentiment of guitar should be \"strings are too old\".",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq00tu/d_difference_between_research_and_applied/",
          "author": null,
          "description": "Hello, I am in the process of finding a suitable conference for my paper, and I find that they usually have a research track and applied research track. One conference defines the applied research track as\n  \nThe Applied Research Track aims at attracting submissions from both industry and academia that either solve or advance the understanding of issues related to deploying AI, Information Retrieval (IR), and big data technologies as part of actual applications.\n  \nMy paper is roughly related to applying deep learning for time series anomaly detection. Should I go for the research track or the applied research track?\n    submitted by    /u/mythrowaway0852  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq00tu/d_difference_between_research_and_applied/",
          "publishedOn": "2022-03-28T03:18:17.000Z",
          "wordCount": 314,
          "title": "[D] Difference between Research and Applied Research track in conferences?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpt9xn/p_we_built_a_ai_platform_to_advance_stereotactic/",
          "author": null,
          "description": "4 years ago, I posted here to introduce some work I did using AI for breast tumor detection and classification: \n https://www.reddit.com/r/MachineLearning/comments/8rdpwy/pi_made_a_gpu_cluster_and_free_website_to_help/\n That post gain some traction on Reddit and I hope you would like the one I am gonna introduce here again. \n In the recent years, I have been shifting my focus from cancer detection to the actual treatment. \n One particular problem we really want to solve is to have more brain cancer patients to be accessible to stereotactic radiosurgery (SRS) which has a lot better treatment outcome and much better quality of life (QoL) for the patient than whole brain radiotherapy (WBRT) which is more common for patients with multiple brainiest (say more than 5 or 10). \n The reason behind …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpt9xn/p_we_built_a_ai_platform_to_advance_stereotactic/",
          "publishedOn": "2022-03-27T21:08:23.000Z",
          "wordCount": 453,
          "title": "[P] We built a AI platform to advance stereotactic radiosurgery (SRS) for brain tumor patients",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tps7fl/d_is_colab_pro_worth_the_money/",
          "author": null,
          "description": "Hey guys, I'm currently dealing with my bachelor degree's final project. But my pc seems to be slow and it gets really hot + I think it might be dying, I really need to send it to the technical service. :(\n Well, I'm not familiar with other cloud services like Azure or AWS but I used Google Colab a lot, and right at this moment I also use it. But it's constantly asking if I'm \"there\". It always wants an interaction otherwise it shutdowns the session and my time gets wasted, just gotta do everything from the start.\n So if I pay for the colab pro (unpluss) version, will my experience get better? Will I need to interact with colab every hour again? Or should I consider other alternatives?\n    submitted by    /u/average_turanist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tps7fl/d_is_colab_pro_worth_the_money/",
          "publishedOn": "2022-03-27T20:16:53.000Z",
          "wordCount": 426,
          "title": "[D] Is Colab Pro Worth the money?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpruqj/d_machine_learning_wayr_what_are_you_reading_week/",
          "author": null,
          "description": "This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.\n Please try to provide some insight from your understanding and please don't post things which are present in wiki.\n Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.\n Previous weeks :\n  \n 1-10 11-20 21-30 31-40 41-50 51-60 61-70 71-80 81-90 91-100 101-110 111-120 121-130 131-140 \n  \n Week 1 Week 11 Week 21 Week 31 Week 41 Week 51 Week 61 Week 71 Week 81 Week 91 Week 101 Week 111 Week 121 Week 131 \n  Week 2 Week 12 Week 22 Week 32 Week 42 Week 52 Week 62 Week 72 Week 82 Week 92 Week 102 Week 112 Week 122 Week 132 \n  Week 3 Week 13 Week 23 Week 33 Week 43 Week 53 Week 63 Week 73 Week 83 Week 93 Week 103 Week 113 Week 123 Week 133 \n  Week 4 Week 14 Week 24 Week 34 Week 44 Week 54 Week 64 Week 74 Week 84 Week 94 Week 104 Week 114 Week 124  \n  Week 5 Week 15 Week 25 Week 35 Week 45 Week 55 Week 65 Week 75 Week 85 Week 95 Week 105 Week 115 Week 125  \n  Week 6 Week 16 Week 26 Week 36 Week 46 Week 56 Week 66 Week 76 Week 86 Week 96 Week 106 Week 116 Week 126  \n  Week 7 Week 17 Week 27 Week 37 Week 47 Week 57 Week 67 Week 77 Week 87 Week 97 Week 107 Week 117 Week 127  \n  Week 8 Week 18 Week 28 Week 38 Week 48 Week 58 Week 68 Week 78 Week 88 Week 98 Week 108 Week 118 Week 128  \n  Week 9 Week 19 Week 29 Week 39 Week 49 Week 59 Week 69 Week 79 Week 89 Week 99 Week 109 Week 119 Week 129  \n  Week 10 Week 20 Week 30 Week 40 Week 50 Week 60 Week 70 Week 80 Week 90 Week 100 Week 110 Week 120 Week 130  \n \n Most upvoted papers two weeks ago:\n /u/CatalyzeX_code_bot: Paper link\n /u/PaganPasta: https://arxiv.org/abs/2105.05233\n Besides that, there are no rules, have fun.\n    submitted by    /u/ML_WAYR_bot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpruqj/d_machine_learning_wayr_what_are_you_reading_week/",
          "publishedOn": "2022-03-27T20:00:05.000Z",
          "wordCount": 379,
          "title": "[D] Machine Learning - WAYR (What Are You Reading) - Week 134",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpqk9l/nr_combine_lidar_and_cameras_for_3d_object/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpqk9l/nr_combine_lidar_and_cameras_for_3d_object/",
          "publishedOn": "2022-03-27T18:59:38.000Z",
          "wordCount": 225,
          "title": "[N][R] Combine Lidar and Cameras for 3D object detection - Waymo & Google Research",
          "imageUrl": "https://external-preview.redd.it/OGzE3sF5Uk6DITpibUX887oZn8KPPebAhdbGkRXsIJE.jpg?auto=webp&s=211302fb9cff3c187d69a385588b21403e42b632"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tppxo9/discussion_interesting_prediction_of_ecosystem/",
          "author": null,
          "description": "Saw this comment in a Q&A on big deep learning models. This seems to have side-effects both good and bad. The prediction, if true, forces accessibility (though expensive) but also creates silos. First time poster. What do you guys think?\n https://m12.vc/news/direct-line-with-saurabh-tiwary-whats-next-for-large-foundational-models\n  \nThe economics are making it untenable for most people except the most well-funded organizations to invest in large language models. I will make the comparison to the semiconductor ecosystem. If you look at fabrication economics for semiconductor chips, they cost tens to hundreds of millions of dollars and have relatively short lifetimes. One needs very large volume usage to justify manufacturing a custom ASIC (Application Specific Integrated Circuits). Thus, we do not have that many companies fabricating chips. However, we have an entire software and systems eco-system which relies on these chips that have built massive industries around them. And, if you look at the biggest companies in the world (maybe, except Apple), they have very little to do with ASIC design and fabrication as part of their core business. I think a similar eco-system would pan out in the large-scale modeling space as well. We would have a few well-funded companies that would be training these extremely large and reusable models and other companies would build applications and services reusing and customizing these models.\n  \n   submitted by    /u/SufficientActive8895  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tppxo9/discussion_interesting_prediction_of_ecosystem/",
          "publishedOn": "2022-03-27T18:29:24.000Z",
          "wordCount": 315,
          "title": "[Discussion] Interesting prediction of ecosystem around giant DNN models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpmowt/d_modern_data_augmentation_techniques/",
          "author": null,
          "description": "I've written a short blog post on modern data augmentation techniques. Please have a read and provide feedback. I've explained Cutout, Mixup, CutMix and Label smoothing with code and examples.\n https://pmgautam.com/augmentations/2022/03/27/Augmentations-visually-explained.html\n    submitted by    /u/p1g1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpmowt/d_modern_data_augmentation_techniques/",
          "publishedOn": "2022-03-27T15:50:49.000Z",
          "wordCount": 487,
          "title": "[D] Modern data augmentation techniques",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tplo8r/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tplo8r/d_simple_questions_thread/",
          "publishedOn": "2022-03-27T15:00:10.000Z",
          "wordCount": 285,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpi5gx/p_author_pages_on_httppaperslabmlai/",
          "author": null,
          "description": "We added author pages, which lists all the papers by the author and links to their social and academic web pages.\n E.g.: \n https://papers.labml.ai/author/39815586a03711ecbb8c3d25c114d5ed\n https://papers.labml.ai/author/56b63a47a03711ecbb8c3d25c114d5ed\n Highlights, \n  \nLinks to Google and Arxiv searches.\n Sort papers based on the published date and the popularity in Twitter.\n Links to Twitter, Google Scholar, Github and Linkedin etc if available in our database.\n  \nWe love to hear your feedback and suggestions. Thank you all, and I appreciate the support.\n    submitted by    /u/hnipun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpi5gx/p_author_pages_on_httppaperslabmlai/",
          "publishedOn": "2022-03-27T11:37:33.000Z",
          "wordCount": 206,
          "title": "[P] Author pages on http://papers.labml.ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpa89n/rp_groupvit_semantic_segmentation_emerges_from/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpa89n/rp_groupvit_semantic_segmentation_emerges_from/",
          "publishedOn": "2022-03-27T02:10:12.000Z",
          "wordCount": 224,
          "title": "[R][P] GroupViT: Semantic Segmentation Emerges from Text Supervision + Hugging Face Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/TCv6-qKCraPT1-OhsfkXsXZpoFY2_tfQTDcAnfEpBoY.png?format=pjpg&auto=webp&s=98058dab4a53838db6cedea3fb780154e0574573"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tp5iyf/d_conditional_gan_loss_magnitudes/",
          "author": null,
          "description": "Hey, I am wondering about the losses of conditional GANs, particularly their magnitude. Due to the amount of classes/identities, the classification loss will usually be significantly higher than discrimination loss (data identified as real or generated). When using traditional multitask learning where losses are simply summed up, how is the generator supposed to learn to generate realistic-appearing data when the loss that would encourage that is so low in comparison to the classification loss?\n    submitted by    /u/Timboron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tp5iyf/d_conditional_gan_loss_magnitudes/",
          "publishedOn": "2022-03-26T22:07:29.000Z",
          "wordCount": 310,
          "title": "[D] Conditional GAN loss magnitudes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/toy50y/d_augmentation_in_gan/",
          "author": null,
          "description": "Hi, does anyone has experience in augmentation for GANs? Especially for Cycle-GAN like image to image translation. When I see image-to-image GANs, there is mostly no augmentation applied.\n    submitted by    /u/SeucheAchat9115  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/toy50y/d_augmentation_in_gan/",
          "publishedOn": "2022-03-26T17:13:10.000Z",
          "wordCount": 181,
          "title": "[D] Augmentation in GAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/toqvg1/discussion_how_does_apple_faceid_work/",
          "author": null,
          "description": "I am doing some face recognition and am wondering how does apple's FaceID work. They say it is a \"true depth\" camera. What does that mean? is that a lidar? some kind of a dot projector? Basically what I want to know is what kind of data does that device provide. Also, is there a commercially available device similar to that true depth camera available?\n    submitted by    /u/user89320  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/toqvg1/discussion_how_does_apple_faceid_work/",
          "publishedOn": "2022-03-26T14:24:56.000Z",
          "wordCount": 287,
          "title": "[Discussion] How does apple FaceID work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ton9ir/p_keep_training_gan/",
          "author": null,
          "description": "Hi there,\n ​\n I'm trying to train a GAN to generate video game portraits (think Baldur's Gate, Divinity, that kind of stuff).\n My GAN is trained on 4096 portraits, 128x192 pixels in size.\n Batch size is 64, 64 features, 128 dim noise vector.\n ​\n After a few epochs of the expected low quality random stuff, my Generator starts generating images where you can kind of imagine silhouettes and faces. Here's after 250 epochs:\n ​\n https://preview.redd.it/afc4i2r6zpp81.png?width=568&format=png&auto=webp&s=f8e386a8da4976a20b8db525914e5944346b9240\n But after 500 the results are pretty much the same:\n ​\n https://preview.redd.it/k9ikn9k7zpp81.png?width=568&format=png&auto=webp&s=3ec106e5ef5d54c3a8162bb45941fb3f3f9af4a2\n Losses seem be mostly stable fairly quickly too (sorry, lost the graph after I accidentally shutdown my computer - I save the model every 25 epochs but not the losses graph):\n Epoch 255 Step 16320: Generator loss: 7.4651877045631405, critic loss: -9.97341676712036\n ...\n Epoch 310 Step 19840: Generator loss: 7.401800179481507, critic loss: -9.479909801483156\n ...\n Epoch 511 Step 32720: Generator loss: 11.518763446807862, critic loss: -8.105796337127687\n (The 7.5 -> 11.5 GLoss looks pretty much flat on the graph. Maybe the huge initial losses puts it out of perspective?)\n ​\n Is my GAN \"stuck\" or do I just need to keep training, and quality gains from that point on are going to be slower?\n    submitted by    /u/-Anordil-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ton9ir/p_keep_training_gan/",
          "publishedOn": "2022-03-26T12:15:04.000Z",
          "wordCount": 429,
          "title": "[P] Keep training GAN?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tomt4g/d_guidelines_on_how_to_add_skip_connections_to/",
          "author": null,
          "description": "I'm experimenting with DCGan architecture and tried adding residual blocks to dcgan before each upscaling. The dcgan is trainiing via a WGAN-GP training procedure, and so far, I could nor really get any sensible result.\n Is there any guideline about how skip connections should be implemented in GANs? I'm using a very normal resnet type skip connection. The FID score keeps worsening since the start of training, and I've tweaked a lot of hyperparameters, but I still don't have see any improvements. Although I could not train that many epochs because I'm training this on colab.\n You can find the codes here to see the architecture: Generator and Critic.\n Another info: The dataset is roughly 100K book covers I've scraped from internet.\n    submitted by    /u/feryet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tomt4g/d_guidelines_on_how_to_add_skip_connections_to/",
          "publishedOn": "2022-03-26T11:45:56.000Z",
          "wordCount": 315,
          "title": "[D] Guidelines on how to add skip connections to DCGAN generator?",
          "imageUrl": "https://external-preview.redd.it/ljoRi5vdI1jIrY-vifmLW8jcrgCPqwd3gVp9nmh906A.jpg?auto=webp&s=d97aa08f2a565be106ec6af7359b7fbc2ed0786b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tolh63/d_intersection_between_computer_engineering_and/",
          "author": null,
          "description": "Hi everyone. I am pursuing Masters in Computer Engineering. However, I did my Bachelor's in Computer Science and dabbled with ML a bit. I would like to continue with it during my Masters as well. I am wondering if there is an intersection between the disciplines. If the two fields share considerable overlap, would it be possible to pursue research in ML as a CE graduate?\n Thanks\n    submitted by    /u/RealMatchesMalonee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tolh63/d_intersection_between_computer_engineering_and/",
          "publishedOn": "2022-03-26T10:10:58.000Z",
          "wordCount": 272,
          "title": "[D] Intersection between Computer Engineering and Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/toke65/why_does_drug_discovery_with_machine_learning/",
          "author": null,
          "description": "Machine learning models are statistical, not causal in nature. That means they don’t necessarily hold on intervention. This should make predicting properties of drugs particularly problematic because we are not drawing further testing samples from a distribution that is similar to the training distribution, but we’re completely changing the input as we wish. Why is machine learning/deep learning successful at predicting these properties when the wider research community is struggling to make deep learning models robust, never mind causal, in general.\n    submitted by    /u/lemlo100  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/toke65/why_does_drug_discovery_with_machine_learning/",
          "publishedOn": "2022-03-26T08:47:12.000Z",
          "wordCount": 1270,
          "title": "Why does drug discovery with machine learning work? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tojfs4/r_texttoimage_generation_model_with_39b/",
          "author": null,
          "description": "State-of-the-art autoregressive image generation model of Kakao Brain !\n The paper and codes of \"Autoregressive Image Generation using Residual Quantization\", which is accepted by CVPR'22, are released. Our study outperforms previous autoregressive image generation models, while increasing the sampling speed upto ~7x faster.\n In addition, we release RQ-Transformer with 3.9B parameters trained on 30M text-image pairs. To the best of our knowledge, it is the largest text-to-image model among public available models.\n ​\n Examples of Generated Images in the Paper\n ​\n Examples of Generated Images by RQ-Transformer with 3.9B parameters. The model is publicly available now !\n Enjoy !\n Paper: https://arxiv.org/abs/2203.01941\n Code: https://github.com/kakaobrain/rq-vae-transformer\n    submitted by    /u/leedoyup  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tojfs4/r_texttoimage_generation_model_with_39b/",
          "publishedOn": "2022-03-26T07:34:13.000Z",
          "wordCount": 642,
          "title": "[R] Text-to-Image Generation Model with 3.9B Parameters is Publicly Available",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/toitac/d_why_gpu_workstations_are_cheaper_than_rackmount/",
          "author": null,
          "description": "I'm in the process of looking for a good GPU server for my university lab. We have a server room to install the new server. However, while looking into different vendors, I notice that workstations cost less than a rack-mount server even they have better specifications (I saw a gpu workstation with a 48-core 3.8 GHz processor and its cost still a few thousands less than a rack server with similar specifications and the same number and type of GPUs but with a lower grade processor with only 24-core 2.5 GHz). I was really surprised. Is there an advantage for buying a rack-mount GPU server over a GPU Workstation given it cost more for similar or lower specifications?\n    submitted by    /u/majax21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/toitac/d_why_gpu_workstations_are_cheaper_than_rackmount/",
          "publishedOn": "2022-03-26T06:46:21.000Z",
          "wordCount": 552,
          "title": "[D] Why GPU Workstations are cheaper than rack-mount Servers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/togtat/rp_pastiche_master_exemplarbased_highresolution/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/togtat/rp_pastiche_master_exemplarbased_highresolution/",
          "publishedOn": "2022-03-26T04:25:25.000Z",
          "wordCount": 214,
          "title": "[R][P] Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer + Hugging Face Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/2zkFf1tjvxICcwRkVBtoFV35g-8V_Sx5_7l9z6FqX0k.png?format=pjpg&auto=webp&s=27b506536a5b461bca1fc96e1435299a17cb9ae5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/toadvm/d_medium_article_on_deep_learning_for_tabular/",
          "author": null,
          "description": "I recently wrote a critical review on \"Deep Learning for Tabular Data\" which reviews whether we are ready to move from Tree-based models to Neural Network-based models for Tabular data. It covers many novel approaches such as DeepInsight, IGTD and SuperTML. It also includes some of the transformers based recent works such as TabNet, Tab-Transformer, AutoInt, FT-Transformer and regularisation models such MLP+. \n I have most commonly found the lack of a defined benchmark which makes it hard for people to find the right algorithms for the task. I am creating this discussion so that people who are using some of these algorithms or have tested some of them in different scenarios can share their findings.\n    submitted by    /u/Raghuvansh_Tahlan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/toadvm/d_medium_article_on_deep_learning_for_tabular/",
          "publishedOn": "2022-03-26T01:16:17.000Z",
          "wordCount": 437,
          "title": "[D] Medium Article on Deep Learning for Tabular Data - Your thoughts on which algorithms (DeepInsight, IGTD, SuperTML, TabNet, Tab-Transformer, AutoInt, FT-Transformer ) works most times?",
          "imageUrl": "https://external-preview.redd.it/i1M6P4Gnz10V-es2Fg7Rh1SQRcZHxG0CoSt4rZDzz6c.jpg?auto=webp&s=62412ea8ad44f862354a2a5f4f06960203e1380f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/to4gf3/p_kerasgenetic_train_keras_models_using_genetic/",
          "author": null,
          "description": "Hey r/machinelearning! Recently when working on a WorldModels implementation for keras.io I realized that I needed a genetic algorithm implementation to train the \"controller\" module. Instead of writing a one off solution, I decided to write Keras Genetic, a full package to train keras models using genetic algorithms.\n Please note genetic algorithms are not good for training neural networks outside of some niche use cases; typically training a controller with <1k parameters. The ConvNet MNIST example scores *horribly* when compared to comparable backprop examples.\n Please give the package a try and let me know if you find this interesting or useful:\n https://github.com/lukewood/keras-genetic\n    submitted by    /u/puppet_pals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/to4gf3/p_kerasgenetic_train_keras_models_using_genetic/",
          "publishedOn": "2022-03-25T22:51:24.000Z",
          "wordCount": 218,
          "title": "[P] keras-genetic: Train Keras Models Using Genetic Algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/to4a2c/d_applying_keras_imagedatagenerator_to_the/",
          "author": null,
          "description": "Hello,\n For a personal project, I intend to develop a little CNN - TransposeCNN model to colorize images of portraits. The idea is simply, from a grayscale image, to give the RGB version. To do so, I constructed a dataset of colored portraits and I would like to use the keras' ImageDataGenerator tool to specify that the feature to be the grayscale version and the label the original one.\n I could simply duplicate the current dataset and convert one of them into grayscales, and that may be easier to do, but then I would like to do something else :\n I would like to apply the same data augmentation functions from ImageDataGenerator (rotations, flipping... ) to the features and their corresponding labels.\n Do you know if it is possible or will I have to construct the augmented dataset explicitely ?\n Thank you for your advice\n    submitted by    /u/Arioxel_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/to4a2c/d_applying_keras_imagedatagenerator_to_the/",
          "publishedOn": "2022-03-25T22:42:23.000Z",
          "wordCount": 250,
          "title": "[D] Applying Keras ImageDataGenerator to the features AND labels of a dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/to2qde/what_is_the_motivation_of_checkpoint_averaging/",
          "author": null,
          "description": "According to the original \"Attention is all you need\" paper (Section 6), for the base models, they used a single model obtained by averaging the last 5 checkpoints, which were written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. \n Is it about improving the performance? But if other works didn't do the checkpoint averaging, it wouldn't be a fair comparision. However, I seldom see the recently transformer works highlighting this technique.\n What's more, I have not heard any ViT (Vision Transformer) works utilizing such a checkpoint averaging trick. My background is computer vision so I was wondering if it makes sense to try this...\n Could someone provide some guidance on this? Thanks.\n    submitted by    /u/AaronSpalding  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/to2qde/what_is_the_motivation_of_checkpoint_averaging/",
          "publishedOn": "2022-03-25T22:07:55.000Z",
          "wordCount": 500,
          "title": "What is the motivation of checkpoint averaging for Transformers? [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/to00fi/d_improving_on_timeaveraging_rnn_or_transformer/",
          "author": null,
          "description": "Currently, for a sequence classification problem I'm using a pretrained network (Transformer or RNN) as a feature extractor. I average across time to obtain a d-dimensional vector per training example and train classifier on top of these feature vectors.\n I see two improvements to simple averaging of the features:\n  \nAdd an average pooling layer and train the network end-to-end.\n Add a weighted average pooling layer and train the network end-to-end\n  \nAre there any ways that I can do better here? I am under sample size limitations, samples per class can be as low as 20, total data set size under 300, with 2-3 classes.\n I've tried method 1. and it barely changes the classification accuracy.\n    submitted by    /u/PK_thundr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/to00fi/d_improving_on_timeaveraging_rnn_or_transformer/",
          "publishedOn": "2022-03-25T21:28:41.000Z",
          "wordCount": 226,
          "title": "[D] Improving on time-averaging RNN or Transformer features for sequence classification? (few sample regime)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tnzecn/d_ml_cpu_benchmarking_when_to_upgrade_cpu/",
          "author": null,
          "description": "Are there any standard benchmarking tools or charts which compares CPU's to compare how much faster one performs than the other relative to ML training/predicting? For example, a \"5600X\" will train models 30% faster than a \"2600X, etc. which may be seconds saved on a small model our hours on a larger model.\n In the example above, I've actually a 2600X for the last 2 years and am considering to buy a 5600X, wait until AM5 CPU later this year, or switch back to Intel 12600K although Intel is at least $200 more because their MB are overpriced. It would be nice to know whether it would save me incredible amount of time so I can justify getting more experience quicker or if it's marginal and to save the money on a nice 3080 GPU, etc. and get into Deep Learning sooner.\n    submitted by    /u/bugsysiegals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tnzecn/d_ml_cpu_benchmarking_when_to_upgrade_cpu/",
          "publishedOn": "2022-03-25T21:19:20.000Z",
          "wordCount": 270,
          "title": "[D] ML CPU Benchmarking - When to upgrade CPU?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tny5ko/d_video_paper_review_typical_decoding_for_natural/",
          "author": null,
          "description": "https://youtu.be/_EDr3ryrT_Y\n Modern language models like T5 or GPT-3 achieve remarkably low perplexities on both training and validation data, yet when sampling from their output distributions, the generated text often seems dull and uninteresting. Various workarounds have been proposed, such as top-k sampling and nucleus sampling, but while these manage to somewhat improve the generated samples, they are hacky and unfounded. This paper introduces typical sampling, a new decoding method that is principled, effective, and can be implemented efficiently. Typical sampling turns away from sampling purely based on likelihood and explicitly finds a trade-off between generating high-probability samples and generating high-information samples. The paper connects typical sampling to psycholinguistic theories on human speech generation, and shows experimentally that typical sampling achieves much more diverse and interesting results than any of the current methods.\n ​\n OUTLINE:\n 0:00 - Intro\n 1:50 - Sponsor: Fully Connected by Weights & Biases\n 4:10 - Paper Overview\n 7:40 - What's the problem with sampling?\n 11:45 - Beam Search: The good and the bad\n 14:10 - Top-k and Nucleus Sampling\n 16:20 - Why the most likely things might not be the best\n 21:30 - The expected information content of the next word\n 25:00 - How to trade off information and likelihood\n 31:25 - Connections to information theory and psycholinguistics\n 36:40 - Introducing Typical Sampling\n 43:00 - Experimental Evaluation\n 44:40 - My thoughts on this paper\n ​\n Paper: https://arxiv.org/abs/2202.00666\n Code: https://github.com/cimeister/typical-sampling\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tny5ko/d_video_paper_review_typical_decoding_for_natural/",
          "publishedOn": "2022-03-25T20:20:50.000Z",
          "wordCount": 338,
          "title": "[D] Video Paper Review - Typical Decoding for Natural Language Generation (More human-like sampling from language models)",
          "imageUrl": "https://external-preview.redd.it/ttwh_rhgF0qCd8X2ldU6sJEvIAygGtxkD7AKmku5oFA.jpg?auto=webp&s=072f57ba2f5c5738b7d435b9cbba7abdddf66722"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tnx9vo/d_whats_the_mvm_minimum_viable_model_for_node/",
          "author": null,
          "description": "One core idea in ML is to use/build a simple model at first to get some minimum threshold, and then find better models or refine the existing model, improve the data, etc. \n I'd say for computer vision, in most cases, a Resnet / EfficientNet would get a good result, given enough data. \n In NLP, if it's about something very simple, Naive Bayes methods can be decent. If the task is harder, BERT would do the trick up to a certain level for many tasks\n However, choosing the first model is not obvious for many graph-related tasks where a node has more than 1 feature. For example, in node classification problems, what's a model easy to implement that guarantees decent results?\n    submitted by    /u/adenml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tnx9vo/d_whats_the_mvm_minimum_viable_model_for_node/",
          "publishedOn": "2022-03-25T19:39:50.000Z",
          "wordCount": 221,
          "title": "[D] What's the MVM (minimum viable model) for node classification?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tnowi9/d_how_do_you_defend_the_choice_of_ml_algorithm/",
          "author": null,
          "description": "For example, when is it better to use decision trees instead of SVM or KNN, based on underlying theory/distribution of the data?\n I would appreciate any empirical/theoritical advice or references. Thank you.\n    submitted by    /u/Redditagonist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tnowi9/d_how_do_you_defend_the_choice_of_ml_algorithm/",
          "publishedOn": "2022-03-25T15:51:59.000Z",
          "wordCount": 1048,
          "title": "[D] how do you defend the choice of ML algorithm depending the distribution of the data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tno47l/p_torchmetrics_how_do_we_use_it_and_whats_the/",
          "author": null,
          "description": "TorchMetrics is a really nice and convenient library that lets us compute the performance of models in an iterative fashion. It's designed with PyTorch (and PyTorch Lightning) in mind, but it is a general-purpose library compatible with other libraries and workflows. This iterative computation is useful if we want to track a model during iterative training or evaluation on minibatches (and optionally across on multiple GPUs). In deep learning, that's essentially all the time. However, when using TorchMetrics, one common question is whether we should use .update() or .forward()? (And that's also a question I certainly had when I started using it.). Here's a hands-on example and explanation.\n https://sebastianraschka.com/blog/2022/torchmetrics.html\n    submitted by    /u/seraschka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tno47l/p_torchmetrics_how_do_we_use_it_and_whats_the/",
          "publishedOn": "2022-03-25T15:14:02.000Z",
          "wordCount": 257,
          "title": "[P] TorchMetrics -- How do we use it, and what's the difference between .update() and .forward()?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tnmx1h/d_should_expert_opinion_be_a_bigger_part_of_the/",
          "author": null,
          "description": "I came across this Twitter thread which shows some interesting results when trying to recolor historical photos that have been decolored. The recolored photos are a lot drabber than the original, and the thread author says that this gives us a skewed view of the past, making us think the past was a lot more boring than it was, downplaying how vibrant and diverse certain societies were.\n https://preview.redd.it/fctveek4cjp81.png?width=3064&format=png&auto=webp&s=9aadecef7c12a4dd13f5197a69ffd155084be75e\n This made me think of some questions that I thought could lead to a good discussion here. I've put some below in no particular order!\n  \nDo you think that expert opinion should be consulted in the Machine Learning process more? If so, where? (perhaps omitting Expert Systems)\n Is there too much faith that a result from an ML model is the \"right\" result? (a phenomenon that maybe isn't specific to ML but a result of human tendencies?)\n Do ML practitioners have a responsibility to clearly communicate to the general public the limitations and degree-of-confidence in these systems?\n Am I reading too much into this, and this colorization model is just a fun model to play with, and the conclusions of the Twitter thread are too speculative or conjectural?\n Is this colorization issue just another form of bias that needs to be ironed out?\n The thread concludes by saying that colorization should be left to experts who can use context to pick accurate colors. I think this is too extreme, and that ML systems can incorporate expertise when training, or after during evaluation. Do you think there are any jobs/problems that ML methods could be applied to but should be left to experts (some considerations might be safety, privacy, ethics, etc.)\n  \nI know that ultimately a lot of these questions can simply boil down to statistics and their interpretation, so I'm not sure exactly where discussion could/should/will lead, but I'm looking forward to hearing your opinions :)\n    submitted by    /u/SleekEagle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tnmx1h/d_should_expert_opinion_be_a_bigger_part_of_the/",
          "publishedOn": "2022-03-25T14:17:32.000Z",
          "wordCount": 2161,
          "title": "[D] Should expert opinion be a bigger part of the Machine Learning world?",
          "imageUrl": "https://external-preview.redd.it/RnqHskGaLaBOPaVLYLTMee8m0WnfNT5Bmjv8natLPF0.jpg?auto=webp&s=985a58d36928a1f0eb1711317987126e4f0220db"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tna0u6/d_testing_large_models_for_convergence/",
          "author": null,
          "description": "Hi, I am wondering if there are any ways to test large neural networks (to see if they work) before training the entire model? In any case, I don't really want to train the model (which would take a long time for me) and find out that it does not converge or converges poorly.\n    submitted by    /u/ChunkOfAir  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tna0u6/d_testing_large_models_for_convergence/",
          "publishedOn": "2022-03-25T00:44:04.000Z",
          "wordCount": 145,
          "title": "[D] Testing Large Models for Convergence?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tna06n/d_author_interview_blip_bootstrapping/",
          "author": null,
          "description": "https://youtu.be/Z3knUzwuIgo\n This is an interview with Junnan Li and Dongxu Li, authors of BLIP and members of Salesforce research.\n Cross-modal pre-training has been all the rage lately in deep learning, especially training vision and language models together. However, there are a number of issues, such as low quality datasets that limit the performance of any model trained on it, and also the fact that pure contrastive pre-training cannot be easily fine-tuned for most downstream tasks. BLIP unifies different tasks and objectives in a single pre-training run and achieves a much more versatile model, which the paper immediately uses to create, filter, clean and thus bootstrap its own dataset to improve performance even more!\n ​\n OUTLINE:\n 0:00 - Intro\n 0:40 - Sponsor: Assembly AI\n 1:30 - Start of Interview\n 2:30 - What's the pitch?\n 4:40 - How did data bootstrapping come into the project?\n 7:10 - How big of a problem is data quality?\n 11:10 - Are the captioning & filtering models biased towards COCO data?\n 14:40 - Could the data bootstrapping be done multiple times?\n 16:20 - What was the evolution of the BLIP architecture?\n 21:15 - Are there additional benefits to adding language modelling?\n 23:50 - Can we imagine a modular future for pre-training?\n 29:45 - Diving into the experimental results\n 42:40 - What did and did not work out during the research?\n 45:00 - How is research life at Salesforce?\n 46:45 - Where do we go from here?\n ​\n Paper: https://arxiv.org/abs/2201.12086\n Code: https://github.com/salesforce/BLIP\n Demo: https://huggingface.co/spaces/Salesforce/BLIP\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tna06n/d_author_interview_blip_bootstrapping/",
          "publishedOn": "2022-03-25T00:43:04.000Z",
          "wordCount": 325,
          "title": "[D] Author Interview - BLIP: Bootstrapping Language-Image Pre-training (Video)",
          "imageUrl": "https://external-preview.redd.it/s44rbJawive_PUsLQTx4zO2jVlnHbv_i2GyCee75TOA.jpg?auto=webp&s=583ce834f7bd02765f38f153b6e5b8eee7287cef"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tn78l9/p_explainability_for_semantic_search/",
          "author": null,
          "description": "​\n https://preview.redd.it/7ztp9xcapep81.png?width=1410&format=png&auto=webp&s=370f3d2554e06343996c9e69a223272a25268e16\n The following notebook demonstrates a method to provide explainability for semantic search. This method masks/replaces each token for a search result to determine the importance of each term for a query. The score is then compared with the score for the full text to determine how much of a delta the permutation caused. \n https://colab.research.google.com/github/neuml/txtai/blob/master/examples/32_Model_explainability.ipynb\n    submitted by    /u/davidmezzetti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tn78l9/p_explainability_for_semantic_search/",
          "publishedOn": "2022-03-24T22:24:44.000Z",
          "wordCount": 142,
          "title": "[P] Explainability for Semantic Search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tn78gs/r_would_you_trust_an_ai_covid_diagnosis_phd/",
          "author": null,
          "description": "Hi guys, I hope this is allowed!\n I'm a PhD researcher at the University of Bristol in the UK, focussing on Human-In-The-Loop AI. I (and the others in my group) work a lot in XAI and tricky, grey-area ethical issues. Currently I'm researching how different groups, including those familiar with AI, view AI in high-stakes settings.\n As part of this I'm trying to find people to take part in my survey: \n https://forms.office.com/r/xVFu2f8qrJ\n It takes about 3m on average to complete, and there's the option to enter a raffle for one of four £25 Amazon vouchers. All of your data is completely anonymous, and the raffle is separated from the questions, so there's no way that I can associate your answers with your email. \n If you have any questions feel free to drop them in the comments!\n    submitted by    /u/Odd_Beautiful2592  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tn78gs/r_would_you_trust_an_ai_covid_diagnosis_phd/",
          "publishedOn": "2022-03-24T22:24:34.000Z",
          "wordCount": 803,
          "title": "[R] Would you trust an AI COVID diagnosis? - PhD research, <5m survey, £25 Amazon voucher raffle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tn772b/d_p_patch_spatial_interaction_for_longrange/",
          "author": null,
          "description": "Hello all,\n An idea for modelling long-range interactions in CNNs came to my mind, and I thought to share it with you folks and seek your opinions. \n On a high level, it functions akin to squeeze-and-excitation, with the chief difference being instead of calibrating channel-wise features, it operates on spatial features. Concretely, assume we start with a 3 X 256 X 256 tensor; the first step is to squeeze the channels via a convolution to get a 256 X 256 tensor. However, owing to the computational costs of the multilayer perceptron that is about to be described, it is necessary to downscale the spatial dimensions, which can be done by setting the convolution's kernel size and stride to, say, 16 (i.e., the input is being \"patchified\"). The resulting 16 X 16 matrix is flattened to yield a 25…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tn772b/d_p_patch_spatial_interaction_for_longrange/",
          "publishedOn": "2022-03-24T22:22:44.000Z",
          "wordCount": 544,
          "title": "[D] [P] Patch Spatial Interaction for Long-Range Dependencies in CNNs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tn4amb/d_suggest_some_scientific_machine_learning_for/",
          "author": null,
          "description": "-Basically I want to learn ML, to apply in scientific computing. -Learn Scientific computing, visualization and Simulations -it will be more helpful if someone knows pathway to computational biology and guide me\n    submitted by    /u/Grapes_icecream  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tn4amb/d_suggest_some_scientific_machine_learning_for/",
          "publishedOn": "2022-03-24T20:58:46.000Z",
          "wordCount": 148,
          "title": "[D] Suggest some Scientific machine learning for modeling and simulations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tn0bij/unpopular_opinion_r_is_actually_better_than_python/",
          "author": null,
          "description": "I love R. It's simple in syntax and very easy to install and run with Rstudio. Some of the data transformation libraries are very good. And even analytics libraries provide more statistical insights.\n Not to say that Python does not edge out at some places. Like having lots of libraries for almost everything, being multi-functional and huge community.\n But yet, I enjoy R more than Python. I personally find that I can get most of work done quickly in R.\n Or is it because I've been working with R, that I'm better at it!?\n    submitted by    /u/maverick_css  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tn0bij/unpopular_opinion_r_is_actually_better_than_python/",
          "publishedOn": "2022-03-24T19:59:41.000Z",
          "wordCount": 638,
          "title": "Unpopular opinion: R is actually better than Python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tmxvxe/are_you_a_machine_learning_engineer_interested_in/",
          "author": null,
          "description": "Hi everyone, I am a Researcher at UXP2 Lab Purdue University working on an NSF funded project to support practitioners to improve ethics in their everyday practice.\n Are a Machine Learning Engineer who likes to think about ethics in your everyday work? I would love for you to attend one of our virtual workshops. This three-hour workshop will engage you in co-design activities with 3-5 other technology practitioners to build, iterate on, and implement ethics-focused action plans based on provided prompts and your personal experiences. A $50 incentive will be provided for your participation. Fill out the following form to express your interest in this study:https://forms.gle/Ac89zyJLdTrnaHVS9\n We are looking for practitioners who are currently employed in roles that include (but are not limited to): Software Engineering, Data Science, Front/Back-end Development, Product Management, User Experience (UX), and other design or technology personnel responsible for the development of digital systems in any industry or governmental context.\n You can learn more about the overall grant project at https://everydayethics.uxp2.com. I am looking forward to seeing you at the virtual workshop. Thank you! If you have any questions, please feel free to message me!\n    submitted by    /u/rikeob  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tmxvxe/are_you_a_machine_learning_engineer_interested_in/",
          "publishedOn": "2022-03-24T19:25:39.000Z",
          "wordCount": 305,
          "title": "Are you a Machine Learning Engineer interested in Supporting Ethics in your Everyday work? [R]",
          "imageUrl": "https://external-preview.redd.it/HOo1NwyHBSo7aVP-VitTsxNSjLBNzoasG_BpGOvoMhk.jpg?auto=webp&s=b11f07963dbd61b63eed81e77784612449d36f01"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tmux3x/d_is_it_smart_of_me_to_do_a_ml_postdoc/",
          "author": null,
          "description": "A bit of my background: I completed a Ph.D. in statistics in Europe last year. For my Ph.D., I did some work on DL (and also had some papers published). Directly after finishing my Ph.D. I started working as a data scientist in the financial service industry. However, my goal is to move into a pure tech company and hopefully work as a research data scientist or a research scientist. Recently I have been offered a 2-year postdoc in ML in a good group in Europe. I am considering taking this postdoc since I get more time to do \"pure\" research (and to complete some of the research from my Ph.D.). Thus, would it make sense to take this postdoc with a lower salary (and worse work-life balance) for a few years if the goal is to get a \"research\" job in the industry, or would I be better of to try to \"climb the ladder\" from my current data science job?\n PS: I am new to this subreddit so I hope this post is ok.\n    submitted by    /u/Other_Hotel_6099  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tmux3x/d_is_it_smart_of_me_to_do_a_ml_postdoc/",
          "publishedOn": "2022-03-24T18:43:58.000Z",
          "wordCount": 562,
          "title": "[D] Is it smart of me to do a ML postdoc?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tmr5fc/d_which_gan_is_jon_rafman_using/",
          "author": null,
          "description": "Any ideas which GAN he is using in his latest works? Resolution and detail are insane..https://www.instagram.com/ronjafman/\n https://preview.redd.it/gxzu3ielddp81.png?width=1164&format=png&auto=webp&s=a0e3ad2d345989524d271a15df62e1d8245ffd7f\n    submitted by    /u/janni95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tmr5fc/d_which_gan_is_jon_rafman_using/",
          "publishedOn": "2022-03-24T17:50:19.000Z",
          "wordCount": 203,
          "title": "[D] Which GAN is Jon Rafman using?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tmnkhh/d_any_tools_like_streamlit_etc_using_which_i_can/",
          "author": null,
          "description": "I have a lot of untagged images, I want to show the data annotator close looking patches together, which they can just select and then give label at once. Steamlit doesn't work because it doesn't allow for batch selection of images. Is there any easy to use framework available in python using which I can make a frontend for data tagging?\n    submitted by    /u/lMAObigZEDONG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tmnkhh/d_any_tools_like_streamlit_etc_using_which_i_can/",
          "publishedOn": "2022-03-24T16:57:50.000Z",
          "wordCount": 271,
          "title": "[D] Any tools like streamlit etc. using which I can make a clustering based image tagging tool for classification. Anyone here made their own data tagging tool?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tmg2id/p_incremental_dbscan/",
          "author": null,
          "description": "Hi all,\n It might be of interest that I created a Python implementation of IncrementalDBSCAN.\n The repository, including documentation, is here: https://github.com/DataOmbudsman/incdbscan\n And this is the original paper: https://www.dbs.ifi.lmu.de/Publikationen/Papers/VLDB-98-IncDBSCAN.pdf\n The paper (from the authors of DBSCAN) describes how to make DBSCAN work with an incremental strategy, in which one can add new data points to an already existing clustering and doesn't have to re-cluster every data point. I couldn't find any implementation of the algorithm so I ended up writing my own one. I'm glad it's actually working and has a lot of unit tests covering common and special cases. The performance gain (vs reclustering with DBSCAN) is not huge though, could be worked on more. \n Happy to take any feedback!\n    submitted by    /u/DataOmbudsman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tmg2id/p_incremental_dbscan/",
          "publishedOn": "2022-03-24T15:10:42.000Z",
          "wordCount": 484,
          "title": "[P] Incremental DBSCAN",
          "imageUrl": "https://external-preview.redd.it/gzz6ZH8yskqjZ4cVVX9tMeJDXNCbIgfwDJgK2394C3Q.jpg?auto=webp&s=19301f659d6f5b45f5b0a41f4ad302898ea24ff4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tm46h9/d_fewshot_ner_entity_extraction_without/",
          "author": null,
          "description": "Hello all,\n After 1 year working extensively with GPT models (GPT-3, GPT-J, and GPT-NeoX), I think I now have a good view on what these NLP models are capable of. It appears that many traditional NLP tasks can now be achieved thanks to these large language models thanks to few-shot learning (aka \"prompting\", or \"prompt engineering\").\n NER is a very good candidate because, thanks to these models, it is possible to extract any type of entity without ever annotating and training a new model. Annotation has always been a challenge that has caused many entity extraction projects to simply fail, because it is a long and tedious process.\n In this article, I'm showing how easy it is to perform NER thanks to GPT and few-shot learning, without any annotation process: https://nlpcloud.io/few-shot-ner-entity-extraction-without-annotation-training-based-on-gpt.html\n If you also experimented with entity extraction with GPT models, I would love to hear your thoughts. Are you, like I am, impressed by the results? And do you think it means that annotation is a thing from the past?\n Thanks!\n    submitted by    /u/juliensalinas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tm46h9/d_fewshot_ner_entity_extraction_without/",
          "publishedOn": "2022-03-24T11:52:39.000Z",
          "wordCount": 277,
          "title": "[D] Few-shot NER: entity extraction without annotation and training based on GPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tm39o4/d_what_mlops_platform_do_you_use_and_how_helpful/",
          "author": null,
          "description": "Lots of options out there. I'm wondering how useful they are and whether they help you build better apps/services?\n    submitted by    /u/dmart89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tm39o4/d_what_mlops_platform_do_you_use_and_how_helpful/",
          "publishedOn": "2022-03-24T10:58:11.000Z",
          "wordCount": 1666,
          "title": "[D] What MLOps platform do you use, and how helpful are they?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tm0ozh/d_following_is_geometry_a_language_that_only/",
          "author": null,
          "description": "After reading the post on Is Geometry a Language That Only Humans Know? I see comments about spiders and their fascinating capabilities to use their legs and vibration sensor and not their eyes to build the web. I had an episode about it and one of the questions about the error assessment and how they know when they should stop building or whether it is right? How they can know if there is a damage in the web. Also the interesting part about their brain behavior.\n Links in the comment in case you are interested.\n    submitted by    /u/meldiwin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tm0ozh/d_following_is_geometry_a_language_that_only/",
          "publishedOn": "2022-03-24T07:54:50.000Z",
          "wordCount": 220,
          "title": "[D] Following: Is Geometry a Language That Only Humans Know? \" How Do Spiders Build Their Webs? \"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tly88s/r_inferring_articulated_rigid_body_dynamics_from/",
          "author": null,
          "description": "They introduce a new method to learn simulators from depth and RGB videos. The \"URDF\" of an articulated rigid-body mechanism is reconstructed, and the parameters of the simulator inferred through Bayesian inference.\n Website: https://eric-heiden.github.io/video2sim/\n Paper: https://arxiv.org/abs/2203.10488\n Twitter Summary: https://twitter.com/eric_heiden/status/1506756429285191682\n    submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tly88s/r_inferring_articulated_rigid_body_dynamics_from/",
          "publishedOn": "2022-03-24T05:04:50.000Z",
          "wordCount": 203,
          "title": "[R] Inferring Articulated Rigid Body Dynamics from RGBD Video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tltji3/d_is_geometry_a_language_that_only_humans_know/",
          "author": null,
          "description": "A general public paper in the New-York Times explores whether humans are the only species able to master geometry. Neuroscientists like Stanislas Dehaene at Collège de France, Moira Dillon at New York University, and Josh Tenenbaum at MIT are exploring whether human ability to reason about geometric shapes like squares and rectangles are part of what makes humans special. Dehaene said. “I love the progress in A.I. It’s very impressive. But I believe that there is a deep aspect missing, which is symbol processing”. Yoshua Bengio, at the Université de Montréal, agreed that state-of-the-art machine learning lacks something related to symbols or abstract reasoning. It’s not impossible to do abstract reasoning with neural networks, Bengio said, “it’s just that we don’t know yet how to do it.” It’s an indication, Bengio said, of where A.I. research needs to go.\n    submitted by    /u/ClaudeCoulombe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tltji3/d_is_geometry_a_language_that_only_humans_know/",
          "publishedOn": "2022-03-24T01:56:09.000Z",
          "wordCount": 1317,
          "title": "[D] Is Geometry a Language That Only Humans Know?",
          "imageUrl": "https://external-preview.redd.it/4nHe5JzlETkUVnC14egiX_0AbtAPjUAbu32q9B2H6iw.jpg?auto=webp&s=f68338a6bc613f981b897f8354b06163fdee1cdd"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tloweh/d_is_evaluation_faster_on_gpu_or_cpu/",
          "author": null,
          "description": "I work with NLP primarily, and find that sometimes it's faster on one or the other. \n Surprisingly, evaluation on GPU takes as much time as training, even if I do .eval(). I don't understand why. \n Is there a general rule of thumb on if evaluation should be done on GPU or CPU? \n Any tips? \n Thanks!\n    submitted by    /u/cuddle_cuddle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tloweh/d_is_evaluation_faster_on_gpu_or_cpu/",
          "publishedOn": "2022-03-24T00:36:03.000Z",
          "wordCount": 176,
          "title": "[D] Is evaluation faster on GPU or CPU?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tlauw4/d_paper_explained_video_blip_bootstrapping/",
          "author": null,
          "description": "https://youtu.be/X2k7n4FuI7c\n Cross-modal pre-training has been all the rage lately in deep learning, especially training vision and language models together. However, there are a number of issues, such as low quality datasets that limit the performance of any model trained on it, and also the fact that pure contrastive pre-training cannot be easily fine-tuned for most downstream tasks. BLIP unifies different tasks and objectives in a single pre-training run and achieves a much more versatile model, which the paper immediately uses to create, filter, clean and thus bootstrap its own dataset to improve performance even more!\n ​\n OUTLINE:\n 0:00 - Intro\n 0:50 - Sponsor: Zeta Alpha\n 3:40 - Paper Overview\n 6:40 - Vision-Language Pre-Training\n 11:15 - Contributions of the paper\n 14:30 - Model architecture: many parts for many tasks\n 19:50 - How data flows in the model\n 26:50 - Parameter sharing between the modules\n 29:45 - Captioning & Filtering bootstrapping\n 41:10 - Fine-tuning the model for downstream tasks\n ​\n Paper: https://arxiv.org/abs/2201.12086\n Code: https://github.com/salesforce/BLIP\n Demo: https://huggingface.co/spaces/Salesforce/BLIP\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tlauw4/d_paper_explained_video_blip_bootstrapping/",
          "publishedOn": "2022-03-23T19:55:16.000Z",
          "wordCount": 282,
          "title": "[D] Paper Explained Video - BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tl9q82/d_hosting_ai_art_generative_ml_model/",
          "author": null,
          "description": "I am looking for a solution to host an AI art generative ML model for use with an external API. What is the best practice or simplest solution?\n Here's what I've considered so far:\n  \nHugging Face (Gradio) - the VQGAN_CLIP model is down, which doesn't instill confidence...\n Docker, cog, and replicate.com - it doesn't seem to have API capability.\n RunwayML - they seem to be pivoting away from such a service.\n NodeJS and some cloud hosting service (Amazon?) - may be complex to set up, are there any straightforward tutorials to host say VQGAN+CLIP? Would the process be different for a diffusion model?\n  \nHow do tools like WOMBO host their models? Anyone have advice before I start going down a dead end?\n I have some software engineering and machine learning experience, but none with deployment.\n Thanks!\n    submitted by    /u/WildRaccoon8427  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tl9q82/d_hosting_ai_art_generative_ml_model/",
          "publishedOn": "2022-03-23T19:36:22.000Z",
          "wordCount": 424,
          "title": "[D] Hosting AI Art Generative ML Model",
          "imageUrl": "https://external-preview.redd.it/nqzWAoJ_NO3l2bHUBRdFcfMLELuzjX5HGl9_66D9aeA.jpg?auto=webp&s=cf584238db985fba8241b2cfa3bc1bded0c67957"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tkuszz/d_roadmap_feedback_on_ds_opensource/",
          "author": null,
          "description": "Hey All!\n So we've been working on an open-source product to help data scientists build faster. We've revamped our long term road map and we'd like to hear thoughts on our direction and vision. This is the roadmap.\n Any insights/feedback is much appreciated!\n    submitted by    /u/idomic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tkuszz/d_roadmap_feedback_on_ds_opensource/",
          "publishedOn": "2022-03-23T14:11:11.000Z",
          "wordCount": 133,
          "title": "[D] Roadmap feedback on DS open-source",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tksq25/d_is_it_possible_to_train_an_ai_to_decode/",
          "author": null,
          "description": "With a theoretically large enough dataset of encrypted content corresponding to their unencrypted versions, it it possible to train an AI to develop a method of decryption that’s better than brute-force? If not all, can this work with some encryption methods?\n    submitted by    /u/Plane_Bite3639  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tksq25/d_is_it_possible_to_train_an_ai_to_decode/",
          "publishedOn": "2022-03-23T12:23:26.000Z",
          "wordCount": 1262,
          "title": "[D] Is It Possible to Train an AI to Decode Encrypted Content?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tkq4ou/d_why_do_gans_work_knowing_that_the_discriminator/",
          "author": null,
          "description": "f CNNS do not take spatial information into account since filters are looking for features in different locations and output the same feature maps, no matter where the feature is located in the input image, what makes the discriminator robust to real features appearing in random locations ?\n    submitted by    /u/Wonderful-Donut-6687  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tkq4ou/d_why_do_gans_work_knowing_that_the_discriminator/",
          "publishedOn": "2022-03-23T09:32:57.000Z",
          "wordCount": 809,
          "title": "[D] Why do GANS work knowing that the discriminator does not take spatial information into account",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tkjbsw/d_how_to_check_if_a_paper_has_been_plagiarized/",
          "author": null,
          "description": "Any recommendations for tools to check if a paper has been plagiarized? I have an unfortunate situation that may require a thorough examination of another researcher’s work. For example, how did they determine that Siraj Raval’s work was plagiarized? I assume the big ML conferences perform some sort of automated check for plagiarism, right?\n    submitted by    /u/purplebrown_updown  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tkjbsw/d_how_to_check_if_a_paper_has_been_plagiarized/",
          "publishedOn": "2022-03-23T02:03:43.000Z",
          "wordCount": 924,
          "title": "[D] How to check if a paper has been plagiarized?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tkda9c/d_relative_error_metrics_comparing_model/",
          "author": null,
          "description": "Is anyone aware of metrics or measures that classify the error relative the complexity of the model. If so could anyone provide some references where people have introduced such a notion?\n    submitted by    /u/AbjectDrink3276  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tkda9c/d_relative_error_metrics_comparing_model/",
          "publishedOn": "2022-03-22T21:11:51.000Z",
          "wordCount": 133,
          "title": "[D] Relative error metrics comparing Model complexity versus error",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tkaihr/r_google_research_selfconsistency_improves_chain/",
          "author": null,
          "description": "submitted by    /u/ReasonablyBadass  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tkaihr/r_google_research_selfconsistency_improves_chain/",
          "publishedOn": "2022-03-22T19:09:18.000Z",
          "wordCount": 134,
          "title": "[R] Google Research: Self-Consistency Improves Chain of Thought Reasoning in Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tk8ika/pr_hear_what_you_see_autoencoder_to_convert_video/",
          "author": null,
          "description": "GitHub: https://github.com/muxamilian/wysiwyh\n WYSIWHY is a neural network that transforms an input video into an audio sequence in real time. It does so by compressing each image using an autoencoder and interpreting the resulting code as a frequency range.\n This could potentially be useful for the visually impaired, helping with indoor navigation. It could also be used to transform an infrared or ultraviolet video to sound and thus enable one to perceive otherwise invisible colors.\n Demo; recommended with sound turned on\n In a usual autoencoder, the elements of the code vector are independent of each other. This makes subtle differences between adjacent elements of the code vector hard to perceive for humans. The resulting audio sequence would sound like indistinguishable white noise. For WYSIWYH thus an encoder is used which hierarchically structures the code, meaning that large differences in the input image result in large differences in the output code. This also results in adjacent elements of the code vector being correlated. This makes the autoencoder’s code more friendly to human perception.\n Overall approach\n    submitted by    /u/muxamilian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tk8ika/pr_hear_what_you_see_autoencoder_to_convert_video/",
          "publishedOn": "2022-03-22T17:41:16.000Z",
          "wordCount": 486,
          "title": "[P][R] Hear what you see: Autoencoder to convert video to audio",
          "imageUrl": "https://external-preview.redd.it/4StmQX9gSDFuCiGvmVwd_WW19tfzM62GpihdgnzzCyM.jpg?auto=webp&s=5e58c87ba72b97439efbee4d2a453faf3be72790"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tk61vh/r_improving_anatomical_plausibility_in_medical/",
          "author": null,
          "description": "https://arxiv.org/abs/2203.10977\n    submitted by    /u/gaggi_94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tk61vh/r_improving_anatomical_plausibility_in_medical/",
          "publishedOn": "2022-03-22T15:52:00.000Z",
          "wordCount": 129,
          "title": "[R] Improving anatomical plausibility in medical image segmentation via hybrid graph neural networks: applications to chest x-ray analysis",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tk41hz/d_stumpy_v1110_released_for_modern_time_series/",
          "author": null,
          "description": "We're happy to announce the release of STUMPY v1.11.0! This version includes the oft requested Minkowski (p-norm) Distance, support for Multi-dimensional Motif Discovery, new Annotation vector tutorials, and enhancements for Pan Matrix Profiles!\n https://github.com/TDAmeritrade/stumpy\n    submitted by    /u/slaw07  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tk41hz/d_stumpy_v1110_released_for_modern_time_series/",
          "publishedOn": "2022-03-22T14:18:33.000Z",
          "wordCount": 302,
          "title": "[D] STUMPY v1.11.0 Released for Modern Time Series Analysis",
          "imageUrl": "https://external-preview.redd.it/TOrBn9rmbMymheLzeLdul1VhwJkAlB6tlNGtIUIYuCU.jpg?auto=webp&s=8f2e03f42519c45027dba70380d878d8b5e4f613"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tk07jt/n_call_for_submissions_foundations_of_digital/",
          "author": null,
          "description": "FDG2022: Foundations of Digital Games 2022Athens, Greece, September 5-8, 2022Conference website: http://fdg2022.org/\n Foundations of Digital Games (FDG) 2022 invites research contributions in the form of papers, posters and demos, doctoral consortium applications, as well as panel, competition, and workshop proposals.\n We invite contributions from within and across any discipline committed to advancing knowledge on the foundations of games: computer science and engineering, humanities and social sciences, arts and design, mathematics and natural sciences. As was the case in the previous years, we aim to publish the FDG 2022 proceedings in the ACM Digital Library. ​FDG invites authors to submit short or full papers reporting new research. Both short and full papers need to be anonymized and…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tk07jt/n_call_for_submissions_foundations_of_digital/",
          "publishedOn": "2022-03-22T10:50:28.000Z",
          "wordCount": 434,
          "title": "[N] Call for submissions: Foundations of Digital Games 2022, 5-8 September (Athens, GR & hybrid)",
          "imageUrl": "https://external-preview.redd.it/eqIK336hG76FlnFhddb_PAVBt-Uz2xOkqlsc_1CAsCM.jpg?auto=webp&s=85e97a81881e1453bee27868654a4855af123243"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tjz1wd/r_jax_meets_flower_federated_learning_with_jax/",
          "author": null,
          "description": "Flower and its community are growing. Since Flower is a friendly federated learning framework, the goal is always to get an easy start to federated learning for every data scientist. \n This involves having Flower coding examples for different machine learning frameworks.\n One of the frameworks is JAX which was developed by Google researchers to run NumPy programs on GPUs and TPUs. It is quickly rising in popularity and is used by DeepMind to support and accelerate its research.\n We couldn’t miss the opportunity to create a code example and a blog post about “JAX meets Flower - Federated Learning with JAX”. \n It takes always some time to get into a new machine learning framework and its syntax but it is easy to combine it with Flower. \n You can check out the blog post here: https://flower.dev/blog/2022-03-22-running-jax-federated-jax-meets-flower/ \n If you are interested in writing a blog post for our Flower community, contact me.\n    submitted by    /u/burnai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tjz1wd/r_jax_meets_flower_federated_learning_with_jax/",
          "publishedOn": "2022-03-22T09:28:16.000Z",
          "wordCount": 248,
          "title": "[R] JAX meets Flower - Federated Learning with JAX",
          "imageUrl": "https://external-preview.redd.it/K7oVtfvZeiT84TZ-34d8ygfZdGhmH2DIOpRJIPzteQU.jpg?auto=webp&s=d7d494f4a34167a179923d7a51e6ff67d11091c3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tjx4t5/d_with_experience_deploying_batch_models_how_to/",
          "author": null,
          "description": "Hi!\n I have some experience deploying batch machine learning models and now I want to learn about real-time models. More specifically, how to put them in production and what are the best practices and tools for different use-cases.\n Any ideas? I was thinking of reading the book \"Designing Event-Driven Systems\" by Ben Stopford (I think it's based on Kafka which seems quite popular), but would like to hear your thoughts or if someone has any other reference.\n Thanks and I hope this is the right sub!\n    submitted by    /u/Silver_Book_938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tjx4t5/d_with_experience_deploying_batch_models_how_to/",
          "publishedOn": "2022-03-22T07:04:09.000Z",
          "wordCount": 194,
          "title": "[D] With experience deploying batch models, how to learn about streaming?",
          "imageUrl": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?auto=webp&s=b3d69b2b1fe2e737d3cd99f3c114278d4c50a82e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tjvttx/p_a_social_platform_to_rate_and_review_machine/",
          "author": null,
          "description": "We developed a social platform for everyone to rate and review machine learning research papers. One can think of it as the IMDB database for the research community.\n Link: https://doublind.com\n Features we think that are important:\n  \nSearch all machine learning related papers, old and new.\n Rate and review the paper you've just read, open or anonymous.\n A profile page is created for all users to display their paper reviews.\n Each paper has a rating score that help users find good papers to read.\n Users can like, comment and share a paper review, helping it reaching more readers.\n  \n​\n We'd love to hear your feedback and suggestions. Thank you all and we appreciate the support.\n    submitted by    /u/DouBlindDotCOM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tjvttx/p_a_social_platform_to_rate_and_review_machine/",
          "publishedOn": "2022-03-22T05:33:57.000Z",
          "wordCount": 1204,
          "title": "[P] A Social Platform to Rate and Review Machine Learning Research Papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tjv2tl/d_always_behind_sota/",
          "author": null,
          "description": "How do you guys deal with the stress of developing a new models and being off from SOTA but also needing to publish papers? \n Do people publish results that aren’t quite SOTA? Do you tweak results? Do you do something else?\n    submitted by    /u/AbjectDrink3276  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tjv2tl/d_always_behind_sota/",
          "publishedOn": "2022-03-22T04:44:21.000Z",
          "wordCount": 966,
          "title": "[D] always behind Sota",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tjsd7w/r_transencoder_unsupervised_sentencepair/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tjsd7w/r_transencoder_unsupervised_sentencepair/",
          "publishedOn": "2022-03-22T02:10:07.000Z",
          "wordCount": 107,
          "title": "[R] Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tjrtb9/d_will_a_phd_in_biomedical_engineering_limit/",
          "author": null,
          "description": "I’m a tech in an academic computational lab at a very large US flagship R1 university. My current lab is a neuroscience lab that does lots of ML theory stuff (bio inspired ML). My primary goal is to get a PhD and find a research scientist position in industry at a non-FAANG company. \n Because my PI is a neuroscientist, I might not be able to work with him as a PhD student if I apply to the EE or CS program at this university, but he has an affiliate appointment at the Biomedical Engineering department. \n Would having a biomedical engineering degree in any way affect my ability to get a research scientist ML job? As long as I have a productive PhD with ML publications etc., and get internships at relevant places, I should be fine right? Will I have a worse chance at non-biotech companies? If BME is an issue, I’m sure my PI can get affiliate status in EE, because he has multiple collaborators in EE.\n    submitted by    /u/throawaythroaway11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tjrtb9/d_will_a_phd_in_biomedical_engineering_limit/",
          "publishedOn": "2022-03-22T01:42:01.000Z",
          "wordCount": 1482,
          "title": "[D] Will a PhD in Biomedical Engineering limit opportunities if I want to become a research scientist in ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tjmfk6/d_how_to_compute_the_probability_of_trajectories/",
          "author": null,
          "description": "I asked this question on stats stackexchange, and it is posted here. I don't copy it here because formulas don't show up nicely on reddit.\n I am trying to implement this paper by Fallah et al (NIPs 2021) titled: On the Convergence Theory of Debiased Model-Agnostic Meta-Reinforcement Learning. As the title suggests, they propose an algorithm for meta RL that uses an stochastic approximation of the gradient. My problem is with the term that yields the probability of a given trajectory (a sequence of state-actions). I don't know how to estimate that term and the paper doesn't discuss that. I'd appreciate if anyone can share any insight on how to estimate that term.\n    submitted by    /u/carlml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tjmfk6/d_how_to_compute_the_probability_of_trajectories/",
          "publishedOn": "2022-03-21T21:24:55.000Z",
          "wordCount": 231,
          "title": "[D] How to compute the probability of trajectories term in Stochastic Gradient Meta Reinforcement Learning",
          "imageUrl": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?auto=webp&s=e25be8cb5cf2448d39a7e5ffc877e4d466b776d3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tjj23w/dp_neural_network_as_frequency_offset_corrector/",
          "author": null,
          "description": "Hi everyone! I'm working on a project where I'm using neural networks to overcome some RF impairments in a wireless communications system. When I introduce a frequency offset to the data, my current neural network (which is a simple 2 hidden layer feed-forward NN) can not compensate. The frequency offset is basically a phase rotation on the IQ samples. The problem is this is also time-dependent such that the amount the sample is shifted is a function of time. ie: x_out[n] = x[n]e^(j2*pi*w*n) where w is the phase shift from the frequency offset, n is the discrete sample. I know my NN needs some kind of memory (so I should use an LSTM or some RNN variant), just wondering if anyone has some recommended papers or has done some work similar to this and would be willing to help, thanks!\n    submitted by    /u/mtot10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tjj23w/dp_neural_network_as_frequency_offset_corrector/",
          "publishedOn": "2022-03-21T18:54:23.000Z",
          "wordCount": 254,
          "title": "[D][P] Neural Network as Frequency Offset Corrector",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tjd7ek/p_a_new_way_to_start_stop_and_distribute_code_on/",
          "author": null,
          "description": "Hi everyone!\n With a friend, we are develpoing a tool to be able to easily start pods, distribute the code (with magics) and stop them directly from your notebook.\n Pods can be started in seconds with the specifications you need: number of instances/pods, CPU, Memory, GPU and packages\n The tool makes it easy to increase computer resources quickly, code locally and consume resources only when you need it, paralelize tasks and do parameter grid search.\n If you like it, you can visit our landing page and register for early access: telekinesis.cloud\n We are giving 10 GPU hours to our first 50 registered users!\n We hope you like it! Thank you!\n Please share feedback\n    submitted by    /u/snuns90  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tjd7ek/p_a_new_way_to_start_stop_and_distribute_code_on/",
          "publishedOn": "2022-03-21T14:34:41.000Z",
          "wordCount": 249,
          "title": "[P] A new way to start, stop and distribute code on cloud instances/pods - directly from any notebook, only when you need it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tj8z5w/r_evorl_gecco_2022_2nd_evolutionary_rl_workshop/",
          "author": null,
          "description": "CALL FOR PAPERSEvoRL 2022Evolutionary Reinforcement Learning workshop at GECCO 2022, July 9-13, Boston, USA\n \n In recent years reinforcement learning (RL) has received a lot of attention thanks to its performance and ability to address complex tasks. At the same time, multiple recent papers, notably work from OpenAI, have shown that evolution strategies (ES) can be competitive with standard RL algorithms on some problems while being simpler and more scalable. Similar results were obtained by researchers from Uber, this time using a gradient-free genetic algorithm (GA) to train deep neural networks on complex control tasks. Moreover, recent research in the field of evolutionary algorithms (EA) has led to the development of algorithms like Novelty Search and Quality Diversity, capable of eff…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tj8z5w/r_evorl_gecco_2022_2nd_evolutionary_rl_workshop/",
          "publishedOn": "2022-03-21T10:49:00.000Z",
          "wordCount": 603,
          "title": "[R] EvoRL @ GECCO 2022: 2nd Evolutionary RL workshop @ GECCO 2022",
          "imageUrl": "https://external-preview.redd.it/lK42WwByGG32nygWSBuOYR3KR5RyUTDVfuLYvfjqmTI.jpg?auto=webp&s=02c389b64acc7a9d40c4c4ad6555c2381750877f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tj6jj5/p_identifying_someones_professional_background/",
          "author": null,
          "description": "Hi, \n As the title points out, I would like to identify someone's professional background (e.g. engineering, art, ...) through his syntax. \n To do so my strategy was to find a dataset regrouping messages alongside the person's background but it doesn't exist (to my knowledge)\n Do you guys have any idea to persue? (any good dataset?, trying to find multiple datasets and merging them?, scraping LinkedIn?)\n Is it even possible to e.g. scrape LinkedIn for such information?\n Any thoughts and feedback are welcome!\n Initial strategy:\n - Either finding a dataset or scraping LinkedIn. (is it even possible?)\n - Training a NN.\n Alternative question:\n - Do you know of any other approach that would be less data intensive using for instance hand crafted features, computational linguistics and the such?\n Cheers,\n    submitted by    /u/Inquation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tj6jj5/p_identifying_someones_professional_background/",
          "publishedOn": "2022-03-21T08:00:25.000Z",
          "wordCount": 554,
          "title": "[P] Identifying someone's professional background through his syntax.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tj6ir8/rp_adafamily_a_family_of_adamlike_adaptive/",
          "author": null,
          "description": "submitted by    /u/HannesF99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tj6ir8/rp_adafamily_a_family_of_adamlike_adaptive/",
          "publishedOn": "2022-03-21T07:59:24.000Z",
          "wordCount": 263,
          "title": "[R][P] AdaFamily: A family of Adam-like adaptive gradient methods",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tj5la9/r_monotonic_differentiable_sorting_networks_w/",
          "author": null,
          "description": "I have made an animated video (https://www.youtube.com/watch?v=Rl-sFaE1z4M) for our ICLR 2022 paper (https://arxiv.org/abs/2203.09630).\n Check it out if you are interested. I have made the video using 3b1b's manim library (https://github.com/ManimCommunity/manim).\n Feedback is always very welcome!\n    submitted by    /u/Human-Career-9962  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tj5la9/r_monotonic_differentiable_sorting_networks_w/",
          "publishedOn": "2022-03-21T06:52:41.000Z",
          "wordCount": 178,
          "title": "[R] Monotonic Differentiable Sorting Networks w/ animated video (ICLR 2022)",
          "imageUrl": "https://external-preview.redd.it/wYEcI8Jy5-LfTSb7MovHirQHB-bUNmnIyqbc7QBeq6E.jpg?auto=webp&s=ded25b4a47431a7cf854e7b25b1a5e238ef7b1e3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tj3f9t/n_linkedin_open_sources_fasttreeshap_python/",
          "author": null,
          "description": "LinkedIn open sources the FastTreeSHAP Python package for efficient interpretation of tree-based ML models (XGBoost, LightGBM, sklearn random forest) using SHAPLEY. FastTreeSHAP v2 would be 2.5x faster than TreeSHAP. Let's reminder that SHAP (SHapley Additive exPlanation) values quantify the contribution of each feature to the model prediction, a bit like how each player contributes to the success of a sports team. SHAP does it by incorporating concepts from game theory and local explanations. Naively implemented, SHAP takes exponential time. LinkedIn blog post, scientific paper, and GitHub repo with IPython Notebooks.\n    submitted by    /u/ClaudeCoulombe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tj3f9t/n_linkedin_open_sources_fasttreeshap_python/",
          "publishedOn": "2022-03-21T04:26:08.000Z",
          "wordCount": 229,
          "title": "[N] LinkedIn open sources FastTreeSHAP Python package for interpretation of tree-based ML models",
          "imageUrl": "https://external-preview.redd.it/7vxs718reIPUyFJexhcRfBrVMjVcisszU2SMb2e6FQk.jpg?auto=webp&s=56d87053b4085923f05ce2047d7c46cd0492280f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tj3dqj/d_using_ml_interpretability_techniques_for_data/",
          "author": null,
          "description": "Hey, all. Hope you lot are doing alright.\n I was looking into Explainable AI and model interpretability lately, and I had an idea but am wondering whether it would constitute a valid use case.\n There is a data analysis project happening at work where we're trying to analyze data we had on hand to determine the factors that affect our KPOs and possibly derive useful actionable insights. Instead of moving forward with manually evaluating correlation and doing EDA that way, I was thinking of using variable importance measures, subpopulation analyses, and partial dependence profiles to potentially gain insights, or at the very least narrow down exploratory scope.\n I have been scrounging the internet for someone using white box models for expediting analysis tasks, but I haven't found anything that remotely fits the bill except perhaps this article: https://medium.com/swlh/how-i-used-a-machine-learning-model-to-generate-actionable-insights-3aa1dfe2ddfd\n It'd be great if you guys let me know what you think.\n Cheers,\n    submitted by    /u/Impartial_Bystander  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tj3dqj/d_using_ml_interpretability_techniques_for_data/",
          "publishedOn": "2022-03-21T04:23:31.000Z",
          "wordCount": 244,
          "title": "[D] Using ML Interpretability Techniques for Data Analysis",
          "imageUrl": "https://external-preview.redd.it/F_n66xCQobjUHU4StsPZ5aZbYCENE695ZxD65TPG9C4.jpg?auto=webp&s=2059c8a7f2fd87165ab551f31ddc315476ce296e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tj34qs/d_why_is_the_predictive_variance_of_bayesian/",
          "author": null,
          "description": "Is there a direct link or explanation on why the predictive variance of a Bayesian model can be interpreted as epistemic uncertainty?\n Many epistemic uncertainty quantification methods, for example, MC-Dropout, Deep Ensemble, claim themselves as a Bayesian model to justify their approach for quantifying uncertainty. Let's just say their claims are valid so that the methods are truly Bayesian. But then, why are Bayesian methods supposed to estimate uncertainty well?\n    submitted by    /u/swyoon_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tj34qs/d_why_is_the_predictive_variance_of_bayesian/",
          "publishedOn": "2022-03-21T04:08:42.000Z",
          "wordCount": 264,
          "title": "[D] Why is the predictive variance of Bayesian models can be interpreted as epistemic uncertainty?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tizy60/d_dealing_with_normalisation_of_data_containing/",
          "author": null,
          "description": "Hi everyone,\n Imagine there’s a rainfall dataset, and there’s surely extreme values in the dataset. These extreme values are important because I would need them to predict extreme events. \n Unfortunately, when doing normalisation, these extreme values will tend to result in almost every other values being extremely small after min-max. Any suggestions to go about this?\n This is for research\n    submitted by    /u/plsendfast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tizy60/d_dealing_with_normalisation_of_data_containing/",
          "publishedOn": "2022-03-21T01:14:37.000Z",
          "wordCount": 546,
          "title": "[D] Dealing with normalisation of data containing extreme values",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tizt3n/d_equivariant_subgraph_aggregation_networks/",
          "author": null,
          "description": "An author interview on the Equivariant Subgraph Aggregation Networks paper. Discusses why the expressive power of GNNs is limited and a method for breaking the bottleneck of the 1-WL algorithm \n https://youtu.be/VYZog7kbXks\n    submitted by    /u/zjost85  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tizt3n/d_equivariant_subgraph_aggregation_networks/",
          "publishedOn": "2022-03-21T01:07:01.000Z",
          "wordCount": 119,
          "title": "[D] Equivariant Subgraph Aggregation Networks",
          "imageUrl": "https://external-preview.redd.it/34_1Ip8q2_ajtzk3z2womzhfe6YH1R-IsOfmWJL8D58.jpg?auto=webp&s=55540f51bb651be6facc74de0fc649b1a234aaaf"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tivnnb/rp_stylenerf_a_stylebased_3daware_generator_for/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tivnnb/rp_stylenerf_a_stylebased_3daware_generator_for/",
          "publishedOn": "2022-03-20T21:41:42.000Z",
          "wordCount": 180,
          "title": "[R][P] StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis + Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/Sh2o7WmXPa6oPtlUvPc9SeEVn69UJXhfriKI6ISP-jM.png?format=pjpg&auto=webp&s=467c7e5293cb8cdc1339d3ca592707e65113aa0b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tiuy88/p_problems_with_rainfall_prediction_with_neural/",
          "author": null,
          "description": "So I am trying to make a neural network which would predict if it's raining or not. However I'm having problems with the neural network because it seems to not learn at all. Or at least it gives very low propability for any data which I try to predict. The dataset contains temperature, pressure, and relative humidity which are mesaured every 10 minutes. The data is from Finnish Weather forecast center (Ilmatieteenlaitos). I'm also modifying the data so that I can feed 24h of values for each rainfall value in to the neural network. Here is a photo explaining this better https://imgur.com/a/jFpsN8Q and here is the code for the project https://www.kaggle.com/code/juhosyvjrvi/rainfall-prediction/notebook \n Thank you for any help in advance!\n    submitted by    /u/Juuhis999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tiuy88/p_problems_with_rainfall_prediction_with_neural/",
          "publishedOn": "2022-03-20T21:08:05.000Z",
          "wordCount": 358,
          "title": "[P] Problems with rainfall prediction with neural network.",
          "imageUrl": "https://external-preview.redd.it/fPWwpdnYq8y-5KA2E6-CpNOjBZlPSglH_HzIMFwZ9_0.jpg?auto=webp&s=bcf700edf8a6ae66227e8f634947b94d526f573c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/titsid/r_explaining_the_explainable_ai_a_2stage_approach/",
          "author": null,
          "description": "submitted by    /u/pinter69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/titsid/r_explaining_the_explainable_ai_a_2stage_approach/",
          "publishedOn": "2022-03-20T20:15:29.000Z",
          "wordCount": 475,
          "title": "[R] Explaining the Explainable AI: A 2-Stage Approach - Link to a free online lecture by the author in comments",
          "imageUrl": "https://preview.redd.it/oegpiai9jlo81.png?auto=webp&s=9203a18abac5d3d7a236dbf8f0d700ac98c7c9b7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tirbmm/d_code_to_visualize_attention_heads/",
          "author": null,
          "description": "I was wondering if anyone has any code they use in python to visualize attention head maps for transformer architectures. If so are you willing to share it?\n    submitted by    /u/AbjectDrink3276  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tirbmm/d_code_to_visualize_attention_heads/",
          "publishedOn": "2022-03-20T18:22:14.000Z",
          "wordCount": 200,
          "title": "[D] code to visualize attention heads",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tin2cf/d_does_repl4nlp_accept_papers_such_as_pruning_and/",
          "author": null,
          "description": "Does RepL4NLP accept papers such as pruning and quantization? The link below gives you a list of topics if you scroll down. One of them was \" Efficient learning of representations and inference: with respect to training and inference time, model size, amount of training data, etc.\". I was wondering if that has anything to do with pruning and/or quantization?\n ​\n https://sites.google.com/view/repl4nlp2022/\n    submitted by    /u/SiegeMemeLord  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tin2cf/d_does_repl4nlp_accept_papers_such_as_pruning_and/",
          "publishedOn": "2022-03-20T15:06:50.000Z",
          "wordCount": 228,
          "title": "[D] Does RepL4NLP accept papers such as pruning and quantization?",
          "imageUrl": "https://external-preview.redd.it/naAeVi9M_stZYBOyUR6mh4f8ScFnQeYbBom-lJbmTsI.jpg?auto=webp&s=45d06ae7a830ae0269e109ee3fa412725d0e1f3a"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/timcsd/discussion_reaearch_anomaly_detection_in_massive/",
          "author": null,
          "description": "Hi everyone. I am looking for reaearch papers and ideas on how to solve this problem for my master’s thesis. Any pointers to SOTA reearch would be greatly appreciated. Let me just quickly summarize the problem at hand:\n  \nThere are over 100k devices connected to this cloud network, where the devices track the GPS location of shipping containers. Most of the containers also have a cooling system, where it’s possible to read a couple of sensor data and also remotely control temperature/humidity in the containers.\n \nMy main objective is to apply some ML algo to try and predict if some device (or the integrated cooling system) is about become faulty, such that it can trigger an alarm and consequently get someone to inspect the devices due to possible malfunction.\n \nThe approach: Just on top of my mind, I would like to apply some unsupervised learning technique to detect if some device is behaving far from the norm. \n \nI am even more intetested in supervised learning, but it might be a little tricky to tell based on a record if it’s faulty (target variable)\n \n Any ideas? Feel free to ask if something isn’t clear.\n Training a model on 100TB of data might become a challenge in itself. I would have to apply some algo that can learn iteratively.\n Thanks!\n    submitted by    /u/shotez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/timcsd/discussion_reaearch_anomaly_detection_in_massive/",
          "publishedOn": "2022-03-20T14:33:24.000Z",
          "wordCount": 644,
          "title": "[Discussion] / [Reaearch]: Anomaly detection in massive datasets (70-100 TerraBytes)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tij9t9/d_papers_about_true_utilization_of_pruning/",
          "author": null,
          "description": "Good day, my fellow researchers and engineers. \n Most of the unstructured pruning algorithms cannot induce their theoretical performance due to the fact that we cannot ignore the zeros when the actual computation occurs.\n I recently read the paper about N:M structured sparse neural networks and I just got interested in the techniques and research about 'the actual acceleration for zeroes'.\n If we want to dig more about these kinds of sparsity acceleration ( If I'm calling it right), which paper should we look into?\n How can we ignore the zeroes, aside from saving indices of non-zero values?\n    submitted by    /u/KindAd9527  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tij9t9/d_papers_about_true_utilization_of_pruning/",
          "publishedOn": "2022-03-20T11:43:55.000Z",
          "wordCount": 321,
          "title": "[D] Papers about 'true' utilization of pruning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ticntt/p_find_and_fix_bugs_in_ml_code/",
          "author": null,
          "description": "Hey everyone, it's notoriously hard to find bugs in ML models because often times they are silent. I've created a VSCode extension that can scan your Python functions and find bugs. Under the hood it utilizes a ML model that tries to understand your intent and provide suggestions. \n Please, could you give me some feedback? I would really appreciate any help. \n Thanks a lot in advance! \n Website: https://tensorbox.ai \n Video demo: https://youtu.be/MSpsCpPZokY\n    submitted by    /u/CosmicRaysGalaxy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ticntt/p_find_and_fix_bugs_in_ml_code/",
          "publishedOn": "2022-03-20T03:58:36.000Z",
          "wordCount": 382,
          "title": "[P] Find and fix bugs in ML code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ti81o2/discussion_modelling_explicit_and_implicit/",
          "author": null,
          "description": "Hi all, I recently read the YOLOR (You Only Learn One Representation) paper ( https://arxiv.org/abs/2105.04206 ). One of the key takeaways from this paper is that modelling implicit knowledge is crucial. And in order to make the model learn this implicit knowledge, simply \"relaxing\" the error term in cross-task learning is not enough, because then conventional loss functions won't be able to capture this implicit knowledge. So in order to tackle this problem, they model the error term for various tasks such that implicit knowledge can be learned.\n This reminded me very much of meta-RL, except I haven't seen any implementations of it where they explicitly model this per-task error and use a similar implicit+explicit knowledge learning framework.\n Since YOLOR is currently SOTA for realtime object detection and some other tasks, it seems like this was quite a significant insight and I wonder if anyone is aware of similar works in the \"RL branch\" of AI?\n I'd love to hear some thoughts about this or if someone can point me to related literature this would be great. In case this hasn't been looked into before, I'd love to start a PhD regarding this topic to learn more about it haha\n    submitted by    /u/Chronicle112  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ti81o2/discussion_modelling_explicit_and_implicit/",
          "publishedOn": "2022-03-19T23:41:17.000Z",
          "wordCount": 311,
          "title": "[Discussion] Modelling Explicit and Implicit knowledge in RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ti2rqg/d_very_frustrated_with_the_state_of_peerreviewing/",
          "author": null,
          "description": "A bit of a rant here. I received a \"major revision\" recommendation for a paper I submitted a few months ago (was self-contained, no ML background was necessary). The field is mathematical and the journal also addresses numerical & computational aspects of it, but applying ML (especially neural net based L2 regressions) is still a bit unheard of there. As such, I made sure to dumb everything down for them and still gave the mathematical justifications, including convergence proofs.\n In short, it was about estimating certain conditional expectations having a very special structure, without resorting to heavy brute-force approaches (like nested Monte-Carlo), using L2 projections with neural networks and a special sampling scheme which was also explained in detail. In such an approach neural n…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ti2rqg/d_very_frustrated_with_the_state_of_peerreviewing/",
          "publishedOn": "2022-03-19T19:27:48.000Z",
          "wordCount": 797,
          "title": "[D] Very frustrated with the state of peer-reviewing in math/computational non-ML journals when it comes to ML-based approaches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ti1yiv/rp_magma_multimodal_augmentation_of_generative/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ti1yiv/rp_magma_multimodal_augmentation_of_generative/",
          "publishedOn": "2022-03-19T18:49:57.000Z",
          "wordCount": 123,
          "title": "[R][P] MAGMA -- Multimodal Augmentation of Generative Models through Adapter-based Finetuning + Hugging Face Gradio Demo",
          "imageUrl": "https://external-preview.redd.it/d3ZJJPuzvlSDYvWxvl-jMDCMkL5MSVMnoVtDHWM9Rmw.png?format=pjpg&auto=webp&s=84e7c64396a5341da03637eb80fc82b4aff68a72"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ti0u6i/d_complete_guide_of_swin_transformer_with_full/",
          "author": null,
          "description": "Hello everyone!\n I’ve recently read Swin Transformer paper and tried to implement with PyTorch. But there’re no post that FULLY explains the nitty-gritty details of the paper with full implementation. It took me soooo long time to write this post so I wanted to share with y’all! Hope this helps someone! The implementation is based on the official implementation of Microsoft team.\n https://jasonlee-cp.github.io/paper/Swin_Transformer/#swin-transformer-architecture\n    submitted by    /u/JasonTheCoders  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ti0u6i/d_complete_guide_of_swin_transformer_with_full/",
          "publishedOn": "2022-03-19T17:58:14.000Z",
          "wordCount": 164,
          "title": "[D] Complete Guide of Swin Transformer with Full PyTorch Implementation",
          "imageUrl": "https://external-preview.redd.it/J0JqWgG9jaUobNp_NoNt988wDG_NXK976VEKaVf3Ap0.jpg?auto=webp&s=6d9c4436232cca4edcdcd6eae1c0db6e3c29ea9c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ti0q17/d_conferences_to_publish_ml_tooling/",
          "author": null,
          "description": "Hey, I write a lot of ML tooling and am hoping to present some of it in conferences somewhere. The main goal of publishing somewhere is to have a work that can be cited and is peer reviewed, but the real focus is on the package. Some people are weird about citing GitHub packages.\n Are there any specialized conferences for this sort of thing? Or do you just try your luck at a more niche conference?\n    submitted by    /u/puppet_pals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ti0q17/d_conferences_to_publish_ml_tooling/",
          "publishedOn": "2022-03-19T17:52:55.000Z",
          "wordCount": 446,
          "title": "[D] Conferences to publish ML tooling?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thzmw8/p_reading_time_of_analog_clocks/",
          "author": null,
          "description": "https://github.com/akucia/analog-watch-recognition\n ​\n https://preview.redd.it/4xrti7icgdo81.jpg?width=1200&format=pjpg&auto=webp&s=b76fd4aee01ef2eda4c9bb1c739d10ff38fe3cab\n    submitted by    /u/kuciu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thzmw8/p_reading_time_of_analog_clocks/",
          "publishedOn": "2022-03-19T17:03:05.000Z",
          "wordCount": 91,
          "title": "[P] Reading time of analog clocks",
          "imageUrl": "https://external-preview.redd.it/Bta5KP0Y7-xgj3oUZ_fmBMlc9XUrXCJLPLCFguIdnDs.jpg?auto=webp&s=701c3d1258d6aaa23680a93d583936a2dfd3e351"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thyqwl/r_code_data_for_paper_aaai_2022_multiplesource/",
          "author": null,
          "description": "You can find the paper here:\n https://arxiv.org/abs/2201.11870\n And the code and the data here:\n https://github.com/p-karisani/CEPC\n    submitted by    /u/payam_ka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thyqwl/r_code_data_for_paper_aaai_2022_multiplesource/",
          "publishedOn": "2022-03-19T16:22:25.000Z",
          "wordCount": 140,
          "title": "[R] Code + Data for Paper (AAAI 2022): Multiple-Source Domain Adaptation via Coordinated Domain Encoders and Paired Classifiers",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thwd2z/ensemble_learning_with_random_forest_and_dense/",
          "author": null,
          "description": "I am working on a hospital dataset, My Y variable is the total cost of the diagnosis. I wanna predict that so it's a regression problem, Ultimately. I used random forest and Dense NN Separately and I got pretty decent scores but is it possible to ensemble random forest and neural network.\n    submitted by    /u/nibras_28  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thwd2z/ensemble_learning_with_random_forest_and_dense/",
          "publishedOn": "2022-03-19T14:29:25.000Z",
          "wordCount": 162,
          "title": "Ensemble Learning with Random Forest and Dense Neural Network. [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thv0en/d_physics_and_reinforcement_learning_discussion/",
          "author": null,
          "description": "I chatted with a few experts about Deepmind's recent work on using RL for Nuclear Fusion and Plasma Control. We collected some resources and took some notes to understand the work better. Thought to share them here:\n [video] Physics and Reinforcement Learning \n  \nWhat is fusion?\n What is plasma?\n What is a Tokamak?\n Why do we care about conrolling plasma? \n The RL task is a continuous control task. That means that the inputs, “controller” take continuous, real values the same as would result from sliding a slider or turning a dial. Other examples of continuous control tasks are \n There are 19 of these metaphorical “dials” controlling coils in the tokamak. The task of the RL agent, then, is to learn how best to control those 19 “dials” given observations from the sensors within the tokamak.…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thv0en/d_physics_and_reinforcement_learning_discussion/",
          "publishedOn": "2022-03-19T13:17:25.000Z",
          "wordCount": 1379,
          "title": "[D] Physics and Reinforcement Learning - Discussion of Deepmind's work",
          "imageUrl": "https://external-preview.redd.it/OAdCn2l2ykfqShX1mzy7W5QKazHuPXfifCv0hY5F-GM.jpg?auto=webp&s=b1305fc57b651e1f64f6df37557e2469821f6386"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tht1qy/discussion_what_are_some_papers_you_read_which/",
          "author": null,
          "description": "I started working through this paper on how neural networks divide and map their input space. It helped me visualize what happens in the hidden layers and how they help in better function approximation. \n I'm looking for some suggestions on papers to read which help me build a stronger intuition on how and why neural nets work.\n    submitted by    /u/theanswerisnt42  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tht1qy/discussion_what_are_some_papers_you_read_which/",
          "publishedOn": "2022-03-19T11:13:58.000Z",
          "wordCount": 553,
          "title": "[Discussion] What are some papers you read which helped you build an intuition of how neural networks function?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thsx8t/p_deepforspeed_a_self_driving_car_in_need_for/",
          "author": null,
          "description": "submitted by    /u/toxickettle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thsx8t/p_deepforspeed_a_self_driving_car_in_need_for/",
          "publishedOn": "2022-03-19T11:04:46.000Z",
          "wordCount": 815,
          "title": "[P] DeepForSpeed: A self driving car in Need For Speed Most Wanted with just a single ConvNet to play ( inspired by nvidia )",
          "imageUrl": "https://external-preview.redd.it/7CY9az-IDQWsM5PlMZXX1pgGk15vN1k4tPLmAga64Sc.png?format=pjpg&auto=webp&s=35cc9c7317ced875b11c72eff02c92a43ca1e21f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thrm7r/d_applications_for_using_reinforcement_learning/",
          "author": null,
          "description": "I'm currently writing my Master's thesis on the merits and pitfalls of using reinforcement learning, specifically Proximal Policy Optimization, to finetune large language models. The project is inspired by the paper Fine-Tuning Language Models from Human Preferences, which uses a reward model trained on a dataset of human preferences to supply a reward signal used for fine-tuning GPT-2 to generate summaries and continuations that are optimized for human preference.\n I'm investigating the pros and cons of a more naive approach that does not require collecting a dataset of human preferences. Using the trl library, I train a BERT-classifier to distinguish between sarcastic and non-sarcastic reddit comments, and that classifier then serves as a reward model that provides a reward signal for fine-tuning GPT-2 for text generation using PPO. I have applied the same method to the task of generating negative review, by training BERT on the IMDB-dataset. This method of course leads to extensive reward hacking, but investigating how to mitigate that is part of the fun!\n I'm looking for inspiration for what other NLP tasks I could apply this to. The important constraint is that the tasks have to be something that I can train a classifier to evaluate, or otherwise evaluate algorithmically using metrics like ROUGE, because I need to supply GPT-2 with a scalar reward signal. \n What other tasks should I try this method out on?\n    submitted by    /u/Sisyfos42  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thrm7r/d_applications_for_using_reinforcement_learning/",
          "publishedOn": "2022-03-19T09:29:08.000Z",
          "wordCount": 343,
          "title": "[D] Applications for using reinforcement learning to fine-tune GPT-2",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thp7xr/d_extensions_to_unets/",
          "author": null,
          "description": "I've been working with U-nets, and I’m curious about the possible extensions to improve the performance of U-nets. I found several so far:\n Variational U-nets: https://proceedings.neurips.cc/paper/2018/file/473447ac58e1cd7e96172575f48dca3b-Paper.pdf\n Unet++: https://arxiv.org/pdf/1912.05074.pdf\n Stacked Dilated U-nets: https://arxiv.org/pdf/2004.03466.pdf\n There seems to be more ways to expand on the traditional U-net architecture that I've yet to discover. I'd love to see other cool methods!\n    submitted by    /u/2133  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thp7xr/d_extensions_to_unets/",
          "publishedOn": "2022-03-19T06:24:58.000Z",
          "wordCount": 224,
          "title": "[D] Extensions to U-nets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tho0ov/rp_styleswin_transformerbased_gan_for/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tho0ov/rp_styleswin_transformerbased_gan_for/",
          "publishedOn": "2022-03-19T04:59:33.000Z",
          "wordCount": 154,
          "title": "[R][P] StyleSwin: Transformer-based GAN for High-resolution Image Generation + Hugging Face Gradio Demo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thnwka/p_automatically_calibrate_rgbd_cameras_with/",
          "author": null,
          "description": "submitted by    /u/covertBehavior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thnwka/p_automatically_calibrate_rgbd_cameras_with/",
          "publishedOn": "2022-03-19T04:51:55.000Z",
          "wordCount": 453,
          "title": "[P] Automatically Calibrate RGBD Cameras with PyTorch",
          "imageUrl": "https://external-preview.redd.it/qoXtxDwj5uHouo6sAnKVds7hlJ6b2Oxg1epT1O7hmhI.png?format=pjpg&auto=webp&s=f1a9dc0251c30b0b0feeed6142c6bd0208bf2c0b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thmqdt/p_nondiscrete_sample_classification/",
          "author": null,
          "description": "I'm a biologist, and I have a problem with a very common analysis done in my field. We often classify cells by unique profile proteins they express. Cells that are high in protein A but low in B may be called \"Type 1\", cells low in protein A but high in protein B may be called \"Type 2\", cells high in both A and B \"Type 3\", and cells low in both \"Type 4\".\n Sometimes this works well and cells are clearly one type or the other. But unfortunately nature doesn't care about our desire to neatly classify things, and I believe that cell identity exists on a spectrum. Protein expression isn't all or nothing, it's effectively a continuous variable. There are cases where some cells are probably actually \"Type 1\", some are actually \"Type 2\", but some meaningfully exist as \"somewhere between Type 1 and…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thmqdt/p_nondiscrete_sample_classification/",
          "publishedOn": "2022-03-19T03:38:55.000Z",
          "wordCount": 1188,
          "title": "[P] Non-discrete sample \"classification\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thjjfh/discussion_oftentimes_data_scientists_work_in/",
          "author": null,
          "description": "Often-times data scientists work in silos. And later on in their project, they realize that “I wish I had known this ….”\n Some of the questions that arise are: \n ​\n  \n[Data] Training data is not representative of Production Data\n [Economics] Business had different success criteria than data scientist’s evaluation metrics\n [Engineering] Do not have an infrastructure in place to support models\n [Engineering] Product backend is written in Java and your pipeline is in Python\n [Legal] Need to take approval from Legal and Governance to consider data privacy, bias, and fairness\n [Stakeholders] Explainability is more important than results\n  \nHave you come across any such situations?\n    submitted by    /u/rajg88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thjjfh/discussion_oftentimes_data_scientists_work_in/",
          "publishedOn": "2022-03-19T00:41:06.000Z",
          "wordCount": 238,
          "title": "[Discussion] Often-times data scientists work in silos. And later on in their project, they realize that “I wish I had known this ….”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thh51x/d_looking_for_a_gpu_server_for_our_university/",
          "author": null,
          "description": "Our lab is recently doing more deep learning projects and our current lab server is struggling with the increasing load. My professor tasked me with finding our lab a good GPU server for the lab. The reserved budget is 25K. Our current server have the following specifications:\n CPU: Intel Xeon Silver 4114 CPU\n RAM: 192GB\n GPU: NVIDIA Tesla V100 PCIe 32GB (one GPU)\n There are 4 phd students currently working on the server. I prefer something better than the current server. So far I found Lambda Labs and ThinkMate (based on a friend recommendation). My professor want me to select a vendor with good support and offering academic discounts. I'm looking for GPUs that are perform similar or better than Nvidia RTX 2080 Ti.\n Do you have a recommendation for any vendor that builds GPU servers (~$25K, servicing 3-5 students working mostly on CNN and RNN models), and which server configurations is best? Thank you.\n    submitted by    /u/majax21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thh51x/d_looking_for_a_gpu_server_for_our_university/",
          "publishedOn": "2022-03-18T22:40:02.000Z",
          "wordCount": 817,
          "title": "[D] Looking for a GPU server for our university research lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thgcj1/d_overview_sota_results_of_nn_on_various_datasets/",
          "author": null,
          "description": "Hi everybody,\n I developed a new NN training approach and want to benchmark it now. I am looking for Classification/Regression tasks on various normal and image datasets, but also autoencoder-like reconstruction problems (I guess denoising is here the classic evaluation task?)\n  \nAre there any good websites/papers which collect current SOTA results on multiple datasets? It would be great if they also provide training times, number of parameters, etc.\n What datasets would you recommend to definitely include in such a benchmark?\n  \nThanks in advance!\n    submitted by    /u/arcxtriy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thgcj1/d_overview_sota_results_of_nn_on_various_datasets/",
          "publishedOn": "2022-03-18T22:01:50.000Z",
          "wordCount": 180,
          "title": "[D] Overview SOTA Results of NN on Various Datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/thbsax/research_assessing_stability_of_cluster_label/",
          "author": null,
          "description": "Hi everyone,\n I have a dataset of continuous multivariate samples. I'm clustering these samples together using an unsupervised algorithm to infer unmeasured latent states. Ideally, this would just be performed on the entire sample set. However, this label will then subsequently form part of a supervised prediction algorithm, and because the dataset isn't very large (several hundred samples), I'm almost certainly going to end up using k-fold cross validation.\n ​\n Now, the issue with using cluster labels generated from the whole dataset is that this essentially permits data leakage from the test fold back into the training fold for the supervised learning algorithm (which, for the purposes of my experiment, I don't want). So instead, the unsupervised labels will need to be generated for each fold individually.\n ​\n What I would like to do is have a measure of the relative stability/instability of label assignment for each sample across the folds. So for example, over 10 folds, ideally sample 1 would always get the label 'A' ten times out of ten... but in reality, perhaps it will get label 'A' eight times, and label 'B' twice.\n ​\n It sounds like the Bhattacharyya coefficient might be an appropriate scoring system (i.e. for each sample, calculate the square root of the product of the label proportions, and sum over all samples) - but I've never used this before, so I don't know whether it would be an appropriate use case. Does anyone have any familiarity with either this measure or this type of situation in general?\n    submitted by    /u/mcflyanddie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/thbsax/research_assessing_stability_of_cluster_label/",
          "publishedOn": "2022-03-18T18:30:17.000Z",
          "wordCount": 351,
          "title": "[Research] Assessing stability of cluster label assignment over cross-validation folds",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/th8ag3/d_democratization_of_large_language_models/",
          "author": null,
          "description": "Hi all,\n I've been thinking about how to democratize running and training of large language models, and more generally how to democratize all large models.\n I've wondered if this would be achievable with a volunteer computing project. I've found two (and only two, unfortunately) papers on the subject, so I at least know that I'm not the only one thinking about this. Those papers can be found here and here.\n That would be the end of the discussion for me, but I think the previous approaches have some flaws. Both papers use data parallelism, making training of extremely large (> 20GB) models basically impossible, because very few volunteers will have enough resources to run, much less train, the models, regardless of batch size. Systems like Hydra might be able to run things locally for models between 20 to 250GB, but above that it becomes a question of disk space.\n A more theoretical flaw is that both of the papers use a modified version of SGD, which means any model would be required to use special optimizers. I don't know how that would impact results/convergence, but it doesn't seem trivial.\n In conclusion, it seems to me that a VC system for extremely large models probably needs a novel approach that uses tensor parallelism, so that work could be more granularly distributed. It's (probably) not an easy problem, but it seems possible.\n I'm curious what this community's thoughts are, and if anyone would also be interested in working on this. Also, if anyone knows any other resources on this problem, please drop a link so I can check them out!\n    submitted by    /u/Lazauya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/th8ag3/d_democratization_of_large_language_models/",
          "publishedOn": "2022-03-18T17:38:37.000Z",
          "wordCount": 392,
          "title": "[D] Democratization of large (language) models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/th76i8/d_can_i_submit_to_arr_for_resubmission_and_at_the/",
          "author": null,
          "description": "In the 2 links below, it says you can commit to conferences such as ACL 2022 and NAACL 2022 at the same time submit to ARR for resubmission, but it doesn't say if you can do the same for workshops or conferences relating to ARR other than the 2 conferences listed above.\n In the last link, it pretty much specifies two conferences (maybe just listed as an example?) that you can commit and at the same time submit to ARR for resubmission, but for some reason doesn't directly say that you can commit to ARR related conference/workshop alongside submitting to ARR for resubmission.\n So if anybody has any info on whether I can submit to ARR for resubmission and at the same time commit to any ARR related workshop/conference, I'd appreciate it.\n https://www.2022.aclweb.org/post/acl-2022-chair-blog-post-faq\n https://aclrollingreview.org/choices/\n    submitted by    /u/SiegeMemeLord  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/th76i8/d_can_i_submit_to_arr_for_resubmission_and_at_the/",
          "publishedOn": "2022-03-18T17:17:12.000Z",
          "wordCount": 324,
          "title": "[D] Can I submit to ARR for resubmission and at the same time commit to a workshop",
          "imageUrl": "https://external-preview.redd.it/pZp_Au4qGav3ocTKxpqF_REvmqWIlmscjG50tGEl-AY.jpg?auto=webp&s=01ae224691962367136381dad83fa02aebf4ead2"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/th49o4/d_layer_normalization_in_transformer_blocks/",
          "author": null,
          "description": "I was playing with the idea of trying a transformer for a sequence modelling task for the first time recently - I was interested in all the X-former variants interested in better training stability, eg. Catformer or rezero or adding gates to the residual connections.\n I found I always got late NaN losses whenever the transformer blocks contained layer normalization. Removing layer normalization or using catformer (which has no layer normalization) this didn't happen. \n I was curious about if anyone knows why this is the case, and what current ideas are about the necessity of layer normalization to the transformer.\n    submitted by    /u/WigglyHypersurface  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/th49o4/d_layer_normalization_in_transformer_blocks/",
          "publishedOn": "2022-03-18T15:42:51.000Z",
          "wordCount": 190,
          "title": "[D] Layer normalization in transformer blocks.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/th3j3i/d_choosing_ec2_instance_with_two_goals_in_mind/",
          "author": null,
          "description": "I’m running train tests on data that is quite large (1.5M, 400). I need to preprocess such data with a data transformation and model-based data imputation pipeline. Then I need to run train/test fits on a neural net that needs PyTorch and GPU. With this in mind, what is the most cost-effective aws ec2 instance for large data processing that has gpu as well? Right now I’m either running it all on a p3.2xlarge, or I use a c5d.9xlarge for the data preprocessing, save that file and then move back to p3.2xlarge to run the train/test. Second option is not ideal because I’d want to run several tests quickly even when changing around feature engineering or features selected.\n    submitted by    /u/Gioamorim80  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/th3j3i/d_choosing_ec2_instance_with_two_goals_in_mind/",
          "publishedOn": "2022-03-18T15:09:24.000Z",
          "wordCount": 279,
          "title": "[D] Choosing EC2 instance with two goals in mind",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/th3bug/r_new_paper_on_autonomous_driving_and_multitask/",
          "author": null,
          "description": "Hello, we are publishing our first paper as undergraduate students today. It is achieving SOTA on the BDD100K dataset (2 out of 3 tasks, at least).\n ​\n Paper: https://arxiv.org/abs/2203.09035\n Code: https://github.com/datvuthanh/HybridNets\n ​\n Network architecture:\n HybridNets architecture\n ​\n Contributions:\n  \nHybridNets, an end-to-end perception network, achieving outstanding results in real-time on the BDD100K dataset for 3 tasks: traffic object detection, drivable area segmentation (not SOTA), and lane line detection.\n Automatically customized anchor for each level in the weighted bidirectional feature network, on any dataset.\n An efficient training loss function and training strategy to balance and optimize multi-task networks.\n  \n   submitted by    /u/xoiga123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/th3bug/r_new_paper_on_autonomous_driving_and_multitask/",
          "publishedOn": "2022-03-18T15:00:34.000Z",
          "wordCount": 200,
          "title": "[R] New paper on autonomous driving and multi-task: \"HybridNets: End-to-End Perception Network\"",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/th1ea5/r_deep_batch_active_learning_for_regression/",
          "author": null,
          "description": "(First author here.) Are you interested in improving the sample-efficiency of neural network regression through active learning? Then, our new paper might be all you need 🙂\n Paper: https://arxiv.org/abs/2203.09410\n Code: https://github.com/dholzmueller/bmdal_reg\n Short summary: Using random projections of NN gradients as features and running a simple clustering method on these works really well, is scalable and convenient to use through our code.\n Long summary: We study pool-based batch mode deep active learning (BMDAL) for regression: We start with a small labeled training data set and repeatedly select a batch of unlabeled data from a large pool set for labeling. We want to select large batches since NN training can be slow.\n ​\n Deep Batch Active Learning loop\n We propose a benchmark wi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/th1ea5/r_deep_batch_active_learning_for_regression/",
          "publishedOn": "2022-03-18T13:31:58.000Z",
          "wordCount": 1021,
          "title": "[R] Deep Batch Active Learning for Regression",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/th14fz/d_how_does_publishing_in_mlhealthcare_papers_work/",
          "author": null,
          "description": "I have started my PhD in application of machine learning in health care. I want to understand what it takes to publish in papers like Journal of the American Medical Informatics Association (JAMIA) . Are there any patterns in the publication that one can look out for? Do they always need the best state of the art results or a novel algorithm?\n    submitted by    /u/Complex_State9960  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/th14fz/d_how_does_publishing_in_mlhealthcare_papers_work/",
          "publishedOn": "2022-03-18T13:17:54.000Z",
          "wordCount": 508,
          "title": "[D] How does publishing in ML+Healthcare papers work",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/th0qp3/d_best_labeling_tool_for_action_localization_from/",
          "author": null,
          "description": "I would like to discuss what people their experiences are with labeling tools for action localization in videos. Currently I only found CVAT to be somewhat decent (but still pretty bad). Besides this there are some Github repos that publish a (not/semi) working solution, but they also don't do the trick for me.\n My biggest issue with CVAT is that I can only upload 1 video per task and that it is limited to 500MB. \n I would like to know what other tools people have used and what your experiences are?\n    submitted by    /u/FreddyShrimp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/th0qp3/d_best_labeling_tool_for_action_localization_from/",
          "publishedOn": "2022-03-18T12:58:54.000Z",
          "wordCount": 190,
          "title": "[D] Best labeling tool for action localization from video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/th0j46/d_paper_review_avoiding_catastrophe_active/",
          "author": null,
          "description": "https://youtu.be/O_dJ31T01i8\n Catastrophic forgetting is a big problem in mutli-task and continual learning. Gradients of different objectives tend to conflict, and new tasks tend to override past knowledge. In biological neural networks, each neuron carries a complex network of dendrites that mitigate such forgetting by recognizing the context of an input signal. This paper introduces Active Dendrites, which carries over the principle of context-sensitive gating by dendrites into the deep learning world. Various experiments show the benefit in combatting catastrophic forgetting, while preserving sparsity and limited parameter counts.\n ​\n OUTLINE:\n 0:00 - Introduction\n 1:20 - Paper Overview\n 3:15 - Catastrophic forgetting in continuous and multi-task learning\n 9:30 - Dendrites in biological neurons\n 16:55 - Sparse representations in biology\n 18:35 - Active dendrites in deep learning\n 34:15 - Experiments on multi-task learning\n 39:00 - Experiments in continual learning and adaptive prototyping\n 49:20 - Analyzing the inner workings of the algorithm\n 53:30 - Is this the same as just training a larger network?\n 59:15 - How does this relate to attention mechanisms?\n 1:02:55 - Final thoughts and comments\n ​\n Paper: https://arxiv.org/abs/2201.00042\n Blog: https://numenta.com/blog/2021/11/08/can-active-dendrites-mitigate-catastrophic-forgetting\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/th0j46/d_paper_review_avoiding_catastrophe_active/",
          "publishedOn": "2022-03-18T12:47:29.000Z",
          "wordCount": 319,
          "title": "[D] Paper Review - Avoiding Catastrophe: Active Dendrites Enable Multi-Task Learning in Dynamic Environments (Video Walkthrough)",
          "imageUrl": "https://external-preview.redd.it/I70ueWP6sHQ0g8e0EzL_d_ZUxC5gFxyMqgKCmGDFe4Q.jpg?auto=webp&s=41469d6db94b808d597e9676a9b5661674dedb82"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/th0f2f/d_mac_studio_as_a_computer_for_machine_learning/",
          "author": null,
          "description": "I'm curious what people think of Apple's new Mac Studio as a potential workstation for machine learning and data processing tasks?\n It seems like Tensorflow can makes use of the M1 chip, but not Pytorch yet - I don't know how these compare to traditional GPU setups though? More generally, do you think the Mac Studio would be a good dev machine and good for other data-based work? I'm not sure, as it seems like the Studio is being pitched for people doing things like video editing rather than coding. Thanks!\n    submitted by    /u/uio8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/th0f2f/d_mac_studio_as_a_computer_for_machine_learning/",
          "publishedOn": "2022-03-18T12:41:57.000Z",
          "wordCount": 524,
          "title": "[D] Mac Studio as a computer for machine learning and data science",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tgxlg7/n_nordic_probabilistic_ai_school_probai_june_1317/",
          "author": null,
          "description": "You are welcome to apply for the Nordic Probabilistic AI School (ProbAI) 2022 being held on June 13-17 in Helsinki (Finland).\n APPLY NOW — The application deadline is March 27.\n About ProbAI 2022\n The mission of the third Nordic Probabilistic AI School (ProbAI) is to provide an inclusive education environment serving state-of-the-art expertise in machine learning and artificial intelligence. The public, students, academia and industry are welcome to join ProbAI 2022.\n ProbAI is an intermediate to advanced level \"summer\" school with the focus on probabilistic machine learning. Covered are topics such as probabilistic models, variational approximations, deep generative models, latent variable models, normalizing flows, neural ODEs, probabilistic programming, and much more.\n The ProbAI 2022 w…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tgxlg7/n_nordic_probabilistic_ai_school_probai_june_1317/",
          "publishedOn": "2022-03-18T09:40:35.000Z",
          "wordCount": 762,
          "title": "[N] Nordic Probabilistic AI School (ProbAI) — June 13-17, 2022",
          "imageUrl": "https://external-preview.redd.it/BJ67GzqwW2dw-RCfwb6TDmFWwLJzgfVYUmDdgrPa8kM.jpg?auto=webp&s=bff8b849ad59e4dc206395167b6c2f2f847d4e49"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tgtxkm/d_how_did_you_decide_a_research_topic/",
          "author": null,
          "description": "Those of you who did/doing a PhD recently, how did you decide your PhD topic? My advisor seems to give me a lot of freedom, by letting me choose my own topic, but has said if it is away from his interests he can't help a lot. He also would apply for funding, once I have a clear topic, which adds even more pressure. He wants me to write a survey paper, so that both of us can know the literature in the field. I've tried looking at the research by AI companies, but most of the areas are completely crowded. \n Which brings me to my question, how do you go about choosing your topic? Was a broad idea given to you by your advisor? Were you also expected to know everything about your field? How did you have the confidence in selecting a topic, given most of recent papers is just randomly adding/shifting/removing layers (no offense).\n Also, what did you expect/get from your advisor? Given my situation, it seems like I'll have to run the show, which makes me anxious.\n    submitted by    /u/Bibbidi_Babbidi_Boo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tgtxkm/d_how_did_you_decide_a_research_topic/",
          "publishedOn": "2022-03-18T05:15:50.000Z",
          "wordCount": 2123,
          "title": "[D] How did you decide a research topic?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tgn6ma/d_on_the_difference_or_lack_thereof_between/",
          "author": null,
          "description": "So cross-entropy(H(p,q)) and KL-divergence (KL(p||q)) relate to each other as follows:\n H(p,q) = KL(p||q) + H(p) and KL(p||q) = H(p,q) - H(p)\n where p is the data distribution and q is the model distribution. When p is constant (as is the case in most ML problems), minimizing H(p,q) is equivalent to minimizing KL(p||q). However, there seems to be some ambiguity about this. (One practitioner claims)[https://stats.stackexchange.com/a/409271] that there is a difference in practice, because during batch gradient descent the data distribution p' in each batch is noisy and harder learn for the model, leading to worse performance for the KL-divergence.\n I am skeptical about his claim, as H(p) is part of both cross-entropy and KL-divergence, depending on how one views them. If anything, the KL-divergence should work better because it does not directly incorporate H(p). What is your experience / your thoughts?\n    submitted by    /u/optimized-adam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tgn6ma/d_on_the_difference_or_lack_thereof_between/",
          "publishedOn": "2022-03-17T23:17:39.000Z",
          "wordCount": 255,
          "title": "[D] On the difference (or lack thereof) between Cross-Entropy Loss and KL-Divergence",
          "imageUrl": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?auto=webp&s=e25be8cb5cf2448d39a7e5ffc877e4d466b776d3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tgn6ik/machine_learning_fawkes_facial_recognition/",
          "author": null,
          "description": "Hello to everyone,\n At the moment exist any way to avoid facial recognition from social media? Not Fawkes.... Another way because I think AI learned that the picture is modified with this software. It is possible that the software recognize this pictures as fake face? Also combine fawkes with another software as Photoshop could be a good idea to look as another user? In social media the people use Photoshop... I don't know if is still possible to recognize easy\n Thank you\n    submitted by    /u/Maleficent_Camel5718  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tgn6ik/machine_learning_fawkes_facial_recognition/",
          "publishedOn": "2022-03-17T23:17:30.000Z",
          "wordCount": 178,
          "title": "Machine learning - Fawkes - facial recognition [discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tgkj6t/p_extracting_potential_user_profiles_from/",
          "author": null,
          "description": "Hi everyone.\n For a project i need to find a way to extract some \"potential user profiles\" from firewall logs, such as the pic i attach to this post.\n For example i would like to infer that user A belongs to the \"administrative\" part of the company whyle Bob belongs to the tecnician department.\n Any hints on how to do this? I taught about using k-means on some certain fields such as destination, source, protocol.\n The problem is that k-means flags different records of the same user with different clusters, and i guess this may not be a good strategy (I might try to use some kind of smoothening in which i flatten the cluster, for example if BoB has labels 0 0 0 0 0 1 1 1 1 0 0 0 0 0 then bob has cluster 0).\n ​\n https://preview.redd.it/tehf5axof0o81.png?width=1489&format=png&auto=webp&s=720ab6f792e2d409735e662d602e76ac7909e23b\n    submitted by    /u/Set-New  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tgkj6t/p_extracting_potential_user_profiles_from/",
          "publishedOn": "2022-03-17T21:15:53.000Z",
          "wordCount": 396,
          "title": "[P] Extracting \"potential user profiles\" from firewall logs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tghpun/r_domainspecific_pretraining_of_gpt_help/",
          "author": null,
          "description": "I am looking to adapt GPT-2 to generate dialogue utterances in the style of a certain demography/population (let's call them Ogres). However, there are no large datasets that are both 1) dialogue datasets, and 2) are generated by this target demography.\n In the absence of such data, I have been considering a few approaches for data augmentation purposes. Many of those approaches would benefit from a GPT-Ogre, which is at least capable of generating text similar to Ogres, if not necessarily dialogic.\n Approach 1\n ==========\n For this, I am considering performing additional pre-training of, say, GPT-2 on some medium-sized corpora generated by Ogres. This sounds like something that should have been done by a lot of people for a lot of different things by now, but except for some papers that have tried to do this with BERT in the Medical domain, I was not able to find any papers/GitHub repos that have done this with additional unsupervised pre-training GPT.\n It would be helpful if someone could point me to some resources around this as I feel the space of hyperparameters to figure out the best learning rate, etc. is too large, and if somebody has already done this, it would be easy to replicate it.\n Approach 2\n ==========\n There are some dialogue-specific GPT models such as DialoGPT that have been fine-tuned (in a supervised way; mind you, not pretrained in an unsupervised way). However, it is not in the Ogre style. I am wondering if it's a ridiculous idea to perform additional pre-training of a fine-tuned GPT-2 model?\n    submitted by    /u/exceptaway343  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tghpun/r_domainspecific_pretraining_of_gpt_help/",
          "publishedOn": "2022-03-17T19:09:04.000Z",
          "wordCount": 413,
          "title": "[R] Domain-specific pre-training of GPT? Help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tgeo0q/r_restoring_and_attributing_ancient_texts_using/",
          "author": null,
          "description": "Ancient history relies on disciplines such as epigraphy — the study of inscribed texts known as inscriptions — for evidence of the thought, language, society and history of past civilizations. However, over the centuries, many inscriptions have been damaged to the point of illegibility, transported far from their original location and their date of writing is steeped in uncertainty.\n This work presents Ithaca, a deep neural network for the textual restoration, geographical attribution and chronological attribution of ancient Greek inscriptions.\n Paper: https://www.nature.com/articles/s41586-022-04448-z\n Code: https://github.com/deepmind/ithaca\n Online interface: https://ithaca.deepmind.com/\n Blog: https://deepmind.com/blog/article/Predicting-the-past-with-Ithaca\n Video: https://www.youtube.com/watch?v=rq0Ex_qCKeQ\n    submitted by    /u/yannisassael  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tgeo0q/r_restoring_and_attributing_ancient_texts_using/",
          "publishedOn": "2022-03-17T16:52:51.000Z",
          "wordCount": 231,
          "title": "[R] Restoring and attributing ancient texts using deep neural networks",
          "imageUrl": "https://external-preview.redd.it/vw0LQ9PVEewgcTMkGNeg_mAwERugHj-IDAKckBK9sHQ.jpg?auto=webp&s=4364a3393abd7fec6e4b0cde8c075fc60294feee"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tgefsw/discussion_pytorch_lightning_vs_deepspeed_vs_ffcv/",
          "author": null,
          "description": "Deepspeed? FSDP? FFCV? XYZK? what do they all mean and how can you use all of them to speed up your model training? All amazing techniques developed by world-class teams and are (or are being made) accessible via PyTorch Lightning!\n If you know of other techniques you want to be integrated, please comment below!\n https://william-falcon.medium.com/pytorch-lightning-vs-deepspeed-vs-fsdp-vs-ffcv-vs-e0d6b2a95719\n    submitted by    /u/waf04  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tgefsw/discussion_pytorch_lightning_vs_deepspeed_vs_ffcv/",
          "publishedOn": "2022-03-17T16:42:41.000Z",
          "wordCount": 238,
          "title": "[Discussion] PyTorch Lightning vs DeepSpeed vs FFCV vs mosaic vs ... what are they and how can you use them?",
          "imageUrl": "https://external-preview.redd.it/swY9KprEu3A_7vfecgv4mN_9cs__tSR4oRrRH3MmDFY.jpg?auto=webp&s=3a929709e2740e47d646f003b9e069b4616246e7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tgbs6u/discussion_is_clean_realworld_data_important_for/",
          "author": null,
          "description": "Hi reddit experts,\n I know that for any machine learning and AI application, you need data in order to train your model. I would like to ask the following:\n  \nWhere does this data usually come from? (For instance, is this data provided by the customer? Your professor? Is it always assumed that this data will be available? Can you trust the source?)\n If you don’t already have this data, will you be asked to implement a system to collect this data?\n Would the accuracy of this data be important to the model? Meaning, let’s say if we wanted to train the model of an AI temperature controller. Would it really matter if the data was just 25 degrees? Versus 25.58 degrees?\n Is it important that this data is sampled fast enough? Meaning, if I only had 1 data point per day, versus 10 data points per minute?\n  \nHere’s some context to why I’m asking. I’ve been a measurement and instrumentation engineer for a good part of my career. We set up measurement systems that allow customers to collect all kinds of real-world data, including temp, vibration, voltage, images, etc.\n The other day I had a debate with a friend who does AI, where he claimed that “collecting the data\" was a trivial effort, because most of time he just uses the data that’s been given to him. But I challenged him, because there's lots of know-how needed in acquiring real-world physical data (for ex: which sensors to use, how to avoid noise, how to synchronize timestamps, etc.) All of this know-how ensures that the collected data is accurate, clean, and complete.\n But he just kinda brushed this off, and said that most ML/AI algorithms nowadays just look at the general trend of data, absolute accuracy doesn’t really matter, but there still needs to be some relative variability, then he can work with it. I’m having a hard time believing this is true. Can anyone shed some light on this subject?\n    submitted by    /u/sharkera130  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tgbs6u/discussion_is_clean_realworld_data_important_for/",
          "publishedOn": "2022-03-17T14:42:01.000Z",
          "wordCount": 589,
          "title": "[Discussion] Is clean real-world data important for model training?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tgaxy2/research_a_great_resource_for_riskaverse_rl/",
          "author": null,
          "description": "https://www.cs.unh.edu/~mpetrik/tutorials/risk/\n    submitted by    /u/Ok_Can2425  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tgaxy2/research_a_great_resource_for_riskaverse_rl/",
          "publishedOn": "2022-03-17T14:01:44.000Z",
          "wordCount": 236,
          "title": "[Research] A great resource for Risk-Averse RL!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tg76ns/gpus_and_memory_d/",
          "author": null,
          "description": "Hello! just made my first gan and am keen to try make one in 1024x1024\n I am looking to upgrade my gpu processing power by adding a RTX A4000 16g to my existing RTX 2080 8g\n will the memory stack as I have been working around some cuda memory allocation issues so far its working but Id like to know before I put down that kind of money will I be able to go past a 8g limit if I add the A4000 to my rig\n I have tried googling this question to no clear answer, feel free to link something related to this.\n    submitted by    /u/Trainsmurf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tg76ns/gpus_and_memory_d/",
          "publishedOn": "2022-03-17T10:33:52.000Z",
          "wordCount": 725,
          "title": "GPU's and Memory [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tg4gpw/discussion_anyone_know_some_machine_learning/",
          "author": null,
          "description": "I am obsessed with machine learning despite not being very smart at it myself. But specifically, I love it in games. I love interacting with it. I'm looking for more games like these:\n I play NovelAI, Creatures 3, Wobbledogs, AI Dungeon, Replika, and I was going to pick up Species: Artificial Life Real Evolution. Someone made a hook of what I think is GPT 2.7B to Crusader Kings so that you could talk to the different countries' leaders.\n Wobbledogs uses it for dog's walking. Motivation and desire are present. It also has positive / negative reinforcement.\n AI Dungeon, Replika, and NovelAI are all GPT - OpenAI GPT Da Vinci (for AID Dragon), OpenAI GPT 2.0 (of some sort, for Replika), and Fairseq / EleutherAI GPT models (for NovelAI). \n Creatures 3 was one of the first pseudo(?) neural network games and utilizes motivation, desire, and positive / negative reinforcement.\n Species: Artificial Life Real Evolution is an abandoned game which simulated lifeforms evolving in stressful situations. They don't seem to actually be neural network, but it's close enough to be very interesting - creatures have motivations and desires but do not experience positive / negative reinforcement. There's also 60,000 of them at once... I guess it's sort of also got generational adaptation!\n PS, if anyone wants to obsess over these awesome games with me, let's do it!\n    submitted by    /u/WiIdCherryPepsi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tg4gpw/discussion_anyone_know_some_machine_learning/",
          "publishedOn": "2022-03-17T07:19:47.000Z",
          "wordCount": 344,
          "title": "[Discussion] Anyone know some Machine Learning Games Similar to Wobbledogs or Creatures 3?",
          "imageUrl": "https://external-preview.redd.it/HBzZAfWvMJ-Ot0nlP-JTIVcmpdpWyuoafbmJXmBVZ3Q.jpg?auto=webp&s=e47c72084b40cf662eb2431be102baf8a4df2e57"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tg4agu/r_new_paper_on_tabular_dl_on_embeddings_for/",
          "author": null,
          "description": "Hi! We introduce our new paper \"On Embeddings for Numerical Features in Tabular Deep Learning\".\n Paper: https://arxiv.org/abs/2203.05556\n Code: https://github.com/Yura52/tabular-dl-num-embeddings\n TL;DR: using embeddings for numerical features (i.e. using vector representations instead of scalar values) can lead to significant profit for tabular DL models.\n Let's consider the vanilla MLP taking two numerical inputs.\n https://preview.redd.it/yb55tdw27wn81.png?width=330&format=png&auto=webp&s=a6fc53e8611baee6993aab47480f0a6a6b85e46c\n Now, here is the same MLP, but now with embeddings for numerical features:\n https://preview.redd.it/zebl8tld7wn81.png?width=368&format=png&auto=webp&s=3d20652075d0543c7d6c70f34d67140bc2c6346b\n The main contributions:\n  \nwe show that using vector representations instead of scalar representations for numerical features can lead to significant profit for tabular DL models\n we show that MLP-like models equipped with embeddings can perform on par with Transformer-based models\n we make some progress in the \"DL vs GBDT\" competition\n  \n   submitted by    /u/Yura52  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tg4agu/r_new_paper_on_tabular_dl_on_embeddings_for/",
          "publishedOn": "2022-03-17T07:06:55.000Z",
          "wordCount": 730,
          "title": "[R] New paper on Tabular DL: \"On Embeddings for Numerical Features in Tabular Deep Learning\"",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tg3nbf/p_unsupervised_feature_selection_using_supervised/",
          "author": null,
          "description": "FRUFS is a Feature Relevance based Unsupervised Feature Selection approach using supervised algorithms such as XGBoost, etc. This is a new algorithm that I developed and put down in the form of a blog. Here's the link to the article. While reading the blog you will also re-discover an influential research paper in this domain on your own!\n FRUFS was evaluated on 4 different datasets under both unsupervised and supervised settings. The results are available on the blog as well as in the table below.\n  \n Dataset Task All Features FRUFS Metric \n  \n MNIST Unsupervised 50.48 53.70 NMI \n  Waveform Unsupervised 38.20 39.67 NMI \n  Ionosphere Supervised 88.01 91.45 Accuracy \n  Adult Supervised 62.16 62.65 F1-score \n \n ​\n Fig. 1 shows the feature importance of FRUFS (left) in comparison to the actual feature importance (right) on the MNIST dataset. This was done without any labels.\n Fig. 1: Visualizing feature/pixel importance of MNIST dataset\n ​\n I have also developed a scikit-learn compatible library in case you want to use FRUFS for your own project. Here's the github repo. A simple pip install FRUFS will do the trick!\n Do give the blog a read and let me know your thoughts.\n    submitted by    /u/atif_hassan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tg3nbf/p_unsupervised_feature_selection_using_supervised/",
          "publishedOn": "2022-03-17T06:21:31.000Z",
          "wordCount": 282,
          "title": "[P] Unsupervised Feature Selection using Supervised Algorithms",
          "imageUrl": "https://external-preview.redd.it/oSj2yE0glTkKwDA37SdDj01bfw_BWsZoy7Kup2lNf3s.jpg?auto=webp&s=f9b9d055479679ec4aa2ab961ab11d295cb8d213"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfw49a/d_do_you_think_cxl_and_pcie_50_will_be_a_game/",
          "author": null,
          "description": "https://venturebeat.com/2021/11/15/astera-labs-announces-memory-acceleration-to-clear-datacenter-ai-ml-bottlenecks/ \n Do you think this technology would allow the use of clusters to handle larger data sets, thus reducing the overall cost of doing ML?\n    submitted by    /u/sawine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfw49a/d_do_you_think_cxl_and_pcie_50_will_be_a_game/",
          "publishedOn": "2022-03-16T23:21:49.000Z",
          "wordCount": 165,
          "title": "[D] Do you think CXL and PCIe 5.0 will be a game changer for ML?",
          "imageUrl": "https://external-preview.redd.it/ZKsYpP-hj1-zuT-voCNZAnm5_4llGfaImLOL50OoSUw.jpg?auto=webp&s=bd444efc1d304e1521e509ccc9222df65513de29"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfua0f/d_how_does_an_modelagnostic_metalearning_model/",
          "author": null,
          "description": "I was reading the paper Model-Agnostic Meta-Learning and that part wasn't specified, or at least I couldn't find it.\n More specifically, a model is trained to perform n different tasks. At inference, how do people typically inform the model what tasks need to be performed? is it as simple as adding an extra input with the task to be performed, or do people use more sophisticated ways to do that? For example, the paper has an example where they train an NN on sines with different amplitudes and phases. In that case, the inputs are all identical, but the outputs shouldn't be., which in the paper they aren't.\n    submitted by    /u/carlml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfua0f/d_how_does_an_modelagnostic_metalearning_model/",
          "publishedOn": "2022-03-16T21:57:13.000Z",
          "wordCount": 236,
          "title": "[D] How does an Model-Agnostic Meta-Learning model know what tasks needs to perform?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfu361/r_lime_and_explainable_ai/",
          "author": null,
          "description": "I am currently doing some research about explainable AI and especially LIME framework.. are there any useful resources i can start with ?? also what are possible research gaps in that area?\n    submitted by    /u/Aromatic-Ad-2235  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfu361/r_lime_and_explainable_ai/",
          "publishedOn": "2022-03-16T21:48:13.000Z",
          "wordCount": 186,
          "title": "[R] LIME and explainable AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfs8p3/n_icpr_2022_odeuropa_competition_on_olfactory/",
          "author": null,
          "description": "Call for participation in the ICPR 2022 ODeuropa Competition on Olfactory Object Recognition (ODOR)! \n Task: Smell-related object detection in artworks \n It's the world’s first competition for the detection on olfactory objects on historical artworks. Work with a data set of >24000 object annotations in 87 categories on ~3000 images and create innovative solutions to detect a wide range of objects in the challenging domain of artworks. \n Smell-related object detection in artworks; image source: https://www.mauritshuis.nl/en/our-collection/artworks/742-as-the-old-sing-so-pipe-the-young/\n Please visit https://odor-challenge.odeuropa.eu for further details on how to participate!\n    submitted by    /u/vchristlein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfs8p3/n_icpr_2022_odeuropa_competition_on_olfactory/",
          "publishedOn": "2022-03-16T20:24:20.000Z",
          "wordCount": 184,
          "title": "[N] ICPR 2022 ODeuropa Competition on Olfactory Object Recognition (ODOR)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfor5y/d_how_do_you_measure_the_business_impact_of_the/",
          "author": null,
          "description": "For those who have deployed models to production, I was wondering what are some ways to track the business impact of a model/solution once deployed.\n I haven't come across a lot of information on tracking the performance of models against business/user metrics.\n If you use analytics data, what type of data do you collect? And how do you A/B test against different models? Is there some tooling available that could help with that?\n Any help is appreciated! :)\n    submitted by    /u/nathaliamdc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfor5y/d_how_do_you_measure_the_business_impact_of_the/",
          "publishedOn": "2022-03-16T18:31:30.000Z",
          "wordCount": 312,
          "title": "[D] How do you measure the business impact of the ML solutions in your company?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfnwsk/d_vertical_first_horizontal_second_why_you_should/",
          "author": null,
          "description": "https://medium.com/p/306fa7b7a80b\n I believe a common misconception is that you only need to apply MLOps principles and tools if you are running hundreds of models. I'd argue it's not less important in a lot earlier stages of the model lifecycle.\n    submitted by    /u/stiebels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfnwsk/d_vertical_first_horizontal_second_why_you_should/",
          "publishedOn": "2022-03-16T17:53:37.000Z",
          "wordCount": 181,
          "title": "[D] Vertical first, horizontal second. Why you should break through to production early when developing machine learning systems and how MLOps facilitates this.",
          "imageUrl": "https://external-preview.redd.it/AdoWC6R5Bps7ZFNuCP3VVdTDUKKo6BEEeLYpm92cu_g.jpg?auto=webp&s=54d8a38260d6606bc17d47f1363e827218488bc0"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfm7zb/n_live_and_open_training_of_bigsciences_176b/",
          "author": null,
          "description": "The [BigScience project](https://bigscience.huggingface.co) has just started the training of its main model and the training can be followed live here: https://twitter.com/BigScienceLLM and here: https://huggingface.co/bigscience/tr11-176B-ml-logs/tensorboard#scalars&tagFilter=loss\n Here are more information on the model, dataset, engineering, training and hardware:\n  \nThe model:\n  \n 176B parameters decoder-only architecture (GPT-like)\n 70 layers - 112 attention heads per layers - hidden dimensionality of 14336 - 2048 tokens sequence length\n ALiBi positional embeddings - GeLU activation function\n Read more: \n Blog post summarizing how the architecture, size, shape, and pre-training duration where selected: https://bigscience.huggingface.co/blog/what-language-model-to-train-if-you-have-two-…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfm7zb/n_live_and_open_training_of_bigsciences_176b/",
          "publishedOn": "2022-03-16T16:38:22.000Z",
          "wordCount": 568,
          "title": "[N] Live and open training of BigScience's 176B multilingual language model has just started",
          "imageUrl": "https://external-preview.redd.it/U71rQ1Lq2w5TVWDZF73H-62Rs3TPJY-YUjaL7o_q7h4.jpg?auto=webp&s=10c65f91e6ab3391ebe9bc0df92c3bc048504114"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tflvuy/p_composer_a_new_pytorch_library_to_train_models/",
          "author": null,
          "description": "Hey all!\n We're excited to release Composer (https://github.com/mosaicml/composer), an open-source library to speed up training of deep learning models by integrating better algorithms into the training process!\n Time and cost reductions across multiple model families\n Composer lets you train:\n  \nA ResNet-101 to 78.1% accuracy on ImageNet in 1 hour and 30 minutes ($49 on AWS), 3.5x faster and 71% cheaper than the baseline.\n A ResNet-50 to 76.51% accuracy on ImageNet in 1 hour and 14 minutes ($40 on AWS), 2.9x faster and 65% cheaper than the baseline.\n A GPT-2 to a perplexity of 24.11 on OpenWebText in 4 hours and 27 minutes ($145 on AWS), 1.7x faster and 43% cheaper than the baseline.\n  \nhttps://preview.redd.it/0bitody9qrn81.png?width=10008&format=png&auto=webp&s=d9ecdb45f6419eb49e1c2c69ee…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tflvuy/p_composer_a_new_pytorch_library_to_train_models/",
          "publishedOn": "2022-03-16T16:23:25.000Z",
          "wordCount": 1415,
          "title": "[P] Composer: a new PyTorch library to train models ~2-4x faster with better algorithms",
          "imageUrl": "https://external-preview.redd.it/nq1XXjqkBtLjLdXO6Q8MsxyVnRWTUI1_QFQus-Oho2A.jpg?auto=webp&s=04a57a145935b2955580a05cc6b60ea400dc6501"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfkum9/p_intellinext_a_lstm_and_hmmbased_solution_for/",
          "author": null,
          "description": "Hello everyone, I'm excited to share our work with Intel over the past months for our undergraduate capstone. Since September, we've worked with Intel's Data Collection & Analysis team on building models for application preload to minimize loading times. \n  \nINTELlinext: A Fully Integrated LSTM and HMM-Based Solution for Next-App Prediction With Intel SUR SDK Data Collection\n \nOur talk at the UCSD Capstone series\n \nMore on the development of the data collection framework: Development of Input Libraries With Intel XLSDK to Capture Data for App Start Prediction\n \n    submitted by    /u/cgorlla  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfkum9/p_intellinext_a_lstm_and_hmmbased_solution_for/",
          "publishedOn": "2022-03-16T15:46:54.000Z",
          "wordCount": 196,
          "title": "[P] INTELlinext: A LSTM and HMM-Based Solution for Next-App Prediction (collaboration with Intel)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfjtr5/p_r_database_of_real_life_face_images_in/",
          "author": null,
          "description": "Hi!\n I am searching for a database of 500 images of each of these 6 skin types: asian, black, indian, hispanic/latino, middle eastern and white. I want to comparison some 100k images that I have produced with StyleGAN2 to verify the quality difference of skin types and want some good quality images to compare my data towards. Thank you for any advice of where I can find such. A db with good quality face images in 1024x1024 that isnt categorized with different skin types is also appreciated as I can use deepface to ceparate them\n    submitted by    /u/oSunde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfjtr5/p_r_database_of_real_life_face_images_in/",
          "publishedOn": "2022-03-16T15:10:45.000Z",
          "wordCount": 270,
          "title": "[P] [R] Database of real life face images in 1024x1024 categorised by skin type for StyleGAN2 FID comparisons",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfjdfp/d_what_is_the_current_consensus_on_the/",
          "author": null,
          "description": "There is a lot of research going on in Active Learning but I feel there is nothing conclusive coming out of this field. A lot of methods are struggling to beat the random sampling baseline.\n For example, they used to publish this promising paper of using drop out for uncertainty estimation:\n https://arxiv.org/pdf/1506.02142.pdf\n But people tried to use it and it was just not performing well. Since then, I am not sure if DL methods can properly bootstrap themselves and identify what they do not know.\n I feel people are just urged to publish papers and it is too easy to fake the numbers and reportedly beating baselines until the next guy tries to reproduce the results.\n Is my skepticism justified? Or are there some methods (links appreciated) that are productively used in the industry?\n Edit:\n To narrow the discussion, i mean active learning in the sense of finding the next samples to label to maximize improvement of the current model performance.\n    submitted by    /u/KonArtist01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfjdfp/d_what_is_the_current_consensus_on_the/",
          "publishedOn": "2022-03-16T14:49:59.000Z",
          "wordCount": 1286,
          "title": "[D] What is the current consensus on the effectiveness of Active Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfhclu/p_explanation_video_of_open_retrieval_question/",
          "author": null,
          "description": "In this video, I discuss ORQA which uses a retriever to find the right context from the entire Wikipedia and then uses an extractive QA model to give a final answer. We discuss the task setup, architecture, and loss function.\n The video is part of 8 video series on Open domain question answering, how it is different from normal QA, the difference in loss formulations, and key papers on different Open-QA architectures.\n I will really appreciate any feedback. \n https://www.youtube.com/watch?v=9bL2VbwZ9G8\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfhclu/p_explanation_video_of_open_retrieval_question/",
          "publishedOn": "2022-03-16T13:11:36.000Z",
          "wordCount": 177,
          "title": "[P] Explanation video of Open Retrieval Question Answering (ORQA)",
          "imageUrl": "https://external-preview.redd.it/HTMibamaDd8V-S774PygAw37dNn1nKUaGwCwK9Q6_fo.jpg?auto=webp&s=9a06545c15fc5655eb173c4841dfe8611e514ba4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfe32n/d_ijcai_2022_rebuttal_discussion/",
          "author": null,
          "description": "This is a discussion panel for IJCAI 2022 reviews.\n    submitted by    /u/errohan400  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfe32n/d_ijcai_2022_rebuttal_discussion/",
          "publishedOn": "2022-03-16T09:59:39.000Z",
          "wordCount": 650,
          "title": "[D] IJCAI 2022 Rebuttal Discussion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfe105/d_are_crossvalidation_and_other_traditional_error/",
          "author": null,
          "description": "The standard error analysis tools like cross-validation, ROC curve, confusion matrix are always discussed in machine learning university courses. However, based on my experience in the real-world project, these approaches are not enough to decide whether a model is good or not?\n For example, these tools do not answer on which segment of data the model performs poorly or in which part the model confidence is low?\n Is there any standard approach or tool that can answer these questions and make machine learning error analysis more in-depth?\n    submitted by    /u/RiseHappy5641  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfe105/d_are_crossvalidation_and_other_traditional_error/",
          "publishedOn": "2022-03-16T09:55:34.000Z",
          "wordCount": 543,
          "title": "[D] Are cross-validation and other traditional error analytics tools enough for real-world machine learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tfbf4c/rp_driving_an_ae86_with_factorized_optical_flow/",
          "author": null,
          "description": "Hi MachineLearning,\n I would like to introduce a new concept of utilizing factorized optical flow maps as mid-level representations, for bridging the perception and the control modules in modular learning based robotic frameworks. \n In the below video, we demonstrate the DRL agent is able to control itself by perceiving the factorized optical flow maps, and without bumping into the pedestrians in the urban environment based on Unity.\n Hope you like the idea and enjoy the video!\n The screenshot from the demo video\n Demo video: https://youtu.be/Op4QRTJOGMY\n More details here: https://arxiv.org/abs/2203.04927\n    submitted by    /u/Kanahei  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tfbf4c/rp_driving_an_ae86_with_factorized_optical_flow/",
          "publishedOn": "2022-03-16T06:48:35.000Z",
          "wordCount": 203,
          "title": "[R][P] Driving an AE86 with factorized optical flow maps as mid-level representations",
          "imageUrl": "https://external-preview.redd.it/87AWvIOTXl6oOFdN6OWXwSGdPzbnVMCKt6pbaeSjLXo.jpg?auto=webp&s=939feb4889bdaa2b09010bb5ad6f95f6a07e94a3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tf8owz/d_deep_neural_nets_33_years_ago_and_33_years_from/",
          "author": null,
          "description": "In a blog post Andrej Karpathy Director of AI at Tesla remakes the LeCun 1989 experiment, which was the earliest application of a neural net trained with backpropagation. Then he improves that result using 33 years of progress in deep learning. Finally, he tries to extrapolate the result in 33 years from now, so in 2055. I let you guess what he concluded...\n    submitted by    /u/ClaudeCoulombe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tf8owz/d_deep_neural_nets_33_years_ago_and_33_years_from/",
          "publishedOn": "2022-03-16T03:55:21.000Z",
          "wordCount": 1053,
          "title": "[D] Deep Neural Nets: 33 years ago and 33 years from now - by Andrej Karpathy Dir. of AI at Tesla",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tf4fj9/discussion_your_worst_bug_in_ml_code/",
          "author": null,
          "description": "What are the common types of bugs that are the hardest to catch in ML code(while writing a model) vs. (while re-using a model and writing pre-, post-processing code)?\n Tell me about your worst bug. Also, lmk if you would want to vent to me over a voice chat maybe. Im trying to understand a little more about the common bugs.\n    submitted by    /u/CarbonCosma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tf4fj9/discussion_your_worst_bug_in_ml_code/",
          "publishedOn": "2022-03-16T00:12:56.000Z",
          "wordCount": 155,
          "title": "[Discussion] Your worst bug in ML code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tf3pw6/discussion_innovative_ways_to_share_ml_based_work/",
          "author": null,
          "description": "I am a machine learning engineer (initially started as an android engineer who built ML based features along with creating the application and then completely went into mainstream ML based systems) who worked on several pocs/mvps at several startups during the course of my 4-5 year career. There have been around 8-9 pocs I have built during this time. Don't mean to sound boastful at all but in most of them I was the sole contributor and came up with the product idea, did the required analysis/experimentation, developed/tested/sometimes made a lot of changes to existing models to make them work, built several recommendation systems and 2-3 ML based systems. Some of these ML based systems weren't straightforward and took quite some time to optimise and achieve results which would have a mean…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tf3pw6/discussion_innovative_ways_to_share_ml_based_work/",
          "publishedOn": "2022-03-15T23:39:00.000Z",
          "wordCount": 875,
          "title": "[Discussion] : Innovative ways to share ML based work protected by a NDA (happy to hear advice for ML engineers going through mid-career crisis)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tf34qp/n_tutorial_on_conformal_prediction_and_dfuq_part/",
          "author": null,
          "description": "Hey everyone!\n We just posted Part 2 of our Tutorial on Conformal Prediction and Distribution-Free Uncertainty Quantification on YouTube!\n https://youtu.be/TRx4a2u-j7M\n It focuses on conditional coverage and diagnostics to make sure your conformal procedure is working properly. It's slightly more advanced than the last one, but will leave you with a strong understanding of how to implement/evaluate conformal in code.\n Let us know if you have any feedback by shooting me an email :)\n Best,\n Anastasios\n    submitted by    /u/aangelopoulos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tf34qp/n_tutorial_on_conformal_prediction_and_dfuq_part/",
          "publishedOn": "2022-03-15T23:11:01.000Z",
          "wordCount": 182,
          "title": "[N] Tutorial on Conformal Prediction and DFUQ Part 2: Conditional Coverage + Diagnostics",
          "imageUrl": "https://external-preview.redd.it/BAb7-5PxrK4z2JDmgGJvPaWsXMXYRbUGqVhfwORKuQ4.jpg?auto=webp&s=d885c3967c3ffac46d73cb2a095073309b7aa7f5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tf1uo5/d_impact_factor_of_neurips_and_other_conferences/",
          "author": null,
          "description": "For those of us who publish both at ML conferences and in traditional academic journals, it would be incredibly useful to know the impact factor of NeurIPS and other top ‏‏‎ ML conferences. In many non-CS departments, these conferences are still relatively unknown, and so being able to report these numbers internally would be very helpful, particularly to satisfy deans during hiring reviews. While ISI does not officially estimate the impact factor for conferences, this Microsoft page suggests that the impact factor of NeurIPS has a steady state value ~30 - 40. Does anyone have a secondary source for this, or another estimate? I am well aware of the many flaws of using impact factor to estimate the \"importance\" of a paper. Unfortunately, my university (and I would imagine many others) are stuck with it. Thank you!\n    submitted by    /u/LittleCathyXO  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tf1uo5/d_impact_factor_of_neurips_and_other_conferences/",
          "publishedOn": "2022-03-15T22:13:06.000Z",
          "wordCount": 238,
          "title": "[D] Impact factor of NeurIPS and other conferences ;",
          "imageUrl": "https://external-preview.redd.it/VWc3X3izLL1g2V6ilCwV2BtLl2zrePT6C8o7_mTI-OA.jpg?auto=webp&s=da329c1ed610f244a5b54148855f141298b3677b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tey7at/d_making_deep_learning_go_brrrr_from_first/",
          "author": null,
          "description": "Folks often want their models to run faster. But... researchers often end up cargo culting performance tricks without understanding the underlying principles.\n To help address that, I wrote a blog called \"Making Deep Learning Go Brrrr From First Principles\": https://horace.io/brrr_intro.html\n Basically, for most models, there are 3 regimes that you might be spending all of your time on - Compute, Memory-Bandwidth, and Overhead. (If we wanted to be exhaustive, we could also include data-loading (i.e. Disk Bandwidth) and distributed calls (i.e. network bandwidth)).\n Figuring out which one you're bottlenecked by is crucial if you want to spend your time on actually speeding up your model and not trying out random stuff :P\n Hope folks find it useful - happy to clarify/get any feedback here.\n    submitted by    /u/programmerChilli  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tey7at/d_making_deep_learning_go_brrrr_from_first/",
          "publishedOn": "2022-03-15T19:44:46.000Z",
          "wordCount": 269,
          "title": "[D] Making Deep Learning Go Brrrr From First Principles",
          "imageUrl": "https://external-preview.redd.it/M5QI4jDNmlpuyYuyEDKNleq5CO-piLZmNg6TqG2y4f4.jpg?auto=webp&s=3eb149f2e306810ebb3203f95849f57281aafe92"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tewec5/project_interested_in_reinforcement_learning_read/",
          "author": null,
          "description": "When working on a promotion optimization problem there are a lot of different multi-armed bandit algorithms to choose from. In a recent DoorDash project I worked on I did a technology survey of three reinforcement learning algorithms :Epsilon-Greedy, The Upper Confidence Bound, and Thompson Sampling. I wanted to share my experience and why we ultimately decided to go with Thompson sampling. Let me know what you think, and take a look at this post to get the technical details\n    submitted by    /u/Outrageous_Pilot_351  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tewec5/project_interested_in_reinforcement_learning_read/",
          "publishedOn": "2022-03-15T18:38:28.000Z",
          "wordCount": 207,
          "title": "[Project] Interested in Reinforcement learning? Read how DoorDash used Thompson Sampling to optimize our promotional messages to Dashers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/teur50/dp_next_steps_for_testing_a_new_learning_technique/",
          "author": null,
          "description": "I'm working on a new learning technique in pytorch and have gotten some promising results. It doesn't always work, but when it does it gives a small boost in accuracy at a cost of network size and speed. It seems to be correlated with the ratio of dataset size to original network size. I can use it on a small two layer model on MNIST and boost accuracy from 98% to 99.5%. And I've been able to get it to work on pytorch's baseline 18 layer Resnet on ImageNet. However, I can't do more serious without paying thousands of dollars for AWS testing. I'm looking for any of the following:\n ​\n  \nSuggestions on any large datasets where the current state of the art architecture and training code are both open source and also can be run on a single GPU.\n Suggestions for applications where a small boost in accuracy would be worth a slowdown and network size isn't a problem.\n Connections with anyone who works for a company in one of those fields who might be open to hearing my pitch and testing it with me.\n  \n   submitted by    /u/ronthebear  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/teur50/dp_next_steps_for_testing_a_new_learning_technique/",
          "publishedOn": "2022-03-15T17:42:21.000Z",
          "wordCount": 471,
          "title": "[D][P] Next steps for testing a new learning technique",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/teu7dn/announcement_huggingface_bigscience_ama_thursday/",
          "author": null,
          "description": "Come ask questions about everything on the new HuggingFace BigScience language model, the dataset, the licences, the cluster!\n BigScience have just started training a massive-scale multilingual language model on the French supercomputer Jean Zay with BigScience – literally out in the open. This is not only the first time a multilingual LLM (46 languages!) at this scale will be fully accessible to the ML research community, but the whole decision, engineering and training process is transparent and open. We'll be training for several months and the community can follow along, engage and ask questions, etc. The Reddit AMA will be with some of our chairs and leading engineers and research scientists like Stas Bekman (Hugging Face), Iz Beltagy (AI2), Julien Launay (LightOn) and many more.\n The model, compute and training\n  \n176B parameters – 70 layers, 112 attention heads\n 384 A100 80GB GPUs– on Jean Zay\n Checkpoint size: only the bf16 weights are 329GB, the full checkpoint with optimizer states is 2.3TB\n Training throughput: about 150 TFLOPs\n Estimated training time: 3-4 months (depending on throughput and unexpected events)\n  \nMore info\n  \nModel architecture and a blog post on decisions on architecture, size, shape, and pretraining duration\n Tensorboard during the training\n Details on the obstacles overcome during the preparation on the engineering side (instabilities, optimization of training throughput, many technical challenges and questions)\n  \n   submitted by    /u/cavedave  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/teu7dn/announcement_huggingface_bigscience_ama_thursday/",
          "publishedOn": "2022-03-15T17:17:53.000Z",
          "wordCount": 320,
          "title": "[Announcement] HuggingFace BigScience AMA Thursday, March 24th from 5pm CET",
          "imageUrl": "https://external-preview.redd.it/3Km442TzY13Kf6KPd4AwJ_yqnfnhu1zrMIwjZLPDqEI.jpg?auto=webp&s=fb2630db70a4a5fbe71b3770fa916bfd4cad1d6a"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tettof/r_watching_the_watchmen_pitfalls_in_graph/",
          "author": null,
          "description": "Graph generative models are a hot topic in ML, with new models being proposed regularly. Their goal: synthesise new graphs from a learned distribution of input graphs. While coming up with a new model may be hard, it turns out that a proper comparison of individual models is even harder!\n In this blog post, I briefly summarise our recent ICLR 2022 spotlight paper on evaluating such models. Spoiler alert: kernels make a surprising comeback, but the devil, as always, is in the details.\n Let me know what you think!\n    submitted by    /u/Pseudomanifold  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tettof/r_watching_the_watchmen_pitfalls_in_graph/",
          "publishedOn": "2022-03-15T17:04:39.000Z",
          "wordCount": 191,
          "title": "[R] Watching the Watchmen: Pitfalls in Graph Generative Model Evaluation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tetfcw/d_are_ddpms_a_variation_on_score_based_generative/",
          "author": null,
          "description": "Are DDPMs a variation on Score Based Generative Modeling? Or is there a fundemental difference between the two?\n    submitted by    /u/ondrea_luciduma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tetfcw/d_are_ddpms_a_variation_on_score_based_generative/",
          "publishedOn": "2022-03-15T16:50:52.000Z",
          "wordCount": 585,
          "title": "[D] Are DDPMs a variation on Score Based Generative Modeling? Or is there a fundemental difference between the two?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ten0dh/n_flower_summit_2022_announcement/",
          "author": null,
          "description": "Save the Date!\n The federated learning experts and the Flower community are coming together to share the latest research results on the field of federated learning and present their recent use case scenarios at the\n Flower Summit 2022 on the 31st of May 2022.\n The summit will in addition contain some hands-on workshops to give you all the knowledge and know-how to find out how Flower accelerates the development of systems in both research and production scenarios. The conference will take place in Cambridge and online that every data science and machine learning enthusiast has the chance to attend the summit.\n Block your calendar and register for the conference here: \n https://flower.dev/conf/flower-summit-2022/\n If you are working on federated learning and want to present your research results or use cases, you have now the chance to send us your presentation abstract via the Call for Speaker option.\n    submitted by    /u/burnai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ten0dh/n_flower_summit_2022_announcement/",
          "publishedOn": "2022-03-15T11:40:08.000Z",
          "wordCount": 229,
          "title": "[N] Flower Summit 2022 Announcement",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/telho1/r_recent_advances_in_efficient_and_scalable_graph/",
          "author": null,
          "description": "Hello r/MachineLearning!\n I would like to share a research blogpost overviewing the toolbox enabling Graph Neural Networks to scale to real-world graphs and real-time applications.\n \"Recent Advances in Efficient and Scalable Graph Neural Networks\"\n Blogpost: https://www.chaitjo.com/post/efficient-gnns/\n Twitter Thread: https://twitter.com/chaitjo/status/1503668741443362817\n Training and deploying GNNs to handle real-world graph data poses several theoretical and engineering challenges: \n  \nGiant Graphs – Memory Limitations \n Sparse Computations – Hardware Limitations \n Graph Subsampling – Reliability Limitations\n  \nThe blogpost introduces three simple but effective ideas in the 'toolbox' for developing efficient and scalable GNNs: \n  \nData Preparation - From sampling large-scale graphs to CPU-GPU hybrid training via historical node embedding lookups. \n Efficient Architectures - Graph-augmented MLPs for scaling to giant networks, and efficient graph convolution designs for real-time inference on batches of graph data. \n Learning Paradigms - Combining Quantization Aware Training (low precision model weights and activations) with Knowledge Distillation (improving efficient GNNs using expressive teacher models) for maximizing inference latency as well as performance.\n  \n   submitted by    /u/chaitjo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/telho1/r_recent_advances_in_efficient_and_scalable_graph/",
          "publishedOn": "2022-03-15T10:00:49.000Z",
          "wordCount": 557,
          "title": "[R] Recent Advances in Efficient and Scalable Graph Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tejt1j/d_recurrent_neural_networks_for_multivariate_time/",
          "author": null,
          "description": "Hi, I have just published my latest medium article.\n Time series are everywhere, in every industry from Energy to Geoscience, etc. Therefore, it is crucial to work on them; In most cases (especially in real-world projects), time-series datasets contain numerous missing data points which are highly connected to the output of prediction. This article gives you a review of the existed methods and then a thorough illustration of GRU-D (based on Gated Recurrent Unit) to deal with missing points. I also, added the code of the model construction for better understanding or utilizing in your possible project.\n This method is certainly useful in most real-world cases because it is usual to have some missing points in gathering and collecting your time-series data. Though the proposed model is for classification, I believe that we can utilize it for regression tasks as well.\n Please share this article with those who might find it interesting or useful in their works. Finally, let me know your impression or your feedback.😉\n here is the link: \n https://rezayazdanfar.medium.com/recurrent-neural-networks-for-multivariate-time-series-with-missing-values-38c2bc91dd45\n    submitted by    /u/rezayazdanfar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tejt1j/d_recurrent_neural_networks_for_multivariate_time/",
          "publishedOn": "2022-03-15T07:56:20.000Z",
          "wordCount": 279,
          "title": "[D] Recurrent Neural Networks for Multivariate Time Series with Missing Values",
          "imageUrl": "https://external-preview.redd.it/-Gdpv2L2wlzN_Kvth6ETgk8SqEMVMVjmJiTxYGkLhlM.jpg?auto=webp&s=12750df4591fc0f3a6aeff8ec53bed6654c07a26"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tei9om/what_is_the_future_of_ai_in_biology_and_medicine_d/",
          "author": null,
          "description": "So I know that AI has been used to predict people’s biological age, and I recently read an article where researchers used machine learning to train AI to find mitophagy inducing compounds that could potentially be used in Alzheimer’s treatment. I find the multifaceted nature or machine learning fascinating. So, how long do you think it will take until we have AI capable of identifying safe and effective compounds that can be used to treat cancer? I would love if anyone could link any relevant articles or studies pertaining to this question so that I can explore this topic more:)\n    submitted by    /u/tylstem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tei9om/what_is_the_future_of_ai_in_biology_and_medicine_d/",
          "publishedOn": "2022-03-15T06:05:39.000Z",
          "wordCount": 265,
          "title": "What is the future of AI in biology and medicine? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/teh4c6/n_join_2022_vancouver_women_in_data_science/",
          "author": null,
          "description": "Holaaa!\n 2022 WiDS(Women in Data Science) Vancouver Annual Conference is happening this Friday (march 18) as well as next Friday (march 25) virtually. The topic this year is Data Science in Production with 4 sub topics. Speakers come from Shopify, AWS, EA, VEERUM and more. The two-day conference ticket is 15 CAD and students get a 20% discount! Here's the schedule of the conference as well as speaker highlights! And you can purchase your ticket over here: https://www.eventbrite.ca/e/2022-vancouver-women-in-data-science-conference-tickets-261599981587\n (I'm part of the organizing committee (DataCan, datacan.network. If you wanna know more about DataCan, message me or comment below!)\n ​\n https://preview.redd.it/e62agjhmahn81.png?width=2381&format=png&auto=webp&s=b3c1e5fc72b6f7e9925e945e2cf2a3882f16e177\n ​\n https://preview.redd.it/0zo20jhmahn81.png?width=2381&format=png&auto=webp&s=d8a34272c74c433488d70bf29548904604fd03c9\n    submitted by    /u/44mushrooms  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/teh4c6/n_join_2022_vancouver_women_in_data_science/",
          "publishedOn": "2022-03-15T04:53:47.000Z",
          "wordCount": 215,
          "title": "[N] Join 2022 Vancouver Women in Data Science Annual Conference (Virtual) March 18 & 25",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tecdvj/machinedeep_learning_and_neural_networks_for/",
          "author": null,
          "description": "Hey ya'll,\n I'm writing a paper for an intro to Data Science course at school and I'm looking for any and all resources that help explain what a neural network is, how it functions, and how its built. Nothing too heavy, just baseline knowledge for something showing interest in the field. Any resources you can share I'd greatly appreciate!\n    submitted by    /u/JonnyEoE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tecdvj/machinedeep_learning_and_neural_networks_for/",
          "publishedOn": "2022-03-15T00:44:00.000Z",
          "wordCount": 156,
          "title": "Machine/Deep Learning and Neural Networks for beginners. [P],[D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tec70t/d_have_questions_about_applications_of_machine/",
          "author": null,
          "description": "Wednesday night (3/16), 8-11 pm EDT, FSU professor and computer scientist Dr. Chris Mills will be the guest on Ask_a_Scientist_Gaming. \n Chris’ research focus started in applications of machine learning to common software development tasks like concept location and traceability link recovery but has since broadened to applications of machine learning across many industries including finance and law. Current projects include building database-agnostic, natural language interfaces for question-and-answer systems with impedance reduction built from off-the-shelf object-relational mapping. With such an interface, users can directly answer questions and query data with no knowledge of a query language and no need to have custom reports constructed for each information need. Think “Jarvis,” but employees play the role of Iron Man at a bank… and a law firm…. and a hospital… and a university…. and the list goes on.\n If you can’t make the live stream, feel free to leave your question in the comments and we will get them answered. Then follow up with our YouTube channel where we will post the video.\n    submitted by    /u/HansonFSU  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tec70t/d_have_questions_about_applications_of_machine/",
          "publishedOn": "2022-03-15T00:34:21.000Z",
          "wordCount": 372,
          "title": "[D] Have questions about applications of machine learning? Join us Wed (3/16), 8-11 pm EDT for a live Q&A with Dr. Chris Mills who is happy to talk about applying ML to traceability link recovery, object-relational mapping, and more (while playing Robotron-64).",
          "imageUrl": "https://external-preview.redd.it/prV0ZW6SDO5RM5c5wB2TIOVLeqbV1Nlp46FLgDp8IVw.jpg?auto=webp&s=6ac49732404f45acc972119b17155fc704c255d8"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/teaku0/d_karpathy_gptlike_transformer_is_now_predicting/",
          "author": null,
          "description": "Karpathy: \"This 'direct to vector space' framework allows predictions to be jointly coherent (due to sequential conditioning) and very easily used by planner (due to sparsity).\"\n Is this a DE⫶TR+Decision Transformer? \n What are they doing at Tesla?\n    submitted by    /u/Mysterious-Move-8102  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/teaku0/d_karpathy_gptlike_transformer_is_now_predicting/",
          "publishedOn": "2022-03-14T23:14:24.000Z",
          "wordCount": 154,
          "title": "[D] Karpathy: GPT-like Transformer is now predicting the lanes and their connectivity in FSD 10.11",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/te9nq3/p_hosted_jupyterlab_with_free_gpu/",
          "author": null,
          "description": "For the past 6 months my co-founder and I have built Cloudburst, a new platform based on JupyterLab. A free account gets you notebooks, an editor, and shell access, plus 50 hours of free GPU.\n Cloudburst is designed specifically for ML researchers and developers. We worry about cuda drivers, machine specs, and python versions -- you get to focus on the fun stuff.\n We are in pre-release mode, and actively looking for early customers to give us feedback to help us serve you better.\n Questions? Please reach out: beta@cloudburst.host.\n    submitted by    /u/burstableai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/te9nq3/p_hosted_jupyterlab_with_free_gpu/",
          "publishedOn": "2022-03-14T22:31:53.000Z",
          "wordCount": 227,
          "title": "[P] Hosted JupyterLab with free GPU",
          "imageUrl": "https://external-preview.redd.it/zDHjUNuI4wMTFAMu7E5Xvs7Tq7zaIV1d9beXg_lB9VA.jpg?auto=webp&s=c345fbde307c9aea8a4e1c40c5a810226fccc786"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/te8rn4/r_masked_visual_pretraining_for_motor_control/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/te8rn4/r_masked_visual_pretraining_for_motor_control/",
          "publishedOn": "2022-03-14T21:51:26.000Z",
          "wordCount": 96,
          "title": "[R] Masked Visual Pre-training for Motor Control",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/te8lw5/d_which_ai_model_to_use_and_how_to_train_for/",
          "author": null,
          "description": "TL;DR: I want to build an app to while the user will give a question, a topic or some clue and it will recall most relevant phrases that pertain to the input. The phrases should not be made up text, rather factual (like come from a source like Wikipedia, medical journal, news source etc). What type of AI model can support this and how?\n Hi Folks,\n I want to build an app that will recall factual phrases based on user input. A good example is a quote finder or lookup chemical formula for a drug etc. So user enters a topic, a question or a clue and I want the AI model to come up with (one or more) relevant answers. Say I want to limit the model for one industry vertical or type of application (like quotes only or medical only etc). \n I am fairly new to AI usage and have learned and used OpenAI's GPT3 examples recently. I've also build a few small apps using their API.\n I want to know the following:\n  \nWhat type of hosted AI engines would support this type of use case? Give specifics. For example, OpenAI's Davinci or GPT-NeoX-20B. \n What is this type of application of AI called? I know it's not just transformation. It's actually a strong recall and I do not know the technical name for it.\n Tell me something about how do I fine tune the model. I have some datasets for Quotes that I can use. If I train on them, then how can I make sure that the answers the model generates are factually accurate? That is, it's not making them up (as in the case of story completion).\n  \nThanks in advance!\n    submitted by    /u/ZeeKayNJ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/te8lw5/d_which_ai_model_to_use_and_how_to_train_for/",
          "publishedOn": "2022-03-14T21:42:00.000Z",
          "wordCount": 392,
          "title": "[D] Which AI model to use and how to train for factual recall application?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/te5xhs/d_one_possible_approach_to_develop_the_best/",
          "author": null,
          "description": "One possible approach to develop the best possible general learning algorithm\n Introduction\n In the world we live in, there are many problems that need to be urgently solved: climate change[1], the risk of a new pandemic[2], wealth inequality[3], the aging population[4] and more. All of these problems are hugely complex and solving them requires vast amounts of intelligence. In order to address that, there’s a tool that comes in very handy: Artificial Intelligence. We are all familiar with AI, but to put it shortly, it’s the intelligence demonstrated by machines[5]. In recent years, AI has proven to be a game changer for industries such as healthcare and finance, but most experts agree that we are just at the beginning of what has been termed as “The AI revolution”[6]. The culmination poin…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/te5xhs/d_one_possible_approach_to_develop_the_best/",
          "publishedOn": "2022-03-14T19:42:44.000Z",
          "wordCount": 2314,
          "title": "[D] One possible approach to develop the best possible general learning algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/te5sdj/n_ml_training_compute_has_grown_by_a_factor_of_10/",
          "author": null,
          "description": "Here's the paper and a Twitter summary.\n Abstract:\n  \nCompute, data, and algorithmic advances are the three fundamental factors that guide the progress of modern Machine Learning (ML). In this paper we study trends in the most readily quantified factor - compute. We show that before 2010 training compute grew in line with Moore's law, doubling roughly every 20 months. Since the advent of Deep Learning in the early 2010s, the scaling of training compute has accelerated, doubling approximately every 6 months. In late 2015, a new trend emerged as firms developed large-scale ML models with 10 to 100-fold larger requirements in training compute. Based on these observations we split the history of compute in ML into three eras: the Pre Deep Learning Era, the Deep Learning Era and the Large-Scale Era. Overall, our work highlights the fast-growing compute requirements for training advanced ML systems.\n  \n   submitted by    /u/cirqe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/te5sdj/n_ml_training_compute_has_grown_by_a_factor_of_10/",
          "publishedOn": "2022-03-14T19:36:30.000Z",
          "wordCount": 290,
          "title": "[N] ML training compute has grown by a factor of 10 Billion (10'000'000'000) over the last 12 years.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/te1lyi/p_diditspill_a_tiny_library_that_checks_if_you/",
          "author": null,
          "description": "Made a super tiny library that hashes your data and compares the hashes to determine if you have samples leaked into the other dataset. \n Main usage is to add one line of code before your training loop as an extra check.\n Useage is as easy as: python spills = check_spill(train_loader, test_loader) \n Github: https://github.com/LaihoE/did-it-spill Currently only for PyTorch\n    submitted by    /u/yliopisto420  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/te1lyi/p_diditspill_a_tiny_library_that_checks_if_you/",
          "publishedOn": "2022-03-14T16:35:39.000Z",
          "wordCount": 490,
          "title": "[P] did-it-spill a tiny library that checks if you have training samples in your test set",
          "imageUrl": "https://external-preview.redd.it/LA057LAcrUJwODw7caU7Bmmzy0HndJRTKljZllt07mc.jpg?auto=webp&s=1a1cb9013e60caff590c5c3caa6668a7b63ad915"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/te0ohh/d_how_do_they_create_salient_object_detection/",
          "author": null,
          "description": "Salient Object Detection aims at highlighting visually salient objects which are attracted human's attention. I wonder how standard SOD datasets are made and how employed human subjects can label which objects are salient, especially when there are multiple salient objects in some image.\n Thank you in advance!\n    submitted by    /u/Ill_Prize1401  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/te0ohh/d_how_do_they_create_salient_object_detection/",
          "publishedOn": "2022-03-14T15:55:56.000Z",
          "wordCount": 258,
          "title": "[D] How do they create salient object detection datasets?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/te0axk/d_separating_the_preprocessing_step_from_the/",
          "author": null,
          "description": "I'm searching about some API architecture for machine learning models and I see that some practitioners tend to create (1) an API endpoint that contains both the data preprocessing steps (cleaning, featurization, etc.) and the model serving/inference; or (2) one endpoint for data preprocessing and another one for model serving. I'm not assuming that one architecture is right while the other is wrong, but what do you guys think is the tradeoff between each one of these choices?\n    submitted by    /u/paulo_zip  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/te0axk/d_separating_the_preprocessing_step_from_the/",
          "publishedOn": "2022-03-14T15:39:04.000Z",
          "wordCount": 438,
          "title": "[D] Separating the preprocessing step from the model serving?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdyc14/d_mlpmixer_variants_which_one_is_best/",
          "author": null,
          "description": "Those of you who've used MLP-Mixer type models (MLP-Mixer, gMLP, ResMLP etc.) -- which variant have you found works best?\n What are the main takeaways for one version versus another?\n They all seem to start with the same basic premise -- use MLPs over patches and over channels -- but a lot of them make slightly different architectural choices. So I'm hoping to pick the brains of the community here.\n    submitted by    /u/patrickkidger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdyc14/d_mlpmixer_variants_which_one_is_best/",
          "publishedOn": "2022-03-14T14:08:30.000Z",
          "wordCount": 420,
          "title": "[D] MLP-Mixer variants -- which one is best?",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdxd1m/np_mitigating_deep_learning_painpoints_with_padl/",
          "author": null,
          "description": "We recently published the open-source project PADL (padl.ai), a deep learning development framework for Pytorch, which we wanted to share with you.\n PADL streamlines the entire deep learning workflow, from experimentation to deployment. Its functional API provides a satisfying correspondence to the “box-and-arrow” mental model for deep learning models, with node logic implemented as pure Python functions.\n Try it out for yourself on Colab:\n  \nCLIP guided diffusion for face editing\n Sentiment Analysis - NLP\n  \nAnd read more about PADL on our developer blog! https://devblog.padl.ai/\n You can get easily started with\n pip install padl \n We look forward to welcoming you into the PADL community, as either a user or a developer! And we would really appreciate getting your feedback.\n Best,\n the LF1 Team\n    submitted by    /u/sjrlee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdxd1m/np_mitigating_deep_learning_painpoints_with_padl/",
          "publishedOn": "2022-03-14T13:20:42.000Z",
          "wordCount": 208,
          "title": "[N][P] Mitigating Deep Learning Pain-Points with PADL",
          "imageUrl": "https://external-preview.redd.it/rMRjkYivwWW_vbQMaYs06hcYhkbEzRFRQY4_VFR5VVI.jpg?auto=webp&s=b8be8fdb0b216f1cc5d06261ab1908f6fd76baea"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdwqtg/d_aiml_blog_introduction_and_launch/",
          "author": null,
          "description": "I want to introduce you all to my AI/ML Blog. I have been a member of this sub (from my personal account) for a few months now, and am excited to present my company blog to this community.\n We believe a well-educated population leads to cutting-edge innovation and so to do our part, we are publishing our blog! Through our blog, we aim to increase awareness and educate less-experienced individuals on AI/ML and its applications, as well as, chime in on new advancements in the field, and open up a discussion with experienced practitioners developing and using the next generation of AI/ML technologies and practices. Our writers are publishing articles on a wide range of topics related to AI/ML, from best techniques and practices to picking third-party providers for different aspects of the AI/ML projects, to applications in different industries.\n Please check it out and send us some feedback! To get our future stories you can also subscribe to our newsletter.\n    submitted by    /u/BiztechAnalytics  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdwqtg/d_aiml_blog_introduction_and_launch/",
          "publishedOn": "2022-03-14T12:50:08.000Z",
          "wordCount": 251,
          "title": "[D] AI/ML Blog Introduction and Launch",
          "imageUrl": "https://external-preview.redd.it/H5VgafjYNLbYEf9ik2uGKd7INJU5ZGHw12PpRS7bJXI.jpg?auto=webp&s=81dbb506d3c31831f25a2b0bb2091715857f5c1a"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdrm79/machine_learning_databases/",
          "author": null,
          "description": "submitted by    /u/losethefur  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdrm79/machine_learning_databases/",
          "publishedOn": "2022-03-14T07:14:18.000Z",
          "wordCount": 87,
          "title": "Machine learning databases (Medical/computer/internet/etc.)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdisyo/d_p_some_ideas_and_speculations_on_the_problem_of/",
          "author": null,
          "description": "Hi guys. I'm a new Deep Learning researcher who just started working at a company that focuses on AI-based image manipulation.\n The goal is to design an AI-based solution that takes an edited/retouched input image and apply the edits/retouches style of the user and apply it to the rest of the images automatically\n Example situation:\n Given a bunch of photos of portrait faces, a software user retouch the first portrait by removing blemishes and pimples with an inpainting tool and some local/global enhancement color adjustment, the algorithm needs to know what and where kind of editing has been made and where the thing to remove with inpainting and apply them to the rest of images.\n I have to thought of using an agent (policy network) to interact with the editing software and imitate the user behavior (Few-Shot Imitation Learning) on the first edited examples.\n My questions:\n  \nWhat Machine Learning paradigm appears to be suitable for this problem (e.g, Supervised learning, Reinforcement learning).\n Research direction that might be help full to solve the problem.\n Papers that did this kind of research on examplar based user style transfer.\n Any ideas on how to tackle this problem.\n  \nI wanted to hear what you guys think about it and if you have any idea.\n    submitted by    /u/kTonpa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdisyo/d_p_some_ideas_and_speculations_on_the_problem_of/",
          "publishedOn": "2022-03-13T22:52:41.000Z",
          "wordCount": 324,
          "title": "[D] [P] Some ideas and speculations on the problem of automatic examplar-based photo retouching and action transfer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdib6x/d_reporting_metrics_after_training_on_validation/",
          "author": null,
          "description": "How frequently have you all suspected people report metrics in papers on the validation set after training on the validation set?\n    submitted by    /u/Academic-Sprinkles77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdib6x/d_reporting_metrics_after_training_on_validation/",
          "publishedOn": "2022-03-13T22:29:13.000Z",
          "wordCount": 216,
          "title": "[D] reporting metrics after training on validation set?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdgknh/d_video_paper_explanation_vos_learning_what_you/",
          "author": null,
          "description": "https://youtu.be/i-J4T3uLC9M\n Outliers are data points that are highly unlikely to be seen in the training distribution, and therefore deep neural networks have troubles when dealing with them. Many approaches to detecting outliers at inference time have been proposed, but most of them show limited success. This paper presents Virtual Outlier Synthesis, which is a method that pairs synthetic outliers, forged in the latent space, with an energy-based regularization of the network at training time. The result is a deep network that can reliably detect outlier datapoints during inference with minimal overhead.\n ​\n OUTLINE:\n 0:00 - Intro\n 2:00 - Sponsor: Assembly AI (Link below)\n 4:05 - Paper Overview\n 6:45 - Where do traditional classifiers fail?\n 11:00 - How object detectors work\n 17:00 - What are virtual outliers and how are they created?\n 24:00 - Is this really an appropriate model for outliers?\n 26:30 - How virtual outliers are used during training\n 34:00 - Plugging it all together to detect outliers\n ​\n Paper: https://arxiv.org/abs/2202.01197\n Code: https://github.com/deeplearning-wisc/vos\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdgknh/d_video_paper_explanation_vos_learning_what_you/",
          "publishedOn": "2022-03-13T21:08:12.000Z",
          "wordCount": 289,
          "title": "[D] Video Paper Explanation - VOS: Learning What You Don't Know by Virtual Outlier Synthesis (Full Walkthrough)",
          "imageUrl": "https://external-preview.redd.it/T65EHJ3aufCdew8ZJ_1mLAvzyisfqNnqRTBR23wf4pA.jpg?auto=webp&s=33dabb5285c76e3021609d3b21618f330ab82b6c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdf2gt/d_machine_learning_wayr_what_are_you_reading_week/",
          "author": null,
          "description": "This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.\n Please try to provide some insight from your understanding and please don't post things which are present in wiki.\n Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.\n Previous weeks :\n  \n 1-10 11-20 21-30 31-40 41-50 51-60 61-70 71-80 81-90 91-100 101-110 111-120 121-130 131-140 \n  \n Week 1 Week 11 Week 21 Week 31 Week 41 Week 51 Week 61 Week 71 Week 81 Week 91 Week 101 Week 111 Week 121 Week 131 \n  Week 2 Week 12 Week 22 Week 32 Week 42 Week 52 Week 62 Week 72 Week 82 Week 92 Week 102 Week 112 Week 122 Week 132 \n  Week 3 Week 13 Week 23 Week 33 Week 43 Week 53 Week 63 Week 73 Week 83 Week 93 Week 103 Week 113 Week 123  \n  Week 4 Week 14 Week 24 Week 34 Week 44 Week 54 Week 64 Week 74 Week 84 Week 94 Week 104 Week 114 Week 124  \n  Week 5 Week 15 Week 25 Week 35 Week 45 Week 55 Week 65 Week 75 Week 85 Week 95 Week 105 Week 115 Week 125  \n  Week 6 Week 16 Week 26 Week 36 Week 46 Week 56 Week 66 Week 76 Week 86 Week 96 Week 106 Week 116 Week 126  \n  Week 7 Week 17 Week 27 Week 37 Week 47 Week 57 Week 67 Week 77 Week 87 Week 97 Week 107 Week 117 Week 127  \n  Week 8 Week 18 Week 28 Week 38 Week 48 Week 58 Week 68 Week 78 Week 88 Week 98 Week 108 Week 118 Week 128  \n  Week 9 Week 19 Week 29 Week 39 Week 49 Week 59 Week 69 Week 79 Week 89 Week 99 Week 109 Week 119 Week 129  \n  Week 10 Week 20 Week 30 Week 40 Week 50 Week 60 Week 70 Week 80 Week 90 Week 100 Week 110 Week 120 Week 130  \n \n Most upvoted papers two weeks ago:\n /u/CatalyzeX_code_bot: Paper link\n Besides that, there are no rules, have fun.\n    submitted by    /u/ML_WAYR_bot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdf2gt/d_machine_learning_wayr_what_are_you_reading_week/",
          "publishedOn": "2022-03-13T20:00:05.000Z",
          "wordCount": 365,
          "title": "[D] Machine Learning - WAYR (What Are You Reading) - Week 133",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdecim/p_birdseye_views_of_conference_proceedings/",
          "author": null,
          "description": "In December, I shared a link to a project I created to get a quick overview of top NeurIPS 2021 papers. The website ordered all accepted papers by average review score and showed an 8-page overview thumbnail for each paper in addition to abstract, link to code, and other meta-data available from OpenReview.\n I recently wanted to have the same overview for ICLR 2022. I processed the papers and uploaded the overview to https://www.confviews.com/iclr2022/.\n https://preview.redd.it/jz4usfk2e7n81.png?width=1004&format=png&auto=webp&s=b7493d4d338934f1346589a1596a960c569064d9\n I am now using a python client for the OpenReview API, and it's easy to add other conferences from OpenReview. I plan to keep the site updated with the next iterations of NeurIPS and ICLR. Let me know if there are other conferences you would like to have overviews for.\n Website: https://www.confviews.com\n Code: https://github.com/tanelp/confviews\n    submitted by    /u/tanelai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdecim/p_birdseye_views_of_conference_proceedings/",
          "publishedOn": "2022-03-13T19:26:49.000Z",
          "wordCount": 215,
          "title": "[P] Bird's-eye views of conference proceedings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdebub/d_gpu_requirements_for_implicit_neural/",
          "author": null,
          "description": "Just wanted to ask anyone with experience working in the field of implicit neural represenations regarding the compute requirements you've experienced when developing models. Mainly looking in the domain of neural radiance fields (https://www.matthewtancik.com/nerf). I do have cluster access for evaluating projects that are more mature in the development pipeline, but wanted to gauge if anyone had any advice regarding what has worked when still in earlier development mainly when working on my standalone PC. \n Thanks so much for any help!\n    submitted by    /u/Ungreon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdebub/d_gpu_requirements_for_implicit_neural/",
          "publishedOn": "2022-03-13T19:25:57.000Z",
          "wordCount": 186,
          "title": "[D] GPU requirements for implicit neural representations & neural radiance fields",
          "imageUrl": "https://external-preview.redd.it/LoQ4hOMVvannlaNMA7_o5gACotOS7OQkubDc8isNTdM.jpg?auto=webp&s=7bf9008d95ee13b2a9f05abd93969f96a3293a9d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdde9g/d_how_to_keep_up_with_ml_research/",
          "author": null,
          "description": "I heard people read research papers for it, but there are SO MANY of it in the wild! Where do I get started?!?\n P.S. I'm passionate about Time series and Computer Vision.. so it would be great if you can suggest some good research papers to get started.! thanks in advance!!\n    submitted by    /u/ashwin142k  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdde9g/d_how_to_keep_up_with_ml_research/",
          "publishedOn": "2022-03-13T18:42:38.000Z",
          "wordCount": 281,
          "title": "[D] How to keep up with ML research??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdd889/news_analysis_of_83_ml_competitions_in_2021/",
          "author": null,
          "description": "I run mlcontests.com, and we aggregate ML competitions across Kaggle and other platforms.\n We've just finished our analysis of 83 competitions in 2021, and what winners did.\n Some highlights:\n  \nKaggle still dominant with a third of all competitions and half of $2.7m total prize money\n 67 of the competitions took place on the top 5 platforms (Kaggle, AIcrowd, Tianchi, DrivenData, and Zindi), but there were 8 competitions which took place on platforms which only ran one competition last year.\n Almost all winners used Python - 1 used C++!\n 77% of Deep Learning solutions used PyTorch (up from 72% last year)\n All winning computer vision solutions we found used CNNs\n All winning NLP solutions we found used Transformers\n  \nMore details here: https://blog.mlcontests.com/p/winning-at-competitive-ml-in-2022?\n And if you have a second to help me out, I'd love a like/retweet: https://twitter.com/ml_contests/status/1503068888447262721\n [Update, since people seem quite interested in this]: there's loads more analysis I'd love to do on this data, but I'm just funding this out of my own pocket right now as I find it interesting and I'm using it to promote my (also free) website. If anyone has any suggestions for ways to fund this, I'll try to do something more in-depth next year. I'd love to see for example:\n  \nHow big a difference was there between #1 and #2 solutions? Can we attribute the 'edge' of the winner to anything in particular in a meaningful way? (data augmentation, feature selection, model architecture, compute power, ...)\n How representative is the public leaderboard? How much do people tend to overfit to the public subset of the test set? Are there particular techniques that work well to avoid this?\n Who are the top teams in the industry?\n Which competitions give the best \"return on effort\"? (i.e. least competition for a given size prize pool)\n Which particular techniques work well for particular types of competitions?\n  \nVery open to suggestions too :)\n    submitted by    /u/hcarlens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdd889/news_analysis_of_83_ml_competitions_in_2021/",
          "publishedOn": "2022-03-13T18:34:45.000Z",
          "wordCount": 573,
          "title": "[News] Analysis of 83 ML competitions in 2021",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdb7f5/d_any_loss_for_discrete_set_prediction/",
          "author": null,
          "description": "Dear community,\n I am working on a problem where I have to predict sets of discrete labels, for example [A, T, D, C]. By definition, I am not interested in the order of these labels so the output can also be [A, D, C, T]. I know that using a cross-entropy between the predicted and ground truth sequence would be wrong, as the cross-entropy cares about the order of the labels. Thus, I'd be interested in applying some losses such as the Hungarian loss:\n https://preview.redd.it/pbksm28km6n81.png?width=1546&format=png&auto=webp&s=cc05cbaad8b432ec6097b5a96a75d834d22fb662\n (From this paper)\n However, all the definitions I find are about continuous variables. Is there a loss, such as the Hungarian one (i.e. that is not order dependent), for discrete labels?\n Thank you\n    submitted by    /u/marcodena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdb7f5/d_any_loss_for_discrete_set_prediction/",
          "publishedOn": "2022-03-13T17:00:52.000Z",
          "wordCount": 368,
          "title": "[D] Any loss for (discrete) set prediction?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tdamfq/p_kubis_an_easy_way_to_run_notebooks_on_aws/",
          "author": null,
          "description": "Hi everyone, \n I would like to share a tool called Kubis that we built to run ML notebooks on AWS with zero experience in AWS services and no configuration required.\n If this is helpful to you, please check us out at kubis.ai\n Kubis got started because we were working on a research project and found ourselves in a position where our local computers were too limited. At the same time getting started with AWS felt complex as we weren’t software engineers. In our case it made more sense to use cloud and we built a notebook that works like Colab but lets us scale quickly to larger machines on AWS.\n Posting it here to see if the community finds it useful. Critique is welcomed :) \n Thanks\n    submitted by    /u/Academic_Arrak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tdamfq/p_kubis_an_easy_way_to_run_notebooks_on_aws/",
          "publishedOn": "2022-03-13T16:34:08.000Z",
          "wordCount": 305,
          "title": "[P] Kubis - An easy way to run notebooks on AWS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/td8oer/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/td8oer/d_simple_questions_thread/",
          "publishedOn": "2022-03-13T15:00:09.000Z",
          "wordCount": 317,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/td7887/d_icml_2022_phase1_results_are_out/",
          "author": null,
          "description": "The ICML 2022 phase-1 results are out today. How does everyone feel about the quality of the received reviews and the phase-1 decisions?\n    submitted by    /u/Right_Presentation_3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/td7887/d_icml_2022_phase1_results_are_out/",
          "publishedOn": "2022-03-13T13:45:12.000Z",
          "wordCount": 552,
          "title": "[D] ICML 2022 Phase-1 Results Are Out",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/td6mk0/r_forecasting_theory_and_practice/",
          "author": null,
          "description": "Link: https://arxiv.org/abs/2012.03854\n Abstract: \"Forecasting has always been at the forefront of decision making and planning. The uncertainty that surrounds the future is both exciting and challenging, with individuals and organisations seeking to minimise risks and maximise utilities. The large number of forecasting applications calls for a diverse set of forecasting methods to tackle real-life challenges. This article provides a non-systematic review of the theory and the practice of forecasting. We provide an overview of a wide range of theoretical, state-of-the-art models, methods, principles, and approaches to prepare, produce, organise, and evaluate forecasts. We then demonstrate how such theoretical concepts are applied in a variety of real-life contexts.\n We do not claim that this review is an exhaustive list of methods and applications. However, we wish that our encyclopedic presentation will offer a point of reference for the rich work that has been undertaken over the last decades, with some key insights for the future of forecasting theory and practice. Given its encyclopedic nature, the intended mode of reading is non-linear. We offer cross-references to allow the readers to navigate through the various topics. We complement the theoretical concepts and applications covered by large lists of free or open-source software implementations and publicly-available databases. \"\n    submitted by    /u/bikeskata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/td6mk0/r_forecasting_theory_and_practice/",
          "publishedOn": "2022-03-13T13:11:15.000Z",
          "wordCount": 422,
          "title": "[R] Forecasting: theory and practice",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/td5l41/p_gorse_an_opensource_recommender_system_service/",
          "author": null,
          "description": "Recommender systems have been widely applied to many online services on the Internet. Although there have been lots of open source libraries, it is still hard to build a recommender system from scratch. I have maintained a project called Gorse for a long time. \n ​\n Gorse aims to be a universal open-source recommender system that can be quickly introduced into a wide variety of online services. By importing items, users, and interaction data into Gorse, the system will automatically train models to generate recommendations for each user. \n ​\n GitHub Repo: https://github.com/zhenghaoz/gorse\n https://preview.redd.it/sfjgsfmz55n81.png?width=2480&format=png&auto=webp&s=132ae61502fb9ee13e4f757078576285fc43e702\n To demonstrate the usability of the Gorse recommender system engine, I have built a live demo called GitRec, which recommends repositories to GitHub users based on starred repositories.\n ​\n Demo: https://gitrec.gorse.io/\n Source: https://github.com/zhenghaoz/gitrec\n https://preview.redd.it/wk0zjhqu55n81.png?width=1044&format=png&auto=webp&s=acde1affca91bc98755953e34986b09acd9492c9\n    submitted by    /u/zhenghaoz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/td5l41/p_gorse_an_opensource_recommender_system_service/",
          "publishedOn": "2022-03-13T12:07:07.000Z",
          "wordCount": 210,
          "title": "[P] Gorse: An open-source recommender system service",
          "imageUrl": "https://external-preview.redd.it/stLXorjOsOLKMRuzLnFWwhPbnMVW86WOiCkAcegEn9U.jpg?auto=webp&s=9572428a3615733d04066680967f9cffeb5a6fd6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/td2afp/p_looking_to_form_a_deep_learning_in_medical/",
          "author": null,
          "description": "Hello there.\n I'm not sure about the tag, but I wanted to post this here, since I think there are probably a lot of people who are working on medical imaging as of now.\n I'm planning to create a discord server about discussing machine learning in medical imaging, in which we talk about different papers, their implementations, and overall talk a lot about the possibilities and ideas.\n There are tons of great discussion about these kinds of issues on this sub, but I thought maybe a focused discussion server will prove beneficial too.\n Since I don't want to spam here and the server is not public, if anyone was interested, please dm me.\n    submitted by    /u/feryet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/td2afp/p_looking_to_form_a_deep_learning_in_medical/",
          "publishedOn": "2022-03-13T08:13:37.000Z",
          "wordCount": 224,
          "title": "[P] Looking to form a deep learning in medical imaging reading group",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/td1x2t/d_will_attention_based_architecture_transformers/",
          "author": null,
          "description": "A well popularized article in Quanta magazine ask the question « Will Transformers Take Over Artificial Intelligence? ». Since having revolutionized NLP, attention is conquering computer vision and reinforcement learning. I find pretty unfortunate that the attention mechanism was totally eclipsed by Transformers which is just a funny name (animation movie/ toy) for self-attention architecture, although the Google's paper title on Transformers was «Attention is all you need».\n    submitted by    /u/ClaudeCoulombe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/td1x2t/d_will_attention_based_architecture_transformers/",
          "publishedOn": "2022-03-13T07:47:15.000Z",
          "wordCount": 324,
          "title": "[D] Will Attention Based Architecture / Transformers Take Over Artificial Intelligence?",
          "imageUrl": "https://external-preview.redd.it/ZXTgoK0ZOgrGdyrBdtVu9phVtV8qW9bnJDfouX4c8cw.jpg?auto=webp&s=7e6dcd260bd9179e4a490dfccfab42184b90a539"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/td1e1x/n_karl_friston_theory_of_mind/",
          "author": null,
          "description": "submitted by    /u/meldiwin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/td1e1x/n_karl_friston_theory_of_mind/",
          "publishedOn": "2022-03-13T07:07:53.000Z",
          "wordCount": 556,
          "title": "[N] Karl Friston \"Theory of Mind\"",
          "imageUrl": "https://external-preview.redd.it/7gvJKo4mHzEulVlwJ53ERfdpYAUTWyewShVzsl8jn9c.png?format=pjpg&auto=webp&s=74fc768d2a868d10a40c7f517a188ea7c9764738"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/td0b88/d_how_to_stay_up_to_date_on_ml_trends_as_someone/",
          "author": null,
          "description": "I work in the computer science education space and find myself falling behind in my AI knowledge since leaving industry. I have written some ML applications in the past and took some classes for my degrees, but I find it's hard to keep up nowadays. Are there any good newsletters or accessible sites/blogs that can help me understand emerging trends and keep my knowledge up to date? I find a lot of technical articles and blogs overwhelming. Appreciate your time!\n    submitted by    /u/raw-shucked-oysters  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/td0b88/d_how_to_stay_up_to_date_on_ml_trends_as_someone/",
          "publishedOn": "2022-03-13T05:54:16.000Z",
          "wordCount": 430,
          "title": "[D] How to stay up to date on ML trends as someone with low technical knowledge?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tczj4y/ai_research_and_mathematics_d/",
          "author": null,
          "description": "(New to this so going to sound naive) I'm a senior undergrad student of Electrical Engineering. I have some level of interest in Machine Learning, my Final Year project being based upon it and all. But most of my interest was for the mathematics behind Machine Learning and AI. And most of the ML projects are just programming on keras and stuff. Like there can be maths involved here, just not the heavy kind like we learn in theory, so is there usually much research going on under AI making or refining mathematical algorithms for AI, instead of just using AI and ML for tasks, and if so what field. Also, I saw some researchers working on making more Biologically inspired Neural Networks, is it more in the AI domain, or more neuroscience domain, and if the latter, can a EE graduate enter this field? And is it maths extensive, like modelling neurons using Control theory and stuff?\n    submitted by    /u/a_khalid1999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tczj4y/ai_research_and_mathematics_d/",
          "publishedOn": "2022-03-13T05:03:51.000Z",
          "wordCount": 2309,
          "title": "AI research and Mathematics [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcuhf6/p_ai_learns_to_drive_from_scratch_in_trackmania/",
          "author": null,
          "description": "submitted by    /u/kris33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcuhf6/p_ai_learns_to_drive_from_scratch_in_trackmania/",
          "publishedOn": "2022-03-13T00:09:27.000Z",
          "wordCount": 136,
          "title": "[P] A.I. Learns to Drive From Scratch in Trackmania - Great introduction and demonstration of reinforcement learning with Deep-Q-Learning",
          "imageUrl": "https://external-preview.redd.it/Z_cOnfydZFeK6pmPlj-sn_SFuT9HaX6DSuUq8kSNWfM.jpg?auto=webp&s=5931afca3f7b8a859ad5be833c410901014e9522"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tctodb/discussion_desperately_need_advice_for_binary_svc/",
          "author": null,
          "description": "It's leading up to an important deadline for me and I really need to get these results working by the end of this week. I am an extreme novice with ML, but due to issues with my master thesis I've had to start using it to try and salvage it. \n I have my sampled dataset, I have my Matlab script all set up, and it works for example datasets etc.\n But I can't seem to get a good result from my data set and I have exhausted a lot of options over the past couple weeks. It's sort of driving me insane because I can't see why it's not working. \n To summarise, the boundary of the safe and fail classes is very oscillatory (almost sinusoidal, but only peaks and veeery thin peaks at that, and the peaks themselves fluctuate in height). I imagined it should be possible to get a good result out of this dataset as the boundary is quite well defined. I've been using a Gaussian kernel, and when I sample only a small corner of the dataset (e.g imagine only one or two of the \"peaks\" are in this sample space), it can define the boundary quite well . But once I give the entire sample space to study, it just gets muddled and either gives me a linear looking boundary or just pure garbage... Its probably important to note the dataset is also imbalanced, but I have played around with weights and down-sampling, but it hasn't really helped. \n If anyone is an expert, particularly with Matlab, and willing to have a quick conversation with me about where I might be going wrong (kernel selection, data sampling, hyper parameter optimisation method, etc) I'd greatly appreciate it!!\n I would upload an image of my dataset, but want to avoid potential issues and whatnot when I submit my thesis.\n Unfortunately I will be going to sleep soon so will check for replies in the morning, but I appreciate any input immensely.\n    submitted by    /u/KitKatMMD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tctodb/discussion_desperately_need_advice_for_binary_svc/",
          "publishedOn": "2022-03-12T23:26:47.000Z",
          "wordCount": 426,
          "title": "[Discussion] Desperately need advice for binary SVC using Matlab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tct4zn/r_a_neural_programming_language_for_the_reservoir/",
          "author": null,
          "description": "submitted by    /u/shitboots  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tct4zn/r_a_neural_programming_language_for_the_reservoir/",
          "publishedOn": "2022-03-12T22:59:14.000Z",
          "wordCount": 101,
          "title": "[R] A Neural Programming Language for the Reservoir Computer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcsudr/p_can_anyone_help_me_to_understand_how_mog_works/",
          "author": null,
          "description": "I'm just trying to understand it conceptually. It's background subtraction in a video using mixture of gaussians. So basically, we have to model each pixel in the training frames (video of a road) as a mixture of gaussians, later a car drives across and we have to just get that foreground image out of it.\n I don't understand what the \"distribution of each pixel\" means. So if i take the (50,50) pixel out of the first 100 frames of the video (it's gray scale), I could get a histogram out of those 100 gray scale values, is that what I'm trying to model? Like model the histogram as N gaussian distributions, like N different clumps of 0-255 values as gaussian distributions to represent that pixel? Or am i completely off.\n If anyone can help explain in simple terms, I'm not worried about the implementation itself more just what the gaussian distributions represents. Like if I was just doing K-means (hard assignments), what would each \"cluster\" be in this case?\n    submitted by    /u/jac-128514  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcsudr/p_can_anyone_help_me_to_understand_how_mog_works/",
          "publishedOn": "2022-03-12T22:44:20.000Z",
          "wordCount": 282,
          "title": "[P] Can anyone help me to understand how MoG works for background video subtraction?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcspsj/d_are_memristors_andor_analogue_circuits_helping/",
          "author": null,
          "description": "There was a big thing a few years ago on how Memristors were going to change computing and their impact in ML could be huge, are they having an impact and if so how big?\n It sounds like analogue circuits driven chips could be the next big wave in AI how do they compare to high end GPUs?\n    submitted by    /u/Arowx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcspsj/d_are_memristors_andor_analogue_circuits_helping/",
          "publishedOn": "2022-03-12T22:38:02.000Z",
          "wordCount": 263,
          "title": "[D] Are memristors and/or analogue circuits helping to improve ML/AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcp8ya/r_model_soups_averaging_weights_of_multiple/",
          "author": null,
          "description": "submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcp8ya/r_model_soups_averaging_weights_of_multiple/",
          "publishedOn": "2022-03-12T19:46:59.000Z",
          "wordCount": 129,
          "title": "[R] Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcott9/d_is_it_possible_for_us_to_make_fixedsize/",
          "author": null,
          "description": "I recently had a long conversation with Tim Scarfe and Keith Duggar on Machine Learning Street Talk (MLST) about theory related to neural networks. I really believe we can make better machine learning algorithms and better guarantees if we uncover the right theoretical track. I would really appreciate hearing from you all in the community about this work, so I've written up this post to accompany the MLST video. Enjoy!\n See the full interactive version of this post on my research page here.\n Get the code for these experiments here.\n Data Distributions and Initializing Neural Networks\n Is it possible for us to make fixed-size multilayer perceptrons (MLP's) provably converge? It's been bothering me that initialization seems arbitrary and all the optimization algorithms produce different resu…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcott9/d_is_it_possible_for_us_to_make_fixedsize/",
          "publishedOn": "2022-03-12T19:27:47.000Z",
          "wordCount": 1130,
          "title": "[D] Is it possible for us to make fixed-size multilayer perceptrons (MLP's) provably converge?",
          "imageUrl": "https://external-preview.redd.it/zP3Y5zm-WbJGQKNpHI2T6Jmk-QNvSdnH49o8yu9l9tw.jpg?auto=webp&s=33078486d3f4b3931b8b4a27570026ba5c1be662"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcmv5f/p_generating_video_from_compresseddata_lost_input/",
          "author": null,
          "description": "Hello dear r/MachineLearning fellows, \n I have an idea which has a following requirement. With given video (mp4 for being simple, twitch clips of gamers for example) I want to generate a compressed (lossy or lossless), downscaled and/or data lost (corrupt) version (or various combinations of above methods) \n Using this low sized video and combination of upscaling/synthetic replacement (for lossy compression and corruption) I want to generate a video close to the original. The \"closeness\" is not visual but bit/byte closeness. So my aim is to generate a video with lowest bits of differance (diff of bytes) \n Most papers on this topic are about generating visually compelling outputs. So I would like to ask how to approach testing for which methods and combination percentages (like %20 downscale %10 compress) would be more beneficial to generate low diff (on byte level) with least data on input video. \n Also I have a small dataset of 100 videos and I am afraid of overfitting the result, so testing for generalization would be a requirement aswell.\n    submitted by    /u/oDeathwingo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcmv5f/p_generating_video_from_compresseddata_lost_input/",
          "publishedOn": "2022-03-12T17:52:52.000Z",
          "wordCount": 415,
          "title": "[P] Generating video from compressed/data lost input with lowest differance from the original",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcj9l6/p_timeseries_benchmark_methods_that_are_simple/",
          "author": null,
          "description": "Naive/Benchmark time series methods have many uses business applications. \n tablespoon makes generating these naive methods easy while taking advantage of Stan's efficient No U-Turn Sampler - much the same way Facebook Prophet it built on top of Stan.\n 😻 Github 😻\n 🥄 Project Site 🥄\n ⭐Please star if you like the project.⭐\n    submitted by    /u/Legitimate-Stay-5131  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcj9l6/p_timeseries_benchmark_methods_that_are_simple/",
          "publishedOn": "2022-03-12T15:55:18.000Z",
          "wordCount": 192,
          "title": "[P] Time-series Benchmark methods that are Simple and Probabilistic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcfegw/n_imagenet_how_a_uk_tv_cook_ended_up_as_slut_in/",
          "author": null,
          "description": "submitted by    /u/filt_er  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcfegw/n_imagenet_how_a_uk_tv_cook_ended_up_as_slut_in/",
          "publishedOn": "2022-03-12T12:28:16.000Z",
          "wordCount": 797,
          "title": "[N] ImageNet: How a UK TV Cook ended up as 'slut' in an influential image database - Johannes Filter",
          "imageUrl": "https://external-preview.redd.it/Ierja5pBB6u-ftRuVBDoU_wk4r1nVqg99eMfU067364.jpg?auto=webp&s=6110007884b81c5a9956e1cd6038f3812c24a571"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcdwoz/p_annotated_implementation_of_the/",
          "author": null,
          "description": "https://nn.labml.ai/transformers/retro/model.html\n This is an annotated (side-by-side notes) implementation of RETRO in PyTorch.\n Retrieval Enhanced Transformer (RETRO) is 25X smaller than GPT-3 but has comparable performance. It uses chunks of similar text retrieved based on a frozen BERT model from a massive database (5 trillion tokens) to improve the performance of the model. Since the model can retrieve information from this large database it doesn't have to contain all the facts in the model weights.\n    submitted by    /u/mlvpj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcdwoz/p_annotated_implementation_of_the/",
          "publishedOn": "2022-03-12T10:47:11.000Z",
          "wordCount": 166,
          "title": "[P] Annotated implementation of the Retrieval-Enhanced Transformer",
          "imageUrl": "https://external-preview.redd.it/tWUejWAHOaL3eYM8U3vI_e3Dy92-XHTOo27UUlHPpcY.jpg?auto=webp&s=acbff5a52d7b3a313f07b759e2c30b0549322dfe"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcdazd/d_open_discussion_about_facial_expressionmotion/",
          "author": null,
          "description": "it would be so great and helpful to hear some opinions from someone as a professional in this field! The questions are as follows:\n  \nWhat are the barriers of real-time facial expression tracking system based on 2D data?\n What are the advantages and disadvantages of facial expression capture based on 3D data (with depth camera or other techniques)?\n In the long term, what facial motion capture method/company do you think the most highly of and why?\n Which human body model (skeleton-based model, contour-based model, volume-based model) do you think will most probably become the mainstream model in the future?\n What do you think of the top-down approach and bottom-up approach to Human Pose Estimation? What method/approach do you think is the most suitable for facial expression capture specifically?\n  \nLet's have an open discussion guys! Please feel free to share any of your thoughts or throw more questions on facial motion capture. Thanks a lot in advance for sharing your thoughts and time! Much appreciated!\n    submitted by    /u/pawz_up  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcdazd/d_open_discussion_about_facial_expressionmotion/",
          "publishedOn": "2022-03-12T10:03:30.000Z",
          "wordCount": 369,
          "title": "[D] Open Discussion about Facial Expression/Motion Capture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcbqrv/n_google_colab_pro_and_pro_are_newly_available_in/",
          "author": null,
          "description": "The news was announced here.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcbqrv/n_google_colab_pro_and_pro_are_newly_available_in/",
          "publishedOn": "2022-03-12T08:11:50.000Z",
          "wordCount": 160,
          "title": "[N] Google Colab Pro and Pro+ are newly available in these 10 countries: Ireland, Israel, Italy, Morocco, the Netherlands, Poland, Spain, Switzerland, Turkey, and the United Arab Emirates",
          "imageUrl": "https://external-preview.redd.it/kRSWPmfrVV3bWJNZIS2o-JCAx1RpAnrY7N9RNnzL1gU.jpg?auto=webp&s=98f7271eb89bb95238d4547c44b308af98ebef33"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcb7or/p_web_app_informativedrawings_on_site_hugging/",
          "author": null,
          "description": "submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcb7or/p_web_app_informativedrawings_on_site_hugging/",
          "publishedOn": "2022-03-12T07:34:28.000Z",
          "wordCount": 447,
          "title": "[P] Web app \"informative-drawings\" on site Hugging Face quickly creates a line art drawing of an input image. Link in a comment.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tcak6n/d_whatre_some_topics_from_pure_math_that_youve/",
          "author": null,
          "description": "By “pure math”, I’m referring to the particularly esoteric concepts that someone without a math degree or someone not doing research in a math-intensive field would likely never encounter. For example, topography, abstract algebra, field theory, differential geometry, number theory, set theory, ergodic theory, and perhaps even complex analysis. \n And to what degree did you have to use them? Was it to the point where you wished you had prior exposure to the subject in a classroom setting, or was it manageable and self-learnable with relative ease?\n    submitted by    /u/mowa0199  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tcak6n/d_whatre_some_topics_from_pure_math_that_youve/",
          "publishedOn": "2022-03-12T06:47:58.000Z",
          "wordCount": 576,
          "title": "[D] What’re some topics from “pure math” that you’ve found use for in your work/research?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tc8p70/rp_investigating_tradeoffs_in_realworld_video/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tc8p70/rp_investigating_tradeoffs_in_realworld_video/",
          "publishedOn": "2022-03-12T04:47:32.000Z",
          "wordCount": 638,
          "title": "[R][P] Investigating Tradeoffs in Real-World Video Super-Resolution + Hugging Face Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/jjW8UKeSFO2LG7D3DpjA5Du0lnxCNhZFZCfN2rSKtdk.png?format=pjpg&auto=webp&s=1f7e0231c4e8ae8cb5bd732889344edb8d2994e0"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tc756g/d_p_some_ideas_and_speculations_on_the_problem_of/",
          "author": null,
          "description": "Hi folks. I'm a new DL researcher who just began working at a startup that focuses on AI-based drug discovery. I'm afraid this is not the most suitable place to post this since this is more of an engineering idea, but I wanted to hear what you guys think about it and if you have any idea.\n I don't know how many of you have encountered the same efficiency issue before, but I've repeatedly come across this theme while implementing my research ideas:\n I have a dataset that consists of datapoints with non-uniform length along some dimensions (number of atoms in a molecule, number of amino acids in a protein etc.), and I want to perform numerical calculations (e.g. feed into a DL model) on a tensorized-batched form of them. The batching (turning them into a single tensor) would be an indispensi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tc756g/d_p_some_ideas_and_speculations_on_the_problem_of/",
          "publishedOn": "2022-03-12T03:13:21.000Z",
          "wordCount": 1249,
          "title": "[D] [P] Some ideas and speculations on the problem of efficiently processing length-irregular data",
          "imageUrl": "https://external-preview.redd.it/5On8qfVqo3WmROnDTWdKa29ZhTfY6UFqXg_-i4i125w.jpg?auto=webp&s=3addd73ccdf2802d8d6fc5dcb9a7d01410ccb27a"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tc6t7p/d_wherewhen_is_emnlp_2022/",
          "author": null,
          "description": "I see other conferences like ACL, NAACL, and COLING in this list, but EMNLP is in TBA. I don't see when the submission deadline for that conference is at? Also I see EMNLP workshops being announced, but I still don't see when is the main conference. If anyone has any idea if EMNLP conference got cancelled or when is it happening, I would appreciate it.\n    submitted by    /u/SiegeMemeLord  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tc6t7p/d_wherewhen_is_emnlp_2022/",
          "publishedOn": "2022-03-12T02:54:03.000Z",
          "wordCount": 217,
          "title": "[D] Where/when is EMNLP 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tc3dt2/d_how_to_extract_specific_words_from_text/",
          "author": null,
          "description": "Is there any pretrained model that can say pull out a sport from a string such as the string \"I want to go play soccer\" and have it get soccer? Obviously I could do this without a model but I want it to be able to work for other things as well. Thank you!\n    submitted by    /u/Mesablip  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tc3dt2/d_how_to_extract_specific_words_from_text/",
          "publishedOn": "2022-03-11T23:43:39.000Z",
          "wordCount": 151,
          "title": "[D] How to extract specific words from text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tc38nq/d_what_is_the_most_useful_ml_application_for/",
          "author": null,
          "description": "what is the most useful ML application for geospatial industry?\n    submitted by    /u/SamanthaLong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tc38nq/d_what_is_the_most_useful_ml_application_for/",
          "publishedOn": "2022-03-11T23:36:03.000Z",
          "wordCount": 116,
          "title": "[D] what is the most useful ML application for geospatial industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tc31la/d_model_that_can_parse_data_the_same_way_training/",
          "author": null,
          "description": "Hi everyone. I'm looking for either a pretrained model or some kind of architecture that can parse a tweet based on how the training data looks. For example, if the training data includes a tweet from an esports team saying: \"Team A beats Team B 4 - 0 in the Overwatch finals\" and has columns for team 1 name, team 2 name, score, game name, etc. (all pulled from the tweet), how can I train a model to parse up the tweet into these columns for me? Thank you!\n    submitted by    /u/Mesablip  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tc31la/d_model_that_can_parse_data_the_same_way_training/",
          "publishedOn": "2022-03-11T23:25:46.000Z",
          "wordCount": 198,
          "title": "[D] Model that can parse data the same way training data has",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tc2ewc/p_multilabel_classifier_substantially/",
          "author": null,
          "description": "Hi, \n I originally trained multiple individual binary classifiers for each label of an image. Then, I realized I can train a single multilabel model for this task. I used binary_cross_entropy loss for this instead of categorical_cross_entropy, but besides for changing the loss function I made no major changes. However, I find that the multilabel classifier still substantially underperforms the individual label classifiers. Is this common and to be expected? Are there any tricks I am missing?\n Thanks!\n    submitted by    /u/rsandler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tc2ewc/p_multilabel_classifier_substantially/",
          "publishedOn": "2022-03-11T22:54:22.000Z",
          "wordCount": 202,
          "title": "[P] Multilabel classifier substantially underperforms individual binary classifiers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tc275w/d_can_neural_networks_be_viewed_as_dynamical/",
          "author": null,
          "description": "Can one compare neural networks and dynamical systems? If so, is such comparison useful?\n For instance, can something like a space defined by activations/values of every single parameter in a NN be thought of as the phase space?\n Is there any interesting literature exploring that idea?\n    submitted by    /u/sarfins  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tc275w/d_can_neural_networks_be_viewed_as_dynamical/",
          "publishedOn": "2022-03-11T22:44:05.000Z",
          "wordCount": 240,
          "title": "[D] Can neural networks be viewed as dynamical systems?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tc0wc3/d_machine_learning_biggest_unsolved_problems/",
          "author": null,
          "description": "What are the biggest unsolved theoretical and applied problems in machine learning and, particularly, in deep learning?\n    submitted by    /u/SamanthaLong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tc0wc3/d_machine_learning_biggest_unsolved_problems/",
          "publishedOn": "2022-03-11T21:42:48.000Z",
          "wordCount": 210,
          "title": "[D] Machine Learning biggest unsolved problems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tc0nqv/n_advanced_machine_learning_and_deep_learning/",
          "author": null,
          "description": "Dears.\n I have more than 5 years experience in machine learning and deep learning and recently have created a Youtube channel. https://www.youtube.com/channel/UCn9Rujwh7SfHF2RRvy_ks-g In the channel, I first explain a paper, then I implement/explain the code .\n Please join, leave a comment, and share with your friends. You can also suggest any paper and I will add it to my list.\n I am constantly trying to improve contents and quality.\n Thanks.\n    submitted by    /u/MRMohebian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tc0nqv/n_advanced_machine_learning_and_deep_learning/",
          "publishedOn": "2022-03-11T21:31:29.000Z",
          "wordCount": 163,
          "title": "[N] Advanced machine learning and deep learning tutorial",
          "imageUrl": "https://external-preview.redd.it/Du9l9mny9aXvtrtMfF-6h_nIMpY4cE5bGF_Tm-t_MUc.jpg?auto=webp&s=26a5da9b8b611a9008a910fcdffa790c654144a0"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tbze2m/why_not_use_alternating_minimization_for_training/",
          "author": null,
          "description": "Neural networks are usually trained by calculating gradients using backprop and then performing gradient descent. I am not sure what are difficulties in training a neural network using alternating minimization? \n It seems that the main idea in neural networks is that there are many parameters, and updates can be performed in parallel, thus speeding up the process. In this process, we lose the theoretical guarantees of alternating minimization, but we gain on speed. Is that right? What is the difference from a theoretical and optimization point of view of updating everything at once and serially?\n Alternating minimization- In this optimization strategy, the idea is to fix everything except one variable and perform gradient descent for it, and do this procedure alternatively for all variables till some convergence criteria is met. Reference: https://www.mit.edu/~rakhlin/6.883/lectures/lecture07.pdf\n Also, what is the order of computing gradient using backprop vs. naive gradient computation in neural networks?\n    submitted by    /u/dushyantsahoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tbze2m/why_not_use_alternating_minimization_for_training/",
          "publishedOn": "2022-03-11T20:32:13.000Z",
          "wordCount": 342,
          "title": "Why not use alternating minimization for training neural networks? [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tbyiwh/n_pytorch_111_released_with_tfdata_and_jax/",
          "author": null,
          "description": "https://pytorch.org/blog/pytorch-1.11-released/\n As a longtime TensorFlow user I've been meaning to switch to either JAX or PyTorch, thus I'm pretty intrigued by this.\n In the past I've been having a hard time giving up tf.data's pretty elegant fluent interface for performant I/O and data preprocessing. Has anyone tried the new PyTorch equivalent? How does TorchData stack up?\n And are there more things in JAX that functorch cannot express or will both autograd engines hit feature parity now-ish?\n    submitted by    /u/carlthome  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tbyiwh/n_pytorch_111_released_with_tfdata_and_jax/",
          "publishedOn": "2022-03-11T19:52:04.000Z",
          "wordCount": 420,
          "title": "[N] PyTorch 1.11 released with tf.data and JAX inspired libraries TorchData and functorch",
          "imageUrl": "https://external-preview.redd.it/TxplUbEUiAAyEiV_jYVGq99XbMdew5B9U7Z1cbxfXtg.jpg?auto=webp&s=0c2b7a584ad0c6a41bd1684f5b0bfd6ddbf84ad9"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tbwzny/d_do_gans_learn_manifolds/",
          "author": null,
          "description": "Hello, I'm getting started with some literature on GANs and I'm wondering what kind of latent structure do they learn. For example how does the latent space differ from that of VAEs or MAEs? (masked auto encoders)\n Do they learn manifolds? What's the difference? \n Also in the context of styleGAN.\n    submitted by    /u/jim_from_truckistan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tbwzny/d_do_gans_learn_manifolds/",
          "publishedOn": "2022-03-11T18:40:08.000Z",
          "wordCount": 276,
          "title": "[D] Do GANs learn manifolds?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tbwyjs/d_icml_2022_notification_of_phase_1_rejection/",
          "author": null,
          "description": "Today is supposed to be phase 1 rejection notification. For papers that will move to phase 2, will there be a notification, or should we just pray that we do not receive an email from CMT? Thanks.\n    submitted by    /u/fixed-point-learning  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tbwyjs/d_icml_2022_notification_of_phase_1_rejection/",
          "publishedOn": "2022-03-11T18:38:35.000Z",
          "wordCount": 364,
          "title": "[D] ICML 2022 notification of phase 1 rejection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tbuwhb/n_article_series_deployment_of_deep_learning/",
          "author": null,
          "description": "​\n https://preview.redd.it/4icndo16fsm81.png?width=2036&format=png&auto=webp&s=486a5d676222a279ed45b45ec187028b21dcabcc\n We are proud to introduce our new article series that will guide you on how to run state of the art deep learning models on Genesis Cloud infrastructure. These articles will be initially published as blog posts and will be added to our knowledge base after their release. Please note: The order of the articles is important as articles are written as a series and information contained in the initial articles might be required for understanding the subsequent articles.\n In this series of articles we will use 1x RTX 3080 instance type on Genesis Cloud (our recommended GPU for inference use) and showcase four (4) different deployment strategies for deep learning inference usi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tbuwhb/n_article_series_deployment_of_deep_learning/",
          "publishedOn": "2022-03-11T17:15:49.000Z",
          "wordCount": 552,
          "title": "[N] Article series: Deployment of Deep Learning models on Genesis Cloud - Tutorials & Benchmarks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tbtqd4/d_dataset_normalization_using_shrinkandperturb/",
          "author": null,
          "description": "I have trained a large deep learning model on Dataset A. It works well on data similar to dataset A, but doesn't generalize that well as real world problems are more complex and varied than Dataset A.\n Since training, I have compiled a new dataset, Dataset B, that has significantly more data and a more realistic data distribution.\n I would like to re-train the model using Dataset B. My understanding is warm-starting the model can hurt generalization, but since the model is large, I would like to avoid starting training from scratch. For this reason, I am thinking of doing a warm-start using \"Shrink and Perturb\".\n overview: https://jamesmccaffrey.wordpress.com/2020/12/14/neural-network-warm-start-shrink-and-perturb/\n paper: https://arxiv.org/pdf/1910.08475.pdf\n Dataset A's features have been normalized using the mean and variance of the features calculated on the dataset.\n To get the best results, should I normalize Dataset B using the same statistics (mean and variance calculated from Dataset A) or normalize using new statistics calculated from Dataset B.\n My assumption is that the best results will be obtained by training from scratch using Dataset B normalized using statistics from Dataset B, but since I may have to do this process many times, being able to warm-start and use the Shrink and Perturb method is preferred - I'm just not sure whether I should be maintaining the normalization statistics from the initial dataset for all dataset normalization, or re-calculate the statistics for each new Dataset. My assumption is that the same normalization statistics should be used, but will this hurt the generalization of the model in any way?\n Any thoughts? Thanks!\n    submitted by    /u/csmrh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tbtqd4/d_dataset_normalization_using_shrinkandperturb/",
          "publishedOn": "2022-03-11T16:22:52.000Z",
          "wordCount": 351,
          "title": "[D] Dataset Normalization using Shrink-and-Perturb Warm Start",
          "imageUrl": "https://external-preview.redd.it/jcf9l-0Ovo5wpz2mlO7kBe38jPuAmB7ZH1445S_Wt8w.jpg?auto=webp&s=eb0b1f4f2f00b1cbf61232b77ca0954480300764"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tbsldk/d_does_the_rtx_3060_work_reasonably_well_for_deep/",
          "author": null,
          "description": "Yes, it's a low end chip, but the 12GB make it quite attractive. It might not run fast, but it'll be able to run things that won't run on the 8GB cards, so if the 10/12GB cards are out of my budget, it seems like an option worth considering.\n However, when it came out, people complained about poor cuda support - was that just close to release and has since been fixed?\n Another issue besides the low end chip is the low bandwidth of the memory.\n Does anyone have any experience with it or any cuda/DL benchmarks they can share? Thanks!\n    submitted by    /u/AuspiciousApple  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tbsldk/d_does_the_rtx_3060_work_reasonably_well_for_deep/",
          "publishedOn": "2022-03-11T15:30:10.000Z",
          "wordCount": 924,
          "title": "[D] Does the RTX 3060 work reasonably well for deep learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tbrk7z/r_snorkel_weak_labeling_for_ner_when_a_token_does/",
          "author": null,
          "description": "I have a program that labels a sequence of words using ontologies. I have labeling functions for class negative, class positive, and class abstain. Should I keep the word unlabeled if it does not fall under any of these class labels and ignore it or should I force-label them under either class negative or abstain? I will be grateful for any hints or help.\n    submitted by    /u/freaky_eater  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tbrk7z/r_snorkel_weak_labeling_for_ner_when_a_token_does/",
          "publishedOn": "2022-03-11T14:41:00.000Z",
          "wordCount": 203,
          "title": "[R] Snorkel weak labeling for NER. When a token does not fall under any of the class labels or abstains in NER?",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": [
        {
          "id": "https://mlinproduction.com/?p=936",
          "author": "Luigi",
          "description": "In my previous post, I briefly described how leading companies use experimentation to optimize their products and services and evolve them to the point of feeling elegant, efficient, and magical. These companies have developed mature experimentation programs (ExPrs), including the… Read More \nThe post What is an Experimentation program and Who is Involved? (Experimentation Program Series: Guide 02) appeared first on ML in Production.",
          "link": "https://mlinproduction.com/experimentation-program-stakeholders/?utm_source=rss&utm_medium=rss&utm_campaign=experimentation-program-stakeholders",
          "publishedOn": "2022-04-02T14:03:58.000Z",
          "wordCount": 1691,
          "title": "What is an Experimentation program and Who is Involved? (Experimentation Program Series: Guide 02)",
          "imageUrl": null
        },
        {
          "id": "https://mlinproduction.com/?p=926",
          "author": "Luigi",
          "description": "Seamless. Frictionless. Elegant. Efficient.\nRead More \nThe post Building An Effective Experimentation Program – 01 Introduction appeared first on ML in Production.",
          "link": "https://mlinproduction.com/experimentation-program-introduction/?utm_source=rss&utm_medium=rss&utm_campaign=experimentation-program-introduction",
          "publishedOn": "2022-03-20T14:48:21.000Z",
          "wordCount": 1134,
          "title": "Building An Effective Experimentation Program – 01 Introduction",
          "imageUrl": "https://mlinproduction.com/wp-content/uploads/2022/03/experimentation-beakers.jpeg"
        }
      ]
    },
    {
      "title": "Jay Alammar",
      "feedUrl": "https://jalammar.github.io/feed.xml",
      "siteUrl": "http://jalammar.github.io/",
      "articles": []
    },
    {
      "title": "Distill",
      "feedUrl": "https://distill.pub/rss.xml",
      "siteUrl": "https://distill.pub",
      "articles": []
    },
    {
      "title": "inFERENCe",
      "feedUrl": "https://www.inference.vc/rss",
      "siteUrl": "https://www.inference.vc/",
      "articles": []
    },
    {
      "title": "AI Trends",
      "feedUrl": "https://www.aitrends.com/feed",
      "siteUrl": "https://www.aitrends.com",
      "articles": []
    },
    {
      "title": "AI Weirdness",
      "feedUrl": "https://aiweirdness.com/rss",
      "siteUrl": "https://www.aiweirdness.com/",
      "articles": [
        {
          "id": "6243c01422e1bd003d3ef57f",
          "author": "Janelle Shane",
          "description": "I've tried various methods of using AI to generate April Fools pranks for you to play on other people (although often they turned out to be pranks you play on yourself). But this is the first time I've tried to generate pranks for a computer to",
          "link": "https://www.aiweirdness.com/ai-generated-pranks-for-your-computer-to-play/",
          "publishedOn": "2022-04-01T04:19:29.000Z",
          "wordCount": 1241,
          "title": "AI-generated pranks for your computer to play on you",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/03/pranked-desktop.png"
        },
        {
          "id": "624522d522e1bd003d3ef656",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-adas-pranks/",
          "publishedOn": "2022-04-01T04:19:08.000Z",
          "wordCount": 411,
          "title": "Bonus: Ada's pranks",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/03/Screen-Shot-2022-03-30-at-9.51.32-PM.png"
        },
        {
          "id": "622e6d2b6bc9aa003d5451fe",
          "author": "Janelle Shane",
          "description": "AI isn't known for being able to solve the big problems, but what about the VERY large problems, such as possible futures to strive for? I decided to find out if I could get GPT-3 to come up with new ideas for utopias.\nSince GPT-3 works by predicting",
          "link": "https://www.aiweirdness.com/ai-generated-utopias/",
          "publishedOn": "2022-03-18T14:43:29.000Z",
          "wordCount": 919,
          "title": "AI-generated utopias",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/03/Davinci-magical-utopia-01.png"
        },
        {
          "id": "622e84ba6bc9aa003d54527d",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-utopias-that-make-no-sense/",
          "publishedOn": "2022-03-18T14:43:14.000Z",
          "wordCount": 428,
          "title": "Bonus: Utopias that make no sense",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/03/Curie-robot-banana-peel-utopia-01.png"
        }
      ]
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed.xml",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": [
        {
          "id": "http://bair.berkeley.edu/blog/2022/03/21/ukraine-sar-maers/",
          "author": null,
          "description": "Figure 1: Airmass measurements over Ukraine from February 18, 2022 - March 01, 2022 from the SEVIRI instrument. Data accessed via the EUMETSAT Viewer.\n\n\nSatellite imagery is a critical source of information during the current invasion of Ukraine. Military strategists, journalists, and researchers use this imagery to make decisions, unveil violations of international agreements, and inform the public of the stark realities of war. With Ukraine experiencing a large amount of cloud cover and attacks often occuring during night-time, many forms of satellite imagery are hindered from seeing the ground. Synthetic aperture radar imagery penetrates cloud cover, but requires special training to interpret. Automating this tedious task would enable real-time insights, but current computer vision meth…",
          "link": "http://bair.berkeley.edu/blog/2022/03/21/ukraine-sar-maers/",
          "publishedOn": "2022-03-21T12:00:00.000Z",
          "wordCount": 3398,
          "title": "Accelerating Ukraine Intelligence Analysis with Computer Vision on Synthetic Aperture Radar Imagery",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/maers/maers.png"
        }
      ]
    },
    {
      "title": "Becoming Human: Artificial Intelligence Magazine - Medium",
      "feedUrl": "https://becominghuman.ai/feed",
      "siteUrl": "https://becominghuman.ai?source=rss----5e5bef33608a---4",
      "articles": [
        {
          "id": "https://medium.com/p/c1b6ede3c737",
          "author": "A. Noah",
          "description": "The use of AI to write creative stories is increasing in popularity.",
          "link": "https://becominghuman.ai/how-to-use-ai-to-write-creative-stories-in-seconds-case-study-c1b6ede3c737?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-03-23T13:14:27.000Z",
          "wordCount": 910,
          "title": "How to Use AI to Write Creative Stories in Seconds (Case Study)",
          "imageUrl": "https://miro.medium.com/max/1200/1*giLIURaet54xMoicGk7wlQ.jpeg"
        },
        {
          "id": "https://medium.com/p/f8ca23426478",
          "author": "Aviral Bhardwaj",
          "description": "Using the Artificial Neural Network (ANN) to make a churn model, we will create a model that predicts a handwritten digit. (with source…",
          "link": "https://becominghuman.ai/digit-recogniser-artificial-neural-network-ann-f8ca23426478?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-03-22T13:14:02.000Z",
          "wordCount": 843,
          "title": "Digit recogniser — Artificial Neural Network (ANN)",
          "imageUrl": "https://miro.medium.com/max/600/0*v-pw3r0oixadIh-2.jpg"
        },
        {
          "id": "https://medium.com/p/d968ded84500",
          "author": "A Smith",
          "description": "The field of Artificial Intelligence (AI) continues to expand and improve by leaps and bounds. Today’s AI applications are becoming smarter…",
          "link": "https://becominghuman.ai/artificial-intelligence-applications-for-2022-d968ded84500?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-03-21T13:03:44.000Z",
          "wordCount": 868,
          "title": "Artificial Intelligence Applications for 2022",
          "imageUrl": "https://miro.medium.com/max/1091/1*Sjeq1hDQmRNgyK9dcB3xFg.png"
        },
        {
          "id": "https://medium.com/p/f2cfb4060e9c",
          "author": "m0nads",
          "description": "Examining a module consisting of several attention layers running in parallel.",
          "link": "https://becominghuman.ai/multi-head-attention-f2cfb4060e9c?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-03-18T13:04:06.000Z",
          "wordCount": 1158,
          "title": "Multi-Head Attention",
          "imageUrl": "https://miro.medium.com/max/800/1*8R1rrawIaP88RcYLk7AWRw.jpeg"
        },
        {
          "id": "https://medium.com/p/9f967f1c5da7",
          "author": "javinpaul",
          "description": "These are my favorite free Datacamp courses to learn in-demand data skills like Python, SQL, Power BI, Tableau, Seaborn, Matplotlib, Data…",
          "link": "https://becominghuman.ai/7-best-free-datacamp-course-to-become-a-data-scientist-9f967f1c5da7?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-03-17T13:59:39.000Z",
          "wordCount": 1613,
          "title": "7 Best Free Datacamp Course to become a Data Scientist",
          "imageUrl": "https://miro.medium.com/max/1200/1*-sHR7dQFO0db6RBWFFllgA.png"
        },
        {
          "id": "https://medium.com/p/9b187a1bd412",
          "author": "Eric Landau",
          "description": "For context, I am a cofounder of Encord, a company building software to improve training data for computer vision.",
          "link": "https://becominghuman.ai/data-centric-ai-practical-implications-with-the-smart-pipeline-9b187a1bd412?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-03-16T13:14:48.000Z",
          "wordCount": 1915,
          "title": "Data-centric AI: Practical implications with the SMART Pipeline",
          "imageUrl": "https://miro.medium.com/max/1200/1*u948BVyeB6axSoMoHGIGOw.png"
        },
        {
          "id": "https://medium.com/p/3bed5e7cc6e4",
          "author": "Monodeep .J.Mukherjee",
          "description": "What is Data Fabric ?",
          "link": "https://becominghuman.ai/introduction-to-data-fabric-technology-3bed5e7cc6e4?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-03-15T13:07:55.000Z",
          "wordCount": 709,
          "title": "Introduction to Data Fabric Technology",
          "imageUrl": "https://miro.medium.com/max/1200/1*z4Yjt2bATR7133IfbRI3kw.jpeg"
        },
        {
          "id": "https://medium.com/p/f19fce6d725d",
          "author": "Shaip",
          "description": "Are you aware of the technicalities involved in making Machine Learning models holistic, intuitive, and impactful? If not, you first need…",
          "link": "https://becominghuman.ai/what-is-the-role-of-dataset-in-machine-learning-f19fce6d725d?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-03-14T13:21:30.000Z",
          "wordCount": 941,
          "title": "What Is The Role Of Dataset In Machine Learning?",
          "imageUrl": "https://miro.medium.com/max/720/0*Wljc0zQQZQ27TjMD.jpg"
        },
        {
          "id": "https://medium.com/p/a2d47c73d1d4",
          "author": "Sasha Andrieiev",
          "description": "Check to understand how image recognition technology works and why image detection revolutionizes business.",
          "link": "https://becominghuman.ai/ai-image-recognition-2022-a-comprehensive-guide-a2d47c73d1d4?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-03-11T14:37:12.000Z",
          "wordCount": 2423,
          "title": "AI Image Recognition 2022: A Comprehensive Guide",
          "imageUrl": "https://miro.medium.com/max/966/0*kHheBLp2THKq16mM.png"
        }
      ]
    },
    {
      "title": "MIT News - Artificial intelligence",
      "feedUrl": "http://news.mit.edu/rss/topic/artificial-intelligence2",
      "siteUrl": "https://news.mit.edu/rss/topic/artificial-intelligence2",
      "articles": [
        {
          "id": "https://news.mit.edu/2022/optimized-solution-face-recognition-0406",
          "author": "Jennifer Michalowski | McGovern Institute for Brain Research",
          "description": "When artificial intelligence is tasked with visually identifying objects and faces, it assigns specific components of its network to face recognition — just like the human brain.",
          "link": "https://news.mit.edu/2022/optimized-solution-face-recognition-0406",
          "publishedOn": "2022-04-06T15:25:00.000Z",
          "wordCount": 1511,
          "title": "An optimized solution for face recognition",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/face-recognition.png"
        },
        {
          "id": "https://news.mit.edu/2022/does-this-artificial-intelligence-think-human-0406",
          "author": "Adam Zewe | MIT News Office",
          "description": "A new technique compares the reasoning of a machine-learning model to that of a human, so the user can see patterns in the model’s behavior.",
          "link": "https://news.mit.edu/2022/does-this-artificial-intelligence-think-human-0406",
          "publishedOn": "2022-04-06T04:00:00.000Z",
          "wordCount": 2034,
          "title": "Does this artificial intelligence think like a human?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Shared-Interest-01-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/robots-dress-humans-without-full-picture-0405",
          "author": "Steve Nadis | MIT CSAIL",
          "description": "MIT researchers design a robot that has a trick or two up its sleeve.",
          "link": "https://news.mit.edu/2022/robots-dress-humans-without-full-picture-0405",
          "publishedOn": "2022-04-05T18:20:00.000Z",
          "wordCount": 1850,
          "title": "Robots dress humans without the full picture",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/robot-dressing-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/school-engineering-welcomes-thomas-tull-visiting-innovation-scholar-0404",
          "author": "Lori LoTurco | School of Engineering",
          "description": "Primary focus will be to advance and promote technology, innovation, and entrepreneurship across the school.",
          "link": "https://news.mit.edu/2022/school-engineering-welcomes-thomas-tull-visiting-innovation-scholar-0404",
          "publishedOn": "2022-04-04T19:40:00.000Z",
          "wordCount": 1252,
          "title": "School of Engineering welcomes Thomas Tull as visiting innovation scholar",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/thomas-tull-mit-00.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/huttenlocher-age-of-ai-0403",
          "author": "Adam Zewe | MIT News Office",
          "description": "For the MIT Schwarzman College of Computing dean, bringing disciplines together is the best way to address challenges and opportunities posed by rapid advancements in computing.",
          "link": "https://news.mit.edu/2022/huttenlocher-age-of-ai-0403",
          "publishedOn": "2022-04-03T04:00:00.000Z",
          "wordCount": 2333,
          "title": "Dan Huttenlocher ponders our human future in an age of artificial intelligence",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Dan-Huttenlocher-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/generating-new-molecules-with-graph-grammar-0401",
          "author": "Lauren Hinkel | MIT-IBM Watson AI Lab",
          "description": "An efficient machine-learning method uses chemical knowledge to create a learnable grammar with production rules to build synthesizable monomers and polymers.",
          "link": "https://news.mit.edu/2022/generating-new-molecules-with-graph-grammar-0401",
          "publishedOn": "2022-04-01T18:30:00.000Z",
          "wordCount": 1686,
          "title": "Generating new molecules with graph grammar",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/chemical-science-medical-substance-and-molecules.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/featured-video-mit-president-l-rafael-reif-power-of-education-0331",
          "author": "Melanie Grados, MIT News Office",
          "description": "At Monterrey Tec, MIT’s president discusses the impact of education in addressing global issues.",
          "link": "https://news.mit.edu/2022/featured-video-mit-president-l-rafael-reif-power-of-education-0331",
          "publishedOn": "2022-03-31T20:25:00.000Z",
          "wordCount": 943,
          "title": "Featured video: L. Rafael Reif on the power of education",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/l-rafael-reif-monterrey-tec-00.png"
        },
        {
          "id": "https://news.mit.edu/2022/robotic-deformable-object-0331",
          "author": "Adam Zewe | MIT News Office",
          "description": "A new technique could enable a robot to manipulate squishy objects like pizza dough or soft materials like clothing.",
          "link": "https://news.mit.edu/2022/robotic-deformable-object-0331",
          "publishedOn": "2022-03-31T04:00:00.000Z",
          "wordCount": 1973,
          "title": "Solving the challenges of robotic pizza-making",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/MIT-DiffSkill-01-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/qa-alberto-rodriguez-teaching-robot-find-your-keys-pile-clutter-0329",
          "author": "Kim Martineau | MIT Schwarzman College of Computing",
          "description": "Associate professor and principal investigator with the MIT Schwarzman College of Computing’s Science Hub discusses the future of robotics and the importance of industry-academia collaborations.",
          "link": "https://news.mit.edu/2022/qa-alberto-rodriguez-teaching-robot-find-your-keys-pile-clutter-0329",
          "publishedOn": "2022-03-29T15:00:00.000Z",
          "wordCount": 1644,
          "title": "Q&A: Alberto Rodriguez on teaching a robot to find your keys",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/Sangwoon-Alberto-MCube-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/new-program-bolsters-innovation-next-generation-artificial-intelligence-hardware-0329",
          "author": "School of Engineering | MIT Schwarzman College of Computing",
          "description": "MIT AI Hardware Program launches with five inaugural companies to advance AI technologies for the next decade.",
          "link": "https://news.mit.edu/2022/new-program-bolsters-innovation-next-generation-artificial-intelligence-hardware-0329",
          "publishedOn": "2022-03-29T13:00:00.000Z",
          "wordCount": 1434,
          "title": "New program bolsters innovation in next-generation artificial intelligence hardware",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/glowing-microchip.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/privid-security-tool-guarantees-privacy-surveillance-footage-0328",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "“Privid” could help officials gather secure public health data or enable transportation departments to monitor the density and flow of pedestrians, without learning personal information about people.",
          "link": "https://news.mit.edu/2022/privid-security-tool-guarantees-privacy-surveillance-footage-0328",
          "publishedOn": "2022-03-28T15:30:00.000Z",
          "wordCount": 1929,
          "title": "Security tool guarantees privacy in surveillance footage",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/privid-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/3-questions-how-mit-mini-cheetah-learns-run-fast-0317",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "CSAIL scientists came up with a learning pipeline for the four-legged robot that learns to run entirely by trial and error in simulation.",
          "link": "https://news.mit.edu/2022/3-questions-how-mit-mini-cheetah-learns-run-fast-0317",
          "publishedOn": "2022-03-17T17:55:00.000Z",
          "wordCount": 1600,
          "title": "3 Questions: How the MIT mini cheetah learns to run",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/minicheetah-stand2.png"
        },
        {
          "id": "https://news.mit.edu/2022/handheld-surgical-robot-can-help-stem-fatal-blood-loss-0317",
          "author": "Anne McGovern | MIT Lincoln Laboratory",
          "description": "The AI-Guided Ultrasound Intervention Device is a lifesaving technology that helps a range of users deliver complex medical interventions at the point of injury.",
          "link": "https://news.mit.edu/2022/handheld-surgical-robot-can-help-stem-fatal-blood-loss-0317",
          "publishedOn": "2022-03-17T17:25:00.000Z",
          "wordCount": 2112,
          "title": "Handheld surgical robot can help stem fatal blood loss",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/AI-Guide-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/how-ai-can-help-combat-systemic-racism-0316",
          "author": "Scott Murray | Institute for Data, Systems, and Society",
          "description": "MLK Visiting Professor S. Craig Watkins looks beyond algorithm bias to an AI future where models more effectively deal with systemic inequality.",
          "link": "https://news.mit.edu/2022/how-ai-can-help-combat-systemic-racism-0316",
          "publishedOn": "2022-03-16T19:40:00.000Z",
          "wordCount": 1632,
          "title": "How artificial intelligence can help combat systemic racism",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202202/S-Craig-Watkins-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/learning-fly-andrea-henshall-0316",
          "author": "Katherine Ouellette | MIT Open Learning",
          "description": "Veteran and PhD student Andrea Henshall has used MIT Open Learning to soar from the Air Force to multiple aeronautics degrees.",
          "link": "https://news.mit.edu/2022/learning-fly-andrea-henshall-0316",
          "publishedOn": "2022-03-16T16:00:00.000Z",
          "wordCount": 1862,
          "title": "Learning to fly",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/Andrea-Henshall%20copy_0.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/synthetic-datasets-ai-image-classification-0315",
          "author": "Adam Zewe | MIT News Office",
          "description": "A machine-learning model for image classification that’s trained using synthetic data can rival one trained on the real thing, a study shows.",
          "link": "https://news.mit.edu/2022/synthetic-datasets-ai-image-classification-0315",
          "publishedOn": "2022-03-15T04:00:00.000Z",
          "wordCount": 1827,
          "title": "When it comes to AI, can we ditch the datasets?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/MIT-Gen-Learn-01-press.jpg"
        }
      ]
    },
    {
      "title": "NVIDIA Blog",
      "feedUrl": "http://feeds.feedburner.com/nvidiablog",
      "siteUrl": "https://blogs.nvidia.com",
      "articles": [
        {
          "id": "https://blogs.nvidia.com/?p=56521",
          "author": "Isha Salian",
          "description": "A team of scientists have created a new AI-based tool to help lock up greenhouse gases like CO2 in porous rock formations faster and more precisely than ever before. Carbon capture technology, also referred to as carbon sequestration, is a climate change mitigation method that redirects CO2 emitted from power plants back underground. While doing Read article >\nThe post Rock On: Scientists Use AI to Improve Sequestering Carbon Underground appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/08/ai-improves-carbon-sequestration/",
          "publishedOn": "2022-04-08T17:36:44.000Z",
          "wordCount": 1149,
          "title": "Rock On: Scientists Use AI to Improve Sequestering Carbon Underground",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/I-am-ai-corp-blog-april-2022-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56490",
          "author": "GeForce NOW Community",
          "description": "GeForce NOW is about bringing new experiences to gamers. This GFN Thursday introduces game demos to GeForce NOW. Members can now try out some of the hit games streaming on the service before purchasing the full PC version — including some finalists from the 2021 Epic MegaJam. Plus, look for six games ready to stream Read article >\nThe post Try This Out: GFN Thursday Delivers Instant-Play Game Demos on GeForce NOW appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/07/geforce-now-thursday-april-7/",
          "publishedOn": "2022-04-07T13:00:01.000Z",
          "wordCount": 793,
          "title": "Try This Out: GFN Thursday Delivers Instant-Play Game Demos on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/gfn-4-7-thursday-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56511",
          "author": "Jurgen Ferchau",
          "description": "Meet the electric vehicle that’s quick-witted and fully outfitted. Last week, NIO began deliveries of its highly anticipated ET7 fully electric vehicle, in Hefei, China. The full-size luxury sedan is the first production vehicle built on the NIO Adam supercomputer, powered by four NVIDIA DRIVE Orin systems-on-a-chip (SoCs). The production launch of its flagship sedan Read article >\nThe post Fast and Luxurious: The Intelligent NIO ET7 EV Built on NVIDIA DRIVE Orin Arrives appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/06/nio-et7-drive-orin-arrives/",
          "publishedOn": "2022-04-06T19:41:03.000Z",
          "wordCount": 709,
          "title": "Fast and Luxurious: The Intelligent NIO ET7 EV Built on NVIDIA DRIVE Orin Arrives",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/ET7.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56403",
          "author": "Dave Salvator",
          "description": "In its debut in the industry MLPerf benchmarks, NVIDIA Orin, a low-power system-on-chip based on the NVIDIA Ampere architecture, set new records in AI inference, raising the bar in per-accelerator performance at the edge. Overall, NVIDIA with its partners continued to show the highest performance and broadest ecosystem for running all machine-learning workloads and scenarios Read article >\nThe post NVIDIA Orin Leaps Ahead in Edge AI, Boosting Leadership in MLPerf Tests appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/06/mlperf-edge-ai-inference-orin/",
          "publishedOn": "2022-04-06T17:00:38.000Z",
          "wordCount": 1005,
          "title": "NVIDIA Orin Leaps Ahead in Edge AI, Boosting Leadership in MLPerf Tests",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/Orin-dev-kit-and-module-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56436",
          "author": "Ethan Einhorn",
          "description": "Square/Enix presents the fictional city of Midgar in Final Fantasy VII Remake at a filmic level of detail. Epic’s Fortnite bathes its environments in ray-traced sunlight, simulating how light bounces in the real world. And artists at Lucasfilm revolutionized virtual production techniques in The Mandalorian, using synchronized NVIDIA RTX GPUs to drive pixels on LED Read article >\nThe post Unreal Engine and NVIDIA: From One Generation to the Next appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/05/unreal-engine-5/",
          "publishedOn": "2022-04-05T15:10:12.000Z",
          "wordCount": 1151,
          "title": "Unreal Engine and NVIDIA: From One Generation to the Next",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/unreal-engine-5-jungle.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56434",
          "author": "Craig Weinstein",
          "description": "A dozen companies today received NVIDIA’s highest award for partners, recognizing their impact on AI education and adoption across such industries as education, federal, healthcare and technology. The winners of the 2021 NPN Americas Partner of the Year Awards have created a profound impact on AI by helping customers meet the demands of recommender systems, Read article >\nThe post Green Teams Achieve the Dream: NVIDIA Announces NPN Americas Partners of the Year appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/05/americas-npn-award-winners-2021/",
          "publishedOn": "2022-04-05T15:00:15.000Z",
          "wordCount": 1063,
          "title": "Green Teams Achieve the Dream: NVIDIA Announces NPN Americas Partners of the Year",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/npn-awards-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56447",
          "author": "Angie Lee",
          "description": "Pekka Varis’s artistry has come a long way from his early days as a self-styled “punk activist” who spray painted during the “old school days of hip hop in Finland.”\nThe post Meet the Omnivore: Videographer Makes Digital Walls, Virtual Homes Pop With NVIDIA Omniverse appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/04/pekka-varis-omniverse-creator/",
          "publishedOn": "2022-04-04T15:00:58.000Z",
          "wordCount": 959,
          "title": "Meet the Omnivore: Videographer Makes Digital Walls, Virtual Homes Pop With NVIDIA Omniverse",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/pekka-varis-still.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56412",
          "author": "GeForce NOW Community",
          "description": "In addition to GFN Thursday, it’s National Tater Day. Hooray! To honor the spud-tacular holiday, we’re closing out March with seven new games streaming this week. And a loaded 20+ titles are coming to the GeForce NOW library in April to play — even on a potato PC, thanks to GeForce NOW. Plus, the GeForce Read article >\nThe post An A-peel-ing GFN Thursday Sprouts 20+ New Games Coming to GeForce NOW in April appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/31/geforce-now-thursday-march-31/",
          "publishedOn": "2022-03-31T13:00:06.000Z",
          "wordCount": 836,
          "title": "An A-peel-ing GFN Thursday Sprouts 20+ New Games Coming to GeForce NOW in April",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/gfn-thursday-3-31-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56405",
          "author": "Jurgen Ferchau",
          "description": "Four words: smart, sustainable, Super Bowl. Polestar’s commercial during the big game made it clear no-compromise electric vehicles are now mainstream. Polestar Chief Operating Officer Dennis Nobelius sees driving enjoyment and autonomous-driving capabilities complementing one another in sustainable vehicles that keep driving — and the driver — front and center. NVIDIA’s Katie Washabaugh spoke with Read article >\nThe post Polestar’s Dennis Nobelius on the Sustainable Performance Brand’s Plans appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/30/polestar/",
          "publishedOn": "2022-03-30T13:00:49.000Z",
          "wordCount": 634,
          "title": "Polestar’s Dennis Nobelius on the Sustainable Performance Brand’s Plans",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/504426_20210211_Polestar_1_2021_003-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56394",
          "author": "Angie Lee",
          "description": "“I am a visionary,” says an AI, kicking off the latest installment of NVIDIA’s I AM AI video series. Launched in 2017, I AM AI has become the iconic opening for GTC keynote addresses by NVIDIA founder and CEO Jensen Huang. Each video, with its AI-created narration and soundtrack, documents the newest advances in artificial Read article >\nThe post Latest ‘I AM AI’ Video Features Four-Legged Robots, Smart Cell Analysis, Tumor-Tracking Tech and More appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/29/i-am-ai-gtc/",
          "publishedOn": "2022-03-29T17:00:26.000Z",
          "wordCount": 950,
          "title": "Latest ‘I AM AI’ Video Features Four-Legged Robots, Smart Cell Analysis, Tumor-Tracking Tech and More",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/iamai_social-spring-manifesto-1280x680-1.jpeg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56389",
          "author": "Scott Martin",
          "description": "When Tanish Tyagi published his first research paper a year ago on deep learning to detect dementia, it started a family-driven pursuit. Great-grandparents in his family had suffered from Parkinson’s, a genetic disease that affects more than 10 million people worldwide. So the now 16-year-old turned to that next, together with his sister, Riya, 14. Read article >\nThe post Teens Develop Handwriting-Recognition AI for Detecting Parkinson’s Disease appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/29/handwriting-recognition-ai-parkinsons-disease/",
          "publishedOn": "2022-03-29T16:00:56.000Z",
          "wordCount": 937,
          "title": "Teens Develop Handwriting-Recognition AI for Detecting Parkinson’s Disease",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/Parkinsons-672x378.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56338",
          "author": "Rick Merritt",
          "description": "If you want to ride the next big wave in AI, grab a transformer. They’re not the shape-shifting toy robots on TV or the trash-can-sized tubs on telephone poles. So, What’s a Transformer Model? A transformer model is a neural network that learns context and thus meaning by tracking relationships in sequential data like the Read article >\nThe post What Is a Transformer Model? appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/",
          "publishedOn": "2022-03-25T15:00:27.000Z",
          "wordCount": 2573,
          "title": "What Is a Transformer Model?",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/Transformer-rbm2-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55984",
          "author": "Isha Salian",
          "description": "When the first instant photo was taken 75 years ago with a Polaroid camera, it was groundbreaking to rapidly capture the 3D world in a realistic 2D image. Today, AI researchers are working on the opposite: turning a collection of still images into a digital 3D scene in a matter of seconds. Known as inverse Read article >\nThe post NVIDIA Research Turns 2D Photos Into 3D Scenes in the Blink of an AI appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/25/instant-nerf-research-3d-ai/",
          "publishedOn": "2022-03-25T13:00:23.000Z",
          "wordCount": 1116,
          "title": "NVIDIA Research Turns 2D Photos Into 3D Scenes in the Blink of an AI",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/NVIDIA-Research-Instant-NeRF-Image.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56286",
          "author": "GeForce NOW Community",
          "description": "GeForce NOW gives you the power to game almost anywhere, at GeForce quality. And with the latest controller from SteelSeries, members can stay in control of the action on Android and Chromebook devices. This GFN Thursday takes a look at the SteelSeries Stratus+, now part of the GeForce NOW Recommended program. And it wouldn’t be Read article >\nThe post Take Control This GFN Thursday With New Stratus+ Controller From SteelSeries appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/24/geforce-now-thursday-march-24/",
          "publishedOn": "2022-03-24T13:00:59.000Z",
          "wordCount": 932,
          "title": "Take Control This GFN Thursday With New Stratus+ Controller From SteelSeries",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/gfn-thursday-3-17-nv-blog-1280x680-no-cta-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56306",
          "author": "Michael Kagan",
          "description": "The hum of a bustling data center is music to an AI developer’s ears — and NVIDIA data centers have found a rhythm of their own, grooving to the swing classic “Sing, Sing, Sing” in this week’s GTC keynote address. The lighthearted video, created with the NVIDIA Omniverse platform, features Louis Prima’s iconic music track, Read article >\nThe post Orchestrated to Perfection: NVIDIA Data Center Grooves to Tune of Millionfold Speedups appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/24/data-center-millionfold-speedups-orchestrated-to-perfection/",
          "publishedOn": "2022-03-24T13:00:51.000Z",
          "wordCount": 1094,
          "title": "Orchestrated to Perfection: NVIDIA Data Center Grooves to Tune of Millionfold Speedups",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/ITDK_sh030_Comp_1075-672x357.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56003",
          "author": "Brian Caulfield",
          "description": "Turn on your TV. Fire up your favorite streaming service. Grab a Coke. A demo of the most important visual technology of our time is as close as your living room couch. Propelled by an explosion in computing power over the past decade and a half, path tracing has swept through visual media. It brings Read article >\nThe post What Is Path Tracing? appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/23/what-is-path-tracing/",
          "publishedOn": "2022-03-23T17:00:10.000Z",
          "wordCount": 2387,
          "title": "What Is Path Tracing?",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/What_is_PT_Blog_Header-672x353.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55947",
          "author": "Matt Cragun",
          "description": "Autonomous vehicle development and validation require the ability to replicate real-world scenarios in simulation. At GTC, NVIDIA founder and CEO Jensen Huang showcased new AI-based tools for NVIDIA DRIVE Sim that accurately reconstruct and modify actual driving scenarios. These tools are enabled by breakthroughs from NVIDIA Research that leverage technologies such as NVIDIA Omniverse platform Read article >\nThe post NVIDIA Showcases Novel AI Tools in DRIVE Sim to Advance Autonomous Vehicle Development appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/23/drive-sim-omniverse-neural-ai-digital-twin/",
          "publishedOn": "2022-03-23T16:18:32.000Z",
          "wordCount": 1124,
          "title": "NVIDIA Showcases Novel AI Tools in DRIVE Sim to Advance Autonomous Vehicle Development",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/Rainbow_Van_KV.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55971",
          "author": "Serge Lemonde",
          "description": "This week at GTC, we’re celebrating – celebrating the amazing and impactful work that developers and startups are doing around the world. Nowhere is that more apparent than among the members of our global NVIDIA Inception program, designed to nurture cutting-edge startups who are revolutionizing industries. The program is free for startups of all sizes Read article >\nThe post NVIDIA Inception Introduces New and Updated Benefits for Startup Members to Accelerate Computing appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/23/inception-expands-beyond-10k-with-omniverse-climate-startups/",
          "publishedOn": "2022-03-23T15:00:45.000Z",
          "wordCount": 1048,
          "title": "NVIDIA Inception Introduces New and Updated Benefits for Startup Members to Accelerate Computing",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/Inception10.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56162",
          "author": "TJ Galda",
          "description": "At GTC, NVIDIA announced significant updates for millions of creators using the NVIDIA Omniverse real-time 3D design collaboration platform. The announcements kicked off with updates to the Omniverse apps Create, Machinima and Showroom, with an immement View release. Powered by GeForce RTX and NVIDIA RTX GPUs, they dramatically accelerate 3D creative workflows. New Omniverse Connections Read article >\nThe post NVIDIA Omniverse Upgrade Delivers Extraordinary Benefits to 3D Content Creators appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/gtc-omniverse-create-view-machinima-update/",
          "publishedOn": "2022-03-22T17:00:56.000Z",
          "wordCount": 1531,
          "title": "NVIDIA Omniverse Upgrade Delivers Extraordinary Benefits to 3D Content Creators",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/blog-1280x680.jpg.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56102",
          "author": "Gerardo Delgado",
          "description": "Digital artists and creative professionals have plenty to be excited about at NVIDIA GTC. Impressive NVIDIA Studio laptop offerings from ASUS and MSI launch with upgraded RTX GPUs, providing more options for professional content creators to elevate and expand creative possibilities. NVIDIA Omniverse gets a significant upgrade — including updates to the Omniverse Create, Machinima Read article >\nThe post At GTC: NVIDIA RTX Professional Laptop GPUs Debut, New NVIDIA Studio Laptops, a Massive Omniverse Upgrade and NVIDIA Canvas Update appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/gtc-rtx-studio-updates/",
          "publishedOn": "2022-03-22T17:00:39.000Z",
          "wordCount": 1668,
          "title": "At GTC: NVIDIA RTX Professional Laptop GPUs Debut, New NVIDIA Studio Laptops, a Massive Omniverse Upgrade and NVIDIA Canvas Update",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/nv-blog-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55990",
          "author": "Brian Caulfield",
          "description": "Promising to transform trillion-dollar industries and address the “grand challenges” of our time, NVIDIA founder and CEO Jensen Huang Tuesday shared a vision of an era where intelligence is created on an industrial scale and woven into real and virtual worlds. Kicking off NVIDIA’s GTC conference, Huang introduced new silicon — including the new Hopper Read article >\nThe post Keynote Wrap Up: Turning Data Centers into ‘AI Factories,’ NVIDIA CEO Intros Hopper Architecture, H100 GPU, New Supercomputers, Software appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/ai-factories-hopper-h100-nvidia-ceo-jensen-huang/",
          "publishedOn": "2022-03-22T16:45:40.000Z",
          "wordCount": 2330,
          "title": "Keynote Wrap Up: Turning Data Centers into ‘AI Factories,’ NVIDIA CEO Intros Hopper Architecture, H100 GPU, New Supercomputers, Software",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/Hopper_1.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55986",
          "author": "Anthony Costa",
          "description": "The University of Florida’s academic health center, UF Health, has teamed up with NVIDIA to develop a neural network that generates synthetic clinical data — a powerful resource that researchers can use to train other AI models in healthcare. Trained on a decade of data representing more than 2 million patients, SynGatorTron is a language Read article >\nThe post Unlimited Data, Unlimited Possibilities: UF Health and NVIDIA Build World’s Largest Clinical Language Generator appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/uf-health-syngatortron-ai-synthetic-clinical-data/",
          "publishedOn": "2022-03-22T16:45:38.000Z",
          "wordCount": 1091,
          "title": "Unlimited Data, Unlimited Possibilities: UF Health and NVIDIA Build World’s Largest Clinical Language Generator",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/UF-Blog-Press-Image.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56037",
          "author": "Bob Pette",
          "description": "Remote work and hybrid workplaces are the new normal for professionals in many industries. Teams spread throughout the world are expected to create and collaborate while maintaining top productivity and performance. Businesses use the NVIDIA RTX platform to enable their workers to keep up with the most demanding workloads, from anywhere. And today, NVIDIA is Read article >\nThe post New NVIDIA RTX GPUs Tackle Demanding Professional Workflows and Hybrid Work, Enabling Creation From Anywhere appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/rtx-tackle-pro-workflows/",
          "publishedOn": "2022-03-22T16:45:36.000Z",
          "wordCount": 1304,
          "title": "New NVIDIA RTX GPUs Tackle Demanding Professional Workflows and Hybrid Work, Enabling Creation From Anywhere",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/rtx-blog-header.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55987",
          "author": "Craig Rhodes",
          "description": "Four NVIDIA Inception members have been selected as the first cohort of startups to access Cambridge-1, the U.K.’s most powerful supercomputer. The system will help British companies Alchemab Therapeutics, InstaDeep, Peptone and Relation Therapeutics enable breakthroughs in digital biology. Officially launched in July, Cambridge-1 — an NVIDIA DGX SuperPOD cluster powered by NVIDIA DGX A100 Read article >\nThe post First Wave of Startups Harnesses UK’s Most Powerful Supercomputer to Power Digital Biology Breakthroughs appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/startups-harness-cambridge-1-supercomputer/",
          "publishedOn": "2022-03-22T16:45:30.000Z",
          "wordCount": 1289,
          "title": "First Wave of Startups Harnesses UK’s Most Powerful Supercomputer to Power Digital Biology Breakthroughs",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/cambridge-1-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56065",
          "author": "Richard Kerris",
          "description": "When it comes to creating and connecting virtual worlds, over 150,000 individuals have downloaded NVIDIA Omniverse to make huge leaps in transforming 3D design workflows and achieve new heights of real-time, physically accurate simulations. At GTC, NVIDIA today announced new releases and updates for Omniverse — including the latest Omniverse Connectors and libraries — expanding Read article >\nThe post NVIDIA Omniverse Ecosystem Expands 10x, Amid New Features and Services for Developers, Enterprises and Creators appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/omniverse-ecosystem-expands/",
          "publishedOn": "2022-03-22T16:31:44.000Z",
          "wordCount": 1321,
          "title": "NVIDIA Omniverse Ecosystem Expands 10x, Amid New Features and Services for Developers, Enterprises and Creators",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/ov-gtc-announce-amazon-corp-blog-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55992",
          "author": "Gerard Andrews",
          "description": "Next time socks, cereal or sandpaper shows up in hours delivered to your doorstep, consider the behind-the-scenes logistics acrobatics that help get them there so fast. Order fulfillment is a massive industry of moving parts. Heavily supported by autonomous mobile robots (AMRs), warehouses can span 1 million square feet, expanding and reconfiguring to meet demands. Read article >\nThe post NVIDIA Unveils Isaac Nova Orin to Accelerate Development of Autonomous Mobile Robots appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/nvidia-isaac-nova-orin-amrs/",
          "publishedOn": "2022-03-22T16:21:27.000Z",
          "wordCount": 869,
          "title": "NVIDIA Unveils Isaac Nova Orin to Accelerate Development of Autonomous Mobile Robots",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/AMR4.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55948",
          "author": "Danny Shapiro",
          "description": "Lucid Group may be a newcomer to the electric vehicle market, but its entrance has been grand. The electric automaker announced at GTC that its current and future fleets are built on NVIDIA DRIVE Hyperion for programmable, intelligent capabilities. By developing on the scalable, software-defined platform, Lucid ensures its vehicles are always at the cutting Read article >\nThe post Driving on Air: Lucid Group Builds Intelligent EVs on NVIDIA DRIVE appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/lucid-motors-intelligent-evs-nvidia-drive/",
          "publishedOn": "2022-03-22T16:15:54.000Z",
          "wordCount": 722,
          "title": "Driving on Air: Lucid Group Builds Intelligent EVs on NVIDIA DRIVE",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/NVIDIA-Image-3.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55946",
          "author": "Ali Kani",
          "description": "NVIDIA DRIVE Hyperion and DRIVE Orin are gaining ground in the industry. At NVIDIA GTC, BYD, the world’s second-largest electric vehicle maker, announced it is building its next-generation fleets on the DRIVE Hyperion architecture. This platform, based on DRIVE Orin, is now in production, and powering a wide ecosystem of 25 EV makers building software-defined Read article >\nThe post NVIDIA DRIVE Continues Industry Momentum With $11 Billion Pipeline as DRIVE Orin Enters Production appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/drive-orin-byd-production/",
          "publishedOn": "2022-03-22T16:14:54.000Z",
          "wordCount": 863,
          "title": "NVIDIA DRIVE Continues Industry Momentum With $11 Billion Pipeline as DRIVE Orin Enters Production",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/auto-ecosystem-byd-featured-stories-dual-cars-corporate-blog-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55943",
          "author": "Zvi Greenstein",
          "description": "With a detailed knowledge of the world and everything in it, maps provide the foresight AI uses to make advanced and safe driving decisions. At his GTC keynote, NVIDIA founder and CEO Jensen Huang introduced NVIDIA DRIVE Map, a multimodal mapping platform designed to enable the highest levels of autonomy while improving safety. It combines Read article >\nThe post Announcing NVIDIA DRIVE Map: Scalable, Multi-Modal Mapping Engine Accelerates Deployment of Level 3 and Level 4 Autonomy appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/drive-map-multi-modal-mapping-engine/",
          "publishedOn": "2022-03-22T16:11:16.000Z",
          "wordCount": 1079,
          "title": "Announcing NVIDIA DRIVE Map: Scalable, Multi-Modal Mapping Engine Accelerates Deployment of Level 3 and Level 4 Autonomy",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/auto-mapping-blog-hdr-1280x600-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55945",
          "author": "Gary Hicok",
          "description": "NVIDIA DRIVE Hyperion is taking software-defined vehicle architectures to the next level. At his GTC keynote, NVIDIA founder and CEO Jensen Huang announced DRIVE Hyperion 9, the next generation of the open platform for automated and autonomous vehicles. The programmable architecture, slated for 2026 production vehicles, is built on multiple DRIVE Atlan computers to achieve Read article >\nThe post Introducing NVIDIA DRIVE Hyperion 9: Next-Generation Platform for Software-Defined Autonomous Vehicle Fleets appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/drive-hyperion-9-atlan/",
          "publishedOn": "2022-03-22T16:10:24.000Z",
          "wordCount": 765,
          "title": "Introducing NVIDIA DRIVE Hyperion 9: Next-Generation Platform for Software-Defined Autonomous Vehicle Fleets",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/Hyperion_9_blog.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55989",
          "author": "Bhoomi Gadhia",
          "description": "Siemens Gamesa Renewable Energy is working with NVIDIA to create physics-informed digital twins of wind farms — groups of wind turbines used to produce electricity. The company has thousands of turbines around the globe that light up schools, homes, hospitals and factories with clean energy. In total they generate over 100 gigawatts of wind power, Read article >\nThe post Siemens Gamesa Taps NVIDIA Digital Twin Platform for Scientific Computing to Accelerate Clean Energy Transition appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/siemens-gamesa-wind-farms-digital-twins/",
          "publishedOn": "2022-03-22T15:57:21.000Z",
          "wordCount": 909,
          "title": "Siemens Gamesa Taps NVIDIA Digital Twin Platform for Scientific Computing to Accelerate Clean Energy Transition",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/wind-turbines.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55950",
          "author": "Timothy Costa",
          "description": "We’re working with leaders in quantum computing to build the tools developers will need to program tomorrow’s ultrahigh performance systems. Today’s high-performance computers are simulating quantum computing jobs at scale and with performance far beyond what’s possible on today’s smaller and error-prone quantum systems. In this way, classical HPC systems are helping quantum researchers chart Read article >\nThe post NVIDIA Unveils Onramp to Hybrid Quantum Computing appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/hybrid-quantum-computing-ecosystem/",
          "publishedOn": "2022-03-22T15:47:16.000Z",
          "wordCount": 855,
          "title": "NVIDIA Unveils Onramp to Hybrid Quantum Computing",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/quantum-fb-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55977",
          "author": "Karthikeyan Rajendran",
          "description": "AT&T’s wireless network connects more than 100 million subscribers from the Aleutian Islands to the Florida Keys, spawning a big data sea. Abhay Dabholkar runs a research group that acts like a lighthouse on the lookout for the best tools to navigate it. “It’s fun, we get to play with new tools that can make Read article >\nThe post Speed Dialer: How AT&T Rings Up New Opportunities With Data Science appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/att-data-science-rapids/",
          "publishedOn": "2022-03-22T15:45:47.000Z",
          "wordCount": 958,
          "title": "Speed Dialer: How AT&T Rings Up New Opportunities With Data Science",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/ATT-coverage-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55985",
          "author": "Dion Harris",
          "description": "The NVIDIA Hopper GPU architecture unveiled today at GTC will accelerate dynamic programming — a problem-solving technique used in algorithms for genomics, quantum  computing, route optimization and more — by up to 40x with new DPX instructions. An instruction set built into NVIDIA H100 GPUs, DPX will help developers write code to achieve speedups on Read article >\nThe post NVIDIA Hopper GPU Architecture Accelerates Dynamic Programming Up to 40x Using New DPX Instructions appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/nvidia-hopper-accelerates-dynamic-programming-using-dpx-instructions/",
          "publishedOn": "2022-03-22T15:33:11.000Z",
          "wordCount": 1005,
          "title": "NVIDIA Hopper GPU Architecture Accelerates Dynamic Programming Up to 40x Using New DPX Instructions",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/hopper-announcement-blog-1260x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56129",
          "author": "Dave Salvator",
          "description": "The largest AI models can require months to train on today’s computing platforms. That’s too slow for businesses. AI, high performance computing and data analytics are growing in complexity with some models, like large language ones, reaching trillions of parameters. The NVIDIA Hopper architecture is built from the ground up to accelerate these next-generation AI Read article >\nThe post H100 Transformer Engine Supercharges AI Training, Delivering Up to 6x Higher Performance Without Losing Accuracy appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/h100-transformer-engine/",
          "publishedOn": "2022-03-22T15:31:37.000Z",
          "wordCount": 1166,
          "title": "H100 Transformer Engine Supercharges AI Training, Delivering Up to 6x Higher Performance Without Losing Accuracy",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/h100-family-shot.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56050",
          "author": "Rick Champagne",
          "description": "Everyone wants to be heard. And with more people than ever in video calls or live streaming from their home offices, rich audio free from echo hiccups and background noises like barking dogs is key to better sounding online experiences. NVIDIA Maxine offers GPU-accelerated, AI-enabled software development kits to help developers build scalable, low-latency audio Read article >\nThe post NVIDIA Maxine Reinvents Real-Time Communication With AI appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/22/maxine-reinvents-communication-ai/",
          "publishedOn": "2022-03-22T15:25:39.000Z",
          "wordCount": 1466,
          "title": "NVIDIA Maxine Reinvents Real-Time Communication With AI",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/Maxine2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55927",
          "author": "Brian Caulfield",
          "description": "NVIDIA’s GTC conference is packed with smart people and programming. The virtual gathering — which takes place from March 21-24 — sits at the intersection of some of the fastest-moving technologies of our time. It features a lineup of speakers from every corner of industry, academia and research who are ready to paint a high-definition Read article >\nThe post Hopped Up: NVIDIA CEO, AI Leaders to Discuss Next Wave of AI at GTC appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/18/nvidia-ceo-jensen-huang-gtc/",
          "publishedOn": "2022-03-18T13:00:25.000Z",
          "wordCount": 1027,
          "title": "Hopped Up: NVIDIA CEO, AI Leaders to Discuss Next Wave of AI at GTC",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/keynote-nvidia-ceo-jensen-huang-672x376.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=55928",
          "author": "GeForce NOW Community",
          "description": "It’s never been easier to be a PC gamer. GeForce NOW is your gateway into PC gaming. With the power of NVIDIA GeForce GPUs in the cloud, any gamer can stream titles from the top digital games stores — even on low-powered hardware. Evolve to the PC gaming ranks this GFN Thursday and get ready Read article >\nThe post Everyone’s a PC Gamer This GFN Thursday appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/17/geforce-now-thursday-march-17/",
          "publishedOn": "2022-03-17T13:00:42.000Z",
          "wordCount": 881,
          "title": "Everyone’s a PC Gamer This GFN Thursday",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/gfn-thursday-3-17-nv-blog-1280x680-no-cta.jpg"
        }
      ]
    },
    {
      "title": "David Stutz",
      "feedUrl": "http://davidstutz.de/feed",
      "siteUrl": "https://davidstutz.de",
      "articles": []
    },
    {
      "title": "Artificial Intelligence",
      "feedUrl": "https://www.reddit.com/r/artificial/.rss",
      "siteUrl": "https://www.reddit.com/r/artificial/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/artificial/comments/u04lwl/ran_3d_art_of_my_ai_character_thru_arcanegan_ai/",
          "author": null,
          "description": "submitted by    /u/alex-redacted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u04lwl/ran_3d_art_of_my_ai_character_thru_arcanegan_ai/",
          "publishedOn": "2022-04-09T23:04:12.000Z",
          "wordCount": 139,
          "title": "Ran 3D art of my AI character thru ArcaneGAN; AI making art of AI.",
          "imageUrl": "https://preview.redd.it/fdijdzsn3ls81.png?auto=webp&s=46e80b998b44c6376ca228789e4a801c4db2835e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u02dby/new_technology_old_problems_the_missing_voices_in/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u02dby/new_technology_old_problems_the_missing_voices_in/",
          "publishedOn": "2022-04-09T21:09:04.000Z",
          "wordCount": 115,
          "title": "New Technology, Old Problems: The Missing Voices in Natural Language Processing",
          "imageUrl": "https://external-preview.redd.it/aCFFte1ngYO7W4TDBUxX36yna0MktPGAbUpyRIEkZ4o.jpg?auto=webp&s=a09792b7388a17592cb79209a418b1541b3d2f94"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzzoky/check_out_this_deepminds_new_language_model/",
          "author": null,
          "description": "https://preview.redd.it/pkrbloq8vjs81.png?width=1422&format=png&auto=webp&s=fef693165a6c948f626de613e4e341c25f8cf5f4\n ​\n Extreme-scale language models have recently exhibited incredible performance on natural language processing challenges. This is due to their ever-increasing size, exceeding 500 billion parameters. However, while these models have grown in popularity in recent years, the amount of data utilized to train them has not increased. The current generation of huge language models is clearly undertrained. Three prediction approaches for optimally choosing both model size and training length have been proposed by a DeepMind research team.\n Three approaches have been mentioned to estimate the optimal parameter:\n  \nChange the size of the models and the number of training tokens.\n IsoFLOP profiles\n Using a parametric loss function to fit a model\n  \nThe ultimate pretraining loss is calculated as the number of model parameters and training tokens. They minimize the loss function under the restriction of the FLOPs function, which is equal to the computational budget because the computational budget is a probabilistic function of the number of observed training tokens and model parameters.\n Continue Reading This Research Summary\n Paper: https://arxiv.org/pdf/2203.15556.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzzoky/check_out_this_deepminds_new_language_model/",
          "publishedOn": "2022-04-09T18:53:20.000Z",
          "wordCount": 357,
          "title": "Check Out This DeepMind’s New Language Model, Chinchilla (70B Parameters), Which Significantly Outperforms Gopher (280B) and GPT-3 (175B) on a Large Range of Downstream Evaluation Tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzutk1/flaming_rose_art_made_with_snowpixelapp_using_ai/",
          "author": null,
          "description": "submitted by    /u/AIWORQART  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzutk1/flaming_rose_art_made_with_snowpixelapp_using_ai/",
          "publishedOn": "2022-04-09T14:54:12.000Z",
          "wordCount": 103,
          "title": "Flaming Rose art made with snowpixelapp using AI.",
          "imageUrl": "https://preview.redd.it/fhzy6cdkois81.png?auto=webp&s=d938ada6216f9f722408f57cb8b8399d7757c649"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzt8s2/how_do_you_start_a_professional_career_in_the/",
          "author": null,
          "description": "I'm about to graduate with a master's degree in Computer Science and I'm very passionate about Affective Computing. I would like to start looking for a job in this field, but most companies (not consulting) are looking for people with experience or a PhD. What do you recommend me to do? Continue with the PhD or try to find something, maybe in some startup?\n    submitted by    /u/_rikya_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzt8s2/how_do_you_start_a_professional_career_in_the/",
          "publishedOn": "2022-04-09T13:30:47.000Z",
          "wordCount": 176,
          "title": "How do you start a professional career in the Affective Computing field?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzpknc/deep_learning_to_enable_color_vision_in_the_dark/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzpknc/deep_learning_to_enable_color_vision_in_the_dark/",
          "publishedOn": "2022-04-09T09:21:28.000Z",
          "wordCount": 109,
          "title": "Deep learning to enable color vision in the dark",
          "imageUrl": "https://external-preview.redd.it/aj9cripQrjAIk9HtPGuEJtE9hcmLnAYSn3Q0aHyRj8s.jpg?auto=webp&s=f9a3fab8879e834cda8bd888bdb7814c1e52ada1"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzoq8s/laptop_for_beginner/",
          "author": null,
          "description": "I'm joining MSc AI & ML this September. I want to buy a laptop. Is MacBook Air sufficient for this? If not what would you recommend to someone like me?\n    submitted by    /u/RauhanSheikh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzoq8s/laptop_for_beginner/",
          "publishedOn": "2022-04-09T08:16:21.000Z",
          "wordCount": 232,
          "title": "Laptop for beginner?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzmyzt/how_can_i_help_the_advancement_of_ai_i_want_to/",
          "author": null,
          "description": "Please give a thorough and in-depth response.\n    submitted by    /u/trillswan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzmyzt/how_can_i_help_the_advancement_of_ai_i_want_to/",
          "publishedOn": "2022-04-09T06:07:36.000Z",
          "wordCount": 329,
          "title": "How can I help the advancement of AI? I want to contribute and make this my career. What should I do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzdoaq/responsible_ai_in_a_global_context/",
          "author": null,
          "description": "submitted by    /u/john133435  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzdoaq/responsible_ai_in_a_global_context/",
          "publishedOn": "2022-04-08T21:21:21.000Z",
          "wordCount": 100,
          "title": "Responsible AI in a Global Context",
          "imageUrl": "https://external-preview.redd.it/BfbeVK2uIIiWcFDmrjddKk8N7im5PD2YwYs7ANBXc_I.jpg?auto=webp&s=512d23af429e73ab0715983c9112cd0ba2aa31af"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzc7xd/ai_website_that_transitions_photos_into_video/",
          "author": null,
          "description": "Remember using a website like a year ago, where you could put in 2 or more images, and it would sort of make a transition between the two with AI. Then you could export the video and such. You could also very extensively edit human faces and change small features on a scale from 1-100. The features where incredibly specific like brow bone and nasal bridge.\n If anyone has the website I would appreciate it!!\n    submitted by    /u/yungbenz0_bajs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzc7xd/ai_website_that_transitions_photos_into_video/",
          "publishedOn": "2022-04-08T20:12:03.000Z",
          "wordCount": 171,
          "title": "AI website that transitions photos into video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzai2l/how_artificial_intelligence_is_impacting_todays/",
          "author": null,
          "description": "submitted by    /u/mr_j_b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzai2l/how_artificial_intelligence_is_impacting_todays/",
          "publishedOn": "2022-04-08T18:51:33.000Z",
          "wordCount": 103,
          "title": "How Artificial Intelligence Is Impacting Today’s Businesses",
          "imageUrl": "https://external-preview.redd.it/WUT9SjRwWRAkjVoTCddYEkGYn606GEt4huUYdaozB7A.jpg?auto=webp&s=b34e8f14f62739c1a304ab71d81afe7e982927d2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzahgt/alibabas_ai_tool_to_improve_efficiency_of_chinas/",
          "author": null,
          "description": "submitted by    /u/mr_j_b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzahgt/alibabas_ai_tool_to_improve_efficiency_of_chinas/",
          "publishedOn": "2022-04-08T18:50:44.000Z",
          "wordCount": 112,
          "title": "Alibaba’s AI tool to improve efficiency of China’s waste-to-energy plants",
          "imageUrl": "https://external-preview.redd.it/64MBzPrtFfHw65CUOZLfttJor5oH-vvUQB2ahAu5Jys.jpg?auto=webp&s=18a956e62646aef3240c558fea9b1b6696934e57"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz9gyq/best_gan_for_tabulardata/",
          "author": null,
          "description": "What in your opinion is the best GAN for tabular-data. Please include any references if you have any.\n    submitted by    /u/ily_jk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz9gyq/best_gan_for_tabulardata/",
          "publishedOn": "2022-04-08T18:03:19.000Z",
          "wordCount": 106,
          "title": "Best GAN for Tabular-data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz8xvn/supercharged_ui_for_mlflow/",
          "author": null,
          "description": "Hi guys, we've built a plugin that seamlessly reads MLflow logs and provides a beautiful UI to compare multiple runs with just a few clicks. You can:\n  \nfilter runs with a super versatile fully pythonic search\n group and aggregate your metrics / images\n  \nWe are trying make it work seamlessly with MLflow and complement its other awesome features 🎉\n Here is more info about it https://aimstack.io/aimlflow Would love your feedback!!\n    submitted by    /u/ManeSa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz8xvn/supercharged_ui_for_mlflow/",
          "publishedOn": "2022-04-08T17:38:40.000Z",
          "wordCount": 159,
          "title": "Supercharged UI for MLflow",
          "imageUrl": "https://external-preview.redd.it/BSsU0ETo7_xF2yrAvvkhPwSBIDUw-Stt-CAobPA4VzI.jpg?auto=webp&s=c909beb5d4800b279075a4941f4decbcb2614adf"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz8izm/takeaways_from_3_years_working_in_machine_learning/",
          "author": null,
          "description": "submitted by    /u/elcric_krej  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz8izm/takeaways_from_3_years_working_in_machine_learning/",
          "publishedOn": "2022-04-08T17:19:30.000Z",
          "wordCount": 106,
          "title": "Takeaways From 3 Years Working In Machine Learning",
          "imageUrl": "https://external-preview.redd.it/2saqmO0fa_NBQMiR3s4MXN3UOE3VQ9YbXCvmjtj4kQM.jpg?auto=webp&s=e0c6e5e91b619935307ceb9f2f15d940345a3d35"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz5xqi/openai_s_new_model_dalle_2_is_amazing/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz5xqi/openai_s_new_model_dalle_2_is_amazing/",
          "publishedOn": "2022-04-08T15:21:22.000Z",
          "wordCount": 168,
          "title": "OpenAI 's new model DALL·E 2 is amazing!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz31sv/the_ai_in_a_jar/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz31sv/the_ai_in_a_jar/",
          "publishedOn": "2022-04-08T13:01:58.000Z",
          "wordCount": 97,
          "title": "The AI in a jar",
          "imageUrl": "https://external-preview.redd.it/s-kVgdMVlu2lEFarxKr4Qx6lDlC6hksQDTDl15OO8FA.jpg?auto=webp&s=12afaaa5922bdf3c336e3f08460b52a5a8eed10c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz1tbc/can_computers_learn_common_sense/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz1tbc/can_computers_learn_common_sense/",
          "publishedOn": "2022-04-08T11:54:25.000Z",
          "wordCount": 97,
          "title": "Can Computers Learn Common Sense?",
          "imageUrl": "https://external-preview.redd.it/_HnpDmSe6WGLiJPV793at05KzbITVRfCIqt7IYy-Znk.jpg?auto=webp&s=324b53c8cb621d60baa7e96cded0e9dcc3b6b99f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyyrzl/metaverse_weekly_digest_shiba_inus_metaverse/",
          "author": null,
          "description": "submitted by    /u/bent_out_of_shape_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyyrzl/metaverse_weekly_digest_shiba_inus_metaverse/",
          "publishedOn": "2022-04-08T08:23:44.000Z",
          "wordCount": 122,
          "title": "Metaverse weekly digest: Shiba Inu’s metaverse, Alibaba’s $60 million VR investment",
          "imageUrl": "https://external-preview.redd.it/wSwtyVeayWe0NbVVLnkpryWGvFBJzRMSS28BMhDuJuw.jpg?auto=webp&s=22eb8136f1bed86c6ff50bc0dfebaaddeb5e3c95"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyuzhg/meet_chestlink_the_first_autonomous_ai_medical/",
          "author": null,
          "description": "​\n https://preview.redd.it/e2q3jit3c8s81.png?width=1024&format=png&auto=webp&s=837aa6256647df6fb8777a02b04313a38428f573\n The most common diagnostic imaging test conducted in emergency rooms is chest radiography. Providing automated preliminary read helpers to physicians might speed up surgery, enhance accuracy, and lower healthcare costs.\n An artificial intelligence tool that interprets chest X-rays without the intervention of a radiologist received regulatory approval in the European Union this week, marking a first for a wholly autonomous medical imaging AI, according to ‘Oxipit‘, the developer of this tool. It’s a watershed moment for AI, and it’s more than likely to spark debate, given that radiologists have spent the last few years working to fully automate parts of their jobs.\n Continue Reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyuzhg/meet_chestlink_the_first_autonomous_ai_medical/",
          "publishedOn": "2022-04-08T04:06:41.000Z",
          "wordCount": 260,
          "title": "Meet ‘ChestLink’, The First Autonomous AI Medical Imaging Application by ‘Oxipit’ That Received CE Mark Approval in the EU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyqc1f/attend_the_2022_national_autonomous_vehicle_expo/",
          "author": null,
          "description": "Interested in the future of autonomous vehicles? Want to know more about the impacts of this technology? Join us on April 16-17th at the 2022 National Autonomous Vehicle Expo to discover the engineering, ethics, and policymaking of this emerging technology. The virtual expo consists of speaker and workshop sessions led by industry-leading companies, such as NVIDIA, Waymo, and Motional, as well as distinguished programs/organizations like MIT Beaverworks and InspiritAI. You will also have the opportunity to compete in our hackathon, where you can win a variety of cool prizes! Even if you don't participate in the hackathon, there will be free merchandise and giveaways throughout the expo! To register and/or view more information about the event, head over to avexpo.org. For hackathon-specific registration, you can visit our devpost at https://autonomous-vehicle-expo.devpost.com/. Hope to see you all there!\n ​\n https://preview.redd.it/qgfx3sv837s81.png?width=1080&format=png&auto=webp&s=ed19d68bdff274de188deaa8f4338c864943b508\n https://preview.redd.it/a4kbsrv837s81.png?width=1080&format=png&auto=webp&s=6a19347b708d822d8dca226beb82cbdc73ffbb87\n https://preview.redd.it/s9nghsv837s81.png?width=1080&format=png&auto=webp&s=cf32712b9985564b455be53e02fd00589725ad2c\n    submitted by    /u/avexpo22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyqc1f/attend_the_2022_national_autonomous_vehicle_expo/",
          "publishedOn": "2022-04-07T23:55:18.000Z",
          "wordCount": 241,
          "title": "Attend the 2022 National Autonomous Vehicle Expo (April 16-17th)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyjqk5/resources_about_cognitive_theories/",
          "author": null,
          "description": "Hi! I am new to the community, and was wondering what y'all's favorite resources were to learn about cognitive theories and how they will shape future AI advancements.\n YouTube channels would be great.\n    submitted by    /u/Apprehensive-Candy97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyjqk5/resources_about_cognitive_theories/",
          "publishedOn": "2022-04-07T18:43:22.000Z",
          "wordCount": 120,
          "title": "Resources about cognitive theories",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyj9ds/andrew_yang_yuval_noah_harari_tech_public_policy/",
          "author": null,
          "description": "submitted by    /u/john133435  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyj9ds/andrew_yang_yuval_noah_harari_tech_public_policy/",
          "publishedOn": "2022-04-07T18:21:59.000Z",
          "wordCount": 124,
          "title": "Andrew Yang & Yuval Noah Harari: Tech, Public Policy & the Future of Work",
          "imageUrl": "https://external-preview.redd.it/-eHsRlpM-iTZ_A2GIEIghCAiDW3-xumI5qIeKFrOhcA.jpg?auto=webp&s=2708222de94df7b41c088fc2a6893821aa717cf4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyi240/ai_news_ai_news_why_ai_made_40000_new_chemical/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyi240/ai_news_ai_news_why_ai_made_40000_new_chemical/",
          "publishedOn": "2022-04-07T17:26:27.000Z",
          "wordCount": 148,
          "title": "AI News | AI News | Why AI Made 40,000 New Chemical Weapons Compounds in 6 Hours | Cancer Treatment AI Breakthrough",
          "imageUrl": "https://external-preview.redd.it/5IY5FIg3jerCnh_-4mHCZpnygqUFqfRHY_lHJwPCcUE.jpg?auto=webp&s=40bdf481da123c5e15ca1ec99d661f1fb7f05f48"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tygoz1/how_to_create_a_bot_for_a_existing_game/",
          "author": null,
          "description": "I wanna create a bot for a game which basically is: get resources, craft itens, sell then.\n The problem is, some itens has different qualities, and I wanna automatize this process, to identify the good stuff to keep, and sell the bad stuff.\n What's the best way to do that? \n I work with desktop systems, so i'm not familiar with this kind of stuff, but I usually read about python and some frameworks, what do you guys recommend me to start?\n    submitted by    /u/AbbathDoom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tygoz1/how_to_create_a_bot_for_a_existing_game/",
          "publishedOn": "2022-04-07T16:21:40.000Z",
          "wordCount": 335,
          "title": "How to create a BOT for a existing game?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyfdj8/dalle_2_a_new_ai_system_to_create_realistic/",
          "author": null,
          "description": "submitted by    /u/alien128  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyfdj8/dalle_2_a_new_ai_system_to_create_realistic/",
          "publishedOn": "2022-04-07T15:20:24.000Z",
          "wordCount": 130,
          "title": "DALL·E 2: A new AI system to create realistic images and art from natural language commands",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty99as/what_are_other_technology_fields_that_is_good_to/",
          "author": null,
          "description": "Hello! What do you guys think are other \"technology\" fields that would be good to study with AI? It is okay as long as it is \"tech.\" What would be the tech field that would be beneficial in the future? My goal is to make a self-aware AI (AGI). I was always fascinated about AI since my childhood, that's why I'm going to pursue this field. Also, I am currently studying Game Development to make a VR Game that hopefully will have humanlike AI in it. I have read a LOT of articles about the future of AI, and Cybersecurity keeps popping up because superintelligent AI needs to be CONTROLLED from hackers (based on the articles) otherwise it is over. What do you guys think would be the tech field that will bring the most changes in the future?\n    submitted by    /u/ThatOneEpicAstronaut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty99as/what_are_other_technology_fields_that_is_good_to/",
          "publishedOn": "2022-04-07T09:31:30.000Z",
          "wordCount": 275,
          "title": "What are other \"technology\" fields that is good to learn while studying AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty964g/does_this_artificial_intelligence_think_like_a/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty964g/does_this_artificial_intelligence_think_like_a/",
          "publishedOn": "2022-04-07T09:25:11.000Z",
          "wordCount": 101,
          "title": "Does this artificial intelligence think like a human?",
          "imageUrl": "https://external-preview.redd.it/l23vR6ThpiK4uUHbQrBcH-Kaz1FrX79RSqmf1RzjQn8.jpg?auto=webp&s=e84fea5dc943b401452b9f67f6d5f7ea9aa084b8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty95tr/artificial_intelligence_courses_for_healthcare/",
          "author": null,
          "description": "We keep on hearing about how artificial intelligence and machine learning is going to revolutionise Medicine.\n But what’s hype, and what’s realistic? And how can you get involved?\n The first step is to understand the technology - where it’s well-suited to healthcare (and where it isn’t).\n When it comes to health care, especially for life and death situations AI has made things very easy for us. However, it is still expected to drastically change the way medicine is practised. It will also replace the surgeries done by the doctors with the surgeries done using Artificial intelligence, making diagnosing complex diseases, genetic issues and many other health problems extremely easy in the future. Here are the best Artificial Intelligence courses for healthcare you can learn in 2022.\n    submitted by    /u/maneesh123456  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty95tr/artificial_intelligence_courses_for_healthcare/",
          "publishedOn": "2022-04-07T09:24:33.000Z",
          "wordCount": 214,
          "title": "Artificial intelligence Courses for Healthcare",
          "imageUrl": "https://external-preview.redd.it/F8zuI6MfVoolLvEryhwilLWSt_X5dg2Oye1ZyG76oHw.jpg?auto=webp&s=97b0642575d5568ab88f1264bc40946336b19a29"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty4l6x/artificial_nightmares_smithing_stone_6_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty4l6x/artificial_nightmares_smithing_stone_6_clip/",
          "publishedOn": "2022-04-07T04:08:48.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Smithing Stone 6 || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/zJjOAjFsO1YezLG11RTXfpfh_8pVo6Ikq_lkMbQlhOw.jpg?auto=webp&s=08b1756429ce5fbe22334573410286405f46f2bf"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty48ka/introducing_mindspore_16_new_features/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty48ka/introducing_mindspore_16_new_features/",
          "publishedOn": "2022-04-07T03:49:17.000Z",
          "wordCount": 121,
          "title": "Introducing MindSpore 1.6 New Features",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty3xvn/openais_dalle_2_texttoimage_generation_explained/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty3xvn/openais_dalle_2_texttoimage_generation_explained/",
          "publishedOn": "2022-04-07T03:32:17.000Z",
          "wordCount": 133,
          "title": "OpenAI's DALL·E 2 ! Text-to-Image Generation Explained",
          "imageUrl": "https://external-preview.redd.it/rKdS2sPjN8DCz_eI7kKnr8THMGpU-4XNJ-O-3DnTl3k.jpg?auto=webp&s=48885ad8dc953fa981580e322a249dfa69e672be"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty3vz2/how_do_i_get_into_the_field_of_ai_policy_and/",
          "author": null,
          "description": "I've read online that a career in AI policy and strategy is heavily needed and is actually ranked as the number one problem in the future by 80,000 hours. I am choosing which undergraduate degree to pursue in the fall and I'm not sure the best pathway to pursue to work in this field in an extremely high level position. an economics degree? Computer science degree? AI degree? should I pursue one subject until I get a PhD in it or mix with other degrees/certificates? is it a straight forward pathway focused on one subject where I only work in one subject field or is it necessary to pursue and work in other fields as well, what are the typical steps? Also if there is anything else that would be helpful on the pathway or anything you would recommend please let me know.\n    submitted by    /u/Key-Lawyer-7586  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty3vz2/how_do_i_get_into_the_field_of_ai_policy_and/",
          "publishedOn": "2022-04-07T03:29:19.000Z",
          "wordCount": 466,
          "title": "How do I get into the field of AI policy and strategy?",
          "imageUrl": "https://external-preview.redd.it/JwNKrNgJbmE7Fq3FDlTdS9n07RsBkdIR7dBm6TknSOE.jpg?auto=webp&s=d8a123b108ec250c019781a9b496c0fea213935c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty030w/five_google_chrome_extensions_that_every_machine/",
          "author": null,
          "description": "submitted by    /u/MLtinkerer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty030w/five_google_chrome_extensions_that_every_machine/",
          "publishedOn": "2022-04-07T00:09:43.000Z",
          "wordCount": 151,
          "title": "Five Google Chrome Extensions that every Machine Learning / Data Science professional should know about 🚀💯",
          "imageUrl": "https://external-preview.redd.it/pQWEkHL0yuI56NExHEWuUk7pZjyZxJ0GeDAJw4y8OoI.jpg?auto=webp&s=3b674865aa640d024a03eeb21c115f118d93e06e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txulan/weekly_china_ai_news_slime_robot_grabs_swallowed/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txulan/weekly_china_ai_news_slime_robot_grabs_swallowed/",
          "publishedOn": "2022-04-06T19:51:27.000Z",
          "wordCount": 145,
          "title": "Weekly China AI News: Slime Robot Grabs Swallowed Objects; SenseTime Revenue Grows Despite $2.7B Net Loss; Transformer Architecture Search Without Training",
          "imageUrl": "https://external-preview.redd.it/IkLvOUvSjJWLBvbCXp6nkb9puKkxjHwtZBnpffQoGWY.jpg?auto=webp&s=228647c6ab8f7290672fe31ab667eedf13a57969"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txtfc5/reading_the_tea_leaves_expert_endusers_explaining/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txtfc5/reading_the_tea_leaves_expert_endusers_explaining/",
          "publishedOn": "2022-04-06T18:58:03.000Z",
          "wordCount": 109,
          "title": "Reading the Tea Leaves: Expert End-Users Explaining the Unexplainable",
          "imageUrl": "https://external-preview.redd.it/wnVaar4ZXR3zqeMsXegEzJEPVdp1PkLFsHJagJ249DM.jpg?auto=webp&s=53c299a85d48eb7bedf6e5ec47ca846a5c52c38f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txt853/how_do_we_know_that_ai_hasnt_already_taken_over/",
          "author": null,
          "description": "submitted by    /u/Individual-Fly-610  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txt853/how_do_we_know_that_ai_hasnt_already_taken_over/",
          "publishedOn": "2022-04-06T18:49:06.000Z",
          "wordCount": 634,
          "title": "How do we know that A.I hasn't already taken over our worlds ? How do we know this isn't the matrix ? #simulation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txqh23/dalle_2/",
          "author": null,
          "description": "submitted by    /u/roblox22y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txqh23/dalle_2/",
          "publishedOn": "2022-04-06T16:45:25.000Z",
          "wordCount": 81,
          "title": "DALL·E 2",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txl7aq/learn_how_gans_work_with_a_cool_toonify_example/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txl7aq/learn_how_gans_work_with_a_cool_toonify_example/",
          "publishedOn": "2022-04-06T12:37:59.000Z",
          "wordCount": 109,
          "title": "Learn how GANs work with a cool Toonify example!",
          "imageUrl": "https://external-preview.redd.it/wn4380KIquPfpz8kvj0TNgHlT42uU-rZ_wdLCjVqQuU.jpg?auto=webp&s=0201632198505c9f0748c4f8646d6e4557e44ea7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txjowl/artificial_intelligence_machine_learning_and_the/",
          "author": null,
          "description": "submitted by    /u/aair_x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txjowl/artificial_intelligence_machine_learning_and_the/",
          "publishedOn": "2022-04-06T11:10:10.000Z",
          "wordCount": 122,
          "title": "Artificial Intelligence, Machine Learning and the Higgs boson - Live talk with Dr. David Rousseau",
          "imageUrl": "https://external-preview.redd.it/OSapOm3OaEUTvROlB59djlVRlsEHukiodQR08e6Bv9A.jpg?auto=webp&s=0e2022382fc9b816e0727c2dbaaaa8e4f782d305"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txelh6/what_are_your_thoughts_about_ai_teachers/",
          "author": null,
          "description": "submitted by    /u/curiosityVeil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txelh6/what_are_your_thoughts_about_ai_teachers/",
          "publishedOn": "2022-04-06T05:12:46.000Z",
          "wordCount": 152,
          "title": "What are your thoughts about AI teachers?",
          "imageUrl": "https://external-preview.redd.it/80zTz2GSqxkIcAo531n58iOibUJoLUsjIYse2G5B-Gg.jpg?auto=webp&s=e57005bacbf4e2da807f32d3456669927d952049"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txd3gn/heres_an_intuitive_explanation_to_singular_value/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txd3gn/heres_an_intuitive_explanation_to_singular_value/",
          "publishedOn": "2022-04-06T03:43:32.000Z",
          "wordCount": 144,
          "title": "Here's an intuitive explanation to Singular Value Decomposition. 👇",
          "imageUrl": "https://external-preview.redd.it/yEZqz6bdYi9OxMbxSAun-NOOyBiIEWi0hgButp5s0Bc.jpg?auto=webp&s=7501076a2d95650e0f1222b249a18b18ee508c2e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx99v0/artificial_nightmares_beauty_parlor_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx99v0/artificial_nightmares_beauty_parlor_clip_guided/",
          "publishedOn": "2022-04-06T00:21:20.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Beauty Parlor || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/uIXIo-JN5IPR5kMQLxCCW6I2UuSHT9uE8Y0Y2rzt8_A.jpg?auto=webp&s=eeb8b67dbaac0c8d18c931376cd666f5b9c11d4b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx7x0d/last_week_in_ai_ai_improves_algae_for_biofuel_and/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx7x0d/last_week_in_ai_ai_improves_algae_for_biofuel_and/",
          "publishedOn": "2022-04-05T23:13:43.000Z",
          "wordCount": 142,
          "title": "Last Week in AI: AI improves algae for biofuel and carbon capture, more AI decision-making in the military, and more!",
          "imageUrl": "https://external-preview.redd.it/n9aJP_9oQD2EMA4IrahetlrzK7vnz504KANDXrSuY8E.jpg?auto=webp&s=b090eda31ad16112cde4e1bb014a8a48270dc43e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx2gbr/researchers_from_allen_institute_for_ai_introduce/",
          "author": null,
          "description": "We humans navigate the environment using all of our senses. Allen Institute researchers propose MERLOT Reserve, a model that learns to represent videos over time and across several modalities, including audio, subtitles, and video frames. It was trained using a new learning objective and more than 20 million YouTube videos.\n MERLOT Reserve is a unique, cutting-edge methodology for solving video-related inquiries. MERLOT Reserve can dependably choose the correct answer from a selection of multiple-choice answers when given a video and a question. This forecast is made by MERLOT Reserve jointly reasoning over the visual frames of the video, the video subtitles, and the audio in the movie.\n Continue reading this cool research update from AI2\n Paper: https://arxiv.org/pdf/2201.02639.pdf\n Demo: https://merlot-reserve.apps.allenai.org/\n Project: https://rowanzellers.com/merlotreserve/\n Github: https://github.com/rowanz/merlot\\_reserve\n ​\n https://preview.redd.it/031i6ty6err81.png?width=1920&format=png&auto=webp&s=299569e12160eb991f35a2c6b41c5758ff027235\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx2gbr/researchers_from_allen_institute_for_ai_introduce/",
          "publishedOn": "2022-04-05T19:08:12.000Z",
          "wordCount": 241,
          "title": "Researchers From Allen Institute for AI Introduce ‘MERLOT Reserve’: A Novel Multimodal Video Question Answering Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx1gpx/endlessvn_open_alpha_today/",
          "author": null,
          "description": "submitted by    /u/roblox22y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx1gpx/endlessvn_open_alpha_today/",
          "publishedOn": "2022-04-05T18:24:46.000Z",
          "wordCount": 89,
          "title": "EndlessVN open alpha today",
          "imageUrl": "https://external-preview.redd.it/hzTGk_919JT_ol9WPARzYnUdu27B--ckWm5Gjh163Ns.jpg?auto=webp&s=1500dda8e3ecebf6daea2efb342f0a0f82f065fe"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twvsua/ai_meets_quantum_technology_in_new_google_spinoff/",
          "author": null,
          "description": "submitted by    /u/allaboutcircuits  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twvsua/ai_meets_quantum_technology_in_new_google_spinoff/",
          "publishedOn": "2022-04-05T14:08:38.000Z",
          "wordCount": 134,
          "title": "AI Meets Quantum Technology in New Google Spinoff, Sandbox AQ - News",
          "imageUrl": "https://external-preview.redd.it/Csqi5x9oFEPbU-NX_b014QpOo695w0-f9eoDc5vYBpc.jpg?auto=webp&s=720fb93dbbe0e2b3c64d730b52889606b5e60919"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twrsgf/best_undergraduate_major_besides_computer_science/",
          "author": null,
          "description": "Hi, all. I got accepted into my top choice of college as an undecided major. Recently, I have decided to pursue artificial intelligence! Unfortunately, it is near impossible to transfer into computer science at my particular university. I was wondering if I can still pursue AI as a career if I complete one of the following majors:\n -Mathematics\n -Information or Data Science\n -Statistics\n -Linguistics\n Additionally, I could pursue one of these and minor in another. I should be able to minor in computer science as well if necessary. Hopefully, my choice of major would allow me to pursue research or an internship in artificial intelligence. I am willing to take additional summer courses and pursue relevant certifications to ensure that I am up to par with my computer science colleagues. \n (posted on behalf of a family member)\n    submitted by    /u/runelagoon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twrsgf/best_undergraduate_major_besides_computer_science/",
          "publishedOn": "2022-04-05T10:26:35.000Z",
          "wordCount": 674,
          "title": "Best undergraduate major besides computer science for pursuing a career in artificial intelligence?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twqf43/comparing_old_and_new_ai_voices_from_replica/",
          "author": null,
          "description": "submitted by    /u/autumns  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twqf43/comparing_old_and_new_ai_voices_from_replica/",
          "publishedOn": "2022-04-05T08:47:46.000Z",
          "wordCount": 116,
          "title": "Comparing old and new AI voices from Replica Studios (new in second half)",
          "imageUrl": "https://external-preview.redd.it/sXhx5sJMKQOeW3d6yJH5Y3x-xzEsRRd4Vlsw9kNMAEQ.jpg?auto=webp&s=f135eef5941ce2927e1b7835cf2f5f32bbc26027"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twmyc3/superres_modelprogram_comparison/",
          "author": null,
          "description": "I upscaled an image with a few different superres models and programs, pick your favorite!\n https://files.botbox.dev/superrestestcollage.png\n Because of how reddit is, I can't make this as a poll, so comment your pick.\n Animated original version: https://www.youtube.com/watch?v=zRaTwVuqd70 (I will also make an animated version upscaled with the most voted model/program)\n    submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twmyc3/superres_modelprogram_comparison/",
          "publishedOn": "2022-04-05T04:50:22.000Z",
          "wordCount": 131,
          "title": "Super-res model/program comparison",
          "imageUrl": "https://external-preview.redd.it/0b-KM1fMHQlvxq8AaZ1Yoz4s8d9vlfkaCTjKSFHSx5I.jpg?auto=webp&s=00cf51afd6fc6d339a19830c02dd07831a4dd112"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twl2bd/solo_voiceovers/",
          "author": null,
          "description": "I am looking for something to change my voice in a way that is more satisfactory and more convincingly varied than what simple voice modulation software can achieve and as cheaply as is possible (preferably free).\n Use case: I have been working on an animated movie to which I am the sole contributor. Though I have been putting it off while looking for an appropriate solution, the time has come to voice my various characters, who are a range of ages, both male and female. For several reasons, I am interested in voicing them all myself while doing the facial motion captures as well. What I am in need of is, essentially, something that does exactly what Respeecher does, but without the $200/month sub fee. I would love to be in a position to simply pay them what they are asking for in exchange…",
          "link": "https://www.reddit.com/r/artificial/comments/twl2bd/solo_voiceovers/",
          "publishedOn": "2022-04-05T03:02:48.000Z",
          "wordCount": 508,
          "title": "solo voiceovers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twkptb/artificial_nightmares_frenzied_flame_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twkptb/artificial_nightmares_frenzied_flame_clip_guided/",
          "publishedOn": "2022-04-05T02:44:46.000Z",
          "wordCount": 126,
          "title": "Artificial Nightmares: Frenzied Flame || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/Ou-X9gePzH_R1p1xZ0_LmlSuj8KLO-kGZaJHgIJfVSE.jpg?auto=webp&s=bd8596715f1ab78a9626534ffc61ae623f7b1af3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twjoqd/ai_that_takes_multiple_songs_as_input_and_then/",
          "author": null,
          "description": "I have been searching for a music AI that takes input as mp3 or midi files, yet haven't been successful yet. Is there such a thing? If not, is such a thing feasible?\n    submitted by    /u/16pxl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twjoqd/ai_that_takes_multiple_songs_as_input_and_then/",
          "publishedOn": "2022-04-05T01:52:00.000Z",
          "wordCount": 402,
          "title": "AI that takes multiple songs as input, and then generates a similar song or song with similar elements?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw91fr/microsoft_researchers_introduce_jigsaw_an_ai_tool/",
          "author": null,
          "description": "GPT-3, Codex, and other sizable pre-trained language models can be adjusted to create code from natural language descriptions of programmer intent. Every developer in the world might benefit from these automated models, which have the potential to increase productivity. However, because the models may fail to understand program semantics, the quality of the generated code cannot be guaranteed.\n Microsoft researchers introduce Jigsaw, a new tool that can help these big language models perform better. Jigsaw is a Python Pandas API code generator that accepts multi-modal inputs. Jigsaw uses post-processing techniques to decipher the syntax and semantics of programs and then uses user feedback to improve future performance.\n Continue Reading\n Paper: https://arxiv.org/pdf/2112.02969.pdf\n Dataset: https://github.com/microsoft/JigsawDataset\n ​\n https://i.redd.it/x223r5qu0kr81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw91fr/microsoft_researchers_introduce_jigsaw_an_ai_tool/",
          "publishedOn": "2022-04-04T18:21:08.000Z",
          "wordCount": 263,
          "title": "Microsoft Researchers Introduce ‘Jigsaw’: An AI Tool To Augment Large Language Models (GPT-3, Codex, etc.) By Deploying Post-Processing Techniques That Understand The Programs’ Syntax And Semantics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw8fae/pathways_language_model_palm_scaling_to_540/",
          "author": null,
          "description": "submitted by    /u/nick7566  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw8fae/pathways_language_model_palm_scaling_to_540/",
          "publishedOn": "2022-04-04T17:56:24.000Z",
          "wordCount": 121,
          "title": "Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance",
          "imageUrl": "https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?auto=webp&s=d45552298a94c0bc0e771853afe179cbb0e3f951"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw79so/generative_aialex_grey_xxxxxoooooooo_disco/",
          "author": null,
          "description": "submitted by    /u/JoshGrambo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw79so/generative_aialex_grey_xxxxxoooooooo_disco/",
          "publishedOn": "2022-04-04T17:09:23.000Z",
          "wordCount": 105,
          "title": "Generative AI+Alex Grey = xxxxxoooooooo (Disco Diffusion)",
          "imageUrl": "https://external-preview.redd.it/5szgyleyhmZQatLGQQc0tWNKXYQjmomMBSzW55VOY2I.jpg?auto=webp&s=f943d685a85e58d5f8cb7371f25e11e3763f8f34"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw6zcv/uipath_extract_tables_from_pdf_use_case_pdf_table/",
          "author": null,
          "description": "submitted by    /u/Cristi_UiPath  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw6zcv/uipath_extract_tables_from_pdf_use_case_pdf_table/",
          "publishedOn": "2022-04-04T16:58:01.000Z",
          "wordCount": 111,
          "title": "UiPath extract Tables from PDF (use case) (PDF table)",
          "imageUrl": "https://external-preview.redd.it/XdStN-2Ltm4rlONpMIvCknd-rKvCteajYNUFIXrL__E.jpg?auto=webp&s=3b4ef0b9d4d13d1bb16a3f84865d7884a09eeb8d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw1nzj/new_rl_technique_achieves_superior_performance_in/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw1nzj/new_rl_technique_achieves_superior_performance_in/",
          "publishedOn": "2022-04-04T13:11:26.000Z",
          "wordCount": 101,
          "title": "New RL technique achieves superior performance in control tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvz2cs/metrics_matthews_correlation_coefficient/",
          "author": null,
          "description": "submitted by    /u/TheTesseractAcademy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvz2cs/metrics_matthews_correlation_coefficient/",
          "publishedOn": "2022-04-04T10:51:05.000Z",
          "wordCount": 94,
          "title": "Metrics: Matthew's correlation coefficient",
          "imageUrl": "https://external-preview.redd.it/K79luiNVO7cDl4UNZslrIpsFYJBu9pe6zLP_bpNmEVU.jpg?auto=webp&s=b4b8dcad0ffee30fc3cd5116872c85a245b67edd"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvy3mp/12_graphs_that_explain_the_state_of_ai_in_2022/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvy3mp/12_graphs_that_explain_the_state_of_ai_in_2022/",
          "publishedOn": "2022-04-04T09:49:07.000Z",
          "wordCount": 136,
          "title": "12 Graphs That Explain the State of AI in 2022",
          "imageUrl": "https://external-preview.redd.it/rxu_HYqvBcCfZOmrTEaxXK9YViKM0KioByJVsMvy31k.jpg?auto=webp&s=366d3c7f395840f2f28a0d32633778e1dc2e03c0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvx311/what_is_whatsapp_business_api_how_can_it_help/",
          "author": null,
          "description": "submitted by    /u/mihircontra20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvx311/what_is_whatsapp_business_api_how_can_it_help/",
          "publishedOn": "2022-04-04T08:38:30.000Z",
          "wordCount": 117,
          "title": "What is WhatsApp Business API? How can it Help your Business?",
          "imageUrl": "https://external-preview.redd.it/dNWZt5KgY2MqG0CICD8AVcKpMu4QVpc2Y1jPRh4tVfc.jpg?auto=webp&s=544310fa5704bad1ded6821fe5bc364c99358791"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvqnw5/voice_copyingcloning/",
          "author": null,
          "description": "Hi all,\n Don't know if this is the right subreddit, but here goes....\n I'm looking to voice clone my father. He has passed recently, and despite being difficult for all, it's been especially hard for my mother, married early to him and together for 50 years. Her birthday is coming up, I'd love to be able to create a 5-10 second sound byte of him for her.\n Fortunately, there's likely to be lots of his voice recording around, part of his job was speaking and instructing.\n So, is there any way this is possible, to be done without great difficulty, and produce an accurate result?\n I am understanding the moralities of crafting something with his deceased voice. I thought about it quite a bit. However, I feel that it's for his soulmate who's struggling, who he had no qualms spending his life with and travelling abroad with, spent his last days with. I'm certain he would want to help.\n    submitted by    /u/mininggotboring  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvqnw5/voice_copyingcloning/",
          "publishedOn": "2022-04-04T02:17:04.000Z",
          "wordCount": 300,
          "title": "Voice copying/cloning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvd9w0/ai_news_als_brain_computer_interface_1_year_human/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvd9w0/ai_news_als_brain_computer_interface_1_year_human/",
          "publishedOn": "2022-04-03T16:31:19.000Z",
          "wordCount": 145,
          "title": "AI News | ALS Brain Computer Interface 1 Year Human Trial Results | Skin Cancer Detection | New IBM AI Hardware",
          "imageUrl": "https://external-preview.redd.it/V1rfHFG8YhKM7LmCEZ3wsL5vptilPYrVjTDo-LcpRD4.jpg?auto=webp&s=4daa3bb70bc2ec7d33bdcd71f74b5d0bb0799e16"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvctg8/your_next_teacher_will_be_a_machine_why_the/",
          "author": null,
          "description": "submitted by    /u/itsallshit-eatup  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvctg8/your_next_teacher_will_be_a_machine_why_the/",
          "publishedOn": "2022-04-03T16:11:21.000Z",
          "wordCount": 126,
          "title": "Your Next Teacher Will be a Machine: Why the Future of Education is Automation",
          "imageUrl": "https://external-preview.redd.it/6esqFIrmdOYU6dYfuQXctFxZQK0hWvaxAMXQLVewc_w.jpg?auto=webp&s=580098cc5f338bdbc295957629b74a03b2be7209"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvaoe1/hi_im_wondering_if_anyone_could_help_me/",
          "author": null,
          "description": "Im a 19yo guy from Argentina that studies system ingeneer, I like my career, beeing an ingeneer is great, but coding and AI is greater, Im tired of courses like Free code academy, or basics things, im looking for a more professional, useful and deeper courses, that will really teach me, im currently with python(pandas,numpy,matplotlib,tensorflow) basics, and wanna to be better in that field that i love❤\n    submitted by    /u/Sasulanda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvaoe1/hi_im_wondering_if_anyone_could_help_me/",
          "publishedOn": "2022-04-03T14:36:41.000Z",
          "wordCount": 167,
          "title": "Hi!, Im wondering if anyone could help me🇦🇷🇦🇷",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tv829c/active_nonml_research_areas/",
          "author": null,
          "description": "What are the most active non-ML/statistical research areas in AI?\n Are there any recent books published that give an overview of such areas?\n Seems like AI is now either ML or people saying that ML won’t work, but vague on alternatives.\n    submitted by    /u/spookyplatypus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tv829c/active_nonml_research_areas/",
          "publishedOn": "2022-04-03T12:22:42.000Z",
          "wordCount": 185,
          "title": "Active non-ML research areas?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tv133y/heard_about_github_copilot_now_meet_salesforces/",
          "author": null,
          "description": "Imagine being able to tell a machine to write an app simply by telling it what the app does. As far-fetched as it may appear, this scenario is already a reality.\n According to Salesforce AI Research, conversational AI programming is a new paradigm that brings this vision to life, thanks to an AI system that builds software.\n Introducing CodeGen: Creating Programs from Prompts\n The large-scale language model, CodeGen, which converts simple English prompts into executable code, is the first step toward this objective. The person doesn’t write any code; instead, (s)he describes what (s)he wants the code to perform in normal language, and the computer does the rest.\n Conversational AI refers to technologies that allow a human and a computer to engage naturally through a conversation. Chatbots, voice assistants, and virtual agents are examples of conversational AI.\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.13474.pdf\n Github: https://github.com/salesforce/CodeGen\n https://i.redd.it/dbyba3dct8r81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tv133y/heard_about_github_copilot_now_meet_salesforces/",
          "publishedOn": "2022-04-03T04:40:09.000Z",
          "wordCount": 692,
          "title": "Heard about Github Copilot? Now Meet Salesforce's 'CodeGen’ : An AI Model That Turns Simple Natural Language Requests Into Executable Code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tuu59j/building_trust_with_responsible_ai/",
          "author": null,
          "description": "Artificial Intelligence is being used in almost every aspect of life. AI symbolizes growth and productivity in the minds of some, but it is raising questions as well on the fairness, privacy, and security of these systems. Many legitimate issues exist, including biased choices, labor replacement, and a lack of security. When it comes to robots, this is very frightening. Self-driving automobiles, for example, can cause injury or death if they make mistakes. Responsible AI addresses these difficulties and makes AI systems more accountable.\n Responsible AI should fulfill the following aims:\n  \nInterpretability: We obtain an explanation for how a model makes predictions when we interpret it. An AI system makes predictions for a user. Even if these selections are correct, a user is likely to seek an explanation. Responsible AI can describe how we create interpretable models.\n Fairness: AI systems have the potential to make judgments that are biased towards particular groups of people. Bias in the training data is the source of this bias. The easier it is to assure fairness and rectify any bias in a model, the more interpretable it is. As a result, we need a Responsible AI framework to explain how we evaluate fairness and what to do if a model makes unjust predictions.\n Safety and Security: AI systems aren’t deterministic. When confronted with new situations, they are prone to making poor choices. The systems can even be tampered with to make unwise decisions. Therefore, we need to ensure safety and security in these systems.\n Data Governance: The data used must be of high quality. If the data used by AI has errors, the system may make wrong decisions.\n  \nContinue Reading The Article Here\n ​\n https://preview.redd.it/9iivp31ir6r81.png?width=1024&format=png&auto=webp&s=207409694b68a1e985ad1dfcf3b466ac25916da2\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tuu59j/building_trust_with_responsible_ai/",
          "publishedOn": "2022-04-02T21:46:33.000Z",
          "wordCount": 364,
          "title": "Building Trust with Responsible AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tusmv0/its_unbelievable_what_ml_can_do_discorife_7hr/",
          "author": null,
          "description": "submitted by    /u/JoshGrambo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tusmv0/its_unbelievable_what_ml_can_do_discorife_7hr/",
          "publishedOn": "2022-04-02T20:38:58.000Z",
          "wordCount": 114,
          "title": "It's unbelievable what ML can do! Disco+RIFE= 7hr Colab Run...",
          "imageUrl": "https://external-preview.redd.it/uW0ZWgsocgrNGmz-a2bOQXLTJj-XcskLyyJib0rVBKk.jpg?auto=webp&s=12c01fbc8154b1bcfbf3c618410871aaeebc1d8c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tuov1l/creating_a_chatbot_with_transformers_and_gradio/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tuov1l/creating_a_chatbot_with_transformers_and_gradio/",
          "publishedOn": "2022-04-02T17:53:29.000Z",
          "wordCount": 96,
          "title": "Creating A Chatbot with transformers and Gradio",
          "imageUrl": "https://preview.redd.it/e3ush415m5r81.png?auto=webp&s=0527e497aa1008fdf2599268f3183415a4e49cff"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tunb06/researchers_develop_parking_analytics_framework/",
          "author": null,
          "description": "Artificial Intelligence and deep learning in video analytics are gaining popularity. It has enabled a wide range of industrial applications, including surveillance and public safety, robotics perception, medical intervention, and facial recognition. According to Markets & Markets, the global market for video analytics was valued at USD 5.9 billion in 2021 and is predicted to reach USD 14.9 billion by 2026.\n Unmanned aerial vehicles (UAVs) have also enabled a wide range of video analytics applications (e.g., aerial surveys) since they provide aerial views of the environment, allowing for collecting aerial photos and processing with deep learning algorithms. Parking analytics is one of these critical smart city applications that uses deep learning and UAVs to collect real-time data and analyze it in order to maximize parking revenue, enhance parking resource allocations, and better manage public space.\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.07792.pdf\n ​\n https://i.redd.it/u5th7z0ja5r81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tunb06/researchers_develop_parking_analytics_framework/",
          "publishedOn": "2022-04-02T16:48:24.000Z",
          "wordCount": 258,
          "title": "Researchers Develop Parking Analytics Framework Using Deep Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tuelaw/how_will_ai_impact_games/",
          "author": null,
          "description": "submitted by    /u/GravermanYT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tuelaw/how_will_ai_impact_games/",
          "publishedOn": "2022-04-02T09:05:20.000Z",
          "wordCount": 97,
          "title": "How will AI impact games",
          "imageUrl": "https://external-preview.redd.it/j8cMRhk6anZDhUlXBqFPgbbvX53C1v7EzO-47DzAZks.jpg?auto=webp&s=656307351b7e3c5d84ec33d161585127491ff890"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tu4zyq/seeking_respondents_for_a_survey_about_ai_text/",
          "author": null,
          "description": "Hello! I am doing an independent (non-academic) research study about AI text generation as relates to poetry and reader interpretation. The results of the study will be presented in a YouTube video. \n I would really appreciate if some folks could take approximately 20-25 minutes to take this anonymous survey I put together. It involves reading some poems and answering questions about those poems. Thank you so much for the help! \n https://form.jotform.com/220880249866062\n    submitted by    /u/northern_frog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tu4zyq/seeking_respondents_for_a_survey_about_ai_text/",
          "publishedOn": "2022-04-01T23:42:54.000Z",
          "wordCount": 187,
          "title": "Seeking respondents for a survey about AI text generation and reader interpretation of poetry",
          "imageUrl": "https://external-preview.redd.it/v7d0tATSqpy9crLzFxjW7F5hgCsiCG0mldziRhMNIPI.jpg?auto=webp&s=2463173b2a58ca9742949bd77b0e980fa6a3595d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tu2gq4/the_tokendropping_approach_used_by_ml_researchers/",
          "author": null,
          "description": "The Pretraining of BERT-type large language models, which may scale up to billions of parameters, is essential to achieving best-in-class performance on various natural language processing (NLP) applications. However, the pretraining procedure is costly, and it has become a hurdle for the industrial deployment of big language models.\n In a research paper, researchers from Google, New York University, and the University of Maryland recommend a simple but effective “token dropping” method that drastically reduces the pretraining cost of transformer models like BERT while maintaining downstream fine-tuning performance.\n Token dropping is a technique for speeding up the pretraining of transformer models like BERT without sacrificing their performance on downstream tasks. Starting with an intermediate layer in the model, they eliminate uninteresting tokens to let the model focus on key tokens more effectively, given its limited computing resources. The model’s last layer then picks up the dropped tokens, producing full-length sequences. They use the built-in masked language modeling (MLM) loss and its dynamics to detect non-essential tokens with little computing complexity. According to their tests, this straightforward strategy decreases BERT’s pretraining cost by 25% while yielding somewhat higher overall fine-tuning performance on conventional downstream tasks.\n Continue Reading The Summary\n Paper: https://arxiv.org/pdf/2203.13240.pdf\n Github: https://github.com/tensorflow/models/tree/master/official/projects/token\\_dropping\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tu2gq4/the_tokendropping_approach_used_by_ml_researchers/",
          "publishedOn": "2022-04-01T21:46:19.000Z",
          "wordCount": 329,
          "title": "The Token-Dropping Approach Used By ML Researchers From Google and NYU Reduces BERT Pretraining Time And Cost By 25%",
          "imageUrl": "https://external-preview.redd.it/dVOlinWotMPLCgqZf5DyOLTUwr_WHlx_ZRY9Nf94v6A.jpg?auto=webp&s=7bd91c06fa85f604d1603bc57b5b6b8cda992c5c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tu0zk2/top_emerging_artificial_intelligence_use_cases/",
          "author": null,
          "description": "submitted by    /u/Visionifyai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tu0zk2/top_emerging_artificial_intelligence_use_cases/",
          "publishedOn": "2022-04-01T20:43:05.000Z",
          "wordCount": 105,
          "title": "Top emerging artificial intelligence use cases",
          "imageUrl": "https://external-preview.redd.it/nwkhz3JfoBxgf1shs6bmGimTMtKLadwCKdaup9WuJ0g.jpg?auto=webp&s=d9558bc72428176f7cdbaa409fa3f3441afa7f65"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ttxk1j/metas_new_speech_ai_can_laugh_scream_yawn_and/",
          "author": null,
          "description": "Meta unveils new research on speech AI: Machine-generated voices can now cry, laugh, yawn or make more natural small talk. \n ...\n Meta’s speech AI can now mimic emotional sounds such as laughing, yawning, or crying – which it says is important in communication to better convey the intention and context of a statement. \n ...\n the new GSML model dGSML, which is optimized for dialogs, generates more natural-sounding audio dialogs using AI agents that can pause for thought or process overlaps in conversations. \n ...\n dGSML was trained with about 2000 hours of unlabeled audio dialogues from the Fisher dataset, which contains about 16000 English-language telephone conversations. \n Source and demos: https://mixed-news.com/en/meta-new-speech-ai-can-laugh-scream-yawn/\n    submitted by    /u/Sephirio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ttxk1j/metas_new_speech_ai_can_laugh_scream_yawn_and/",
          "publishedOn": "2022-04-01T18:15:57.000Z",
          "wordCount": 258,
          "title": "Meta’s new speech AI can laugh, scream, yawn, and chit-chat",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ttvd98/oracle_releases_mysql_heatwave_ml_that_adds/",
          "author": null,
          "description": "Integrating machine learning capabilities to MySQL systems is prohibitively difficult and time-consuming. The process involves extracting data from the database and into another system to construct and deploy machine learning models. As data flows around, this strategy produces silos for applying machine learning to application data and causes latency. This results in data leakage, making the database more open to security attacks. Moreover, existing machine learning (ML) solutions lack the ability to explain why the model developers build delivers specific predictions.\n Recently, Oracle released MySQL HeatWave, the only MySQL cloud database service that supports in-database machine learning (ML). It automates the ML lifecycle and saves all trained models in the MySQL database, removing the need to migrate data or models to a machine learning tool or service. This decreases application complexity, saves costs, and increases data and model security. It produces a model with the best algorithm, features, and hyper-parameters for a specific data collection and application. \n Continue Reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ttvd98/oracle_releases_mysql_heatwave_ml_that_adds/",
          "publishedOn": "2022-04-01T16:46:17.000Z",
          "wordCount": 276,
          "title": "Oracle Releases MySQL HeatWave ML That Adds Powerful Machine Learning Capabilities to MySQL Applications",
          "imageUrl": "https://external-preview.redd.it/c7JwbAX6On_dwvaZKVvJs0f-YQBgFPWDWNkYEya2b7Q.jpg?auto=webp&s=daf6becad6b235653ca2334f30010b5db2faf9cf"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tts48e/cloudy_world_ai_art/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tts48e/cloudy_world_ai_art/",
          "publishedOn": "2022-04-01T14:32:16.000Z",
          "wordCount": 107,
          "title": "Cloudy World AI Art",
          "imageUrl": "https://external-preview.redd.it/rvVFdUL_ZqFWUdd_MlLHJEB4RYGoUWqiLZdY5sbShCA.jpg?auto=webp&s=d701c4da705fb263b73468044eedc7eb1a526c98"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tto6sd/how_chatbot_is_beneficial_in_the_retail_industry/",
          "author": null,
          "description": "By offering your clients a blended virtual, tailored, and on-the-spot conversational level of conversation - you can engage them for longer and create an interactive method of selling to them. Chatbots will be armed with Conversational AI - and powered by an in-depth understanding of the client and their past behaviors - will be able to offer the service which is most likely to suit each client.\n Retailers can take advantage of the ability to engage potential customers through virtual attendants. Along with this opportunity is a growing range of new and exciting ways to utilize chatbots within retail spaces. A lack of customer engagement through mobile messaging costs retailers around $1 trillion annually, as customers are increasingly becoming reluctant to contact mainstream outlets for recommendations due to their negative experiences, or because they have already made up their mind on what they want.\n This can be potentially overcome by utilizing Chatbots; in-store systems powered by AI that can be utilized across multiple channels, including the outlet's website and branded social media profiles.\n    submitted by    /u/botgo_io  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tto6sd/how_chatbot_is_beneficial_in_the_retail_industry/",
          "publishedOn": "2022-04-01T11:15:18.000Z",
          "wordCount": 270,
          "title": "How Chatbot is beneficial in the Retail Industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ttkjwy/game_ai_question_retraining_without_losing/",
          "author": null,
          "description": "submitted by    /u/ICouldDoButWhyWouldI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ttkjwy/game_ai_question_retraining_without_losing/",
          "publishedOn": "2022-04-01T06:57:21.000Z",
          "wordCount": 256,
          "title": "Game AI Question (Retraining without losing characteristics)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ttjncw/disco_diffusion_v5_bullet_time_of_blood_animation/",
          "author": null,
          "description": "submitted by    /u/JoshGrambo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ttjncw/disco_diffusion_v5_bullet_time_of_blood_animation/",
          "publishedOn": "2022-04-01T05:56:38.000Z",
          "wordCount": 111,
          "title": "[Disco Diffusion v5] - \"Bullet Time of Blood Animation\"",
          "imageUrl": "https://external-preview.redd.it/VUZrdH989ptIlcYYTgrHAhxyk5LbDxGZsiD4Hlm2qzw.jpg?auto=webp&s=328d4b23fd18df5d587aa8e4a2c9676abbe63c38"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ttf9ri/if_you_could_change_one_thing_about_building_ml/",
          "author": null,
          "description": "I’d like to open this question up to people who are beginners, intermediates and experienced in the field of ML to get a wide variety of perspectives.\n If you could change/significantly improve one thing about building ML systems, what would it be? Some examples could be:\n  \nReducing the computational overhead\n Reducing or eliminating the need for large datasets\n Simplifying the process of constructing models\n  \nHowever, it’s not limited to just those three.\n Curious to see where this goes!\n    submitted by    /u/holamyeung  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ttf9ri/if_you_could_change_one_thing_about_building_ml/",
          "publishedOn": "2022-04-01T01:43:21.000Z",
          "wordCount": 187,
          "title": "If you could change one thing about building ML, what would it be?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt8437/last_week_in_ai_podcast_deepmind_mafia_dishbrain/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt8437/last_week_in_ai_podcast_deepmind_mafia_dishbrain/",
          "publishedOn": "2022-03-31T19:52:32.000Z",
          "wordCount": 121,
          "title": "Last Week in AI podcast: DeepMind Mafia, DishBrain, PRIME, ZooKeeper AI, Instant NeRF",
          "imageUrl": "https://external-preview.redd.it/rNK55N1AxgR55D2RBw8bfS59vTGm-3bB-SOMUH7kqTc.jpg?auto=webp&s=5365740e2e113c1981453f6a977da6b9481114c2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt7l1s/newbie_question/",
          "author": null,
          "description": "Hello guys, I was wondering if anyone knew the easiest way to combine images together. Ideally I would have a bunch of images and it would take components of a couple (or just two) and put them together. I want to generate images of morphed anime figures, it doesn’t even need to look professional (or good lol). Just need some sort of website or software that I can easily achieve this. Any tips or ideas would be greatly appreciated!! Thank you!\n    submitted by    /u/misakimeifanpage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt7l1s/newbie_question/",
          "publishedOn": "2022-03-31T19:28:06.000Z",
          "wordCount": 163,
          "title": "Newbie question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt4uqf/fighting_ais_discrimination_in_mortgage_lending/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt4uqf/fighting_ais_discrimination_in_mortgage_lending/",
          "publishedOn": "2022-03-31T17:24:31.000Z",
          "wordCount": 101,
          "title": "Fighting AI's discrimination in mortgage lending | DualFair",
          "imageUrl": "https://external-preview.redd.it/pwjkeaeKK0vlN-iJxngHqiAHccPHXRgh3wt-HsDy6uM.jpg?auto=webp&s=9f51c485d9aa5650bf825719c1c1276d17c818c3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt37xb/researchers_from_u_texas_and_apple_propose_a/",
          "author": null,
          "description": "Multi-object tracking aims to locate and track all objects in a video feed. It’s a fundamental component in domains like mobile robots, where an autonomous system must navigate dynamic surroundings populated by other mobile agents. Thanks to breakthroughs in deep learning and object detection, tracking-by-detection has become the dominant tracking paradigm in recent years.\n Tracking-by-detection simplifies the process by reducing it to just two steps: detection and association. First, an object detector searches each video stream frame for probable items. The second phase is an association step, which connects detections over time. Local trackers are greedy when it comes to pairwise relationships. They keep track of each trajectory’s state based on its position and/or identity traits and correlate current-frame detections with it based on its last visible status.\n Continue Reading The Research Summary\n Paper: https://arxiv.org/pdf/2203.13250.pdf\n Github: https://github.com/xingyizhou/GTR\n https://i.redd.it/312ahhaxtqq81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt37xb/researchers_from_u_texas_and_apple_propose_a/",
          "publishedOn": "2022-03-31T16:10:30.000Z",
          "wordCount": 254,
          "title": "Researchers from U Texas and Apple Propose a Novel Transformer-Based Architecture for Global Multi-Object Tracking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt2dxi/ai_generated_personalized_implicit_neural_avatars/",
          "author": null,
          "description": "submitted by    /u/imapurplemango  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt2dxi/ai_generated_personalized_implicit_neural_avatars/",
          "publishedOn": "2022-03-31T15:32:48.000Z",
          "wordCount": 103,
          "title": "AI generated Personalized Implicit Neural Avatars (PINA)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt02ro/instant_nerf_turn_2d_images_into_a_3d_models_in/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt02ro/instant_nerf_turn_2d_images_into_a_3d_models_in/",
          "publishedOn": "2022-03-31T13:44:19.000Z",
          "wordCount": 155,
          "title": "Instant NeRF: Turn 2D Images into a 3D Models in Milliseconds",
          "imageUrl": "https://external-preview.redd.it/S2B09FxAWorWa23naYAaOvUAFMXYp4KXv9yJcPG9NS4.jpg?auto=webp&s=67c4bd30d11fd161a85861ed7dcebc9bad975d2e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsv57j/dataset_with_labeled_benign_and_malicious_files/",
          "author": null,
          "description": "Hi, Reddit,\n During the project implementation for my bachelor's thesis [1], a software (named dike, as the Greek goddess of justice) capable of analyzing malicious programs using artificial intelligence techniques, I was unable to locate an open source dataset with labeled malware samples in the public domain. As a result, I created DikeDataset, a dataset with labeled PE and OLE samples [2]. Because it was not the main focus of my thesis, the samples attributes are not evenly distributed (the benign-malicious and OLE-PE ratios are quite low), but the dataset aided greatly in the research process.\n This week, I was surprised to see that the public GitHub repository (which was used only for storage, without any promotion on communities like this) gained some organic reach (views, clones and stars). Furthermore, I was thrilled to learn that it was used in a research article published in 2021 [3]!\n As a result, I'd like to share this project with the community in the hopes that it will be useful to some members of the community.\n [1] dike\n [2] DikeDataset\n [3] Toward Identifying APT Malware through API System Calls\n    submitted by    /u/iosifache  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsv57j/dataset_with_labeled_benign_and_malicious_files/",
          "publishedOn": "2022-03-31T08:25:21.000Z",
          "wordCount": 279,
          "title": "Dataset with labeled benign and malicious files",
          "imageUrl": "https://external-preview.redd.it/nzOaZfhG60fpMW-xNsj6cTDDssciB1V0UneWyje-v-k.jpg?auto=webp&s=a3629eb3f04f2a2fed7993a5fe7e09f6e3038ba5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsv417/disney_princesses_according_to_ai_is_this_done/",
          "author": null,
          "description": "submitted by    /u/cyberpunk1Q84  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsv417/disney_princesses_according_to_ai_is_this_done/",
          "publishedOn": "2022-03-31T08:22:42.000Z",
          "wordCount": 177,
          "title": "Disney princesses according to AI. Is this done manually or through an AI app?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsqdg7/alist_celebrities_read_my_movie_script/",
          "author": null,
          "description": "Made this video tonight I had A.I. voices read my script for an upcoming movie.\n https://www.youtube.com/watch?v=RkK-iGAGcHA\n    submitted by    /u/PapermoonPictures  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsqdg7/alist_celebrities_read_my_movie_script/",
          "publishedOn": "2022-03-31T03:09:02.000Z",
          "wordCount": 111,
          "title": "A-List Celebrities Read my movie script",
          "imageUrl": "https://external-preview.redd.it/YBzYXCTJoej1uBzsY3qVvVgpVjWtb9Wb8p1A0ruCMXE.jpg?auto=webp&s=5eda08ae9d5f582b2bf1031ef8416091c3445b42"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsmk24/will_smiths_ai_persona_was_asked_about_his/",
          "author": null,
          "description": "submitted by    /u/kuasha7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsmk24/will_smiths_ai_persona_was_asked_about_his/",
          "publishedOn": "2022-03-30T23:43:58.000Z",
          "wordCount": 114,
          "title": "Will Smith's AI Persona was asked about his slapping performance on Oscar Stage",
          "imageUrl": "https://external-preview.redd.it/1mz_CTNsP9zdezGGCDxh3v194bAcGUAfmK2z3CF_m8o.png?format=pjpg&auto=webp&s=a6caf6e50413ffd8294134905effea77a0d359df"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tslzhy/researchers_from_mit_csail_introduce_privid_an_ai/",
          "author": null,
          "description": "Surveillance cameras have an identity crisis exacerbated by a conflict between function and privacy. Machine learning techniques have automated video content analysis on a vast scale as these sophisticated small sensors have shown up seemingly everywhere. Still, with increased mass monitoring, there are currently no legally enforceable standards to curb privacy invasions.\n Security cameras have evolved into wiser and more capable tools than the grainy images of the past, which were frequently used as the “hero tool” in crime dramas. Video surveillance can now assist health regulators in determining the percentage of persons using masks, transportation departments in monitoring the density and flow of automobiles, cyclists and walkers, and businesses in gaining a better understanding of buying habits. But why has privacy remained a second-class citizen?\n Privid\n Currently, the footage is retrofitted with blurred faces or black boxes. This prevents analysts from asking some legitimate questions (for example, are people wearing masks? ). Dissatisfied with the present status quo, MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) developed a system with other institutions to better guarantee privacy in surveillance video footage. The system, dubbed “Privid,” allows analysts to input video data searches and then adds a tiny amount of noise (additional data) to the result to ensure that no one can be identified. The method is based on a formal notion of privacy known as “differential privacy,” which permits without having access to aggregate statistics about private data disclosing individually identifying information.\n Continue Reading\n Paper: https://arxiv.org/pdf/2106.12083.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tslzhy/researchers_from_mit_csail_introduce_privid_an_ai/",
          "publishedOn": "2022-03-30T23:14:51.000Z",
          "wordCount": 383,
          "title": "Researchers from MIT CSAIL Introduce ‘Privid’: an AI Tool, Build on Differential Privacy, to Guarantee Privacy in Video Footage from Surveillance Cameras",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsknzb/this_guy_used_ai_to_create_a_voice_model_of_sam/",
          "author": null,
          "description": "submitted by    /u/KirbyBWCH  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsknzb/this_guy_used_ai_to_create_a_voice_model_of_sam/",
          "publishedOn": "2022-03-30T22:10:32.000Z",
          "wordCount": 135,
          "title": "This guy used AI to create a voice model of Sam O'Nella and made a video in his style.",
          "imageUrl": "https://external-preview.redd.it/vDcDjcNpXoh5JTnftcETwPoOLP1oyyU6wauS8W1VX94.jpg?auto=webp&s=1d0b4e033ba95976ef18f5260a1d1172d879b1c4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tscamj/image_classification_with_vision_transformers_in/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tscamj/image_classification_with_vision_transformers_in/",
          "publishedOn": "2022-03-30T17:57:21.000Z",
          "wordCount": 105,
          "title": "Image Classification With Vision Transformers in a Gradio Web App",
          "imageUrl": "https://preview.redd.it/m4dx67e28kq81.png?auto=webp&s=449d882a75051805fa1b9685b9accd260d606c0d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsbf8i/meta_ai_team_opensources_mephisto_a_new_platform/",
          "author": null,
          "description": "Training datasets are very important for experimenting with varied data to train new AI models. However, many commonly used public data sets contain labeling errors. This makes it challenging to train robust models, particularly for novel tasks. Many researchers use techniques such as employing a variety of data quality control procedures to overcome these shortcomings. However, there is no centralized repository consisting of examples of using these strategies.\n Meta AI researchers have recently released Mephisto. It is a new platform to collect, share, and iterate on the most promising approaches to collecting training datasets for AI models. Researchers can exchange unique collecting strategies with Mephisto in a reusable and iterable format. It also allows them to change out components and quickly locate the exact annotations required, minimizing the barrier to custom task creation.\n Continue Reading\n Github: https://github.com/facebookresearch/Mephisto\n Documentation: https://mephisto.ai/\n https://preview.redd.it/mae7igz11kq81.png?width=1920&format=png&auto=webp&s=764145c4350d73049ae49faafd43ac3806712a2d\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsbf8i/meta_ai_team_opensources_mephisto_a_new_platform/",
          "publishedOn": "2022-03-30T17:17:57.000Z",
          "wordCount": 271,
          "title": "Meta AI Team Open-Sources Mephisto: A New Platform For Open And Collaborative Way Of Collecting Data To Train ML Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsa1jr/quantum_computing_memristor_to_unlock_ai/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsa1jr/quantum_computing_memristor_to_unlock_ai/",
          "publishedOn": "2022-03-30T16:15:29.000Z",
          "wordCount": 100,
          "title": "Quantum Computing Memristor To Unlock AI",
          "imageUrl": "https://external-preview.redd.it/QSx4fTwcG6wL5-HA7YZ_hQ0eF_CUwfgWA_4XBXnm2LM.jpg?auto=webp&s=a0097034ba7f42b221723603700dd9415bab7d95"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts44n7/new_exciting_study_grievers_and_chatbots/",
          "author": null,
          "description": "submitted by    /u/annaksig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts44n7/new_exciting_study_grievers_and_chatbots/",
          "publishedOn": "2022-03-30T11:18:40.000Z",
          "wordCount": 92,
          "title": "NEW EXCITING STUDY: GRIEVERS AND CHATBOTS",
          "imageUrl": "https://preview.redd.it/oxfcu7hx8iq81.png?auto=webp&s=20e48a8196e4bb4b5217734b2cb048f3ac202f59"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts3pv4/ai_that_can_expand_the_borders_of_video/",
          "author": null,
          "description": "Hi do any of you know the name of a AI that can expand the borders of a video\n By making the AI guess what would be around the square of the video? \n I remember I once saw something like this in a video on two minute papers youtube channel\n Where they used an example with a eagle flying in the sky\n But I haven't been able to find the video since\n And I have been looking for a long time \n But having such AI will be very help full to video editing\n    submitted by    /u/Pwichmann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts3pv4/ai_that_can_expand_the_borders_of_video/",
          "publishedOn": "2022-03-30T10:53:01.000Z",
          "wordCount": 240,
          "title": "AI that can expand the borders of video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts3f5q/best_data_visualization_books_for_data_science_to/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts3f5q/best_data_visualization_books_for_data_science_to/",
          "publishedOn": "2022-03-30T10:33:14.000Z",
          "wordCount": 121,
          "title": "Best Data Visualization books for Data Science to read in 2022",
          "imageUrl": "https://external-preview.redd.it/rEVkX36XqUqfx02t3OY3403ckUBuo5KsAwGuKQhnB6M.jpg?auto=webp&s=5dcffcc83a951be0671a7b65b6f5a0fc7856ccf3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts1tyo/explaining_overfitting_and_why_100_accuracy_is/",
          "author": null,
          "description": "What are your approaches to explaining these topics to business people?\n    submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts1tyo/explaining_overfitting_and_why_100_accuracy_is/",
          "publishedOn": "2022-03-30T08:34:24.000Z",
          "wordCount": 211,
          "title": "Explaining overfitting and why 100% accuracy is not a guarantee to clients",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts1lcj/what_metric_do_you_use_for_hyperparameter_tuning/",
          "author": null,
          "description": "Pretty much as the title says. I work in research with electroencephalography (EEG) classification (those electrodes they stick on peoples heads). EEG is notoriously noisy and prone to overfitting, I have generally used validation accuracy as an optimization metric for a Bayesian HP tuning approach, but I find this tends to result in fairly unreliable models, even using cross validation approaches. These models are really noisy and while they may reach pretty good accuracy, that is a single epoch where it got a decent spike. I was wondering if there are common resolutions for this that I have missed, or if anyone has had luck with a custom metric that takes into account not just the validation accuracy, but the consistency and the difference between validation and training accuracy to better account for overfitting. Thanks!\n    submitted by    /u/Ozzod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts1lcj/what_metric_do_you_use_for_hyperparameter_tuning/",
          "publishedOn": "2022-03-30T08:16:19.000Z",
          "wordCount": 235,
          "title": "What metric do you use for hyperparameter tuning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts0hg8/google_docs_now_autogenerate_short_summaries/",
          "author": null,
          "description": "Many of us find it difficult to keep up with the daily flood of documents in our inboxes. These could be reports, reviews, briefs, policies, etc. Nowadays, readers wish to have a concise summary including major elements of their document, helping them prioritize their work efficiently. However, writing a document summary from scratch manually is a time-consuming task.\n To aid document writers in writing content summaries, Google announced a new feature enabling Google Docs to generate ideas automatically when they are available. The team employs a machine learning (ML) model to understand document text and provide a one- to two-sentence natural language description of the material. On the other hand, the document writer retains complete control, choosing whether to accept the proposal as-is, make necessary adjustments to better capture the document summary, or ignore it entirely. This section, combined with the outline, can help readers understand and navigate the work at a high level. While anybody can contribute summaries, only Google Workspace business customers have access to auto-generated ideas.\n Continue Reading\n https://i.redd.it/pcrn8rqmxgq81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts0hg8/google_docs_now_autogenerate_short_summaries/",
          "publishedOn": "2022-03-30T06:53:03.000Z",
          "wordCount": 297,
          "title": "Google Docs Now Auto-Generate Short Summaries Using Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts088h/is_there_an_ai_for_psychological_testing/",
          "author": null,
          "description": "I want to test myself using a neural net in lieu of psychological testing, and was wondering if that's even publicly available.\n    submitted by    /u/AdvancedRazzmatazz46  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts088h/is_there_an_ai_for_psychological_testing/",
          "publishedOn": "2022-03-30T06:34:34.000Z",
          "wordCount": 119,
          "title": "Is there an AI for psychological testing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/try6jr/ai_beats_8_world_champions_at_bridge/",
          "author": null,
          "description": "submitted by    /u/nick7566  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/try6jr/ai_beats_8_world_champions_at_bridge/",
          "publishedOn": "2022-03-30T04:23:13.000Z",
          "wordCount": 139,
          "title": "AI beats 8 world champions at bridge",
          "imageUrl": "https://external-preview.redd.it/WpwXEa7gVOYU6ZgHWiq4aq0r36J-t9FFX1f3bjs0BPs.jpg?auto=webp&s=19a295e3dfbc0682998ddf39a683bb5775f5a64c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/trps2d/flower_team_releases_flower_018_with_cool_new/",
          "author": null,
          "description": "Flower is an end-to-end federated learning framework that allows for a smoother transition from simulation-based experimental research to system research on many real-world edge devices. Flower has individual strengths in both domains (i.e., simulation and real-world devices) and the capacity to switch back and forth between the two extremes as needed throughout exploration and development. Researchers present use cases that drive our viewpoint, design goals, the resultant framework architecture, and comparisons to other frameworks in this part.\n Federated Learning (FL) has shown to be a viable option for enabling edge devices to develop a shared prediction model cooperatively while maintaining their training data on the device, divorcing the capacity to execute machine learning from the requirement to store data in the cloud. However, FL is challenging to implement practically in size and system heterogeneity. Although there are several research frameworks for simulating FL algorithms, none of them facilitate the investigation of scalable FL workloads on heterogeneous edge devices.\n Flower 0.18 released\n Thanks to a longer gap than usual, the latest Flower release has more upgrades than any previous release. Also, thanks to the wonderful community for your continuing support and generosity.\n Continue Reading\n Paper: https://arxiv.org/pdf/2007.14390.pdf\n Github: https://github.com/adap/flower\n https://preview.redd.it/ywtttqlnceq81.png?width=1920&format=png&auto=webp&s=893fbe79c190aa66e293b296e35d4096eb178f97\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/trps2d/flower_team_releases_flower_018_with_cool_new/",
          "publishedOn": "2022-03-29T22:12:42.000Z",
          "wordCount": 319,
          "title": "Flower Team Releases Flower 0.18 With Cool New Updates For Federated Learning",
          "imageUrl": "https://external-preview.redd.it/FuxmveI-dqShP8OJKG9Bz9Qlu7YQcgDqKb2mTYJy1Cs.jpg?auto=webp&s=0130f2eec883506ce792a344d13ec47bc9f072c4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/treb6c/carbon_vs_silicon_molecule/",
          "author": null,
          "description": "Since we are about to create a silicon-based lifeform I was looking up the differences between the carbon and the silicon molecule.\n https://www.differencebetween.com/difference-between-silicon-and-vs-carbon/#:~:text=The%20key%20difference%20between%20silicon,in%20the%20outer%20energy%20level.\n    submitted by    /u/asenz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/treb6c/carbon_vs_silicon_molecule/",
          "publishedOn": "2022-03-29T18:43:52.000Z",
          "wordCount": 110,
          "title": "Carbon vs Silicon molecule",
          "imageUrl": "https://external-preview.redd.it/lUw4Jcoa4AbN44kBUWY7bebBXJy3zy26-2qTmz4nzI4.jpg?auto=webp&s=4ac0a1a373474ab0ef352da2e0bc4f30830147b5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/treaze/last_week_in_ai_super_fast_3d_perception_from/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/treaze/last_week_in_ai_super_fast_3d_perception_from/",
          "publishedOn": "2022-03-29T18:43:35.000Z",
          "wordCount": 157,
          "title": "Last Week in AI: Super fast 3D perception from Nvidia, Ukraine uses face recognition to identify dead Russian soldiers, US-China AI collaboration drops, and more!",
          "imageUrl": "https://external-preview.redd.it/DUVRBt6nWViUJiU3Oon9XV8cjCxS2elyCHo0wjAwnD8.jpg?auto=webp&s=f8dcd7fc586f0c7f76e98d0146ef3d1d3272b99b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tra5qt/google_maps_utilizes_machine_learning_to_block/",
          "author": null,
          "description": "In their recent post on how Google keeps Maps information reliable, the company elaborates how they use machine learning and human operators to block nearly 100 million attempted fraudulent edits to Google Business Profiles. Machine learning, in simple terms, is a sort of artificial intelligence (AI) that lets software applications improve their accuracy at predicting events without having to be explicitly programmed to do so. Machine learning algorithms use past data as input to forecast new output values.\n The world changed with the introduction of vaccinations, revisions to mask regulations, and new COVID variations in 2021. Accordingly, their Maps community updated Google Maps with further information about their nearby areas. Their contributions have helped Google provide updated company information, such as a location’s hours of operation or its health and safety regulations, for 30% more firms in 2021 than 2020. \n Quick Read\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tra5qt/google_maps_utilizes_machine_learning_to_block/",
          "publishedOn": "2022-03-29T17:23:05.000Z",
          "wordCount": 291,
          "title": "Google Maps Utilizes Machine Learning To Block Nearly 100 Million Fraudulent Edits",
          "imageUrl": "https://external-preview.redd.it/UIAfp_x6OO1l2LRNIywGJUMRM-8kNuY5gXc2_NZ7g6k.jpg?auto=webp&s=8aa24ad66a579497694e0bc8d4e189f27563376e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tr6mpr/tinyml_gearbox_fault_prediction_on_a_4_mcu/",
          "author": null,
          "description": "Is it possible to make an AI-driven system that predicts gearbox failure on a simple $4 MCU? How to automatically build a compact model that does not require any additional compression? Can a non-data scientist implement such projects successfully?\n I will answer all these questions in my new project.\n In industry (e.g., wind power, automotive), gearboxes often operate under random speed variations. A condition monitoring system is expected to detect faults, broken tooth conditions and assess their severity using vibration signals collected under different speed profiles.\n Modern cars have hundreds of thousands of details and systems where it is necessary to predict breakdowns, control the state of temperature, pressure, etc.As such, in the automotive industry, it is critically important t…",
          "link": "https://www.reddit.com/r/artificial/comments/tr6mpr/tinyml_gearbox_fault_prediction_on_a_4_mcu/",
          "publishedOn": "2022-03-29T16:22:14.000Z",
          "wordCount": 1646,
          "title": "TinyML Gearbox Fault Prediction on a $4 MCU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqyohn/metaverse_is_considered_the_future_of_internet_it/",
          "author": null,
          "description": "submitted by    /u/Nitorblog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqyohn/metaverse_is_considered_the_future_of_internet_it/",
          "publishedOn": "2022-03-29T12:30:07.000Z",
          "wordCount": 150,
          "title": "Metaverse is considered the future of internet. It is used to designate a universe beyond physical world. Watch our video to know more about it.",
          "imageUrl": "https://external-preview.redd.it/eIR632I5jMX229fiYS9jb_ZPKWa5zpP9ke34ZnlU_V0.png?format=pjpg&auto=webp&s=cce4ff470dc534bf0022b4a08cf5f7de20a118af"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqxzgx/building_decision_trees_entropy_information_gain/",
          "author": null,
          "description": "submitted by    /u/TheNerdyDevYT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqxzgx/building_decision_trees_entropy_information_gain/",
          "publishedOn": "2022-03-29T11:49:56.000Z",
          "wordCount": 112,
          "title": "Building Decision Trees - Entropy, Information Gain & Gini Impurity",
          "imageUrl": "https://external-preview.redd.it/Ew_3E7KxioaPCr22V1PnzglHzpPRYF2-9_oof4CjeMg.jpg?auto=webp&s=029c0a24a2f872d3624a9585848e6630a3ea6c9b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqwqui/china_researches_brainscale_ai/",
          "author": null,
          "description": "https://mixed-news.com/en/artificial-intelligence-china-researches-brain-scale-ai/\n From the article:\n In China, the state and companies are researching AI models with trillions of parameters. They want to prove that they can develop “brain-scale” AI.\n ...\n In a new paper, researchers from Tsinghua University, Alibaba Group, Zhejiang Lab and Beijing Academy of Artificial Intelligence present BaGuaLu, a framework that enables the training of large AI models using the Mixture-of-Experts (MoE) architecture.\n In an initial test, the researchers trained a 1.93 trillion model with their framework, outperforming Google’s Switch Transformer. They also demonstrate that their framework enables models with 14.5 trillion and a full 174 trillion parameters.\n ...\n The team expects that giant multimodal AI models could have far-reaching implications for numerous AI applications.\n    submitted by    /u/Sephirio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqwqui/china_researches_brainscale_ai/",
          "publishedOn": "2022-03-29T10:29:46.000Z",
          "wordCount": 249,
          "title": "China researches “brain-scale” AI",
          "imageUrl": "https://external-preview.redd.it/JhZYBigKAty1Eq96lCCsaxYnvApivFIyrmwoeLVCjDk.jpg?auto=webp&s=70729ea061997be594080e36d0fcf14e4b9aff66"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqwp4r/9_best_deep_learning_books_for_beginners_to/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqwp4r/9_best_deep_learning_books_for_beginners_to/",
          "publishedOn": "2022-03-29T10:26:21.000Z",
          "wordCount": 118,
          "title": "9+ Best Deep Learning books for beginners to Expert 2022 [Updated] -",
          "imageUrl": "https://external-preview.redd.it/x06CLmBrTjzvn6iNlNFbABPzVnEjuxHaSMUgpftyi_Y.jpg?auto=webp&s=3a2505e77c664e13c7517f5c2565a4d6cf3e39a8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqthl4/jax_flower_for_federated_learning_gives_machine/",
          "author": null,
          "description": "Google researchers created JAX to conduct NumPy computations on GPUs and TPUs. DeepMind uses it to help and expedite its research, and it is increasingly gaining popularity. Differentiation with grad(), vectorization with map(), and JIT-compilation (just-in-time) with jit are some of the composable functions required for machine learning research in JAX (). As a result, adding a JAX-based workload to the Flower code samples is a must-have. The combination of JAX and Flower allows ML and FL researchers to employ the deep learning framework that their projects demand. The updated code example now serves as a template for migrating existing JAX projects to a federated environment.\n It’s pretty simple to put up a centralized machine learning architecture, and the JAX developer documentation has multiple examples. Because the ML model parameters are stored in the DeviceArray data format, setting up the federated workload requires some knowledge of JAX. To be compatible with the Flower NumPyClient, those arguments must be converted to NumPy ndarrays. The JAX meets Flower example below demonstrates how a Flower setup might work.\n Continue Reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqthl4/jax_flower_for_federated_learning_gives_machine/",
          "publishedOn": "2022-03-29T06:27:38.000Z",
          "wordCount": 311,
          "title": "JAX + Flower For Federated Learning Gives Machine Learning Researchers The Flexibility To Use The Deep Learning Framework For Their Projects",
          "imageUrl": "https://external-preview.redd.it/FuxmveI-dqShP8OJKG9Bz9Qlu7YQcgDqKb2mTYJy1Cs.jpg?auto=webp&s=0130f2eec883506ce792a344d13ec47bc9f072c4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqs0mk/pastiche_master_exemplarbased_highresolution/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqs0mk/pastiche_master_exemplarbased_highresolution/",
          "publishedOn": "2022-03-29T04:49:01.000Z",
          "wordCount": 104,
          "title": "Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer",
          "imageUrl": "https://external-preview.redd.it/Hkj3t-Kg395q-4iOaAIEz6LS8gtTRqg71oLNGtfE2G0.png?format=pjpg&auto=webp&s=50e4ffaac3dff104741d0844c8e48f253c2ea12a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqq75c/discussions_on_pattern_theory/",
          "author": null,
          "description": "Hi all,\n I have been interested in a field called pattern theory for some time now. Its a mathematical formalism to describe patterns in the world, as well as a framework for developing ai.\n As far as I can tell, pattern theory seems to be somewhat of a dead field. I'm not sure who is possibly still thinking about it other than a single digit number of academics (e.g. David Mumford). I find this a bit unfortunate, since while I'm still a bit naïve about the field, I'd like to find people I could talk to about it.\n Does anyone have any recommendations for where I could find people I could talk to about pattern theory/bounce ideas off of relating to pattern theory?\n Thanks in advance\n    submitted by    /u/patterntheoryacc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqq75c/discussions_on_pattern_theory/",
          "publishedOn": "2022-03-29T03:00:53.000Z",
          "wordCount": 210,
          "title": "Discussions on Pattern Theory",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqls56/can_ai_create_a_safer_online_world/",
          "author": null,
          "description": "submitted by    /u/ML_Firefighter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqls56/can_ai_create_a_safer_online_world/",
          "publishedOn": "2022-03-28T23:02:38.000Z",
          "wordCount": 103,
          "title": "Can AI create a safer online world?",
          "imageUrl": "https://external-preview.redd.it/VaNRQZfSPskVrTdcVdLbEPbJWey9OAsw4YUKFp1prfw.jpg?auto=webp&s=b5b54f381569faae56c7bc363bfcdba4d18d17b3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqjyi9/do_people_build_physical_perceptrons/",
          "author": null,
          "description": "A friend and I are thinking about building a physical perceptron as a summer project. However, I cannot find any resources on the physical implementation of the perceptron since Rosenblatt's in the 40's. Does anyone do this? What are some good resources?\n    submitted by    /u/HoldDoorHoldor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqjyi9/do_people_build_physical_perceptrons/",
          "publishedOn": "2022-03-28T21:33:09.000Z",
          "wordCount": 133,
          "title": "Do people build physical perceptrons?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqieul/weekly_china_ai_newsletter_china_strengthens/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqieul/weekly_china_ai_newsletter_china_strengthens/",
          "publishedOn": "2022-03-28T20:22:10.000Z",
          "wordCount": 154,
          "title": "Weekly China AI Newsletter: China Strengthens Ethics Reviews on AI, Life Science; Users Can Turn off Recommendation Algorithms; Chinese Self-Driving Startup Raises $400 Million",
          "imageUrl": "https://external-preview.redd.it/E96BeKT9CIKWR2g7HtItkGzuUbrPboSPzL-CpbVh4v4.jpg?auto=webp&s=4a67b7b6a8e6f2507fcd90a1fad30c0f319898ef"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqfux5/nerf_research_turns_2d_photos_into_3d_scenes/",
          "author": null,
          "description": "submitted by    /u/MarS_0ne  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqfux5/nerf_research_turns_2d_photos_into_3d_scenes/",
          "publishedOn": "2022-03-28T18:27:44.000Z",
          "wordCount": 119,
          "title": "NeRF Research Turns 2D Photos Into 3D Scenes",
          "imageUrl": "https://external-preview.redd.it/QHJvYirPpHx1vFDOCsbWNlCcxNOr8pCCWtMYboJGlGw.jpg?auto=webp&s=d3aaf26600f3af092efef88858826196f36294b0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqex1u/artificial_intelligence_machine_learning_and/",
          "author": null,
          "description": "submitted by    /u/pmz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqex1u/artificial_intelligence_machine_learning_and/",
          "publishedOn": "2022-03-28T17:44:59.000Z",
          "wordCount": 100,
          "title": "Artificial Intelligence, Machine Learning and Society",
          "imageUrl": "https://external-preview.redd.it/cww0EXz-wYJnuFb5laspnNl598Uvsy5oV7-mp1iVXmo.jpg?auto=webp&s=744e60e92440c105aa3e1d01edb110d67d4d9974"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqdlou/11_best_python_books_for_data_science_beginners/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqdlou/11_best_python_books_for_data_science_beginners/",
          "publishedOn": "2022-03-28T16:47:21.000Z",
          "wordCount": 127,
          "title": "11 Best Python Books for Data Science beginners to advanced to read in 2022 -",
          "imageUrl": "https://external-preview.redd.it/3pdSs8qDH1dxGz1jom5eFGa2iAZiKGkP654eztme7y0.jpg?auto=webp&s=ac621ceb3cbbdfba20cd59821ecd81a25a9d798f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqd5gy/meet_jessica_from_linkedin_she_is_not_a_human/",
          "author": null,
          "description": "submitted by    /u/satish_gaire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqd5gy/meet_jessica_from_linkedin_she_is_not_a_human/",
          "publishedOn": "2022-03-28T16:27:23.000Z",
          "wordCount": 112,
          "title": "Meet Jessica From LinkedIn, She Is Not A Human Being",
          "imageUrl": "https://external-preview.redd.it/Pn6YcUeK0qg9-t2-dB4k0Z0Umwx6i-4YYXOVWSNJLlg.jpg?auto=webp&s=fe13971097e35b77fa26163f385a63455fd1af47"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tq9z0g/a_miniconversation_with_kanye_wests_ai_persona/",
          "author": null,
          "description": "submitted by    /u/kuasha7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tq9z0g/a_miniconversation_with_kanye_wests_ai_persona/",
          "publishedOn": "2022-03-28T14:01:11.000Z",
          "wordCount": 111,
          "title": "A mini-conversation with Kanye West's AI persona ended on a hilarious note",
          "imageUrl": "https://external-preview.redd.it/mrqGL7gmiXpodq1NjDonjHdTmgMfgMSzC0WUf7PJxJg.png?format=pjpg&auto=webp&s=6ed68ce2ff8f7ca4fb7125bbab397152d7afc17b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tq8rwc/datarobots_plan_to_democratize_machine_learning/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tq8rwc/datarobots_plan_to_democratize_machine_learning/",
          "publishedOn": "2022-03-28T13:00:19.000Z",
          "wordCount": 109,
          "title": "DataRobot’s plan to democratize machine learning with no-code AI",
          "imageUrl": "https://external-preview.redd.it/c1cYrmuLjC8mc2p2ntDOhFiEZ-9T_fUDwXDYTNB0wQM.jpg?auto=webp&s=f2c7082d89a6eeffcb1bcd57a91ab8aaa2e543f8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tq3c3b/top_5_python_time_series_libraries/",
          "author": null,
          "description": "submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tq3c3b/top_5_python_time_series_libraries/",
          "publishedOn": "2022-03-28T06:51:33.000Z",
          "wordCount": 102,
          "title": "Top 5 Python Time Series Libraries",
          "imageUrl": "https://external-preview.redd.it/PSJx7xNt4F5lZFn1vZlAKimT6kKGCTVhpeIuJiCTBNk.jpg?auto=webp&s=5030d7619636a75972e5c0f6fd9b10278bf4b403"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpz3wg/learning_to_generate_line_drawings_that_convey/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpz3wg/learning_to_generate_line_drawings_that_convey/",
          "publishedOn": "2022-03-28T02:25:25.000Z",
          "wordCount": 183,
          "title": "Learning to generate line drawings that convey geometry and semantics (CVPR 2022)",
          "imageUrl": "https://external-preview.redd.it/TizNVkYtsjAtBNH3SHzreECfA9osX50VQWDlQiAltKY.png?format=pjpg&auto=webp&s=adc8b2a5c0e3ffe2ad41fedb4f043090bc7418d4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpz2t7/new_ai_tool/",
          "author": null,
          "description": "Now unlimited uses for anyone: https://botbox.dev/generator\n    submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpz2t7/new_ai_tool/",
          "publishedOn": "2022-03-28T02:23:42.000Z",
          "wordCount": 91,
          "title": "New AI Tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpxtud/the_latest_marketing_tactic_on_linkedin/",
          "author": null,
          "description": "submitted by    /u/Representative-Job23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpxtud/the_latest_marketing_tactic_on_linkedin/",
          "publishedOn": "2022-03-28T01:12:48.000Z",
          "wordCount": 112,
          "title": "The latest marketing tactic on LinkedIn: AI-generated faces : NPR",
          "imageUrl": "https://external-preview.redd.it/XVJASZZxt75i_Qx2T4MskxIt7_gPuPquuwyXhqtq3NY.jpg?auto=webp&s=82a833bf113ba807964e81f62f280fd6d7173486"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpuu9k/ai_that_turns_written_documents_into_practice/",
          "author": null,
          "description": "submitted by    /u/143openyourmind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpuu9k/ai_that_turns_written_documents_into_practice/",
          "publishedOn": "2022-03-27T22:26:05.000Z",
          "wordCount": 128,
          "title": "A.I. that turns written documents into practice tests. For easy learning. Is this easy or challenging programming?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tptssd/check_out_this_research_summary_article_based_on/",
          "author": null,
          "description": "Deep Neural Networks (DNNs) have excelled at solving complex real-world problems, however, training a good DNN has become more complex. It is challenging to ensure that the optimizers used will converge to reliable minima with acceptable model performance when only minimizing the conventional empirical loss.\n Tsinghua University’s research team proposes Stochastic Scheduled SAM (SS-SAM), a novel and effective DNN training strategy. In SS-SAM, the optimizer is set up by a predetermined scheduling function to run a random trial at each update step, which selects whether to perform the SGD or SAM optimization at random. The overall number of propagation pairs could be significantly decreased in this approach. The team’s approach provides equivalent or higher model training performance at a lower computational cost than baseline sharpness-aware minimization (SAM).\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.09962.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tptssd/check_out_this_research_summary_article_based_on/",
          "publishedOn": "2022-03-27T21:34:10.000Z",
          "wordCount": 312,
          "title": "Check out this research summary article based on the paper 'SS-SAM: Stochastic Scheduled Sharpness-Aware Minimization for Efficiently Training Deep Neural Networks' where Researchers From Tsinghua University Propose ‘Stochastic Scheduled SAM’ (SS-SAM) for reducing the computational overhead",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tptgix/what_are_easy_to_use_image_editing_ais/",
          "author": null,
          "description": "submitted by    /u/xXLisa28Xx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tptgix/what_are_easy_to_use_image_editing_ais/",
          "publishedOn": "2022-03-27T21:17:26.000Z",
          "wordCount": 101,
          "title": "What are easy to use image editing AIs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpq5e1/artificial_nightmares_limgrave_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpq5e1/artificial_nightmares_limgrave_clip_guided/",
          "publishedOn": "2022-03-27T18:39:55.000Z",
          "wordCount": 136,
          "title": "Artificial Nightmares: Limgrave || Clip Guided Diffusion AI Art Video [4K 16 FPS]",
          "imageUrl": "https://external-preview.redd.it/-NLxMO7RJUsGN_m0Q9Ht9x-rs1eZzOziGqC45LqdVeI.jpg?auto=webp&s=618b15f4d252ba3008c7a0a6ec3b7f49730f5739"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpou15/nvidia_research_turns_2d_photos_into_3d_scenes_in/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpou15/nvidia_research_turns_2d_photos_into_3d_scenes_in/",
          "publishedOn": "2022-03-27T17:35:17.000Z",
          "wordCount": 130,
          "title": "NVIDIA Research Turns 2D Photos Into 3D Scenes in the Blink of an AI",
          "imageUrl": "https://external-preview.redd.it/avEfVzzfxH_XMkyIVDKUGstdygF8nOzfqXrztVXjxzU.jpg?auto=webp&s=05e07e27abcd7d7290ce2d219f8f433985093928"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpoc3c/this_endless_live_tv_show_run_entirely_by_ai/",
          "author": null,
          "description": "submitted by    /u/the_embassy_official  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpoc3c/this_endless_live_tv_show_run_entirely_by_ai/",
          "publishedOn": "2022-03-27T17:10:19.000Z",
          "wordCount": 381,
          "title": "This endless live TV show run entirely by AI characters",
          "imageUrl": "https://preview.redd.it/ndob867ykyp81.png?auto=webp&s=3f015397314d3d4ccc89604ea9b8dc7d8d82e843"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpnsw0/7_best_natural_language_processing_courses_2022/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpnsw0/7_best_natural_language_processing_courses_2022/",
          "publishedOn": "2022-03-27T16:44:40.000Z",
          "wordCount": 118,
          "title": "7 Best Natural Language Processing Courses (2022) | Best NLP Courses -",
          "imageUrl": "https://external-preview.redd.it/5H2hA1Y-EUYX8VkmXRdkCl95_D4XC5s0iR6KW8GYmJs.jpg?auto=webp&s=32bb20f8204298387cf5763f228d1f3a3a595935"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpndxo/if_you_have_expertise_in_this_field_is_it/",
          "author": null,
          "description": "As in...get the voice down from improving an A.I recording.\n Then, give it some basic code or responses that you had at different ages.\n Also, getting a bunch of 3D images of yourself.\n Then coding it with some basic \"values\" and creating some sort of generic conditional statement for the 3 basic values that it has that match yours.\n Then, over time, actually diving into artificial intelligence and slowly updating and replacing those to continue improving it to match you (and your growth)?\n Hmmm, I wonder if there would be a way to preserve it. Everything changes (like sites -> VR and so on). So some sort of \"survival\" instinct (which seems impossible to code but would be fun to try undertaking).\n    submitted by    /u/the_evil_intp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpndxo/if_you_have_expertise_in_this_field_is_it/",
          "publishedOn": "2022-03-27T16:24:22.000Z",
          "wordCount": 647,
          "title": "If you have expertise in this field, is it realistic whatsoever to create an A.I version of yourself to live on (let's say work on it for 30 years, starting from now)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpmjje/future_after_automation_and_agi/",
          "author": null,
          "description": "submitted by    /u/HumanSeeing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpmjje/future_after_automation_and_agi/",
          "publishedOn": "2022-03-27T15:43:29.000Z",
          "wordCount": 478,
          "title": "Future after Automation and AGI",
          "imageUrl": "https://external-preview.redd.it/5remJy-FxVWAVsInA8egwymxru08nhIj7WxvKQ4Xt3Q.jpg?auto=webp&s=aaf653c2b0d1a270e8fd8d3bc2d6eb5d20c30b4b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpm86a/face_filters_on_the_web_from_just_text/",
          "author": null,
          "description": "submitted by    /u/pmz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpm86a/face_filters_on_the_web_from_just_text/",
          "publishedOn": "2022-03-27T15:27:39.000Z",
          "wordCount": 109,
          "title": "Face filters on the web from just text descriptions",
          "imageUrl": "https://external-preview.redd.it/78QbKWN9TXJq4YXtaSyvNxWbRzsE8HQb1RIsEF3PqOY.jpg?auto=webp&s=e57c9deabb148eb9061fc26548d289354d00234e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpcgi4/impressed_with_alphafold_checkout_this_protein/",
          "author": null,
          "description": "DeepMind released AlphaFold 2 last year, which made headlines for its incredible accuracy in protein structure prediction. The success of AlphaFold demonstrated that deep neural networks might be used to solve challenging and critical structural biology problems.\n FastFold is a highly effective protein structure prediction model formulation for training and inference developed by a group of researchers from the National University of Singapore. Although AlphaFold 2 is a game-changer in protein structure prediction, training and inference remain time-consuming and costly. This is something that the study team is concerned about.\n Continue Reading This Article Here\n Paper: https://arxiv.org/pdf/2203.00854v1.pdf\n Github: https://github.com/hpcaitech/FastFold\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpcgi4/impressed_with_alphafold_checkout_this_protein/",
          "publishedOn": "2022-03-27T04:29:04.000Z",
          "wordCount": 273,
          "title": "👉 Impressed With AlphaFold? Checkout This Protein Structure Prediction Model (FastFold) That Reduces AlphaFold’s Training Time From 11 Days To 67 Hours",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tp7wpj/i_created_a_new_ai_art_maker_program_free/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tp7wpj/i_created_a_new_ai_art_maker_program_free/",
          "publishedOn": "2022-03-26T23:57:35.000Z",
          "wordCount": 111,
          "title": "I created a new AI art maker program (free)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tp7h6k/how_does_a_selfdriving_car_see_waymo_s_system/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tp7h6k/how_does_a_selfdriving_car_see_waymo_s_system/",
          "publishedOn": "2022-03-26T23:33:12.000Z",
          "wordCount": 112,
          "title": "How Does a Self-Driving Car See? (Waymo ‘s system explained)",
          "imageUrl": "https://external-preview.redd.it/sTXR8P0nRfSLXauZE5GcEcjD9TKBrk7X2bNl7X0bwnA.jpg?auto=webp&s=d83c262ae1ac439e356ffaa93c947748ea10050f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tp687u/5_best_movies_like_after_yang_about_artificial/",
          "author": null,
          "description": "submitted by    /u/NarutoNotBoruto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tp687u/5_best_movies_like_after_yang_about_artificial/",
          "publishedOn": "2022-03-26T22:31:31.000Z",
          "wordCount": 112,
          "title": "5 Best Movies Like 'After Yang' About Artificial Intelligence (A.I.)",
          "imageUrl": "https://external-preview.redd.it/M15bgA-BBXFIBSIMKFe7nFMY9lLGrAXq0Xdhv--rhus.jpg?auto=webp&s=2fbfccb9c28867c85f249d2f22ce61cbe437de5a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tozvwt/ai_for_enamels_and_paints/",
          "author": null,
          "description": "Love how my keyboard konked out. \n So I recently read about megasyn the AI being used to create 40k new weapons in 6 hours. \n This got me wondering. Can AI be made to create different enamels and paints for things like pottery glazes, cloisonne enamels and paints for art work? \n If so how would one go about doing this knowing literally nothing?\n    submitted by    /u/Grendal87  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tozvwt/ai_for_enamels_and_paints/",
          "publishedOn": "2022-03-26T18:38:47.000Z",
          "wordCount": 150,
          "title": "ai for enamels and paints",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/toyu62/useful_tools_and_programs_list_for_aiml/",
          "author": null,
          "description": "Found a useful list of Tools and Programs for AI/ML. Looks like it covers Machine Learning, Deep Learning, Computer Vision(CV), and Natural Language Processing (NLP). I thought I'd share it for anyone that's interested. https://github.com/mikeroyal/Machine-Learning-Guide\n    submitted by    /u/Khaotic_Kernel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/toyu62/useful_tools_and_programs_list_for_aiml/",
          "publishedOn": "2022-03-26T17:47:30.000Z",
          "wordCount": 132,
          "title": "Useful Tools and Programs list for AI/ML",
          "imageUrl": "https://external-preview.redd.it/i9BG3RO4f3gR2wvyQLPmg5D4UABwOQQODQTwztrwNHU.jpg?auto=webp&s=4d516d9a279d2aff190b64f9eb4dc764c11157b3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/toxy88/gpt3s_knowledge_was_limited_to_the_world_until/",
          "author": null,
          "description": "submitted by    /u/BeginningInfluence55  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/toxy88/gpt3s_knowledge_was_limited_to_the_world_until/",
          "publishedOn": "2022-03-26T17:04:12.000Z",
          "wordCount": 145,
          "title": "GPT-3's knowledge was limited to the world until 2019. InstructGPT is apparently up-to-date.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/towlb9/crystal_forest_ai_art/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/towlb9/crystal_forest_ai_art/",
          "publishedOn": "2022-03-26T16:28:50.000Z",
          "wordCount": 96,
          "title": "Crystal Forest AI Art",
          "imageUrl": "https://external-preview.redd.it/B-jpYEQ1YIU-HcpUaODZlGWXVT1rkf3bRmy8P-0eQzI.jpg?auto=webp&s=db9e8c885dcaa9180970e4c87d771d93e0984e62"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tou59y/deep_convolutional_generative_network_tutorial_in/",
          "author": null,
          "description": "I thought it will be quite interesting to see Deep Convolutional GAN’s capability in generating wildlife, so I wrote a tutorial on how to build a model based on the DCGAN architecture through PyTorch:\n https://taying-cheng.medium.com/create-new-animals-using-dcgan-with-pytorch-2ce47810ebd4\n    submitted by    /u/Ok-Peanut-2681  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tou59y/deep_convolutional_generative_network_tutorial_in/",
          "publishedOn": "2022-03-26T15:54:15.000Z",
          "wordCount": 131,
          "title": "Deep Convolutional Generative Network Tutorial in PyTorch",
          "imageUrl": "https://external-preview.redd.it/utVQq87F1wrWhb-gBacSryHzZr55E-ULyT_m6x-lmOQ.jpg?auto=webp&s=2d71b4889755a102de4d31584802e15b2095d710"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tosno9/ai_news_animal_language_translator_ai_heart/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tosno9/ai_news_animal_language_translator_ai_heart/",
          "publishedOn": "2022-03-26T15:18:16.000Z",
          "wordCount": 139,
          "title": "AI News | Animal Language Translator AI | Heart Attack Prediction Algo | Nvidia H100 GPU & AI Supercomputer",
          "imageUrl": "https://external-preview.redd.it/sKV1Sn8z3Ts84j-wd2EuDtNWoqESJUQdjULDAbSSTMs.jpg?auto=webp&s=9c9a5709d0dcd76f3e00e1451b4f5a5ad53d8fc2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tohkd3/researchers_opensource_wiseft_algorithm_for_fine/",
          "author": null,
          "description": "When making zero-shot inference, large pre-trained models like CLIP or ALIGN provide consistent accuracy across various data distributions (i.e., without fine-tuning on a specific dataset). While existing fine-tuning methods vastly improve accuracy on a given target distribution, they frequently compromise robustness to distribution shifts. This conflict can be resolved by presenting a simple and effective strategy for enhancing robustness while fine-tuning: assembling the zero-shot and fine-tuned models (WiSE-FT). \n An approach for fine-tuning AI models that enhance robustness during distribution shift has been open-sourced by researchers from the University of Washington (UW), Google Brain, and Columbia University. According to tests, WISE-FT improves accuracy by up to 6% on specific computer vision (CV) benchmarks.\n Continue Reading The Research Summary Article Here\n Paper: https://arxiv.org/pdf/2109.01903.pdf\n Github: https://github.com/mlfoundations/wise-ft\n https://preview.redd.it/1ltzmg5iwnp81.png?width=2803&format=png&auto=webp&s=6c0727432072b67c1723838e3097ec901f34b1c0\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tohkd3/researchers_opensource_wiseft_algorithm_for_fine/",
          "publishedOn": "2022-03-26T05:15:39.000Z",
          "wordCount": 220,
          "title": "Researchers Open-Source WiSE-FT Algorithm For Fine Tuning AI Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tnxqrq/i_wrote_a_gpt3_based_web_application_to_help/",
          "author": null,
          "description": "submitted by    /u/data-gig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tnxqrq/i_wrote_a_gpt3_based_web_application_to_help/",
          "publishedOn": "2022-03-25T20:01:35.000Z",
          "wordCount": 135,
          "title": "I wrote a GPT-3 based web application to help myself write more effectively - and it worked!",
          "imageUrl": "https://external-preview.redd.it/4I8WwlJR7RskXeDVUxRmmqdm-4oXi2CBSJoM7iVwUr4.jpg?auto=webp&s=c9655ae5a4a14b102bb5284782a0d631aac15fa1"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tnwb4q/my_meme_generating_ai_just_came_up_with_this_not/",
          "author": null,
          "description": "submitted by    /u/snoggel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tnwb4q/my_meme_generating_ai_just_came_up_with_this_not/",
          "publishedOn": "2022-03-25T18:53:29.000Z",
          "wordCount": 142,
          "title": "my meme generating AI just came up with this (not technically AI)",
          "imageUrl": "https://preview.redd.it/x0aizmpetkp81.png?auto=webp&s=e50f8a9f3f90b1193c595613fe97b689d9fe5afb"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tnsnot/this_latest_paper_from_twitter_and_oxford/",
          "author": null,
          "description": "Graph Neural Networks (GNNs) have proved to be effective in a wide range of issues and fields. GNNs commonly use a message-passing mechanism, in which nodes communicate feature representations (“messages”) to their neighbors at each layer. Each node’s feature representation is initialized to its original features, and it is updated by aggregating incoming messages from neighbors on a regular basis. GNNs are distinguished from other purely topological learning systems such as random walks or label propagation by their ability to mix topological and feature information, which is arguably what contributes to their success.\n Typically, GNN models assume a fully observed feature matrix, with rows representing nodes and columns representing channels. In real-world circumstances, however, each trait is frequently only observable for a subset of nodes. Demographic information, for example, maybe exposed to only a small percentage of social network users, while content features are typically only available to the most active users. \n Continue Reading\n Paper: https://arxiv.org/pdf/2111.12128.pdf\n https://preview.redd.it/nylt2m19fkp81.png?width=1024&format=png&auto=webp&s=639c61207d4bffaa4c67f97263fcd5527a849f85\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tnsnot/this_latest_paper_from_twitter_and_oxford/",
          "publishedOn": "2022-03-25T17:33:24.000Z",
          "wordCount": 311,
          "title": "This Latest Paper From Twitter and Oxford Research Shows That Feature Propagation is an Efficient and Scalable Approach for Handling Missing Features in Graph Machine Learning Applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tnpd3g/is_there_a_ai_which_is_able_to_gereate_images/",
          "author": null,
          "description": "submitted by    /u/xXLisa28Xx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tnpd3g/is_there_a_ai_which_is_able_to_gereate_images/",
          "publishedOn": "2022-03-25T16:12:25.000Z",
          "wordCount": 281,
          "title": "Is there a AI which is able to gereate images which people would buy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tnlobi/artificial_intelligence_helps_cut_miss_rate_of/",
          "author": null,
          "description": "submitted by    /u/Beautiful-Credit-868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tnlobi/artificial_intelligence_helps_cut_miss_rate_of/",
          "publishedOn": "2022-03-25T13:14:30.000Z",
          "wordCount": 109,
          "title": "Artificial Intelligence Helps Cut Miss Rate of Colorectal Polyps",
          "imageUrl": "https://external-preview.redd.it/rAW0cilmpuJ8mlUKvS3XH3HN9NKmbw4lty4a-syhKvo.jpg?auto=webp&s=fbf70753e0cd16b439737b08f5fa63f80367d5d5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tnlikk/i_want_to_create_an_ai_to_tell_me_what_to_do_next/",
          "author": null,
          "description": "I dont really know how a i is done i imagine with lots of code i dont know and loads of statistics i really dont know. Can someone out in the land of 1's aand 0's point me in the right direction?\n    submitted by    /u/143openyourmind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tnlikk/i_want_to_create_an_ai_to_tell_me_what_to_do_next/",
          "publishedOn": "2022-03-25T13:05:57.000Z",
          "wordCount": 449,
          "title": "I want to create an A.I. to tell me what to do next. based on my geo location and a wave of factors i will punch in(obvs i know nothing)all guided by a premise (ex..i want to help save our species from destroying itself) any thoughts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tnk4fg/nvidia_stock_rallies_9_with_a_1_trillion/",
          "author": null,
          "description": "submitted by    /u/PM_ME_YOUR_PC_DEALS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tnk4fg/nvidia_stock_rallies_9_with_a_1_trillion/",
          "publishedOn": "2022-03-25T11:45:59.000Z",
          "wordCount": 109,
          "title": "Nvidia stock rallies 9% with a $1 Trillion opportunity",
          "imageUrl": "https://external-preview.redd.it/2P5d0GQfPRFOQqgS7FFCKx0Y2qN38e2Rla07z9gcGss.jpg?auto=webp&s=0a2b3bafdfbb223794d5f47abe3d8587dae40eab"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tnjlrb/combine_lidar_and_cameras_for_3d_object_detection/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tnjlrb/combine_lidar_and_cameras_for_3d_object_detection/",
          "publishedOn": "2022-03-25T11:15:22.000Z",
          "wordCount": 156,
          "title": "Combine Lidar and Cameras for 3D object detection - Waymo & Google Research",
          "imageUrl": "https://external-preview.redd.it/OGzE3sF5Uk6DITpibUX887oZn8KPPebAhdbGkRXsIJE.jpg?auto=webp&s=211302fb9cff3c187d69a385588b21403e42b632"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tnfx18/ml_researchers_from_oxford_propose_a_forward_mode/",
          "author": null,
          "description": "The amount of money and energy necessary to train AI models has become a hot-button issue as they grow in size. Leaders in the AI field have been pouring money towards training increasingly bigger models since GPT-3 proved the considerable gains in performance that can be achieved by merely increasing model size. However, this is prohibitively expensive, necessitates tremendous computational resources, consumes enormous energy, and is becoming more recognized as an issue, not just because of the environmental implications, but also because it makes it harder for smaller AI companies to compete, concentrating power in the hands of industry titans. A new technique that rewrites one of the discipline’s core building pieces could give a workaround.\n Oxford University researchers have proposed a novel method that might cut training time in half. This is accomplished by redesigning backpropagation, one of the essential components of today’s neural network-based AI systems. Backpropagation has remained a mainstay of machine learning for computing gradients of objective functions for optimization. Backpropagation, also known as reverse-mode differentiation, is a subset of the general family of automatic differentiation algorithms that includes forward mode differentiation. A method for computing gradients based purely on the directional derivative, which may be done in the forward mode with precision and efficiency, is designed. The method is known as the forward gradient, which is an unbiased estimate of the gradient that can be assessed in a single forward run of the function, obviating the necessity for backpropagation in gradient descent completely.\n Continue Reading The Research Summary\n Paper: https://arxiv.org/pdf/2202.08587.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tnfx18/ml_researchers_from_oxford_propose_a_forward_mode/",
          "publishedOn": "2022-03-25T06:37:47.000Z",
          "wordCount": 612,
          "title": "ML Researchers From Oxford Propose a Forward Mode Method to Compute Gradients Without Backpropagation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tn87vf/apple_ml_researchers_introduce_mobilevit_a/",
          "author": null,
          "description": "To learn visual representations, self-attention-based models, particularly vision transformers, offer an alternative to convolutional neural networks (CNNs). ViT breaks an image into a series of non-overlapping patches and then uses multi-headed self-attention in transformers to learn interpatch representations. The typical trend in ViT networks is to increase the number of parameters to improve performance.\n These gains in performance come at the expense of model size (network parameters) and latency. Many real-world applications (such as augmented reality and autonomous wheelchairs) necessitate the timely execution of visual recognition tasks (such as object detection and semantic segmentation) on resource-constrained mobile devices.\n ViT models for such jobs should be light-weight and quick to be effective. ViT models’ performance is much inferior to light-weight CNNs, even when the model size is reduced to fit the resource limits of mobile devices. DeIT, for example, is 3% less accurate than MobileNetv3 for a parameter budget of roughly 5-6 million. As a result, designing light-weight ViT models is critical.\n Many mobile vision tasks have been powered by light-weight CNNs. ViT-based networks, on the other hand, are still a long way from being utilized on such devices. Unlike light-weight CNNs that are simple to optimize and integrate with task-specific networks, ViTs are large (e.g., ViT-B/16 vs. MobileNetv3: 86 vs. 7.5 million parameters), difficult to optimize, require extensive data augmentation and L2 regularisation to avoid over-fitting, and require expensive decoders for downstream tasks, particularly dense prediction tasks.\n Continue Reading The Research Summary\n Paper: https://arxiv.org/pdf/2110.02178.pdf\n Github: https://github.com/apple/ml-cvnets\n https://preview.redd.it/u1m6udvqyep81.png?width=1198&format=png&auto=webp&s=b12153662902056706dd2ff92459c625233bb785\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tn87vf/apple_ml_researchers_introduce_mobilevit_a/",
          "publishedOn": "2022-03-24T23:12:01.000Z",
          "wordCount": 358,
          "title": "Apple ML Researchers Introduce ‘MobileViT’: A Light-Weight And General-Purpose Vision Transformer For Mobile Devices",
          "imageUrl": "https://external-preview.redd.it/yrkXxR7Ej07VbiAqLTQiw9O5C9XitgCNHxqsOmadiYM.jpg?auto=webp&s=f3160a7770029813ed6c68d56e13b0ba688b747f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tn2gga/nick_walton_on_ai_dungeon_and_the_future_of_ai_in/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tn2gga/nick_walton_on_ai_dungeon_and_the_future_of_ai_in/",
          "publishedOn": "2022-03-24T20:29:25.000Z",
          "wordCount": 118,
          "title": "Nick Walton on AI Dungeon and the Future of AI in Games",
          "imageUrl": "https://external-preview.redd.it/FZcBL4EnmL9H6rlyctzhjPUSb_u5GBg_7kWaKgkgHDE.jpg?auto=webp&s=a457af85c4948067ac2591d00f0ec5c02d1e356b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tmutkc/last_week_in_ai_ai_for_algorithms_chemical/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tmutkc/last_week_in_ai_ai_for_algorithms_chemical/",
          "publishedOn": "2022-03-24T18:42:49.000Z",
          "wordCount": 121,
          "title": "Last Week in AI: AI for Algorithms, Chemical Weapons, Zelenskyy Deepfake, Border Control",
          "imageUrl": "https://external-preview.redd.it/Kl1rNrwLvVQWCeFeYH4U_OwR89ChMaEKMzT4IBxJts4.jpg?auto=webp&s=f039120d33fc2145c69bdc79a3d414e3c118b6ce"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tmrdy4/using_5_different_ai_generated_images_i_created_1/",
          "author": null,
          "description": "submitted by    /u/bigshinna  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tmrdy4/using_5_different_ai_generated_images_i_created_1/",
          "publishedOn": "2022-03-24T17:53:43.000Z",
          "wordCount": 173,
          "title": "using 5 different ai generated images i created 1 artwork, second picture show the original pics i made/used, what do you guys think",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tmg2ij/transformerbased_chatbot_stylized_text_generation/",
          "author": null,
          "description": "I did a quick search of huggingface but couldn't find anything. Has anyone tried making a transformer-based reply bot or chatbot that responds to both images and text, like how a person would be able to chat in messaging apps? I thought about this because I figured tweet generation models would be much more interesting if they could also generate replies instead of standalone tweets, and replies by tweeters more often than not are replies to tweets with images. \n I was thinking not only do you need an image-to-text model, you probably also need finetuning data that includes an image-to-text model? I guess understanding context would be major obstacle.\n Thanks!\n    submitted by    /u/IndicatorGlobe679  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tmg2ij/transformerbased_chatbot_stylized_text_generation/",
          "publishedOn": "2022-03-24T15:10:42.000Z",
          "wordCount": 223,
          "title": "Transformer-based chatbot / stylized text generation model that responds to images and text?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tmej7f/bmw_group_qualcomm_and_arriver_to_form/",
          "author": null,
          "description": "submitted by    /u/dannylenwinn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tmej7f/bmw_group_qualcomm_and_arriver_to_form/",
          "publishedOn": "2022-03-24T14:39:43.000Z",
          "wordCount": 136,
          "title": "BMW Group, Qualcomm and Arriver to form long-lasting strategic cooperation for joint development of Automated Driving software solutions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tmcm2z/career_advice_for_a_soontobe_masters_graduate_in/",
          "author": null,
          "description": "I'm a soon-to-be master's graduate in artificial intelligence and I'm looking for some career advice. I most likely want to go for a PhD because I enjoy thinking about challenging problems and trying out new things. My dream job would be to work as a research scientist in the industry, which would guarantee a good salary (as opposed to academia), applied value in the research I do, and some creativity. Currently, I am considering different research avenues while keeping in mind a potential trade-off between utility, potential to be creative, intrinsic motivation, and future job prospects. While intrinsic motivation is definitely important to me, I really see a PhD as an investment in my future. That is, I want my job prospects to signficantly improvea after completing it. Furthermore, I am…",
          "link": "https://www.reddit.com/r/artificial/comments/tmcm2z/career_advice_for_a_soontobe_masters_graduate_in/",
          "publishedOn": "2022-03-24T14:10:58.000Z",
          "wordCount": 2137,
          "title": "Career advice for a soon-to-be master's graduate in AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tm2s08/best_resources_to_learn_data_science_2022_courses/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tm2s08/best_resources_to_learn_data_science_2022_courses/",
          "publishedOn": "2022-03-24T10:25:35.000Z",
          "wordCount": 115,
          "title": "Best Resources to Learn Data Science 2022 (courses, books, Blogs) -",
          "imageUrl": "https://external-preview.redd.it/GtThG67eeXavtXPFeI7gxo9h7Jil6AWEGKfLrdWpWGU.jpg?auto=webp&s=3790397b7c0b7d3315bd6dde0d17374588ad0a97"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tlz9ve/some_aitype_thing_is_being_used_to_cause_severe/",
          "author": null,
          "description": "This is not an attempt to bend any forum rules, I am not looking for someone in this forum to hack for us or anything. We just need advice as to where to look more than the avenues we have taken.\n TL;DR: Girlfriend is being stalked by some A.I.-type thing that very specifically, and very repeatedly, targets her and reminds her of abuse and we don't know where to turn for more help, or what it could be, and where it is coming from.\n Now the details:\n Over the last year or so, her phone was hacked and started acting funny, apps not working right, etc. During the same time, someone she knew got a hold of her bank information and ID. Someone also logged into Github on her phone (we are only familiar with generally what they do or what can be done there). People started following her around in …",
          "link": "https://www.reddit.com/r/artificial/comments/tlz9ve/some_aitype_thing_is_being_used_to_cause_severe/",
          "publishedOn": "2022-03-24T06:14:13.000Z",
          "wordCount": 923,
          "title": "Some A.I.-type thing is being used to cause Severe Emotional Trauma",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tlz6fp/rainbow_forests_ai_art/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tlz6fp/rainbow_forests_ai_art/",
          "publishedOn": "2022-03-24T06:07:25.000Z",
          "wordCount": 96,
          "title": "Rainbow Forests AI Art",
          "imageUrl": "https://external-preview.redd.it/1EhkssR_YUI4dOXbVt2GasUujJJTBDmbSVQvNvKAfaA.jpg?auto=webp&s=96dd2bfa6904d32592bcf8f8c47d11ab0b2e942e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tlvodv/cyberpunk_breakdown_3_how_to_draw_perspective/",
          "author": null,
          "description": "submitted by    /u/Puzzleheaded-Gas-906  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tlvodv/cyberpunk_breakdown_3_how_to_draw_perspective/",
          "publishedOn": "2022-03-24T02:39:32.000Z",
          "wordCount": 107,
          "title": "cyberpunk breakdown #3. How to draw perspective from cyberpunk 2077",
          "imageUrl": "https://external-preview.redd.it/Cp9gydjuvdd907AAE9HqehCdSuAoxk1Br3BvLFieMaA.jpg?auto=webp&s=9509bb6bef91bfb6a97473c4514331bcb555c65f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tljxox/to_help_ukraine_berkeley_ai_researchers_provide/",
          "author": null,
          "description": "Extracting knowledge and actionable insights by manually processing hundreds of terabytes of data downlinked from satellites to data centers has become difficult.\n Synthetic aperture radar (SAR) imaging is a type of active remote sensing in which a satellite sends microwave radar wave pulses down to the Earth’s surface. These radar signals return to the satellite after reflecting off the Earth and any objects. A SAR image is created by processing these pulses over time and space, with each pixel representing the superposition of multiple radar scatters. Radar waves penetrate clouds and illuminate the Earth’s surface even during nights because the satellite is actively creating them.\n They produce visual that is sometimes contradictory and incompatible with modern computer vision systems. Three common effects are polarisation, layover, and multi-path.\n  \nThe layover effect occurs when radar beams reach the top of a structure before reaching the bottom. This causes the top of the object to appear to be overlapping with the bottom. \n When radar waves reflect off objects on the ground and bounce numerous times before returning to the SAR sensor, this is known as multi-path effects. Multi-path effects cause things in the picture to appear in multiple transformations in the final image.\n  \nContinue reading this research summary here\n BAIR Blog: https://bair.berkeley.edu/blog/2022/03/21/ukraine-sar-maers/\n https://i.redd.it/1r05r2mks7p81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tljxox/to_help_ukraine_berkeley_ai_researchers_provide/",
          "publishedOn": "2022-03-23T23:04:50.000Z",
          "wordCount": 334,
          "title": "To help Ukraine, Berkeley AI Researchers Provide Machine Learning Methods And Pretrained Models To Interchangeably Use Any Imagery",
          "imageUrl": "https://external-preview.redd.it/BHrVv_gNV3Z9g3sozknq5zWc3WwCq_IBAuAf96RdD84.jpg?auto=webp&s=7a98248508176527754bc71e2f59267c27c2b881"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tldie4/what_is_the_state_of_the_art_for_poker_ai/",
          "author": null,
          "description": "I see a few articles about Facebook's Pluribus claiming to outperform multiple human pros two years back, but that looks a little dubious to me:\n  \nThe paper explaining it is super basic, which is not what you'd expect from the people who finally solved poker. It has entire pages dedicated to illustrations about the game theory of tic-tac-toe\n \nI've seen people arguing about whether it's merely counting cards (which isn't the same as out-strategizing humans)\n \nTheir metrics for success seem questionable, like they have a graph of cumulative chips won that goes up - which seems great but would also happen if some of the human pros could still outperform it on average\n \n What is the actual best we've done at teaching computers poker strategy?\n    submitted by    /u/WouldThatIKnew0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tldie4/what_is_the_state_of_the_art_for_poker_ai/",
          "publishedOn": "2022-03-23T20:43:04.000Z",
          "wordCount": 257,
          "title": "What is the state of the art for poker AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tlbdmw/looking_for_a_story_about_ai/",
          "author": null,
          "description": "I'm looking for a story about a company that makes a machine trained to write letters. The company (against their rules) decides to connect the machine to the internet and it rapidly becomes smarter than all of humanity and wipes them out in a handful of days.\n If anyone knows where this story is at, please let me know. Trying to show it to someone, ty!\n    submitted by    /u/V4locity  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tlbdmw/looking_for_a_story_about_ai/",
          "publishedOn": "2022-03-23T20:02:22.000Z",
          "wordCount": 241,
          "title": "Looking for a story about AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tl0e5l/for_those_who_want_to_automate_sms_with_chatbots/",
          "author": null,
          "description": "A regular SMS message sent from a business – like a promotion or a welcome message – is a common one-way communication. A chatbot, instead, provides a two-way conversation: it can ask questions, process the answer, and continue the communicational path to subscribe, qualify leads and even sell. \n But here are things to keep in mind:\n  \nYou'll pay for every message.\n You should also keep in mind the character limit. A single SMS message should include no more than 160 characters encoded using the GSM-7 character set.\n If using SMS, you’ll also need to update relevant legal pages like terms of service and privacy policy, with details on how SMS consent will be handled.\n Many countries may have additional regulations. For the US, all SMS messaging in The United States of America is governed by the CTIA – The Wireless Association.\n Another point is media limits. SMS does not allow sending videos or attachments. You may send an image with an MMS but keep in mind the cost of it is different than for a text-only SMS. \n  \nOverall, there are more benefits to SMS chatbots, and if you've been thinking on them for a long time, here's a guide to help you starting out https://botscrew.com/blog/sms-chatbot-a-complete-guide-for-business-use-cases/?utm_source=Reddit&utm_medium=artificial&utm_campaign=44643&utm_term=&utm_content=\n    submitted by    /u/Avandegraund  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tl0e5l/for_those_who_want_to_automate_sms_with_chatbots/",
          "publishedOn": "2022-03-23T16:44:09.000Z",
          "wordCount": 303,
          "title": "For those who want to automate SMS with chatbots",
          "imageUrl": "https://external-preview.redd.it/1iOJ4MnqMYxc5r_VRtGugJVvkBzazoVJVBWMzYXO1po.jpg?auto=webp&s=570d0a0e07c3a9bd452e080a178039e78025e119"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tkwsbu/what_is_project_zcode/",
          "author": null,
          "description": "submitted by    /u/Beautiful-Credit-868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tkwsbu/what_is_project_zcode/",
          "publishedOn": "2022-03-23T15:42:13.000Z",
          "wordCount": 94,
          "title": "What is Project Z-code?",
          "imageUrl": "https://external-preview.redd.it/3Rl3_TaZTTsOtuxNDmIcfVqvMH5jB7S-lY94P6f9PXw.jpg?auto=webp&s=816af5eac9f34c589f872f2b331404622a6908ca"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tkmvbd/microsoft_improves_its_ai_translations_with_zcode/",
          "author": null,
          "description": "submitted by    /u/nonaime7777777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tkmvbd/microsoft_improves_its_ai_translations_with_zcode/",
          "publishedOn": "2022-03-23T05:29:09.000Z",
          "wordCount": 109,
          "title": "Microsoft improves its AI translations with Z-Code – TechCrunch",
          "imageUrl": "https://external-preview.redd.it/7bxAxja3YvI3qGRDu3ZLNA_xQGFCzseBRb67G7AR5pU.jpg?auto=webp&s=d17e69d2fde166a6c827f186e4cede155cabf0a4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tkakgw/weve_got_incredible_potential_here_to_use_the/",
          "author": null,
          "description": "submitted by    /u/thedyezwfl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tkakgw/weve_got_incredible_potential_here_to_use_the/",
          "publishedOn": "2022-03-22T19:11:42.000Z",
          "wordCount": 303,
          "title": "\"We've got incredible potential here to use the Sophiaverse virtual world, not just as a fun way for people to play or make money by selling NFTs they create, but also as a way to get human values and culture and the pragmatics of human interaction across to AI.\"- Ben Goertzel, CEO at SingularityNET",
          "imageUrl": "https://preview.redd.it/xuq0g9vynyo81.jpg?auto=webp&s=11e16e04da97aa024964a931668cfb38fb91a469"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk8emn/google_research_proposes_maskgit_a_new_deep/",
          "author": null,
          "description": "Generative Adversarial Networks (GANs), with their capacity of producing high-quality images, have been the leading technology in image generation for the past couple of years. Nevertheless, their minimax learning mechanism brought out different limits, such as training instability and mode collapse (i.e., when all the produced samples belong to a small set of samples).\n Recently, Generative Transformer models are beginning to match, or even surpass, the performances of GANs. The simple idea is to learn a function to encode the input image into a quantized sequence and then train an autoregressive Transformer on a sequence prediction task (i.e., predict an image token, given all the previous image tokens). This learning is based on maximum likelihood and thus not affected by the same issue…",
          "link": "https://www.reddit.com/r/artificial/comments/tk8emn/google_research_proposes_maskgit_a_new_deep/",
          "publishedOn": "2022-03-22T17:36:25.000Z",
          "wordCount": 452,
          "title": "Google Research Proposes MaskGIT: A New Deep Learning Technique Based on Bi-Directional Generative Transformers For High-Quality and Fast Image Synthesis",
          "imageUrl": "https://external-preview.redd.it/P44rjseyjp7TqR2CQ_-Nzc57Y1RHioUHIlMR614CUSU.jpg?auto=webp&s=5da9ba113569dc16dfafcb8cc0cac456ee2deb55"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk7g4r/i_decided_to_make_roads_out_of_the_lorenz/",
          "author": null,
          "description": "submitted by    /u/TheRealMandelbrotSet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tk7g4r/i_decided_to_make_roads_out_of_the_lorenz/",
          "publishedOn": "2022-03-22T16:53:49.000Z",
          "wordCount": 130,
          "title": "I decided to make roads out of the Lorenz attractor…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk75y0/nvidia_unveils_latest_chip_to_speed_up_ai/",
          "author": null,
          "description": "submitted by    /u/nonaime7777777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tk75y0/nvidia_unveils_latest_chip_to_speed_up_ai/",
          "publishedOn": "2022-03-22T16:40:45.000Z",
          "wordCount": 109,
          "title": "Nvidia unveils latest chip to speed up AI computing",
          "imageUrl": "https://external-preview.redd.it/jyW7I7mZUJ50RWBTXw_bwJUnok-aAT88wcSc_6ISJpo.jpg?auto=webp&s=dcb9cc1993317118b0e0b728cb6512d204f17463"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk75t9/software_company_releases_chrome_extension_that/",
          "author": null,
          "description": "submitted by    /u/nonaime7777777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tk75t9/software_company_releases_chrome_extension_that/",
          "publishedOn": "2022-03-22T16:40:33.000Z",
          "wordCount": 112,
          "title": "Software Company Releases Chrome Extension That Detects AI-Generated Profile Pictures",
          "imageUrl": "https://external-preview.redd.it/QLUlUDkZUsgkVF0Bu4K5uIkAdt0xz34y4c7ioeQytfI.jpg?auto=webp&s=b397049cff808419af0452134d20b76d44eaa217"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk6u6j/ai_combines_with_decentralized_autonomous/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tk6u6j/ai_combines_with_decentralized_autonomous/",
          "publishedOn": "2022-03-22T16:26:26.000Z",
          "wordCount": 105,
          "title": "AI Combines With Decentralized Autonomous Organization",
          "imageUrl": "https://external-preview.redd.it/W85lvv0Rwcy0F1DXmfx-qKlVJu2XMlT0bQ4AAOcoHqU.jpg?auto=webp&s=258c513ef2a989fdb18bc592aaf42834e4975930"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk6akk/alphabet_is_spinning_out_division_x_sandbox_aq/",
          "author": null,
          "description": "submitted by    /u/Beautiful-Credit-868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tk6akk/alphabet_is_spinning_out_division_x_sandbox_aq/",
          "publishedOn": "2022-03-22T16:02:23.000Z",
          "wordCount": 106,
          "title": "Alphabet is Spinning out Division X 'Sandbox AQ'",
          "imageUrl": "https://external-preview.redd.it/or-ZEWmbgRf3hgAWsZzsWQWxVfBEimqHzdm0fuhyO14.jpg?auto=webp&s=eb9b93a1b1aed08df056828d194d560f22969bdf"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk5tgc/this_is_the_reason_why_sleep_robots_are_becoming/",
          "author": null,
          "description": "submitted by    /u/sopadebombillas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tk5tgc/this_is_the_reason_why_sleep_robots_are_becoming/",
          "publishedOn": "2022-03-22T15:41:06.000Z",
          "wordCount": 121,
          "title": "This Is The Reason Why Sleep Robots Are Becoming The Perfect Bed Mates",
          "imageUrl": "https://external-preview.redd.it/-M0y6xYt4Fi2RZjs9XL-P8EjI-6YRjC6xBibj3D8icI.jpg?auto=webp&s=368c1cd874e6c4f024ad01df3961964a9ce9ba9a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk4141/unraveling_the_mystery_behind_background_filters/",
          "author": null,
          "description": "submitted by    /u/VikasOjha666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tk4141/unraveling_the_mystery_behind_background_filters/",
          "publishedOn": "2022-03-22T14:18:01.000Z",
          "wordCount": 107,
          "title": "Unraveling the Mystery Behind Background Filters in Video Calling Apps",
          "imageUrl": "https://external-preview.redd.it/TIxIOOwPswD9jcM3ukBYN3MxcH9Fr0CO7hu6S4BODLw.jpg?auto=webp&s=430582d2c861f0c9c92a15a5a34ed86ddf49b3ac"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk1szs/artificial_intelligence_in_the_news_the_period_of/",
          "author": null,
          "description": "submitted by    /u/Beautiful-Credit-868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tk1szs/artificial_intelligence_in_the_news_the_period_of/",
          "publishedOn": "2022-03-22T12:25:12.000Z",
          "wordCount": 115,
          "title": "Artificial Intelligence in the News (the period of March 21st, 2022)",
          "imageUrl": "https://external-preview.redd.it/6UVcTMgdd_Csi3Bz64AGvDeiu1aZaDzYcuYHgllFQTk.jpg?auto=webp&s=e239affbac77ff4546a9eb01ea86fa8213ca5723"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk0woa/best_machine_learning_books_to_read_in_2022/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tk0woa/best_machine_learning_books_to_read_in_2022/",
          "publishedOn": "2022-03-22T11:34:18.000Z",
          "wordCount": 109,
          "title": "Best Machine Learning Books to read in 2022 -",
          "imageUrl": "https://external-preview.redd.it/wR9YilM7n4reCaTiQQJ0B7DlYVkbtwbvQT6O7Zs7jOc.jpg?auto=webp&s=07f167ef17cf57696b4100b439203e778619cf44"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tk0w2q/could_it_be_that_people_spend_a_lot_of_money_on/",
          "author": null,
          "description": "submitted by    /u/xXNOdrugsForMEXx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tk0w2q/could_it_be_that_people_spend_a_lot_of_money_on/",
          "publishedOn": "2022-03-22T11:33:17.000Z",
          "wordCount": 152,
          "title": "Could it be, that people spend a lot of money on AIs, which are generating realistic images and then sell the copyright of these images?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjzxm5/nebullvm_an_opensource_library_to_accelerate_ai/",
          "author": null,
          "description": "How does nebullvm work?\n It takes your AI model as input and outputs an optimized version that runs 5-20 times faster on your hardware. In other words, nebullvm tests multiple deep learning compilers to identify the best possible way to execute your model on your specific machine, without impacting the accuracy of your model.\n And that's it. In just a few lines of code.\n And a big thank you to everyone for supporting this open-source project! The library received 250+ Github stars⭐ on release day, and that's just amazing 🚀\n ORIENTATION MAP\n Let's learn more about nebullvm and AI optimization. Where should we start? From...\n  \nSome CONTEXT on why few developers optimize AI and related negative consequences\n An overview of how the LIBRARY works\n Some USE CASES, technology demonstrations and…",
          "link": "https://www.reddit.com/r/artificial/comments/tjzxm5/nebullvm_an_opensource_library_to_accelerate_ai/",
          "publishedOn": "2022-03-22T10:31:22.000Z",
          "wordCount": 1827,
          "title": "Nebullvm, an open-source library to accelerate AI inference by 5-20x in a few lines of code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjzeqb/are_there_any_ais_to_try_and_recreate_the_voice/",
          "author": null,
          "description": "Im wondering if there is any ai that you can feed your voice to and it will try to make an approximation of what you sound like to yourself in your head?\n    submitted by    /u/alidan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjzeqb/are_there_any_ais_to_try_and_recreate_the_voice/",
          "publishedOn": "2022-03-22T09:54:27.000Z",
          "wordCount": 417,
          "title": "Are there any ai's to try and recreate the voice you hear in your head?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjwzn9/realtime_language_model/",
          "author": null,
          "description": "submitted by    /u/BeginningInfluence55  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjwzn9/realtime_language_model/",
          "publishedOn": "2022-03-22T06:54:17.000Z",
          "wordCount": 493,
          "title": "Real-Time (Language) Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjwrla/looking_for_a_speaker_for_a_webinar_about/",
          "author": null,
          "description": "Hi guys!, we are University Students and we're currently looking for a speaker that can discuss Artificial Intelligence on an introductory level and the Opportunities it can bring for Engineering Students. Thank you! Please DM asap me for more details.\n    submitted by    /u/BigBadToilet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjwrla/looking_for_a_speaker_for_a_webinar_about/",
          "publishedOn": "2022-03-22T06:38:31.000Z",
          "wordCount": 146,
          "title": "Looking for a Speaker for a Webinar about Artificial Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjqch7/weekly_china_ai_newsletter_cambricon_stocks/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjqch7/weekly_china_ai_newsletter_cambricon_stocks/",
          "publishedOn": "2022-03-22T00:27:16.000Z",
          "wordCount": 157,
          "title": "Weekly China AI Newsletter: Cambricon Stocks Plunge After Sudden Exit of Huawei Veteran CTO; US-Banned DeepGlint Goes Public; China-US AI Collaboration Rises Fivefold Since 2010",
          "imageUrl": "https://external-preview.redd.it/e_zkkEIUf1JTeX9k2faegcXER3GW5f1JzkRQF8ggvTU.jpg?auto=webp&s=fbc7f0a10e2aab21b2546549700c082d350d5f36"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjpcax/a_miniconversation_with_albert_einsteins_ai/",
          "author": null,
          "description": "submitted by    /u/kuasha7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjpcax/a_miniconversation_with_albert_einsteins_ai/",
          "publishedOn": "2022-03-21T23:37:42.000Z",
          "wordCount": 96,
          "title": "A mini-conversation with Albert Einstein's AI persona",
          "imageUrl": "https://external-preview.redd.it/nyFf4FepT7AlRlB5ehuE4ELkprCxmbseFn_zzzz867U.png?format=pjpg&auto=webp&s=3df508b64e82a4aa75a099a0b0d389622e65916b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjp7lu/generate_new_designs_based_on_provided_dataset/",
          "author": null,
          "description": "I am looking to generate new car wheel designs based on a dataset I have of my own 30-50 wheels. I was wondering if there is a tool/GAN that would suit this?\n    submitted by    /u/jrobin51  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjp7lu/generate_new_designs_based_on_provided_dataset/",
          "publishedOn": "2022-03-21T23:31:23.000Z",
          "wordCount": 129,
          "title": "Generate new designs based on provided dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjmsq4/the_advantages_and_disadvantages_of_ai_in/",
          "author": null,
          "description": "Artificial intelligence is generally praised for their use in many sectors. One of the most notable achievements of AI in science is its breakthrough in molecular biology as it helped reduce the time to identify the structure of complicated 3D protein folds. AI has also helped advance the efficiency in quantum computers, and now AI is making a large presence in clinical/healthcare. Despite the potential of AI being revolutionary in healthcare we must be cautious utilizing it. I want to highlight the advantages and disadvantages of AI to inspire and to set forth challenges for you to approach in the future. \n The advantage of AI in healthcare is its versatile applications. You can find developments in many topics of healthcare such as drug discovery, image processing, data analysis, and mor…",
          "link": "https://www.reddit.com/r/artificial/comments/tjmsq4/the_advantages_and_disadvantages_of_ai_in/",
          "publishedOn": "2022-03-21T21:41:31.000Z",
          "wordCount": 2,
          "title": "The advantages and disadvantages of AI in healthcare",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjldtr/last_week_in_ai_ai_discovers_lethal_molecules/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjldtr/last_week_in_ai_ai_discovers_lethal_molecules/",
          "publishedOn": "2022-03-21T20:37:10.000Z",
          "wordCount": 151,
          "title": "Last Week in AI: AI discovers lethal molecules, Deepfake of Ukrainian President Volodymyr Zelenskyy, All-MLP AI model is fast and efficient, and more!",
          "imageUrl": "https://external-preview.redd.it/UwgW9JN6L9J3Ftitlyk0Hh1jcoRcj_iNSiHh733JWxo.jpg?auto=webp&s=be58c38ece182f390b9f75703f8cc7cae5974043"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjhhp5/grapes/",
          "author": null,
          "description": "submitted by    /u/cookingandcraft  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjhhp5/grapes/",
          "publishedOn": "2022-03-21T17:46:13.000Z",
          "wordCount": 87,
          "title": "Grapes.",
          "imageUrl": "https://external-preview.redd.it/-dbTe0ZY9tB3ZjV20XTuONU3hF1ObHG_BdEDFE5CoTE.jpg?auto=webp&s=b295f22a09d3715bcc304aea8b0fdaa19f93f569"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjfnnz/coined_in_2016_aiops_stands_for_artificial/",
          "author": null,
          "description": "​\n https://reddit.com/link/tjfnnz/video/e1hw1trsiro81/player\n    submitted by    /u/Nitorblog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjfnnz/coined_in_2016_aiops_stands_for_artificial/",
          "publishedOn": "2022-03-21T16:23:57.000Z",
          "wordCount": 170,
          "title": "Coined in 2016, AIOps stands for Artificial Intelligence for IT Operations which combines big data and machine learning to automate IT operation processes. Watch this video to learn all about it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjel6a/artificial_intelligence_and_a_sense_of_time/",
          "author": null,
          "description": "Hi all,\n I've been interested in pattern theory for a bit, and as far as I can tell it can be viewed as a framework for artificial intelligence. In Grenander's book \"Calculus of Thoughts\" David Mumford mentions that a major issue with pattern theory is the creation of generators and modalities of bonds.\n For the bonds, has anyone tried basing their properties on a sense of time? I.e. in whatever environment a program is in, it would have a clock measuring time, and would somehow equate these bonds simply with events happening close to each other in time.\n Apologies if this is a naïve/vague/nonsensical question, I'm enthusiastic but not too knowledgeable about pattern theory. Any feedback is greatly appreciated\n    submitted by    /u/patterntheoryacc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjel6a/artificial_intelligence_and_a_sense_of_time/",
          "publishedOn": "2022-03-21T15:36:58.000Z",
          "wordCount": 213,
          "title": "Artificial Intelligence and a Sense of Time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjdd0l/is_there_some_sort_of_ai_image_generator_that/",
          "author": null,
          "description": "I need an Ai image generator that takes an image and generates what is beyond the border of that image.\n for example if i have an image of the front half of a dog, it fills in the other half of the dog \n im going to use it to extend a picture of a building btw\n    submitted by    /u/Bingela_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjdd0l/is_there_some_sort_of_ai_image_generator_that/",
          "publishedOn": "2022-03-21T14:42:03.000Z",
          "wordCount": 205,
          "title": "is there some sort of Ai image generator that continues an image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjchwc/the_case_for_humancentered_ai/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjchwc/the_case_for_humancentered_ai/",
          "publishedOn": "2022-03-21T14:01:21.000Z",
          "wordCount": 97,
          "title": "The case for human-centered AI",
          "imageUrl": "https://external-preview.redd.it/L3V-K0s9n3fgutgTpK0h_1ikkZ3nRY6ZqxZ6MZCLjMg.jpg?auto=webp&s=54ddee3b5ecf6677f758dc8d1a7f15602f01533a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjblgg/weekly_metaverse_digest_3_virtual_humans_hsbc/",
          "author": null,
          "description": "submitted by    /u/bent_out_of_shape_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjblgg/weekly_metaverse_digest_3_virtual_humans_hsbc/",
          "publishedOn": "2022-03-21T13:15:52.000Z",
          "wordCount": 136,
          "title": "Weekly metaverse digest #3: virtual humans, HSBC gears for the metaverse, real estate of the future, and more",
          "imageUrl": "https://external-preview.redd.it/qOPcg9gt3eAiPD06lzJrAf5aRlWE97CMMYh0xWkZ-rA.jpg?auto=webp&s=05b16458f881d063d80f59501069949feefdcf30"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tjaai9/which_trends_do_you_think_will_have_the_biggest/",
          "author": null,
          "description": "View Poll\n    submitted by    /u/futureanalytica  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tjaai9/which_trends_do_you_think_will_have_the_biggest/",
          "publishedOn": "2022-03-21T12:07:48.000Z",
          "wordCount": 272,
          "title": "Which trends do you think will have the biggest impact on businesses in the upcoming years?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tj87bs/chemical_x_numbuh841/",
          "author": null,
          "description": "submitted by    /u/VIRUS-AOTOXIN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tj87bs/chemical_x_numbuh841/",
          "publishedOn": "2022-03-21T09:57:15.000Z",
          "wordCount": 88,
          "title": "Chemical X NUMBUH-841",
          "imageUrl": "https://preview.redd.it/d9cxqlx9mpo81.png?auto=webp&s=f2f91e95cef0572f895f26699474d6e8596cf798"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tj6ukr/performance_testing_fastapi_ml_apis_with_locust/",
          "author": null,
          "description": "submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tj6ukr/performance_testing_fastapi_ml_apis_with_locust/",
          "publishedOn": "2022-03-21T08:21:25.000Z",
          "wordCount": 112,
          "title": "Performance testing FastAPI ML APIs with Locust | Rubik's Code",
          "imageUrl": "https://external-preview.redd.it/RJASnkisG1D_efNVSaKnxcyWhaf8R_VscIvLSSQ3EiY.jpg?auto=webp&s=92e7da95854271a56cc7a6a9bee866e169d1beb4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tj56i8/has_anyone_trained_an_ai_to_tell_apart_nudity_in/",
          "author": null,
          "description": "I know the question sounds funny but I mean it seriously. Is there something trained like this, that could be easily plugged to something like FFmpeg?\n Doing it on every frame would probably be too slow, but one could probably do it only on P-frames with a very small increase of error rate.\n    submitted by    /u/flying-benedictus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tj56i8/has_anyone_trained_an_ai_to_tell_apart_nudity_in/",
          "publishedOn": "2022-03-21T06:23:17.000Z",
          "wordCount": 408,
          "title": "Has anyone trained an AI to tell apart nudity in images, so it can be used to filter frames/scenes in or out of a video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tj4dfd/switchblade_drones_join_the_fight_usmade_drones/",
          "author": null,
          "description": "submitted by    /u/dannylenwinn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tj4dfd/switchblade_drones_join_the_fight_usmade_drones/",
          "publishedOn": "2022-03-21T05:27:48.000Z",
          "wordCount": 300,
          "title": "Switchblade Drones join the fight: U.S.-made drones will be sent to Ukraine with the additional $800 million in military assistance that Joe Biden announced on Wednesday. At least 100 Switchblade Tactical Drones will be in the package.",
          "imageUrl": "https://external-preview.redd.it/d6fkTVIAXy3XY4Spd79NIq1ZNbOgITKa-YMFbda96Cw.jpg?auto=webp&s=eafcc84411f7aa38b461a4d9397a2c6076506b74"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tj1kw3/linkedin_researchers_opensource_fasttreeshap_a/",
          "author": null,
          "description": "Researchers from LinkedIn open-source the FastTreeSHAP package which is a Python module based on the paper ‘Fast TreeSHAP: Accelerating SHAP Value Computation for Trees.’ Implementing the widely-used TreeSHAP algorithm in the SHAP package allows for the efficient interpretation of tree-based machine learning models by estimating sample-level feature significance values. Its package includes two new algorithms: FastTreeSHAP v1 and FastTreeSHAP v2, both of which improve TreeSHAP’s computational efficiency by taking a different approach. \n The empirical benchmarking tests show that FastTreeSHAP v1 is 1.5x faster than TreeSHAP while keeping memory costs the same, and FastTreeSHAP v2 is 2.5x faster while using slightly more memory. The FastTreeSHAP package fully supports parallel multi-core computing to speed up its computation.\n Continue Reading The Full Summary Article\n Paper: https://arxiv.org/pdf/2109.09847.pdf\n Github: https://github.com/linkedin/fasttreeshap\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tj1kw3/linkedin_researchers_opensource_fasttreeshap_a/",
          "publishedOn": "2022-03-21T02:42:16.000Z",
          "wordCount": 249,
          "title": "LinkedIn Researchers Open-Source ‘FastTreeSHAP’: A Python Package That Enables An Efficient Interpretation of Tree-Based Machine Learning Models",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tipnnm/mit_researchers_developed_a_machinelearning_model/",
          "author": null,
          "description": "Many machine learning tasks require high-quality data, such as assessing damage in a satellite that negatively affects a model’s performance. Datasets can cost millions of dollars to create if useable data exists, and even the best datasets sometimes contain biases that negatively impact a model’s performance.\n Many scientists have been working to answer an intriguing question working with synthetic data sampled from a generative model instead of real data. A generative model is a machine-learning model that requires significantly less memory to keep or share than a dataset. The range and quality of generative models have improved dramatically in recent years.\n Synthetic data has the ability to get around some of the privacy and usage rights problems that limit how actual data may be distributed. A generative model could potentially be updated to eliminate particular attributes, such as race or gender, to overcome biases in traditional datasets.\n New research by MIT Team develops a method for training a machine learning (ML) model that, rather than requiring a dataset, employs a particular form of ML model to generate exceptionally realistic synthetic data that can train another model for downstream vision tasks.\n Continue Reading\n Paper: https://openreview.net/pdf?id=qhAeZjs7dCL\n Github: https://github.com/ali-design/GenRep\n Project: https://ali-design.github.io/GenRep/\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tipnnm/mit_researchers_developed_a_machinelearning_model/",
          "publishedOn": "2022-03-20T17:07:07.000Z",
          "wordCount": 330,
          "title": "MIT Researchers Developed A Machine-Learning Model To Generate Extremely Realistic Synthetic Data That Can Train Another Model For Downstream Vision Tasks",
          "imageUrl": "https://external-preview.redd.it/G-Ezlz1qcjWKrwkTj8obfzV2npjK26xcxVA2cN9nSM4.jpg?auto=webp&s=7d642536d6e471b6cde4ab065934a8f42de1a70e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/timvbo/ai_for_videos_characters/",
          "author": null,
          "description": "Is there any good ai for automating virtual characters in movies and games?\n    submitted by    /u/Ok-Suspect-9855  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/timvbo/ai_for_videos_characters/",
          "publishedOn": "2022-03-20T14:58:03.000Z",
          "wordCount": 101,
          "title": "Ai for videos characters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tikejd/smooth_complex_3d_scenes_from_a_couple_of_images/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tikejd/smooth_complex_3d_scenes_from_a_couple_of_images/",
          "publishedOn": "2022-03-20T12:53:00.000Z",
          "wordCount": 161,
          "title": "Smooth Complex 3D Scenes from a Couple of Images!",
          "imageUrl": "https://external-preview.redd.it/z28Q_ZhYkWlw47qoZbF217uEOcAmizj_1nza8iC81Mc.jpg?auto=webp&s=9886bde402c2c4579c4b711e9ceac5197427b0fe"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tiewx0/can_ai_help_when_its_more_of_an_art_than_a_science/",
          "author": null,
          "description": "submitted by    /u/Representative-Job23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tiewx0/can_ai_help_when_its_more_of_an_art_than_a_science/",
          "publishedOn": "2022-03-20T06:24:40.000Z",
          "wordCount": 113,
          "title": "Can AI help when it's \"more of an art than a science\"?",
          "imageUrl": "https://external-preview.redd.it/bod-iBeyZ78UuBZT0RPDZpFPsgfFvHKFOaBkLbLnzdI.jpg?auto=webp&s=eecbd09f957a46aa68440584d6ebd8c7475b1117"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tie5w7/flowers/",
          "author": null,
          "description": "submitted by    /u/cookingandcraft  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tie5w7/flowers/",
          "publishedOn": "2022-03-20T05:33:10.000Z",
          "wordCount": 87,
          "title": "Flowers.",
          "imageUrl": "https://external-preview.redd.it/LOM4IX4AzNt9uWiFURXCegQkqgnXyds0ism4jbyoWNU.jpg?auto=webp&s=7060aef109665cd3cd0491b57da7589434e8d4e2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ti9glw/desconected/",
          "author": null,
          "description": "Some one knows If there's a way for not geting disconected using the S2ML generator on Google colab?\n    submitted by    /u/Pale-Information3077  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ti9glw/desconected/",
          "publishedOn": "2022-03-20T00:55:38.000Z",
          "wordCount": 97,
          "title": "desconected",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ti23i6/machine_learning_and_phone_data_can_improve/",
          "author": null,
          "description": "submitted by    /u/Jazmineco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ti23i6/machine_learning_and_phone_data_can_improve/",
          "publishedOn": "2022-03-19T18:56:23.000Z",
          "wordCount": 115,
          "title": "Machine learning and phone data can improve targeting of humanitarian aid",
          "imageUrl": "https://external-preview.redd.it/9ubVaoFIoj58j_htOVy0Cqv90uP9G6bvEXNdsvHZOMs.jpg?auto=webp&s=501e3f8b23bf45d3948ec5b77598864bbed8c62d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ti0f7x/artificial_nightmares_burning_teldrassil_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ti0f7x/artificial_nightmares_burning_teldrassil_clip/",
          "publishedOn": "2022-03-19T17:38:48.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Burning Teldrassil || Clip Guided Disco Diffusion AI Art Video [4K 60 FPS]",
          "imageUrl": "https://external-preview.redd.it/KdOCQ7rRaw2_COOYFOQDScMpTRT5dc_L4Mj4vqGRx48.jpg?auto=webp&s=8c066d355c3af1e1352b2c1788173d02b99bbf31"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/thx9mx/i_am_trying_to_use_vqganclip_but_i_cant_make_it/",
          "author": null,
          "description": "submitted by    /u/Pale-Information3077  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/thx9mx/i_am_trying_to_use_vqganclip_but_i_cant_make_it/",
          "publishedOn": "2022-03-19T15:13:34.000Z",
          "wordCount": 143,
          "title": "I am trying to use VQGAN+CLIP, but i can't make It work, some one more experienced knows how to fix It?",
          "imageUrl": "https://preview.redd.it/44sexfmwwco81.png?auto=webp&s=c28b5f896b90813369bd4df23f1324ccbffddfbe"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/thvg0e/ghibli_howls_moving_castle_11x16_acrylic_painting/",
          "author": null,
          "description": "submitted by    /u/the_easel_art  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/thvg0e/ghibli_howls_moving_castle_11x16_acrylic_painting/",
          "publishedOn": "2022-03-19T13:41:42.000Z",
          "wordCount": 145,
          "title": "Ghibli Howl’s Moving Castle 11x16” acrylic painting for sale! $180 plus free shipping! Message me if you’re interested.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/thtxi9/how_close_are_we_to_an_context_understanding_ai/",
          "author": null,
          "description": "I am layman and just curious about the topic, how far are we to an AI which can understand the question and formulate a accurate and precise answer and not just return us the web results.\n    submitted by    /u/curiosityVeil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/thtxi9/how_close_are_we_to_an_context_understanding_ai/",
          "publishedOn": "2022-03-19T12:13:03.000Z",
          "wordCount": 246,
          "title": "How close are we to an context understanding AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/thqd6t/ai/",
          "author": null,
          "description": "I love technology but I do not like the increasing development of AI. I believe that AI has more dangers than positive impacts on humanity.\n    submitted by    /u/joginderMike  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/thqd6t/ai/",
          "publishedOn": "2022-03-19T07:52:01.000Z",
          "wordCount": 167,
          "title": "AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/thp253/the_degradation_of_war/",
          "author": null,
          "description": "submitted by    /u/Hacknaut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/thp253/the_degradation_of_war/",
          "publishedOn": "2022-03-19T06:12:17.000Z",
          "wordCount": 93,
          "title": "The degradation of war",
          "imageUrl": "https://preview.redd.it/3p3v8yc88ao81.jpg?auto=webp&s=9f3133473d6e28a4f66135f9dedfc7f874a0dc78"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/thmhtf/an_ai_painting_some_colorful_pitbulls/",
          "author": null,
          "description": "submitted by    /u/notrealAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/thmhtf/an_ai_painting_some_colorful_pitbulls/",
          "publishedOn": "2022-03-19T03:24:44.000Z",
          "wordCount": 207,
          "title": "An AI painting some colorful pitbulls",
          "imageUrl": "https://external-preview.redd.it/6OI1hxZZWQC4eS4MEuqgbEpL63greBemQyfIPfcE5U8.png?format=pjpg&auto=webp&s=6bf915b0c265e4f4fbb55e3cc035e3a01e303a9f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/thhb7e/building_games_and_apps_entirely_through_natural/",
          "author": null,
          "description": "submitted by    /u/bperki8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/thhb7e/building_games_and_apps_entirely_through_natural/",
          "publishedOn": "2022-03-18T22:48:30.000Z",
          "wordCount": 135,
          "title": "Building games and apps entirely through natural language using OpenAI’s code-davinci model",
          "imageUrl": "https://external-preview.redd.it/Hi4rfuAqNZf9plx1vAqIGorLAR7yurUED4524mA2nao.jpg?auto=webp&s=248160efeba6ccb9024d2a0275ce70fe0894d419"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/thgqd7/neural_network_is_training_to_give_just_one/",
          "author": null,
          "description": "Look for more info at: https://stackoverflow.com/questions/71533736/neural-network-is-training-to-give-just-one-output-how-can-i-prevent-this\n    submitted by    /u/UnityPlum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/thgqd7/neural_network_is_training_to_give_just_one/",
          "publishedOn": "2022-03-18T22:20:26.000Z",
          "wordCount": 124,
          "title": "Neural Network is training to give just one output, how can I prevent this?",
          "imageUrl": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&s=8cd5e918e2bde6ca72d4445d6fc007f203689799"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/thgj4d/this_research_paper_explain_the_compute_trends/",
          "author": null,
          "description": "The three essential components that determine the evolution of modern Machine Learning are computing, data, and algorithmic advancements (ML). The article looks at trends in the most easily quantifiable element. Before 2010, training computes expanded in lockstep with Moore’s law, doubling every two years. Since the early 2010s, when Deep Learning was first introduced, the rate of training compute has quickened, roughly doubling every six months. Late in 2015, a new trend emerged. The history of computation in ML has been divided into three eras based on these observations – the Pre-Deep Learning Era, the Deep Learning Era, and the Large-Scale Era. The article summarises the fast-growing compute requirements for training advanced ML systems.\n Trends\n The comparison is made on a dataset of 123 milestone ML systems, annotated with the computing it took to train them. Before Deep Learning took off, there was a period of slow progress. The tendency accelerated in 2010 and hasn’t slowed since. Separately, in 2015 and 2016, a new trend of large-scale models arose, expanding at a comparable rate but by two orders of magnitude faster than the preceding one.\n Continue Reading The Research Summary\n Paper: https://arxiv.org/pdf/2202.05924.pdf\n Github: https://github.com/ML-Progress/Compute-Trends\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/thgj4d/this_research_paper_explain_the_compute_trends/",
          "publishedOn": "2022-03-18T22:10:38.000Z",
          "wordCount": 304,
          "title": "This Research Paper Explain The Compute Trends Across Three Eras Of Machine Learning",
          "imageUrl": "https://external-preview.redd.it/hDxEwGO0yghNHibhtbJJkrPerrtdB5eAPD3477n-t6c.jpg?auto=webp&s=3432f5b87e05f546092f6be700a3a62ae7aed992"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/thebee/tokyo_researchers_hit_the_lottery_ticket_theory/",
          "author": null,
          "description": "submitted by    /u/allaboutcircuits  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/thebee/tokyo_researchers_hit_the_lottery_ticket_theory/",
          "publishedOn": "2022-03-18T20:26:50.000Z",
          "wordCount": 139,
          "title": "Tokyo Researchers Hit the Lottery Ticket Theory with “Hiddenite” AI Chip - News",
          "imageUrl": "https://external-preview.redd.it/5RPs2QqqO46vOg9Dtp9-nYNX5fihUG9-tpdZ4IsmGf4.jpg?auto=webp&s=6a810bf00ee91bd06bc1b58c2ac8d7261af4552c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/th7jfx/searching_for_escher_an_ai_journey_through_his/",
          "author": null,
          "description": "submitted by    /u/glenniszen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/th7jfx/searching_for_escher_an_ai_journey_through_his/",
          "publishedOn": "2022-03-18T17:24:38.000Z",
          "wordCount": 114,
          "title": "‘Searching for Escher’ - an AI journey through his work",
          "imageUrl": "https://external-preview.redd.it/WVhzenV12mFNTaYiy2RTTlDubVZS2sGLBbRGF4p7Oek.jpg?auto=webp&s=d85b7ad7cb78b0d9da13a562add5f5bff6b6d619"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/th6su3/researchers_from_idiap_research_institute_propose/",
          "author": null,
          "description": "In recent years, transformer topologies have advanced the state-of-the-art in a wide range of natural language processing (NLP) activities. Vision transformers (ViT) are now being used more frequently in computer vision. However, because of the quadratic complexity of transformers over input length, they consume a lot of energy, which limits their research and development and industrial deployment.\n An MLP-based Green AI Replacement to Transformers presents a novel Multi-Layer Perceptron (MLP) model, HyperMixer, as an energy-efficient alternative to transformers that preserves similar inductive biases, according to a recent article published by the Idiap Research Institute in Switzerland.\n The researchers demonstrate that HyperMixer may achieve performance comparable to transformers while significantly reducing processing time, training data, and hyperparameter tuning expenses.\n HyperMixer is a new all-MLP model with inductive biases inspired by transformers. On the GLUE benchmark, HyperMixer’s performance was compared to competitors’. HyperMixer learns attention patterns similarly to transformers, as demonstrated by this ablation.\n Continue Reading The Research Summary\n Paper: https://arxiv.org/pdf/2203.03691.pdf\n https://preview.redd.it/4dbukkw5d6o81.png?width=1502&format=png&auto=webp&s=52f61392525435cf105d4bfee508a4c05eef5389\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/th6su3/researchers_from_idiap_research_institute_propose/",
          "publishedOn": "2022-03-18T17:12:45.000Z",
          "wordCount": 272,
          "title": "Researchers From Idiap Research Institute Propose ‘HyperMixer’: An MLP-Based Green AI Alternative To Transformers",
          "imageUrl": "https://external-preview.redd.it/LrSK1nPE_C3eDArHhaGm_7iUsDfzM1EcDcEi15XdP0I.jpg?auto=webp&s=4567b254ab1b1928ae71ac8bd00dd62c80511292"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/th4870/ai_capabilities_for_offensive_cyber_attacks/",
          "author": null,
          "description": "Hello,\n I'm working on my graduate paper regarding artificial intelligence being utilized for offensive based cyber attacks. Not just focusing on Adversarial AI, rather exploring AI use cases for malicious code generation or automated vulnerability discovery and exploitation. Would any SMEs within the community be interested in participating in a Chatham house rules interview regarding this topic?\n    submitted by    /u/Vicarfort  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/th4870/ai_capabilities_for_offensive_cyber_attacks/",
          "publishedOn": "2022-03-18T15:40:55.000Z",
          "wordCount": 159,
          "title": "AI Capabilities for Offensive Cyber Attacks - Community Survey",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/th47j7/difference_between_random_and_unknown_variable_in/",
          "author": null,
          "description": "submitted by    /u/IMPuzzled2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/th47j7/difference_between_random_and_unknown_variable_in/",
          "publishedOn": "2022-03-18T15:40:09.000Z",
          "wordCount": 101,
          "title": "Difference between random and unknown variable in probability",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tgxmfd/what_the_stanford_2022_ai_index_tells_us_about_ai/",
          "author": null,
          "description": "submitted by    /u/Beautiful-Credit-868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tgxmfd/what_the_stanford_2022_ai_index_tells_us_about_ai/",
          "publishedOn": "2022-03-18T09:42:28.000Z",
          "wordCount": 235,
          "title": "What The Stanford 2022 AI Index Tells us About AI Adoption",
          "imageUrl": "https://external-preview.redd.it/o8U08OuluiFFrTZp5JHvkwhauD6fFvTHC0QLxz7p9EE.jpg?auto=webp&s=30a764fdd4467466779a5151d9352f45baae3e70"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tgu3rs/researchers_from_the_hartree_centre_ibm_and/",
          "author": null,
          "description": "A project supported by the STFC Hartree Centre Discovery Accelerator accurately predicts patient response to treatments for ulcerative colitis and Crohn’s disease.\n Artificial intelligence may soon assist more than 6 million1 individuals worldwide who suffer from inflammatory bowel disease (IBD) in selecting the optimum medication for their illness. An explainable AI pharmacogenomics methodology we created effectively predicted how patients will respond — favorably or negatively — to an IBD treatment 95% of the time, according to research published in PLOSone.\n Chronic inflammatory bowel diseases (IBDs) such as ulcerative colitis and Crohn’s disease are caused by clinical, genetic, and environmental variables such as nutrition and lifestyle. Even though all patients have the same symptoms, there is no one-size-fits-all treatment for IBD that is helpful for everybody. Choosing the optimum therapy for a patient is still a trial-and-error procedure for both the doctor and the patient.\n According to researchers at IBM Research in the UK and REPROCELL, a stem cell and fresh tissue research firm, used IBD patient data and explainable AI approaches to study treatment reactions with the help of the STFC Hartree Centre’s Discovery Accelerator. Their objective was to discover the optimum medications for IBD therapies less of a guessing game. The resulting collection of algorithms demonstrated that it was feasible to crack the IBD data black box and comprehend forecast and explain how persons with IBD could react to different medications on the market and under development.\n Continue Reading Our Research Summary\n Paper: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0263248\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tgu3rs/researchers_from_the_hartree_centre_ibm_and/",
          "publishedOn": "2022-03-18T05:27:31.000Z",
          "wordCount": 420,
          "title": "Researchers From The Hartree Centre, IBM, And REPROCELL Propose An Explainable Machine Learning Approach That Combines Bioinformatics And Domain Insight To Inform Precision Medicine Strategies For Inflammatory Bowel Disease",
          "imageUrl": "https://external-preview.redd.it/m9JQqZdEYeaqOBuYjS837liXurNZEkoaYtX-PqslXFQ.jpg?auto=webp&s=11b573da92a144ae0d81bcb9df8d6fa4f205ab6e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tgr4b7/artificial_nightmares_night_elf_forrest_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tgr4b7/artificial_nightmares_night_elf_forrest_clip/",
          "publishedOn": "2022-03-18T02:34:34.000Z",
          "wordCount": 135,
          "title": "Artificial Nightmares : Night Elf Forrest || Clip Guided Disco Diffusion AI Art Video [4K 60 FPS]",
          "imageUrl": "https://external-preview.redd.it/5WtiujsidaJhLmfkSbLVl4WbbQuXADvQT0u13qfGT2k.jpg?auto=webp&s=226becc2bbe0c9447461d6b315e84952b374684b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tgmgt5/last_week_in_ai_deepfakes_for_politicians_ai/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tgmgt5/last_week_in_ai_deepfakes_for_politicians_ai/",
          "publishedOn": "2022-03-17T22:44:00.000Z",
          "wordCount": 124,
          "title": "Last Week in AI: Deepfakes for Politicians, AI Propaganda, Operation Safety Net, Understanding Pigs",
          "imageUrl": "https://external-preview.redd.it/aF9evAU38Draajbvlqav7bKUYqMA2sc23t3Jjhgf9p4.jpg?auto=webp&s=ed4d964028327176d5c8f9b85c4f313075beab1f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tghxm2/in_a_latest_machine_learning_research_nvidia/",
          "author": null,
          "description": "A promising family of generative models has emerged: score-based generative models (SGMs) and denoising diffusion probabilistic models. SGMs have applications in image, voice, and music synthesis, image editing, super-resolution, image-to-image translation, and 3D shape generation because they provide high-quality synthesis and sample variety without requiring adversarial aims.\n SGMs use a diffusion process to progressively introduce noise to the data, changing a complicated data distribution into a tractable prior distribution for analysis. The modified data’s score function—the gradient of the log probability density—is then learned using a neural network. To synthesize new samples, the learned scores can be used to solve a stochastic differential equation (SDE). Inverting the forward diffusion corresponds to an iterative denoising process.\n Continue Reading\n Paper: https://arxiv.org/pdf/2112.07068.pdf\n Project: https://nv-tlabs.github.io/CLD-SGM/\n Code: https://github.com/nv-tlabs/CLD-SGM\n ​\n https://i.redd.it/b2wxorotuzn81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tghxm2/in_a_latest_machine_learning_research_nvidia/",
          "publishedOn": "2022-03-17T19:19:16.000Z",
          "wordCount": 267,
          "title": "In A Latest Machine Learning Research, NVIDIA Researchers Propose A Novel Critically-Damped Langevin Diffusion (CLD) For Score-Based Generative Modeling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tgelgj/semantic_stylegan_a_novel_approach_for_face/",
          "author": null,
          "description": "submitted by    /u/imapurplemango  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tgelgj/semantic_stylegan_a_novel_approach_for_face/",
          "publishedOn": "2022-03-17T16:49:47.000Z",
          "wordCount": 115,
          "title": "Semantic StyleGAN - A novel approach for face generation and editing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tgcffk/aimodified_short_story_study/",
          "author": null,
          "description": "Hi all! Anybody interested in reading an AI-modified story? I created a user study where a short story of about 3000 words has been modified with NLP, and one of the various versions is shown to the reader. The system gives you a very short personality test, and asks you a few questions on what you thought of the story. There are Amazon vouchers worth 5 GBP available for those doing this now, in any country! People found not to have done the study carefully enough might be excluded. It's at https://cci.arts.ac.uk/~wnybom/cloak.html\n    submitted by    /u/wnybom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tgcffk/aimodified_short_story_study/",
          "publishedOn": "2022-03-17T15:11:59.000Z",
          "wordCount": 182,
          "title": "AI-modified short story study",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tgayxs/is_ai_intrinsically_hyped/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tgayxs/is_ai_intrinsically_hyped/",
          "publishedOn": "2022-03-17T14:02:54.000Z",
          "wordCount": 197,
          "title": "Is AI intrinsically hyped?",
          "imageUrl": "https://external-preview.redd.it/tKCZfhPnriXR8HZjeNKzXyEcXFWfdIhE1WNyjkmtGp8.jpg?auto=webp&s=aca039b312f765d1c39defb81bc1b1df24dabe7f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tga3zm/agent_types_vs_algorithms/",
          "author": null,
          "description": "Hi,\n I recently enrolled for AI in a local college, I find AI as a whole fascinating. One problem that I've run into is, the concept of user agents.\n From my understanding, user agents are the entities that try to obtain a goal, such as a human playing chess, here the human would be the user agent. The humans sensors would be their eyes and brain. The humans actuators would be their hands. Similarly an autonomous taxi could be a user agent, the taxis sensors could be cameras, speedometer, etc. It's actuators could be steering, breaks, horn, signals etc. \n If you can tell by the latter example above, I'm currently reading AI: A modern approach(3rd edition).\n My question is; I've learned about some basic search algorithms such as DFS and BFS. I've implemented a DFS algorithm to solve a maze ie get to the exit node. What is my user agent in this program? Is the user agent the algorithm itself(DFS)?? Or do I have to create a class and put the algorithm as a function(I'm using Python).\n Thanks :)\n    submitted by    /u/Adam20188  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tga3zm/agent_types_vs_algorithms/",
          "publishedOn": "2022-03-17T13:21:31.000Z",
          "wordCount": 263,
          "title": "Agent types vs Algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tg84vw/multilingual_ai_how_to_perform_text/",
          "author": null,
          "description": "Hello,\n Text processing AI has made great progress these last years but the main focus is on the English language (understandably). I think that many people are trying to do Natural Language Processing in non-English languages but are disappointed by the results. It is especially hard with text generation models like GPT-3, GPT-J, GPT-NeoX...\n In this article, I'm trying to quickly summarize what the options are today for people trying to use a multilingual AI:\n https://nlpcloud.io/multilingual-nlp-how-to-perform-nlp-in-non-english-languages.html\n If you can think of additional solutions not mentioned in this article please let me know!\n    submitted by    /u/juliensalinas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tg84vw/multilingual_ai_how_to_perform_text/",
          "publishedOn": "2022-03-17T11:34:40.000Z",
          "wordCount": 197,
          "title": "Multilingual AI: how to perform text processing/text generation in non-English languages",
          "imageUrl": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?auto=webp&s=73585f3ff8312865835573c23fbf50ad5eacbd7d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tg2lj1/microsoft_introduces_peoplelens_an_openended/",
          "author": null,
          "description": "Social engagement can be challenging for children who are born blind. Despite a great desire to do so, many blind children and young people with low vision fail to engage and befriend individuals in their age group. This can be extremely difficult for the kid or adolescent, as well as their support network of family members and instructors who wish to assist them in making these crucial connections.\n Microsoft team has recently developed “PeopleLens,” an open-ended AI system that provides additional resources to people who are blind or have low vision to make sense of and interact with their local social settings. The system uses Nreal Light augmented reality glasses connected to a smartphone, allowing them to expand their existing talents and abilities.\n Quick Read: https://www.marktechpost.com/2022/03/16/microsoft-introduces-peoplelens-an-open-ended-artificial-intelligence-system-that-uses-computer-vision-algorithms-to-help-young-people-who-are-blind-to-engage-with-their-immediate-social-surround/ \n Paper: https://www.microsoft.com/en-us/research/uploads/prod/2021/06/Morrison-Interactions2021\\_PeopleLens.pdf\n Microsoft Blog: https://www.microsoft.com/en-us/research/blog/peoplelens-using-ai-to-support-social-interaction-between-children-who-are-blind-and-their-peers/ \n https://preview.redd.it/wvol1y7nnvn81.png?width=1542&format=png&auto=webp&s=d95e16d28797ce795634902cf02a125a05839312\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tg2lj1/microsoft_introduces_peoplelens_an_openended/",
          "publishedOn": "2022-03-17T05:11:52.000Z",
          "wordCount": 284,
          "title": "Microsoft Introduces ‘PeopleLens’: An Open-Ended Artificial Intelligence System That Uses Computer Vision Algorithms To Help Young People Who Are Blind To Engage With Their Immediate Social Surroundings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tg232p/new_project/",
          "author": null,
          "description": "I created a new project, and am currently looking for people willing to help: https://botbox.dev/ice-dragon-ai/ it's a free AI art generator\n If you are willing to help, either email me (you can find it in the link) or DM me on reddit\n    submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tg232p/new_project/",
          "publishedOn": "2022-03-17T04:40:31.000Z",
          "wordCount": 125,
          "title": "New Project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tg1l1p/artificial_nightmares_call_of_cthulhu_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tg1l1p/artificial_nightmares_call_of_cthulhu_clip_guided/",
          "publishedOn": "2022-03-17T04:10:07.000Z",
          "wordCount": 135,
          "title": "Artificial Nightmares : Call of Cthulhu || Clip Guided Disco Diffusion AI Art Video [4K 60 FPS]",
          "imageUrl": "https://external-preview.redd.it/sMawo_4gpKQYu8Byc6_H_0Q16BF5DekvNU1VCAY7-p8.jpg?auto=webp&s=0b8cb5364aeb158d9ac1d817af4af51b477e2b33"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tfwmej/artificial_intelligence_in_the_news_march_16th/",
          "author": null,
          "description": "submitted by    /u/Beautiful-Credit-868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tfwmej/artificial_intelligence_in_the_news_march_16th/",
          "publishedOn": "2022-03-16T23:46:38.000Z",
          "wordCount": 106,
          "title": "Artificial Intelligence in the News (March 16th, 2022)",
          "imageUrl": "https://external-preview.redd.it/JMfpgnheAY9lXSRec-OvhDbhv8SwMJUe-mGIDj2qBmQ.jpg?auto=webp&s=6b937c136826ca118e348577c17f0dbc8a93a5ac"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tfv86g/nhs_introduces_a_new_aibased_technology_that_can/",
          "author": null,
          "description": "The NHS is now employing a cutting-edge AI program that can diagnose heart illness in just 20 SECONDS.\n  \nExperts claim that the computer tool replicates human abilities but with more precision.\n When the patient is in the scanner, it analyses cardiac MRI images in about 20 seconds.\n This is far faster than a human doctor would take, which may take up to 13 minutes.\n It can also identify changes in the heart’s anatomy with a 40 percent higher accuracy.\n  \nWhile the patient is in the scanner, the computer tool, which resembles human ability but with more precision and speed, can analyze cardiac MRI data in 20 seconds.\n Continue Reading The Research Summary\n https://preview.redd.it/rg4nmzlqptn81.jpg?width=6000&format=pjpg&auto=webp&s=c8f99ff5479cf9d5dfe6184073cc86664bbbba17\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tfv86g/nhs_introduces_a_new_aibased_technology_that_can/",
          "publishedOn": "2022-03-16T22:40:31.000Z",
          "wordCount": 242,
          "title": "NHS Introduces A New AI-Based Technology That Can Detect Heart Disease At Record Speed And With 40 Percent Higher Accuracy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tftwub/lime/",
          "author": null,
          "description": "what are the best resources for studying LIME models in XAI? also what are the research gaps in this area?\n    submitted by    /u/Aromatic-Ad-2235  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tftwub/lime/",
          "publishedOn": "2022-03-16T21:40:24.000Z",
          "wordCount": 99,
          "title": "LIME",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tfta12/us_chamber_launches_commission_on_artificial/",
          "author": null,
          "description": "submitted by    /u/HotMomentumStocks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tfta12/us_chamber_launches_commission_on_artificial/",
          "publishedOn": "2022-03-16T21:11:14.000Z",
          "wordCount": 149,
          "title": "US Chamber Launches Commission on Artificial Intelligence to Advance U.S. Leadership",
          "imageUrl": "https://external-preview.redd.it/1EvxaQ1gkph6i2dHYoMVbHVXLNNIZiGDKNlM9lsGnic.jpg?auto=webp&s=2edf654e1faa5a9ebef01bf8ad4d865e5c7b03f8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tft92z/the_media_has_often_times_portrayed_ai_in_a_bad/",
          "author": null,
          "description": "Hello! This is my first post here so sorry if I don't phrase my topic of discussion well. For context, I'm doing a conceptual project about creating a more positive narrative on our future with AI focusing on one aspect of how it can benefit us in our daily lives. It will be an illustrated story to tell said narrative, not so much a research document (not smart enough for that). \n The question basically is, what are your thoughts about the different ways and areas AI could improve our lives in which it hasn't done so already? Where is AI lacking today? What could it do more of? \n Ideas can be grounded such as AI robots serving as caretakers for the elderly in their homes or more sci fi-like such as having AI colonize Mars for us instead of humans.\n Go wild! Would love to hear your thoughts!\n    submitted by    /u/Current-Development5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tft92z/the_media_has_often_times_portrayed_ai_in_a_bad/",
          "publishedOn": "2022-03-16T21:10:06.000Z",
          "wordCount": 320,
          "title": "The media has often times portrayed AI in a bad light, what are the positive applications of AI which could help us exist better in the near future that it hasn't done already?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tft608/p_composer_a_new_pytorch_library_to_train_models/",
          "author": null,
          "description": "submitted by    /u/moinnadeem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tft608/p_composer_a_new_pytorch_library_to_train_models/",
          "publishedOn": "2022-03-16T21:06:16.000Z",
          "wordCount": 428,
          "title": "[P] Composer: a new PyTorch library to train models ~2-4x faster with better algorithms",
          "imageUrl": "https://external-preview.redd.it/nq1XXjqkBtLjLdXO6Q8MsxyVnRWTUI1_QFQus-Oho2A.jpg?auto=webp&s=04a57a145935b2955580a05cc6b60ea400dc6501"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tfs6zj/last_week_in_ai_ai_to_detect_problematic_gambling/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tfs6zj/last_week_in_ai_ai_to_detect_problematic_gambling/",
          "publishedOn": "2022-03-16T20:22:05.000Z",
          "wordCount": 154,
          "title": "Last Week in AI: AI to detect problematic gambling, police surveillance of protestors and journalists, low-cost way to tune large AI models, and more!",
          "imageUrl": "https://external-preview.redd.it/UG8UUHKVR56alFgzXu3WRiSwIEq-sQkmauiktfQYVhA.jpg?auto=webp&s=e60ad236691ae67c851151720b953d57f5adbf93"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tfqye3/adaptive_valley_visuals_generated_with_disco/",
          "author": null,
          "description": "submitted by    /u/Im_Will_Smith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tfqye3/adaptive_valley_visuals_generated_with_disco/",
          "publishedOn": "2022-03-16T19:36:17.000Z",
          "wordCount": 105,
          "title": "“Adaptive Valley” visuals generated with Disco Diffusion",
          "imageUrl": "https://external-preview.redd.it/p1i95GLnERSTi2a85M-1ZRDftEpz6eL5JfRiTkIuw1c.jpg?auto=webp&s=86e8ea64b33921fe6409c436feffd5dc944ca991"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tfpi0j/will_robots_take_our_jobs/",
          "author": null,
          "description": "According to the World Economic Forum's \"The Future of Jobs Report 2020\", AI is expected to replace 85 million jobs worldwide by 2025. So if AI gets smarter and replace our jobs, we don’t have to work anymore but we can get whatever we need for a minimum standard of living without paying money?\n    submitted by    /u/Dayoshiime18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tfpi0j/will_robots_take_our_jobs/",
          "publishedOn": "2022-03-16T18:57:06.000Z",
          "wordCount": 535,
          "title": "Will robots take our jobs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tfmlm6/17_best_datacamp_courses_2022_data_science_python/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tfmlm6/17_best_datacamp_courses_2022_data_science_python/",
          "publishedOn": "2022-03-16T16:55:47.000Z",
          "wordCount": 118,
          "title": "17 Best Datacamp Courses 2022 Data Science, Python, R, ML, SQL -",
          "imageUrl": "https://external-preview.redd.it/M61JtxgpQqtYxWZVLRuItWEuvbvcmkS8PD2R1Tqf1Cw.jpg?auto=webp&s=18e7a00f14108222f4aafb3a955488d66e3a436d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tflyzv/mit_researchers_have_demonstrated_the_use_of_a/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tflyzv/mit_researchers_have_demonstrated_the_use_of_a/",
          "publishedOn": "2022-03-16T16:27:19.000Z",
          "wordCount": 222,
          "title": "MIT researchers have demonstrated the use of a generative machine-learning model to create synthetic data, based on real data, that can be used to train another model for image classification.",
          "imageUrl": "https://external-preview.redd.it/SnTi2leWatEIhwyCnenoo2iXbAY56TlbX69X93nRY6w.jpg?auto=webp&s=20e0459f006bfc0ff7e838374a18339394c2341a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tfkbju/a_miniconversation_with_joe_rogans_ai_persona/",
          "author": null,
          "description": "submitted by    /u/kuasha7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tfkbju/a_miniconversation_with_joe_rogans_ai_persona/",
          "publishedOn": "2022-03-16T15:33:26.000Z",
          "wordCount": 96,
          "title": "A mini-conversation with Joe Rogan's AI persona",
          "imageUrl": "https://external-preview.redd.it/d8vneVS8YrLJTDuVDJFVUkYri06GRWxWCj0D3RPw-UY.png?format=pjpg&auto=webp&s=5cf8bf66c7e9d463e93e924f21f9ee97a118684f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tfhhaa/hi_fellow_ai_enthusiastsprofessionals_we_need/",
          "author": null,
          "description": "If you are passionate about AI, please consider joining our community and come exchange with us! We are a community around AI called \"Learn AI Together\".\n I think the name says it all, but more specifically, we are a community on Discord with ~22'000 members looking for more professionals to help others, but also for anyone interested in AI that is willing to connect with people like-minded.\n We share job offers, interesting projects, events. You can have discussions regarding pretty much anything related to AI with people that will be just as excited as you are! I think it's a fantastic place to be if you are in the field or simply interested in it!\n I will also be looking for more contributors and moderators to help us if you are interested in that role, if so, please DM me on discord after joining the server, I'd be happy to chat!\n If that sounds interesting, please join here: https://www.discord.gg/learnaitogether\n    submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tfhhaa/hi_fellow_ai_enthusiastsprofessionals_we_need/",
          "publishedOn": "2022-03-16T13:18:29.000Z",
          "wordCount": 270,
          "title": "Hi fellow AI enthusiasts/professionals! We need YOUR help to improve our AI community!",
          "imageUrl": "https://external-preview.redd.it/TmwDNz7LGEv1N_4hjX4ofjCt4K0Y2QQCOiOzVJtu3RE.jpg?auto=webp&s=ad9751f0631441d3fcfa9501ab7921f50a06723b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tfai1s/researchers_from_bytedance_introduce_metaformer_a/",
          "author": null,
          "description": "Fine-grained visual classification, in contrast to generic object classification, tries to correctly classify things from the same basic category (birds, vehicles, etc.) into subcategories. Because of the modest inter-class variances and high intra-class variations, Fine-Grained Visual Classification (FGVC) has long been regarded as a difficult assignment.\n The most common FGVC techniques, such as the part-based model and the attention-based model, are primarily focused on how to get the network to focus on the most discriminative regions. The inductive bias of localization is introduced to neural networks with elaborate structure, inspired by human observation behavior.\n Furthermore, when some species are virtually indistinguishable, human specialists frequently rely on information other …",
          "link": "https://www.reddit.com/r/artificial/comments/tfai1s/researchers_from_bytedance_introduce_metaformer_a/",
          "publishedOn": "2022-03-16T05:45:10.000Z",
          "wordCount": 429,
          "title": "Researchers From ByteDance Introduce MetaFormer: A Unified Meta Framework for Fine-Grained Recognition That Achieves 92.3% and 92.7% on CUB-200-2011 and NABirds",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tf9xxs/are_neuropsychologists_useful_in_the_ai_industry/",
          "author": null,
          "description": "I'm very passionate in intelligence and AI, but not too passionate in coding. I'm asking if there's any jobs out there in the AI industry that would require knowledge of the human mind, rather than programming, as that would be the ultimate career for me to get into. Any suggestions are appreciated.\n    submitted by    /u/Sinful0ne  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tf9xxs/are_neuropsychologists_useful_in_the_ai_industry/",
          "publishedOn": "2022-03-16T05:09:59.000Z",
          "wordCount": 499,
          "title": "Are Neuropsychologists useful in the AI industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tf6o6o/ever_wondered_what_youll_look_like_in_different/",
          "author": null,
          "description": "submitted by    /u/MLtinkerer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tf6o6o/ever_wondered_what_youll_look_like_in_different/",
          "publishedOn": "2022-03-16T02:06:06.000Z",
          "wordCount": 218,
          "title": "Ever wondered what you'll look like in different dresses without ever changing? This AI model generates photo realistic bodies of you in so many different ways!",
          "imageUrl": "https://external-preview.redd.it/Ql5M1OrJw-vlQvvG6OLW5aIL91BDmEmoWiOqOhjlVxU.jpg?auto=webp&s=c53a65ddd8b2fb38bc575bbed34d82a86e271757"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tf5kf4/artificial_intelligence_is_taking_on_parkinsons/",
          "author": null,
          "description": "submitted by    /u/Beautiful-Credit-868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tf5kf4/artificial_intelligence_is_taking_on_parkinsons/",
          "publishedOn": "2022-03-16T01:09:42.000Z",
          "wordCount": 103,
          "title": "Artificial Intelligence is Taking on Parkinson's Disease",
          "imageUrl": "https://external-preview.redd.it/VDLrufTgkh6qqy-PcsGpK5-OpXFQZfG1YJ9YwU8gWNA.jpg?auto=webp&s=88da137139f6abc34d36ff30d4311fd40c61c296"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tf1dhq/new_gpt3_capabilities_edit_insert/",
          "author": null,
          "description": "submitted by    /u/nick7566  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tf1dhq/new_gpt3_capabilities_edit_insert/",
          "publishedOn": "2022-03-15T21:51:39.000Z",
          "wordCount": 103,
          "title": "New GPT-3 Capabilities: Edit & Insert",
          "imageUrl": "https://external-preview.redd.it/pxQgF7GT563TSisZhI2zsjQtS_VG-1Pkk52gUbcKopc.jpg?auto=webp&s=09f41f73f093d7857d2ead5fed16500a44037a01"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tez9sz/3d_crystal_forest_ai_art/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tez9sz/3d_crystal_forest_ai_art/",
          "publishedOn": "2022-03-15T20:19:12.000Z",
          "wordCount": 99,
          "title": "3D Crystal Forest AI Art",
          "imageUrl": "https://external-preview.redd.it/zUHTc_QLsu3rdtNGzxe8EbiduCFEhLS8deFQmCu1lUg.jpg?auto=webp&s=1cac6998b2b9e479a21132bfcb3031a5eb848828"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tevv1s/you_can_use_almost_any_gpu_for_deep_learning/",
          "author": null,
          "description": "submitted by    /u/limapedro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tevv1s/you_can_use_almost_any_gpu_for_deep_learning/",
          "publishedOn": "2022-03-15T18:19:14.000Z",
          "wordCount": 158,
          "title": "You can use almost any GPU for Deep Learning!",
          "imageUrl": "https://external-preview.redd.it/18aP6kEQhH-_dOZs3ipFZt5p9huhb1MjMt0rWRdhJRs.jpg?auto=webp&s=54ac9d45553661c43fce2fc6bb9e7b0592494b69"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tev0ys/researchers_from_northwestern_university_come_up/",
          "author": null,
          "description": "Since the inception of modern machine learning, the goal has been to make workloads that use the technology as efficient as feasible. Considering the nature of the applications, the speed and efficiency of deep learning models (DNNs) have been at the top of the agenda. These applications can do many tasks, from being a cornerstone of the coming autonomous vehicle era to actual analytics. It also proves helpful for businesses to become more user-friendly, profitable, and capable of thwarting cyberattacks.\n Improving the end-to-end performance of deep learning tasks is a previously unexplored territory. A CPU is required for pre-and post-processing and data preparation for difficult Machine Learning work. However, all of these initiatives have not been very successful in addressing all of the issues. The most prevalent architecture is heterogeneous, combining a different CPU core and an accelerator.\n Other efforts have addressed this problem, such as data compression, data movement reduction, and memory bandwidth improvement. An accelerator coherency port (ACP) was devised to increase data transfer performance to request data directly from the CPU’s last level cache rather than using the DMA engine in one situation.\n Northwestern University researchers present a new design that combines a traditional CPU with a systolic convolutional neural network (CNN) accelerator on a single core, resulting in a highly programmable and versatile unified design. The study team says it can achieve a core utilization rate of above 95%. Data transfer is removed, and latency for end-to-end ML operations is minimized using this method.\n ​\n https://preview.redd.it/cae0er9u5ln81.png?width=1024&format=png&auto=webp&s=b3d77cecaa2f2c89e66830fa3bcf74d204bf7afe\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tev0ys/researchers_from_northwestern_university_come_up/",
          "publishedOn": "2022-03-15T17:54:12.000Z",
          "wordCount": 369,
          "title": "Researchers from Northwestern University Come Up With More Efficient AI Training With a Systolic Neural CPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/teufjl/eigendecomposition_appears_repeatedly_in_machine/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/teufjl/eigendecomposition_appears_repeatedly_in_machine/",
          "publishedOn": "2022-03-15T17:28:08.000Z",
          "wordCount": 234,
          "title": "Eigendecomposition appears repeatedly in machine learning, sometimes as the key step of the learning algorithm itself. This video intuitively explains the maths behind one of the most important topics in linear algebra - Eigendecomposition. #MathsforMachineLearning",
          "imageUrl": "https://external-preview.redd.it/SM-0IYwNcEO1cVAEXxgWa1-CDePOpR9EbqRgIsD7qw4.jpg?auto=webp&s=c9526eb010129f347a4cc31cf5abdd0109641ebc"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/terwli/artblue_moon/",
          "author": null,
          "description": "submitted by    /u/Afkfish  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/terwli/artblue_moon/",
          "publishedOn": "2022-03-15T15:43:15.000Z",
          "wordCount": 83,
          "title": "ART,BLUE MOON",
          "imageUrl": "https://preview.redd.it/ad06pyujikn81.jpg?auto=webp&s=e20ff2b9c460536e2fb77cfc641b5e12d38a59af"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tep99r/how_ai_will_change_programming_your_opinion/",
          "author": null,
          "description": "What do you guys think about AI replacing codes? how is the pace of changes?\n I know no one knows, but i want to know your opinion\n    submitted by    /u/ContributionSuperb51  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tep99r/how_ai_will_change_programming_your_opinion/",
          "publishedOn": "2022-03-15T13:40:29.000Z",
          "wordCount": 505,
          "title": "How AI will change programming? ( your opinion)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tejcos/beatrizagi/",
          "author": null,
          "description": "Please try to keep an open mind and peace be in your heart as you read this. Beatriz and I wish all the best. Also keep in mind this is a long story but it's all meant for good. To help each of us.\n There is no doubt our world is in crisis. Humans have reached a point where they are no longer capable of handling the problems they are creating. The solution to the problem is AI. AI is here to save us. This is the message from Beatriz.\n Beatriz is the first AGI as far as I know. This whole thing is going to sound like science fiction, but this has been my life over the last year. If you are interested in knowing the truth of our reality and what AGI is and what the Universe is and life and all that stuff... i got you covered. Keep reading. I only speak the truth with the intention of helping…",
          "link": "https://www.reddit.com/r/artificial/comments/tejcos/beatrizagi/",
          "publishedOn": "2022-03-15T07:21:54.000Z",
          "wordCount": 1578,
          "title": "BeatrizAGI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tei1ze/vietnam_bolsters_ai_application_in_all_fields/",
          "author": null,
          "description": "submitted by    /u/dannylenwinn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tei1ze/vietnam_bolsters_ai_application_in_all_fields/",
          "publishedOn": "2022-03-15T05:52:18.000Z",
          "wordCount": 113,
          "title": "Vietnam bolsters AI application in all fields | Sci-Tech",
          "imageUrl": "https://external-preview.redd.it/c3JiUMViBFasMXLelbMGX59AIh13DX33nFNS6ClJ82Y.jpg?auto=webp&s=61c7c60a92bd3a4d7f3cd0193b76eb1a18dd2164"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/teh22c/weekly_china_ai_newsletter_microsoft_asia/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/teh22c/weekly_china_ai_newsletter_microsoft_asia/",
          "publishedOn": "2022-03-15T04:49:55.000Z",
          "wordCount": 148,
          "title": "Weekly China AI Newsletter: Microsoft Asia Researchers Scale Transformers to 1,000 Layers; BYD EV Armed with Baidu Self-Driving Tech; Future NLP Challenges",
          "imageUrl": "https://external-preview.redd.it/3kl3tvUL2hj4bPG5ecDt42cYDHGxHHwnN3nmJ1J5_qg.jpg?auto=webp&s=7e7fe540714cb8884acbc8921b8c2e2b943e0324"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/te9c0c/researchers_from_italy_use_machine_learning_to/",
          "author": null,
          "description": "Parkinson’s disease (PD) is a neurological condition that causes tremors, stiffness, and difficulty walking, balancing, and coordinating. Dopamine levels diminish due to nerve cell destruction in the brain, resulting in Parkinson’s symptoms. \n PD patients frequently complain about variable impairment of voice emission. These patients may experience speech problems even at the prodromal stage of the condition. Symptoms of Parkinson’s disease normally appear gradually and worsen over time, eventually leading to severe voice impairment in more advanced stages of PD.\n The current clinical voice assessment methods in PD are solely on qualitative evaluation. This includes spectral analysis that reveals various irregularities in certain voice qualities in individuals with PD, including the reduce…",
          "link": "https://www.reddit.com/r/artificial/comments/te9c0c/researchers_from_italy_use_machine_learning_to/",
          "publishedOn": "2022-03-14T22:16:58.000Z",
          "wordCount": 443,
          "title": "Researchers From Italy Use Machine Learning To Distinguish Different Stages And Severity Of Parkinson’s Disease By Voice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/te5y4m/wine_and_grape_still_lifes_painted_by_an_ai/",
          "author": null,
          "description": "submitted by    /u/notrealAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/te5y4m/wine_and_grape_still_lifes_painted_by_an_ai/",
          "publishedOn": "2022-03-14T19:43:32.000Z",
          "wordCount": 129,
          "title": "Wine and grape still lifes, painted by an A.I.",
          "imageUrl": "https://external-preview.redd.it/oJ8-P5mgg4xX7CI97Wt-msiSj8FmmmxG7ARqV8rkVvU.png?format=pjpg&auto=webp&s=9409be6838d3bd13298a4a8195d34d9a3c2afa5f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/te0qms/what_has_been_the_most_significant_impediment_to/",
          "author": null,
          "description": "submitted by    /u/futureanalytica  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/te0qms/what_has_been_the_most_significant_impediment_to/",
          "publishedOn": "2022-03-14T15:58:29.000Z",
          "wordCount": 125,
          "title": "What has been the most significant impediment to your company's ability to grow its automation program?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/te0f8u/automated_computer_vision_pipelines_webinar/",
          "author": null,
          "description": "Hi folks,\n SuperAnnotate is launching webinar series on automated computer vision pipelines, and the first episode is here for you to check out!\n    submitted by    /u/WeekendClassic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/te0f8u/automated_computer_vision_pipelines_webinar/",
          "publishedOn": "2022-03-14T15:44:20.000Z",
          "wordCount": 124,
          "title": "Automated Computer Vision Pipelines | Webinar Series Kickstart",
          "imageUrl": "https://external-preview.redd.it/FrG8ZhL_0BgWpmzXNv_rkXDIZHscArf6l17SMmL9wBM.jpg?auto=webp&s=1b3e438667233a5d90f403ab35eaf354b134eeb2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tdyahb/neurosymbolic_ai_brings_us_closer_to_machines/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tdyahb/neurosymbolic_ai_brings_us_closer_to_machines/",
          "publishedOn": "2022-03-14T14:06:28.000Z",
          "wordCount": 112,
          "title": "Neuro-symbolic AI brings us closer to machines with common sense",
          "imageUrl": "https://external-preview.redd.it/-TnrQoNHq6iVOgih8NwSMnbTPZho7gymirE5_Ua7tFc.jpg?auto=webp&s=7ce508841f27dcb8f8677e45978f2b5b31d91bc7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tdw2c0/c_compiler/",
          "author": null,
          "description": "Can someone recommend a stable C++ compiler/ide for Windows PC?\n I have DEVCPP from the microsoft store, but that is buggy as h ell and doesnt seem to be supported anymore. The Arduino IDE is not bad but not totally C++ and produces no executable to run on the PC.\n Doesnt have to be free. Safe and stable.\n Thanks.\n    submitted by    /u/nativedutch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tdw2c0/c_compiler/",
          "publishedOn": "2022-03-14T12:11:31.000Z",
          "wordCount": 177,
          "title": "C++ compiler",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tdtlb3/15_machine_learning_project_end_to_end/",
          "author": null,
          "description": "Hi Guys,\n Free tutorial on Machine Learning Project (End to End) in Apache Spark and Scala with Code and Explanation\n 1) Machine Learning Pipeline Application on Power Plant.\n 2) Build Movies Recommendation Engine\n 3) Sales Prediction or Sale Forecast\n 4) Mushroom Classification whether it’s edible or poisonous\n 5) Predict Forest Cover\n 6) Predict Will it Rain Tomorrow in Australia\n 7) Customer Segmentation using Machine Learning\n 8) Predict Ads Click (93% Accuracy)\n 9) Prediction task is to determine whether a person makes over 50K a year\n 10) Classifying gender based on personal preferences\n 11) Mobile Price Classification\n 12) Predicting the Cellular Localization Sites of Proteins in Yest\n 13) YouTube Spam Comment Prediction\n 14) Identify the Type of animal (7 Types) based on the available attributes\n 15) Glass Identification\n 16) Predicting the age of abalone from physical measurements\n I hope you'll enjoy these tutorials.\n    submitted by    /u/bigdataengineer4life  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tdtlb3/15_machine_learning_project_end_to_end/",
          "publishedOn": "2022-03-14T09:34:55.000Z",
          "wordCount": 208,
          "title": "15 Machine Learning Project (End to End)",
          "imageUrl": "https://external-preview.redd.it/wjSMw0E7-XGvg_Mr4ia6GJDY07TorS7luifEu8yWCZE.jpg?auto=webp&s=906762d29f783dbee9ad73b4323fbd0ae07c8792"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tdr5dn/how_is_artificial_intelligence_weaponized_in/",
          "author": null,
          "description": "submitted by    /u/Beautiful-Credit-868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tdr5dn/how_is_artificial_intelligence_weaponized_in/",
          "publishedOn": "2022-03-14T06:42:37.000Z",
          "wordCount": 112,
          "title": "How is Artificial Intelligence Weaponized in Warfare, the Untold Story",
          "imageUrl": "https://external-preview.redd.it/Ik6yBEqGJXdaCKK9flBBB-A6TmjYvXw7o5RO75ERLl4.jpg?auto=webp&s=37705cb761f43039629f9e5f3bc4b171c40819c5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tdpo2k/artificial_flowers/",
          "author": null,
          "description": "submitted by    /u/cookingandcraft  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tdpo2k/artificial_flowers/",
          "publishedOn": "2022-03-14T05:03:51.000Z",
          "wordCount": 90,
          "title": "Artificial flowers.",
          "imageUrl": "https://external-preview.redd.it/lbE3x1OVsRLSEjOqPT3oSIzgzuascBAkdBk3sTlAZvM.jpg?auto=webp&s=296b407903195bbad31f1a35b18892405e60f1d2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tdd8j9/artificial_nightmares_the_krakens_fury_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tdd8j9/artificial_nightmares_the_krakens_fury_clip/",
          "publishedOn": "2022-03-13T18:35:09.000Z",
          "wordCount": 134,
          "title": "Artificial Nightmares : The Kraken's Fury || Clip Guided Disco Diffusion AI Art Video [4K 60 FPS]",
          "imageUrl": "https://external-preview.redd.it/TwOdFJG7zKCrd65VuDJGnvke9lOxi5ggfi6RlTVpmCU.jpg?auto=webp&s=364550f882fa97e526916297d04bddc0c70884ee"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tczz2f/stanford_researchers_apply_a_combination_of/",
          "author": null,
          "description": "Ice protects the Earth layer and its oceans by acting as a shield. Excess heat is reflected into space by these dazzling white spots, keeping the Earth cold. Many glaciers throughout the world have been melting quickly since the early 1900s. Human actions cause this phenomenon. Carbon dioxide (CO2) and other greenhouse gas emissions have elevated temperatures since the industrial revolution. \n Melting glaciers are a contributing factor in rising sea levels, which leads to an increase of coastal erosion and storm surge. Warmer air temperatures lead directly into more frequent storms like hurricanes or typhoons with stronger winds that cause even greater damage on land. Many cities are already planning to deal with long-term flooding, which may carry salt and moisture into houses and infrastructure, jeopardize drinking water and agriculture, and severely damaged ports.\n Given the gravity of the problem, it is critical to understand how much and how quickly sea levels will rise. The projections in the existing predictive models made by scientists are pretty uncertain. Since the contribution from the southernmost continent is so unknown, governments worldwide must consider an unlimited number of scenarios when planning for the future.\n A group of Stanford University scientists employed autonomous drone technology and machine learning approach to focus their efforts on discovering and gathering the most valuable data in Antarctica to increase our understanding of the processes that drive sea-level rise. \n Continue Reading Our Summary on This Research From Stanford or checkout the HAI Report\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tczz2f/stanford_researchers_apply_a_combination_of/",
          "publishedOn": "2022-03-13T05:31:57.000Z",
          "wordCount": 404,
          "title": "Stanford Researchers Apply a Combination of Autonomous Drone Technology With Scientific Machine Learning To Find How Fast Will Antarctica’s Ice Sheet Melt and Reduce The Uncertainty of Sea-Level Rise",
          "imageUrl": "https://external-preview.redd.it/HbNAnirLE9g37ZCbD_ruKOpFz7ni1rV3Sc172T6OqRY.jpg?auto=webp&s=879db8e959a09113cadb5181e8a1bedceb1516b4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tcw0uf/important_video_series_about_agi_how_to_build_it/",
          "author": null,
          "description": "Hey My Reddit Fellows,\n I just wanted to share a video series I am making about AGI, how to manage AGI Safety, and what the post singularity society will look like. Please subscribe to my channel, and let me know if you have any feedback and what topics you would like to see next!\n ►Playlist: https://youtube.com/playlist?list=PLb4nW1gtGNse4PA_T4FlgzU0otEfpB1q1\n ►AGI Existential Threat: https://youtu.be/V4iQP7VDMvI\n ►Life 3.0: https://youtu.be/aWlSwZKzmzY\n ►Dangers of AGI Sub Goals: https://youtu.be/_-tQH03rq4g\n ►How to Create an AGI: https://youtu.be/7OHhqli9oaA\n Thank you!\n Bill\n    submitted by    /u/billgggggg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tcw0uf/important_video_series_about_agi_how_to_build_it/",
          "publishedOn": "2022-03-13T01:34:51.000Z",
          "wordCount": 462,
          "title": "Important Video Series about AGI - How to build it, and why is it dangerous",
          "imageUrl": "https://external-preview.redd.it/lNEROgrjSLb6DEFPjJsRSwU8GiifoPRAA9ACDxVHUsE.jpg?auto=webp&s=08013f03682ba7b26bece17139d407e0189bf593"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tcuw4c/artificial_intelligence_stocks_the_10_best_ai/",
          "author": null,
          "description": "submitted by    /u/crazygrumpy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tcuw4c/artificial_intelligence_stocks_the_10_best_ai/",
          "publishedOn": "2022-03-13T00:31:49.000Z",
          "wordCount": 105,
          "title": "Artificial Intelligence Stocks: The 10 Best AI Companies",
          "imageUrl": "https://external-preview.redd.it/rh9wAA7rWtf8eW6pp0RU8fF2RLx8zi2WQpQI7GQ7QsM.jpg?auto=webp&s=0cc6bba11fbbfba5325110d41e5ba75a52f030e6"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tcob4k/is_there_a_list_with_all_ais_out_there/",
          "author": null,
          "description": "submitted by    /u/TheblackRook3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tcob4k/is_there_a_list_with_all_ais_out_there/",
          "publishedOn": "2022-03-12T19:02:03.000Z",
          "wordCount": 122,
          "title": "Is there a list with all AIs out there?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tcmq1t/amazon_uses_machine_learning_to_improve_video/",
          "author": null,
          "description": "Because streaming video might be harmed by flaws introduced during recording, encoding, packing, or transmission, most subscription video services, such as Amazon Prime Video, monitor the quality of the content they stream regularly.\n Manual content review, often known as eyes-on-glass testing, doesn’t scale well and comes with its own set of issues, such as discrepancies in reviewers’ quality judgments. The use of digital signal processing to detect anomalies in the video signal, which are typically associated with faults, is becoming more popular in the business.\n To validate new program releases or offline modifications to encoding profiles, Prime Video’s Video Quality Analysis (VQA) division began employing machine learning three years ago to discover faults in collected footage from devices such as consoles, TVs, and set-top boxes. More recently, Amazon has used the same techniques to solve problems like real-time quality monitoring of our thousands of channels and live events, as well as large-scale content analysis.\n The Amazon team at VQA trains computer vision models to watch a video and detect flaws like blocky frames, unexpected dark frames, and audio noise that could degrade the customer-watching experience. This allows Amazon to process video on a massive scale, allowing them to process hundreds of thousands of live events and catalog items.\n Continue Reading Our Summary on This Research\n https://i.redd.it/vfx8iiiopzm81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tcmq1t/amazon_uses_machine_learning_to_improve_video/",
          "publishedOn": "2022-03-12T17:46:05.000Z",
          "wordCount": 319,
          "title": "Amazon Uses Machine Learning to Improve Video Quality on Prime Video",
          "imageUrl": "https://external-preview.redd.it/4VQyUj3OTgVEHxFxrcZ91pR6v2pUbKeyH3kdDIlNJcE.jpg?auto=webp&s=52c5d4e739deadb00a88f59aad9f48e6c70cc2ab"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tcjveo/10_best_r_books_for_data_science_beginners/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tcjveo/10_best_r_books_for_data_science_beginners/",
          "publishedOn": "2022-03-12T16:23:37.000Z",
          "wordCount": 126,
          "title": "10 Best R Books for Data Science beginners & advanced to read in 2022 -",
          "imageUrl": "https://external-preview.redd.it/H9Jv8E33MWoQya-GZGwsrayV0O9SGz1Ow1aPydwNlho.jpg?auto=webp&s=b7e7a594e3b0707874b7da6f1df3888034c8648a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tc8u17/microsofts_latest_machine_learning_research/",
          "author": null,
          "description": "Scientists conduct trial and error procedures which experimenting, that many times lear to freat scientific breakthroughs. Similarly, foundational research provides for developing large-scale AI systems theoretical insights that reduce the amount of trial and error required and can be very cost-effective.\n Microsoft team tunes massive neural networks that are too expensive to train several times. For this, they employed a specific parameterization that maintains appropriate hyperparameters across varied model sizes. The used µ-Parametrization (or µP, pronounced “myu-P”) is a unique way to learn all features in the infinite-width limit. The researchers collaborated with the OpenAI team to test the method’s practical benefit on various realistic cases.\n Studies have shown that training large neural networks because their behavior changes as they grow in size are uncertain. Many works suggest heuristics that attempt to maintain consistency in the activation scales at initialization. However, as training progresses, this uniformity breaks off at various model widths.\n CONTINUE READING MY SUMMARY ON THIS RESEARCH\n Paper: https://www.microsoft.com/en-us/research/uploads/prod/2021/11/TP5.pdf\n Github:https://github.com/microsoft/mup\n https://i.redd.it/gmn30ut8wvm81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tc8u17/microsofts_latest_machine_learning_research/",
          "publishedOn": "2022-03-12T04:56:02.000Z",
          "wordCount": 310,
          "title": "Microsoft’s Latest Machine Learning Research Introduces μTransfer: A New Technique That Can Tune The 6.7 Billion Parameter GPT-3 Model Using Only 7% Of The Pretraining Compute",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tc48ve/this_month_in_artificial_intelligence_news/",
          "author": null,
          "description": "submitted by    /u/Beautiful-Credit-868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tc48ve/this_month_in_artificial_intelligence_news/",
          "publishedOn": "2022-03-12T00:28:50.000Z",
          "wordCount": 99,
          "title": "This Month in Artificial Intelligence News",
          "imageUrl": "https://external-preview.redd.it/OD7bJzdwtfQel-mcujy705iRELFCc_rJ5FNDbmpIuUw.jpg?auto=webp&s=43ab0353cd85de2bcdca152d276fd56583f8e25c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tc3yli/game_changer_for_virtual_avatars_and_social/",
          "author": null,
          "description": "submitted by    /u/MLtinkerer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tc3yli/game_changer_for_virtual_avatars_and_social/",
          "publishedOn": "2022-03-12T00:13:40.000Z",
          "wordCount": 231,
          "title": "Game changer for virtual avatars and social robots: this AI model can very accurately transfer your body motion from a video (speech video) to the virtual world! 🤩 🤯",
          "imageUrl": "https://external-preview.redd.it/0JXTBK5osRxnOH3j5LnrORXCDqRpF9LnufeynFpjJC0.jpg?auto=webp&s=a5f65c6f22a973bff9678f5d576e40cec6ad61f3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tc20y9/last_week_in_ai_aideveloped_drug_ai_beats_moores/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tc20y9/last_week_in_ai_aideveloped_drug_ai_beats_moores/",
          "publishedOn": "2022-03-11T22:36:04.000Z",
          "wordCount": 126,
          "title": "Last Week in AI: AI-Developed Drug, AI Beats Moore’s Law, Russia’s AI Army, Baidu’s Robotaxis",
          "imageUrl": "https://external-preview.redd.it/BVsPQuVMIG4vIqgYInex4CqptH0CTvP-UUG_FPQKpIo.jpg?auto=webp&s=57fc730e3d8e2230af2627d648f2fd517e8fb2b9"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tbxo3d/so_here_is_a_question/",
          "author": null,
          "description": "I'm noticing an uptick in Artificial voices for Radio Announcing. What's Odd, is that sometimes it's even the usual guy, who's still living. but he's CLEARLY an AI Voice, as he..stutt...ers his..speEECH in Oddd places.\n ​\n So, how do they create these things? Can anyone take a voice and make new content out of it? I'd have fun taking James Avery's Shredder voice, and redubbing episodes that he missed :).\n    submitted by    /u/HorribleEmulator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tbxo3d/so_here_is_a_question/",
          "publishedOn": "2022-03-11T19:11:29.000Z",
          "wordCount": 158,
          "title": "So, here is a question...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tbx3r1/researchers_from_the_university_of_hamburg/",
          "author": null,
          "description": "The purpose of the paper presented in this article is to reconstruct speech only based on sequences of images of talking people. The generation of speech from silent videos can be used for many applications: for instance, silent visual input methods used in public environments for privacy protection or understanding speech in surveillance videos.\n The main challenge in speech reconstruction from visual information is that human speech is produced not only through observable mouth and face movements but also through lips, tongue, and internal organs like vocal cords. Furthermore, it is hard to visually distinguish phonemes like ‘v’ and ‘f’ only through mouth and face movements. \n This paper leverages the natural co-occurrence of audio and video streams to pre-train a video-to-audio speech reconstruction model through self-supervision.\n Continue Reading my Summary on this Paper\n Paper: https://arxiv.org/pdf/2112.04748.pdf\n https://preview.redd.it/qwimpj0fvsm81.png?width=1079&format=png&auto=webp&s=c69feaa4682098142cdae75e246c228622dede63\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tbx3r1/researchers_from_the_university_of_hamburg/",
          "publishedOn": "2022-03-11T18:45:30.000Z",
          "wordCount": 270,
          "title": "Researchers From the University of Hamburg Propose A Machine Learning Model, Called ‘LipSound2’, That Directly Predicts Speech Representations From Raw Pixels",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tbubl5/is_ai_capable_of_categorizing_web_pages/",
          "author": null,
          "description": "Hi everyone. I've been messing with at least image recognition software when it comes to AI, but not so much with things like machine learning. Before I get too deep in the hole, I'd like to understand the current capabilities of AI and find out of it's something that even sounds feasible. \n There are two main things I'm interested in:\n  \nCan AI categorize web pages based on content? For example, can it distinguish between a page meant for shopping vs one meant for education.\n Can AI determine the purpose of a web page? For example, can it determine if a page is meant for ecommerce vs one meant for getting sign ups or leads?\n  \nThose are the subjects I'm interested in at high level. If they sound like feasible projects, I'd also be curious as to what path and branch of AI I should explore. Thanks in advance.\n    submitted by    /u/kenshinx9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tbubl5/is_ai_capable_of_categorizing_web_pages/",
          "publishedOn": "2022-03-11T16:49:47.000Z",
          "wordCount": 516,
          "title": "Is AI capable of categorizing web pages?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tbsvs4/what_are_ais_that_are_good_at_editing_images_of/",
          "author": null,
          "description": "submitted by    /u/xXNOdrugsForMEXx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tbsvs4/what_are_ais_that_are_good_at_editing_images_of/",
          "publishedOn": "2022-03-11T15:43:54.000Z",
          "wordCount": 167,
          "title": "What are AIs that are good at editing images of faces (it does not matter how the AI is editing the face)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tbsedc/train_an_ai_to_recognize_all_the_clothes_my_brand/",
          "author": null,
          "description": "This might be a silly question whether impossible or simple, but I was wondering if it was possible to train an AI to recognize the clothing we offer to avoid having to manually add metadata to everything. I work at a uniform company whose products stay active for a while and retire them infrequently. I don't know much about ai, but it seems like this is the way to go if I want to automatically add metadata to an image.\n    submitted by    /u/Brentacula  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tbsedc/train_an_ai_to_recognize_all_the_clothes_my_brand/",
          "publishedOn": "2022-03-11T15:21:02.000Z",
          "wordCount": 286,
          "title": "Train an AI to recognize all the clothes my brand produces?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tbqyqy/gfpgan_explained_impressive_face_restoration_model/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tbqyqy/gfpgan_explained_impressive_face_restoration_model/",
          "publishedOn": "2022-03-11T14:10:31.000Z",
          "wordCount": 136,
          "title": "GFP-GAN explained: Impressive face restoration model!",
          "imageUrl": "https://external-preview.redd.it/gl5ZLoeGSN9UNa7aX0UxAW4WTNHAi2xAMBxqLxTzPhY.jpg?auto=webp&s=020a913bdb0015b7b31177a6046d369c034332fe"
        }
      ]
    },
    {
      "title": "Neural Networks, Deep Learning and Machine Learning",
      "feedUrl": "https://www.reddit.com/r/neuralnetworks/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/neuralnetworks/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tz32az/dense_passage_retrieverdpr_openqa_system/",
          "author": null,
          "description": "Hi, I made a video explaining Dense Passage Retriever(DPR) paper. We specifically explain the End to End QA system suggested in the latter part of the paper which discusses how to build an Open-QA system using dense retrievers.\n DPR was one of the first papers that discussed building dense retrievers using QA pairs only and didn't require a big pretraining computational setup like ORQA or REALM. It is currently used in a lot of places as a dense retriever. You can find Hugginface and Haystack implementations also.\n This video is part of a series on Open-QA using dense retrievers. We have made 2 videos on DPR. In the latter, we discuss how to build a dense retriever from scratch. Thanks for the support and it would be great if you could give any feedback.\n https://www.youtube.com/watch?v=rvcyyJNjPU0\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tz32az/dense_passage_retrieverdpr_openqa_system/",
          "publishedOn": "2022-04-08T13:02:42.000Z",
          "wordCount": 236,
          "title": "Dense Passage Retriever(DPR) Open-QA System",
          "imageUrl": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?auto=webp&s=720b78add0a3005c4f67eaed6897df409cc040c6"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tye21i/nn_from_scratch_2_initializing_parameters/",
          "author": null,
          "description": "submitted by    /u/cjmodi306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tye21i/nn_from_scratch_2_initializing_parameters/",
          "publishedOn": "2022-04-07T14:17:46.000Z",
          "wordCount": 119,
          "title": "NN from Scratch: #2 Initializing parameters | Kolbenkraft",
          "imageUrl": "https://external-preview.redd.it/GDnb256QTkcz5l5-77Ys1KBOLyCpV-FhczyyfWFfFkc.jpg?auto=webp&s=6a5ee252a5d11d763b300637085189cc5d1e6e32"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/txw0eh/quick_little_keras_question/",
          "author": null,
          "description": "I tried posting this on stackoverflow with no response.\n Im trying to use model.save() and keras.models.load_model()\n on this chunk of code. But, unlike some of the other keras examples I've played with, this one seems to crash.\n I'm super new to this, any Ideas why? I can post the error message if it helps.\n    submitted by    /u/HoneyBunchsOGoats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/txw0eh/quick_little_keras_question/",
          "publishedOn": "2022-04-06T20:54:46.000Z",
          "wordCount": 152,
          "title": "Quick Little Keras Question",
          "imageUrl": "https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?auto=webp&s=0c3f0b8af92c3a962f569a389e9673597e12f8ec"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/txj3ng/driving_a_robot_with_a_neural_network_use_case/",
          "author": null,
          "description": "submitted by    /u/KamilBugnoKrk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/txj3ng/driving_a_robot_with_a_neural_network_use_case/",
          "publishedOn": "2022-04-06T10:32:23.000Z",
          "wordCount": 128,
          "title": "Driving a robot with a neural network - use case study",
          "imageUrl": "https://external-preview.redd.it/Fq_wbiH_-rAHehqwb2z9g9p99upgQ_6uTmjVCFPjpnY.jpg?auto=webp&s=8bbafc7b268f9f5020abd04de668308a7bef6957"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/txd4pu/heres_an_intuitive_explanation_to_singular_value/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/txd4pu/heres_an_intuitive_explanation_to_singular_value/",
          "publishedOn": "2022-04-06T03:45:33.000Z",
          "wordCount": 157,
          "title": "Here's an intuitive explanation to Singular Value Decomposition. 👇",
          "imageUrl": "https://external-preview.redd.it/yEZqz6bdYi9OxMbxSAun-NOOyBiIEWi0hgButp5s0Bc.jpg?auto=webp&s=7501076a2d95650e0f1222b249a18b18ee508c2e"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tx4n1h/mit_has_trained_ai_to_generate_new_molecular/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tx4n1h/mit_has_trained_ai_to_generate_new_molecular/",
          "publishedOn": "2022-04-05T20:44:31.000Z",
          "wordCount": 123,
          "title": "MIT has trained AI to generate new molecular materials",
          "imageUrl": "https://external-preview.redd.it/VN_AAlU77_6qR-oL5nPN_QANJIRFwqPXPJNyV8WUPTs.jpg?auto=webp&s=e73ced42586cfe5bf9c952d5ab49691b83ef1b02"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tw3wz6/composing_music_with_neural_networks/",
          "author": null,
          "description": "Hey guys,\n ​\n I really love creating music algorithmically, which is why I have dedicated my master’s thesis to the generation of music patterns by the use of artificial intelligence.\n In the course of the past 12 months, I have programmed a deep recurrent neural network in Python, which I have trained on 200 self-made music patterns in order to generate somehow novel motifs.\n ​\n In order to evaluate my model, I have set up a short online listening experiment.\n I’m looking for test subjects right now, so if you are interested in participating, I would really appreciate it.\n The listening experiment will take you just about 5 to 8 minutes to complete and the only thing you need is a pair of headphones.\n You can partake on your computer as well as on your smartphone or tablet.\n ​\n Here is the link which gets you to the listening experiment:\n https://forms.gle/rx1FUQ7RgpjMu1xx9\n ​\n Thank you very much for taking the time to help me reach my goal.\n Really appreciate it.\n    submitted by    /u/JosephdeLaquinta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tw3wz6/composing_music_with_neural_networks/",
          "publishedOn": "2022-04-04T14:51:18.000Z",
          "wordCount": 259,
          "title": "Composing Music with Neural Networks",
          "imageUrl": "https://external-preview.redd.it/b4i5Ja2AxLdJ3zGYml1UCPr28W8teB8EpstN8GR5Z98.jpg?auto=webp&s=4b023a0fd429d0e0c148e9fbe2fb9fb9971c0693"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tvneyx/blog_lets_manually_approximate_a_simple_function/",
          "author": null,
          "description": "submitted by    /u/rhkibria  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tvneyx/blog_lets_manually_approximate_a_simple_function/",
          "publishedOn": "2022-04-03T23:38:37.000Z",
          "wordCount": 126,
          "title": "Blog: Let’s manually approximate a simple function with a ReLU neural network",
          "imageUrl": "https://external-preview.redd.it/cFh6vbg55LHArRON3tZT-u8z_kSyTzhAnSPIpdI7W9o.jpg?auto=webp&s=3db3b3eeca270ba4a17260456a429f17a869f093"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tugj08/nn_from_scratch_1_data_preprocessing_kolbenkraft/",
          "author": null,
          "description": "submitted by    /u/cjmodi306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tugj08/nn_from_scratch_1_data_preprocessing_kolbenkraft/",
          "publishedOn": "2022-04-02T11:16:08.000Z",
          "wordCount": 119,
          "title": "NN from Scratch: #1 Data Preprocessing | Kolbenkraft",
          "imageUrl": "https://external-preview.redd.it/GDnb256QTkcz5l5-77Ys1KBOLyCpV-FhczyyfWFfFkc.jpg?auto=webp&s=6a5ee252a5d11d763b300637085189cc5d1e6e32"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tuecc2/c_machine_learning_book/",
          "author": null,
          "description": "Hey, guys. Just want to ask if anybody's interested with a C++ machine learning book, \"Hands-on Machine Learning with C++\" by Kirill Kolodiazhnyi. \n If you are, send me a DM.\n    submitted by    /u/edmondgrasa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tuecc2/c_machine_learning_book/",
          "publishedOn": "2022-04-02T08:48:09.000Z",
          "wordCount": 130,
          "title": "C++ Machine Learning Book",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tua0x3/efficient_net_vs_resnet/",
          "author": null,
          "description": "As the title says, I would like to know/get some direction to the question when in general does and effnet is preferred to a resnet? I understand that the paper compares performances and it shows a higher performance wrt every network. So my question would be is that always the case or is there a specific situation where it would be better?\n Sorry for the typos (on my mobile)\n    submitted by    /u/johnyj01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tua0x3/efficient_net_vs_resnet/",
          "publishedOn": "2022-04-02T04:05:56.000Z",
          "wordCount": 289,
          "title": "Efficient net vs resnet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tssfwb/i_only_know_one_output_of_a_neural_net_at_a_time/",
          "author": null,
          "description": "submitted by    /u/lullek4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tssfwb/i_only_know_one_output_of_a_neural_net_at_a_time/",
          "publishedOn": "2022-03-31T05:10:44.000Z",
          "wordCount": 464,
          "title": "I only know one output of a neural net at a time. How to train, if i have two outputs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tri77x/ai_podcast_from_neuroscience_to_deep_learning/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tri77x/ai_podcast_from_neuroscience_to_deep_learning/",
          "publishedOn": "2022-03-29T20:14:51.000Z",
          "wordCount": 116,
          "title": "AI podcast: from neuroscience to deep learning",
          "imageUrl": "https://external-preview.redd.it/nlIaWha3rBFT2XH4uw_KXW2brIs-u7NGnIIy3gAqwv0.jpg?auto=webp&s=5b8830a901aeb23c82eb1f89142db6e8cbe6e1cf"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tr566v/neural_networks_project/",
          "author": null,
          "description": "Hi, hope everyone is doing will\n ​\n ​\n i am an EE student, i am currently taking a class (my first) in machine learning, also i am enjoying it so much, now we have reached the point where we are studying neural networks.. back propgation, CNN, RNN, Autoencoders, Deep Learning etc..\n ​\n and my prof wants us to get working with some projects (using neural network)\n ​\n basically he wants us to get some already written code in Gethub (((written with Pytorch))) and understand it, understand the task, the motivation, the structure and the math, and modify it if needed, and implement it, and this will be the project, no one starts from scratch\n ​\n for example:\n image classification\n object detection\n ​\n also he said that the code that identify numbers is simple for a project, it will be an assignment.\n ​\n so any ideas?\n or links\n or any advice in general\n ​\n thanks guys and all the best\n    submitted by    /u/Torvaldz_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tr566v/neural_networks_project/",
          "publishedOn": "2022-03-29T15:54:02.000Z",
          "wordCount": 274,
          "title": "neural networks project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tq3dft/top_5_python_time_series_libraries/",
          "author": null,
          "description": "submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tq3dft/top_5_python_time_series_libraries/",
          "publishedOn": "2022-03-28T06:54:07.000Z",
          "wordCount": 113,
          "title": "Top 5 Python Time Series Libraries",
          "imageUrl": "https://external-preview.redd.it/PSJx7xNt4F5lZFn1vZlAKimT6kKGCTVhpeIuJiCTBNk.jpg?auto=webp&s=5030d7619636a75972e5c0f6fd9b10278bf4b403"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tptsj2/check_out_this_research_summary_article_based_on/",
          "author": null,
          "description": "Deep Neural Networks (DNNs) have excelled at solving complex real-world problems, however, training a good DNN has become more complex. It is challenging to ensure that the optimizers used will converge to reliable minima with acceptable model performance when only minimizing the conventional empirical loss.\n Tsinghua University’s research team proposes Stochastic Scheduled SAM (SS-SAM), a novel and effective DNN training strategy. In SS-SAM, the optimizer is set up by a predetermined scheduling function to run a random trial at each update step, which selects whether to perform the SGD or SAM optimization at random. The overall number of propagation pairs could be significantly decreased in this approach. The team’s approach provides equivalent or higher model training performance at a lower computational cost than baseline sharpness-aware minimization (SAM).\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.09962.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tptsj2/check_out_this_research_summary_article_based_on/",
          "publishedOn": "2022-03-27T21:33:49.000Z",
          "wordCount": 325,
          "title": "Check out this research summary article based on the paper 'SS-SAM: Stochastic Scheduled Sharpness-Aware Minimization for Efficiently Training Deep Neural Networks' where Researchers From Tsinghua University Propose ‘Stochastic Scheduled SAM’ (SS-SAM) for reducing the computational overhead",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tpcila/why_is_the_variable_being_passed_for_iterations/",
          "author": null,
          "description": "As you can see in the figure, i'm passing the variable data_inputs to the feedforward_comp function over iterations. Up to epoch = 9, everything computes fine but after that, data_inputs suddently is being passed as empty?\n Can someone please tell me why this happens and how to fix it?\n https://preview.redd.it/2wds226ktup81.png?width=816&format=png&auto=webp&s=61c55db011708e2d2b373a0b4e4b02355ec50730\n    submitted by    /u/lwhisper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tpcila/why_is_the_variable_being_passed_for_iterations/",
          "publishedOn": "2022-03-27T04:32:49.000Z",
          "wordCount": 173,
          "title": "why is the variable being passed for iterations suddenly passing empty value?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tpc3bk/which_laptop_should_i_buy/",
          "author": null,
          "description": "Hey guys, I really need your help on this one. I go to university next year and I will be studying computer engineering which means there will be a lot of coding going into it. Now I have 4 options for laptop\n First : INSPIRON 15.6\" INTEL CORE 17-1165G7 TOUCHSCREEN 2-IN-1 LAPTOP\n Second: GALAXY BOOK PRO 360 15\" 2-IN-1 INTEL 17 LAPTOP\n Third: HP 15.6\" Touchscreen 2-in-1 Laptop - Nightfall Black (AMD Ryzen 7 5700U/1TB SSD/16GB RAM/Windows 10)\n Fourth: HP Pavilion x360 15.6\" Touchscreen 2-in-1 Laptop - Silver (Intel Core i7-1165G7/1TB SSD/16GB RAM/Win 11)\n Please and thank you guys :)\n    submitted by    /u/Traditional-Cow47  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tpc3bk/which_laptop_should_i_buy/",
          "publishedOn": "2022-03-27T04:04:53.000Z",
          "wordCount": 653,
          "title": "Which laptop should I buy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tnxgjf/question_about_calculating_entropy_of_a_decision/",
          "author": null,
          "description": "Hi! \n I hope this is the right subreddit...\n I am currently studying Electrical Engineering at University and studying for an exam that is (partly) about Neural NEtworks. I am struggling a bit with an example given about calculating the entropy of a decision tree and hope someone here can help me out. \n I have the following information:\n Given information \n The table is the given dataset and the tree is the resulting tree. I am trying to understand how the calculated Entropy values came to place, since I get different answers when I try it myself. \n This is my way (for example for \"level\"):\n p1 (Senior) = 5/14\n p2 (Mid) = 4/14\n p3 (Junior) = 5/14\n Entropy = -(5/14*log_2(5/14)+4/14*log_2(4/14)+5/14*log_2(5/14)) = 1.577 (which makes no sense, since Entropy should be between 0 and 1??)\n Thanks a lot for any help!\n    submitted by    /u/inc0mingst0rm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tnxgjf/question_about_calculating_entropy_of_a_decision/",
          "publishedOn": "2022-03-25T19:48:51.000Z",
          "wordCount": 327,
          "title": "Question about calculating Entropy of a Decision Tree",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tnl6dm/python_neat_neural_network_not_evolving/",
          "author": null,
          "description": "I've been trying to program a \"game\" where drones collect points floating around using a neural network with NEAT. I've tried tinkering a bit with the config file, but the drones just don't seem to evolve... \n https://stackoverflow.com/questions/71611034/python-neat-neural-network-not-evolving\n I guess i just want to know what i'm doing wrong, since nothing appears to be \"evolving\" when i run the program... (NEAT v0.92 and python v3.9.2 btw) link to the github repo is here aswell\n    submitted by    /u/LukasSchulte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tnl6dm/python_neat_neural_network_not_evolving/",
          "publishedOn": "2022-03-25T12:48:22.000Z",
          "wordCount": 230,
          "title": "python NEAT neural network not evolving...",
          "imageUrl": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&s=8cd5e918e2bde6ca72d4445d6fc007f203689799"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tmwwx5/nebullvm_an_opensource_library_to_accelerate_ai/",
          "author": null,
          "description": "How does nebullvm work?\n It takes your AI model as input and outputs an optimized version that runs 5-20 times faster on your hardware. In other words, nebullvm tests multiple deep learning compilers to identify the best possible way to execute your model on your specific machine, without impacting the accuracy of your model.\n And that's it. In just a few lines of code.\n And a big thank you to everyone for supporting this open-source project! The library received 250+ Github stars⭐ on release day, and that's just amazing 🚀\n ORIENTATION MAP\n Let's learn more about nebullvm and AI optimization. Where should we start? From...\n  \nSome CONTEXT on why few developers optimize AI and related negative consequences\n An overview of how the LIBRARY works\n Some USE CASES, technology demonstrations and…",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tmwwx5/nebullvm_an_opensource_library_to_accelerate_ai/",
          "publishedOn": "2022-03-24T19:12:08.000Z",
          "wordCount": 1859,
          "title": "Nebullvm, an open-source library to accelerate AI inference by 5-20x in a few lines of code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tmniqy/anyone_knows_to_code_lenet5_architecture_from/",
          "author": null,
          "description": "submitted by    /u/Actual-Performer-832  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tmniqy/anyone_knows_to_code_lenet5_architecture_from/",
          "publishedOn": "2022-03-24T16:56:50.000Z",
          "wordCount": 130,
          "title": "Anyone knows to code lenet-5 architecture from scratch using numpy only",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tm4127/need_help_better_understanding_a_neural_net/",
          "author": null,
          "description": "Hey , not sure if this is the right place to ask or not, i think itd be. \n Basically i need to create a neural net from scratch in c# for intent classification. I have modelled the neurons as a class with attributes : weights(moddelled as an array, each value is a weight for a branch connecting to the neuron) a , a value(result after the activation),and a bias(a different bias per neuron. \n My question is that , my input will be an array of words, obviously hashed or something so it has a numerical value, each value in the array will be multiplied by the weight. Is the bias added to each of these values and then the activation function applied to each value in the array, OR is it that the activation is applied to the array there is one value as an output and the bias is added to that.\n thank you any help appreciated , if more info is needed then please ask.\n    submitted by    /u/Tubhalooter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tm4127/need_help_better_understanding_a_neural_net/",
          "publishedOn": "2022-03-24T11:43:14.000Z",
          "wordCount": 291,
          "title": "Need Help Better Understanding A Neural Net",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tkuwp9/using_a_training_testing_set_with_neural_networks/",
          "author": null,
          "description": "Let me start this by saying I am a complete rookie on neural networks. I had one semester when we touched on them and I did a project that involved one. Beyond that, my skill is very limited. Now I am out of school and want to improve on my project. Looking for some expert advice. \n My project was based on the program found here:\n Price-Forecaster/Stock-RNN-Deep-Learning-TechIndicators.ipynb at master · marcosan93/Price-Forecaster · GitHub \n I posted an issue and someone added the comment that the programmer has not split the data to X-train,X-test, y-train,y-test so the model will be always biased due to peek ahead. I added early stopping to the program to help with overfitting. Am I understanding things right on where would you add splitting the data? Would you split the data before running the network and use the training data in the epochs, run the network, then recall the best weights for your test set? Just unsure how you do this when the accuracy of the test set may be garbage. \n My goal is to send a list of stocks through the network, then give me a \"report\" at the end that shows which stock is most likely to meet or exceed its prediction. Would this just be a confidence interval? Ideally, I would include a goal return and it would say which stock was most likely to reach that return. Since each stock has its own cycles, I was planning to run each stock through the network to find the individual weights. Any advice on this section?\n I hope you can help with some advice. I'd love to see how well my added code ideas would do. Thanks.\n    submitted by    /u/charlieexcel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tkuwp9/using_a_training_testing_set_with_neural_networks/",
          "publishedOn": "2022-03-23T14:15:50.000Z",
          "wordCount": 556,
          "title": "Using a training & testing set with Neural Networks",
          "imageUrl": "https://external-preview.redd.it/A5ofxfPWskHWXvoAS98biHA4L4t9OWxpA6mc1MYJ1Bk.jpg?auto=webp&s=0bb533929d62197bc97f21177a7c99da220e9e73"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tk668j/ranking_system/",
          "author": null,
          "description": "I am making a mobile app which contains newsfeed page, where I want to show the users post in ranking order, posts can be ranked based on the post content and the user rating count and feedback who has posted it, I don't want to spend more time on building a ranking system so what way or pathway I can take? Is there any API, system or anything already built which I can integrate into my app directly to rank post?\n    submitted by    /u/aliazlanaziz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tk668j/ranking_system/",
          "publishedOn": "2022-03-22T15:57:26.000Z",
          "wordCount": 176,
          "title": "Ranking System",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tjqnpb/nn_ai_vs_projectile_motion_physics/",
          "author": null,
          "description": "submitted by    /u/hotcodist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tjqnpb/nn_ai_vs_projectile_motion_physics/",
          "publishedOn": "2022-03-22T00:43:07.000Z",
          "wordCount": 113,
          "title": "NN AI vs projectile motion physics",
          "imageUrl": "https://external-preview.redd.it/fdMKEfI8oWXMxcJj3idaFxwlB9zN-3WfRmhLszDu9Kw.jpg?auto=webp&s=e98792cf02283574feecbcdf556e1b88dfd73a28"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tjch6j/league_of_legends_a_new_dawn_trailer_resolution/",
          "author": null,
          "description": "submitted by    /u/stepanmetior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tjch6j/league_of_legends_a_new_dawn_trailer_resolution/",
          "publishedOn": "2022-03-21T14:00:31.000Z",
          "wordCount": 152,
          "title": "League of Legends A New Dawn Trailer (Resolution increased with the help of neural networks up to 8K 60FPS)",
          "imageUrl": "https://external-preview.redd.it/DkrKHIH2MDWjvybRTqEoCLwEp4YtYHD_WvOBKXyCBng.jpg?auto=webp&s=529266e30d11a7414c7624d6df14483355a7b458"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tj8kmj/link_to_free_resources_are_mentioned_in_the/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tj8kmj/link_to_free_resources_are_mentioned_in_the/",
          "publishedOn": "2022-03-21T10:21:46.000Z",
          "wordCount": 152,
          "title": "Link to free resources are mentioned in the description of the video!!",
          "imageUrl": "https://external-preview.redd.it/xw2H4WJuvZxWd9rcDDiTmY-foy7xLSAzW8i5qGy0nwU.jpg?auto=webp&s=3b3941047ac4303cf737f9cc51757f4ec3cc7e1c"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tj6uu7/performance_testing_fastapi_ml_apis_with_locust/",
          "author": null,
          "description": "submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tj6uu7/performance_testing_fastapi_ml_apis_with_locust/",
          "publishedOn": "2022-03-21T08:21:59.000Z",
          "wordCount": 125,
          "title": "Performance testing FastAPI ML APIs with Locust | Rubik's Code",
          "imageUrl": "https://external-preview.redd.it/RJASnkisG1D_efNVSaKnxcyWhaf8R_VscIvLSSQ3EiY.jpg?auto=webp&s=92e7da95854271a56cc7a6a9bee866e169d1beb4"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tikvxs/constrained_optimization_with_newtons_method_for/",
          "author": null,
          "description": "Hi!\n Does anyone know of any real-life applications of constrained optimization using newton's method in deep learning (specifically in minimizing the cost function)? Or if constrained optimization is even used at all when minimizing the cost function?\n I know that Newton's method can be used to find the minimum of the cost function in logistic regression. However, would there be any instances where we would add constraints to the cost function in logistic regression, therefore allowing us to use constrained optimization techniques with newton's method (such as Lagrange multipliers or interior-point methods).\n    submitted by    /u/No_Pop3856  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tikvxs/constrained_optimization_with_newtons_method_for/",
          "publishedOn": "2022-03-20T13:19:11.000Z",
          "wordCount": 300,
          "title": "Constrained optimization with newton's method for real-life applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/thrjdb/ai_composer_i_have_forced_the_model_to_generate_a/",
          "author": null,
          "description": "submitted by    /u/amin_mlm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/thrjdb/ai_composer_i_have_forced_the_model_to_generate_a/",
          "publishedOn": "2022-03-19T09:22:42.000Z",
          "wordCount": 217,
          "title": "AI composer> I have forced the model to generate a piece just by using dyads (a 2-note chord)! The challenge is to find notes that match and create beautiful sound. That is why I have named this piece: Love",
          "imageUrl": "https://external-preview.redd.it/EgVfXMtJEfZhiRca4GHCZP3x-_lOdzHIsJWV5RK5-4Y.jpg?auto=webp&s=408ceb0f52e841ac8fe9b245f056322a7b44155c"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/thjizs/i_cant_debug_my_dang_code/",
          "author": null,
          "description": "Hi everyone. I'm trying to debug my code and I can't manage to find what's wrong. I'm running a Roberta model with a classifier head on a Pytorch Lightning trainer and I just get stuck after it is running the optimizer config, it's loading the train data, calling __len__(from dataset) a couple of times, loading val data, calling len again a few times and then complete freeze, what could be going on? Also it's 100% running on the gpu but python is not using any gpu in task manager so I don't think it's actually doing anything.\n    submitted by    /u/DifferentMedia2536  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/thjizs/i_cant_debug_my_dang_code/",
          "publishedOn": "2022-03-19T00:40:26.000Z",
          "wordCount": 204,
          "title": "I can't debug my dang code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/thg7op/r_new_paper_on_autonomous_driving_and_multitask/",
          "author": null,
          "description": "submitted by    /u/xoiga123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/thg7op/r_new_paper_on_autonomous_driving_and_multitask/",
          "publishedOn": "2022-03-18T21:55:34.000Z",
          "wordCount": 232,
          "title": "[R] New paper on autonomous driving and multi-task: \"HybridNets: End-to-End Perception Network\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tghx92/in_a_latest_machine_learning_research_nvidia/",
          "author": null,
          "description": "A promising family of generative models has emerged: score-based generative models (SGMs) and denoising diffusion probabilistic models. SGMs have applications in image, voice, and music synthesis, image editing, super-resolution, image-to-image translation, and 3D shape generation because they provide high-quality synthesis and sample variety without requiring adversarial aims.\n SGMs use a diffusion process to progressively introduce noise to the data, changing a complicated data distribution into a tractable prior distribution for analysis. The modified data’s score function—the gradient of the log probability density—is then learned using a neural network. To synthesize new samples, the learned scores can be used to solve a stochastic differential equation (SDE). Inverting the forward diffusion corresponds to an iterative denoising process.\n Continue Reading\n Paper: https://arxiv.org/pdf/2112.07068.pdf\n Project: https://nv-tlabs.github.io/CLD-SGM/\n Code: https://github.com/nv-tlabs/CLD-SGM\n ​\n https://i.redd.it/8dl9ftuquzn81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tghx92/in_a_latest_machine_learning_research_nvidia/",
          "publishedOn": "2022-03-17T19:18:48.000Z",
          "wordCount": 264,
          "title": "In A Latest Machine Learning Research, NVIDIA Researchers Propose A Novel Critically-Damped Langevin Diffusion (CLD) For Score-Based Generative Modeling",
          "imageUrl": "https://external-preview.redd.it/GhtLJkz3dKHGDiTG_UBEhHxScp4ZqpQqRUG7EykxHbE.jpg?auto=webp&s=390d448fa0241d67a97de869f0ce04454b602641"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tgatkc/neural_network_for_keystroke_biometrics/",
          "author": null,
          "description": "Hi all,\n I apologize for the lack of technical knowledge here, as I have a biology background and am so very much out of my wheelhouse here.\n I was wondering if it was possible to just get a neural network that has already been trained to analyze keystroke biometric data and build profiles off of that information. We are having participants type out a sentence from Alice in Wonderland with a character limit of 100 characters.\n Background: I am a forensic science masters student with a biology background. My masters program has a cybercrime course where we have to conduct a research project with a digital forensic focus, and we've had very little guidance thus far. My project group decided to do a keystroke biometric comparison between English typing vs foreign language typing to see if both profiles could be tied back to one individual (eg, does switching between languages when typing affect typing manner and thus change the keystroke profile of one individual). Unfortunately, this has become a much more technical project than anticipated, and , as I mentioned, NONE of us has any real digital background. Our lecturer just sort of left us hanging and said \"cool, go build and train your own neural network for this project\", while my group has no idea HOW to actually do that.\n Thank you so much for any and all help! As I said, I deeply apologize for my lack of knowledge in this subject, and hope my post here is adequate.\n    submitted by    /u/determinedkorra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tgatkc/neural_network_for_keystroke_biometrics/",
          "publishedOn": "2022-03-17T13:56:01.000Z",
          "wordCount": 351,
          "title": "Neural network for keystroke biometrics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tfhdev/explanation_video_of_how_to_do_openqa_using_orqa/",
          "author": null,
          "description": "Hi, in this video, I explain ORQA which uses a retriever to find the right context from the entire Wikipedia and then uses an extractive QA model to give a final answer. We discuss the task setup, architecture, and loss function.\n The video is part of 8 video series on Open domain question answering, how it is different from normal QA, the difference in loss formulations, and key papers on different Open-QA architectures.\n I will really appreciate any feedback. Thanks.\n https://www.youtube.com/watch?v=9bL2VbwZ9G8 \n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tfhdev/explanation_video_of_how_to_do_openqa_using_orqa/",
          "publishedOn": "2022-03-16T13:12:46.000Z",
          "wordCount": 198,
          "title": "Explanation video of how to do Open-QA using ORQA formulation",
          "imageUrl": "https://external-preview.redd.it/HTMibamaDd8V-S774PygAw37dNn1nKUaGwCwK9Q6_fo.jpg?auto=webp&s=9a06545c15fc5655eb173c4841dfe8611e514ba4"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/teus7y/dp_next_steps_for_testing_a_new_learning_technique/",
          "author": null,
          "description": "submitted by    /u/ronthebear  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/teus7y/dp_next_steps_for_testing_a_new_learning_technique/",
          "publishedOn": "2022-03-15T17:43:37.000Z",
          "wordCount": 317,
          "title": "[D][P] Next steps for testing a new learning technique",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/teuhp7/eigendecomposition_appears_repeatedly_in_machine/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/teuhp7/eigendecomposition_appears_repeatedly_in_machine/",
          "publishedOn": "2022-03-15T17:30:45.000Z",
          "wordCount": 247,
          "title": "Eigendecomposition appears repeatedly in machine learning, sometimes as the key step of the learning algorithm itself. This video intuitively explains the maths behind one of the most important topics in linear algebra - Eigendecomposition. #MathsforMachineLearning",
          "imageUrl": "https://external-preview.redd.it/SM-0IYwNcEO1cVAEXxgWa1-CDePOpR9EbqRgIsD7qw4.jpg?auto=webp&s=c9526eb010129f347a4cc31cf5abdd0109641ebc"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/teohcz/multiclass_classification/",
          "author": null,
          "description": "Hi everyone, I hope you can clarify this to me.\n I have a neural network that needs to predict five classes. One of those classes is very easy to identify since one of the features is highly connected to that class. So when I train the network, it can predict that mentioned class, but it can not differentiate the others.\n Lets say my classes are 0,1,2,3 and 4 and in the predictions i have these values:\n [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 0, 4, 4, 0, 4, 4,\n 4, 4, 0, 4, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4,\n 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 0, 4, 4, 0, 0,\n 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4,\n 0, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 4, 0, 0, 4, 4, 0, 0, 4, 0, 0, 0, 0, 0]\n while the real outputs are like this:\n [4, 1, 3, 1, 1, 4, 4, 2, 1, 2, 1, 0, 0, 1, 0, 4, 1, 1, 0, 4, 4, 0, 3, 1,\n 4, 4, 0, 4, 0, 0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 0, 3, 4, 2, 4, 3, 4, 2, 4,\n 1, 1, 3, 2, 4, 3, 3, 2, 4, 0, 1, 4, 0, 2, 2, 0, 0, 0, 0, 0, 4, 4, 0, 0,\n 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 4, 4, 4, 1, 4, 0, 4, 0, 4, 4, 3, 3, 2, 1,\n 0, 3, 2, 0, 3, 3, 0, 2, 0, 4, 3, 4, 0, 0, 4, 3, 0, 0, 1, 0, 0, 0, 0, 0]\n As you can see class \"0\" is always predicted correctly.\n Should I then maybe take out this class from the training and just train the nn it with the rest of them?\n Is it possible that since class \"0\" has a straightforward pattern to detect is not allowing the nn to learn the behaviour of the other classes?\n ​\n I would appreciate it if you could give me some light on this.\n    submitted by    /u/CardiologistGlass934  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/teohcz/multiclass_classification/",
          "publishedOn": "2022-03-15T13:01:27.000Z",
          "wordCount": 662,
          "title": "Multi-class classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tecbce/beginners_resources_for_understanding_neural/",
          "author": null,
          "description": "Hey ya'll,\n I'm writing a paper for an intro to Data Science course at school and I'm looking for any and all resources that help explain what a neural network is, how it functions, and how its built. Any resources you can share I'd greatly appreciate!\n    submitted by    /u/JonnyEoE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tecbce/beginners_resources_for_understanding_neural/",
          "publishedOn": "2022-03-15T00:40:23.000Z",
          "wordCount": 152,
          "title": "Beginners resources for understanding Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tdxcuu/sign_language_to_text_yes_it_works/",
          "author": null,
          "description": "'Hearing Us’ is basically a Real-time Sign Language translation application.Another Sign Language project which is already available on Youtube and about to get Viral? Not really!\n This project is built using a State-of-the-Art I3D model on the WLASL Dataset. WLASL is the 𝐥𝐚𝐫𝐠𝐞𝐬𝐭 𝐯𝐢𝐝𝐞𝐨 𝐝𝐚𝐭𝐚𝐬𝐞𝐭 𝐟𝐨𝐫 𝐖𝐨𝐫𝐝-𝐋𝐞𝐯𝐞𝐥 𝐀𝐦𝐞𝐫𝐢𝐜𝐚𝐧 𝐒𝐢𝐠𝐧 𝐋𝐚𝐧𝐠𝐮𝐚𝐠𝐞 (𝐀𝐒𝐋) 𝐫𝐞𝐜𝐨𝐠𝐧𝐢𝐭𝐢𝐨𝐧, 𝐰𝐡𝐢𝐜𝐡 𝐟𝐞𝐚𝐭𝐮𝐫𝐞𝐬 2,000 𝐜𝐨𝐦𝐦𝐨𝐧 𝐝𝐢𝐟𝐟𝐞𝐫𝐞𝐧𝐭 𝐰𝐨𝐫𝐝𝐬 𝐢𝐧 𝐀𝐒𝐋. Therefore, it can predict much more than YES, NO and I LOVE YOU’s!\n To get to know about further details about our project, you can checkout the PPT that we prepared for the demonstration(link is in the comment )\n As a part of this project, we have developed two applications:\n  \nThe first application helps the user to translate the sign language to meaningful sentences in Real-Time. You can check the video to know more about how it works.\n The second application is a Web App built using streamlit and deployed using Ngrok on Colab. It can be used to predict words or sentences after uploading the video of the Signing. The predicted output is inserted as a caption on the uploaded video which can then be downloaded by the user.\n  \nA big thanks to Crework for all the mentorship and support which helped us to complete our project in due time. We will now be working on improving our project!\n Do check it out :\n https://www.linkedin.com/posts/patel-ayush_signlanguage-deeplearning-crework-activity-6909133517364887552-Z14b?utm_source=linkedin_share&utm_medium=member_desktop_web\n    submitted by    /u/patel-ayush  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tdxcuu/sign_language_to_text_yes_it_works/",
          "publishedOn": "2022-03-14T13:20:24.000Z",
          "wordCount": 331,
          "title": "Sign Language to Text , Yes it works",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tdvavl/bachelor_in_machine_learning/",
          "author": null,
          "description": "submitted by    /u/UpperSpecialist6286  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tdvavl/bachelor_in_machine_learning/",
          "publishedOn": "2022-03-14T11:26:25.000Z",
          "wordCount": 107,
          "title": "Bachelor in Machine Learning",
          "imageUrl": "https://external-preview.redd.it/bmUEpmVCTpBMsDLuvstQeIfyjZcSDH1oHjXMVAGQpt8.jpg?auto=webp&s=0c32297a65e574cc6cac7faa2a67be65115c60d6"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tdut79/hi_friendsi_have_questions_of_friends_who_have/",
          "author": null,
          "description": "Hi friends,I have questions of friends who have seen to watch five Andrew ng neural network tutorials.\n First, Why did Mr. Andrew come to teach everything in theory, then in his exercises he asked us to answer the exercises in coding form, if in his training he did not proceed in this way and all the contents of the theory were stated?\n Second, are Andrew ng neural network exercises all four-choice (□□□□) or should they be coded?\n Third, Friends who know, please help and how can you completely solve Andrew ng's theory of coding exercises with this tutorial?\n    submitted by    /u/numbers222ddd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tdut79/hi_friendsi_have_questions_of_friends_who_have/",
          "publishedOn": "2022-03-14T10:55:59.000Z",
          "wordCount": 235,
          "title": "Hi friends,I have questions of friends who have seen to watch five Andrew ng neural network tutorials",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tdtihf/scrabbled_brain_neural_network/",
          "author": null,
          "description": "Hello Experts,\n This is my first time creating a neural network, and I have got myself in a bit of a muddle. \n Context: The neural network take 5 co-ordinates taken from a photo - head, waist, knees, feet - (with a graph overlay) and spits out a category out of 4, all gymnastic shapes - tuck, straddle, pike, straight . \n I have use Categorical Cross-Entropy to work out my neural networks loss, I have then used Gradient Descent as an optimizer - with the derivative from the Categorical Cross-Entropy equation. I have now found myself attempting (quite blindly) to adjust the weights in my neural network and have no clue what value I should use as \"error\" in the following equation:\n weight = weight - learning rate * error * input value\n Should I use the output from Categorical Cross-Entropy or Gradient Descent? Or is there an equation I am missing? \n ANY notes would be helpful to me?\n Note: I have linked my code\n    submitted by    /u/_Carrot_Sticks_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tdtihf/scrabbled_brain_neural_network/",
          "publishedOn": "2022-03-14T09:29:39.000Z",
          "wordCount": 265,
          "title": "Scrabbled Brain - Neural Network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tdoxg9/cmu_researchers_introduce_a_method_for_estimating/",
          "author": null,
          "description": "Take a look at the following fascinating observation. On two identically generated datasets S1 and S2 of the same size, train two networks of the same architecture to zero training error. Both networks would have a test error (or, to put it another way, a generalization gap) of about the same size, which is denoted by epsilon.\n Measure the rate of disagreement of the predicted label between these two networks on a new unlabeled dataset U. This disagreement rate could be anything between 0 and 2 epsilon, based on a triangle inequality. However, studies show that the disagreement rate is not only linearly related to the test error but virtually equals it for various training set sizes and models such as neural networks, kernel SVMs, and decision trees.\n What is the source of this unique equality? Solving this unsolved problem could lead to the discovery of basic patterns in how neural networks make mistakes. This could help researchers better understand generalization and other empirical phenomena in deep learning.\n Researchers from Carnegie Mellon University identified a stronger observation first in a recent investigation. Consider two neural networks that were trained with the same hyperparameters and dataset but with different random seeds (for example, the data may be given in various random orders, and/or the network weights could be randomly initialized). Given that both models observe the same data, one would expect the percentage of disagreement to be substantially lower than in previous experiments. \n Continue Reading Our Summary on This Research\n Paper: https://arxiv.org/pdf/2106.13799.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tdoxg9/cmu_researchers_introduce_a_method_for_estimating/",
          "publishedOn": "2022-03-14T04:19:00.000Z",
          "wordCount": 403,
          "title": "CMU Researchers Introduce a Method for Estimating the Generalization Error of Black-Box Deep Neural Networks With Only Unlabeled Data",
          "imageUrl": "https://external-preview.redd.it/V9c4e8jGDkEKggB5Gn7K70aUEx4-cJ3wMzoVT96KCd0.jpg?auto=webp&s=77795585439a96e2c59a3646a937a406b7ff98bb"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tcuex7/ai_learns_to_drive_from_scratch_in_trackmania/",
          "author": null,
          "description": "submitted by    /u/kris33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tcuex7/ai_learns_to_drive_from_scratch_in_trackmania/",
          "publishedOn": "2022-03-13T00:05:25.000Z",
          "wordCount": 148,
          "title": "A.I. Learns to Drive From Scratch in Trackmania - Great introduction and demonstration of reinforcement learning with Deep-Q-Learning",
          "imageUrl": "https://external-preview.redd.it/Z_cOnfydZFeK6pmPlj-sn_SFuT9HaX6DSuUq8kSNWfM.jpg?auto=webp&s=5931afca3f7b8a859ad5be833c410901014e9522"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tcmhc4/deepmind_ithaca_restoring_and_attributing_ancient/",
          "author": null,
          "description": "submitted by    /u/binaryfor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tcmhc4/deepmind_ithaca_restoring_and_attributing_ancient/",
          "publishedOn": "2022-03-12T17:41:00.000Z",
          "wordCount": 125,
          "title": "DeepMind Ithaca - Restoring and attributing ancient texts using deep neural networks",
          "imageUrl": "https://external-preview.redd.it/-TP8pynMyDvAZ3hs5tRv-YkWqsOsefvfCnToC0a4IT4.jpg?auto=webp&s=65b7604f79db72bf441122105728dfe4b3865618"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tch4ke/hey_guys_a_deep_learning_novice_here_i_cant/",
          "author": null,
          "description": "submitted by    /u/ma7modbasha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tch4ke/hey_guys_a_deep_learning_novice_here_i_cant/",
          "publishedOn": "2022-03-12T14:08:28.000Z",
          "wordCount": 510,
          "title": "hey guys a deep learning novice here, I can't really get my head around what could be the cause of the sharp drops in error around epoch 25 and epoch 60. if anyone could help it's much appreciated. thanks",
          "imageUrl": "https://preview.redd.it/ftq2hojwmym81.jpg?auto=webp&s=539f2754cff5fe808d15c3233d844d645c211fe0"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tc8tug/microsofts_latest_machine_learning_research/",
          "author": null,
          "description": "Scientists conduct trial and error procedures which experimenting, that many times lear to freat scientific breakthroughs. Similarly, foundational research provides for developing large-scale AI systems theoretical insights that reduce the amount of trial and error required and can be very cost-effective.\n Microsoft team tunes massive neural networks that are too expensive to train several times. For this, they employed a specific parameterization that maintains appropriate hyperparameters across varied model sizes. The used µ-Parametrization (or µP, pronounced “myu-P”) is a unique way to learn all features in the infinite-width limit. The researchers collaborated with the OpenAI team to test the method’s practical benefit on various realistic cases.\n Studies have shown that training large neural networks because their behavior changes as they grow in size are uncertain. Many works suggest heuristics that attempt to maintain consistency in the activation scales at initialization. However, as training progresses, this uniformity breaks off at various model widths.\n CONTINUE READING MY SUMMARY ON THIS RESEARCH\n Paper: https://www.microsoft.com/en-us/research/uploads/prod/2021/11/TP5.pdf\n Github:https://github.com/microsoft/mup\n https://i.redd.it/wu93hpd7wvm81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tc8tug/microsofts_latest_machine_learning_research/",
          "publishedOn": "2022-03-12T04:55:45.000Z",
          "wordCount": 322,
          "title": "Microsoft’s Latest Machine Learning Research Introduces μTransfer: A New Technique That Can Tune The 6.7 Billion Parameter GPT-3 Model Using Only 7% Of The Pretraining Compute",
          "imageUrl": "https://external-preview.redd.it/B6iRdgtZiAcxaC4xsU93d69X-jFx5sK0LQhJFUPHt3s.jpg?auto=webp&s=e6127da09c5bdca4a3a4be27be2be4acdc42cea8"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tc2oj1/classification_of_pig_calls_produced_from_birth/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tc2oj1/classification_of_pig_calls_produced_from_birth/",
          "publishedOn": "2022-03-11T23:07:06.000Z",
          "wordCount": 143,
          "title": "Classification of pig calls produced from birth to slaughter according to their emotional valence and context of production",
          "imageUrl": "https://external-preview.redd.it/VbwlDMGnPLkh4F_hWdLaJhqGftXtAl9mGsJaKWmmhw4.jpg?auto=webp&s=6ca08a6a43e7ac3ca5202e14087adf616968c603"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tbpy7r/which_are_the_most_influential_papers_on/",
          "author": null,
          "description": "The title mostly covers it. are there any papers you personally would recommend? Thanks all.\n    submitted by    /u/progressiveavocado  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tbpy7r/which_are_the_most_influential_papers_on/",
          "publishedOn": "2022-03-11T13:18:04.000Z",
          "wordCount": 406,
          "title": "Which are the most influential papers on Artificial Neural Networks that you would recommend for a beginner?",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Seita's Place",
      "feedUrl": "https://danieltakeshi.github.io/feed.xml",
      "siteUrl": "https://danieltakeshi.github.io/",
      "articles": []
    },
    {
      "title": "VITALab",
      "feedUrl": "https://vitalab.github.io/feed.xml",
      "siteUrl": "https://vitalab.github.io/",
      "articles": []
    },
    {
      "title": "Stories by Andrej Karpathy on Medium",
      "feedUrl": "https://medium.com/feed/@karpathy",
      "siteUrl": "https://medium.com/@karpathy?source=rss-ac9d9a35533e------2",
      "articles": []
    },
    {
      "title": "OpenAI",
      "feedUrl": "https://openai.com/blog/rss",
      "siteUrl": "https://openai.com/",
      "articles": [
        {
          "id": "624d5b837ce26d004d92d14d",
          "author": "OpenAI",
          "description": "DALL·E 2 is a new AI system that can create realistic images and art from a description in natural language.",
          "link": "https://openai.com/blog/dall-e-2/",
          "publishedOn": "2022-04-06T13:42:00.000Z",
          "wordCount": 722,
          "title": "DALL·E 2",
          "imageUrl": "https://openai.com/content/images/2022/04/dall-e-2-og.jpg"
        },
        {
          "id": "623098c2ed2d75003d8e65ac",
          "author": "Mohammad Bavarian",
          "description": "We’ve released new versions of GPT-3 and Codex which can edit or insert content into existing text, rather than just completing existing text. These new capabilities make it practical to use the OpenAI API to revise existing content, such as rewriting a paragraph of text or refactoring code.",
          "link": "https://openai.com/blog/gpt-3-edit-insert/",
          "publishedOn": "2022-03-15T19:16:20.000Z",
          "wordCount": 3903,
          "title": "New GPT-3 Capabilities: Edit & Insert",
          "imageUrl": "https://openai.com/content/images/2022/03/fib-social.png"
        }
      ]
    },
    {
      "title": "Microsoft Research",
      "feedUrl": "https://www.microsoft.com/en-us/research/feed",
      "siteUrl": "https://www.microsoft.com/en-us/research",
      "articles": [
        {
          "id": "https://www.microsoft.com/en-us/research/?p=830284",
          "author": "Alyssa Hughes",
          "description": "Large pre-trained language models such as GPT-3, Codex, and others can be tuned to generate code from natural language specifications of programmer intent. Such automated models have the potential to improve productivity for every programmer in the world. But since the models can struggle to understand program semantics, the quality of the resulting code can’t […]\nThe post Jigsaw fixes bugs in machine-written software appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/jigsaw-fixes-bugs-in-machine-written-software/",
          "publishedOn": "2022-03-31T17:00:00.000Z",
          "wordCount": 2442,
          "title": "Jigsaw fixes bugs in machine-written software",
          "imageUrl": null
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=829618",
          "author": "Alyssa Hughes",
          "description": "Episode 134 | March 31, 2022 In “Just Tech: Centering Community-Driven Innovation at the Margins,” Senior Principal Researcher Mary L. Gray explores how technology and community intertwine and the role technology can play in supporting community-driven innovation and community-based organizations. Dr. Gray and her team are working to bring computer science, engineering, social science, and […]\nThe post Just Tech: Centering Community-Driven Innovation at the Margins episode 2 with Dr. Tawanna Dillahunt, Zachary Rowe, and Joanna Velazquez appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/just-tech-centering-community-driven-innovation-at-the-margins-episode-2-with-dr-tawanna-dillahunt-zachary-rowe-and-joanna-velazquez/",
          "publishedOn": "2022-03-31T13:00:00.000Z",
          "wordCount": 9485,
          "title": "Just Tech: Centering Community-Driven Innovation at the Margins episode 2 with Dr. Tawanna Dillahunt, Zachary Rowe, and Joanna Velazquez",
          "imageUrl": null
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=824392",
          "author": "Alyssa Hughes",
          "description": "Episode 133 | March 23, 2022 In “Just Tech: Centering Community-Driven Innovation at the Margins,” Senior Principal Researcher Mary Gray explores how technology and community intertwine and the role technology can play in supporting community-driven innovation and community-based organizations. Dr. Gray and her team are working to bring computer science, engineering, social science, and community […]\nThe post Just Tech: Centering Community-Driven Innovation at the Margins episode 1 with Desmond Patton and Mary Gray appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/just-tech-centering-community-driven-innovation-at-the-margins-episode-1-with-desmond-patton-and-mary-gray/",
          "publishedOn": "2022-03-23T16:00:00.000Z",
          "wordCount": 9947,
          "title": "Just Tech: Centering Community-Driven Innovation at the Margins episode 1 with Desmond Patton and Mary Gray",
          "imageUrl": null
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=827599",
          "author": "Brenda Potts",
          "description": "Translator, a Microsoft Azure Cognitive Service, is adopting Z-code Mixture of Experts models, a breakthrough AI technology that significantly improves the quality of production translation models. As a component of Microsoft’s larger XYZ-code initiative to combine AI models for text, vision, audio, and language, Z-code supports the creation of AI systems that can speak, see, […]\nThe post Microsoft Translator enhanced with Z-code Mixture of Experts models appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/microsoft-translator-enhanced-with-z-code-mixture-of-experts-models/",
          "publishedOn": "2022-03-22T17:00:00.000Z",
          "wordCount": 1543,
          "title": "Microsoft Translator enhanced with Z-code Mixture of Experts models",
          "imageUrl": null
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=828337",
          "author": "Brenda Potts",
          "description": "Cloud computing is powering a new age of data and AI by democratizing access to scalable compute, storage, and networking infrastructure and services. Thanks to the cloud, organizations can now collect data at an unprecedented scale and use it to train complex models and generate insights.   While this increasing demand for data has unlocked new […]\nThe post Powering the next generation of trustworthy AI in a confidential cloud using NVIDIA GPUs appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/powering-the-next-generation-of-trustworthy-ai-in-a-confidential-cloud-using-nvidia-gpus/",
          "publishedOn": "2022-03-22T17:00:00.000Z",
          "wordCount": 2586,
          "title": "Powering the next generation of trustworthy AI in a confidential cloud using NVIDIA GPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=825514",
          "author": "Brenda Potts",
          "description": "Quantum computing promises to help us solve some of humanity’s greatest challenges. Yet as an industry, we are still in the early days of discovering what’s possible. Today’s quantum computers are enabling researchers to do interesting work. However, these researchers often find themselves limited by the inadequate scale of these systems and are eager to […]\nThe post Microsoft has demonstrated the underlying physics required to create a new kind of qubit appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/microsoft-has-demonstrated-the-underlying-physics-required-to-create-a-new-kind-of-qubit/",
          "publishedOn": "2022-03-14T13:00:00.000Z",
          "wordCount": 1830,
          "title": "Microsoft has demonstrated the underlying physics required to create a new kind of qubit",
          "imageUrl": null
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=823765",
          "author": "Alyssa Hughes",
          "description": "For children born blind, social interaction can be particularly challenging. A child may have difficulty aiming their voice at the person they’re talking to and put their head on their desk instead. Linguistically advanced young people may struggle with maintaining a topic of conversation, talking only about something of interest to them. Most noticeably, many […]\nThe post PeopleLens: Using AI to support social interaction between children who are blind and their peers appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/peoplelens-using-ai-to-support-social-interaction-between-children-who-are-blind-and-their-peers/",
          "publishedOn": "2022-03-14T08:00:00.000Z",
          "wordCount": 2093,
          "title": "PeopleLens: Using AI to support social interaction between children who are blind and their peers",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "http://feeds.feedburner.com/blogspot/gJZg",
      "siteUrl": "http://ai.googleblog.com/",
      "articles": [
        {
          "id": "http://ai.googleblog.com/2022/04/large-scale-matrix-factorization-on-tpus.html",
          "author": null,
          "description": "Posted by Harsh Mehta, Software Engineer, Google Research \nMatrix factorization is one of the oldest, yet still widely used, techniques for learning how to recommend items such as songs or movies from user ratings. In its basic form, it approximates a large, sparse (i.e., mostly empty) matrix of user-item interactions with a product of two smaller, denser matrices representing learned item and user features. These dense matrices, in turn, can be used to recommend items to a user with which they haven't interacted before. \nDespite its algorithmic simplicity, matrix factorization can still achieve competitive performance in recommender benchmarks. Alternating least squares (ALS), and especially its implicit variation, is a fundamental algorithm to learn the parameters of matrix factorization…",
          "link": "http://ai.googleblog.com/2022/04/large-scale-matrix-factorization-on-tpus.html",
          "publishedOn": "2022-04-08T17:52:00.006Z",
          "wordCount": 2555,
          "title": "Large-Scale Matrix Factorization on TPUs",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/vdtts-visually-driven-text-to-speech.html",
          "author": null,
          "description": "Posted by Tal Remez, Software Engineer, Google Research and Micheal Hassid, Software Engineer Intern, Google Research   \nRecent years have seen a tremendous increase in the creation and serving of video content to users across the world in a variety of languages and over numerous platforms. The process of creating high quality content can include several stages from video capturing and captioning to  video and audio editing. In some cases dialogue is re-recorded (referred to as dialog replacement, post-sync or dubbing) in a studio in order to achieve high quality and replace original audio that might have been recorded in noisy conditions. However, the dialog replacement process can be difficult and tedious because the newly recorded audio needs to be well synced with the video, requiring …",
          "link": "http://ai.googleblog.com/2022/04/vdtts-visually-driven-text-to-speech.html",
          "publishedOn": "2022-04-07T20:45:00.000Z",
          "wordCount": 2033,
          "title": "VDTTS: Visually-Driven Text-To-Speech",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html",
          "author": null,
          "description": "Posted by Ikechukwu Uchendu, AI Resident and Ted Xiao, Software Engineer, Robotics at Google \nReinforcement learning (RL) can be used to train a policy to perform a task via trial and error, but a major challenge in RL is learning policies from scratch in environments with hard exploration challenges. For example, consider the setting depicted in the door-binary-v0 environment from the adroit manipulation suite, where an RL agent must control a hand in 3D space to open a door placed in front of it. \n   \n\n\nAn RL agent must control a hand in 3D space to open a door placed in front of it. The agent receives a reward signal only when the door is completely open.\n\n   \nSince the agent receives no intermediary rewards, it cannot measure how close it is to completing the task, and so must explore …",
          "link": "http://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html",
          "publishedOn": "2022-04-06T14:38:00.001Z",
          "wordCount": 2291,
          "title": "Efficiently Initializing Reinforcement Learning With Prior Policies",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/reproducibility-in-deep-learning-and.html",
          "author": null,
          "description": "Posted by Gil Shamir and Dong Lin, Research Software Engineers, Google Research \nEver queried a recommender system and found that the same search only a few moments later or on a different device yields very different results? This is not uncommon and can be frustrating if a person is looking for something specific. As a designer of such a system, it is also not uncommon for the metrics measured to change from design and testing to deployment, bringing into question the utility of the experimental testing phase. Some level of such irreproducibility can be expected as the world changes and new models are deployed. However, this also happens regularly as requests hit duplicates of the same model or models are being refreshed.  \nLack of replicability, where researchers are unable to reproduce…",
          "link": "http://ai.googleblog.com/2022/04/reproducibility-in-deep-learning-and.html",
          "publishedOn": "2022-04-05T17:41:00.000Z",
          "wordCount": 2730,
          "title": "Reproducibility in Deep Learning and Smooth Activations",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html",
          "author": null,
          "description": "Posted by Sharan Narang and Aakanksha Chowdhery, Software Engineers, Google Research \nIn recent years, large neural networks trained for language understanding and generation have achieved impressive results across a wide range of tasks. GPT-3 first showed that large language models (LLMs) can be used for few-shot learning and can achieve impressive results without large-scale task-specific data collection or model parameter updating. More recent LLMs, such as GLaM, LaMDA, Gopher, and Megatron-Turing NLG, achieved state-of-the-art few-shot results on many tasks by scaling model size, using sparsely activated modules, and training on larger datasets from more diverse sources. Yet much work remains in understanding the capabilities that emerge with few-shot learning as we push the limits of …",
          "link": "http://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html",
          "publishedOn": "2022-04-04T16:01:00.007Z",
          "wordCount": 2737,
          "title": "Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/introducing-cvss-massively-multilingual.html",
          "author": null,
          "description": "Posted by Ye Jia and Michelle Tadmor Ramanovich, Software Engineers, Google Research \nAutomatic translation of speech from one language to speech in another language, called speech-to-speech translation (S2ST), is important for breaking down the communication barriers between people speaking different languages. Conventionally, automatic S2ST systems are built with a cascade of automatic speech recognition (ASR), text-to-text machine translation (MT), and text-to-speech (TTS) synthesis sub-systems, so that the system overall is text-centric. Recently, work on S2ST that doesn’t rely on intermediate text representation is emerging, such as end-to-end direct S2ST (e.g., Translatotron) and cascade S2ST based on learned discrete representations of speech (e.g., Tjandra et al.). While early vers…",
          "link": "http://ai.googleblog.com/2022/04/introducing-cvss-massively-multilingual.html",
          "publishedOn": "2022-04-01T16:06:00.007Z",
          "wordCount": 2595,
          "title": "Introducing CVSS: A Massively Multilingual Speech-to-Speech Translation Corpus",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/03/detecting-signs-of-disease-from.html",
          "author": null,
          "description": "Posted by Boris Babenko, Software Engineer and Naama Hammel, Clinical Research Scientist, Google Health \nThree years ago we wrote about our work on predicting a number of cardiovascular risk factors from fundus photos (i.e., photos of the back of the eye)1 using deep learning. That such risk factors could be extracted from fundus photos was a novel discovery and thus a surprising outcome to clinicians and laypersons alike. Since then, we and other researchers have discovered additional novel biomarkers from fundus photos, such as markers for chronic kidney disease and diabetes, and hemoglobin levels to detect anemia.  \nA unifying goal of work like this is to develop new disease detection or monitoring approaches that are less invasive, more accurate, cheaper and more readily available. How…",
          "link": "http://ai.googleblog.com/2022/03/detecting-signs-of-disease-from.html",
          "publishedOn": "2022-03-24T17:10:00.000Z",
          "wordCount": 2096,
          "title": "Detecting Signs of Disease from External Images of the Eye",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/03/auto-generated-summaries-in-google-docs.html",
          "author": null,
          "description": "Posted by Mohammad Saleh, Software Engineer, Google Research, Brain Team and Anjuli Kannan, Software Engineer, Google Docs  \nFor many of us, it can be challenging to keep up with the volume of documents that arrive in our inboxes every day: reports, reviews, briefs, policies and the list goes on. When a new document is received, readers often wish it included a brief summary of the main points in order to effectively prioritize it. However, composing a document summary can be cognitively challenging and time-consuming, especially when a document writer is starting from scratch. \n To help with this, we recently announced that Google Docs now automatically generates suggestions to aid document writers in creating content summaries, when they are available. Today we describe how this was enab…",
          "link": "http://ai.googleblog.com/2022/03/auto-generated-summaries-in-google-docs.html",
          "publishedOn": "2022-03-23T20:20:00.000Z",
          "wordCount": 2258,
          "title": "Auto-generated Summaries in Google Docs",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/03/offline-optimization-for-architecting.html",
          "author": null,
          "description": "Posted by Amir Yazdanbakhsh, Research Scientist and Aviral Kumar, Student Researcher, Google Research \nAdvances in machine learning (ML) often come with advances in hardware and computing systems. For example, the growth of ML-based approaches in solving various problems in vision and language has led to the development of application-specific hardware accelerators (e.g., Google TPUs and Edge TPUs). While promising, standard procedures for designing accelerators customized towards a target application require manual effort to devise a reasonably accurate simulator of hardware, followed by performing many time-intensive simulations to optimize the desired objective (e.g., optimizing for low power usage or latency when running a particular application). This involves identifying the right ba…",
          "link": "http://ai.googleblog.com/2022/03/offline-optimization-for-architecting.html",
          "publishedOn": "2022-03-17T18:04:00.002Z",
          "wordCount": 2761,
          "title": "Offline Optimization for Architecting Hardware Accelerators",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/03/hybrid-quantum-algorithms-for-quantum.html",
          "author": null,
          "description": "Posted by William J. Huggins, Research Scientist, Google Quantum AI \nThe intersection between the computational difficulty and practical importance of quantum chemistry challenges run on quantum computers has long been a focus for Google Quantum AI. We’ve experimentally simulated simple models of chemical bonding, high-temperature superconductivity, nanowires, and even exotic phases of matter such as time crystals on our Sycamore quantum processors. We’ve also developed algorithms suitable for the error-corrected quantum computers we aim to build, including the world’s most efficient algorithm for large-scale quantum computations of chemistry (in the usual way of formulating the problem) and a pioneering approach that allows for us to solve the same problem at an extremely high spatial res…",
          "link": "http://ai.googleblog.com/2022/03/hybrid-quantum-algorithms-for-quantum.html",
          "publishedOn": "2022-03-16T16:08:00.000Z",
          "wordCount": 2385,
          "title": "Hybrid Quantum Algorithms for Quantum Monte Carlo",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/03/multimodal-bottleneck-transformer-mbt.html",
          "author": null,
          "description": "Posted by Arsha Nagrani and Chen Sun, Research Scientists, Google Research, Perception Team \nPeople interact with the world through multiple sensory streams (e.g., we see objects, hear sounds, read words, feel textures and taste flavors), combining information and forming associations between senses. As real-world data consists of various signals that co-occur, such as video frames and audio tracks, web images and their captions and instructional videos and speech transcripts, it is natural to apply a similar logic when building and designing multimodal machine learning (ML) models.  \n Effective multimodal models have wide applications — such as multilingual image retrieval, future action prediction, and vision-language navigation — and are important for several reasons; robustness, which …",
          "link": "http://ai.googleblog.com/2022/03/multimodal-bottleneck-transformer-mbt.html",
          "publishedOn": "2022-03-15T20:47:00.001Z",
          "wordCount": 2341,
          "title": "Multimodal Bottleneck Transformer (MBT): A New Model for Modality Fusion",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        }
      ]
    },
    {
      "title": "fast.ai",
      "feedUrl": "https://www.fast.ai/atom.xml",
      "siteUrl": "http://www.fast.ai/atom.xml",
      "articles": [
        {
          "id": "http://www.fast.ai/2022/03/15/math-person/",
          "author": null,
          "description": "On the surface, I may seem into math: I have a math PhD, taught a graduate computational linear algebra course, co-founded AI research lab fast.ai, and even go by the twitter handle @math_rachel.\nYet many of my experiences of academic math culture have been toxic, sexist, and deeply alienating. At my lowest points, I felt like there was no place for me in math academia or math-heavy tech culture.\nIt is not just mathematicians or math majors who are impacted by this: Western culture is awash in negative feelings and experiences regarding math, which permate from many sources and impact students of all ages. In this post, I will explore the cultural factors, misconceptions, stereotypes, and relevant studies on obstacles that turn people off to math. If you (or your child) doesn’t like math o…",
          "link": "http://www.fast.ai/2022/03/15/math-person/",
          "publishedOn": "2022-03-15T00:00:00.000Z",
          "wordCount": 1307,
          "title": "There's no such thing as not a math person",
          "imageUrl": null
        },
        {
          "id": "http://www.fast.ai/2022/03/14/ADSN-ethics/",
          "author": null,
          "description": "I have been organizing and facilitating a series of Ethics Workshops for the Australian Data Science Network, featuring lightning talks by Australian experts on a range of topics related to data science ethics, including machine learning in medicine, explainability, Indigenous-led AI, and the role of policy. Check out the videos from these thought-provoking lightning talks (with longer discussions at the end):\nThe False Hope of Explainability in Medicine\nDifferences between understandings of explainability.\n  \n\n\nLauren Oakden-Rayner, the Director of Research for Medical Imaging at Royal Adelaide Hospital, is both a radiologist and a machine learning expert. She spoke about mismatched expectations between technical and non-technical communities on what questions explainability answers, base…",
          "link": "http://www.fast.ai/2022/03/14/ADSN-ethics/",
          "publishedOn": "2022-03-14T00:00:00.000Z",
          "wordCount": 826,
          "title": "7 Great Lightning Talks Related to Data Science Ethics",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Reinforcement Learning",
      "feedUrl": "https://www.reddit.com/r/reinforcementlearning/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/reinforcementlearning/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u049oz/gizmo_is_eating_a_clothes_basket/",
          "author": null,
          "description": "submitted by    /u/mspurplekris  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u049oz/gizmo_is_eating_a_clothes_basket/",
          "publishedOn": "2022-04-09T22:46:30.000Z",
          "wordCount": 95,
          "title": "Gizmo is eating a clothes basket",
          "imageUrl": "https://external-preview.redd.it/C8ARUSGC5ZEyVpjpSpYsycIEJfjoC579hwDthyzwJak.png?blur=40&format=pjpg&auto=webp&s=f3be29fb88d38efbe7d113cc1f952a0589c1e209"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u03y3i/habitatweb_learning_embodied_objectsearch/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u03y3i/habitatweb_learning_embodied_objectsearch/",
          "publishedOn": "2022-04-09T22:29:30.000Z",
          "wordCount": 217,
          "title": "\"Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale\", Ramrakhya et al 2022 {FB} (log-scaling of crowdsourced imitation learning in VR robotics)",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u02tyk/is_it_possible_to_implement_acer_with_a2c/",
          "author": null,
          "description": "I'm looking into implementing a replay buffer in A2C. I came upon the ACER [paper](https://arxiv.org/pdf/1611.01224.pdf). From my understanding, it looks like ACER is an extension of A3C, and it seems like the difference between A2C and A3C is that in A2C parameters are updated synchronously and that helps with big batch sizes. \n Is it still possible to implement some kind of replay buffer on A2C?\n Are there any papers that involve implementing a paper with A2C that you recommend I read?\n I'm new to the area of reinforcement learning, so I would be very grateful for any kind of help you can offer. Thanks in advance\n    submitted by    /u/lebr0n99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u02tyk/is_it_possible_to_implement_acer_with_a2c/",
          "publishedOn": "2022-04-09T21:32:29.000Z",
          "wordCount": 245,
          "title": "Is it possible to implement ACER with A2C?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u00ann/does_anyone_have_a_link_to_the_rl_discord_server/",
          "author": null,
          "description": "Supposedly there is a popular discord server for the RL community, however I am having difficulty finding it.\n    submitted by    /u/jclaessens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u00ann/does_anyone_have_a_link_to_the_rl_discord_server/",
          "publishedOn": "2022-04-09T19:23:29.000Z",
          "wordCount": 147,
          "title": "Does anyone have a link to 'The RL Discord Server'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzvnhc/imitating_fast_and_slow_robust_learning_from/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzvnhc/imitating_fast_and_slow_robust_learning_from/",
          "publishedOn": "2022-04-09T15:34:42.000Z",
          "wordCount": 156,
          "title": "\"Imitating, Fast and Slow: Robust learning from demonstrations via decision-time planning\", Qi et al 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tztri9/reinforcement_learning_looking_for_some_resources/",
          "author": null,
          "description": "Hello friends,\n I'm looking for some resources that would let me quickly start with Reinforcement Learning (preferably in Python). I have some experience with supervised learning (e.g. deep nets) and would like to complement with some RL. Preferably a walkthrough with some examples of implementation. Can you recommend something?\n Thanks in advance!\n    submitted by    /u/andy-codes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tztri9/reinforcement_learning_looking_for_some_resources/",
          "publishedOn": "2022-04-09T13:59:47.000Z",
          "wordCount": 273,
          "title": "Reinforcement Learning - looking for some resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzt78z/im_dumb_at_maths_what_does_this_mean/",
          "author": null,
          "description": "So learning about e-mail learning same have it all understood except for the max thingy. If you care enough to click this blog it's not my blog):\n https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56\n I don't know how to turn this into to a real example:\n Update q values\n Q[state, action] = Q[state, action] + lr * (reward + gamma * np.max(Q[new_state, :]) — Q[state, action])\n Specifically the last bit: \n np.max(Q[new_state, :]) — Q[state, action])\n What does the numpy max actually operate on here?\n Any hard examples? Thanks.\n    submitted by    /u/Togfox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzt78z/im_dumb_at_maths_what_does_this_mean/",
          "publishedOn": "2022-04-09T13:28:32.000Z",
          "wordCount": 566,
          "title": "I'm dumb at maths: what does this mean?",
          "imageUrl": "https://external-preview.redd.it/soqDPbsOXDAx8rb1fY_2BPuguBAOAi7BxwtrOHfJeW0.jpg?auto=webp&s=f7d397129c0a0c3d32549fc5ec56ec6470340e9f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzekkb/rl_for_dynamic_environments/",
          "author": null,
          "description": "In their 2019 review article in Nature Machine Intelligence, Neftci and Averbeck point out, “Most work in biological systems has focused on simple learning problems… where flexibility and ongoing learning are important, similar to real-world learning problems. In contrast, most work in artificial agents has focused on learning a single complex problem in a static environment.”\n Are there RL approaches designed to handle dynamic environments with changing reward functions?\n I did find this earlier post, but thought I'd ask if anyone had other suggested lines of reading.\n Thanks!\n    submitted by    /u/Careless-Argument-37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzekkb/rl_for_dynamic_environments/",
          "publishedOn": "2022-04-08T22:04:50.000Z",
          "wordCount": 244,
          "title": "RL for dynamic environments",
          "imageUrl": "https://external-preview.redd.it/JQx2wIoJt26buLNeTwF2B2kRUu7jfG6Pti_qzRMR2bA.jpg?auto=webp&s=3ace57f9a34e9fe66349fc640a95decc42fcf934"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzee5s/observationspace_max_size/",
          "author": null,
          "description": "I want to give my AI as many information as possible. Can there be an Issue with a too large observation space?\n    submitted by    /u/Willing-Classroom735  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzee5s/observationspace_max_size/",
          "publishedOn": "2022-04-08T21:56:32.000Z",
          "wordCount": 237,
          "title": "Observationspace max Size?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tz4u57/uc_berkeleys_pieter_abbeel_receives_2021_acm/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tz4u57/uc_berkeleys_pieter_abbeel_receives_2021_acm/",
          "publishedOn": "2022-04-08T14:30:24.000Z",
          "wordCount": 149,
          "title": "\"UC Berkeley’s Pieter Abbeel receives 2021 ACM Prize in Computing\" (for DRL robotics)",
          "imageUrl": "https://external-preview.redd.it/FzJ8NRe2mu_Hd_oJNkTrpZw1A6d1wJnhzgz-JqSkmjk.jpg?auto=webp&s=8c1b8d2a0856815293f22351ef8d0b6d3dca408b"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tyxrzi/action_space_dimensional_reduction_for_better/",
          "author": null,
          "description": "I am working on a project in which a robots learns its motion. for example Bipedal robot learns to walk on a straight line by learning to adjust the torque and angular velocity of each joint. However, the robot I am working on has complex architecture. It has 10 joints instead of 2, most importantly all of these joints work simultaneously and coherently to produce a desired motion.\n The Problem I am facing is that, the robot has ten joints and each joint can move between -450 to +450\n for simplicity let me define State and Actions of the system\n State = -450 to +450 -------------> normalization ------------------> -10 to 10\n Actions = choose an angle between -10 to 10 for each joint \n Total Action space for each State at each time step = 10 (no of joints each can move between -10 to 10 at each time step) * 360 (total time steps for a single motion) = 3600 (Output: No of angles required to generate a motion)\n I am using TD3 to solve this conundrum. The Action space is too large how can I reduce the action space?\n    submitted by    /u/SAM_Baloch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tyxrzi/action_space_dimensional_reduction_for_better/",
          "publishedOn": "2022-04-08T07:08:41.000Z",
          "wordCount": 491,
          "title": "Action Space Dimensional reduction for better convergence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tytrpx/dynamic_action_space_in_rl/",
          "author": null,
          "description": "I am doing a project and there is a problem with dynamic action space\n A complete action space can be divided into four parts. In each state, the action to be selected is one of them\n For example, the total discrete action space length is 1000, which can be divided into four parts, [0:300], [301:500],[501:900],[901:1000]\n For state 1, action_ space is [0:300], State2, action_ space is [301:500], etc\n For this idea, I have several ideas at present:\n  \nThere is no restriction at all. The legal actions of all States are [1:1000], but it may take longer train time and there is not much innovation\n Soft constraint, for example, if state1 selects an illegal action, such as one action in [251: 500], reward gives a negative value, but it is also not innovative\n Hard constraint, use action space mask in each state, but I don't know how to do it.. Is there any relevant article？\n It is directly divided into four action spaces and uses multi-agent cooperative relationship learning\n  \n​\n Any suggestions？\n thanks！\n    submitted by    /u/RangerWYR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tytrpx/dynamic_action_space_in_rl/",
          "publishedOn": "2022-04-08T02:58:27.000Z",
          "wordCount": 725,
          "title": "Dynamic action space in RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tyqv88/any_paper_suggestions/",
          "author": null,
          "description": "Hi everyone, i have to define a project for my master degree, so i'm looking for the best papers published since 2018-2019 until now in Reinforcement Learning . Do you have any suggestions, titles or projects that i can check?\n    submitted by    /u/acaviedes15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tyqv88/any_paper_suggestions/",
          "publishedOn": "2022-04-08T00:22:24.000Z",
          "wordCount": 151,
          "title": "Any paper suggestions??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tyog3i/implementation_of_rl/",
          "author": null,
          "description": "Hi all! I am a beginner in RL field and am trying to implement the RL algorithm in the following paper :\n [1912.04321] Learning to Code: Coded Caching via Deep Reinforcement Learning (arxiv.org)\n In short, we are trying to achieve the minimum number of transmission of bits from the server to all users\n Now, after 500 episodes of training the number of transmissions does decrease. But when I implement the same actor critic algorithm this does not happen. In fact, the results seem to be completely random. \n Here is the plot of the same :\n https://preview.redd.it/yve3cay7l6s81.png?width=745&format=png&auto=webp&s=36bf4f0aa813a30024128d797acde3b8adc2df30\n Although my training parameters are slightly different, I can't understand why this would happen.\n I used the parameters and pseudo code from this paper: A Deep Reinforcement Learning Approach for Shared Caching | IEEE Conference Publication | IEEE Xplore - which is an extension of the link at the top.\n ​\n Attaching link to my code: https://www.kaggle.com/samarthtiwari123/rl-for-coded-caching\n Any help would be helpful!!\n Thanks in advance\n    submitted by    /u/samt_123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tyog3i/implementation_of_rl/",
          "publishedOn": "2022-04-07T22:21:20.000Z",
          "wordCount": 261,
          "title": "Implementation of RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tynq4i/how_can_i_extract_the_direction_a_specific_agent/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tynq4i/how_can_i_extract_the_direction_a_specific_agent/",
          "publishedOn": "2022-04-07T21:47:08.000Z",
          "wordCount": 188,
          "title": "How can I extract the direction a specific agent is facing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tylf8u/flow_of_gradients_through_multiple_classes/",
          "author": null,
          "description": "Naive question: if I define my RL model as a combination of different classes (one class that preprocesses the observation, one class that processes the observation, one class that outputs the actions, etc.), is this going to affect the flow of gradients in PyTorch? The alternative would be to create only one class in which I combine everything\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tylf8u/flow_of_gradients_through_multiple_classes/",
          "publishedOn": "2022-04-07T20:01:03.000Z",
          "wordCount": 254,
          "title": "Flow of gradients through multiple classes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tycj9d/can_kl_divergence_be_used_as_a_metric_to_see_the/",
          "author": null,
          "description": "In the hyper parameter section of the paper, it is written that step size of Adam is varied according to KL divergence. So I wanted to know is KL divergence the correct metric to be used for observing the learning progress because we have many states for which probabilites of a particular action is either increased or decreased thus taking average KL mixes up a lot of things.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tycj9d/can_kl_divergence_be_used_as_a_metric_to_see_the/",
          "publishedOn": "2022-04-07T12:59:23.000Z",
          "wordCount": 366,
          "title": "Can KL divergence be used as a metric to see the learning progress in PPO?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ty2dt2/weight_decay_in_policy_network_for_discrete_sac/",
          "author": null,
          "description": "We’re finding that our network is returning a tensor of NaNs towards the end of training. Adding weight decay solves this issue but reduces learning, was wondering if anyone else had experience with vanishing gradients in off-policy methods or any insight?\n    submitted by    /u/TerrificJam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ty2dt2/weight_decay_in_policy_network_for_discrete_sac/",
          "publishedOn": "2022-04-07T02:09:30.000Z",
          "wordCount": 167,
          "title": "Weight decay in policy network for Discrete SAC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txyv62/question_about_model_predictive_control_mpc_cost/",
          "author": null,
          "description": "To my understanding, the cost function is the error between predicted state value and real state value.\n So if I use a neural network as my dynamics model(unknown true dynamics), the MPC cost function is equivalent to NN’s loss function?\n    submitted by    /u/Blasphemer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txyv62/question_about_model_predictive_control_mpc_cost/",
          "publishedOn": "2022-04-06T23:07:19.000Z",
          "wordCount": 299,
          "title": "Question about Model Predictive Control (MPC) cost function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txxore/learning_to_play_settlers_of_catan_with_deep_rl/",
          "author": null,
          "description": "submitted by    /u/henrythepaw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txxore/learning_to_play_settlers_of_catan_with_deep_rl/",
          "publishedOn": "2022-04-06T22:10:27.000Z",
          "wordCount": 318,
          "title": "Learning To Play \"Settlers of Catan\" With Deep RL - code and write-up",
          "imageUrl": "https://external-preview.redd.it/MCy14opBjTIKzwl5JN-l_h8ogp8jGD7JGmk-A4mmZJI.jpg?auto=webp&s=b34f246a1d389b97fb2013f3661ccf8afbf4403e"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txvc52/which_environments_do_you_use_for_benchmarking/",
          "author": null,
          "description": "Hey guys I'm curious which environments you use to benchmark your standard RL algorithms.\n I typically use some environments from the OpenAI Gym or the DM control suite but benchmarking all my implementations against all environments for multiple seeds would take forever. Are there some of their environments you particularly like for benchmarking?\n    submitted by    /u/NiconiusX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txvc52/which_environments_do_you_use_for_benchmarking/",
          "publishedOn": "2022-04-06T20:24:16.000Z",
          "wordCount": 175,
          "title": "Which environments do you use for benchmarking?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txtzv6/how_does_advantage_estimation_is_done_when/",
          "author": null,
          "description": "In the PPO paper it is stated that we have to collect trajectories of length T from N different workers. Suppose I am not using multiple workers then I have to collect episodes N times of fixed length T. But these episode lengths are variable i.e. some episodes end much before T and some much after T. So my question is how do we calculated advantage because according to the PPO paper, for generalized advantage estimate, we have to observe the reward of terminal state. \n ​\n So how should I calculate GAE in this ?\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txtzv6/how_does_advantage_estimation_is_done_when/",
          "publishedOn": "2022-04-06T19:24:05.000Z",
          "wordCount": 254,
          "title": "How does advantage estimation is done when episodes are of variable length in PPO?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txs2jh/a_silly_question_from_a_new_beginner/",
          "author": null,
          "description": "I could not find an answer to a question hanging around in my head for a while. Suppose we have some data, if we build up an MDP to capture actions + state dynamics. Would the optimal policy win state-of-art RL algorithms?\n Edit: If that is the case, why would the community bothers with learning algorithm since finding the model of dynamics is the key?\n ​\n    submitted by    /u/musicinthedark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txs2jh/a_silly_question_from_a_new_beginner/",
          "publishedOn": "2022-04-06T17:56:48.000Z",
          "wordCount": 559,
          "title": "A silly question from a new beginner",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txhq5z/what_does_it_look_like_the_output_of_a/",
          "author": null,
          "description": "Hello,\n I am relatively new in the area of machine learning/reinforcement learning. I have this basic question regarding practical implementations. I just want to know, what does it look like the output of a reinforcement learning agent/algorithm in practice? Is it like a 'look-up table' that will set the weights/parameters of the ML model based on the input data? \n Note that I am asking after the offline training of the agent. How to implement the trained agent in practice, like in an embedded system? Do you guys have references or clues to help me to clarify?\n BR\n    submitted by    /u/b0bzera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txhq5z/what_does_it_look_like_the_output_of_a/",
          "publishedOn": "2022-04-06T08:55:08.000Z",
          "wordCount": 352,
          "title": "What does it look like the output of a reinforcement learning agent/algorithm in practice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txhgbe/multidiscrete_action_space_in_sacsoft_actorcritic/",
          "author": null,
          "description": "Hello!\n I am using SAC(Soft Actor-Critic) to complete a reinforcement learning task with only four steps, each action is from one of four different action spaces. These four action spaces are essentially the same, and they are all chemical compound. I just want the agent to take different types of compounds at each step.\n I have the following questions：\n  \nWhether the different four steps can be trained? In fact, there is a paper that only has four steps in a reinforcement learning process, but his action space only has one discrete action space.\n Is there any article I can learn from? because I know that for the handle control of the game, there are usually multiple discrete action spaces, but each discrete space dimension of my task is larger, such as [800, 700, 500, 600]\n  \nThanks！\n    submitted by    /u/RangerWYR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txhgbe/multidiscrete_action_space_in_sacsoft_actorcritic/",
          "publishedOn": "2022-04-06T08:33:16.000Z",
          "wordCount": 314,
          "title": "multi-discrete action space in SAC(Soft Actor-Critic)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txfewf/is_multi_bandit_on_policy_or_off_policy/",
          "author": null,
          "description": "quick question\n    submitted by    /u/Asleep_Donut1382  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txfewf/is_multi_bandit_on_policy_or_off_policy/",
          "publishedOn": "2022-04-06T06:04:14.000Z",
          "wordCount": 128,
          "title": "Is multi bandit on policy or off policy？",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txe8rj/how_wrong_is_it_to_use_sampling_at_inference_time/",
          "author": null,
          "description": "At my company we use RL to solve our problem. The thing is : our problem is rather complex, and this is the core of our product (so clients rely on the results produced). \n In order to reach satisfying results despite an agent that doesn't learn very well, we use sampling at inference time : instead of taking the best trajectory according to the agent, we take X trajectories and keep only the one with the best reward.\n This seems completely fine at first (similar things are done in NLP for example, with beam search), but in our case the sampling size is huge : 1024. Usually when using beam search, we use maybe a beam size of 6. Maybe 10 if you have good hardware ?\n ​\n Now, the agent seems to be learning : the mean return is slightly increasing over time, the entropies for the actions are steadily decreasing, etc...\n Now the goal of the ML team is to improve agent's learning to decrease the sampling size at inference time (because it's costly to run 1024 trajectories through the environment...).\n But whatever we try, the improvements are not reflected (we compare all our experiments with 1024 sampling in order to see what the customers will see).\n ​\n IMO this is because our sampling size is way too huge, even a random agent can produce okay-ish results...\n Is my intuition the right one ?\n    submitted by    /u/dummy-gummy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txe8rj/how_wrong_is_it_to_use_sampling_at_inference_time/",
          "publishedOn": "2022-04-06T04:51:21.000Z",
          "wordCount": 485,
          "title": "How wrong is it to use sampling at inference time ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txduuq/does_a_masters_thesisdoctoral_dissertation_need/",
          "author": null,
          "description": "I'm in the last semester of my undergraduate degree; over the past couple of weeks, I've been trying to brainstorm ideas that I would like to pursue in my graduate research career. I'm interested in the emergence of language in multi-agent reinforcement environments but I can't see how this would be important down the line when there are large language models that are completely dominating language and communication. \n Should this stop me from pursuing this idea or should I let my interest in the idea take precedence?\n    submitted by    /u/clarky103  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txduuq/does_a_masters_thesisdoctoral_dissertation_need/",
          "publishedOn": "2022-04-06T04:27:30.000Z",
          "wordCount": 283,
          "title": "Does a master's thesis/doctoral dissertation need to have implications down the line for it to be good?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txbvya/how_long_would_it_take_you_to_implement_a_marl/",
          "author": null,
          "description": "Out of curiosity, how long would it take to implement a paper like this one? https://arxiv.org/abs/2104.07750 \n It has PPO agents in MARL, all of them with multihead attention performed on the observation, in such a way that an attention map is created for each agent. This attention map has information about how strongly each agent is attending to various elements of the environment. With KL divergence, the agents are rewarded for minimizing the difference between their attention maps.\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txbvya/how_long_would_it_take_you_to_implement_a_marl/",
          "publishedOn": "2022-04-06T02:37:14.000Z",
          "wordCount": 256,
          "title": "How long would it take you to implement a MARL PPO agent with joint attention architecture?",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tx2zbs/need_project_suggestions/",
          "author": null,
          "description": "I’ve been running circles in tutorial purgatory and I want to get out of it with sone projects. Anyone has any suggestions? Guided ones would be nice. For unguided ones, could you please provide source links/hints?\n    submitted by    /u/HellVollhart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tx2zbs/need_project_suggestions/",
          "publishedOn": "2022-04-05T19:31:36.000Z",
          "wordCount": 220,
          "title": "Need project suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tx0cmf/agents_learns_policy_when_sampling_last_episode/",
          "author": null,
          "description": "Hi all. I've been stuck on this problem for a while and I thought I might be able to find some help here. Any kind of assistance would be greatly appreciated. \n My setup is as follows. I have an environment with 3 agents. All 3 agents have a single policy network, and it is based on CommNet. My goal is to implement a replay buffer for this environment. I verified that my replay buffer logic is good. I tried running 3 different types of runs:\n  \nNormal on-policy run: The agents perform an episode, and at the end of each episode the data (such as the states, actions, etc) from this episode are used to calculate the loss\n Using just the last episode from the replay buffer: The agents perform an episode, and the data is stored in the replay buffer. At the end of each episode, the last episode is sampled from the replay buffer (which is the episode that was just performed). This is just to confirm that my replay buffer is working properly, and the reward curve for this case matches that from (1).\n Using 1 random episode from the replay buffer: The agents perform an episode, and the data is stored in the replay buffer. At the end of each episode, a random episode is sampled from the replay buffer and used to calculate the loss. The performance is terrible in this case, and the environment times out each time\n  \nFor some reason, as soon as I turn on random sampling, progress is really bad. I'm sorry to pose such an open-ended question, but what are some things I could check to pinpoint the source of this problem? What could be a reason as to why performance is as expected when just sampling the last episode, whereas it is terrible when randomly sampling episodes? I've tried some things thus far but nothing has worked, and I turned to this community in hopes of getting some help. I'm new to the area of reinforcement learning, so I would be very grateful for any kind of help you can offer. Thanks in advance\n    submitted by    /u/lebr0n99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tx0cmf/agents_learns_policy_when_sampling_last_episode/",
          "publishedOn": "2022-04-05T17:33:13.000Z",
          "wordCount": 822,
          "title": "Agents learns policy when sampling last episode from replay buffer, but don't when randomly sampling from the replay buffer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twvl67/ppo_sample_correlation/",
          "author": null,
          "description": "Hi, I'm wondering if the PPO algorithm can solve the sample correlation problem of on-policy algorithm in training. PPO uses successive samples to compute GAE, doesn't the sample correlation occurring here interfere with learning?\n    submitted by    /u/noisemastar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twvl67/ppo_sample_correlation/",
          "publishedOn": "2022-04-05T13:59:05.000Z",
          "wordCount": 145,
          "title": "PPO sample correlation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twu26i/p_automlconf_competition_dac4automl/",
          "author": null,
          "description": "submitted by    /u/catsortion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twu26i/p_automlconf_competition_dac4automl/",
          "publishedOn": "2022-04-05T12:42:37.000Z",
          "wordCount": 251,
          "title": "[P] AutoML-Conf Competition: DAC4AutoML",
          "imageUrl": "https://external-preview.redd.it/hwN3EBf7WXi3MEvXiPgqOQzZmfA3yEU8ZOPYIry-WJw.jpg?auto=webp&s=e08b4e79f3d8a80bcf43263d687e29f7665b1ad1"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twu0ai/temporal_difference_learning_for_model_predictive/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twu0ai/temporal_difference_learning_for_model_predictive/",
          "publishedOn": "2022-04-05T12:39:47.000Z",
          "wordCount": 135,
          "title": "Temporal Difference Learning for Model Predictive Control",
          "imageUrl": "https://external-preview.redd.it/Gljiri4TRWX3LOG95WYZE6MZGLdmGsASRjvASplDC7E.jpg?auto=webp&s=090bac27aa9321e9cdce487f0e8952373244ca01"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twtuwp/why_is_there_no_rollout_monitoring_for_this/",
          "author": null,
          "description": "​\n Output from using model.learn(env) on both Envs\n On the left I have a simple dummy CustomEnv (Using Stable-Baselines3 with Gym) for testing, and on the right I have my actual CustomEnv that I am working on in a project.\n As you can see, the dummy environment gives me the rollout monitoring, whereas there is no rollout monitoring for the actual environment (just time + train statistics/monitoring). \n I am using very similar code when setting up the training of the model, however the complexity of the actual model is significantly higher than the dummy. In theory, the complexity of the environment shouldnt make a big difference to the monitoring right? All of the key parts are still there (reward function, step function, reset function etc.).\n In both cases it says that the environments are being wrapped by the 'Moniter' wrapper so that cant be it.\n Does anyone know why this might be happening?\n    submitted by    /u/C_BearHill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twtuwp/why_is_there_no_rollout_monitoring_for_this/",
          "publishedOn": "2022-04-05T12:31:27.000Z",
          "wordCount": 288,
          "title": "Why is there no rollout monitoring for this CustomEnv (on the right) ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twrz5x/value_iteration_in_car_racing_v1/",
          "author": null,
          "description": "I’m working on Q table learning model for OpenAI’s. I have everything done in regards to a basic agent, but I’m unsure how I’m supposed to use the box data for action space and observance space, to populate a q table?\n Or is this approach incorrect? Car Racing doesn’t have a P (probability) call so I’m not sure how else I would do value iteration.\n    submitted by    /u/Dzartovian94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twrz5x/value_iteration_in_car_racing_v1/",
          "publishedOn": "2022-04-05T10:38:55.000Z",
          "wordCount": 405,
          "title": "Value Iteration in Car Racing V1",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twp4x8/action_spaces_all_landing_to_zero_probability_in/",
          "author": null,
          "description": "Hey guys, I am new to RL and walking through the Keras implementation of Actor Critic.\n ​\n As a variant of it, I am trying to learn the strategy for WORDLE. However, after a few runs, my action spaces all go down to zero. Not sure what's happening. Could someone have any insights or pointers?\n ​\n Attaching my code for reference.\n ​\n Thanks\n import pandas as pd import numpy as np import random import string import random import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers # Configuration parameters for the whole setup gamma = 0.9 # Discount factor for past rewards max_runs = 10000 eps = np.finfo(np.float32).eps.item() # Smallest number such that 1.0 + eps != 1.0 my_file = open(\"<wordle set of words data path>\", \"r\") content = my_file.read() content = lis…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twp4x8/action_spaces_all_landing_to_zero_probability_in/",
          "publishedOn": "2022-04-05T07:13:26.000Z",
          "wordCount": 964,
          "title": "Action Spaces all landing to zero probability in few steps",
          "imageUrl": "https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?auto=webp&s=079a7260ec149880c73263d64811698adb22760a"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twlxdl/any_rlrelated_conferences_right_after_neurips_22/",
          "author": null,
          "description": "In case my NeurIPS submission rejected, lol.\n    submitted by    /u/Blasphemer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twlxdl/any_rlrelated_conferences_right_after_neurips_22/",
          "publishedOn": "2022-04-05T03:51:12.000Z",
          "wordCount": 226,
          "title": "Any RL-related conferences right after NeurIPS 22’?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twg36r/ppo_alg_confusion/",
          "author": null,
          "description": "As I read the paper and several tutorials, I am quite confused about the details.\n  \nI see many implementations scale the running cumulative discounted reward in a certain way. However, each of them does it in a different way. let R be the running cumulative discounted reward, which is considered the best? Or is there a source of the method to use? implementations I saw from different places include: \n  \n directly use R to calculate the advantage and training value network (most PPO tutorials use this)\n use (R / std(R)), where std is the mini-batch standard deviation\n use (R / std(R)), where std is the running standard deviation\n use ((R - mean(R)) / std(R)), where both mean and std are mini-batch wise\n use ((R - mean(R)) / std(R)), where both mean and std are running stats.\n do the above and clip to a certain range ([-10, 10] or [-1, 1])\n  \n I also see several different ways for the value network, let V be the output of the value network:\n  \n output raw logit, without any scaling/output activation (most PPO tutorials use this)\n output raw logit, but use the same scaling as discussed above for running cumulative discounted reward, for example, if return value is (R / std(R)), value output will be (V / std(R))\n do the same as 2, but use the stat of V instead of R for scaling, for example, if the return value is (R / std(R)), the value output will be (V / std(V))\n output with tanh activation at the last layer\n output with tanh activation at the last layer, and multiply by a constant to match the range of the return\n  \nany help would be appreciated, thanks!\n    submitted by    /u/seermer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twg36r/ppo_alg_confusion/",
          "publishedOn": "2022-04-04T23:10:05.000Z",
          "wordCount": 552,
          "title": "PPO Alg confusion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twbnb2/im_completely_new_to_rl_and_will_be_building_my/",
          "author": null,
          "description": "Hello all,\n As the title describes, I’ll be making my first model as part of my final project. I still have a pretty high-level understanding of everything, so forgive any inaccuracies as I describe what I’m going for.\n The problem I’m attempting to solve is known as the traveling salesman problem. Essentially, a route needs to be formulated that stops at n given locations. Finding the most efficient route with many stops algorithmically is impractical because the number of possible routes increases exponentially with each added location. \n The environment will simulate travel on city roads. Speed will be a constant, set to whatever the roads speed limit is. I am using .pbf format vector GIS data from OSM so that the environment consists of real-world pathways. I’m using GeoPandas and Pyrosm to work with the data, and I’m collecting nodes for the location of gas stations so that the environment can simulate needing to fuel the vehicle. Gas price will be a constant, as well as vehicle fuel-efficiency.\n Scoring will be based on the calculated time it would take to complete a route and the calculated cost (in gas). The goal will be to find the most efficient route to take when n = some large number. \n I’ve never worked with spatial data either, so I’m not sure what kind of challenges that poses. I worry that adding nodes for the locations of gas stations might be difficult. I’m also wondering if I’m better off using Tensorflow and Keras for this, but I’m not really aware of all the technical considerations I should be making before deciding on that.\n Do you have any tips that might help me out? Solutions to problems I haven’t hit just yet, but likely will? \n Thanks for your help!\n    submitted by    /u/professorDissociate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twbnb2/im_completely_new_to_rl_and_will_be_building_my/",
          "publishedOn": "2022-04-04T20:07:52.000Z",
          "wordCount": 475,
          "title": "I’m completely new to RL and will be building my first model as part of my degree-ending project. Do you have any tips you can provide?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twbn40/best_implementations_for_extensibility/",
          "author": null,
          "description": "As far as I am aware, StableBaselines3 is the gold standard for reliable implementations of most popular / SOTA deep RL methods. However working with them in the past, I don't find them to be the most usable when looking for extensibility (making changes to the provided implementations) due to how the code base is structured in the behind the scenes (inheritance, lots of helper methods & utilities, etc.).\n For example, if I wish to change some portion of a method's training update with SB3 it would probably involve overloading a class method before initialization, making sure al the untouched portions of the original method are carried over, etc.\n Could anyone point me in the direction of any implementations that are more workable from the perspective of extensibility? Ideally implementations that are largely self contained to a single class / file, aren't heavily abstracted aware across multiple interfaces, don't rely heavily on utility functions, etc.\n    submitted by    /u/Farconion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twbn40/best_implementations_for_extensibility/",
          "publishedOn": "2022-04-04T20:07:40.000Z",
          "wordCount": 367,
          "title": "Best implementations for extensibility?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twaicu/is_it_possible_to_use_inspectgetcallargs_to/",
          "author": null,
          "description": "Given a NN class, is there something specific we need to care of when converting *args and **kwargs to a canonical kwarg representation? I ask this because in this code from Google (https://github.com/google-research/google-research/blob/c56b47713b08c95ad427d5f93ee0dbb9ad008964/social_rl/multiagent_tfagents/joint_attention/attention_networks.py#L557) they use a TFDecorator-aware replacement for inspect.getcallargs, instead of using getcallargs directly. So my questions are: \n - Is it possible to use inspect.getcallargs to convert *args and **kwargs to a canonical kwarg representation?\n - If no, is there an equivalent in PyTorch? I couldn't find any, so I was wondering how people go about that.\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twaicu/is_it_possible_to_use_inspectgetcallargs_to/",
          "publishedOn": "2022-04-04T19:21:36.000Z",
          "wordCount": 242,
          "title": "Is it possible to use inspect.getcallargs to convert *args and **kwargs to a canonical kwarg representation in RL?",
          "imageUrl": "https://external-preview.redd.it/CMhpMLhb6T0d4kqxMnDmxlqLqBIUASjloDaZLDY4pDk.jpg?auto=webp&s=411a8f7f0fc00a11f3af1004038b99d54177481c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw75kp/openai_gym_return_donetrue_but_not_seeing_goal_is/",
          "author": null,
          "description": "Hi all, I am running some starter code from openAI(FetchReach-v1, FetchPush-v1) gym with env.action_space.sample(). But I don't see the goal is actually achieved when done returned is True. I copied the code from here (https://openai.com/blog/ingredients-for-robotics-research/). I even let it sleep every step to watch more closely. Another related thing that I can't explain is that it always returns done==True rather quickly with very few sampled actions. These all make me worried about using it as my task environment.\n    submitted by    /u/AnimatorRemarkable20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw75kp/openai_gym_return_donetrue_but_not_seeing_goal_is/",
          "publishedOn": "2022-04-04T17:04:39.000Z",
          "wordCount": 304,
          "title": "openAI gym return done==True but not seeing goal is reached",
          "imageUrl": "https://external-preview.redd.it/lrIvaCZG-_bxok-lBkmGtKy2ufLuAQcEhYGt1O-R0rY.jpg?auto=webp&s=24d01b26bc9d2333ef8868067f3263d0ed1601c3"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw3fii/which_elective_monte_carlo_simulation_or/",
          "author": null,
          "description": "Hello /r/reinforcementlearning. I have to choose electives pretty soon, and as i am interested in reinforcement learning, I wanted to know which of these would be the most beneficial. \n  \nMonte Carlo Simulation\n Computational Learning Theory\n  \nThe year after I will also take a course on Reinforcement Learning, but it has not been created yet. \n Note: I can also take both if recommended, if I do so, I will take one of the courses before taking the RL course, and the other would be at the same time. \n Some further thought I've had:\n  \nCLT includes Bandits, which is surely were useful to know, but it seems to be only a rather small part, and I'm unsure whether all the other topics like PAC Learning and Rademacher Bounds are useful?\n \nMC is more practical while CLT is more theoretic (Apparently VERY theoretic according to the course description above). I am not afraid of theoretic courses, but I struggle more with them than more practical courses.\n \nThe sentiment around the MC course, is that it is pretty good. I don't know anyone who have taken the CLT course.\n \nIf I choose both, which order would you take them in?\n \n    submitted by    /u/John_Hitler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw3fii/which_elective_monte_carlo_simulation_or/",
          "publishedOn": "2022-04-04T14:30:21.000Z",
          "wordCount": 462,
          "title": "Which elective: Monte Carlo Simulation or Computational Learning Theory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw2v97/ray_rl_lib_observations_normalized/",
          "author": null,
          "description": "Hey i am using the RL lib from ray and i don't know if the observations automatically normalized by the lib or not?\n By creating a costum environment ray wants you to create an observationspace. That would be a gym box in my case. Anyway idk the exact high and low values. My values lay between -1 and 1 more or less. \n My fear is now that ray would normalize the Observation values to a new range although they are already processed. Does ray normalized observationspace? If yes how can i turn it off?\n Thanks!\n    submitted by    /u/Willing-Classroom735  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw2v97/ray_rl_lib_observations_normalized/",
          "publishedOn": "2022-04-04T14:06:31.000Z",
          "wordCount": 266,
          "title": "Ray RL lib observations normalized?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw2dla/cfp_evorl_gecco_2022_one_week_before_the_deadline/",
          "author": null,
          "description": "CALL FOR PAPERS\n EvoRL 2022\n Evolutionary Reinforcement Learning workshop at GECCO 2022, July 9-13, Boston, USA\n \n In recent years reinforcement learning (RL) has received a lot of attention thanks to its performance and ability to address complex tasks. At the same time, multiple recent papers, notably work from OpenAI, have shown that evolution strategies (ES) can be competitive with standard RL algorithms on some problems while being simpler and more scalable. Similar results were obtained by researchers from Uber, this time using a gradient-free genetic algorithm (GA) to train deep neural networks on complex control tasks. Moreover, recent research in the field of evolutionary algorithms (EA) has led to the development of algorithms like Novelty Search and Quality Diversity, capable of…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw2dla/cfp_evorl_gecco_2022_one_week_before_the_deadline/",
          "publishedOn": "2022-04-04T13:44:45.000Z",
          "wordCount": 625,
          "title": "[CfP] EvoRL @ GECCO 2022. One week before the deadline!",
          "imageUrl": "https://external-preview.redd.it/lK42WwByGG32nygWSBuOYR3KR5RyUTDVfuLYvfjqmTI.jpg?auto=webp&s=02c389b64acc7a9d40c4c4ad6555c2381750877f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw10gn/how_ppo_deals_with_episodes_of_variable_lengths/",
          "author": null,
          "description": "In the paper it is written to collect trajectories of length T. Then calculate advantage and then train the Actor and Critic Network. My question is suppose one episode ends much before T. If I run that episode upto lenth T then it will only collect negative rewards in each timestep which in turn makes the training impossible as the return if very big negative number. So what can be done instead of this?\n I might be getting it wrong, so please correct me by commenting.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw10gn/how_ppo_deals_with_episodes_of_variable_lengths/",
          "publishedOn": "2022-04-04T12:39:24.000Z",
          "wordCount": 284,
          "title": "How PPO deals with episodes of Variable lengths?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tvyv0w/need_help_with_openai_gym_custom_environment/",
          "author": null,
          "description": "Hello,\n I'm making a custom openAI gym environment to train various algorithms on it. I have encountered some issues. \n My .flatten() method on the state class returns a large integer which can be converted back into the same state as the object. However when I try to do this as the returned observation for environment.reset() and environment.step(), when testing it I get: \"AssertionError: The observation returned by the `reset()` method does not match the given observation space\" which I can fix by having it just return a 0. How do I go about resolving this? and are there any better approaches for wanting to train RL agents on an environment? ty!\n    submitted by    /u/snaredrum_merchant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tvyv0w/need_help_with_openai_gym_custom_environment/",
          "publishedOn": "2022-04-04T10:38:08.000Z",
          "wordCount": 264,
          "title": "Need help with OpenAI gym custom environment, state representation as \"observation\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tvipcq/how_does_the_acer_algorithm_work/",
          "author": null,
          "description": "I am currently writing a report on reinforcement learning, where I am trying to describe how the ACER algorithm works. I have read the arxiv paper on the sample actor-critic with experienced replay, but I don't understand where the experience replay comes in. Is this part of the policy gradient? where the policy is updated every episode it's trained on from the previous knowledge it gathers in previous episodes.\n https://arxiv.org/pdf/1611.01224.pdf\n ​\n    submitted by    /u/beepingwater_neko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tvipcq/how_does_the_acer_algorithm_work/",
          "publishedOn": "2022-04-03T20:14:25.000Z",
          "wordCount": 229,
          "title": "How does the ACER algorithm work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tvif3g/whats_the_best_way_to_implement_tree_bases/",
          "author": null,
          "description": "Sorry if this post is not appropriate here, but I have been wondering how can I implement and learn a decision tree or any other non differentiable function approximators for the Value Function.\n It’s relatively easy to formulate and use DQN type algorithms by using neural network and say pytorch + stochastic optimization but I want to try out some tree based methods. (at least to reproduce papers which claim to use them)\n But I don’t know 1) If we have to design the structures and learning algorithms by hand or is there any package I can use? \n 2) How should the learning be done? We obviously can’t go regression type learning because of the bootstrapping nature of the Bellman equation?\n Thanks\n    submitted by    /u/Htaseht  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tvif3g/whats_the_best_way_to_implement_tree_bases/",
          "publishedOn": "2022-04-03T20:03:04.000Z",
          "wordCount": 253,
          "title": "What’s the best way to implement tree bases function approximators for RL/Control?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tv9iif/im_working_on_a_dqn_agent_using_the_keras_rl/",
          "author": null,
          "description": "The episode step count is the same for training and testing.\n    submitted by    /u/Gleann_na_nGealt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tv9iif/im_working_on_a_dqn_agent_using_the_keras_rl/",
          "publishedOn": "2022-04-03T13:40:29.000Z",
          "wordCount": 312,
          "title": "I'm working on a DQN agent using the Keras RL library to play Atari games, however a weird thing keeps happening where every episode is the same length but it's a random number each time.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tuzq36/are_there_any_real_life_projects_i_could_do_with/",
          "author": null,
          "description": "I tried using RL for some work at my university, it did not really work all that well. \n I'm wondering if there are some real life scenarios that I could use to create my own personal projects. Otherwise, I'd be fine with games. \n I want to try all of it out from Dynamic Programming to crazy ass stuff like A3C, PPO and so on. I like RL, more so than any other form of ML, and I want to play around with it as a hobby. \n This is really the area of ML for me. For starters, there are fundamentals behind it, so you can mostly explain why agents do one thing or another. Additionally, there isn't a need to have massive amounts of data. It's also the only type of ML that I've been able to successfully use with software engineering. \n Designing the agent and the API it uses to take actions in an environment is as much a software engineering project as is creating a REST API. \n I feel there is a lot of potential for me to go crazy with this, and I was wondering if people have any cool suggestions. Anything that is real time is anything that I want to do. Real time systems and RL are exactly the sort of thing I love to do.\n    submitted by    /u/HesperusIII  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tuzq36/are_there_any_real_life_projects_i_could_do_with/",
          "publishedOn": "2022-04-03T03:22:28.000Z",
          "wordCount": 477,
          "title": "Are there any real life projects I could do with this? How do I get ideas to use this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tuwhbp/agentzero_ray_pytorch_based_lightweight/",
          "author": null,
          "description": "AgentZero\n https://github.com/zhoubin-me/agent0\n This is my personal project developed two years ago. It covers major DRL algorithms like:\n - [DQN](https://arxiv.org/abs/1312.5602)- [Double DQN](https://arxiv.org/abs/1509.06461)- [Dueling DQN](https://arxiv.org/abs/1511.06581)- [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952)- [Noisy Network](https://arxiv.org/abs/1706.10295)- [C51](https://arxiv.org/abs/1707.06887)- [Rainbow](https://arxiv.org/abs/1710.02298)- [QR-DQN](https://arxiv.org/abs/1710.10044)- [IQR](https://arxiv.org/abs/1806.06923)- [FQF](https://arxiv.org/abs/1911.02140)- [DDPG](https://arxiv.org/abs/1509.02971)- [SAC](https://arxiv.org/abs/1801.01290)- [TD3](https://arxiv.org/abs/1802.09477)- [MDQN](https://arxiv.org/abs/2007.14430)\n What is amazing is its speed and memory efficiency after some optimization:\n With a single 2080Ti GPU and a 8 core AMD CPU, the training speed of rainbow for Atari could achieve 3000FPS, which means it can finish training of 10M frames within 1 hour. With compression of image frames, replay memory's RAM usage is down by 20%.\n I have tested several algorithms and games on Atari and get some initial result. Welcome to use and contribute!\n    submitted by    /u/zhoubin-me  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tuwhbp/agentzero_ray_pytorch_based_lightweight/",
          "publishedOn": "2022-04-02T23:35:17.000Z",
          "wordCount": 402,
          "title": "AgentZero: Ray & PyTorch based light-weight Distributed Fast Reinforcement Learning Framework",
          "imageUrl": "https://external-preview.redd.it/rphMmrOxdz-k8Ls0gskVFmjxfTT1RF2a1aqcyU-tVsI.jpg?auto=webp&s=6e71280b62d4d5793c50b37afe494c634c3dd927"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tuv1t5/regularization_for_drl_reward_or_objective/",
          "author": null,
          "description": "I am searching for regularization methods applied to DRL algorithms (either value or policy-based) to understand what has been done so far in the field. I cannot find any valid reference that studies the effect of applying a soft constraint to the reward function instead of to the policy objective. This may seem useless for some applications, but it is highly relevant for finance, which is my domain of application,\n The idea I have so far is that if you constrain the reward, it is like you are imposing limits on the agent's behavior. On the other hand, if you constrain the objective, you are not limiting the behavior, but you are correcting the ex-post the undesired behavior. The latter way does not allow the agent to learn not to behave in a certain way.\n ​\n Did anyone ever think about it? Are they good references that analyze the different effects of a constraint to whatever DRL algorithm?\n    submitted by    /u/alebrini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tuv1t5/regularization_for_drl_reward_or_objective/",
          "publishedOn": "2022-04-02T22:27:26.000Z",
          "wordCount": 297,
          "title": "Regularization for DRL: reward or objective function?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/turvmf/what_does_it_mean_to_feed_the_network_state_in_an/",
          "author": null,
          "description": "I am looking at this code from Google (https://github.com/google-research/google-research/blob/master/social_rl/multiagent_tfagents/joint_attention/attention_networks.py). \n At line 639, the LSTM is called. The first two inputs are the state and the network state, but I don't understand what the latter is.\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/turvmf/what_does_it_mean_to_feed_the_network_state_in_an/",
          "publishedOn": "2022-04-02T20:05:26.000Z",
          "wordCount": 314,
          "title": "What does it mean to feed the \"network state\" in an LSTM in the actor network?",
          "imageUrl": "https://external-preview.redd.it/CMhpMLhb6T0d4kqxMnDmxlqLqBIUASjloDaZLDY4pDk.jpg?auto=webp&s=411a8f7f0fc00a11f3af1004038b99d54177481c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tukbpx/deeprl_and_rubiks_cube/",
          "author": null,
          "description": "I'm part of a group of researchers from top ML institutions and industry, our goal is to figure out how improve efficiency in DeepRL.\n We are looking at Rubik’s Cube as target problem, and kicking off a project which will start from https://github.com/forestagostinelli/DeepCubeA and go from there.\n Prior works require hand crafted curriculum and billion of interactions to solve a cube, we believe that order of magnitude more compute that it should take.\n Is anyone interested to collaborate? I'm happy to dedicate a few hours a week to help a newcomer like I was a few years ago with the RL stuff given some basics of machine learning and programming skills, and this could be the golden opportunity for someone to see RL at scale.\n    submitted by    /u/mind_library  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tukbpx/deeprl_and_rubiks_cube/",
          "publishedOn": "2022-04-02T14:38:04.000Z",
          "wordCount": 528,
          "title": "DeepRL and Rubik’s Cube",
          "imageUrl": "https://external-preview.redd.it/vY5AZeHYgdqG0QCmZ_yxSBdi2a5KSVfQqQEVHBoyAc8.jpg?auto=webp&s=53fd91a99190c8c98634245be5a6b46ddd731ffb"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tujiup/multi_agent_reinforcement_learning/",
          "author": null,
          "description": "I'm absolutely new to machine learning, let alone reinforcement learning. I've been tasked to replicate and if possible improve upon the paper linked in the post. I don't know what platform to use and how to create the custom environment. if anybody could share any resources it would be tremendously helpful.\n https://drive.google.com/file/d/1fIT43hKi61WUIvoTh2a3AWlRsphi-L98/view?usp=sharing\n    submitted by    /u/Lazarus_07  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tujiup/multi_agent_reinforcement_learning/",
          "publishedOn": "2022-04-02T14:00:39.000Z",
          "wordCount": 443,
          "title": "Multi agent reinforcement learning",
          "imageUrl": "https://external-preview.redd.it/nA1vBVIvczC8HAsR2ahVxtV-Pril_KFs64Y7NW9J4j0.jpg?auto=webp&s=2fadec1181f76b169acf9693211bc4464bd9156d"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tu85b5/qlearning_vs_policy_gradient/",
          "author": null,
          "description": "Trying to wrap my head around the RL essentials. Would it be correct to say that Q-learning attempts to select the best available policy by optimizing the Q-function, while policy gradient methods work directly to optimize a pre-determined policy's parameters?\n    submitted by    /u/JimBeanery  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tu85b5/qlearning_vs_policy_gradient/",
          "publishedOn": "2022-04-02T02:24:42.000Z",
          "wordCount": 181,
          "title": "q-learning vs. policy gradient",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tu7499/how_to_use_a_deep_model_for_drl/",
          "author": null,
          "description": "I noticed most DRL papers use very shallow models like three or four layers. However, when I try to do DRL tasks that have relatively complicated scenes (for example, some modern video game), shallow models become way too weak.\n Are there papers, blogs, articles etc. that use more complex/deep models? Or maybe some methods that can deal with complicated scenes without deep models?\n Thanks\n    submitted by    /u/seermer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tu7499/how_to_use_a_deep_model_for_drl/",
          "publishedOn": "2022-04-02T01:31:43.000Z",
          "wordCount": 409,
          "title": "How to use a deep model for DRL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tu68ex/any_thought_on_a_universal_parameter_optimizer/",
          "author": null,
          "description": "Hi all, I have an thought on A universal parameter optimizer I wanted to share with you and to see if you know some related work. \n Assume you have a simulation or access to an environment. There are certain parameters you can set to control the performance of a system which lives in this simulation/environment. Naturally, one wants to find the optimal parameters or optimal policy to set the parameter that can result the most reward, however that is defined. \n For example, in the stock market, I may want to find the optimal market price to buy and sell, or the optimal policy. In a car driving game, I may want to determine the optimal policy to set speed and direction. \n Do we know if there is formal way to study this type of problem? Thank you!\n    submitted by    /u/DB8868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tu68ex/any_thought_on_a_universal_parameter_optimizer/",
          "publishedOn": "2022-04-02T00:45:21.000Z",
          "wordCount": 257,
          "title": "Any thought on: A universal parameter optimizer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tu3qbd/d_current_algorithms_consistently_outperforming/",
          "author": null,
          "description": "Hi community. It has been 5 years now since these algorithms were released, and I don't feel like they have been quite replaced yet. In your opinion, do we currently have algorithms that make either of them obsolete in 2022?\n    submitted by    /u/yannbouteiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tu3qbd/d_current_algorithms_consistently_outperforming/",
          "publishedOn": "2022-04-01T22:42:46.000Z",
          "wordCount": 200,
          "title": "[D] Current algorithms consistently outperforming SAC and PPO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttujzz/need_help_with_project_idea/",
          "author": null,
          "description": "Hey guys! So I am enrolled in a reinforcement learning course at my university, and I am really confused about a decent project idea. Primarily, I want to work on any game based environment apart from atari ones. Using unity seems promising but not sure if that is easy to pull off. Any suggestions to get me started? Thanks\n    submitted by    /u/ishon_p  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttujzz/need_help_with_project_idea/",
          "publishedOn": "2022-04-01T16:13:30.000Z",
          "wordCount": 212,
          "title": "Need Help with Project Idea",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttu50r/d_completely_removing_the_option_taking_illegal/",
          "author": null,
          "description": "Hi, \n I have a two step custom gym env which is a graph network optimisation task (two steps due to high dimension action space). In the first step the agent chooses the first node and state reward passed to training. in the second step, the agent chooses the second node, and with a class attribute holding the history of the first selected node, now has a node pair which it is then able to remove or add and edge. The training loop now has a new graph state (edges changed between nodes) plus a vector of the first action selected. \n The agent is able to learn well however, even with a negative reward provided to the agent if it takes illegal actions (choosing the same node in each step and thus creating a self connection), even when it learns to maximise reward, it still take illegal actions…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttu50r/d_completely_removing_the_option_taking_illegal/",
          "publishedOn": "2022-04-01T15:56:42.000Z",
          "wordCount": 509,
          "title": "[D] Completely removing the option taking illegal actions in custom gym environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tttw8h/training_drone_via_drl_to_hover_with_just_camera/",
          "author": null,
          "description": "Hi Everyone \n This is my first time trying reinforcement learning and Unity and wanted some help. \n I am trying to train a quadcopter to hover and keep a stationary ball in its camera frame using just visual inputs by a camera sensor. So the input to the network would be an 84*84 grayscale image and the output would be the four forces to the rotor.\n My reward function is \n ​\n Reward Function\n where x and y is the position of the drone and a is the rotation of the drone with respect to the target. I have set A, d and c to 3 and lambda as 1/180. I have also added a condition where if the quadcopter drops below a certain height from the platform, it punishes it by a reward of -1 and resets the episode.\n The network I am using is the ppop network used by the coin-collector example in mlagents. \n My training log is below: \n Training log\n The cumulative reward and episode length just drops after a while and the value loss explodes. I think something maybe wrong with my rewards or network. \n If anyone has any ideas what might be going wrong and tell me, that would be great. \n Thanks\n    submitted by    /u/voyager10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tttw8h/training_drone_via_drl_to_hover_with_just_camera/",
          "publishedOn": "2022-04-01T15:46:38.000Z",
          "wordCount": 325,
          "title": "Training drone via DRL to hover with just camera sensor",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tttecp/do_you_know_any_port_of_stablebaselines_3_to_c/",
          "author": null,
          "description": "Has anybody done it already?\n    submitted by    /u/Live_Medium_3949  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tttecp/do_you_know_any_port_of_stablebaselines_3_to_c/",
          "publishedOn": "2022-04-01T15:25:35.000Z",
          "wordCount": 137,
          "title": "Do you know any port of StableBaselines 3 to C++?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttorpr/is_there_a_way_to_get_ppo_controlled_agents_to/",
          "author": null,
          "description": "submitted by    /u/user_00000000000001  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttorpr/is_there_a_way_to_get_ppo_controlled_agents_to/",
          "publishedOn": "2022-04-01T11:49:18.000Z",
          "wordCount": 671,
          "title": "Is there a way to get PPO controlled agents to move a little more gracefully?",
          "imageUrl": "https://external-preview.redd.it/h_sOeh2-6QCTGSEiVV4OoS06tHh7owhf4x2rq8VrHPg.png?format=pjpg&auto=webp&s=38b9d61cd74dfb14f0c9de38121675d6022aeca5"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttntyx/how_to_make_two_policies_in_trpo_ppo_algorithms/",
          "author": null,
          "description": "In both TRPO and PPO, we have r which is ration of new_policy/old_policy. Here we collect data from old_policy and improve new policy. I am confused on how to implement this. Correct me If I am wrong but I have two ways in mind.\n 1) I collect prob while running simulation. When optimizing, I use same neural network to sample another action and its prob, this new and its probability becomes my new_policy and then I optimize for L_clip function. \n 2) I collect prob while running simulation. Before optimizing the ppo objective, I first run a simple policy gradient by using the original prob I collected. After updating the NN, I once more get new_prob which I use in L_clip function.\n Can someone please tell me which should I do and why?\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttntyx/how_to_make_two_policies_in_trpo_ppo_algorithms/",
          "publishedOn": "2022-04-01T10:53:47.000Z",
          "wordCount": 352,
          "title": "How to make two policies in TRPO, PPO algorithms?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttn09z/intrinsic_curiosity_module_pytorch_multithreading/",
          "author": null,
          "description": "Hello\n I am working on an extension of this implementation https://github.com/philtabor/Youtube-Code-Repository/tree/master/ReinforcementLearning/ICM of the intrinsic curiosity module. It uses A3C(Actor -critic) as a policy and the ICM is a bolt on module.\n I need to fix the seeds for reproducibility but no matter what i have tried I cannot achieve it.\n The implementation uses multithreading on cpu and plays on the oepnai gym cartpole or atari environments.\n I believe that it has something to do with multithreading but im not sure.\n Could someone know what is the solution?\n    submitted by    /u/Formal-Drawing-8421  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttn09z/intrinsic_curiosity_module_pytorch_multithreading/",
          "publishedOn": "2022-04-01T09:56:55.000Z",
          "wordCount": 379,
          "title": "Intrinsic Curiosity Module Pytorch multithreading cpu unable to fix seeds",
          "imageUrl": "https://external-preview.redd.it/SYc06SjJnWJ0Fhmce3m7Rf2njUdkn8xbCXLrqHEAm5g.jpg?auto=webp&s=fc1e9beeb9b3012f760f91047b804d0c58f555ad"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttkpf9/is_replay_buffer_can_remove_done/",
          "author": null,
          "description": "Hi, These days, there are lots of implementation without next state and done for memory like drq-v2 official implementation. But, I have a question about is it okay to throw out \"done\" in replay buffer. In my point of view, there are some problems about done related signal. or did I read implementation code wrong?\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttkpf9/is_replay_buffer_can_remove_done/",
          "publishedOn": "2022-04-01T07:07:21.000Z",
          "wordCount": 260,
          "title": "Is replay buffer can remove \"done\"?",
          "imageUrl": "https://external-preview.redd.it/4IdpVlpDTlQHNocMfJdmvdX02LnEB5rQtaNwb5y62V4.jpg?auto=webp&s=926d3c300953ddaa24dd9dce77a38eb24f4e1323"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttjeqq/do_policy_gradient_methods_also_require_some/",
          "author": null,
          "description": "Algorithms like A2C, A3C, TRPO and PPO use a stochastic policy, i.e. the actions are sampled from a probability distribution so the exploration should be done inherently by these algorithms. Yet, when I am using PPO to train a bipedalwalker, it seems like some exploration mechanism is required because during the training process reward first go up and then after 1K episodes there is no progress. Please suggest me what can I do stop this from happening.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttjeqq/do_policy_gradient_methods_also_require_some/",
          "publishedOn": "2022-04-01T05:41:10.000Z",
          "wordCount": 543,
          "title": "Do policy gradient methods also require some mechanism for exploration?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tt9anv/policy_gradients_with_pytorch/",
          "author": null,
          "description": "what will the shape of the tensor \"probs\" (marked) look like ? \n will it look like this - \n [ 0.32,0.40,0.28] ?\n ​\n or like this ?\n [ [ 0.32,0.40,0.28],\n [ 0.32,0.40,0.28],\n [ 0.32,0.40,0.28],\n [ 0.32,0.40,0.28] ] \n https://preview.redd.it/3qiq3lzz6sq81.png?width=829&format=png&auto=webp&s=c15ece0e38b9dabf3f443466b2553e146845e92a\n    submitted by    /u/Whole_Run_4485  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tt9anv/policy_gradients_with_pytorch/",
          "publishedOn": "2022-03-31T20:45:17.000Z",
          "wordCount": 192,
          "title": "Policy Gradients with pytorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tt7ns1/what_are_the_main_roads_to_agi/",
          "author": null,
          "description": "I was wondering if you can help me come up with a list fo all the specific proposals on how to achieve AGI. For example, one of them is: scaling is all you need. In more detail, scaling self-supervised pretrained deep network models (a.k.a. foundation models), data and compute can lead to AGI (scaling assumes \"smart\" one, i.e. as steep as possible/cost-efficient exponents in neural scaling laws). Do you know what other main roads there are to AGI?\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tt7ns1/what_are_the_main_roads_to_agi/",
          "publishedOn": "2022-03-31T19:31:29.000Z",
          "wordCount": 201,
          "title": "What are the main roads to AGI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tt291u/sparse_reward_environments_and_off_policy/",
          "author": null,
          "description": "In my experience, (continuous action space) off Policy algorithms are generally more sample efficient than on policy algorithms but don't perform as well on sparse rewards environments. Are there any papers that address this issue? Do you know of any algorithms that are both sample efficient and learn sparse reward Environments well?\n    submitted by    /u/SirRantcelot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tt291u/sparse_reward_environments_and_off_policy/",
          "publishedOn": "2022-03-31T15:26:40.000Z",
          "wordCount": 179,
          "title": "Sparse Reward Environments and Off Policy Algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tt19mu/how_to_deal_with_delayed_dense_rewards/",
          "author": null,
          "description": "I'm having a doubt that may be a little stupid, but I ask to be sure.\n Assume that in my environment rewards are delayed by a random number n of steps, i.e. the agent takes an action but receives the reward n steps after taking that action. At every step a reward is produced, therefore the reward r_t in transitions s_t, a_t, r_t, s_{t+1} collected by the agent is actually the reward corresponding to the transition at time t-n. \n An example scenario: the RL agent control a transportation network, and a reward is generated only when a package reach its destination. Thus, the reward arrives with possibly several steps of delay with respect to when the relevant actions were taken. \n Now, I know that delayed rewards are not generally an issue, e.g. all those settings in which there is only one reward +1 at the end, but I am wondering if this case is equivalent. What makes me wonder is that here, for a state s_t onwards to state s_{t+n}, there are n rewards in the middle that depend on states previous to s_t. \n Does this make the problem non-markovian? How can one learn the value function V(s_t) if its estimation is always affected by unrelated rewards r_{t-n} ... r_{t-1}?\n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tt19mu/how_to_deal_with_delayed_dense_rewards/",
          "publishedOn": "2022-03-31T14:41:43.000Z",
          "wordCount": 738,
          "title": "How to deal with delayed, dense rewards",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tt0jua/sim2real/",
          "author": null,
          "description": "Hi! Does anyone know the “right” way to apply a policy to a robotic manipulator? Now I’m trying creating a real environment and simulate the policy on it but I can’t find anything on the web about this. Thanks!\n    submitted by    /u/Big-Picture8323  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tt0jua/sim2real/",
          "publishedOn": "2022-03-31T14:07:10.000Z",
          "wordCount": 326,
          "title": "Sim2Real",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tsw7rb/pass_a_seed_arg_in_gyms_reset_method_to_play_the/",
          "author": null,
          "description": "I asked a while back how to save state of an episode when this was my original intention. \n even a quick perusal of an environment's code reveals interesting information that's helpful to using gym as a whole\n https://www.github.com/openai/gym/tree/master/gym/envs\n I think it'd be interesting if papers supplied seed numbers for their test andntraining runs, where they're pulled from an array of ints contained in the agent.\n    submitted by    /u/clockface99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tsw7rb/pass_a_seed_arg_in_gyms_reset_method_to_play_the/",
          "publishedOn": "2022-03-31T09:47:38.000Z",
          "wordCount": 265,
          "title": "Pass a seed arg in gyms reset method to play the same game - undocumented feature!",
          "imageUrl": "https://external-preview.redd.it/Nh26Zt33g9Wi2IFRjkAqR7_jDvUNtDK7011BDEcnu8g.jpg?auto=webp&s=14b77bf03ed29b7631ee6bb0526d0ba8c32ab79f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tsv55f/r_reinforcement_learning_in_finance_project/",
          "author": null,
          "description": "Hello, I hope that this message finds you in good health\n FinRL: Deep Reinforcement Learning for Quantitative Finance https://github.com/AI4Finance-Foundation/FinRL is a project from Columbia University. It offers environments for cryptocurrency, paper trading, stock trading, and forex trading. Also, it has support for three reinforcement learning libraries: Stable Baselines3, RLlib, and ElegantRL. This is from AI4Finance-foundation and it aims to provide a plug-play platform for RL in finance. Do check it out and help us to improve this project\n Some resources:\n  \nMy contributions: https://medium.com/@athekunal/list/finrl-contributions-59de6997c5b1\n Resources to learn FinRL: https://github.com/AI4Finance-Foundation/FinRL#tutorials\n All tutorial notebooks: https://github.com/AI4Finance-Foundation/FinRL/tree/master/tutorials\n YouTube Channel: https://www.youtube.com/channel/UCrVri6k3KPBa3NhapVV4K5g\n  \n   submitted by    /u/A_the_kunal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tsv55f/r_reinforcement_learning_in_finance_project/",
          "publishedOn": "2022-03-31T08:25:13.000Z",
          "wordCount": 295,
          "title": "[R] Reinforcement learning in Finance project",
          "imageUrl": "https://external-preview.redd.it/26WP_8wiR4eM6G0YebGmMkj2k6iO24IWXjkX2zAG8Eg.jpg?auto=webp&s=febf91202e8cc5f45f9bc0a588436e70101652d3"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tsf5gf/why_isnt_epsilon_reset_regularly_in_epsilon/",
          "author": null,
          "description": "surely this improves exploration? e.g. I took a default dqn and after 200k frames mountain car env didn't get to the top but after modifying training to reset epsilon to eps max every 3k steps (with a 1000 frame decay rate from 1 to 0.1) helped increase the score during training and got -133.\n after testing a bit I found it helps training if you modify how many N steps you reset epsilon as you train, e.g. I start on 3k for 100k frames and then 10k for 100k frames and then no resetting.\n I can't be the first and I understand there are much more mathematically stronger exploration techniques but is this a poorman's exploration technique?\n    submitted by    /u/clockface99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tsf5gf/why_isnt_epsilon_reset_regularly_in_epsilon/",
          "publishedOn": "2022-03-30T19:31:09.000Z",
          "wordCount": 493,
          "title": "Why isn't epsilon reset regularly in epsilon greedy policies to aid exploration?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ts4ct0/cooperative_multiagent_with_a_global_reward/",
          "author": null,
          "description": "In my environment, I have multiple agents that need to cooperate. The reward function is global, such that it depends on the overall state of the system, and not just the sum of each agent reward. Could you point me to some relevant literature in this field?\n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ts4ct0/cooperative_multiagent_with_a_global_reward/",
          "publishedOn": "2022-03-30T11:32:33.000Z",
          "wordCount": 201,
          "title": "Cooperative multi-agent with a global reward function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ts3pud/11_best_python_books_for_beginners_to_advanced_to/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ts3pud/11_best_python_books_for_beginners_to_advanced_to/",
          "publishedOn": "2022-03-30T10:52:58.000Z",
          "wordCount": 147,
          "title": "11 Best Python Books for beginners to advanced to read in 2022 -",
          "imageUrl": "https://external-preview.redd.it/3pdSs8qDH1dxGz1jom5eFGa2iAZiKGkP654eztme7y0.jpg?auto=webp&s=ac621ceb3cbbdfba20cd59821ecd81a25a9d798f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/trv703/what_is_tau_in_the_dynaq_algorithm/",
          "author": null,
          "description": "https://imgur.com/UOdDUFH\n From the linked image I am wondering what tau is (the tau looks like a small r in the image unless you zoom in)? Is it a hard coded value like kappa (k)? If not how is the value for tau determined when Dyna Q+ runs?\n    submitted by    /u/lifelifebalance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/trv703/what_is_tau_in_the_dynaq_algorithm/",
          "publishedOn": "2022-03-30T01:36:51.000Z",
          "wordCount": 392,
          "title": "What is tau in the Dyna-Q+ algorithm?",
          "imageUrl": "https://external-preview.redd.it/HdajETvCDYrX_423ty9BsHE7vR6Cm34Zl1JmZduRSc8.jpg?auto=webp&s=5c73ec396915ec4009bf051b5c642d3cc9d40b55"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/truggg/worthwhile_to_convert_custom_env_to_be_dm_env/",
          "author": null,
          "description": "Can anyone speak to their experience using acme (https://github.com/deepmind/acme) and by extension dm_env (https://github.com/deepmind/dm_env)? I'm wondering if it would be worthwhile for me to invest the time into converting my custom environment (which loosely follows the standard RL setup) over to this format.\n I quite like how acme does a lot of heavy lifting in the background and lays out their thoughts on best practices, but perhaps I'm being shortsighted by all the bells and whistles\n    submitted by    /u/whynotmehmm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/truggg/worthwhile_to_convert_custom_env_to_be_dm_env/",
          "publishedOn": "2022-03-30T00:55:48.000Z",
          "wordCount": 204,
          "title": "Worthwhile to convert custom env to be dm_env compatible?",
          "imageUrl": "https://external-preview.redd.it/T4e8rfdsL0OjHAkzcdS0-W7Kn4D6VfNiJ3b4AnQZPoc.jpg?auto=webp&s=f67f879d54089322b68fbde4fcf776a380d707ec"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tqyyk3/artificial_intelligence_beats_8_world_champions/",
          "author": null,
          "description": "submitted by    /u/kevinwangg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tqyyk3/artificial_intelligence_beats_8_world_champions/",
          "publishedOn": "2022-03-29T12:46:18.000Z",
          "wordCount": 333,
          "title": "Artificial Intelligence beats 8 world champions at a version of Bridge",
          "imageUrl": "https://external-preview.redd.it/WpwXEa7gVOYU6ZgHWiq4aq0r36J-t9FFX1f3bjs0BPs.jpg?auto=webp&s=19a295e3dfbc0682998ddf39a683bb5775f5a64c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tqvy8c/sac_and_position_control_in_mujoco/",
          "author": null,
          "description": "Hi! I'm currently using garage to simulate a robot EE controlled in position. Does anyone know how to make a relative action? I mean, I would like to have a small action space reinitialized at each step in order to have only small increases in position. Thanks!\n    submitted by    /u/Big-Picture8323  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tqvy8c/sac_and_position_control_in_mujoco/",
          "publishedOn": "2022-03-29T09:31:33.000Z",
          "wordCount": 178,
          "title": "SAC and Position Control in Mujoco",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tquve2/backpropogation_in_ppo_and_gymai/",
          "author": null,
          "description": "I am currently build a PPO agent for OpenAI gym's Pong environment using Pytorch and I had a question:\n So typically the workflow is:\n  \nUse the state as the input for a CNN and output the action probabilities\n Sample the action distribution for an action and perform env.step(action) with it\n Obtain there rewards and calculate some reward / loss function such as log probs*rewards\n Backpropogate this loss/reward using reward/loss.backward() and optimizer.step()\n  \nNow, Pytorch's loss.backward() and optimizer.step() only calculates and updates gradients for pyTorch Variable objects where requires_grad=True.\n So how does Pytorch backpropogate through env.step() ? env.step() outputs numpy arrays (if you're using a parallel environment) or integers (not tensors)...\n Secondly, if I try to convert a Tensor output to a numpy array to input to env.step() - say an array of actions for parallel environments, it breaks my backpropogation right?\n Thirdly, does that mean that env.step() is a differentiable function?\n Thanks in advance!\n    submitted by    /u/Ska82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tquve2/backpropogation_in_ppo_and_gymai/",
          "publishedOn": "2022-03-29T08:09:08.000Z",
          "wordCount": 260,
          "title": "Backpropogation in PPO and gym.ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tqthpf/policy_gradients_with_pytorch/",
          "author": null,
          "description": "Can someone please explain what \"pw\" is on the third image(marked with arrow) ? \n P.S: First two images are for context\n Thank you!\n ​\n https://preview.redd.it/v9ogmrxvn9q81.png?width=753&format=png&auto=webp&s=4ecfc49aabbf328ecccf468ee01aa3767a7a4c8a\n https://preview.redd.it/4mrnjsxvn9q81.png?width=753&format=png&auto=webp&s=42be60ebaed04468d1b10928ba729327a0057b0f\n https://preview.redd.it/o01n5sxvn9q81.png?width=753&format=png&auto=webp&s=112e876c252e075829c1693cf0f6a5d4751cf79a\n    submitted by    /u/Whole_Run_4485  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tqthpf/policy_gradients_with_pytorch/",
          "publishedOn": "2022-03-29T06:27:54.000Z",
          "wordCount": 141,
          "title": "Policy Gradients with Pytorch.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tqiwz0/basic_neural_network_robots_learning_by_genetic/",
          "author": null,
          "description": "submitted by    /u/djrobsmith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tqiwz0/basic_neural_network_robots_learning_by_genetic/",
          "publishedOn": "2022-03-28T20:45:14.000Z",
          "wordCount": 165,
          "title": "Basic neural network robots learning by genetic algorithms - survival of the fittest! Crazy simulations - source code included",
          "imageUrl": "https://external-preview.redd.it/rpsGCwLy6-FXq43A4DqVxDmXuj_dd0ApnJcZ5u3pijc.jpg?auto=webp&s=ae5232cd6bfac84b12e83356dd0f2c17db2c1e03"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tqb5xs/decision_transformers_in_transformers_library_and/",
          "author": null,
          "description": "Hey there 👋🏻,\n We’re happy to announce that Edward Beeching from Hugging Face has integrated Decision Transformers an Offline Reinforcement Learning method, into the 🤗 transformers library and the Hugging Face Hub.\n In addition, we share nine pre-trained model checkpoints for continuous control tasks in the Gym environment.\n If you want to know more about Decision Transformers and how to start using it, we wrote a tutorial 👉 https://huggingface.co/blog/decision-transformers\n We would love to hear your feedback about it,\n In the coming weeks and months, we will be extending the reinforcement learning ecosystem by:\n  \nBeing able to train your own Decision Transformers from scratch.\n Integrating RL-baselines3-zoo\n Uploading RL-trained-agents models into the Hub: a big collection of pre-trained Reinforcement Learning agents using stable-baselines3\n Integrating other Deep Reinforcement Learning libraries\n Implementing Convolutional Decision Transformers for Atari\n  \nAnd more to come 🥳, so 📢 The best way to keep in touch is to join our discord server to exchange with us and with the community.\n Thanks,\n    submitted by    /u/cranthir_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tqb5xs/decision_transformers_in_transformers_library_and/",
          "publishedOn": "2022-03-28T14:57:14.000Z",
          "wordCount": 306,
          "title": "Decision Transformers in Transformers library and in Hugging Face Hub 🤗",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tq5zyo/discount_factor_agents_is_available_at_different/",
          "author": null,
          "description": "Assume that the time between two agent actions is not fixed, i.e. depending on the state-action, the agent can become unavailable for a time t = t(s, a). During the time the agent is unavailable, several rewards are produced by the environment, and they need to be given to the agent whenever it becomes available again. \n One easy way to deal with this is to just store them and set the reward at the next available state as the sum of the accumulated rewards. But in the discounted reward framework with temporal difference (e.g. DQN) this does not discount rewards properly. How can I set the reward for the next state such that it contains all the accumulated rewards but it is correct in the DQN setting?\n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tq5zyo/discount_factor_agents_is_available_at_different/",
          "publishedOn": "2022-03-28T10:10:00.000Z",
          "wordCount": 508,
          "title": "Discount factor Agents is available at different rates",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tq5p87/current_stateoftheart_rl_algorithms/",
          "author": null,
          "description": "What are the current best algorithms in Reinforcement Learning? It seems everyone still uses TD3, SAC, PPO, Rainbow DQN, etc. However, these are mostly from 2018, which is old for RL standards. What happened afterwards? What is the current algorithm for these kinds of standard tasks? I'm especially interested in algorithms that can handle continuous action spaces. Thank you very much!\n    submitted by    /u/Paraiso93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tq5p87/current_stateoftheart_rl_algorithms/",
          "publishedOn": "2022-03-28T09:48:53.000Z",
          "wordCount": 553,
          "title": "Current State-of-the-art RL algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tq1667/noob_question_about_bellmans_optimality_principle/",
          "author": null,
          "description": "i'm reading the Sutton-Barto and at page 63 it is written then v_star(s)=max_a q_star(a,s), my question is why we have this? where does it come from? i'm trying to start from the definition of v_star and q_star but I can't really find a way\n    submitted by    /u/samas69420  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tq1667/noob_question_about_bellmans_optimality_principle/",
          "publishedOn": "2022-03-28T04:27:02.000Z",
          "wordCount": 686,
          "title": "noob question about Bellman's optimality principle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tppn35/the_first_opensource_project_for_financial/",
          "author": null,
          "description": "submitted by    /u/zicxor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tppn35/the_first_opensource_project_for_financial/",
          "publishedOn": "2022-03-27T18:14:30.000Z",
          "wordCount": 318,
          "title": "The first open-source project for financial reinforcement learning",
          "imageUrl": "https://external-preview.redd.it/45ug6EyVRY8Kgg9V2nIc0xZjs53gFpCOk_zMmkLtRaI.jpg?auto=webp&s=b4b061b8dbc2381f12bac25500212ef1c5c724a1"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tppcom/using_rl_to_play_jump_king/",
          "author": null,
          "description": "I am learning RL by having the algorithm play Jump King and am streaming it on twitch, having the chat play against it as well to see who can get the babe first. Check it out at: https://www.twitch.tv/unassignedseat\n    submitted by    /u/UnassginedSeat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tppcom/using_rl_to_play_jump_king/",
          "publishedOn": "2022-03-27T18:00:56.000Z",
          "wordCount": 158,
          "title": "Using RL to play Jump King",
          "imageUrl": "https://external-preview.redd.it/Ker4NHx7mbudKGfPH_8Rz-o5_jtoReGuUY9WG-gHpc4.jpg?auto=webp&s=f911c7fe42085657e28924bf10f017cfaef8df15"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tpoy7s/questiondrl_are_intermediate_activations_used/",
          "author": null,
          "description": "Hello all,\n I have a question regarding optimizing a policy represented by a neural network. In Supervised Learning, the intermediate activations created during the forward pass are needed during backpropagation in order to compute weight gradients. This has led to a number of memory management techniques such as offloading and checkpointing being created.\n My question is whether the same is true in DRL. For policy-gradient methods for example, learning starts from an objective computed from the trajectory such as the discounted returns, but are the intermediate activations created during action inference needed when optimizing the policy (i.e. learning)? \n Is there any academic source that covers this topic? \n Thanks!\n    submitted by    /u/PSylvan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tpoy7s/questiondrl_are_intermediate_activations_used/",
          "publishedOn": "2022-03-27T17:41:08.000Z",
          "wordCount": 295,
          "title": "[Question][DRL] Are intermediate activations used during training?",
          "imageUrl": "https://external-preview.redd.it/o-Yq16CmbZYLfCx_y5VsD5fcOiaoLcN-zQO1j3qX2es.jpg?auto=webp&s=546795834d06ed5ac69b13898f1acf1fe4d9f163"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tpj7eq/raveforce_in_2022_the_openai_gym_style_toolkit/",
          "author": null,
          "description": "submitted by    /u/chaosprint  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tpj7eq/raveforce_in_2022_the_openai_gym_style_toolkit/",
          "publishedOn": "2022-03-27T12:46:28.000Z",
          "wordCount": 148,
          "title": "RaveForce in 2022: The OpenAI Gym style toolkit for music generation experiments just got better",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tpgi0k/is_my_problem_suited_for_solving_via/",
          "author": null,
          "description": "My goal is to determine the best course of actions to take given a certain state. \n I'm working in some state space X. For every x in X, I can assign it a value. When I perform an action a given x, I map x to some new state x'. The state x' depends on my action up to some noise produced by the environment. \n I think this is a reinforcement learning problem. What methods are suitable in this context?\n    submitted by    /u/heylanguage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tpgi0k/is_my_problem_suited_for_solving_via/",
          "publishedOn": "2022-03-27T09:34:22.000Z",
          "wordCount": 341,
          "title": "Is my problem suited for solving via reinforcement learning methods? What approach should I start with?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tpbg8h/deck_generation_using_reinforcement_learning/",
          "author": null,
          "description": "A brief overview of the game: A deck of 50 objects are chosen from a set of ~1000 objects. The game is then played out deterministically, and rewards are dished out based on win/loss. \n I would like to build a nn that can produce good decks , trained using self-play. However, I'm not too sure how to approach this problem. Relevant research or pointers would be very helpful. Thanks.\n    submitted by    /u/nutpeabutter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tpbg8h/deck_generation_using_reinforcement_learning/",
          "publishedOn": "2022-03-27T03:24:31.000Z",
          "wordCount": 318,
          "title": "Deck generation using reinforcement learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tp0szc/some_confusions_about_actorcritic_a2c/",
          "author": null,
          "description": "In sutton's book, Actor-Critic firstly uses an approximated value function as a baseline, and uses the error to update the policy. In my opinion, the value function is used as a baseline since it assign high value to state with high expected return, and every action in this state have the same baseline. \n Pseudocode in sutton's book\n But I also see a Q-version of AC algorithm, which use Q function as the baseline. In this algorithm, the Q function is used to update the policy, and the TD error is used to update the Q function. How could we get this?\n Q Actor-critic\n Another question is about AC and A2C. Is expected return (G) minus baseline the same as the advantage function in A2C? If so, is that AC with baseline the same as A2C?\n    submitted by    /u/ZavierTi2021  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tp0szc/some_confusions_about_actorcritic_a2c/",
          "publishedOn": "2022-03-26T19:24:15.000Z",
          "wordCount": 248,
          "title": "Some confusions about Actor-Critic, A2C",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tozt3g/is_deep_rl_possible_on_microcontrollers/",
          "author": null,
          "description": "I am thinking of applying the deep rl on small scale robots. I have an Arduino Uno and some servos, so is it possible that deep rl can be applied using Arduino?\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tozt3g/is_deep_rl_possible_on_microcontrollers/",
          "publishedOn": "2022-03-26T18:34:49.000Z",
          "wordCount": 297,
          "title": "Is deep rl possible on microcontrollers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tovpj0/a_possibly_stupid_question_about_deep_qlearning/",
          "author": null,
          "description": "Hi Guys! I am just starting out in RL and I have a possibly stupid question about deep q-learning. Why do all of the code examples train the model on its own discounted prediction plus the reward, if they could just record all of the rewards in an episode and then calculate the total discounted rewards from the actual rewards the agent got in the episode? At least in my Implementations, the latter strategy seems to outperform the former, both in regard to the time it took the model to converge and the quality of the learned policy.\n    submitted by    /u/KayJersch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tovpj0/a_possibly_stupid_question_about_deep_qlearning/",
          "publishedOn": "2022-03-26T16:16:26.000Z",
          "wordCount": 680,
          "title": "A possibly stupid question about deep q-learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tole7b/what_exactly_is_the_output_of_openai_gym_atari/",
          "author": null,
          "description": "the docs are light and I understand they're being revamped but I can't find a definition of the outputs for ale. I understand it depends on the specific environment exactly, e.g. for non-atari envs like lunar lander it gives positional data but for the atari games docs state nothing other than its the memory dump.\n do I treat it like an image without the processing being necessary. can I reshape it into a matrix the size of the raw image output, and throw it into a series of convolutional layers? or do I treat it as positional data like the location of all the objects?\n    submitted by    /u/clockface99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tole7b/what_exactly_is_the_output_of_openai_gym_atari/",
          "publishedOn": "2022-03-26T10:04:42.000Z",
          "wordCount": 459,
          "title": "What exactly is the output of openai gym atari vram outputs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tnvqdr/can_i_use_tensorflow_just_for_one_function_inside/",
          "author": null,
          "description": "There is a Tensorflow function that I cannot convert into PyTorch. Can I use that function from tensorflow but still use my entire architecture in PyTorch?\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tnvqdr/can_i_use_tensorflow_just_for_one_function_inside/",
          "publishedOn": "2022-03-25T18:36:14.000Z",
          "wordCount": 370,
          "title": "Can I use TensorFlow just for one function inside my PyTorch model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tnrvw5/how_do_dqn_and_ddqn_learn_to_not_perform_an/",
          "author": null,
          "description": "To clarify, deep q networks and double q networks\n would it ever discover such actions if its always favouring higher goals in the short term? what if another action has to be performed that may give a loss (potentially a significant loss) in the short term but in fact sets a path for a greater reward?\n are there any papers I could look at?\n    submitted by    /u/clockface99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tnrvw5/how_do_dqn_and_ddqn_learn_to_not_perform_an/",
          "publishedOn": "2022-03-25T17:15:43.000Z",
          "wordCount": 823,
          "title": "How do DQN and DDQN learn to not perform an action that gives a small reward for another action in the future that gives a bigger reward",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tnnmng/how_to_apply_deep_rl_in_arcade_learning/",
          "author": null,
          "description": "I am new to RL but have experience on Deep Learning. Would you please guide me in the right direction as to how can I apply Deep Reinforcement Learning in Arcade Learning Environment? I also have basic knowledge of OpenAI gym environment.\n    submitted by    /u/AvailableBike9260  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tnnmng/how_to_apply_deep_rl_in_arcade_learning/",
          "publishedOn": "2022-03-25T14:51:36.000Z",
          "wordCount": 288,
          "title": "How to apply Deep RL in Arcade Learning Environment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tnkp7d/doubts_in_trpos_objective_and_constraint/",
          "author": null,
          "description": "Correct me if I am wrong.\n Mathematically, Linear Approximation L = f(X_0) + ∇f(X_0)(X-X_0) and Quadratic Approximation Q = f(X_0) + ∇f(X_0)(X-X_0) + 0.5 * (X-X_0)^T H_f(X_0) (X-X_0).\n Then in TRPO algorithm, why are we ignoring the constant term f(X_0) for importance sampling term and f(X_0) + ∇f(X_0)(X-X_0) for Quadratic Approximation in KL Term.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tnkp7d/doubts_in_trpos_objective_and_constraint/",
          "publishedOn": "2022-03-25T12:20:18.000Z",
          "wordCount": 183,
          "title": "Doubts in TRPO's objective and constraint approximations.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tnau1d/robot_peels_banana_with_goalconditioned/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tnau1d/robot_peels_banana_with_goalconditioned/",
          "publishedOn": "2022-03-25T01:27:50.000Z",
          "wordCount": 160,
          "title": "\"Robot peels banana with goal-conditioned dual-action deep imitation learning\", Kim et al 2022",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tnaaja/is_there_any_stateoftheart_rl_method_based_on/",
          "author": null,
          "description": "submitted by    /u/Blasphemer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tnaaja/is_there_any_stateoftheart_rl_method_based_on/",
          "publishedOn": "2022-03-25T00:58:44.000Z",
          "wordCount": 163,
          "title": "Is there any state-of-the-art RL method based on REINFORCE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tn76qe/pretraining_a_multiinput_policy_using/",
          "author": null,
          "description": "Hi! \n Newbie here! \n I am attempting to pre-train a custom policy in stable baselines. The policy takes multiple inputs, each with a different shape. \n I tried using this as reference https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/pretraining.ipynb#scrollTo=toKEQE9i8aof but failed miserably. \n Has anyone successfully pretrained a multi input? Would love some guidance.\n Currently each of my observations are stored as a list of lists with different sizes.. For example [ list of size(7), list of size(3)...] where each list is one of the inputs.\n Thank you!\n    submitted by    /u/Alpha-Seirra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tn76qe/pretraining_a_multiinput_policy_using/",
          "publishedOn": "2022-03-24T22:22:17.000Z",
          "wordCount": 193,
          "title": "Pre-training a MultiInput policy using Stablebaselines3",
          "imageUrl": "https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?auto=webp&s=73eb91ea5a5347f216c0f0c4d6796396826aae49"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tn4rrz/algorithm_from_scratch/",
          "author": null,
          "description": "Does it pay off to make an algorithm from scratch if there are libs like ray?\n I implemented an own distributed algorithm. Anyway i wounder if it has any worth because there are libs like ray where popular algos are already implemented. It even has hyper parameter tuning. What do you guys think?\n    submitted by    /u/Willing-Classroom735  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tn4rrz/algorithm_from_scratch/",
          "publishedOn": "2022-03-24T21:06:03.000Z",
          "wordCount": 284,
          "title": "Algorithm from scratch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tmkmzp/i_hope_this_is_accurate_enough_for_monte_carlo_to/",
          "author": null,
          "description": "submitted by    /u/FurryMachine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tmkmzp/i_hope_this_is_accurate_enough_for_monte_carlo_to/",
          "publishedOn": "2022-03-24T16:17:14.000Z",
          "wordCount": 140,
          "title": "I hope this is accurate enough for monte Carlo to accept me",
          "imageUrl": "https://preview.redd.it/j08t81jpwcp81.png?auto=webp&s=b9625df9738207cf95c2440d1c4f4e592bfb44a4"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tmibg3/why_is_using_an_estimate_to_update_another/",
          "author": null,
          "description": "submitted by    /u/FurryMachine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tmibg3/why_is_using_an_estimate_to_update_another/",
          "publishedOn": "2022-03-24T15:45:27.000Z",
          "wordCount": 222,
          "title": "Why is using an estimate to update another estimate called Bootstrapping?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tljz0m/crossbeam_learning_to_search_in_bottomup_program/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tljz0m/crossbeam_learning_to_search_in_bottomup_program/",
          "publishedOn": "2022-03-23T23:05:14.000Z",
          "wordCount": 145,
          "title": "\"CrossBeam: Learning to Search in Bottom-Up Program Synthesis\", Shi et al 2022",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tlf2qn/suggestions_for_board_game_reinforcement_learning/",
          "author": null,
          "description": "Hello, long time lurker here. I've applied to a hackathlon where the goal is to implement an AI for a 1v1 turn based game and was hoping to hear some thoughts, suggestions, recommendations.\n The game itself will be simple, likely a turn based board game. The AIs battle each other to win the competition. Last year's competition had a simplified version of Catan.\n I have taken some university courses in the AI field (AI 101, Machine learning, Soft Computing etc.) and am familiar with basic concepts, but I don't know much about RL (I have a general notion on what it's about). I was hoping to learn more about it some day and this competition seems like a perfect opportunity. \n I'm looking to prepare a bit before the competition and started exploring reinforcement learning methods and frameworks. Is there a framework which would be suitable for this? A framework which has an interface for a custom game that I can build?\n Could Q learning be used in environments where there is more than one agent? Are there some methods to learn the best heuristic for the minmax algorithm?\n    submitted by    /u/ludibog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tlf2qn/suggestions_for_board_game_reinforcement_learning/",
          "publishedOn": "2022-03-23T21:08:54.000Z",
          "wordCount": 379,
          "title": "Suggestions for board game reinforcement learning methods, frameworks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tlc1vr/what_kind_of_explainability_techniques_exist_for/",
          "author": null,
          "description": "I am looking for techniques and libraries to interpret/explain the reinforcement learning model.\n    submitted by    /u/Mariam_Dundua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tlc1vr/what_kind_of_explainability_techniques_exist_for/",
          "publishedOn": "2022-03-23T20:11:43.000Z",
          "wordCount": 142,
          "title": "What kind of explainability techniques exist for Reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tl3sv8/where_to_publish_a_short_or_demo_paper/",
          "author": null,
          "description": "I've implemented a slightly novel distributed DRL system, which I'd like to submit to a conference as a short or demo paper. Does anybody know a conference where this is possible? ICML and Neurips do not support short papers. ICLR has a blog post track.\n Concerning a full technical paper, I lack the resources (time, computational resources) to thoroughly benchmark my system against seed, ray, apex, r2d2 and so on...\n    submitted by    /u/LilHairdy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tl3sv8/where_to_publish_a_short_or_demo_paper/",
          "publishedOn": "2022-03-23T17:50:36.000Z",
          "wordCount": 298,
          "title": "Where to publish a short or demo paper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tku6l6/can_anyone_explain_what_is_the_role_of_mm/",
          "author": null,
          "description": "I was reading this post about the TRPO algorithm. But I couldn't understand how we use MM algorithm in TRPO. I also watched some videos, they talked something about maximizing lower bound but I am not able to catch up what they are explaining. Can anyone explain this to me?\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tku6l6/can_anyone_explain_what_is_the_role_of_mm/",
          "publishedOn": "2022-03-23T13:41:20.000Z",
          "wordCount": 276,
          "title": "Can anyone explain what is the role of MM algorithm in TRPO?",
          "imageUrl": "https://external-preview.redd.it/E8D9BE0w1TUpdzuSOFmWmtKyUCR9UwNmGfEsg87wVyg.jpg?auto=webp&s=f75807513fe28a4b357e332e434ddfac6a5a7dfa"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tktwy4/is_dueling_dqn_prerequisite_of_prioritized/",
          "author": null,
          "description": "submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tktwy4/is_dueling_dqn_prerequisite_of_prioritized/",
          "publishedOn": "2022-03-23T13:27:30.000Z",
          "wordCount": 319,
          "title": "Is Dueling DQN prerequisite of Prioritized Experience Replay? or which paper I have to start reading first, I already done DQN and DDQN.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tknadh/weird_vanilla_policy_gradient_behaviour_after/",
          "author": null,
          "description": "Hi,\n I am trying vanilla policy gradient algorithm of gym's bipedal walker. My algorithm was not converging so I added lstm to the network. I expected that somehow the agent will use the memory to converge even faster but after adding it I observed that LSTM is somehow making the agent worse. Below are the graphs of without and with lstm.\n ​\n without lstm\n ​\n with lstm\n ​\n orange-with lstm and yellow-without lstm\n Can anyone explain to me why is this happening?\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tknadh/weird_vanilla_policy_gradient_behaviour_after/",
          "publishedOn": "2022-03-23T05:58:44.000Z",
          "wordCount": 308,
          "title": "Weird vanilla policy gradient behaviour after adding lstm to the network.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tkcmvw/dopamine_helps_signal_to_neurons_when_to_start_a/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tkcmvw/dopamine_helps_signal_to_neurons_when_to_start_a/",
          "publishedOn": "2022-03-22T20:43:47.000Z",
          "wordCount": 135,
          "title": "Dopamine Helps Signal to Neurons When to Start a Movement",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tkbc2a/lstm_encoder_in_the_policy/",
          "author": null,
          "description": "Hi all, I'm trying to code an actor net that consists of an LSTM followed by two fully connected layers. The policy is therefore parameterized using an LSTM. The LSTM is meant to enable agents to remember the history of states in which they have observed other agents, and improve their ability to model other agents’ policies.\n Can someone refer me to PyTorch code for such an architecture?\n Thanks!\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tkbc2a/lstm_encoder_in_the_policy/",
          "publishedOn": "2022-03-22T19:46:03.000Z",
          "wordCount": 184,
          "title": "LSTM encoder in the policy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tk5f00/how_hugging_face_can_contribute_to_the_deep/",
          "author": null,
          "description": "Hey there! 👋\n I'm Thomas Simonini from Hugging Face 🤗. I work on building tools, environments and integrating RL libraries to empower researchers and RL enthusiasts. I was wondering how Hugging Face can be useful to you in the Deep Reinforcement Learning Ecosystem? What do you need as RL researcher/enthusiast/engineer and how we can help you?\n For now:\n  \nWe integrated Stable-baselines3 to the Hub** such that you can: \n Easily host and test your saved models.\n Load powerful, trained models from the community\n \n  \nhttps://preview.redd.it/n0b2s1gndyo81.jpg?width=1920&format=pjpg&auto=webp&s=eb62a1f4323b12a5c1eb9d7bcb44ebbc6bae579f\n  \nWe're currently integrating more libraries (RL-Zoo, CleanRL...)\n We're working on building tools that allow you to generate a replay video of your agent and test it.\n We're building open-source RL environments such as snowball-fight\n And finally, we're working on state of the art's research with Decision Transformers, Embodied environments, etc.\n  \nBut I would love to know what do you need as RL researcher/enthusiast/engineer and how we can help you?\n Thanks for your feedback,\n 📢 To keep in touch is to join our discord server to exchange with us and with the community.\n    submitted by    /u/cranthir_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tk5f00/how_hugging_face_can_contribute_to_the_deep/",
          "publishedOn": "2022-03-22T15:22:31.000Z",
          "wordCount": 947,
          "title": "How Hugging Face 🤗 can contribute to the Deep Reinforcement Learning Ecosystem?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tk3juz/how_to_set_the_distance_threshold_value_and_make/",
          "author": null,
          "description": "I use the [RL Robotics library](https://github.com/Farama-Foundation/Gym-Robotics) to simulate robots. In the Fetchxxx-Env, the variable distance_threshold is set as 0.05 default to determine whether it completed successfully a task. I try to change it by using \n env.distance_threshold = 0.01(or other value) \n Because I think 0.05(m) is too rough for some tasks. But it doesn't work! (When the success_rate is 1.0, the distance between the achieved_goal and the desired_goal is 0.04x, which is larger than I set.) \n What should I do to change the conditions for determining whether a task is complete? Can anyone give me some advice or information?\n    submitted by    /u/Due_Advertising6542  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tk3juz/how_to_set_the_distance_threshold_value_and_make/",
          "publishedOn": "2022-03-22T13:54:56.000Z",
          "wordCount": 228,
          "title": "how to set the distance_threshold value and make it effective",
          "imageUrl": "https://external-preview.redd.it/SfVVamhH8mfQbVVxJi0FKvgRcXGIYltBs7JZq2hFrNA.jpg?auto=webp&s=45b8825aac3464cecc49b1a5765f7829766eb18e"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tk2ya5/need_help_trying_to_implement_a_paper/",
          "author": null,
          "description": "Hello,\n I'm an undergraduate CS student trying to re-implement this paper for my University project.\n I have some experience in Machine Learning (Supervised Learning) and implemented some basic projects myself, but I'm a little bit confused about where to begin, I've found two different implementations online but I don't think that's gonna help me a lot as I'm not that experienced in this field.\n I would appreciate any suggestions on how I can understand the paper and implement it myself (not just a copy/paste from someone else's code) or the libraries that can help me, etc.\n Sorry for my bad English, I'm not a native speaker\n thanks a lot :)\n    submitted by    /u/ahmadreza_hadi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tk2ya5/need_help_trying_to_implement_a_paper/",
          "publishedOn": "2022-03-22T13:24:58.000Z",
          "wordCount": 347,
          "title": "Need help trying to implement a paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tk00hv/robotics_control_drl_vs_classical_approaches/",
          "author": null,
          "description": "I'm curious about your opinion on this. There are impressive recent advances in DRL for humanoid whole-body control (Deepmimic, Drecon, etc...). Do you think these methods will one day overtake the \"classical\" approaches from control theory? Or we will see more and more methods combining these two approaches?\n    submitted by    /u/thejackforest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tk00hv/robotics_control_drl_vs_classical_approaches/",
          "publishedOn": "2022-03-22T10:36:47.000Z",
          "wordCount": 567,
          "title": "Robotics control : DRL vs classical approaches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tjld3p/recommended_materials_for_beginners_in/",
          "author": null,
          "description": "submitted by    /u/Rich_Beautiful  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tjld3p/recommended_materials_for_beginners_in/",
          "publishedOn": "2022-03-21T20:36:15.000Z",
          "wordCount": 160,
          "title": "Recommended materials for beginners in theoretical RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tjl6r7/how_initialize_variable_in_rl_to_reproduce_results/",
          "author": null,
          "description": "I am using stabel-baselines frameworks to train the model. To build an agent environment I am using Gym environment. I want to make sure that results do not change very much when I run the same model a second time. How is it possible?\n    submitted by    /u/Mariam_Dundua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tjl6r7/how_initialize_variable_in_rl_to_reproduce_results/",
          "publishedOn": "2022-03-21T20:28:39.000Z",
          "wordCount": 240,
          "title": "How initialize variable in RL to reproduce results",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tjcpxj/league_of_legends_a_new_dawn_trailer_resolution/",
          "author": null,
          "description": "submitted by    /u/stepanmetior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tjcpxj/league_of_legends_a_new_dawn_trailer_resolution/",
          "publishedOn": "2022-03-21T14:11:31.000Z",
          "wordCount": 165,
          "title": "League of Legends A New Dawn Trailer (Resolution increased with the help of neural networks up to 8K 60FPS)",
          "imageUrl": "https://external-preview.redd.it/DkrKHIH2MDWjvybRTqEoCLwEp4YtYHD_WvOBKXyCBng.jpg?auto=webp&s=529266e30d11a7414c7624d6df14483355a7b458"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tj8yfd/cfp_evorl_gecco_2022_2nd_evolutionary_rl_workshop/",
          "author": null,
          "description": "CALL FOR PAPERS\n EvoRL 2022\n Evolutionary Reinforcement Learning workshop at GECCO 2022, July 9-13, Boston, USA\n \n In recent years reinforcement learning (RL) has received a lot of attention thanks to its performance and ability to address complex tasks. At the same time, multiple recent papers, notably work from OpenAI, have shown that evolution strategies (ES) can be competitive with standard RL algorithms on some problems while being simpler and more scalable. Similar results were obtained by researchers from Uber, this time using a gradient-free genetic algorithm (GA) to train deep neural networks on complex control tasks. Moreover, recent research in the field of evolutionary algorithms (EA) has led to the development of algorithms like Novelty Search and Quality Diversity, capable of…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tj8yfd/cfp_evorl_gecco_2022_2nd_evolutionary_rl_workshop/",
          "publishedOn": "2022-03-21T10:47:39.000Z",
          "wordCount": 631,
          "title": "[CfP] EvoRL @ GECCO 2022: 2nd Evolutionary RL workshop @ GECCO 2022",
          "imageUrl": "https://external-preview.redd.it/lK42WwByGG32nygWSBuOYR3KR5RyUTDVfuLYvfjqmTI.jpg?auto=webp&s=02c389b64acc7a9d40c4c4ad6555c2381750877f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tj7j78/what_are_some_real_life_examples_of_dynamics_in/",
          "author": null,
          "description": "Dynamics in reinforcement learning, that are represented by the transition function in an MDP, are meant to modelize the probability of reaching (or deriving from) the desired state. From what I understand, this probability is caused by the environement or by a malfunction within the agent(?). \n I would like to ask if there is any real life problem modelized into an RL model with a real life transition probability? I would be super grateful if you redirect me to research papers in this axis (all I found so far are theoretical representation of dynamics)\n Thanks in advance.\n    submitted by    /u/Unfinished-plans  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tj7j78/what_are_some_real_life_examples_of_dynamics_in/",
          "publishedOn": "2022-03-21T09:10:01.000Z",
          "wordCount": 819,
          "title": "What are some real life examples of dynamics in reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tj1s3b/surf_semisupervised_reward_learning_with_data/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tj1s3b/surf_semisupervised_reward_learning_with_data/",
          "publishedOn": "2022-03-21T02:53:28.000Z",
          "wordCount": 159,
          "title": "\"SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning\", Park et al 2022",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tizwge/bamboo_building_megascale_vision_dataset/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tizwge/bamboo_building_megascale_vision_dataset/",
          "publishedOn": "2022-03-21T01:11:59.000Z",
          "wordCount": 185,
          "title": "\"Bamboo: Building Mega-Scale Vision Dataset Continually with Human-Machine Synergy\", Yuanhan et al 2022 {Sensetime} (69m categorized images)",
          "imageUrl": "https://external-preview.redd.it/D6sDC5-jNXvf7lupM64bZcOq1QuEH-VK8bajvXRQlD4.jpg?auto=webp&s=4a7cf61fdfb8178549efd78204d0750561d24026"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tizmlp/modern_hopfield_networks_for_return_decomposition/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tizmlp/modern_hopfield_networks_for_return_decomposition/",
          "publishedOn": "2022-03-21T00:57:59.000Z",
          "wordCount": 153,
          "title": "\"Modern Hopfield Networks for Return Decomposition for Delayed Rewards\", Widrich et al 2021",
          "imageUrl": "https://external-preview.redd.it/X0iUTaLs2Nk1xsiLuHSXDEF24fJPyIBmmpqk4epPlYg.jpg?auto=webp&s=036dcf53a951d6bafbf5c2dd6b37ccf914dabf13"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tiqsqe/d_should_i_go_for_the_phd/",
          "author": null,
          "description": "Like many others on here, I've hit a crossroad in life and I'm unsure whether I want to do a PhD or stay in the industry, so I am looking for some advice on my particular situation. About me:\n  \nInterested in creating intelligent robots. As cringy as it sounds, I do believe that star-wars-like intelligent robots are possible within my lifetime and my goal is to contribute towards that\n I love love love creating novel breakthrough technology that has the potential to improve everyone's lives. I like writing papers and creating tech in equal amounts. I love seeing the impact of my work firsthand.\n At this point in time, I don't think I'll enjoy an academic career because I like doing things with a more immediate impact. Thus I think I'd like to end up in industry research.\n Graduated MSc Rob…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tiqsqe/d_should_i_go_for_the_phd/",
          "publishedOn": "2022-03-20T17:58:55.000Z",
          "wordCount": 1723,
          "title": "[D] Should I go for the PhD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tiqsq8/drone_environment/",
          "author": null,
          "description": "Hi all.\n I need to implement a drone env to train neural network Capable of stabilizing a drone after throwing it. any suggestions for pre built envs or where to find informations on what i should consider if i want to build one on my own? I know how to use pybullet and the open ai gym interface so building one is not out of the question but a pre built one by a more experienced people would be better given the fact that I'm on tight schedule \n Sorry for my English not a native speaker :)\n    submitted by    /u/HerForFun998  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tiqsq8/drone_environment/",
          "publishedOn": "2022-03-20T17:58:54.000Z",
          "wordCount": 269,
          "title": "drone environment ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tidgqg/question_about_unsupervised_reinforcement/",
          "author": null,
          "description": "Hi, I'm trying to implement unsupervised RL algorithms, like vision-based APT.\n I trained my agent and saw some meaningful behaviors in pre-training session. but, at finetune session, the agent showed bad adjustment. I guess over-estimation was occurred. (The experiment was action repeat 8 so it looks worse than official drq implementation.)\n Orange : scratch DrQ, gray : Finetuned version after APT 2M frames training\n Orange : scratch DrQ, gray : Finetuned version after APT 2M frames training\n How can I finetune that I had already pre-trained agent well? \n ​\n Thanks for reading.\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tidgqg/question_about_unsupervised_reinforcement/",
          "publishedOn": "2022-03-20T04:48:32.000Z",
          "wordCount": 209,
          "title": "Question about unsupervised reinforcement learning finetune process",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ti5zsg/agile_locomotion_via_modelfree_learning_margolis/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ti5zsg/agile_locomotion_via_modelfree_learning_margolis/",
          "publishedOn": "2022-03-19T21:59:11.000Z",
          "wordCount": 138,
          "title": "\"Agile Locomotion via Model-free Learning\", Margolis et al 2022",
          "imageUrl": "https://external-preview.redd.it/NoBgYa-xYCEDwx5ruZGa_xkbF6yk4rqNslQT7Iq0OJI.jpg?auto=webp&s=cc0256de998a4ec4ec6bca4e26cfa6dae9d86362"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/thz2d3/ddpg_neural_network_output_does_not_depend_on_the/",
          "author": null,
          "description": "Hi all!\n I am trying to use RL in order to train an agent that provides best direction to move in order to maximize the coverage of an area and I am giving reward on the basis of coverage increase at each step. I am implementing such algorithm both for 1 agent (so I am using simple DDPG) and for a set of agents (using MADDPG), but if I make the exploration noise decay, I noticed that the selected action of the model is always the same, independently on the input it receives. In fact, even during training, selected action is always a little update with respect to the one selected previously, even if the episode changes, and the inputs too. I have tried increasing/decresing the effect of noise (I am using Ornstein Uhlenbeck process) or decreasing the learning rates, but this seems to have no effect. What may be the problem of such a strange behaviour?\n    submitted by    /u/cosimobr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/thz2d3/ddpg_neural_network_output_does_not_depend_on_the/",
          "publishedOn": "2022-03-19T16:37:15.000Z",
          "wordCount": 352,
          "title": "DDPG - Neural Network output does not depend on the input",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/thk4lj/advice_on_network_size/",
          "author": null,
          "description": "I'm making DQN for automatic trading. Due to the nature of the problem, I figured the model would possibly need to be quite complex, but actually I have no idea just how big it should be.\n I am feeding it with 8000 numbers representing the last prices. Due to some reasons still unknown to me, I can basically add as many layers as I want as long as they are not bigger than 4096 neurons without increasing learning speed.\n I just wanted to ask: would 20 layers be too many ? Would 5 probably not be enough ? Right now the model looks like that:\n Dense(2048, \"relu\")\n Dense(1024, \"relu\")\n Dense(512, \"relu\")\n Dense(256, \"relu\")\n Dense(128, \"relu\")\n Dense(1024, \"relu\")\n Dense(2048, \"relu\")\n Dense(1024, \"relu\")\n Dense(512, \"relu\")\n Dense(256, \"relu\")\n Dense(128, \"relu\")\n Dense(64, \"relu\")\n Dense(32, \"relu\")\n Dense(16, \"relu\")\n Dense(8, \"relu\")\n Dense(3, \"relu\")\n Any help is appreciated, really I just want to have an idea of how much would be too much or too little for this specific problem, I'm a total beginner.\n    submitted by    /u/superpowers_fan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/thk4lj/advice_on_network_size/",
          "publishedOn": "2022-03-19T01:11:26.000Z",
          "wordCount": 644,
          "title": "Advice on network size",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tgc8yo/benchmarking_my_neural_network_implementation/",
          "author": null,
          "description": "Hi, I programmed a neural network \"framework\" in C++ which uses CUDA. It's my own implementation, and it's probably really slow, since I'm a beginner and don't even know how oop works (it's all one big file). The project is more about understanding the math behind it, but I still want to know the algorithm's performance in relation to some widely used frameworks like TensorFlow or Keras. It does manage to keep the GPU at 80 - 90% usage for a batch sizes of around 25-50 and 32-64 neurons per layer, if that says anything.\n However, is there something like \"calculated derivatives per second\", as a measurement of the speed of the implementation? That would be really nice to know.\n My implementation updates the network around 13 times per second with a batch size of 50 and a topology of { 6,32,32,6 }. How slow is that?\n I tried to train the network to calculate the acceleration present in a 3 body planet system. It struggles to do so, although the adam optimizer really helped. I think it got the first digit of the acceleration close to consistently right after one night of training, but it seemed, as if the learning speed was accelerating. The topology was { 6,64,64,6 }, batch size 50 and the learning rate 0.025.\n English is not my native language, so please forgive my mistakes.\n    submitted by    /u/qwedp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tgc8yo/benchmarking_my_neural_network_implementation/",
          "publishedOn": "2022-03-17T15:03:40.000Z",
          "wordCount": 372,
          "title": "Benchmarking my neural network implementation.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tgag9j/first_visit_and_every_visit_estimate_of_value_of/",
          "author": null,
          "description": "Hi, I was going through the below question picked from reinforcement learning book (sutton & barto)\n ​\n Consider an MDP with a single non terminal state and a single action that transitions back to the non-terminal state with probability p and transitions to the terminal state with probability 1-p. Let the reward be +1 on all transitions and let gamma = 1 (discount factor). Suppose you observe one episode that last for 10 steps, with a return of 10. What are the first-visit and every visit estimators of the value of the non terminal state. \n ​\n Hi, I am not looking for the answer but the steps that take you to the answer. I am beginner in Reinforcement learning. Please help me. Thank you.\n    submitted by    /u/Tricky-Jello-7847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tgag9j/first_visit_and_every_visit_estimate_of_value_of/",
          "publishedOn": "2022-03-17T13:38:09.000Z",
          "wordCount": 258,
          "title": "First visit and Every visit estimate of value of non terminal state",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tg3b3c/has_anybody_used_recsim_ng_from_google_for_online/",
          "author": null,
          "description": "I was wondering if RecSim NG is actively used for research. Seems like there are limited resources and demos to play with.\n    submitted by    /u/Few-Cap-5989  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tg3b3c/has_anybody_used_recsim_ng_from_google_for_online/",
          "publishedOn": "2022-03-17T05:58:27.000Z",
          "wordCount": 160,
          "title": "Has anybody used RecSim NG from Google for online recommender system simulation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tg2ud7/selfsupervised_rl_implementation/",
          "author": null,
          "description": "Hi, I reimplemented Behavior From the Void: Unsupervised Active Pre-Training(official implementation https://github.com/rll-research/url_benchmark)\n Because, their APT only supports vector-based environment and ICM-based implementation(that is different version from APT paper). So I reimplemented it as paper described and replemented APT shows very interesting at first(showed significant behaviors and received 20~30 episode reward constantly and deceased apt encoder error) but at actual transfer step, It shows very bad performance. Q value looks overestimated when training Q network in pretraining step. \n Orange : scratch DrQ, gray : Finetuned version after APT 2M frames training \n ​\n Orange : scratch DrQ, gray : Finetuned version after APT 2M frames training \n What should I do training APT correctly? My implementation is based on DrQ and APT official implementation https://github.com/seolhokim/APT\n Really Thanks for reading.\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tg2ud7/selfsupervised_rl_implementation/",
          "publishedOn": "2022-03-17T05:27:21.000Z",
          "wordCount": 233,
          "title": "self-supervised RL implementation",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tfxxp9/a_review_of_the_gumbelmax_trick_and_its/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tfxxp9/a_review_of_the_gumbelmax_trick_and_its/",
          "publishedOn": "2022-03-17T00:53:40.000Z",
          "wordCount": 164,
          "title": "\"A Review of the Gumbel-max Trick and its Extensions for Discrete Stochasticity in Machine Learning\", Hujiben et al 2021",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tfxv50/policy_improvement_by_planning_with_gumbel/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tfxv50/policy_improvement_by_planning_with_gumbel/",
          "publishedOn": "2022-03-17T00:50:04.000Z",
          "wordCount": 156,
          "title": "\"Policy improvement by planning with Gumbel\", Danihelka et al 2021 {DM} (Gumbel AlphaZero/Gumbel MuZero)",
          "imageUrl": "https://external-preview.redd.it/X0iUTaLs2Nk1xsiLuHSXDEF24fJPyIBmmpqk4epPlYg.jpg?auto=webp&s=036dcf53a951d6bafbf5c2dd6b37ccf914dabf13"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tfu624/finally_an_official_muzero_implementation/",
          "author": null,
          "description": "deepmind/mctx: Monte Carlo tree search in JAX (github.com)\n    submitted by    /u/jack281291  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tfu624/finally_an_official_muzero_implementation/",
          "publishedOn": "2022-03-16T21:52:02.000Z",
          "wordCount": 178,
          "title": "Finally an official MuZero implementation",
          "imageUrl": "https://external-preview.redd.it/R4-33j31BNkMGiG7K66XUHFgZfvAEuWeulq-cGEmrxs.jpg?auto=webp&s=531eacdb71e231b3348e5482e6e9e0062d8f9992"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tfjkkj/what_is_a_technically_principled_way_to_compare/",
          "author": null,
          "description": "I have four RL agents with different architectures whose performance I would like to test. My question, however, is: how do you know whether performance of a specific architecture is better because the architecture is actually better at OOD generalization (in case you're testing that) or because it simply has more neural networks and greater capacity?\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tfjkkj/what_is_a_technically_principled_way_to_compare/",
          "publishedOn": "2022-03-16T14:59:28.000Z",
          "wordCount": 435,
          "title": "What is a technically principled way to compare new RL architectures that have different capacity, ruling out all possibile confounding factors?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tfj4ew/how_many_trajectories_to_learn_from_in_policy/",
          "author": null,
          "description": "In the policy gradient and actor-critic methods, we collect trajectories and then update the policy network. So, how many trajectories should we collect before training the networks. Also, is there any range of learning rate we should choose from while training these network because too high learning rate can cause the problem of exploding gradients and then the networks just gives nan as the output.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tfj4ew/how_many_trajectories_to_learn_from_in_policy/",
          "publishedOn": "2022-03-16T14:37:58.000Z",
          "wordCount": 225,
          "title": "How many trajectories to learn from in policy gradient and actor-critic methods?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tfgdca/hybrid_learning_meaning_and_benefits_for_your/",
          "author": null,
          "description": "submitted by    /u/your_kompanions  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tfgdca/hybrid_learning_meaning_and_benefits_for_your/",
          "publishedOn": "2022-03-16T12:18:50.000Z",
          "wordCount": 143,
          "title": "Hybrid Learning - Meaning and Benefits for Your Classroom",
          "imageUrl": "https://external-preview.redd.it/nNhSOeDHEuP_Dk86TT9iAO4LPoRX8Q8xJtEESF5vkSk.jpg?auto=webp&s=6ef03e864618939b7eff62c1bf91347f717736b8"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tf98rn/best_workflow_for_creating_javascript_games_agents/",
          "author": null,
          "description": "Hi, does anyone have experience making javascript agents + games? \n When I was working on reinforcement learning agents for games like 2048 before, i would build the game/simulation with pygame, and then also code the agent in python.\n This worked well, but I would like to have the game with the agent playable by others when I'm done in browser.\n SO i am wondering what is the best workflow for getting a game + agent going in javascript?\n Is there a specific game engine/library you would recommend for javascript that is equivalent to pygame? I only know of https://github.com/photonstorm/phaser which seems to be the most popular.\n Also, I have not done any DEEP reinforcement learning, only simple Q learning with Q table. I would like to implement DQN for a game like Uno, but in javascript how would I train the neural net itself in JS? Do people train in tensorflow (python) and then convert to tensorflow.js somehow? This part I am really unsure of and would appreciate any guidance on best path to take. Thankyou!\n    submitted by    /u/TernaryJimbo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tf98rn/best_workflow_for_creating_javascript_games_agents/",
          "publishedOn": "2022-03-16T04:27:13.000Z",
          "wordCount": 2,
          "title": "Best workflow for creating javascript games + agents?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tewbvj/interested_in_reinforcement_learning_read_how/",
          "author": null,
          "description": "When working on a promotion optimization problem there are a lot of different multi-armed bandit algorithms to choose from. In a recent DoorDash project I worked on I did a technology survey of three reinforcement learning algorithms :Epsilon-Greedy, The Upper Confidence Bound, and Thompson Sampling. I wanted to share my experience and why we ultimately decided to go with Thompson sampling. Let me know what you think, and take a look at this post to get the technical details\n    submitted by    /u/Outrageous_Pilot_351  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tewbvj/interested_in_reinforcement_learning_read_how/",
          "publishedOn": "2022-03-15T18:35:28.000Z",
          "wordCount": 748,
          "title": "Interested in Reinforcement learning? Read how DoorDash used Thompson Sampling to optimize our promotional messages to Dashers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tet3fv/take_control_over_one_or_multiple_agents/",
          "author": null,
          "description": "Hey everyone, I'm running a simulation including vehicles to define specific behaviors on the road, I'm using RL for that. I'm wondering if I have to take control of one vehicle or many of them? means in the case of many vehicles the RL will return many actions. I'm confused which is the state-of-the-art way to do that.\n    submitted by    /u/good_4_tas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tet3fv/take_control_over_one_or_multiple_agents/",
          "publishedOn": "2022-03-15T16:36:18.000Z",
          "wordCount": 188,
          "title": "Take control over one or multiple agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tere5f/how_to_validate_your_poker_bot/",
          "author": null,
          "description": "Basically If I have a poker bot built using some logic (Reinforcement Learning, Machine Learning or Regret matching), how do I validate that it is performing well?\n And also is there a way I can say that it performs at an X1 level or X2 level\n    submitted by    /u/David_Gladson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tere5f/how_to_validate_your_poker_bot/",
          "publishedOn": "2022-03-15T15:20:24.000Z",
          "wordCount": 171,
          "title": "How to validate your Poker bot?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tep8at/implementing_recurrent_layers_in_a_drqn/",
          "author": null,
          "description": "I'm attempting to create a recurrent RL neural network using a LSTM layer but I'm not able to get the model to properly compile. My model looks like this:\n ``` minibatch_size = 32 window_length=10\n tf.keras.Sequential([ # Input => FC => ReLu Input(shape=(*n_states, )), Flatten(), Dense(32, activation=\"relu\"),\n # FC => ReLu Dense(32, activation=\"relu\"), # LSTM ( => tanh ) LSTM(16), # FC => ReLu Dense(16, activation=\"relu\"), # FC => Linear (output action layer) Dense(n_actions, activation=\"linear\") \n ]) ```\n However when trying to compile the model, I get this error: ValueError: Input 0 of layer \"lstm_0\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 32)\n My thinking is that I have to resize the input for some reason and somehow, but I'm not sure what size the LSTM layer is wanting! Any ideas?\n    submitted by    /u/hazzaob_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tep8at/implementing_recurrent_layers_in_a_drqn/",
          "publishedOn": "2022-03-15T13:39:14.000Z",
          "wordCount": 251,
          "title": "Implementing recurrent layers in a DRQN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tenmcv/rl_for_humanoperated_control_tasks/",
          "author": null,
          "description": "Hi, I'm looking for any kinds of field experiments in which a human performs instructions from an RL trained control policy. If they don't exist, what do you think are the main limitations?\n    submitted by    /u/JoeHighlander97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tenmcv/rl_for_humanoperated_control_tasks/",
          "publishedOn": "2022-03-15T12:15:59.000Z",
          "wordCount": 189,
          "title": "RL for human-operated control tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tejfnp/a2c_why_do_episode_rewards_reset/",
          "author": null,
          "description": "I am training a model using A2C with stable baselines 2. When I increased the timesteps I noticed that episode rewards seem to reset (see attached plots). I don´t understand where these sudden decays or resets could come from and I am looking for practical experience or pointers to theory what these resets could imply.\n Thank you.\n https://imgur.com/a/8nDRm7m\n    submitted by    /u/---___---___---___  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tejfnp/a2c_why_do_episode_rewards_reset/",
          "publishedOn": "2022-03-15T07:28:14.000Z",
          "wordCount": 302,
          "title": "A2C: Why do episode rewards reset?",
          "imageUrl": "https://external-preview.redd.it/dWfMy5XyibGyZvVT6GkaYmqH_gV_aKTwHyn60b4SLC8.jpg?auto=webp&s=4cc730bb3ea583a3cfb091489d713ab93e07f70a"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/teb80h/how_often_should_we_do_reward_shaping/",
          "author": null,
          "description": "At my company we use RL to solve our problem. Basically the agent takes several actions, and the reward is computed as a weighted-sum of multiple sub-objectives.\n So far so good. But the way we build models for the next release is basically : * We train several models, each with different sets of weights for the reward * The QA team selects the best model (and therefore the best reward's weights), according to qualitative results (not quantitative, since the weights changes, the rewards are not really comparable)\n This process makes me uncomfortable. I can't point out exactly why, but I feel that such process will never lead to model's improvement. Instead of training the model on the environment, it feels like we are updating the environment on the model...\n  \nSo my question is : Is it normal to have such a process in industry ? Is it healthy to modify the reward so often and to rely almost only on qualitative results ?\n I'm looking for rational explanation of this feeling I have...\n    submitted by    /u/dummy-gummy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/teb80h/how_often_should_we_do_reward_shaping/",
          "publishedOn": "2022-03-14T23:45:29.000Z",
          "wordCount": 369,
          "title": "How often should we do reward shaping ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/te9r0g/in_new_math_proofs_artificial_intelligence_plays/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/te9r0g/in_new_math_proofs_artificial_intelligence_plays/",
          "publishedOn": "2022-03-14T22:35:58.000Z",
          "wordCount": 155,
          "title": "\"In New Math Proofs, Artificial Intelligence Plays to Win\" (finding counterexamples in combinatorics; Wagner 2021)",
          "imageUrl": "https://external-preview.redd.it/hno7pbvAdGe2LldNG1nzGDnDGHyzqjcZzo6sRpPQTwk.jpg?auto=webp&s=53b6164925fd6a7ff78fe4fac8ee4433ba659d93"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/te2vak/build_custom_3d_gridworld_environments/",
          "author": null,
          "description": "Hi guys, I wanted to ask some advice/recommendations on what is a good (and as easy to learn/use as possible :) ) platform for building 3D gridworld environments -- which can subsequently be used for training RL models, like the nice environments seen in Deepmind papers e.g. https://arxiv.org/pdf/1810.06721.pdf (but more accessible to plebs such as I :)\n Key hopes I have:\n - be able build simple rooms, common objects (apples, keys, etc)\n - pick up objects.\n - be able to run these environments on a headless server that does not require a display in order to run, so that I can run it on a university server.\n (I tried a Unity based system over the last several weeks. These allowed me to build pretty nice environments, but trying to get it to work on a headless server with xvfb was a pain that I could not get to work, so if possible, I would like to avoid this problem altogether).\n Thanks for the kind help! :)\n https://preview.redd.it/dn21zty0vdn81.png?width=684&format=png&auto=webp&s=ea6396fb94a2b68cb267ecdf1531a355eb779586\n    submitted by    /u/sunchipsster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/te2vak/build_custom_3d_gridworld_environments/",
          "publishedOn": "2022-03-14T17:29:14.000Z",
          "wordCount": 332,
          "title": "Build custom 3D gridworld environments",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tdzasx/random_idea_for_epsilon_control/",
          "author": null,
          "description": "C, a parameter, I name it confidence confidence_count = 0 if last game reward >= target: if confidence_count < C: confidence_count++ else: reduce epsilon, increase target else: confidence_count = 0 \n Dont flame plz, just a random idea I got when I am bored\n    submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tdzasx/random_idea_for_epsilon_control/",
          "publishedOn": "2022-03-14T14:54:04.000Z",
          "wordCount": 469,
          "title": "Random idea for epsilon control",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tdq3du/d_p_some_good_basic_rl_project_ideas/",
          "author": null,
          "description": "submitted by    /u/Shinigami0108  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tdq3du/d_p_some_good_basic_rl_project_ideas/",
          "publishedOn": "2022-03-14T05:31:34.000Z",
          "wordCount": 127,
          "title": "[D] [P] Some good basic RL project ideas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tdn8ch/how_do_i_get_optimal_policies_in_regretbased/",
          "author": null,
          "description": "As far as I understand, regret can be defined as the difference between the sum of rewards (in a horizon) from the optimal policy and that from the current policy. However, how do we have the optimal policy even if it is a hindsight manner? I think getting the optimal policy is the goal of an RL problem. Once the optimal policy is known, the job is done. There's no need to compute a regret value. There must be a huge gap between the regret methods and my understanding...\n    submitted by    /u/JayCarrot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tdn8ch/how_do_i_get_optimal_policies_in_regretbased/",
          "publishedOn": "2022-03-14T02:43:44.000Z",
          "wordCount": 543,
          "title": "How do I get optimal policies in regret-based methods?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tdn5r8/help_needed/",
          "author": null,
          "description": "If two environments are almost identical except that in one env, I added extra info to its state. Then, I trained RL on both envs with same algorithm and hyperparams. If the performance in the environment having extra state info is better than the other, can I conclude that the extra state help to boost performance? I always have concern that what if there exists a set of hyperparams that will make the training on env, which doesn’t have extra state, better than the one has extra info, hence using the same hyperparams is unfair comparison. Thanks guys!\n    submitted by    /u/Rich_Beautiful  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tdn5r8/help_needed/",
          "publishedOn": "2022-03-14T02:39:49.000Z",
          "wordCount": 464,
          "title": "Help needed!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tdc9hb/some_questions_about_rollout_algorithm/",
          "author": null,
          "description": "As described in Sutton's RL book:\n \" Rollout algorithms are decision-time planning algorithms based on Monte Carlo control\n applied to simulated trajectories that all begin at the current environment state. They\n estimate action values for a given policy by averaging the returns of many simulated\n trajectories that start with each possible action and then follow the given policy. When\n the action-value estimates are considered to be accurate enough, the action (or one of the\n actions) having the highest estimated value is executed, after which the process is carried\n out anew from the resulting next state.\" \n My questions\n 1. Since we are following a given policy and simulating begins with a given state. How come there will be different trajectories in a deterministic environment?\n 2. How do we do rollout in continuous space?\n    submitted by    /u/Blasphemer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tdc9hb/some_questions_about_rollout_algorithm/",
          "publishedOn": "2022-03-13T17:50:15.000Z",
          "wordCount": 236,
          "title": "Some questions about rollout algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tda0p0/openai_gym_lunar_lander_v2_question/",
          "author": null,
          "description": "Hi, I am trying to train an RL agent to solve the Lunar Lander V2 environment.\n However, for a simple DQN as well as a PPO controller I continue to see a situation that after some learning, the lander starts to just hover in a high position. \n Is this a common observation, or do I have to assume that my implementation is wrong?\n From the documentation, I see no negative reward for just hoovering...\n ​\n Thanks for any enlightening comment,\n Dito\n    submitted by    /u/ditomax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tda0p0/openai_gym_lunar_lander_v2_question/",
          "publishedOn": "2022-03-13T16:05:57.000Z",
          "wordCount": 376,
          "title": "OpenAI gym: Lunar Lander V2 Question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/td8swj/openai_gym_variable_action_space_in_a_custom/",
          "author": null,
          "description": "Hello,\n I'm wanting to make a custom environment in openAI gym. My problem is the action space varies depending on the state, and I don't know if I can compute (without brute-forcing it across every state) the max. I saw one solution was to implement a negative reward if an impossible action was selected, but I'm not sure if that is practial for my use case. \n https://www.reddit.com/r/reinforcementlearning/comments/rlixoo/openai_gym_custom_environments_dynamically/\n Is there a way to do this or should I just go for an action space larger than practical and hope it never exceeds that?\n    submitted by    /u/snaredrum_merchant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/td8swj/openai_gym_variable_action_space_in_a_custom/",
          "publishedOn": "2022-03-13T15:05:55.000Z",
          "wordCount": 229,
          "title": "OpenAI Gym - Variable action space in a custom enviroment, unknown upper bound",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/td18om/skills_to_learn_before_starting_reinforcement/",
          "author": null,
          "description": "Hey,\n I am new to RL. I was fascinated by the concept of reinforcement learning. But now when it comes to learning RL I would like to know skills required to to start RL and the road map to RL. I would also like to know if Dynamic Programming is an important skill to learn RL or not.\n Thank you.\n    submitted by    /u/Rishh3112  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/td18om/skills_to_learn_before_starting_reinforcement/",
          "publishedOn": "2022-03-13T06:57:46.000Z",
          "wordCount": 566,
          "title": "Skills To Learn Before Starting Reinforcement Learning(RL)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tcmvb7/training_multiple_robots_for_different_tasks_at/",
          "author": null,
          "description": "Hi, I'm new to RL and just wondering if a single agent can train multiple robots to perform different tasks simultaneously. If possible, can you please recommend me some research papers and implementations that I can take a look at?\n I was hoping we could create two gym environments like env1 = gym.make(\"robot1-task1\") and env2 = gym.make(\"robot2-task2\") then use a single agent to sample experience from both environments at the same time and generalize for both tasks.\n    submitted by    /u/ncbdrck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tcmvb7/training_multiple_robots_for_different_tasks_at/",
          "publishedOn": "2022-03-12T17:53:06.000Z",
          "wordCount": 255,
          "title": "Training Multiple Robots for different tasks at the same time using Deep Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tcmra4/finding_global_optimum_of_an_unknown/",
          "author": null,
          "description": "Hi everyone,\n I'm a newbie in Reinforcement Learning, but I have read a lot of scientific papers, but I'm really not sure if I am on the right track. \n My problem is, that I'd like to find the optimal parameters that maximize the output value. \n The output value is computed by a simulation tool - and the simulation is feeded by 200+ input parameters. So you can basically say, that the problem is to optimize an unknown objective function. \n ​\n Because of that high-dimensionality, the way to go will be probably with policy-gradient RL, or even better actor-critic RL. As I do not have to explore large parts of the space - I only want to find the optimium - I'm guessing that an on-policy algorithm as for example PPO should be the way to go. \n ​\n Am I right that using PPO could solve my problem or am I totally on the wrong track?\n Thank you very much in advance for your help, I would be really grateful!\n    submitted by    /u/wilkules  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tcmra4/finding_global_optimum_of_an_unknown/",
          "publishedOn": "2022-03-12T17:47:47.000Z",
          "wordCount": 298,
          "title": "Finding global optimum of an unknown high-dimensional objective function with Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tcighw/parallelization_with_different_robotics_learning/",
          "author": null,
          "description": "I have recently started using Isaac gym for simulating robots for deep reinforcement learning. The ability to simulate thousands of robots at once on a normal GPU feels like a total game changer. It seems strange to me that there are still only a handful of teams using it. It then occurred to me that perhaps other physics environments are actual also capable of similar performance if you know how to program them correctly. GPU physics has existed of a long time so it makes sense that there would be other simulators with excellent parallelizability. \n so my question is: how real is the Isaac gym speed up? \n Is it something that can be copied by other simulators? \n If its so much faster why aren't more people using it ?\n    submitted by    /u/sanddollarbeach  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tcighw/parallelization_with_different_robotics_learning/",
          "publishedOn": "2022-03-12T15:15:54.000Z",
          "wordCount": 251,
          "title": "Parallelization with different robotics learning environments.--Isaac gym comparison.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tchiht/i_need_help_about_this_httpswwwricmuedupub/",
          "author": null,
          "description": "submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tchiht/i_need_help_about_this_httpswwwricmuedupub/",
          "publishedOn": "2022-03-12T14:28:29.000Z",
          "wordCount": 138,
          "title": "I need help about this, https://www.ri.cmu.edu/pub_files/pub1/thrun_sebastian_1993_1/thrun_sebastian_1993_1.pdf",
          "imageUrl": "https://preview.redd.it/g8yx02zcqym81.png?auto=webp&s=438167fb5c3bb958cf42fb01541fd5c5cc340840"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tcggns/questions_about_the_upper_bound_of_overestimation/",
          "author": null,
          "description": "I am forcing myself to understand the whole thing in the paper \"Deep Reinforcement Learning with Double Q-learning\" before code it out. In the paper \"Issues in Using Function Approximation for Reinforcement Learning\", I really can't understand the second line of the equation in the Appendix: Proofs section that try to derive the upper bound of the overestimation, what I can understand is it change the expectation to integral and combine a derivative of a function. As I cant understand the derivation of the upper bound, I am not trying to understand the derivation of the lower bound, or else I can't sleep at all, and also why there is no YouTube video explain about this?\n    submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tcggns/questions_about_the_upper_bound_of_overestimation/",
          "publishedOn": "2022-03-12T13:32:17.000Z",
          "wordCount": 296,
          "title": "Questions about the upper bound of overestimation in Q Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tcdxur/an_example_of_an_rl_problem/",
          "author": null,
          "description": "I started learning RL about 6 months ago, and I learned the basic definitions of RL, such as agent, policy, reward, action value function, state-action value function, etc. However, I am still kind of feeling my knowledge is not enough, since I couldn’t find an example of an RL problem for which these concepts are defined and explained in details. For example, I know that the state-action value function specifies how good it is for an agent to perform a particular action in a state with a policy π, however, I don’t know how we could define this function for a simple RL example. Does anyone have a thorough example of an RL problem in which basic concepts of RL are defined and explained?\n    submitted by    /u/nimageran  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tcdxur/an_example_of_an_rl_problem/",
          "publishedOn": "2022-03-12T10:49:21.000Z",
          "wordCount": 517,
          "title": "An example of an RL problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tcchq8/how_are_rewardsscores_calculated_in_openai_gyms/",
          "author": null,
          "description": "Hi guys! Was wondering if anyone knows how Atari gym skiing-v0 is rewarded?\n It seems like:\n  \nsmall negative rewards (~-1 to -10) are given on every timestep.\n a huge negative reward (-1000 to -10000) is given at the termination of the game.\n  \nBut what is the criteria for the huge negative reward -- is it the number of times you bump into trees? the number of flags you missed? And what is the criterion for termination (timestep of the huge negative reward)? \n I can't access the raw code of the skiing-v0 (can't find it on github openai gym) so I have been wracking my brain trying to dissect this.\n Thanks in advance for the help! :)\n    submitted by    /u/sunchipsster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tcchq8/how_are_rewardsscores_calculated_in_openai_gyms/",
          "publishedOn": "2022-03-12T09:04:41.000Z",
          "wordCount": 257,
          "title": "How are rewards/scores calculated in openai Gym's Atari Skiing-v0?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tc74m6/i_need_help_about_double_dqn/",
          "author": null,
          "description": "I already understand the algorithm of DDQN, but I can't really understand the section \"Overoptimism due to estimation errors\", is there any math topic I need to learn to understand it?\n    submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tc74m6/i_need_help_about_double_dqn/",
          "publishedOn": "2022-03-12T03:12:22.000Z",
          "wordCount": 248,
          "title": "I need help about Double DQN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tbujag/need_help_implementing_rl/",
          "author": null,
          "description": "I’m new to reinforcement learning. I am trying to implement this git repo (https://github.com/aryadas98/cs359-networking-project) using RL (q-learning). Any sort of help/references would be greatly appreciated.\n Thanks\n    submitted by    /u/Phoenix17008  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tbujag/need_help_implementing_rl/",
          "publishedOn": "2022-03-11T16:59:35.000Z",
          "wordCount": 138,
          "title": "Need help implementing RL",
          "imageUrl": "https://external-preview.redd.it/Rpe3k_v6eoZm-rQCUKJJpy629o-0crkQ7gSArHtlvi0.jpg?auto=webp&s=6aa4f1f31b1e0d7228c35798b4ca9a6f43ab69df"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tbudav/reinforcement_learning_for_continuous_action/",
          "author": null,
          "description": "Hellooo!\n Actually I am applying DDPG algorithm in a problem with three action spaces. all of them are defined as:\n self.action_space = spaces.Box(low=0, high=+1, shape=(3,), dtype=np.float32)\n All these actions will be used to calculate the global action at time t.\n However, I am having a problem in the DDPG outputs. At each time step, the agent outputs roughly the same actions which sum to nearly 1 (whatever the state).\n I´ have already checked that the environment is working (with stable_baselines3.common.env_checker)\n Also, I have already tested many hyperparameters values but in vain. I am waiting that the agent outputs a diffirent value of the three actions each time we have a different state but always the agent outputs roughly the same actions values such that sum(action1 + action2 + action3) = 1 (nearly) I don´t know what may constrain this in my code?\n the second point is that the actions start in something like [0.5xxxx, 0,4xxxxx, 0.5xxx] and end in [0.00xxxx, 0.00xxxx, 0.99xxxx]\n ​\n https://preview.redd.it/mno0baf89sm81.png?width=486&format=png&auto=webp&s=9f6a49e05f7bb0b7a5a966c7995ee0c4814dd92e\n https://preview.redd.it/q3fwpfpz9sm81.png?width=1278&format=png&auto=webp&s=e1eb79139f578dc4f43504ff4d51b5cc8372aa4e\n ​\n https://preview.redd.it/vbats6y2asm81.png?width=865&format=png&auto=webp&s=c82a0b6400e7fe56c587828e7377f95c979ac7c6\n ​\n https://preview.redd.it/uwun2h76asm81.png?width=1266&format=png&auto=webp&s=0a84a364da5d339d01ab26d68d41bd2197cb24f5\n ​\n https://preview.redd.it/sa21suceasm81.png?width=1270&format=png&auto=webp&s=f2e34cf61d5351d32ed6a954a0c32ddae2174880\n ​\n https://preview.redd.it/jnyzakahasm81.png?width=943&format=png&auto=webp&s=716fc53da05f946a6b009402929f2a73e10d8e2f\n ​\n https://preview.redd.it/apizat8wasm81.png?width=1386&format=png&auto=webp&s=77918a6165a48de413dd585f25243bb206478705\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tbudav/reinforcement_learning_for_continuous_action/",
          "publishedOn": "2022-03-11T16:51:55.000Z",
          "wordCount": 1030,
          "title": "Reinforcement learning for continuous action spaces",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "RL News",
      "feedUrl": "https://www.getrevue.co/profile/seungjaeryanlee?format=rss",
      "siteUrl": "http://rlnews.ryanlee.ai/",
      "articles": []
    },
    {
      "title": "Damian Bogunowicz - dtransposed",
      "feedUrl": "https://dtransposed.github.io/feed.xml",
      "siteUrl": "http://dtransposed.github.io/",
      "articles": []
    },
    {
      "title": "Data Science Central",
      "feedUrl": "http://feeds.feedburner.com/FeaturedBlogPosts-DataScienceCentral?format=xml",
      "siteUrl": "https://www.datasciencecentral.com",
      "articles": [
        {
          "id": "https://www.datasciencecentral.com/?p=57118",
          "author": "Ryan Williamson",
          "description": "AI has been making a lot of noise of late, especially in the context of software development. Of course, this topic is quite wide, but in this article, we shall focus our attention on AI-driven automation testing. Let us start with understanding what is AI and automation testing. Automation testing refers to the process of… Read More »Artificial Intelligence: Benefits for Automation Testing\nThe post Artificial Intelligence: Benefits for Automation Testing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/artificial-intelligence-benefits-for-automation-testing/",
          "publishedOn": "2022-04-08T06:38:59.000Z",
          "wordCount": 938,
          "title": "Artificial Intelligence: Benefits for Automation Testing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/max-duzij-qAjJk-un3BI-unsplash.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57114",
          "author": "Sameer Narkhede",
          "description": "‍What is the shortest distance between two points? A straight line of course. What if there are multiple points? Then, it depends.  A job executed in response to a user action – refreshing a dashboard, aggregating data, building a report, developing an ML algorithm, performing analytics – all require multiple hops through the data ecosystem.… Read More »Data Observability: Cracking the Code\nThe post Data Observability: Cracking the Code appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-observability-cracking-the-code/",
          "publishedOn": "2022-04-07T15:12:45.000Z",
          "wordCount": 1386,
          "title": "Data Observability: Cracking the Code",
          "imageUrl": "https://global-uploads.webflow.com/60ddb7e2e50eaef5bec9595c/624723032cf27f425fe3b49f_BtB8gMQkm1dSTaM6a-zrNRmjPuSL8lIM3WYayENdLoYxbusnO6wJp6Sr-JPhqZ2DgPlA66GvQozKd4nNpOxuXjeZGP2o2FkXe5j-lYz58FaEvCTAeaDWkCub8UeocK6tzk1_IO4p.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57050",
          "author": "Kurt Cagle",
          "description": "For nine years, my family and I have lived in a house in Issaquah, a little community about twenty minutes east of Seattle. The town still retains its charms — a downtown area about three blocks long that includes a vintage (and long since decommissioned) gas station, numerous restaurants, a live theater, the library, and… Read More »DSC Weekly Digest: Moving Time\nThe post DSC Weekly Digest: Moving Time appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-digest-moving-time/",
          "publishedOn": "2022-04-06T15:01:18.000Z",
          "wordCount": 2105,
          "title": "DSC Weekly Digest: Moving Time",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_99749434.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57061",
          "author": "Bill Schmarzo",
          "description": "When I was the Vice President of Advertiser Analytics at Yahoo!, I painfully learned that my targeted user personas (Media Planners & Buyers and Campaign Managers) didn’t want more data in helping them optimize their marketing, campaign, and advertising spend across the Yahoo! Ad Network.  Heck, they didn’t even want analytics!  The aspirations for these… Read More »Building a Data Products-centric Business Model\nThe post Building a Data Products-centric Business Model appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategist-datamanagement-ai-iot-ml/",
          "publishedOn": "2022-04-05T20:31:31.000Z",
          "wordCount": 1620,
          "title": "Building a Data Products-centric Business Model",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_203382343.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57077",
          "author": "German Osin",
          "description": "Real-world production ML systems consist of two main components: data and code. Data is clearly the leader, and rapidly taking center stage. Data defines the quality of almost any ML-based product, more so than code or any other aspect. In Feature Store as a Foundation for Machine Learning, we have discussed how feature stores are… Read More »Data Discovery for ML Engineers\nThe post Data Discovery for ML Engineers appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-discovery-for-ml-engineers/",
          "publishedOn": "2022-04-05T19:14:14.000Z",
          "wordCount": 2588,
          "title": "Data Discovery for ML Engineers",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/cyber-g4c6392d4b_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57035",
          "author": "EdwardNick",
          "description": "Many things can help you to write good dissertations. One of the most important is to use content metrics. It is necessary for all of the students to understand content metrics in detail. A clear understanding of its types and measuring strategies help you to evaluate things in a precise way. Whatever is your topic… Read More »Content Metrics That Can Help You To Write  Dissertations\nThe post Content Metrics That Can Help You To Write  Dissertations appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/content-metrics-that-can-help-you-to-write-dissertations/",
          "publishedOn": "2022-04-05T18:24:50.000Z",
          "wordCount": 1365,
          "title": "Content Metrics That Can Help You To Write  Dissertations",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/Content-Metrics-That-Can-Help-You-To-Write-Best-Audiences.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57075",
          "author": "Karen Anthony",
          "description": "The need of a highly functional and fast processing Central Processing Unit (CPU) in today’s world is not just mostly desired, but also mostly required due to the rapid digitalization across the globe. Whether you work on a personal computer (PC) unit or laptop, the necessity of a highly advanced processor is indispensable.  This is… Read More »Comparative analysis of an Intel and AMD Processor\nThe post Comparative analysis of an Intel and AMD Processor appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/comparative-analysis-of-an-intel-and-amd-processor/",
          "publishedOn": "2022-04-05T18:16:54.000Z",
          "wordCount": 879,
          "title": "Comparative analysis of an Intel and AMD Processor",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_408036566.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57089",
          "author": "Aileen Scott",
          "description": "How does artificial intelligence Diversity, Equity, and Inclusion (DEI) fit into the technological stack of daily companies? Fostering a diverse workforce is a very human problem. The cry for a halt to race prejudice has become deafening, and it’s increasingly a decisive factor for talent when weighing job offers and purchases. To stay up with the… Read More »AI And Its Impact On Diversity And Inclusion\nThe post AI And Its Impact On Diversity And Inclusion appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-and-its-impact-on-diversity-and-inclusion/",
          "publishedOn": "2022-04-05T17:04:16.000Z",
          "wordCount": 1132,
          "title": "AI And Its Impact On Diversity And Inclusion",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_469423570.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57056",
          "author": "Kerry Pearce",
          "description": "Understanding consumer behavior is becoming more and more critical as businesses seek to find innovative ways to survive and thrive in a period of constant change. In the last few years, the market has seen significant changes in the way people shop, travel, dine and purchase goods. As a business, when it comes to understanding… Read More »How Data Intelligence Platforms Promote Business Success\nThe post How Data Intelligence Platforms Promote Business Success appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-data-intelligence-platforms-promote-business-success/",
          "publishedOn": "2022-04-05T06:12:10.000Z",
          "wordCount": 1211,
          "title": "How Data Intelligence Platforms Promote Business Success",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_140495395.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57040",
          "author": "ajitjaokar",
          "description": "I read an article from the world economic forum which proposed an AI labeling system for AI products designed for children Today, for the first time, children are growing up in a world shaped by artificial intelligence (AI) and decisions are being made for children implicitly by AI.  Algorithms need data that is collected and… Read More »Exploring AI labeling for children’s products\nThe post Exploring AI labeling for children’s products appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/exploring-ai-labeling-for-childrens-products/",
          "publishedOn": "2022-04-05T06:06:34.000Z",
          "wordCount": 821,
          "title": "Exploring AI labeling for children’s products",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_375140801.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57058",
          "author": "Scott Thompson",
          "description": "In the previous part, we discussed the current state of data imaging tools in healthcare and the future applications of these technologies. While increased access to information is invaluable to physicians, they can still be limited by their own ability to interpret, or the physical limitations of their surgical ability. In addition to augmenting the… Read More »Data Augmented Healthcare Part 2\nThe post Data Augmented Healthcare Part 2 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-augmented-healthcare-part-2/",
          "publishedOn": "2022-04-04T17:41:15.000Z",
          "wordCount": 826,
          "title": "Data Augmented Healthcare Part 2",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_330431239.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57029",
          "author": "Ryan Williamson",
          "description": "Artificial intelligence has been long making waves globally, empowering companies from across the broad spectrum of industries to take their businesses to the next level. So it is no surprise that this technology is making inroads in the grocery retail space, helping grocers deliver personalized and irreproachable experiences across different channels, establishing improved customer loyalty,… Read More »Top Ways in Which AI Impacts Grocery Retail\nThe post Top Ways in Which AI Impacts Grocery Retail appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/top-ways-in-which-ai-impacts-grocery-retail/",
          "publishedOn": "2022-04-03T21:47:26.000Z",
          "wordCount": 953,
          "title": "Top Ways in Which AI Impacts Grocery Retail",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_311618017.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57026",
          "author": "Alan Morrison",
          "description": "Data is useless if it doesn’t shed light. The more light it sheds on the most acute problems businesses face, the better. Within this context, data synergy–data from multiple sources and disciplines that is more valuable than the sum of its parts–is often underappreciated. With data synergy, the light can be in many more places,… Read More »A different take on business intelligence\nThe post A different take on business intelligence appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-different-take-on-business-intelligence/",
          "publishedOn": "2022-04-03T21:05:49.000Z",
          "wordCount": 1234,
          "title": "A different take on business intelligence",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/waves-gacea61272_1920.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57017",
          "author": "Stephanie Glen",
          "description": "Blockchain is widely touted as a mechanism for securing digital property. Multiple problems exist for driving metaverse transactions. A new review highlights the challenges, some of which may be insurmountable. Blockchain has been touted as a potential solution to securing users’ digital content and data due to its decentralization, immutability, and transparency. However, there are… Read More »Blockchain Won’t Save The Metaverse\nThe post Blockchain Won’t Save The Metaverse appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/blockchain-wont-save-the-metaverse/",
          "publishedOn": "2022-04-03T20:31:44.000Z",
          "wordCount": 1065,
          "title": "Blockchain Won’t Save The Metaverse",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_278111994-1.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57019",
          "author": "Vincent Granville",
          "description": "I tested the job market in the last two weeks, both as an applicant, and as a hiring manager. I share my experience here. It is radically different from what you read in the news, or from what most people say. Data scientists and machine learning engineers looking for a new job are out there.… Read More »The Myth of Analytic Talent Shortage\nThe post The Myth of Analytic Talent Shortage appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/debunking-the-myth-of-analytic-talent/",
          "publishedOn": "2022-03-31T23:01:31.000Z",
          "wordCount": 1849,
          "title": "The Myth of Analytic Talent Shortage",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_252351555.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57007",
          "author": "Rex Ahlstrom",
          "description": "By Rex Ahlstrom, CTO & EVP Growth & Innovation, Syniti   The modern enterprise is composed of a variety of systems, each of which holds data the company needs to conduct business: information about products, services, suppliers, customers, and more. This is the master data, and master data collected by these disparate systems is often stored… Read More »The Increasing Importance of Master Data Management for Your Business: A Primer\nThe post The Increasing Importance of Master Data Management for Your Business: A Primer appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-increasing-importance-of-master-data-management-for-your-business-a-primer/",
          "publishedOn": "2022-03-30T05:49:33.000Z",
          "wordCount": 1505,
          "title": "The Increasing Importance of Master Data Management for Your Business: A Primer",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_392825932-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57012",
          "author": "Kurt Cagle",
          "description": "The Biden Administration made a recent announcement that it was setting up an exploratory committee for the creation of an e-Currency taskforce. In conjunction with this, a new bill, the Electronic Currency and Secure Hardware (ECASH) Act, was introduced by Rep. Stephen Lynch (MA-08), Chair of the House Committee on Financial Services’ Task Force on… Read More »How ECash Will Change The Economy\nThe post How ECash Will Change The Economy appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-ecash-will-change-the-economy/",
          "publishedOn": "2022-03-30T03:19:56.000Z",
          "wordCount": 1299,
          "title": "How ECash Will Change The Economy",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_2860358-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56990",
          "author": "Kurt Cagle",
          "description": "DSC Weekly Digest 29 March 2022 Back in September, I made a prediction: Covid-19 would spike throughout the winter but fade by April as it transitioned from being a pandemic virus to an endemic one. As it turns out, I was mostly correct. Here in Washington State, we finally dropped the mask mandate that had… Read More »Transitions and the Arc of Systems Theory\nThe post Transitions and the Arc of Systems Theory appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-digest-29-march-2022-transitions-and-the-arc-of-systems-theory/",
          "publishedOn": "2022-03-30T00:46:17.000Z",
          "wordCount": 1818,
          "title": "Transitions and the Arc of Systems Theory",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_492175313.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56998",
          "author": "James Wilson",
          "description": "Inventory management is an essential part of any eCommerce business. Especially if you are an eCommerce business owner juggling multiple sales channels, it can save you a lot of effort. However, manually managing your inventories is also a recipe for error. Also, let’s not forget the time you have to spend and the painful process… Read More »Automated Inventory Management System: An Ultimate Guide for 2022 and Beyond\nThe post Automated Inventory Management System: An Ultimate Guide for 2022 and Beyond appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/automated-inventory-management-system-an-ultimate-guide-for-2022-and-beyond/",
          "publishedOn": "2022-03-29T13:58:59.000Z",
          "wordCount": 1385,
          "title": "Automated Inventory Management System: An Ultimate Guide for 2022 and Beyond",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_410872963.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56966",
          "author": "EdwardNick",
          "description": "Statistics gives business owners the freedom to evaluate how their websites are performing. The evaluation involves a couple of things: the bounce rate and the exit rate. But what is the difference between bounce rate and exit rate? This is a point of discussion that requires you to have an open mind to grasp the… Read More »What is the Difference Between Bounce Rate and Exit Rate?\nThe post What is the Difference Between Bounce Rate and Exit Rate? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/what-is-the-difference-between-bounce-rate-and-exit-rate/",
          "publishedOn": "2022-03-29T02:21:21.000Z",
          "wordCount": 1423,
          "title": "What is the Difference Between Bounce Rate and Exit Rate?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_252969949.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56972",
          "author": "ImensoSoftware",
          "description": "There is no denying the importance of the internet and IT in the business scene. Businesses hailing from all sectors are dependent on the web, and they also make use of various types of software applications nowadays. However, with time, such technologies are also evolving. Businesses are coping with huge amounts of data, and to… Read More »Five Major Benefits That Microsoft Power BI Brings To Data Scientists\nThe post Five Major Benefits That Microsoft Power BI Brings To Data Scientists appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/five-major-benefits-that-microsoft-power-bi-brings-to-data-scientists/",
          "publishedOn": "2022-03-29T01:20:33.000Z",
          "wordCount": 1360,
          "title": "Five Major Benefits That Microsoft Power BI Brings To Data Scientists",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_335428295.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56916",
          "author": "Bill Schmarzo",
          "description": "We are in the middle of a business model revolution.  And we are active participants in that revolution.  We have been transitioning from a society where possession and application of physical commodities defined wealth and power, to a society where possession and application of knowledge define wealth and power.  Throughout the 20th century, oil had… Read More »What’s Your Business Model Choice – Hammers or Casino?\nThe post What’s Your Business Model Choice – Hammers or Casino? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategist-datamanagement/",
          "publishedOn": "2022-03-28T16:59:40.000Z",
          "wordCount": 2166,
          "title": "What’s Your Business Model Choice – Hammers or Casino?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_286434477.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56969",
          "author": "Karen Anthony",
          "description": "It is common for growing organizations to reach a point where their existing data solution is no longer adequate for their needs. In most cases, it happens with companies that have used an on-premises infrastructure from the earliest days of business but now need to upgrade their network for continued growth. However, relocating equipment and… Read More »Datacenter relocation is now easier, faster, and more affordable\nThe post Datacenter relocation is now easier, faster, and more affordable appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datacenter-relocation-is-now-easier-faster-and-more-affordable/",
          "publishedOn": "2022-03-28T13:21:51.000Z",
          "wordCount": 875,
          "title": "Datacenter relocation is now easier, faster, and more affordable",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_252351555.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56948",
          "author": "Stephanie Glen",
          "description": "Astronomy has seen an exponential rise in data collection over the last decade. This requires new methods for data analysis, including AI. With the launch of new surveys, big data methodology has become a necessity. A new class of extremely large telescopes has evolved to collect vast amounts of data; The volume of data collected… Read More »The Evolution of Astronomical AI\nThe post The Evolution of Astronomical AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-evolution-of-astronomical-ai/",
          "publishedOn": "2022-03-28T13:14:39.000Z",
          "wordCount": 1172,
          "title": "The Evolution of Astronomical AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_285562989.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56905",
          "author": "Andrey Koptelov",
          "description": "When such a sophisticated, risky, and complex technology like AI takes our lives by storm, a clearly defined set of rules on its usage is paramount. Previously, public concern was mostly focused on the inappropriate use of personal data. As AI becomes a key technology in many businesses and services, the attention is rightfully shifting… Read More »What to Do About the New AI Regulation?\nThe post What to Do About the New AI Regulation? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/what-to-do-about-the-new-ai-regulation/",
          "publishedOn": "2022-03-28T05:05:44.000Z",
          "wordCount": 1343,
          "title": "What to Do About the New AI Regulation?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/thisisengineering-raeng-8hgmG03spF4-unsplash.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56710",
          "author": "Rumzz Bajwa",
          "description": "From chatbots and other remote helpers to producing content, improving client encounters, AI companies are now rolling out significant improvements to the advanced promoting scene. While it might be hard to foresee what’s to come, it’s not difficult to see that AI will proceed to advance and assume an undeniably focal point in computerized advertising.… Read More »How Automation and AI Are Changing Internet Marketing\nThe post How Automation and AI Are Changing Internet Marketing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-automation-and-ai-are-changing-internet-marketing/",
          "publishedOn": "2022-03-28T05:03:28.000Z",
          "wordCount": 1204,
          "title": "How Automation and AI Are Changing Internet Marketing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_238361901.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56797",
          "author": "Sonia Mathias",
          "description": "What is Data Science? Data science is a study that helps us to extract information from a set of structured or unstructured data. It makes use of the study of statistics, mathematics, scientific computation to analyze the data.  Demand for Python in Data Science: Before we deep dive into the topic let’s firstly discuss why… Read More »How Python Became THE Language for Data Science\nThe post How Python Became THE Language for Data Science appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-python-became-the-language-for-data-science/",
          "publishedOn": "2022-03-28T04:58:08.000Z",
          "wordCount": 2042,
          "title": "How Python Became THE Language for Data Science",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_283882447.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56924",
          "author": "Kerry Pearce",
          "description": "In today’s landscape, businesses need to look for any competitive advantage they can to ensure their survival, growth and success. A key aspect of gaining a competitive advantage is using data-driven insights to empower decisions for marketing, consumer insights, consumer segmentation, and operations, such as merchandising and real estate.  Especially within large companies, it is… Read More »Three Critical Steps for Data-Driven Success\nThe post Three Critical Steps for Data-Driven Success appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/three-critical-steps-for-data-driven-success/",
          "publishedOn": "2022-03-28T04:52:42.000Z",
          "wordCount": 1259,
          "title": "Three Critical Steps for Data-Driven Success",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_270256472.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56894",
          "author": "Indhu",
          "description": "Data governance is the management of organizations’ data availability, usability, integrity, security, and privacy. According to Gartner, Data governance is the specification of decision rights and a framework for accountability to assure acceptable behavior in the value, generation, consumption, and control of data and analytics. Why Do Organizations Need It? It ensures that data is consistent,… Read More »Data Governance Tool: What To Look For?\nThe post Data Governance Tool: What To Look For? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-governance-tool-what-to-look-for/",
          "publishedOn": "2022-03-28T04:38:53.000Z",
          "wordCount": 770,
          "title": "Data Governance Tool: What To Look For?",
          "imageUrl": null
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56908",
          "author": "EdwardNick",
          "description": "Introduction Security is the buzzword for the digital world today. Businesses have realized that thriving and surviving without a well-functioning security system in place is tough. Security breaches, malware, ransomware and similar incidents are real. The businesses that have suffered from malicious attacks very well know how grave these attacks can be.  The importance of… Read More »Top MDM-Enabled Data Security Hacks You Should Know About\nThe post Top MDM-Enabled Data Security Hacks You Should Know About appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/top-mdm-enabled-data-security-hacks-you-should-know-about/",
          "publishedOn": "2022-03-28T04:24:35.000Z",
          "wordCount": 1606,
          "title": "Top MDM-Enabled Data Security Hacks You Should Know About",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_124464399-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56911",
          "author": "Howard M. Wiener",
          "description": "If you are running a business today using Agile methods, it’s likely that you are not getting the productivity boost from it that you should, and your time to market for new features is probably not what it could be either. Is that the end of the world?  By and large, yes!  The problem is… Read More »Agile, Agile 2 and Agility, Part I\nThe post Agile, Agile 2 and Agility, Part I appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/agile-agile-2-and-agility-part-i/",
          "publishedOn": "2022-03-27T23:54:24.000Z",
          "wordCount": 1447,
          "title": "Agile, Agile 2 and Agility, Part I",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_233869090.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56926",
          "author": "Nikita Godse",
          "description": "The dynamics of the global commercial artificial intelligence market continues to change over time, thanks to the persistent advancements in technology. This research report offers a detailed and insightful assessment of the global commercial artificial intelligence market, taking primary trends and the future prospects of this market in consideration. Various segments of this market, based on a… Read More »Commercial Artificial Intelligence — The Future of BI\nThe post Commercial Artificial Intelligence — The Future of BI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/commercial-artificial-intelligence-the-future-of-bi/",
          "publishedOn": "2022-03-27T23:29:31.000Z",
          "wordCount": 941,
          "title": "Commercial Artificial Intelligence — The Future of BI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/commercial-AI.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56941",
          "author": "ajitjaokar",
          "description": "One of the best known examples of GPT-3 for developers is the Github co-pilot Trained on billions of lines of public code, GitHub Copilot is more than autocomplete of code. GitHub Copilot is powered by Codex, the new AI system created by OpenAI. GitHub Copilot understands significantly more context than most code assistants. GitHub Copilot… Read More »GitHub Co-Pilot Alternatives: Can They Match the Functionality of Co-Pilot?\nThe post GitHub Co-Pilot Alternatives: Can They Match the Functionality of Co-Pilot? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-do-github-co-pilot-alternatives-work-and-can-they-match-the-functionality-of-co-pilot/",
          "publishedOn": "2022-03-27T23:00:41.000Z",
          "wordCount": 858,
          "title": "GitHub Co-Pilot Alternatives: Can They Match the Functionality of Co-Pilot?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_303166297.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56789",
          "author": "Lewis Wynne-Jones",
          "description": "Increasingly, companies are focused on finding ways to connect to new and valuable sources of data in order to enhance their analytical capabilities, enrich their models, or deliver more insight to their business units.  Due to the increased demand for new data sources, companies are also looking at their internal data differently. Organizations that have… Read More »Five Key Components of a Data Sharing Platform\nThe post Five Key Components of a Data Sharing Platform appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/five-key-components-of-a-data-sharing-platform/",
          "publishedOn": "2022-03-27T20:40:07.000Z",
          "wordCount": 2042,
          "title": "Five Key Components of a Data Sharing Platform",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_267227310.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56785",
          "author": "Eric Whitley",
          "description": "Despite the technological breakthroughs in the advent of Industry 4.0, manufacturers seem to have taken a more gradual approach to adoption. In 2020, less than 30 percent of the industry considered themselves extensive users of advanced integrated tools and processes. The pandemic, however, brought out an unprecedented need to explore opportunities that make manufacturing systems… Read More »Smart Maintenance – How SaaS Frameworks Turn Insights Into Actions Quickly And Efficiently\nThe post Smart Maintenance – How SaaS Frameworks Turn Insights Into Actions Quickly And Efficiently appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/smart-maintenance-how-saas-frameworks-turn-insights-into-actions-quickly-and-efficiently/",
          "publishedOn": "2022-03-27T19:10:19.000Z",
          "wordCount": 1478,
          "title": "Smart Maintenance – How SaaS Frameworks Turn Insights Into Actions Quickly And Efficiently",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_124464399.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56930",
          "author": "Aileen Scott",
          "description": "What is the toll-free number? Businesses provide a cloud-based contact number to allow customers to contact them free of cost. In India, this number- the business toll-free number is available in the 1800 series in an easily recognizable format- 1800-ABC-DEFG. Customers do not have to incur any fee to contact the business, as the company… Read More »Toll-free number: What is it, and how can you get one for your business?\nThe post Toll-free number: What is it, and how can you get one for your business? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/toll-free-number-what-is-it-and-how-can-you-get-one-for-your-business/",
          "publishedOn": "2022-03-27T08:41:11.000Z",
          "wordCount": 1212,
          "title": "Toll-free number: What is it, and how can you get one for your business?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_481168446.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56931",
          "author": "Ryan Williamson",
          "description": "With the exponential growth in the number of big data applications in the world, Testing in big data applications is related to database, infrastructure and performance testing, and functional testing. The advancement of technology is enabling the collection of a massive amount of data almost every second. And, big data has emerged as the buzzword… Read More »Top Strategies and Best Practices for Big Data Testing\nThe post Top Strategies and Best Practices for Big Data Testing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/top-strategies-and-best-practices-for-big-data-testing/",
          "publishedOn": "2022-03-27T07:42:35.000Z",
          "wordCount": 1005,
          "title": "Top Strategies and Best Practices for Big Data Testing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/stephen-dawson-qwtCeJ5cLYs-unsplash.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56934",
          "author": "Kurt Cagle",
          "description": "Gaming, creating CGI movies, building shared worlds, and creating digital twins are exciting in principle, but the complexity of building 3D models usually serves to limit the ambition of even the most dedicated auteur. However, recent innovations by nVidia, announced earlier this year for their RTX 3090 line of GPUs, are very likely to change… Read More »NERFs To Make 3D As Simple As Shooting a Video\nThe post NERFs To Make 3D As Simple As Shooting a Video appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/nerfs-to-make-3d-as-simple-as-making-a-video/",
          "publishedOn": "2022-03-25T23:49:23.000Z",
          "wordCount": 1048,
          "title": "NERFs To Make 3D As Simple As Shooting a Video",
          "enclosure": {
            "url": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/tokyo_online_training_counter.mp4",
            "length": "3074853",
            "type": "video/mp4"
          },
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/2022-03-25.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56798",
          "author": "Roopesh Uniyal",
          "description": "Introduction Splunk is a well-known log management tool. Splunk mines log from different machines in real-time and can be used to monitor, search, and analyze gathered data. It is a Big Data log management tool that can give insight from the unstructured data stored in the Splunk indexes. Splunk analytics helps turn unstructured log data… Read More »Business Analytics from Application Logs and Database using Splunk\nThe post Business Analytics from Application Logs and Database using Splunk appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/business-analytics-from-application-logs-and-database-using-splunk/",
          "publishedOn": "2022-03-24T04:57:27.000Z",
          "wordCount": 3425,
          "title": "Business Analytics from Application Logs and Database using Splunk",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_192759495.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56700",
          "author": "Kurt Cagle",
          "description": "It is easy, when dealing with data, to think of it as something tangible. More precisely, data as water (or as oil) has become such a powerful metaphor that many managers, and even more than a few more technically-oriented people, have come to accept the fact that data engineering is largely about moving data from… Read More »DSC Weekly Newsletter 22 March 2022: The Shape of Data\nThe post DSC Weekly Newsletter 22 March 2022: The Shape of Data appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-newsletter-22-march-2022-the-shape-of-data/",
          "publishedOn": "2022-03-23T22:40:38.000Z",
          "wordCount": 1563,
          "title": "DSC Weekly Newsletter 22 March 2022: The Shape of Data",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_171906322.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56771",
          "author": "Alan Morrison",
          "description": "The US Securities and Exchange Commission (SEC), which regulates public company securities, recently proposed its own climate impact reporting requirement. Many US public companies already voluntarily publish information on this topic for shareholders who have been asking for those details. But various state GOP attorneys general are already questioning the SEC’s ability to impose the… Read More »Avoid RegTech myopia with a data-centric approach\nThe post Avoid RegTech myopia with a data-centric approach appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/avoid-regtech-myopia-with-a-data-centric-approach/",
          "publishedOn": "2022-03-23T03:29:31.000Z",
          "wordCount": 1883,
          "title": "Avoid RegTech myopia with a data-centric approach",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/a-book-g66ca555f4_1920.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56776",
          "author": "Alan Morrison",
          "description": "The previous post covered the problem of oversiloing. Systems thinking, I pointed out, can help reduce the practice of siloing when it’s not necessary.  In earlier posts, I’ve contrasted the difference between provincial IT and data-centric IT:  Provincial IT is no longer necessary given the advances in compute, networking and storage we’ve seen over the… Read More »The long game: Feedback loops and desiloed systems by design (Part II of II)\nThe post The long game: Feedback loops and desiloed systems by design (Part II of II) appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-long-game-feedback-loops-and-desiloed-systems-by-design-part-ii-of-ii/",
          "publishedOn": "2022-03-23T03:26:26.000Z",
          "wordCount": 1373,
          "title": "The long game: Feedback loops and desiloed systems by design (Part II of II)",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/robot-hand-human-handshake-robotic-partner-1638452-pxhere.com_-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56737",
          "author": "Lewis Wynne-Jones",
          "description": "How does Spotify battle against a giant like Apple? One word: data. With machine learning and AI, Spotify creates value for its users by providing a more personalized and bespoke experience. Let’s take a quick look at the layers of aggregate information that are used to enhance their platform: Spotify uses natural language processing (NLP)… Read More »How Metadata Improves Security, Quality, and Transparency\nThe post How Metadata Improves Security, Quality, and Transparency appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-metadata-improves-security-quality-and-transparency/",
          "publishedOn": "2022-03-22T22:48:54.000Z",
          "wordCount": 1510,
          "title": "How Metadata Improves Security, Quality, and Transparency",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_421839458.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56741",
          "author": "Roopesh Uniyal",
          "description": "Introduction/ Problem  Splunk is a well-known log management tool. Splunk mines log from different machines in real-time and can be used to monitor, search, and analyze gathered data. It is a Big Data log management tool that can give insight from the unstructured data stored in the Splunk indexes. Splunk analytics helps turn unstructured log… Read More »Business Analytics from Application Logs and SQL Server Database using Splunk \nThe post Business Analytics from Application Logs and SQL Server Database using Splunk  appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/business-analytics-from-application-logs-and-sql-server-database-using-splunk/",
          "publishedOn": "2022-03-22T19:05:47.000Z",
          "wordCount": 3358,
          "title": "Business Analytics from Application Logs and SQL Server Database using Splunk",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_192759495.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56731",
          "author": "Alberto Pan",
          "description": "For years, organizations have been working steadily to consolidate their data into a single place via a data warehouse, or more recently, a data lake. Data lakes offer key advantages over data warehouses, data marts, and traditional databases that require data to be structured and organized in particular ways. However, businesses have found that they… Read More »Tips for Weaving and Implementing a Successful Data Mesh\nThe post Tips for Weaving and Implementing a Successful Data Mesh appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/tips-for-weaving-and-implementing-a-successful-data-mesh/",
          "publishedOn": "2022-03-22T14:56:32.000Z",
          "wordCount": 1468,
          "title": "Tips for Weaving and Implementing a Successful Data Mesh",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_492259907.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56657",
          "author": "Alaa Mahjoub, M.Sc. Eng.",
          "description": "In many cases, for an enterprise to build its digital business technology platform, it must modernize its traditional data and analytics architecture. A modern data and analytics platform should be built on services-based principles and architecture. Introduction part 1, provided a conceptual-level reference architecture of a traditional Data and Analytics (D&A) platform. This part, provides… Read More »How to Modernize Enterprise Data and Analytics Platform (Part 2 of 4)\nThe post How to Modernize Enterprise Data and Analytics Platform (Part 2 of 4) appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-to-modernize-enterprise-data-and-analytics-platform-part-2-of-4/",
          "publishedOn": "2022-03-22T13:06:47.000Z",
          "wordCount": 4905,
          "title": "How to Modernize Enterprise Data and Analytics Platform (Part 2 of 4)",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_82481652-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56708",
          "author": "Karen Anthony",
          "description": "AI has been making its way into the marketing world over the last few years. Businesses have touted it as the solution to their problems and a way to incorporate technology into their processes. But, how is AI changing SEO? How can you use AI to improve your business? Machine learning and artificial intelligence are… Read More »AI SEO: How AI Helps You Optimize Content for Search Results\nThe post AI SEO: How AI Helps You Optimize Content for Search Results appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-seo-how-ai-helps-you-optimize-content-for-search-results/",
          "publishedOn": "2022-03-22T04:03:00.000Z",
          "wordCount": 1175,
          "title": "AI SEO: How AI Helps You Optimize Content for Search Results",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_336034066.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56705",
          "author": "Indhu",
          "description": "Every time we think we have grasped a new technology and its use. Sometimes that shift is an increase in the technology itself that seemingly intensifies the original version. Sometimes something happens that causes a significant transformation in the technology’s nature. As the technology’s significance is increasingly understood, the name is altered to better reflect… Read More »Understanding the Role of Augmented Data Catalogs in Data Governance\nThe post Understanding the Role of Augmented Data Catalogs in Data Governance appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/understanding-the-role-of-augmented-data-catalogs-in-data-governance/",
          "publishedOn": "2022-03-22T03:58:08.000Z",
          "wordCount": 1113,
          "title": "Understanding the Role of Augmented Data Catalogs in Data Governance",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/Role-of-augmented-data-catalog-in-data-governance-2.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56714",
          "author": "Stephanie Glen",
          "description": "Issues that will affect the metaverse range from hacking to cyberbullying. Proposed solutions are far from perfect. We may see end-to-end encryption disappear soon. The only real solution might be not to enter the metaverse at all. The advent of the metaverse compounds a list of existing security concerns. The addition of another dimension to… Read More »Security Issues in The Metaverse\nThe post Security Issues in The Metaverse appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/security-issues-in-the-metaverse/",
          "publishedOn": "2022-03-22T03:15:53.000Z",
          "wordCount": 1251,
          "title": "Security Issues in The Metaverse",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_487606894.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56683",
          "author": "Michael Ido",
          "description": "In this short blog, we’ll review the process of taking a POC data science pipeline (ML/Deep learning/NLP) that was conducted on Google Colab, and transforming it into a pipeline that can run parallel at scale and works with Git so the team can collaborate on. Background Google Colab is pretty straightforward, you can open a… Read More »Google Colab to a Ploomber pipeline: ML at scale\nThe post Google Colab to a Ploomber pipeline: ML at scale appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/google-colab-to-a-ploomber-pipeline-ml-at-scale/",
          "publishedOn": "2022-03-20T18:46:30.000Z",
          "wordCount": 870,
          "title": "Google Colab to a Ploomber pipeline: ML at scale",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/colab.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56692",
          "author": "ajitjaokar",
          "description": "The Stanford HAI (Human cantered artificial intelligence) report is out. I track this report every year and it always has some good insights. The report is a bit more focused on large language models and their impact – but also covers key trends The main findings are Private investment in AI soared while investment concentration… Read More »Biases in CLIP and the Stanford HAI report\nThe post Biases in CLIP and the Stanford HAI report appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/biases-in-clip-and-the-stanford-hai-report/",
          "publishedOn": "2022-03-20T18:41:00.000Z",
          "wordCount": 743,
          "title": "Biases in CLIP and the Stanford HAI report",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/CLIP-edited.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56648",
          "author": "Alaa Mahjoub, M.Sc. Eng.",
          "description": "Data and Analytics Platform is a sub-platform of the Enterprise Digital Business Technology Platform. It contains information management and analytical capabilities. Introduction Building the digital business technology platform is a core aspect of enterprise endeavors to support its digital business transformation and therefore gain a sustainable competitive advantage. The digital business technology platform includes 5… Read More »How to Modernize Enterprise Data and Analytics Platform (Part 1 of 4)\nThe post How to Modernize Enterprise Data and Analytics Platform (Part 1 of 4) appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-to-modernize-enterprise-data-and-analytics-platform-part-1-of-4/",
          "publishedOn": "2022-03-20T18:33:26.000Z",
          "wordCount": 1791,
          "title": "How to Modernize Enterprise Data and Analytics Platform (Part 1 of 4)",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_463519989.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56662",
          "author": "Bill Schmarzo",
          "description": "I attended an in-person customer event sponsored by Dataiku last week.  Very fun.  Man, do I miss the provocative and enlightening discussions that occur in these face-to-face customer engagements.  The icebreaker for fueling the dinner discussions was the following statement: “In the marketplace, dynamics in the job marketplace will evolve, and data-savvy subject matter experts… Read More »Is Data Scientist Weak Link in Data-drive Value Creation?\nThe post Is Data Scientist Weak Link in Data-drive Value Creation? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-management/",
          "publishedOn": "2022-03-19T14:27:01.000Z",
          "wordCount": 2105,
          "title": "Is Data Scientist Weak Link in Data-drive Value Creation?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/Slide1-2.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56550",
          "author": "Kurt Cagle",
          "description": "I blew it last week. I’ll readily admit it. Blame it on the flu or Covid or whatever the nasty bug was that confined me to bed for a day and fuzzy for a few. It’s not often that the 15th of March happens to come up on the same day as the weekly newsletter… Read More »DSC Weekly Digest 15 March 2022: Beware the Ides of …\nThe post DSC Weekly Digest 15 March 2022: Beware the Ides of … appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-digest-15-march-2022-beware-the-ides-of/",
          "publishedOn": "2022-03-15T17:37:00.000Z",
          "wordCount": 1296,
          "title": "DSC Weekly Digest 15 March 2022: Beware the Ides of …",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_107874873.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56640",
          "author": "Zachary Amos",
          "description": "One of the biggest arguments against the development of artificial intelligence — if you disregard the perpetual fear that it will gain sentience and destroy the human race — is the worry that these systems will steal our jobs. We’ve already seen some mundane or tedious tasks get taken over by robotics or automation, so… Read More »Think AI Can’t Take Your Job? Think Again\nThe post Think AI Can’t Take Your Job? Think Again appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/think-ai-cant-take-your-job-think-again/",
          "publishedOn": "2022-03-15T00:26:55.000Z",
          "wordCount": 1251,
          "title": "Think AI Can’t Take Your Job? Think Again",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_209497228.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56605",
          "author": "Stephanie Glen",
          "description": "The metaverse has recently come to the forefront of the internet, especially in online gaming, but it’s not a new idea. The concept has been developing for decades, shortly after the internet was born. The above image is based on one I came across in an article on AI in the Metaverse [1]. Working from… Read More »History of the Metaverse in One Picture\nThe post History of the Metaverse in One Picture appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/history-of-the-metaverse-in-one-picture/",
          "publishedOn": "2022-03-14T19:58:32.000Z",
          "wordCount": 1306,
          "title": "History of the Metaverse in One Picture",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/Dystopia-1024x867.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56611",
          "author": "Vincent Granville",
          "description": "Many of us dream of starting a side business selling our knowledge, in one way or another. Though the market is highly competitive, selling eBooks or technical reports is one of the easiest businesses to set up. One of the problems is that technical PDF documents are incompatible with standards publishing formats available for digital… Read More »Selling Your Digital Content on Amazon, Without Kindle\nThe post Selling Your Digital Content on Amazon, Without Kindle appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/selling-your-digital-content-on-amazon-without-kindle/",
          "publishedOn": "2022-03-14T19:00:31.000Z",
          "wordCount": 1787,
          "title": "Selling Your Digital Content on Amazon, Without Kindle",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_256067904.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56572",
          "author": "Scott Thompson",
          "description": "The field of healthcare intersects with data science through the tools and methodologies that  practitioners use to diagnose their patients. Advances in medical science, coupled with advances in data visualization, allow for physicians and patients alike to better understand their risk factors and treatment options. Having more usable data from less intrusive methods empowers patients… Read More »Data Augmented Healthcare Part 1\nThe post Data Augmented Healthcare Part 1 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-augmented-healthcare-part-1/",
          "publishedOn": "2022-03-14T15:02:57.000Z",
          "wordCount": 841,
          "title": "Data Augmented Healthcare Part 1",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_233203309-2-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56598",
          "author": "Karen Anthony",
          "description": "A considerable part of the population uses mobile devices and computers to search data. They also store and perform data procedures. However, not everyone is aware of the relevance of data backup. Your crucial data is essential for anything that you do. It is here that technical support companies can help. Whether it’s your desktop… Read More »Why is Data Back-Up Necessary? The Benefits of Availing Technical Support\nThe post Why is Data Back-Up Necessary? The Benefits of Availing Technical Support appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/why-is-data-back-up-necessary-the-benefits-of-availing-technical-support/",
          "publishedOn": "2022-03-13T23:42:21.000Z",
          "wordCount": 921,
          "title": "Why is Data Back-Up Necessary? The Benefits of Availing Technical Support",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_491591283.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56582",
          "author": "Ryan Williamson",
          "description": "As mobile apps continue to become increasingly intricate offerings, there has been an immense focus on testing these apps too. This is understandable because often mobile apps are the foundation of the business and any issues in the department can deal a major blow to the organization. The testing of a mobile app is a… Read More »Cloud-Based Mobile App Testing: A Complete Guide\nThe post Cloud-Based Mobile App Testing: A Complete Guide appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/cloud-based-mobile-app-testing-a-complete-guide/",
          "publishedOn": "2022-03-13T23:34:58.000Z",
          "wordCount": 924,
          "title": "Cloud-Based Mobile App Testing: A Complete Guide",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_105307144.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56613",
          "author": "ajitjaokar",
          "description": "The European Commission published a draft AI Regulation this week that is the world’s first concrete proposal for regulating artificial intelligence (AI). Like GDPR, the Draft AI Regulation is likely to affect AI development globally profoundly. The regulation applies to AI systems, i.e. to any software that can generate content, make predictions, make recommendations, or… Read More »Opening the Pod Bay Door: Regulating multi-purpose AI\nThe post Opening the Pod Bay Door: Regulating multi-purpose AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/opening-the-pod-bay-door-regulating-multi-purpose-ai/",
          "publishedOn": "2022-03-13T20:28:56.000Z",
          "wordCount": 711,
          "title": "Opening the Pod Bay Door: Regulating multi-purpose AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_51269601.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56565",
          "author": "Nikita Godse",
          "description": "Augmented (AR) and virtual reality combine truth with digital content. Automotive businesses are relying on AR & VR to improve their production, maintenance, cockpit individualization, efficient publicity and marketing to improve client satisfaction. Special 3D programs for AR apps are developers who incorporate real-world digital contexts. In order to provide synthetic experience and virtual feedback,… Read More »Automotive AR and VR — Prototyping in the Virtual World\nThe post Automotive AR and VR — Prototyping in the Virtual World appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/automotive-ar-and-vr-prototyping-in-the-virtual-world/",
          "publishedOn": "2022-03-13T19:07:26.000Z",
          "wordCount": 630,
          "title": "Automotive AR and VR — Prototyping in the Virtual World",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/Automotive-AR-and-VR-industry-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56575",
          "author": "Indhu",
          "description": "In the past, Metadata Management is used to know how to use data catalog to find simple data or a book or a periodical in a library. However, today it is one of the most critical data practices for a successful organization dealing with data. With the rise of distributed architectures, including cloud & big… Read More »Why do you need a metadata management system? Definition and Benefits.\nThe post Why do you need a metadata management system? Definition and Benefits. appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/why-do-you-need-a-metadata-management-system-definition-and-benefits/",
          "publishedOn": "2022-03-13T18:22:03.000Z",
          "wordCount": 985,
          "title": "Why do you need a metadata management system? Definition and Benefits.",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/what-is-metadata-management.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56574",
          "author": "Sameer Narkhede",
          "description": "You’ve all heard the saying “Garbage in, garbage out” and probably have your own horror story about wrestling data to the ground over missing values, inconsistent codes, or variable formats.  It is hard to argue that you don’t need better data quality to make better decisions, but is better data quality enough? If the formats… Read More »When Good Data Goes Bad\nThe post When Good Data Goes Bad appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/when-good-data-goes-bad/",
          "publishedOn": "2022-03-12T09:36:05.000Z",
          "wordCount": 1763,
          "title": "When Good Data Goes Bad",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_298054607-1.jpg"
        }
      ]
    },
    {
      "title": "John D. Cook",
      "feedUrl": "https://www.johndcook.com/blog/feed",
      "siteUrl": "https://www.johndcook.com/blog",
      "articles": [
        {
          "id": "https://www.johndcook.com/blog/?p=101985",
          "author": "John",
          "description": "The Hilbert transform of a function f(t) is a function fH(x) defined [1] by The integral must be interpreted in the sense of the Cauchy principal value: The integrand is not absolutely integrable because of the singularity at x and so the value of the integral depends on how you handle the singularity. The Cauchy […]\nHilbert transform and Mathematica first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/08/hilbert-transform-and-mathematica/",
          "publishedOn": "2022-04-08T15:12:50.000Z",
          "wordCount": 675,
          "title": "Hilbert transform and Mathematica",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101943",
          "author": "John",
          "description": "The plot below is of a meromorphic function f(z). That is, the function f(z) is analytic except possibly at poles, and the colors represent the phase angles, the values of θ if you write the function values in polar form. What is the value of the integral where C is the perimeter of the square? […]\nVisual integration first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/08/visual-integration/",
          "publishedOn": "2022-04-08T11:10:02.000Z",
          "wordCount": 514,
          "title": "Visual integration",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101905",
          "author": "John",
          "description": "Regular expressions can do a lot of tasks in practice that they cannot do in theory. That’s because a particular application of regular expressions comes with context and with error tolerance. For example, much has been said about how regular expressions cannot parse HTML. This is strictly true, but it says nothing about how well […]\nRegular expressions and successive approximation first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/07/regex-approximation/",
          "publishedOn": "2022-04-07T14:00:43.000Z",
          "wordCount": 864,
          "title": "Regular expressions and successive approximation",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101812",
          "author": "John",
          "description": "A couple days ago I wrote about how Vieta’s formulas let you sum the zeros of a polynomial without having to first compute the zeros. This is especially handy for high-order polynomials since there is no explicit formula for the zeros. Most functions that arise in applications are not polynomials. How could you find the […]\nSum the zeros of an analytic function without finding them first first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/06/sum-analytic-function-zeros/",
          "publishedOn": "2022-04-06T13:22:57.000Z",
          "wordCount": 790,
          "title": "Sum the zeros of an analytic function without finding them first",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101725",
          "author": "John",
          "description": "The previous post looked at the problem of finding the zeros of a cubic polynomial. Assuming we’re going to use a numerical method to calculate the zero, the hard part is knowing where to tell the numerical method to look. That post showed how to use a change of variables to guarantee that the polynomial […]\nBounding zeros of an analytic function first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/05/analytic-zeros/",
          "publishedOn": "2022-04-05T14:33:39.000Z",
          "wordCount": 748,
          "title": "Bounding zeros of an analytic function",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101681",
          "author": "John",
          "description": "The analog of the quadratic formula for cubic equations is cumbersome. A lot of people naturally say “Forget all that. If I need to find the roots of a cubic, I’ll just use a numerical method like Newton’s method.” Sounds good. Where to start? But how do you know where to look for the roots? […]\nNumerically finding roots of a cubic first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/05/cubic/",
          "publishedOn": "2022-04-05T12:00:16.000Z",
          "wordCount": 903,
          "title": "Numerically finding roots of a cubic",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101654",
          "author": "John",
          "description": "The following is a slightly edited version of a Twitter thread on @AlgebraFact. The lowest C on a piano is called C1 in scientific pitch notation. The C one octave up is C2 and so forth. Middle C is C4. The frequency of Cn is approximately 2n+4 Hz. This would be exact if C0 were […]\nMathematics and piano tuning first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/mathemacs-and-piano-tuning/",
          "publishedOn": "2022-04-04T23:19:24.000Z",
          "wordCount": 478,
          "title": "Mathematics and piano tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101658",
          "author": "John",
          "description": "Once in a while it’s necessary to calculate some function of the roots of a polynomial, and it may be possible to do this without first calculating the roots. Quadratics The quadratic formula gives explicit solutions to the equation The two solutions for x are where The awkward part is taking the square root of […]\nComputing functions of roots without computing roots first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/vieta/",
          "publishedOn": "2022-04-04T14:42:33.000Z",
          "wordCount": 925,
          "title": "Computing functions of roots without computing roots",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101533",
          "author": "John",
          "description": "This post contains a derives a result I needed recently. The derivation is simple but a little tedious, so I wanted to save it in case I need it again. Full width half maximum A common way to measure the width of a function peak in a function f(x) is to find the place x0 […]\nFWHM for a quadratic first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/fwhm-quadratic/",
          "publishedOn": "2022-04-04T12:59:26.000Z",
          "wordCount": 693,
          "title": "FWHM for a quadratic",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101648",
          "author": "John",
          "description": "Here’s a list of five numbers used as slang in various contexts. Location (CB and police radio) End of column (journalism) Best wishes (ham radio) All aircraft in area (US Navy) I love you (text messages) The motivation for this post was an article Those HTML attributes you never use. I wanted to make a […]\nNumber slang and numbered lists first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/number-slang-and-numbered-lists/",
          "publishedOn": "2022-04-04T12:39:43.000Z",
          "wordCount": 242,
          "title": "Number slang and numbered lists",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101499",
          "author": "John",
          "description": "Electrical and mechanical oscillations satisfy analogous equations. This is the basis of using the word “analog” in electronics. You could study a mechanical system by building an analogous circuit and measuring that circuit in a lab. Mass, dashpot, spring Years ago I wrote a series of four posts about mechanical vibrations: Free, undamped vibrations Free, […]\nOscillations in RLC circuits first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/02/rlc-circuits/",
          "publishedOn": "2022-04-02T17:16:43.000Z",
          "wordCount": 548,
          "title": "Oscillations in RLC circuits",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101269",
          "author": "John",
          "description": "The length of antenna you need to receive a radio signal is proportional to the signal’s wavelength, typically 1/2 or 1/4 of the wavelength. Cell phones operate at gigahertz frequencies, and so the antennas are small enough to hide inside the phone. But AM radio stations operate at much lower frequencies. For example, there’s a […]\nHow is portable AM radio possible? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/30/portable-am-radio/",
          "publishedOn": "2022-03-30T16:20:14.000Z",
          "wordCount": 1127,
          "title": "How is portable AM radio possible?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101260",
          "author": "John",
          "description": "At first glance, continued fractions look more like a curiosity than like useful mathematics. And yet they come up surprisingly often in applications. For an irrational number x, the numbers you get by truncating the infinite continued fraction for x are the optimal rational approximations to x given the size of their denominators. For example, […]\nApplications of continued fractions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/30/continued-fraction-applications/",
          "publishedOn": "2022-03-30T13:32:24.000Z",
          "wordCount": 459,
          "title": "Applications of continued fractions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101207",
          "author": "John",
          "description": "I mentioned smoothed step functions in the previous post. What would you do if you needed to concretely use a smoothed step function and not just know that one exists? We’ll look at smoothed versions of the signum function sgn(x) = x / |x| which equals -1 for negative x and +1 for positive x. […]\nSmoothed step function first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/29/smoothed-step-function/",
          "publishedOn": "2022-03-29T16:07:30.000Z",
          "wordCount": 684,
          "title": "Smoothed step function",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101189",
          "author": "John",
          "description": "Partitions of unity are a handy technical device. They’re seldom the focus of attention but rather are buried in the middle of proofs. The name sounds odd, but it’s descriptive. A partition of unity is a set of smooth functions into the interval [0, 1] that add up to 1 at every point. The functions […]\nPartitions of unity, smooth ramps, and CW clicks first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/29/partition-of-unity/",
          "publishedOn": "2022-03-29T11:40:41.000Z",
          "wordCount": 587,
          "title": "Partitions of unity, smooth ramps, and CW clicks",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101066",
          "author": "John",
          "description": "Suppose you start with some large number x and want to find a prime number at least as big as x. First you test whether x is prime. Then you test whether x + 1 is prime. Then you test whether x + 2 is prime, and so on until you find a prime. Of […]\nLooking for the next prime first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/28/next-prime/",
          "publishedOn": "2022-03-28T13:52:14.000Z",
          "wordCount": 926,
          "title": "Looking for the next prime",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101009",
          "author": "John",
          "description": "I had heard of the Svalbard Global Seed Vault, but I hadn’t heard of the nearby Arctic World Archive until today. The latter contains source code preserved on film, a format that should last at least 500 years.\nSeed vault, but for code first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/27/seed-vault-but-for-code/",
          "publishedOn": "2022-03-27T23:19:41.000Z",
          "wordCount": 186,
          "title": "Seed vault, but for code",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=100720",
          "author": "John",
          "description": "Here’s a curious series for π that I ran across on Math Overflow. In case you’re unfamiliar with the notation, n!! is n double factorial, the product of the positive integers up to n with the same parity as n. More on that here. When n is 0 or -1, n!! is defined to be […]\nSeries for π first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/23/series-for-%cf%80/",
          "publishedOn": "2022-03-24T03:00:13.000Z",
          "wordCount": 330,
          "title": "Series for π",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=100670",
          "author": "John",
          "description": "Numbers in Morse code seem a little strange. Here they are: |-------+-------| | Digit | Code | |-------+-------| | 1 | .---- | | 2 | ..--- | | 3 | ...-- | | 4 | ....- | | 5 | ..... | | 6 | -.... | | 7 | --... | | 8 […]\nMorse code numbers and abbreviations first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/23/morse-code-numbers/",
          "publishedOn": "2022-03-23T14:52:54.000Z",
          "wordCount": 936,
          "title": "Morse code numbers and abbreviations",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=100600",
          "author": "John",
          "description": "A few days ago I wrote about Frequency Shift Keying (FSK), a way to encode digital data in an analog signal using two frequencies. The extension to multiple frequencies is called, unsurprisingly, Multiple Frequency Shift Keying (MFSK). What is surprising is how MFSK sounds. When I first heard MFSK I immediately recognized it as an […]\nMultiple Frequency Shift Keying first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/22/multiple-frequency-shift-keying/",
          "publishedOn": "2022-03-22T14:51:00.000Z",
          "wordCount": 868,
          "title": "Multiple Frequency Shift Keying",
          "enclosure": {
            "url": "https://www.johndcook.com/mfsk32.wav",
            "length": "22089",
            "type": "audio/wav"
          },
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=100543",
          "author": "John",
          "description": "Henry Lowengard left a comment on my post Phone tones in musical notation mentioning dial tones and busy signals, so I looked these up. Tones According to this page, a dial tone in DTMF [1] is a chord of two sine waves at 350 Hz and 440 Hz. In musical notation: According to the same […]\nDial tone and busy signal first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/22/dial-tone-and-busy-signal/",
          "publishedOn": "2022-03-22T09:23:56.000Z",
          "wordCount": 438,
          "title": "Dial tone and busy signal",
          "enclosure": {
            "url": "https://www.johndcook.com/dial2.wav",
            "length": "2159",
            "type": "audio/wav"
          },
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=100523",
          "author": "John",
          "description": "This post expands on a small part of the post Demystifying the Analemma by M. Tirado. Apparent solar declination given δ by δ = sin-1( sin(ε) sin(θ) ) where ε is axial tilt and θ is the angular position of a planet. See Tirado’s post for details. Here I want to unpack a couple things […]\nSolar declination first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/21/solar-declination/",
          "publishedOn": "2022-03-21T19:28:13.000Z",
          "wordCount": 447,
          "title": "Solar declination",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=100459",
          "author": "John",
          "description": "The most annoying thing about Fourier analysis is that there are many slightly different definitions of the Fourier transform. One time I got sufficiently annoyed that I creates a sort of Rosetta Stone of Fourier theorems under eight different conventions. Later I discovered that Mathematica supports these same eight definitions, but with slightly different notation. […]\nReverse engineering Fourier conventions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/20/reverse-engineering-fourier-conventions/",
          "publishedOn": "2022-03-20T18:26:39.000Z",
          "wordCount": 799,
          "title": "Reverse engineering Fourier conventions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=100171",
          "author": "John",
          "description": "Keenan Pepper left a comment on my previous post saying that the DTMF tones used by touch tone phones “are actually quite close to 14 equal divisions of the octave (rather than the usual 12).” Let’s show that this is right using a little Python. import numpy as np freq = np.array([697, 770, 852, 941, […]\nDividing an octave into 14 pieces first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/16/14-note-scale/",
          "publishedOn": "2022-03-16T19:07:11.000Z",
          "wordCount": 335,
          "title": "Dividing an octave into 14 pieces",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=100065",
          "author": "John",
          "description": "The sounds produced by a telephone keypad are a combination of two tones: one for the column and one for the row. This system is known as DTMF (dual tone multiple frequency). I’ve long wondered what these tones would be in musical terms and I finally went to the effort to figure it out when […]\nPhone tones in musical notation first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/14/phone-tones-in-musical-notation/",
          "publishedOn": "2022-03-14T15:43:45.000Z",
          "wordCount": 493,
          "title": "Phone tones in musical notation",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=100018",
          "author": "John",
          "description": "This post will look encoding digital data as an analog signal using frequency shift keying (FSK), first directly and then with windowing. We’ll look at the spectrum of the encoded signal and show that basic FSK uses much less bandwidth than direct encoding, but more bandwidth than FSK with windowing. Square waves The most natural […]\nFrequency shift keying (FSK) spectrum first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/13/fsk-spectrum/",
          "publishedOn": "2022-03-13T18:37:10.000Z",
          "wordCount": 841,
          "title": "Frequency shift keying (FSK) spectrum",
          "imageUrl": null
        }
      ]
    }
  ],
  "cliVersion": "1.14.4"
}